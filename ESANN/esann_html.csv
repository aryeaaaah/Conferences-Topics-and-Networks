Year,Title,Authors,Abstract,Keywords/Content Category,PDF link
2010,Solving Large Regression Problems using an Ensemble of GPU-accelerated ELMs,"Mark van Heeswijk, Yoan Miché, Erkki Oja, Amaury Lendasse","This paper presents an approach that allows for performing regression on large data sets in reasonable time. The main component of the approach consists in speeding up the slowest operation of the used algorithm by running it on the Graphics Processing Unit (GPU) of the video card, instead of the processor (CPU). The experiments show a speedup of an order of magnitude by using the GPU, and competitive performance on the regression task. Furthermore, the presented approach lends itself for further parallelization, that has still to be investigated.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-133.pdf
2010,Mode estimation in high-dimensional spaces with flat-top kernels: application to image denoising,"Arnaud de Decker, John Aldo Lee, Damien Francois, Michel Verleysen","Data denoising can be achieved by approximating the data distribution and replacing each data item with an estimate of its closest mode. This idea has already been successfully applied to image denoising. The data then consists of pixel intensities or image patches, that is, vectorized groups of pixel intensities. The latter case raises the issue of mode estimation in a high-dimensional space, since patches can contain about 10 to more than 100 pixels. This paper shows that the widely used Gaussian kernel is outperformed by flat-top kernels that are specifically tailored in order to fight the curse of dimensionality.",Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-91.pdf
2010,Figure-ground Segmentation using Metrics Adaptation in Level Set Methods,"Alexander Denecke, Irene Ayllon Clemente, Heiko Wersing, Julian Eggert, Jochen Steil","We present an approach for hypothesis-based image segmentation founding on the integration of level set methods and discriminative feature clustering techniques. Building up on previous work, we investigate Localized Generalized Matrix Learning Vector Quantization (LGMLVQ) to train a classifier for fore- and background of an image. Here we extend this concept towards level set segmentation algorithms,  where region descriptors are used to adapt the object contour according to the image features. Finally we demonstrate that the fusion of both methods is capable to outperform their individual applications and improve the performance compared to other state of the art segmentation methods.",Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-83.pdf
2010,An ART-type network approach for video object detection,"Rafael Luque, Enrique Domínguez, Esteban Palomo, José Muñoz","This paper presents an ART2 (adaptive resonant theory) network to detect objects in a video sequence classifying the pixels as foreground or background. The proposed ART network not only possess the structure and learning ability of an ART-based network, but also uses a neural merging process to adapt the variability of the input data (pixels) in the scene along the time. Experimental results demonstrate the effectiveness and feasibility of the proposed ART network for object detection. Standard datasets are used to compare the efficiency of the proposed approach against other traditional methods based on gaussian models.",Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-85.pdf
2010,Computational Intelligence in biomedicine: Some contributions,"Paulo J.G. Lisboa, Alfredo Vellido, José D. Martín",To be written,Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-2.pdf
2010,Segmentation of EMG time series using a variational Bayesian approach for the robust estimation of cortical silent periods,"Iván Olier, Amengual Julià, Alfredo Vellido",A variational Bayesian formulation for a manifold-constrained Hidden Markov Model is used in this paper to segment a set of multivariate time series of electromyographic recordings corresponding to stroke patients and control subjects. An index of variability associated to this model is defined and applied to the robust detection of the silent period interval of the signal. The accuracy in the estimation of the duration of this interval is paramount to assess the rehabilitation of stroke patients.,Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-45.pdf
2010,Spectral Prototype Extraction for dimensionality reduction in brain tumour diagnosis,"Sandra Ortega-Martorell, Iván Olier, Alfredo Vellido, Margarida Julià-Sapé, Carles Arús","Diagnosis in neuro-oncology can be assisted by non-invasive data acquisition techniques such as Magnetic Resonance Spectroscopy (MRS). From the viewpoint of computer-based brain tumour classification, the high dimensionality of MRS poses a difficulty, and the use of dimensionality reduction (DR) techniques is advisable. Despite some important limitations, Principal Component Analysis (PCA) is commonly used for DR in MRS data analysis. Here, we define a novel DR technique, namely Spectral Prototype Extraction, based on a manifold-constrained Hidden Markov Model (HMM). Its formulation within a variational Bayesian framework imbues it with regularization properties that minimize the negative effect of the presence of noise in the data. Its use for MRS pre-processing is illustrated in a difficult brain tumour classification problem.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-15.pdf
2010,On the use of a clinical kernel in survival analysis,"Vanya Van Belle, Kristiaan Pelckmans, Johan Suykens, Sabine Van Huffel","Clinical datasets typically contain continuous, ordinal, cate- gorical and binary variables. To model this type of datasets, linear kernel methods are generally used. However, the linear kernel has some disad- vantages, which were tackled by the introduction of a clinical one. This work shows that the use of a clinical kernel can improve the performance of support vector machine survival models. In addition, the polynomial kernel is adapted in the same way to obtain a clinical polynomial kernel. A comparison is made with other non-linear additive kernels on six different survival data. Our results indicate that the use of a clinical kernel is a simple way to obtain non-linear models for survival analysis, without the need to tune an extra parameter.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-16.pdf
2010,The Application of Gaussian Processes in the Prediction of Percutaneous Absorption for Mammalian and Synthetic Membranes,"Yi Sun, Gary Moss, Maria Prapopoulou, Rod Adams, Marc Brown, Neil Davey","Improving predictions of the skin permeability coefficient is a difficult problem, and an important issue with the increasing use of skin patches as a means of drug delivery. In this work, we apply Gaussian processes (GPs) with five different covariance functions to predict the permeability coefficients of Human, Pig, Rodent and Silastic membranes. We obtain a considerable improvement over the quantitative structure-activity relationship (QSARs) predictors. The GPs with Matern and neural network covariance functions give the best performance in this work. We find that five compound features applied to Human, Pig and Rodent membranes cannot represent the main characteristics of the Silastic dataset.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-35.pdf
2010,Neural models for the analysis of kidney disease patients,"Emilio Soria, José D. Martín, Mónica Climente, Amparo Soldevila, Antonio J. Serrano","This work uses Machine Learning techniques and other classical approaches to analyze both physiological variables and treatment characteristics in patients undergoing chronic renal failure. Firstly, the use of Self-Organizing Maps is proposed in order to extract qualitative knowledge. Secondly, the Hemoglobin concentration is predicted one-month ahead by models based on the Multilayer Perceptron; the prediction uses information from two months (the current month and the previous one). Achieved results support the usefulness of these tools in daily clinical practice.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-81.pdf
2010,Distance functions for local PCA methods,"Alexander Kaiser, Wolfram Schenck, Ralf Moeller","The NGPCA method, a combination of the robust neural gas vector quantization method and a fast neural principal component analyzer, has proved to be a valuable tool for the generalized learning of high-dimensional data. At its core, the method uses a competitive ranking to adapt its units. The competition is guided by a specialized distance function -- known as the normalized Mahalanobis distance -- that assumes elliptic cluster shapes. Recently, an alternative distance function, the normalized Rayleigh quotient, has been suggested. This paper compares the performance of NGPCA on different distance functions. For the comparison a data set from a realistic robot arm experiment is used.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-19.pdf
2010,KNN behavior with set-valued attributes,"Mabel González Castellanos, Yanet Rodríguez Sarabia, Carlos Morell Pérez","This paper addresses the problem of treatment of set-valued attributes in the lazy learning context. This type of attribute is present in various domains, yet the instance-based learning tools don't provide a representation for them. To solve this problem, we present a proposal for the treatment of the sets in the context of k-NN algorithm through an extension to HEOM distance. Experiments using various data sets show the feasibility of this option.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-33.pdf
2010,Kernel generative topographic mapping,"Iván Olier, Alfredo Vellido, Jesús Giraldo","A kernel version of Generative Topographic Mapping, a model of the manifold learning family, is defined in this paper. Its ability to adequately model non-i.i.d. data is illustrated in a problem concerning the identification of protein subfamilies from protein sequences.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-44.pdf
2010,On Finding Complementary Clusterings,"Timo Pröscholdt, Michel Crucianu","In many cases, a dataset can be clustered following several criteria that complement each other: group membership following one criterion provides little or no information regarding group membership following the other criterion. When these criteria are not known a priori, they have to be determined from the data. We put forward one method for simultaneously finding the complementary criteria and the clustering corresponding to each criterion.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-86.pdf
2010,Consensus clustering by graph based approach,"Haytham Elghazel, Khalid Benabdeslem, Fatma Hamdi","In this paper, we propose G-Cons, an extension of a minimal graph coloring paradigm for consensus clustering. Based on the co-association values between data, our approach is a graph partitioning one yielding a combined partition by maximizing an objective function given by the average mutual information between the consensus partition and all initial clusterings. It exhibits more important consensus clustering features (quality and computational complexity) and enables to build a combined partition by improving the stability and accuracy of clustering solutions. The proposed approach is evaluated against benchmark databases and promising results are obtained compared to another consensus clustering techniques.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-92.pdf
2010,Web Document Clustering based on a Hierarchical Self-Organizing Model,"Esteban Palomo, Enrique Domínguez, Rafael Luque, José Muñoz","In this work, a hierarchical self-organizing model based on the GHSOM is presented in order to cluster web contents. The GHSOM is an artificial neural network that has been widely used for data clustering. The hierarchical architecture of the GHSOM is more flexible than a single SOM since it is adapted to input data, mirroring inherent hierarchical relations among them. The adaptation process of the GHSOM architecture is controlled by two parameters. However, these parameters have to be established in advance and this task is not always easy. In this paper, a one parameter hierarchical self-organizing model is proposed. This model has been evaluated by using the 'BankSearch' benchmark dataset. Experimental results show the good performance of this approach.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-89.pdf
2010,Online speaker diarization with a size-monitored growing neural gas algorithm,"Jean-Louis Gutzwiller, Hervé Frezza-Buet, Olivier Pietquin","This paper proposes a method for segmenting and clustering an audio flow on the basis of speaker turns. This process, also known as speaker diarization, is of major importance in multimedia indexation. Here, we propose to realize this process online and without any prior knowledge on the number of speakers. This is done thanks to a  statistical modelling of speakers based on a size-monitored growing neural gas algorithm.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-49.pdf
2010,Validation of unsupervised clustering methods for leaf phenotype screening,"Andreas Backhaus, Asuka Kuwabara, Andrew Fleming, Udo Seiffert","The assessment of visible differences in leaf shape between plant species or mutants (phenotyping) plays a significant role in plant research. This paper investigates the application of unsupervised data clustering techniques for phenotype screening to find hidden common shape categories. A set of two wildtypes and seven mutations of Arabidopsis acted as a test case. K-Means, NG, GNG, SOM and ART2a were evaluated by classical validity indices and one index derived from the task at hand. K-Means showed the best results and a low agreement between classical validity measures and task constraints was found.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-59.pdf
2010,A Novel Two-Phase SOM Clustering Approach to Discover Visitor Interests in a Website,"Ahmad Ammari, Valentina Zharkova","Mining content, structure and usage data in websites can uncover browsing patterns that different groups of Web visitors follow to access the subjects that are truly valuable to them. Many works in the literature focused on proposing new similarity measures to cluster Web logs and detect segments of browsing behaviors. However, this does not reveal which contents the visitors are interested in since a Web page may contain many different topics. In this paper, a novel two-phase clustering approach based on Self Organizing Maps (SOM) is proposed to address this problem. A systematic process to prepare Web content data for clustering is also described.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-132.pdf
2010,Image registration by the extended evolutionary self-organizing map,"Everardo Maia, Guilherme Barreto, André Coelho","The Evolutionary Self-Organizing Map (EvSOM) is a recently proposed robust algorithm for topographic map formation through evolutionary strategies [10, 11]. This work extends the EvSOM algorithm to deal with the Image Registration Problem and evaluate its performance when the relationship between the reference image (Ir) and the free image (If) can be approximate by an affine transformation. The aim of this work is then to use the neighborhood preservation property of topographic maps to improve the performance of traditional image registration algorithms. The results are compared with two other strategies: iterative closest point (ICP) based image registration and template matching (TM) based image registration. Experimental results using black-white retinal images indicate the feasibility of the proposed approach.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-128.pdf
2010,Programmable triangular neighborhood functions of Kohonen Self-Organizing Maps realized in CMOS technology,"Rafal Dlugosz, Marta Kolasa, Witold Pedrycz","The paper presents a programmable triangular neighborhood function for application in low power transistor level implemented Kohonen self-organized maps (SOMs). Detailed simulations carried out for the software model of such network show that the triangular function forms a good approximation of the Gaussian function, while being implemented in a much easier way in hardware. The proposed circuit is very flexible and allows for easy adjustments of the slope of the function. It enables the asynchronous and fully parallel operation of all neurons in the network thus making it very fast. The proposed mechanism can be used in custom designed networks either in their analog or digital implementation. Due to the simple structure, the energy consumption per a single input pattern is low (120 pJ in case of the map of 16 x 16 neurons).",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-48.pdf
2010,Evolution of adaptive center-crossing continuous time recurrent neural networks for biped robot control,"Ángel Campo, José Santos","We used simulated evolution to obtain continuous time recurrent neural networks to control the locomotion of simulated bipeds. We also used the definition of center-crossing networks, so that the recurrent networks nodes can reach their areas of maximum sensitivity of their activation functions. Moreover, we incorporated a run-time adaptation of the nodes' biases to obtain such condition. We tested the improvements and possibilities this adaptation adds, focusing in the use for biped robot control",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-84.pdf
2010,Free-energy-based reinforcement learning in a partially observable environment,"Makoto Otsuka, Junichiro Yoshimoto, Kenji Doya","Free-energy-based reinforcement learning (FERL) can handle Markov decision processes (MDPs) with high-dimensional state spaces by approximating the state-action value function with the negative equilibrium free energy of a restricted Boltzmann machine (RBM). In this study, we extend the FERL framework to handle partially observable MDPs (POMDPs) by incorporating a recurrent neural network that learns a memory representation sufficient for predicting future observations and rewards. We demonstrate that the proposed method successfully solves POMDPs with high-dimensional observations without any prior knowledge of the environmental hidden states and dynamics. After learning, task structures are implicitly represented in the distributed activation patterns of hidden nodes of the RBM.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-102.pdf
2010,Exploiting local structure in stacked Boltzmann machines,"Hannes Schulz, Andreas Müller, Sven Behnke","Restricted Boltzmann Machines (RBM) are well-studied generative models. For image data, however, RBMs are suboptimal, since they do not exploit the local nature of image statistics. We modify RBMs to focus on local structure by restricting visible-hidden interactions. Long-range interactions can then be modelled using direct or indirect lateral interaction between hidden variables.  While learning in our model is much faster, it retains generative and discriminative properties of RBMs.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-126.pdf
2010,Extending reservoir computing with random static projections: a hybrid between extreme learning and RC,"John Butcher, David Verstraeten, Benjamin Schrauwen, Charles Day, Peter Haycock","Reservoir Computing is a relatively new paradigm in the field of neural networks that has shown promise in applications where traditional recurrent neural networks have performed poorly.  The main advantage of using reservoirs is that only the output weights are trained, reducing computational requirements significantly.  There is a trade-off, however, between the amount of memory a reservoir can possess and its capability of mapping data into a highly non-linear transformation space.  A new, hybrid architecture, combining a reservoir with an extreme learning machine, is presented which overcomes this trade-off, whose performance is demonstrated on a 4th order polynomial modelling task and an isolated spoken digit recognition task.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-99.pdf
2010,Machine Learning Techniques based on Random Projections,"Yoan Miché, Benjamin Schrauwen, Amaury Lendasse","This paper presents a short introduction to the Reservoir Computing and Extreme Learning Machine main ideas and developments. While both methods make use of Neural Networks and Random Projections, the Reservoir Computing allows the network to have a recurrent structure, while the Extreme Learning Machine is a Feedforward neural network only. Some state of the art techniques are briefly presented and this special session papers are finally quickly described, in the terms of this introductory paper.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-3.pdf
2010,Learning how to grasp objects,"Annalisa Barla, Luca Baldassarre, Nicoletta Noceti, Francesca Odone","This paper deals with the problem of estimating an appro-  priate hand posture to grasp an ob ject, from 2D ob ject’s visual cues in a  many-to-many (objects,grasp) con&#64257;guration. A statistical learning proto-  col implementing vector-valued regression is adopted for both classifying  the most likely grasp type and estimating the hand posture. An exten-  sive experimental evaluation on a publicly available dataset of visuo-motor  data reports very promising results and encourages further investigations.",Physiology and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-118.pdf
2010,Neural oscillations allow for selective inhibition - New perspective on the role of cortical gamma oscillations,Thomas Burwick,"A pattern recognition mechanism is proposed that uses inhibitory oscillations as fundamental ingredient. The mechanism realizes selective inhibition that could not be reached without oscillations. It uses couplings that are motivated by physiology. Since inhibitory oscillations are key to the generation of cortical gamma oscillation, the proposed mechanism may also shed new light on the gamma oscillation functionality.",Physiology and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-63.pdf
2010,Relational Generative Topographic Map,"Andrej Gisbrecht, Bassam Mokbel, Barbara Hammer","The generative topographic map (GTM) has been proposed as a statistical model to represent high dimensional data by means of a sparse lattice of points in latent space, such that visualization and data inspection become  possible. Original GTM is restricted to euclidean data points in a vector space.  Often, data are not explicitly embedded in a real vector space, rather pairwise dissimilarities of data can be computed, i.e.\ the relations between data points are given rather than the data vectors itself. We propose a method which extends the GTM to relational data and which allows to achieve a sparse representation of data characterized by pairwise dissimilarities in latent space. The method, relational GTM, is demonstrated on several benchmarks.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-94.pdf
2010,Learning vector quantization for heterogeneous structured data,"Dietlind Zühlke, Frank Michael Schleif, Tina Geweniger, Sven Haase, Thomas Villmann",In this paper we introduce an approach to integrate heterogeneous structured data into a learning vector quantization. The total distance between to heterogeneous structured samples is defined as a weighted sum of the distances in the single structural components. The weights are adapted in every iteration of learning using gradient descend on the cost function inspired by Generalized Learning Vector Quantization. The new method was tested on a real world data set for pollen recognition using image analysis.,Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-106.pdf
2010,Deep learning of visual control policies,"Sascha Lange, Martin Riedmiller","This paper discusses the effectiveness of deep auto-encoding neural nets in visual reinforcement learning (RL) tasks. We describe a new algorithm and  give results on succesfully learning policies directly on synthesized and real images without a predefined image processing. Furthermore, we present a thorough evaluation of  the learned feature spaces.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-87.pdf
2010,Geometric models with co-occurrence groups,"Joan Bruna Estrach, Stéphane Mallat",A geometric model of sparse signal representations is introduced for classes of signals. It is computed by optimizing co-occurrence groups with a maximum likelihood estimate calculated with a Bernoulli mixture model. Applications to face image compression and  MNIST digit classification illustrate the applicability of this model.,Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-43.pdf
2010,Directional predictions for 4-class BCI data,"Dieter Devlaminck, Willem Waegeman, Bruno Bauwens, Bart Wyns, Georges Otte, Luc Boullart, Patrick Santens","Brain-computer interfaces (BCI) can allow disabled people to drive a wheel chair, just by imagining movement. Therefore, present day BCIs use training data, recorded during four different conditions, to calibrate a classifier. This, however, causes jerky behavior while abruptly switching between discrete states. We propose a cost-sensitive support vector approach for estimating two-dimensional directions based on four-class BCI data, that is recorded from three subjects.  We found that our method reduces the number of severe errors compared to classical support vector machines and results in a smoother trajectory estimate for application in a wheel chair.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-82.pdf
2010,Autoregressive independent process analysis with missing observations,Szabó Zoltán,"The goal of this paper is to search for independent multidimensional processes subject to missing and mixed observations. The corresponding cocktail-party problem has a number of successful applications, however, the case of missing observations has been worked out only for the simplest Independent Component Analysis (ICA) task, where the hidden processes (i) are one-dimensional, and (ii) signal generation in time is independent and identically distributed (i.i.d.). Here, the missing observation situation is extended to processes with (i) autoregressive (AR) dynamics and (ii) multidimensional driving sources. Performance of the solution method is illustrated by numerical examples.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-52.pdf
2010,Combining back-propagation and genetic algorithms to train neural networks for start-up time modeling in combined cycle power plants,"Ilaria Bertini, Matteo De Felice, Stefano Pizzuti","This paper presents a neural networks based approach in order to estimate the start-up time of turbine based power plants. Neural networks are trained with a hybrid approach, indeed we combine the Back-propagation (BP) algorithm and the Simple Genetic Algorithm (GA) in order to effectively train neural networks in such a way that the BP algorithm initializes a few individuals of the GA's population. Experiments have been performed over a big amount of data and results have shown a remarkable improvement in accuracy compared to the single traditional methods",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-55.pdf
2010,A pseudoregression formulation of emphasized soft target procedures for classification problems,"Soufiane El Jelali, Abdelouahid Lyhyaoui, Anibal R. Figueiras-Vidal","Replacing a hard decision by a soft targets version including an attentional mechanism provides performance advantage and flexibility to solve classification tasks. In this paper, we modify the standard emphasized soft target method by proposing two new ideas, to avoid unnecessary updating and inappropiate definition of soft targets, in order to increase designs performance. Experimental results using MLPs show the effectiveness of this approach compared with the standard ST and other methods.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-60.pdf
2010,Exploiting hierarchical prediction structures for mixed 2d-3d tracking,"Chen Zhang, Julian Eggert","In this paper, we present a generic way to use a hierarchical representation of prediction models for adaptive tracking. Starting with a basic appearance-based tracker working in 2D retinal space, we show how to combine individual trackers for the left and right eye to a true 3D tracker that is built on top of the 2D trackers. We show how the trackers benefit from the hierarchical structure by dynamical model switching depending on the reliability of the tracking results.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-79.pdf
2010,Hybrid Soft Computing for PVT Properties Prediction,"Ghouti Lahouari, Saeed Al-Bukhitan","Pressure-Volume-Temperature (PVT) properties are very important in the reservoir engineering computations. There are many approaches for predicting various PVT properties based on empirical correlations and statistical regression models. Last decade, researchers utilized neural networks to develop more accurate PVT correlations. These achievements of neural networks open the door to data mining techniques to play a major role in oil and gas industry. Unfortunately, the developed neural networks correlations are often limited and global correlations are usually less accurate compared to local correlations. Recently, adaptive neuro-fuzzy inference systems have been proposed as a new intelligence framework for both prediction and classification based on fuzzy clustering optimization criterion and ranking. In this paper, a genetic-neuro-fuzzy inference system is proposed for estimating PVT properties of crude oil systems.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-96.pdf
2010,Approximation of chemical reaction rates in turbulent combustion simulation,"Lars Große, Franz Joos","It is essential to increase the efficiency of the commercially available combustion engines because of the limitations in fossil energy resources and environmental pollution Also the emission standards are a challenging aspect. If one succeeds in designing the combustion process, in particular the chemical reactions, it would be feasible to partly replace complex experiments by computer simulations. The suggestion made in this paper, is the use of artificial neuronal networks for approximation of complex chemistry in turbulent combustion applications. The use of complex chemistry is computationally expensive and limited to simple geometry, therefore it is replaced by trained ANNs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-58.pdf
2010,Efficient online learning of a non-negative sparse autoencoder,"Andre Lemme, Felix Reinhart, Jochen Steil",We introduce an efficient online learning mechanism for non-negative sparse coding in autoencoder neural networks.In this paper we compare the novel method to the batch algorithm non-negative matrix factorization with and without sparseness constraint.We show that the efficient autoencoder yields to better sparseness and lower reconstruction errors than the batch algorithms on the MNIST benchmark dataset.,Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-73.pdf
2010,Model Learning from Weights by Adaptive Enhanced Probabilistic Convergent Network,"Pierre Lorrentz, Gareth Howells, Klaus McDonald-Maier","Current weightless classifiers require historical data to model a system and make prediction about a system successfully. Historical data either is not always available or does not take a recent system modification into consideration. For this reason an adaptive filter is designed, which when employed with a weightless classifier enables system model, difficult to characterise system model, and system output prediction, successfully.         Results of experiments performed show that the fusion of an adaptive filter and a weightless classifier is more beneficial than the filter or the classifier utilised singly, and that no speed advantage is observed.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-65.pdf
2010,An augmented efficient backpropagation training strategy for deep autoassociative neural networks,"Mark Embrechts, Blake Hargis, Jonathan Linton",The purpose of this paper is to introduce an effective training strategy of the backpropagation algorithm for deep autoencoders without relying on a weight initialization with restricted Boltzmann machines.  This strategy is an extension of Efficient BackProp first proposed by LeCun et al. and will be benchmarked on three different types of application data sets.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-122.pdf
2010,Least 1-Norm SVMs: a new SVM variant between standard and LS-SVMs,"Jorge López, José R. Dorronsoro","Least Squares Support Vector Machines (LS-SVMs) were proposed by replacing the inequality constraints inherent to L1-SVMs with equality constraints. So far this idea has only been suggested for a least squares (L2) loss. We describe how this can also be done for the sum-of-slacks (L1) loss, yielding a new classifier (Least 1-Norm SVMs) which gives similar models in terms of complexity and accuracy and that may also be more robust than LS-SVMs with respect to outliers.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-115.pdf
2010,Fast and good initialization of RBF networks,"Dietmar Bauer, Jonas Sjoberg",In this paper a new method for fast initialization of radial basis function (RBF) networks is proposed. A grid of possible positions and widths for the basis functions is defined and new nodes to the RBF network are introduced one at the time. The definition of the grid points is done in a specific way which leads to algorithms which are computationally inexpensive due to  fact that intermediate results  can be reused  and do not need to be re-computed. If the grid is dense one obtains  estimators close to  estimators resulting from  an exhaustive search for the initial parameters which leads to a lower risk to be caught in local minima in the minimization which follows. The usefulness of the approach is demonstrated in a simulation example.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-64.pdf
2010,Time series input selection using multiple kernel learning,"Loris Foresti, Devis Tuia, Vadim Timonin, Mikhaïl Kanevski","In this paper we study the relevance of multiple kernel learning (MKL) for the automatic selection of time series inputs. Recently, MKL has gained great attention in the machine learning community due to its flexibility in modelling complex patterns and performing feature selection. In general, MKL constructs the kernel as a weighted linear combination of basis kernels, exploiting different sources of information. An efficient algorithm wrapping a Support Vector Regression model for optimizing the MKL weights, named SimpleMKL, is used for the analysis. In this sense, MKL performs feature selection by discarding inputs/kernels with low or null weights. The approach proposed is tested with simulated linear and nonlinear time series (AutoRegressive, Henon and Lorenz series).",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-28.pdf
2010,Active set training of support vector regressors,Shigeo Abe,"In our previous work we have discussed the training method of a support vector classifier by active set training allowing the solution to be infeasible during training. In this paper, we extend this method to training a support vector regressor (SVR). We use the dual form of the SVR where variables take real values and in the objective function the weighted linear sum of absolute values of the variables is included. We allow the variables to change signs from one step to the next. This means changes of the active inequality constraints.  Namely, we solve the quadratic programming problem for the initial working set of training data by Newton's method, delete from the working set the data within the epsilon tube, add to the working set training data outside of the epsilon tube, and repeat training the SVM until the working set does not change. We demonstrate the effectiveness of the proposed method using some benchmark data sets.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-13.pdf
2010,Mapping without visualizing local default is nonsense,"Sylvain Lespinats, Michaël Aupetit","High-dimensional dataset are often Embedded in two-dimensional spaces so as to visualize neighborhood relationships. When the map is effective (i.e. when short distances are preserved) it is a powerful mean to understand the dataset. But, mappings most often show defaults and the user is then led astray. Following this line, a mapping should not be considered when its overall quality is not good enough. Many imperfect mappings can however be exploited by informing the user of nature and level of defaults. In this work, we propose to visualize local indices trustworthiness and continuity in that purpose.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-54.pdf
2010,Modelling the McGurk effect,"Ioana Sporea, Andre Gruning","The current study investigates the McGurk effect by modelling it with neural networks. The simulations are designed to test the two main theories about the moment at which the auditory-visual integration happens. To further analyze the causes behind the McGurk illusion, the neural network that best models the effect is used to simulate the influence of language and the frequency of phonemes on auditory-visual speech perception, using two phonetic distribution from English and Japanese, with different empirical results in the McGurk effect.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-61.pdf
2010,Predicting spike-timing of a thalamic neuron using a stochastic synaptic model,"Karim El-Laithy, Martin Bogdan","A twofold spike-timing dependent stochastic synaptic model is used along with a leaky Integrate-and-Fire neuronal model to predict the spike timing of a single post-synaptic neuron in the lateral geniculate nucleus, knowing the spike train on the pre-synaptic side (i.e. in a retinal ganglion cell). In this synaptic model, spike-timing dependency is introduced for both the magnitude and relaxation of the dynamics representing the synaptic action. The results show that the used model is able to reliably predict the exact timing of spikes. These results and the model are the winner of a recent international competition.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-14.pdf
2010,Identifying informative features for ERP speller systems based on RSVP paradigm,"Tian Lan, Deniz Erdogmus, Lois Black, Jan Van Santen",This preliminary study focused on identifying informative features in the frequency and spatial domains for single-trial Event Related Potential (ERP) detection for ERP spelling systems. A predefined sequence of letters was presented to subjects in a Rapid Serial Visual Presentation (RSVP) paradigm. EEG data were collected and analyzed offline. A Linear Discriminant Analysis (LDA) classifier was selected as ERP detector for its simplicity and robustness. A range of features in different frequency bands and EEG channel subsets was extracted and detection accuracies were compared for different classes of features.,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-129.pdf
2010,Oriented Bounding Box Computation Using Particle Swarm Optimization,"Pierre Borckmans, Pierre-Antoine Absil","The problem of finding the optimal oriented bounding box (OBB) for a given set of points in $\mathbb{R}^3$, yet simple to state, is computationally challenging. Existing state-of-the-art methods dealing with this problem are either exact but slow, or fast but very approximative and unreliable. We propose a method based on Particle Swarm Optimization (PSO) to approximate solutions both effectively and accurately. The original PSO algorithm is modified so as to search for optimal solutions over the rotation group $SO(3)$. Particles are defined as 3D rotation matrices and operations are expressed over $SO(3)$ using matrix products, exponentials and logarithms. The symmetry of the problem is also exploited. Numerical experiments show that the proposed algorithm outperforms existing methods, often by far.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-117.pdf
2010,A novel interactive biometric passport photograph alignment system,"George McConnon, Farzin Deravi, Sanaul Hoque, Gareth Howells, Konstantinos Sirlantzis",A novel framework for interactively acquiring images was developed in MathWorks™ MATLAB® which used real-time visual and audio cues to assist in guiding the user into correct alignment for compliance with European biometric passport regulations. The user would pose in front of a camera using visual feedback from a monitor to roughly position themselves before Iris detection was used to calculate their roll (z-axis) alignment. Audio instructions would then be given to refine their posture if required. Blink detection was then used to detect the user’s readiness to have their passport image taken.,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-114.pdf
2010,TreeESN: a Preliminary Experimental Analysis,"Claudio Gallicchio, Alessio Micheli","In this paper we introduce an efficient approach to Recursive Neural Networks (RecNNs) modeling, the Tree Echo State Network (TreeESN), extending the Echo State Network (ESN) model from sequential to tree structured domains processing. For structure-to-element transductions, the state mapping (i.e. the way in which the state values for the whole structure are selected/collected) turns out to have a relevant role and the importance  of its choice is pointed out by experimental results.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-101.pdf
2010,Random search enhancement of error minimized extreme learning machine,"Yuan Lan, Soh Yeng Chai, Huang Guang-Bin","Error minimized extreme learning machine (EM-ELM) proposed by Feng et al. [1] can automatically determine the number of hidden nodes in generalized single-hidden layer feedforward networks (SLFNs). We recently find that some of the hidden nodes that are added into the network may play a very minor role in the network output, which increases the network complexity. Hence, this paper proposes an enhancement of EM-ELM (referred to as EEM-ELM), which introduce a selection phase based on the random search method. The empirical study shows that EEM-ELM leads to a more compact network structure.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-88.pdf
2010,A Markovian characterization of redundancy in echo state networks by PCA,"Claudio Gallicchio, Alessio Micheli","Richness of dynamics is a desirable feature of Echo State Networks (ESNs) limited by a  known high redundancy of state units activations. We show how this feature is mainly influenced by the Markovian state space organization of ESNs through a Principal Component Analysis (PCA)  of the reservoir space. Relevances of principal components are coherent with Markovianity, whose role is further enlightened by investigating the strong relation among the suffix elements of the input sequence and the most relevant directions of variability in the state space.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-36.pdf
2010,Using SVMs with randomised feature spaces: an extreme learning approach,"Benoît Frénay, Michel Verleysen","Extreme learning machines are fast models which almost compare to standard SVMs in terms of accuracy, but are much faster. However, they optimise a sum of squared errors whereas SVMs are maximum-margin classifiers. This paper proposes to merge both approaches by defining a new kernel. This kernel is computed by the first layer of an extreme learning machine and used to train a SVM. Experiments show that this new kernel compares to the standard RBF kernel in terms of accuracy and is faster. Indeed, experiments show that the number of neurons of the ELM behind the randomised kernel does not need to be tuned and can be set to a sufficient value without altering the accuracy significantly.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-56.pdf
2010,Finding correlations in multimodal data using decomposition approaches,"Daniel Dornbusch, Robert Haschke, Stefan Menzel, Heiko Wersing","In this paper, we propose the application of standard decomposition approaches to find local correlations in multimodal data. In a test scenario, we apply these methods to correlate the local shape of turbine blades with their associated aerodynamic flow fields. We compare several decomposition algorithms with regards to their efficiency at finding local correlations and their ability to predict one modality from another.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-24.pdf
2010,Divergence based Learning Vector Quantization,"Ernest Mwebaze, Petra Schneider, Frank Michael Schleif, Sven Haase, Thomas Villmann, Michael Biehl",,Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-97.pdf
2010,Learning sparse codes for image reconstruction,"Kai Labusch, Thomas Martinetz","We propose a new algorithm for the design of overcomplete dictionaries for sparse coding that generalizes the Sparse Coding Neural Gas (SCNG) algorithm such that it is not bound to a particular approximation method for the coefficients of the dictionary elements. In an application to image reconstruction, a dictionary that has been learned using this algorithm outperforms a dictionary that has been obtained from the widely-used K-SVD algorithm, an overcomplete Haar-wavelet dictionary and an overcomplete discrete cosine transformation (DCT).",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-57.pdf
2010,Highly sparse kernel spectral clustering with predictive out-of-sample extensions,"Carlos Alzate, Johan Suykens","Kernel spectral clustering has been formulated as a primal - dual optimization setting allowing natural extensions to out-of-sample data together with model selection in a learning framework which is important for obtaining a good generalization performance. In this paper, we propose a new sparse method for kernel spectral clustering.   The approach exploits the structure of the eigenvectors and the corresponding projections of the data when the clusters are well formed. Experimental results with toy data and images show highly sparse clustering models with predictive capabilities.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-18.pdf
2010,Sparse representation of data,"Thomas Villmann, Frank Michael Schleif, Barbara Hammer","The amount of electronic data available today as well as its dimensionality and complexity increases rapidly in many scientific areas including biology, (bio-)chemistry,  medicine, physics and its application fields like robotics, bioinformatics or multimedia technologies. Many of these data sets are very complex but have also a simple inherent structure which allows an appropriate sparse representation and modeling of such data with less or no information loss.  Advanced methods are needed to extract these inherent but hidden information. Sparsity can be observed at different levels: sparse representation of data points using e.g. dimensionality reduction for efficient data storage, sparse representation of full data sets using e.g. prototypes to achieve compact models for lifelong learning and sparse models of the underlying data structure using sparse encoding techniques. One main goal is to achieve a human-interpretable representation of the essential information. Sparse representations account for the ubiquitous problem that humans have to deal with ever increasing and inherently unlimited information by means of limited resources such as limited time, memory, or perception abilities. Starting with the seminal paper of Olshausen&Field  researchers recognized that sparsity can be used as a fundamental principle to arrive at very efficient information processing models for huge and complex data such as observed e.g. in the visual cortex. Nowadays, sparse models include diverse methods such as relevance learning in  prototype based representations, sparse coding neural gas, factor analysis methods,  latent semantic indexing, sparse Bayesian networks, relevance vector machines and other. This tutorial paper reviews recent developments in the field.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-7.pdf
2010,Towards sub-quadratic learning of probability density models in the form of mixtures of trees,"François Schnitzler, Philippe Leray, Louis Wehenkel","We consider randomization schemes of the Chow-Liu algorithm from weak (bagging, of quadratic complexity) to strong ones (full random sampling, of linear complexity), for learning probability density models in the form of mixtures of Markov trees. Our empirical study on high-dimensional synthetic problems shows that, while bagging is the most accurate scheme on average, some of the stronger randomizations remain very competitive in terms of accuracy, specially for small sample sizes.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-104.pdf
2010,"Adaptive learning rate control for ""neural gas principal component analysis""","Wolfram Schenck, Ralph Welsch, Alexander Kaiser, Ralf Moeller","We propose a novel algorithm for adaptive learning rate control for Gaussian mixture models of the NGPCA type. The core idea is to introduce a unit-specific learning rate which is adjusted automatically depending on the match between the local principal component analysis of each unit (interpreted as Gaussian distribution) and the empirical distribution within the unit's data partition. In contrast to fixed annealing schemes for the learning rate, the novel algorithm is applicable to real online learning. Two experimental studies are presented which demonstrate this important property and the general performance of this algorithm.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-34.pdf
2010,Asymptotic properties of mixture-of-experts models,"Madalina Olteanu, joseph Rynkiewicz","The statistical properties of the likelihood ratio test statistic (LRTS) for  mixture-of-expert models are addressed in this paper. This question is essential when estimating the number of experts in the model. Our purpose is to extend the existing results for mixtures (Liu and Shao, 2003) and mixtures of multilayer perceptron (Olteanu and Rynkiewicz, 2008). In this paper we study a simple example which embodies all the difficulties arising in such models. We find that in some cases the LRTS diverges but, with additional assumptions, the behavior of such models can be totally explicated.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-120.pdf
2010,Modeling contextualized textual knowledge as a Long-Term Working Memory,"Mauro Mazzieri, Sara Topi, Aldo Franco Dragoni, Germano Vallesi","A knowledge management system is more than an archive of textual documents; it provides context information, allowing to know which documents where used by people with a common goal. In the hypothesis that a set of textual documents with a common context can be assimilated to the long term memory of a human expert executor, we can use on them mining techniques inspired by the mechanic of human comprehension in expert domains. Text mining techniques for KM task can use a model of the long-term memory to extract meaningful keywords from the documents. The model acts as a dynamic and non-stationary dimensionality reduction strategy, allowing the clustering of context documents according to keyword presence, the classification of external documents according to local criteria, and a better understanding of document content and relatedness.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-77.pdf
2010,Machine learning analysis and modeling of interest rate curves,"Mikhaïl Kanevski, Vadim Timonin","The present research deals with the review of the analysis and modeling of Swiss franc interest rate curves (IRC) by using unsupervised (SOM, Gaussian Mixtures) and supervised machine (MLP) learning algorithms. IRC are considered as objects embedded into different feature spaces: maturities; maturity-date, parameters of Nelson-Siegel model (NSM). Analysis of NSM parameters and their temporal and clustering structures helps to understand the relevance of model and its potential use for the forecasting. Mapping of IRC in a maturity-date feature space is presented and analyzed for the visualization and forecasting purposes.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-17.pdf
2010,Heuristics Miner for Time Intervals,"Andrea Burattin, Alessandro Sperduti","Process Mining attempts to reconstruct the workflow of a business process from logs of activities. This task is quite important in business scenarios where there is not a well understood and structured definition of the business process performed by workers. Activities logs are thus mined in the attempt to reconstruct the actual business process. In this paper, we propose the generalization of a popular process mining algorithm, named Heuristics Miner, to time intervals. We show that the possibility to use, when available, time interval information for the performed activities allows the algorithm to produce better workflow models.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-105.pdf
2010,Introduction to Computational Intelligence Business Applications,"Thiago Turchetti Maia, Antonio Padua Braga","Computational intelligence business applications have been developed since the early days of computing and are now commonly found in many aspects of modern society.  This paper briefly surveys historic applications of computational intelligence in different business contexts. In addition, it describes this type of application from a business point of view, where computational intelligence is used as a source of competitive advantage. It concludes with an analysis of how organizations may create the proper environment and effectively use computational intelligence to improve their business.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-5.pdf
2010,Financial time series forecasting with machine learning techniques: a survey,"Bjoern Krollner, Bruce Vanstone, Gavin Finnie","Stock index forecasting is vital for making informed investment decisions. This paper surveys recent literature in the domain of machine learning techniques and artificial intelligence used to forecast stock market movements. The publications are categorised according to the machine learning technique used, the forecasting timeframe, the input variables used, and the evaluation techniques employed. It is found that there is a consensus between researchers stressing the importance of stock index forecasting. Artificial Neural Networks (ANNs) are identified to be the dominant machine learning technique in this area. We conclude with possible future research directions.",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-50.pdf
2010,Ensemble Modeling with a Constrained Linear System of Leave-One-Out Outputs,"Yoan Miché, Emil Eirola, Patrick Bas, Olli Simula, Christian Jutten, Amaury Lendasse, Michel Verleysen","This paper proposes a method for ensemble models using their Leave-One-Out output and solving a constrained linear system. By the use of the proposed method to create an ensemble of Locally Linear models, results on six different regression data sets are comparable to state-of-the-art methods such as Least-Squares Support Vector Machines and Gaussian Processes, while being orders of magnitude faster.",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-93.pdf
2010,Maximal Discrepancy for Support Vector Machines,"Davide Anguita, Alessandro Ghio, Sandro Ridella","Several theoretical methods have been developed in the past years to evaluate the generalization ability of a classifier: they provide extremely useful insights on the learning phenomena, but are not as effective in giving good generalization estimates in practice. We focus in this work on the application of the Maximal Discrepancy method to the Support Vector Machine for computing an upper bound of its generalization bias.",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-74.pdf
2010,The Markov Decision Process Extraction Network,"Siegmund Duell, Alexander Hans, Steffen Udluft","This paper presents the Markov decision process extraction network, which is a data-efficient, automatic state estimation approach for discrete-time reinforcement  learning (RL) based on recurrent neural networks. The architecture is designed to model minimal relevant dynamics of an environment, capable of condensing large sets of continuous observables to a compact state representation and excluding irrelevant information. To the best of our knowledge, it is the first approach published to automatically extract minimal relevant aspects of a dynamics from observations to model a Markov decision process, suitable for RL, without requiring special knowledge of the regarded environment. The capabilities of the neural state estimation approach are evaluated using the cart-pole problem and standard table-based dynamic programming.",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-116.pdf
2010,Principal curve tracing,"Erhan Bas, Deniz Erdogmus",We propose a principal curve tracing algorithm that uses the gradient and the Hessian of a given density estimate. Curve definition requires the local smoothness of data density and is based on the concept of subspace local maxima. Tracing of the curve is handled through the leading eigenvector where fixed-step updates are used. We also propose an image segmentation algorithm based on the original idea and show the effectiveness of the proposed algorithm on a Brainbow dataset.,Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-127.pdf
2010,Extending FSNPC to handle data points with fuzzy class assignments,"Tina Geweniger, Thomas Villmann",In this paper we present an advanced Nearest Prototype Classification to handle data points with unsharp class assignments. Therefore we extend the Soft Nearest Prototype Classification as proposed by Seo et al. and its further enhancement working with fuzzy labeled prototypes as introduced by Villmann et al. We adapt the cost function and derive appropriate update rules for the prototypes. We assess the performance on a toy data set and a real-world problem and compare the classification result with the results obtained by Fuzzy Robust Soft LVQ by means of Fuzzy Cohen's Kappa.,Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-123.pdf
2010,Multiple Local Models for System Identification Using Vector Quantization Algorithms,"Luis Souza, Guilherme Barreto","We introduce a novel method to build multiple local regression models based on the prototype vectors of the SOM network and other well-known vector quantization (VQ) algorithms. The resulting models are evaluated in the task of identifying the inverse dynamics of a heat exchanger data set. Additionally, we evaluate through statistical hypothesis testing the influence of the VQ algorithm on the performance of the local model. Simulation results demonstrate that the proposed method consistently outperforms previous MLP- and SOM-based approaches for system identification.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-113.pdf
2010,Relevance learning in generative topographic maps,"Andrej Gisbrecht, Barbara Hammer","The generative topographic map (GTM) provides a flexible statistical model for unsupervised data inspection and topographic mapping.  However, it shares the property of most unsupervised tools that noise in the data cannot be recognized as such and, in consequence, is visualized in the map. The framework of relevance learning or learning metrics as introduced in \cite{grlvq,kaski} offers an elegant way to shape the metric according to auxiliary information at hand such that only those aspects are displayed in distance-based approaches which are relevant for a given classification task. Here we introduce the concept of relevance learning into GTM such that the metric is shaped according to auxiliary class labels. Relying on the prototype-based nature of GTM, several efficient realizations of this paradigm are developed and compared on a couple of benchmarks.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-72.pdf
2010,A randomized algorithm for spectral clustering,"Nicola Rebagliati, Alessandro Verri","Spectral Clustering has reached a wide level of diffusion among unsupervised learning applications. Despite its practical success we believe that for a correct usage one has to face a difficult problem: given a target number of classes K the optimal K-dimensional subspace is not necessarily spanned by the first K eigenvectors of the graph Normalized Laplacian. This problem is usually disregarded but it can make the correct solution not computable by current Spectral Clustering algorithms. The contribution of this paper is twofold. First, we show a bound for choosing a correct number of eigenvectors. Second, we propose a novel randomized spectral algorithm for finding the solution. We show with experiments on real world graphs the efficacy of the algorithm. Our proposal is a scheme that naturally extends the current usage of Spectral Clustering.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-32.pdf
2010,An automated SOM clustering based on data topology,"Kadim Tasdemir, Pavel Milenov","Self-organizing maps are powerful for cluster extraction due to their ability of obtaining a topologically ordered and adaptive vector quantization of data. Thanks to lower-dimensional representation of high-dimensional data on SOM lattice, clustering is often done interactively from informative SOM visualizations. Yet large volumes of today’s data sets necessitate to have automated methods that are as successful as interactive ones for fast and accurate knowledge discovery. An automated SOM clustering, based on hierarchical clustering of a topology representing graph, is proposed here. Applications on several data sets indicate that the proposed method can be successfully used for automated partitioning.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-31.pdf
2010,A critique of BCM behavior verification for STDP-type plasticity models,"Christian Mayr, Johannes Partzsch, Rene Schueffny","Rate based (Bienenstock-Cooper-Munroe, BCM) and spike timing dependent plasticity (STDP) are the two principal learning behaviors found at cortical synapses. Some BCM induction protocols have been shown to be compatible with STDP rules, thus combining both forms of plasticity. However, we demonstrate that the majority of actual experimental BCM protocols cannot be reproduced by STDP. This sensitivity to spike protocol is inconsistent with the robust BCM behavior generally found in experiments. Moreover, we show that major recent spike timing rules, despite incorporating rate based effects, cannot replicate actual experimental BCM evidence. Thus, the purported convergence between these two important plasticity phenomena is called in question.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-95.pdf
2010,Neural competition for motion segmentation,"Jan Steffen, Michael Pardowitz, Jochen Steil, Helge Ritter","We present a system for sensory classification and  segmentation in motion trajectories. It consists of a  combination of manifolds from Unsupervised Kernel  Regression (UKR) and the recurrent neural Competitive  Layer Model (CLM). The UKR manifolds hold learned  representations of a set of candidate motions and the CLM  dynamics, working on features defined in the UKR domain,  realises the segmentation of observed trajectory data  according to the competing candidates. The evaluation on trajectories describing four different letters yields  improved classification results compared to our previous,  pure manifold approach.",Motion estimation and segmentation,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-39.pdf
2010,Reliability of dimension reduction visualizations of hierarchical structures,Elina Parviainen,"Dimension reduction can produce visualizations of  hierarchical structures, like those produced by cluster analysis. So far, reliability of such visualizations has only been assessed with rudimentary means. Here, a method  for assessing reliability of such visualizations is developed. It measures how accurately the location of a data point in high-dimensional hierarchy tree can be inferred from a tree based on the low-dimensional visualization. The criterion can be used in point-wise fashion, allowing visual assessment of results, or as average values, for comparing visualizations. Use of the criterion is demonstrated on handwritten digits data, comparing visualizations by three dimension reduction methods.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-26.pdf
2010,Self Organizing Star (SOS) for health monitoring,"Etienne Côme, Marie Cottrell, Michel Verleysen, Jérôme Lacaille","Self Organizing Maps (SOM) have been successfully applied in a lot of real world hard problems since their apparition. In this paper we present new topologies for SOM based on a planar graph. The design of a specific graph to encode prior information on the dataset topology is the central question addressed in this paper. In this context, star-shaped graphs are advocated for health monitoring applications, leading to a new kind of SOM that we denote by Self Organizing Star (SOS). Experiments using aircraft engine measurements show that SOS lead to meaningful and natural dataset representation.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-29.pdf
2010,Adaptive matrix distances aiming at optimum regression subspaces,"Marc Strickert, Axel J. Soto, Gustavo E. Vazquez","A new supervised adaptive metric approach is introduced for mapping an input vector space to a plottable low-dimensional subspace in which the pairwise distances are in maximum correlation with distances of the associated target space. The formalism of multivariate subspace regression (MSR) is based on cost function optimization, and it allows assessing the relevance of input vector attributes. An application to molecular descriptors in a chemical compound data base is presented for targeting octanol-water partitioning  properties.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-78.pdf
2010,Exploratory Observation Machine (XOM) with Kullback-Leibler Divergence for Dimensionality Reduction and Visualization,"Kerstin Bunte, Barbara Hammer, Thomas Villmann, Michael Biehl, Axel Wismueller","We present an extension of the Exploratory Observation Machine (XOM) for structure-preserving dimensionality reduction. Based on minimizing the Kullback-Leibler divergence of neighborhood functions in data and image spaces, this Neighbor Embedding XOM (NE-XOM) creates a link between fast sequential online learning known from topology-preserving mappings and principled direct divergence optimization approaches. We quantitatively evaluate our method on real world data using multiple embedding quality measures. In this comparison, NE-XOM performs as a competitive trade-off between high embedding quality and low computational expense, which motiviates its further use in real-world settings throughout  science and engineering.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-71.pdf
2010,Curvilinear component analysis and Bregman divergences,"Jigang Sun, Colin Fyfe, Malcolm Crowe","Curvilinear Component Analysis (CCA) is an interesting flavour of multidimensional scaling. In this paper one version of CCA is proved to be equivalent to a kind of Bregman divergence, and its parameter (the neighbourhood radius) is explained.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-107.pdf
2010,"Recent Advances in Nonlinear Dimensionality Reduction, Manifold and Topological Learning","Axel Wismueller, Michel Verleysen, Michaël Aupetit, John Aldo Lee","The ever-growing amount of data stored in digital databases raises the question of how to organize and extract useful knowledge. This paper outlines some current developments in the domains of dimensionality reduction, manifold learning, and topological learning. Several aspects are dealt with, ranging from novel algorithmic approaches to their realworld applications. The issue of quality assessment is also considered and progress in quantitive as well as visual crieria is reported.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-4.pdf
2010,Adaptive velocity tuning for visual motion estimation,"Volker Willert, Julian Eggert","In the brain, both neural processing dynamics as well as the perceptual interpretation of a stimulus can depend on sensory history. The underlying principle is a sensory adaptation to the statistics of the input collected over a certain amount of time, allowing the system to tune its detectors, e.g.~by improving the sampling of the input space. Here we show how a generative formulation for the problem of visual motion estimation leads to an online adaptation of velocity tuning that is compatible with physiological sensory adaptation and observed perceptual effects.",Motion estimation and segmentation,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-76.pdf
2011,Increased robustness and intermittent dynamics in structured Reservoir Networks with feedback,"Sarah Jarvis, Stefan Rotter, Ulrich Egert","Recent studies using feedforward Echo State Networks (ESN) demonstrate that reservoir stability can be strongly affected by reservoir substructures, such as clusters.  Here, we evaluate the impact of including feedback on clustered ESNs and assert that certain cluster configurations extend the permissible range of spectral radius values. We also report a new class of reservoir activity: intermittent dynamics, characterized by variable periods of chaotic activity before returning to quiescent behaviour. Using a non-linear benchmark data set, we establish clustered ESNs have comparable performance against conventional ESNs, but importantly display an increased tolerance and robustness to spectral radius and input choice.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-14.pdf
2011,Stability of Neural Network Control for Uncertain Sampled-Data Systems,"Pornchai Khlaeo-om, Sasikanchana Yenaeng, Sunya Pasuk, Supachai Aroonpun, Sompun Aumpawan","This paper derives robust stability conditions for neural network control of sampled-data systems whose parameters are uncertain. The controllers are nonlinear, full state regulators implemented as single hidden layer, feedforward neural networks. The controlled systems must be locally controllable and full-state accessible. The robust stability is confirmed by the existence of a Lyapunov function of the closed loop systems. A modified backpropagation algorithm with a model reference technique is employed to determine the weights of the controllers. Simulation results on the classical motor-driven inverted pendulum model are presented to demonstrate the applications of these conditions.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-94.pdf
2011,New conditioning model for robots,Jean Marc Salotti,We present a neural network for the prediction of rewards in a conditioning model. It is based on two noisy-or and one noisy-and nodes and update rules inspired from BANNER technique. Interesting results are presented with application to robotics.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-104.pdf
2011,SO-VAT: Self-Organizing Visual Assessment of cluster Tendency for large data sets,"Enrique Pelayo, Carlos Orrite, David Buldain","A new method, Self-Organizing Visual Assessment of cluster Tendency (SO-VAT), is given for visually assessing the cluster tendency in large data sets. It is based on training a SOM with the input samples, and then calculating the VAT image from a selected group of the generated neurons, selection that is done according to a certain density of activation. Tests with synthetic and real examples demonstrate that the new SO-VAT algorithm results in clearer images and shorter computing time than applying directly the VAT procedure to the whole input-data set.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-58.pdf
2011,D-VisionDraughts: a draughts player neural network that learns by reinforcement in a high performance environment,"Araujo Barcelos Ayres Roberto, Silva Julia Rita Maria, Matias Junior Rivalino","This paper describes D-VisionDraughts, a distributed player agent for draughts which is based on Neural Networks trained by Temporal Differences. D-VisionDraughs is trained in a high performance environment and achieves a high level of play without expert game analysis and with minimum human intervention. D-VisionDraughts corresponds to a distributed version of the efficient agent player VisionDraughts. In this way, the main contributions of this paper consist on substituting the distributed Young Brothers Wait Concept algorithm (YBWC) for the serial alpha-beta search algorithm used in VisionDraughts and on measuring the impact of a high performance environment into the non supervised learning abilities of the player. Evaluative tests proved that even a modest distributed version counting on just 10 processors is able to reduce from 68% the search runtime and to increase from 15% its capacity of winning",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-62.pdf
2011,A brief tutorial on reinforcement learning: The game of Chung Toi,"Christopher Gatti, Jonathan Linton, Mark Embrechts","This work presents a simple implementation of reinforcement learning, using the temporal difference algorithm and a neural network, applied to the board game of Chung Toi, which is a challenging variation of Tic-Tac-Toe. The implementation of this learning algorithm is fully described and includes all parameter settings and various techniques to improve the ability of the network to learn the board game. With relatively little training, the network was able to win nearly 90% of games played against a 'smart' random opponent.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-110.pdf
2011,Application of stochastic recurrent reinforcement learning to index trading,Denise Gorse,"A novel stochastic adaptation of the recurrent reinforcement learning (RRL) methodology is applied to daily, weekly, and monthly stock index data, and compared to results obtained elsewhere using genetic programming (GP). The data sets used have been a considered a challenging test for algorithmic trading. It is demonstrated that RRL can reliably outperform buy-and-hold for the higher frequency data, in contrast to GP which performed best for monthly data.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-60.pdf
2011,Anticipating Rewards in Continuous Time and Space with Echo State Networks and Actor-Critic Design,Mohamed Oubbati,"In this paper we implement echo state networks (ESNs) within the concept of actor-critic design to obtain optimal control policy for a mobile robot. The robot is asked to anticipate future rewards/punishments and react accordingly. In this design, the ESN critic has to consider continuous state/action space, deal with uncertainties, and be computationally cheap in order to deal with real-world constraints. Benefits and problems involved in a obstacle avoidance scenario are discussed, supported by real-world experiments.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-69.pdf
2011,Thresholds tuning of a neuro-symbolic net controlling a behavior-based robotic system,"Mariacarla Staffa, Silvia Rossi, Massimo De Gregorio, Ernesto Burattini",In this paper we present the results obtained by adopting an evolutionary approach to tune some critical neuron thresholds of a neuro-symbolic net that regulates the overall emergent behavior of a behavior-based robotic system.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-55.pdf
2011,General bound of overfitting for MLP regression models,joseph Rynkiewicz,"Multilayer perceptrons (MLP) with one hidden layer have been used for a long time to deal with non-linear regression. However, in some task, MLP's are  too powerful models and a small mean square error (MSE) may be more due to overfitting than to actual modelling. If the noise of the regression model is Gaussian, the overfitting of the model is totally determined by the behavior of the likelihood ratio test statistic (LRTS), however in numerous cases the assumption of normality of the noise is arbitrary if not false.  In this paper, we present an universal bound for the overfitting of such model under smooth assumptions, this bound is valid without Gaussian or identifiability  assumptions. The main application of this bound is to give a hint about determining the true architecture of the MLP model when the number of data goes to infinite.",Learning theory,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-15.pdf
2011,Analysis of a Reinforcement Learning algorithm using Self-Organizing Maps,"Vicente Buendia-Ramon, Emilio Soria, José D Martín, Pablo Escandell, José M Martínez",The scenario of this work is defined by the need of many Machine Learning algorithms to tune a number of parameters that define its behavior; the resulting performance can be evaluated with different indices. The relationship between parameters and performance may be neither linear nor straightforward. This work proposes a qualitative approach to the afore-mentioned relationship by using Self-Organizing Maps due to their visual information processing. The approach is evaluated in the framework of Reinforcement Learning algorithms.,Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-56.pdf
2011,Growing Hierarchical Sectors on Sectors,"José M Martínez, Pablo Escandell, Emilio Soria, José D Martín, Juan Gómez, Joan Vila","Self-organizing maps are widely used in visual data mining. This paper proposes a new visualization approach for GHSOM algorithm, a hierarchical variant of SOM. The method is based on pie charts. That improves the visualization in hierarchical data structures making possible to extract all the existing relationships among the attributes of the neurons at any hierarchy level. The methodology is tested in one synthetic data set and one real data set. Achieved results show the suitability and usefulness of the proposed approach.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-74.pdf
2011,A probabilistic approach to the visual exploration of G Protein-Coupled Receptor sequences,"Alfredo Vellido, Martha Ivón Cárdenas, Iván Olier, Xavier Rovira, Jesús Giraldo","The study of G protein-coupled receptors (GPCRs) is of great interest in pharmaceutical research, but only a few of their 3D structures are known at present. On the contrary, their amino acid sequences are known and accessible. Sequence analysis can provide new insight on GPCR function. Here, we use a kernel-based statistical machine learning model for the visual exploration of GPCR functional groups from their sequences. This is based on the rich information provided by the model regarding the probability of each sequence belonging to a certain receptor group.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-44.pdf
2011,Hierarchical clustering for graph visualization,"Stéphan Clémençon, Hector De Arazoza, Fabrice Rossi, Viet Chi Tran","This paper describes a graph visualization methodology based on hierarchical maximal modularity clustering, with interactive and significant coarsening and refining  possibilities. An application of this method to HIV epidemic analysis in Cuba is outlined.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-24.pdf
2011,Seeing is believing: The importance of visualization in real-world machine learning applications,"Alfredo Vellido, José D Martín, Fabrice Rossi, Paulo Lisboa","The increasing availability of data sets with a huge amount of information,   coded in many different features, justifies the research on new methods of   knowledge extraction: the great challenge is the translation of the raw data   into useful information that can be used to improve decision-making processes,   detect relevant profiles, find out relationships among features, etc. It is   undoubtedly true that a picture is worth a thousand words, what makes   visualization methods be likely the most appealing and one of the most   relevant kinds of knowledge extration methods.  At ESANN 2011, the special   session ``Seeing is believing: The importance of visualization in real-world   machine learning applications'' reflects some of the main emerging topics in   the field. This tutorial prefaces the session, summarizing some of its   contributions, while also providing some clues to the current state and the   near future of visualization methods within the framework of Machine Learning.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-3.pdf
2011,Comparison of the Complex Valued and Real Valued Neural Networks Trained with Gradient Descent and Random Search Algorithms,"Hans-Georg Zimmermann, Alexey Minin, Viktoria Kusherbaeva",Complex Valued Neural Network is one of the open topics in the machine learning society. In this paper we will try to get through the problems of the complex valued neural networks. The outcome of the current research is the combined global-local algorithm for training the complex valued feed forward neural network which is appropriate for the considered chaotic problem.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-42.pdf
2011,Locating Anomalies Using Bayesian Factorizations and Masks,"Li Yao, Amaury Lendasse, Francesco Corona","A plethora of methods have been developed to handle anomaly detection in various application domains. This work focuses on locating anomalies inside a categorical data set without assuming any specific domain knowledge. By exploiting the conditional dependence and independence relationships among data attributes, not only can data analysts recognize the anomaly, but also locate the potentially anomalous attributes inside an anomalous instance following its masks. Masks are geometrically generated based on the factorization of the joint probability from a Bayesian network automatically learnt from the given data set.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-49.pdf
2011,Clustering data streams with weightless neural networks,"Douglas de O. Cardoso, Priscila M. V. Lima Lima, Massimo De Gregorio, João Gama, Felipe M. G. França","Producing good quality clustering of data streams in real time is a difficult problem, since it is necessary to perform the analysis of data points arriving in a continuous style, with the support of quite limited computational resources. The incremental and evolving nature of the resulting clustering structures must reflect the dynamics of the target data stream. The WiSARD weightless perceptron, and its associated DRASiW extension, are intrinsically capable of, respectively, performing one-shot learning and producing prototypes of the learnt categories. This work introduces a simple generalization of RAM-based neurons in order to explore both weightless neural models in the data stream clustering problem.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-87.pdf
2011,A post-processing strategy for SVM learning from unbalanced data,"Haydemar Núñez, Luis Gonzalez-Abril, Cecilio Angulo","Standard learning algorithms may perform poorly when learning from unbalanced datasets. Based on the Fisher's discriminant analysis, a post-processing strategy is introduced to deal datasets with significant imbalance in the data distribution. Empirical results from experiments for a learned SVM model on twelve UCI datasets indicates that the proposed solution improves the original SVM, and they also improve those reported when using a z-SVM, in terms of g-mean and sensitivity.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-29.pdf
2011,Sparse LS-SVMs with L0–norm minimization,"J. López, K. De Brabanter, J.R. Dorronsoro, J.A.K. Suykens","Least-Squares Support Vector Machines (LS-SVMs) have been successfully applied in many classification and regression tasks. Their main drawback is the lack of sparseness of the final models. Thus, a procedure to sparsify LS-SVMs is a frequent desideratum. In this paper, we adapt to the LS-SVM case a recent work for sparsifying classical SVM classifiers, which is based on an iterative approximation to the L0-norm. Experiments on real-world classification and regression datasets illustrate that this adaptation achieves very sparse models, without significant loss of accuracy compared to standard LS-SVMs or SVMs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-43.pdf
2011,Symbolic computing of LS-SVM based models,"Siamak Mehrkanoon, Li Jiang, Carlos Alzate, J.A.K. Suykens","This paper introduces a software tool emph{SYM-LS-SVM-SOLVER} written in emph{Maple} to derive the dual system and the dual model representation of LS-SVM based models, symbolically. emph{SYM-LS-SVM-SOLVER} constructs the Lagrangian from the given objective function and list of constraints. Afterwards it obtains the KKT (Karush-Kuhn-Tucker) optimality conditions and finally formulates a linear system in terms of the dual variables. The effectiveness of the developed solver is illustrated by applying it to a variety of problems involving LS-SVM based models.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-97.pdf
2011,Abstract category learning,"Atsushi Hashimoto, Haruo Hosoya","Motivated by a neurophysiological experiment on prefrontal cortex, we study a scheme for learning abstract categories.  An abstract category represents a set of vectors that are identical to each other modulo substitution, e.g., 'ABAB', 'BABA', 'ACAC', etc.  We employ a clustering-based unsupervised learning method for such abstract categories, in which the recognition step is reduced to the problem of maximal perfect weight matching.  Our simulations using artificial inputs confirm that the scheme learns abstract categories robustly even with a certain level of noise in the inputs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-12.pdf
2011,Fisherman learning algorithm of the SOM realized in the CMOS technology,"Rafal Dlugosz, Marta Kolasa, Witold Pedrycz","This study presents an idea of transistor level realization of the fisherman learning algorithm of Self-Organizing Maps (SOMs). The realization of this algorithm in hardware calls for a soluion of several specific problems not present in software implementation. The main problem is related to an iterative nature of the adaptation process of the neighboring neurons positioned at particular rings surrounding the winning neuron. This makes the circuit structure of the SOM very complex. To come up with a feasible realization, we introduce some modifications to the original fisherman algorithm. Detailed simulations of the software model of the SOM show that these modifications do not have the negative impact on the learning process, and helps bring significant reduction of the circuit complexity. In consequence, a fully parallel adaptation of all neurons is possible, which makes the SOM very fast.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-16.pdf
2011,Ensemble Usage for More Reliable Policy Identification in Reinforcement Learning,"Alexander Hans, Steffen Udluft","Reinforcement learning (RL) methods employing powerful function approximators like neural networks have become an interesting approach for optimal control. Since they learn a policy from observations, they are also applicable when no analytical description of the system is available. Although impressive results have been reported, their handling in practice is still hard, as they can fail at reliably determining a good policy. In previous work, we used ensembles of policies from independent runs of neural fitted Q-iteration (NFQ) to produce successful policies more reliable. In this paper we evaluate the approach on more problems and propose to form ensembles from successive iterations of a single NFQ run as a computationally cheap alternative to completely independent runs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-101.pdf
2011,Multispectral image characterization by partial generalized covariance,"Marc Strickert, Björn Labitzke, Andreas Kolb, Thomas Villmann","A general method is presented for the assessment of data attribute  variability, which plays an important role in initial screening of  multi- and high-dimensional data sets. Instead of the commonly used second centralized moment, known as variance, the proposed method allows a mathematically rigorous characterization of attribute sensitivity given not only Euclidean distances but  partial data comparisons by general similarity measures.  Depending on the choice of measure different spectral features get highlighted by attribute assessment, this way creating new image segmentation aspects, as shown in a comparison of Euclidean distance,  Pearson correlation and gamma divergence applied to  multi-spectral images.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-20.pdf
2011,Reservoir regularization stabilizes learning of Echo State Networks with output feedback,"R. Felix Reinhart, Jochen J. Steil",Output feedback is crucial for autonomous and parameterized pattern generation with reservoir networks. Read-out learning can lead to error amplification in these settings and therefore regularization is important for both generalization and reduction of error amplification. We show that regularization of the inner reservoir network mitigates parameter dependencies and boosts the task-specific performance.,Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-48.pdf
2011,A Multi-kernel Framework for Inductive Semi-supervised Learning,"Xilan TIAN, Gilles Gasso, Stéphane Canu",We investigate the benefit of combining both cluster assumption and manifold assumption underlying most of the semi-supervised algorithms using the flexibility and the efficiency of multi-kernel learning. The multiple kernel version of Transductive SVM (a cluster assumption based approach) is proposed and it is solved based on DC (Difference of Convex functions) programming.  Experiments on the benchmark data sets indicate the promising results of the proposed work.,Semi-supervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-57.pdf
2011,Training of multiple classifier systems utilizing partially labeled sequential data sets,"Martin Schels, Patrick Schillinger, Friedhelm Schwenker","Making use of unlabeled data samples for training a classifier is a desirable aim for many real world applications in pattern recognition. In this study, a multiple classifier system is utilized to investigate this matter. Further, cluster analysis is used in order to group the available data while neglecting the actual labels. Then, by implementing an information fusion architecture based on these clusters, a classification architecture is constructed. This kind of an architecture is investigated by means of a facial expression data collection with focusing on one-against-one class decisions to produce locally “unlabeled”, i.e. not assigned to one of the considered classes, data.",Semi-supervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-80.pdf
2011,Recent trends in computational intelligence in life sciences,"Udo Seiffert, Frank-Michael Schleif, Dietlind Zühlke",,Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-5.pdf
2011,Adaptive Kernel Smoothing Regression for Spatio-Temporal Environmental Datasets,"Federico Montesino Pouzols, Amaury Lendasse","This paper describes a method for performing kernel smoothing regression in an incremental, adaptive manner. A simple and fast combination of incremental vector quantization with kernel smoothing regression using adaptive bandwidth is shown to be effective for online regression modeling of environmental datasets. The method is illustrated on openly available datasets corresponding to the Tropical Atmosphere Ocean array and the Helsinki Commission hydrographical database for the Baltic Sea.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-36.pdf
2011,Generalized functional relevance learning vector quantization,"Marika Kaestner, Barbara Hammer, Michael Biehl, Thomas Villmann","Generalized learning vector quantization (GRLVQ) is a prototype based classification algorithm with metric adaptation weighting each data dimensions according to their relevance for the classification task. We present in this paper an extension for functional data, which are usually very high dimensional. This approach supposes the data vectors have to be functional representations. Taking into account, these information the so-called relevance profile are modeled by superposition of simple basis functions depending on only a few parameters. As a consequence, the resulting functional GRLVQ has drastically reduced number of parameters to be adapted for relevance learning. We demonstrate the ability of the new algorithms for standard functional data sets using different basis functions, namely Gaussians and Lorentzians.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-18.pdf
2011,Patch Affinity Propagation,"Xibin Zhu, Barbara Hammer","Affinity propagation constitutes an exemplar based clustering technique which  reliably optimizes the quantization error given a matrix of pairwise data dissimilarities by means of the max-sum algorithm for factor graphs. Albeit very efficient for sparse matrices, it displays squared complexity  in the worst case, hence it is not suited as high throughput method due to time and memory constraints. We propose an extension of affinity propagation to patch clustering such that data are treated in chunks of fixed size with limited memory requirements and linear time.  We test the suitability of the approach for two biomedical applications.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-89.pdf
2011,Information theory related learning,"Thomas Villmann, Jose C. Principe, Andrej Cichocki","This is the introduction paper to a special session held on ESANN conference 2011. It reviews and highlights recent developments and new direction in information related learning, which is a fastly developing research area. These algorithms are based on the fundamental principles of information theory and relate them implicitly or explicitly to learning algoithms and strategies.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-7.pdf
2011,Optimization of Parametrized Divergences in Fuzzy c-Means,"Tina Geweniger, Marika Kaestner, Thomas Villmann",We propose the utilization of divergences as dissimilarity measure in the Fuzzy c-Means algorithm for the clustering of functional data. Further we adapt the relevance parameter to improve the data representation and therefore obtain more accurate clusterings in terms of separation and compactness. We show for two example applications that this method leads to improved performance.,Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-100.pdf
2011,Multivariate class labeling in Robust Soft LVQ,"Petra Schneider, Tina Geweniger, Frank-Michael Schleif, Michael Biehl, Thomas Villmann","We introduce a generalization of Robust Soft Learning Vector Quantization (RSLVQ). This algorithm for nearest prototype classification is derived from an explicit cost function and follows the dynamics of a stochastic gradient ascent. We generalize the RSLVQ cost function with respect to vectorial class labels: Probabilistic LVQ (PLVQ) allows to realize multivariate class memberships for prototypes and training samples, and the prototype labels can be learned from the data during training. We present experiments to demonstrate the new algorithm in practice.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-66.pdf
2011,Statistical dependence measure for feature selection in microarray datasets,"Veronica Bolon-Canedo, Sohan Seth, Noelia Sánchez-Maroño, Amparo Alonso-Betanzos, Jose C. Principe","Feature selection is the domain of machine learning which studies data-driven methods to select, among a set of input variables, the ones that will lead to the most accurate predictive model. In this paper, a statistical dependence measure is presented for variable selection in the context of classification. Its performance is tested over DNA microarray data, a challenging dataset for machine learning researchers due to the high number of genes and relatively small number of measurements. This measure is compared against the so called mRMR approach, and is shown to obtain better or equal performance over the binary datasets.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-11.pdf
2011,Mathematical Foundations of the Self Organized Neighbor Embedding (SONE) for Dimension Reduction and Visualization,"Kerstin Bunte, Frank-Michael Schleif, Sven Haase, Thomas Villmann","In this paper we propose the generalization of the recently introduced Neighbor Embedding Exploratory Observation Machine (NE-XOM)  for dimension reduction and visualization. We provide a general mathematical framework called Self Organized Neighbor Embedding (SONE).  It treats the components, like data similarity measures and neighborhood functions, independently and easily changeable.  And it enables the utilization of different divergences, based on the theory of Fr\'echet derivatives.  In this way we propose a new dimension reduction and visualization algorithm, which can be easily adapted to the user specific request and  the actual problem.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-72.pdf
2011,Sparsity Issues in Self-Organizing-Maps for Structures,"Markus Hagenbuchner, Giovanni Da San Martino, Ah Chung Tsoi, Alessandro Sperduti","Recent developments with Self-Organizing Maps (SOMs) produced methods capable of clustering graph structured data onto a fixed dimensional display space. These methods have been applied successfully to a number of benchmark problems and produced state-of-the-art results. This paper discusses a limitation of the most powerful version of these SOMs, known as probability measure graph SOMs (PMGraphSOMs), viz., the sparsity induced by processing a large number of small graphs, which prevents a successful application of PMGraphSOM to such problems. An approach using the idea of compactifying the generated state space to address this sparsity problem is proposed. An application to an established benchmark problem, viz., the Mutag dataset in toxicology will show that the proposed method is effective when dealing with  a large number of small graphs. Hence, this work fills a gap between the processing of a number of small graphs,  and the processing of densely connected graphs using PMGraphSOMs.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-71.pdf
2011,Multi-Goal Path Planning Using Self-Organizing Map with Navigation Functions,"Jan Faigl, Jan Ma&#269;ák","In this paper, we present a combination of Self-Organizing Map (SOM) approach and navigation functions in the Traveling Salesman Problem (TSP) with segment goals. The problem arises from the inspection planning, where a path from which all points of the given polygonal environment have to be ``seen''. This type of problem belongs to the TSP with neighborhoods family. Moreover, the problem has to also deal with paths among obstacles, thus the problem is not the Euclidean TSP. The proposed approach demonstrates applicability of SOM principles in such problems in which SOM has not yet been applied.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-26.pdf
2011,Statistical properties of the `Hopfield estimator' of dynamical systems,"Miguel Atencia, Gonzalo Joya","This paper analyses the statistical properties of a method for estimating the parameters of systems defined by ordinary differential equations. In previous work, this estimation method was defined as an adapted version of Hopfield neural networks, and its convergence and robustness with respect to signal disturbances were proved, even when parameters are time-varying. This contribution aims at establishing the behaviour of the estimation error by performing a set of simulations where a random noise with known probability distribution is added to signals. It is shown that, asymptotically, the estimator is  unbiased and its variance vanishes. Further theoretical work is being undertaken in order to rigourously support these empirical findings.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-40.pdf
2011,Negatively Correlated Echo State Networks,"Ali Rodan, Peter Tino","Echo State Network (ESN) is a special type of recurrent neural network with fixed random recurrent part (reservoir) and a trainable reservoir-to-output readout mapping (typically obtained by linear regression). In this work we utilise an ensemble of ESNs with diverse reservoirs whose collective read-out is obtained through Negative Correlation Learning (NCL) of ensemble of Multi-Layer Perceptrons (MLP), where each individual MPL realises the readout from a single ESN. Experimental results on three data sets confirm that, compared with both single ESN and flat ensembles of ESNs, NCL based ESN ensembles achieve better generalisation performance.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-31.pdf
2011,A supervised strategy for deep kernel machine,"Florian Yger, Maxime Berar, Gilles Gasso, Alain Rakotomamonjy","This paper presents an alternative approach for learning  a Multilayer Kernel Machine (MKM) based on kernel partial least squares. After explaining the caracteristics and motivation of our approach, we show compelling evidences on real world applications.",Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-21.pdf
2011,Training RBMs based on the signs of the CD approximation of the log-likelihood derivatives,"Asja Fischer, Christian Igel","Contrastive Divergence (CD) learning is frequently applied to Restricted Boltzmann Machines (RBMs), the building blocks of deep believe networks. It relies on biased approximations of the log-likelihood gradient. This bias can deteriorate the learning process. It was claimed that the signs of most components of the CD update are equal to the corresponding signs of the log-likelihood gradient. This suggests using optimization techniques only depending on the signs. Resilient backpropagation is such a method and we combine it with CD learning. However, it does not prevent divergence caused by the approximation bias.",Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-79.pdf
2011,Using very deep autoencoders for content-based image retrieval,"Alex Krizhevsky, Geoffrey Hinton","We show how to learn many layers of features on color images and we use these features to initialize deep autoencoders. We then use the autoencoders to map images to short binary codes. Using semantic hashing, 28-bit codes can be used to retrieve images that are similar to a query image in a time that is independent of the size of the database. This extremely fast retrieval makes it possible to search using multiple different transformations of the query image. 256-bit binary codes allow much more accurate matching and can be used to prune the set of images found using the 28-bit codes.",Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-10.pdf
2011,An Introduction to Deep Learning,"Ludovic Arnold, Sébastien Rebecchi, Sylvain Chevallier, Hélène Paugam-Moisy",The deep learning paradigm tackles problems on which shallow architectures (e.g. SVM) are affected by the curse of dimensionality. As part of a two-stage learning scheme involving multiple layers of nonlinear processing  a set of statistically robust features is automatically extracted  from the data. The present tutorial introducing the ESANN deep learning special session details the state-of-the-art models and summarizes the current understanding of this learning approach that is a reference for many difficult classification tasks.,Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-4.pdf
2011,A distributed learning algorithm based on two-layer artificial neural networks and genetic algorithms,"Diego Peteiro-Barral, Bertha Guijarro-Berdiñas, Beatriz Pérez-Sánchez, Oscar Fontenla-Romero","In many real-world applications of machine learning, the amount of data is now beyond the capability of learning algorithms because they cannot process all available data in a reasonable time. Moreover, most large datasets are naturally distributed or they are being stored in a distributed manner. A promising line of research in order to deal with large and/or distributed data is distributed learning. We propose a new distributed learning algorithm based on two-layer artificial neural networks and genetic algorithms. The results obtained show that our method performs better than other distributed learning algorithms.",Optimization and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-13.pdf
2011,Non-linearly increasing resampling in racing algorithms,"Verena Heidrich-Meisner, Christian Igel",Racing algorithms are iterative methods trying to find the best   among several options with high probability. The quality of each   option is a random variable and is estimated by its empirical mean   and concentration bounds obtained from repeated sampling. In each   iteration of a standard racing algorithm each promising option is   reevaluated once before being statistically compared with its   competitors. We argue that Hoeffding and empirical Bernstein races   benefit from decoupling the racing iteration from the number of   samples per option and illustrate this on an artificial   benchmark problem.,Optimization and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-75.pdf
2011,A Neural Filter for Electrolocation in Weakly Electric Fish,DaeEun Kim,"Weakly electric fish have the electric organ to generate the electric field and electrosensory mechanism to read the change of electric field with their electroreceptors. The electric organ produces a waveform of electric field as their electric organ discharge (EOD). Their active electrolocation system can detect distortion of the self-generated electric field, which is caused by a target object, and estimate the position of the target object. In this paper, we suggest a hypothesis that the periodic EOD signals can be involved to extract localization features from the noisy electrosensory signals and then provide a possible neural network to process noise-filtering to obtain the accurate information of a target position. The neural network has sinusoidal weights to process a time series of sensor readings for each electroreceptor and to obtain the original clean signal purely depending on object perturbation.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-105.pdf
2011,Hybrid HMM and HCRF model for sequence classification,"Yann Soullard, thierry Artieres","We propose a hybrid model combining a generative model and a discriminative model for signal labelling and classification tasks, aiming at taking the best from each world. The idea is to focus the learning of the discriminative model on most likely state sequences as output by the generative model. This allows taking advantage of the usual increased accuracy of generative models on small training datasets and of discriminative models on large training datasets. We instantiate this framework with Hidden Markov Models and Hidden Conditional Random Fields. We validate our model on financial time series and on handwriting data.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-102.pdf
2011,A structure independent algorithm for causal discovery,"Tom Claassen, Tom Heskes","We present two inference rules, based on so called minimal conditional independencies, that are sufficient to find all invariant arrowheads in a single causal DAG, even when selection bias may be present.  It turns out that the set of seven graphical orientation rules that are usually employed to identify these arrowheads are, in fact, just different instances/manifestations of these two rules.  The resulting algorithm to obtain all definite causal information is elegant and fast, once the (often surprisingly small) set of minimal independencies is found.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-82.pdf
2011,Causal relevance learning for robust classification under interventions,"Ernest Mwebaze, John A. Quinn, Michael Biehl","In some classification problems the distribution of the test data is different from that of the training data because of external manipulations to the variables we observe. We propose a classification scheme which is robust to outside interventions by identifying causes in the training data, given that causes of a target variable remain predictive even when the data is manipulated. We do this be extending Relevance Learning Vector Quantization (RLVQ), a classification scheme that learns a relevance profile for the classification task presented. Our proposed algorithm, Causal-RLVQ, learns a relevance profile that weights causally relevant features more strongly. The algorithm can determine a tradeoff between robustness to intervention and accuracy on non-manipulated data, yielding RLVQ as a special case.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-84.pdf
2011,A constraint-based approach to incorporate prior knowledge in causal models,"Giorgos Borboudakis, Sofia Triantafillou, Vincenzo Lagani, Ioannis Tsamardinos","In this paper we address the problem of incorporating prior knowledge, in the form of causal relations, in causal models. We use the framework of Maximal Ancestral Graphs and use a constraint-based approach, allowing the incorporation of prior knowledge in a more flexible manner compared  to previous approaches. Finally, we discuss the limitation of the used graphical models to capture causal knowledge, as well as open questions regarding this problem.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-76.pdf
2011,Selecting from an infinite set of features in SVM,"Remi Flamary, Florian Yger, Alain Rakotomamonjy","Dealing with the continuous parameters of a feature extraction method has always been a difficult task that is usually solved by cross-validation. In this paper, we propose an active set algorithm for selecting automatically these parameters in a SVM classification context. Our experiments on texture recognition and BCI signal classification show that optimizing the feature parameters in a continuous space while learning the decision function yields to better performances than using fixed parameters obtained from a grid sampling.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-23.pdf
2011,Mutual information based feature selection for mixed data,"Gauthier Doquire, Michel Verleysen","The problem of feature selection is crucial for many applications and has thus been studied extensively. However, most of the existing methods are designed to handle data consisting only in categorical or in real-valued features while a mix of both kinds of features is often encoutered in practice.  This paper proposes an approach based on mutual information and the maximal Relevance minimal Redundancy principle to handle the case of mixed data. It combines aspects of both wrapper and filter methods and is well suited for regression problems. Experiments on artificial and real-world datasets show the interest of the methodology.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-51.pdf
2011,Unsupervised feature selection for sparse data,"Artur Ferreira, Mario Figueiredo","Feature selection is a well-known problem in machine learning and pattern recognition. Many high-dimensional datasets are sparse, that is, many features have zero value. In some cases, we do not known the class label for some (or even all) patterns in the dataset, leading us to semi-supervised or unsupervised learning problems.  For instance, in text classification with the bag-of-words (BoW) representations, there is usually a large number of  features, many of which may be irrelevant (or even detrimental) for categorization tasks. In this paper, we propose one efficient unsupervised feature selection technique for sparse data, suitable for both standard floating point and binary features.   The experimental results on standard datasets show that the proposed method yields efficient feature selection, reducing the number of features while simultaneously improving the classification accuracy.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-91.pdf
2011,Multi-class classification in the presence of labelling errors,"Jakramate Bootkrajang, Ata Kaban","Learning a classifier from a training set that contains labelling errors is a difficult, yet not very well studied problem. Here we present a model-based approach that extends multi-class quadratic normal discriminant analysis with a model of the mislabelling process. We demonstrate the benefits of this approach in terms of parameter recovery as well as improved classification performance, on both synthetic and real-world multi-class problems. We also obtain enhanced accuracy in comparison with a previous model-free approach.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-53.pdf
2011,Principal component analysis for unsupervised calibration of bio-inspired airflow array sensors,"Michiel Van Dyck, Herbert Peremans","This paper describes the automatic calibration of a set of air flow sensitive sensors on a robot exposed to unknown random air flow stimuli. This might support the idea that the cricket cercus neural system in the terminal abdominal ganglion is evolved by learning. The algorithm makes use of the singular value decomposition (SVD) and the known reduced model dimension of the system for learning the sensor array setup. The absolute orientation of the array can only be found in function of a reference flow or reference sensor which must be calibrated manually. When only a change in airflow measure is needed, the reference sensor can be left uncalibrated.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-28.pdf
2011,Effects of sparseness and randomness of pairwise distance matrix on t-SNE results,Eli Parviainen,"We apply ideas from random graph theory to sparse pairwise distance matrices in dimension reduction. We use matrices with some short and some randomly chosen distances, and study effects of matrix sparseness and randomness on  trustworthiness and continuity of t-SNE visualizations. The existing works have either concentrated on matrices with only short distances, or implemented heuristics with mixed distances without explaining the effects. We find that trustworthiness generally increases with randomness, but not without limit. Continuity is less affected, but drops if matrices become too random. Sparseness has little effect on continuity, but decreases trustworthiness. Decrease in quality appears sublinear, which suggests that sparse t-SNE could be made subquadratic in complexity without too much effect on quality.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-27.pdf
2011,Nearest neighbors and correlation dimension for dimensionality estimation. Application to factor analysis of real biological time series data.,"Jérôme Lapuyade-Lahorgue, Ali Mohammad-Djafari","Determining the number of components in dimensionality reduction techniques is still one of the open problems of research on data analysis. These methods are often used in knowledge extraction of multivariate great dimensional data, but very often the number of components is assumed to be known. One of the classical methods to estimate this dimensionality is based on the Principal Components Analysis (PCA) eigenvalues. However, this method supposes that the model is linear and the signals are Gaussian. To be able to consider non-linear and non-Gaussian cases, we propose in this paper “measure based methods” as nearest neighbors dimension and correlation dimension. The comparaison between the three methods is evaluated both with simulated data and with real biological data, which are gene expression time series. The main goal of this study is to estimate the minimum number of factors.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-38.pdf
2011,A Similarity Function with Local Feature Weighting for Structured Data,"Rubén Suárez, Rocío García-Durán, Fernando Fernández","The application of learning approaches as Kernel or Instance Based methods to tree structured data requires the definition of similarity functions able to deal with such data. A new similarity function the for nearest prototype classification in relational data that follows a tree structure is defined in this paper. Its main characteristic is its capability to weight the importance of the different data features in different areas of the feature space. This work is built over two previous ideas:a similarity function for Local Feature Weighting (LFW), and a Relational Nearest Prototype Classification algorithm (RNPC).",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-61.pdf
2011,Exploiting vertices states in GraphESN by weighted nearest neighbor,"Claudio Gallicchio, Alessio Micheli","Graph Echo State Networks (GraphESN) extend the Reservoir Computing approach to directly process graph structures. The reservoir is applied to every vertex of an input graph, realizing a contractive encoding process and resulting in a structured state isomorphic to the input. Whenever an unstructured output is required, a state mapping function maps the structured state into a fixed-size feature representation that feeds the linear readout. In this paper we propose an alternative approach, based on distance-weighted nearest neighbor, to realize a more flexible readout exploiting the state information computed for every vertex according to its individual relevance.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-83.pdf
2011,The role of Fisher information in primary data space for neighbourhood mapping,"Héctor Ruiz, Ian Jarman, José D Martín, Paulo Lisboa","Clustering methods and nearest neighbour classifiers typically compute distances between data points as a measure of similarity, with nearby pairs of points considered more like each other than remote pairs. The distance measure of choice is often Euclidean, implicitly treating all directions in space as equally relevant. This paper reviews the application of Fisher information to derive a metric in primary data space.  The aim is to provide a natural coordinate space to represent pairwise distances with respect to a probability distribution p(c|x), defined by an external label c, and use it to compute more informative distances.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-86.pdf
2011,Communication Challenges in Cloud K-means,"Fabrice Rossi, Matthieu Durut","This paper studies how parallel machine learning algorithms can be implemented on top of Microsoft Windows Azure cloud computing platform. More specifically, the proposed algorithm focuses on communication mechanisms through the storage.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-95.pdf
2011,A Spectral Based Clustering Algorithm for Categorical Data with Maximum Modularity,"Lazhar Labiod, Younès Bennani","In this paper we propose a spectral based clustering algorithm to maximize an extended Modularity measure for categorical data; first, we establish the connection with the Relational Analysis criterion. Second, the maximization of the extended modularity is shown as a trace maximization problem. A spectral based algorithm is then presented to search for the partitions maximizing the extended Modularity criterion. Experimental results indicate that the new algorithm is efficient and effective at finding a good clustering across a variety of real world data sets",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-107.pdf
2011,Single-trial P300 detection with Kalman filtering and SVMs,"Lucie Daubigney, Olivier Pietquin","Brain Computer Interfaces (BCI) are systems enabling humans to communicate with machines through signals generated by the brain. Several kinds of signals can be envisioned as well as means to measure them. In this paper we are particularly interested in even-related brain potentials (ERP) and especially visually-evoked potential signals (P300) measured with surface electroencephalograms (EEG). When the human is stimulated with visual inputs, the P300 signals arise about 300 ms after the visual stimulus has been received. Yet, the EEG signal is often very noisy which makes the P300 detection hard. It is customary to use an average of several trials to enhance the P300 signal and reduce the random noise but this results in a lower bit rate of the interface. In this contribution, we propose a novel approach to P300 detection using Kalman filtering and SVMs. Experiments show that this method is a promising step toward single-trial detection of P300.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-41.pdf
2011,Classifying mental states with machine learning algorithms using alpha activity decline,"Carina Walter, Gabriele Cierniak, Peter Gerjets, Wolfgang Rosenstiel, Martin Bogdan","This publication aims at developing computer based learning environments adapting to learners’ individual cognitive condition. The adaptive mechanism, based on Brain-Computer-Interface (BCI) methodology, relays on electroencephalogram (EEG)-data to diagnose learners’ mental states. A first within-subjects study (10 students) was accomplished aiming at differentiating between states of learning and non-learning by means of EEG-data. Support-Vector-Machines classified characteristics in the EEG-signals for these two different stimuli on average as 74.55% correct. For individual students the percentage of correct classification reached 92.22%. The results indicate that continuous EEG-data combined with BCI methodology is a promising approach to measuring learners’ mental states online.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-35.pdf
2011,Approaches for Automatic Speaker Recognition in a Binaural Humanoid Context,"Karim Youssef, Bastien Breteau, Sylvain Argentieri, Jean-Luc Zarader, Zefeng Wang","This paper presents two methods of Automatic Speaker Recognition (ASkR). ASkR has been largely studied in the last decades, but in most cases in mono-microphone or microphone array contexts. Our systems are placed in a binaural humanoid context where the signals captured by both ears of a humanoid robot will be exploited to perform the ASkR. Both methods use Mel-Frequency Cepstral Coding (MFCC), but one performs the classification with Predictive Neural Networks (PNN) and the other performs it with Gaussian Mixture Models (GMM). Tests are made on a database simulating the functioning of the human ears. They study the influence of noise, reverberations and speaker spatial position on the recognition rate.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-30.pdf
2011,Fast Data Mining with Sparse Chemical Graph Fingerprints by Estimating the Probability of Unique Patterns,"Georg Hinselmann, Lars Rosenbaum, Andeas Jahn, Andreas Zell",The aim of this work is to introduce a modification of chemical graphs fingerprints for data mining. The algorithm reduces the number of features by taking the probability of producing an unique feature at a specific search depth into account. We observed the probability of generating a non-unique feature depending on a search parameter (which leads to a power-law growths of features) and modeled it by a sigmoid function. This function was integrated into a fingerprinting routine to reduce the features according to their probability.  The predictive performance was convincing with a considerable speedup for the training of a linear support vector machine for sparse instances.,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-37.pdf
2011,Automatic Enhancement of Correspondence Detection in an Object Tracking System,"Denis Schulze, Sven Wachsmuth, Katharina J. Rohlfing",This paper proposes a strategy to automatically detect the correspondence  between measurements of different sensors using object tracking. In addition  the strategy includes the ability to learn new features to facilitate the  correspondence computation for future measurements. Therefore first a correlation  between objects of different modalities is computed using time synchronous  changes of attribute values. Using statistical methods to determine the dependencies between changes of different attributes it is shown how a  multi layer perceptron (MLP) can be used to enhance the correspondence detection in ambiguous situations.,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-85.pdf
2011,Time Experiencing by Robotic Agents,"Michail Maniadakis, Marc Wittmann, Panos Trahanias","Biological organisms perceive and act in the world based on spatiotemporal experiences and interpretations. However, artificial agents consider mainly the spatial relationships that exist in the world, typically ignoring its temporal aspects. In an attempt to direct research interest towards the fundamental issue of time experiencing, the current work explores two temporally different versions of a robotic rule switching task. An evolutionary process is employed to design a neural network controller capable of accomplishing both versions of the task. The systematic exploration of  neural network dynamics revealed a self-organized time perception capacity in the agent's cognitive system that significantly facilitates the accomplishment of tasks, through the modulation of the supplementary behavioural and cognitive processes.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-70.pdf
2011,Visual place recognition using Bayesian filtering with Markov chains,"Mathieu Dubois, Hervé Guillaume, Emmanuelle Frenoux, Philippe Tarroux","We present a novel idea to use Bayesian filtering in the case of place recognition. More precisely, our system combines global image characterization, Learned Vector Quantization, Markov chains and Bayesian filtering. The goal is to integrate several images seen by a robot during exploration of the environment and the dependency between them. We present our system and the new Bayesian filtering algorithm. Our system has been evaluated on a standard database and shows promising results.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-45.pdf
2011,Iterative multi-task sequence labeling for predicting structural properties of proteins,"Francis Maes, Julien Becker, Louis Wehenkel","Developing computational tools for predicting protein structural information given their amino acid sequence is of primary importance in protein science. Problems, such as the prediction of secondary structures, of solvent accessibility, or of disordered regions, can be expressed as sequence labeling problems and could be solved independently by existing machine learning based sequence labeling approaches. But, since these problems are closely related, we propose to rather approach them jointly in a multi-task approach. To this end, we introduce a new generic framework for iterative multi-task sequence labeling. We apply this - conceptually simple but quite effective - strategy to jointly solve a set of five protein annotation tasks. Our empirical results with two  protein datasets show that the proposed strategy significantly outperforms the single-task approaches.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-52.pdf
2011,Identification of sparse spatio-temporal features in Evoked Response Potentials,"Nisrine Jrad, Marco Congedo","Electroencephalographic Evoked Response Potentials (ERP)s exhibit distinct and individualized spatial and temporal characteristics. Identification of spatio-temporal features improves single-trial classification performance and allows a better understanding of the underlying physiology. This paper presents a method for analyzing the spatio-temporal characteristics associated with Error related Potentials (ErrP)s. First, a resampling procedure based on Global Field Power (GFP) extracts temporal features. Second, a spatially weighted SVM (sw-SVM) is proposed to learn a spatial filter optimizing the classification performance for each temporal feature. Third, the so obtained ensemble of sw-SVM classifiers are combined using a weighted combination of all sw-SVM outputs. Results indicate that inclusion of temporal features provides useful insight regarding the spatio-temporal characteristics of error potentials.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-54.pdf
2011,A unified approach to estimation and control of the False Discovery Rate in Bayesian network skeleton identification,"Angelos P. Armen, Ioannis Tsamardinos","Constraint-based Bayesian network (BN) structure learning algorithms typically control the False Positive Rate (FPR) of their skeleton identification phase. The False Discovery Rate (FDR), however, may be of greater interest and methods for its utilization by these algorithms have been recently devised. We present a unified approach to BN skeleton identification FDR estimation and control and experimentally evaluate the performance of FDR estimators in both tasks over several networks. We demonstrate that estimation is too conservative for most networks and strong control at common FDR thresholds is not achieved with some networks; finally, we identify the possible causes of this situation.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-106.pdf
2011,Inferring the causal decomposition under the presence of deterministic relations,"Jan Lemeire, Stijn Meganck, Francesco Cartella, Tingting Liu, Alexander Statnikov","The presence of deterministic relations pose problems for current algorithms that learn the causal structure of a system based on the observed conditional independencies. Deterministic variables lead to information equivalences; two sets of variables have the same information about a third variable. Based on information content, one cannot decide on the direct causes. Several edges model equally well the dependencies. We call them equivalent edges. We propose to select among the equivalent edges the one with the simplest descriptive complexity. This approach assumes that the descriptive complexity increases along a causal path. As confirmed by our experimental results, the accuracy of the method depends on the chance of accidental matches of complexities.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-93.pdf
2011,Learning of causal relations,"John A. Quinn, Joris Mooij, Tom Heskes, Michael Biehl","To learn about causal relations between variables just by observing samples from them, particular assumptions must be made about those variables' distributions. This article gives a practical description of how such a learning task can be undertaken based on different possible assumptions. Two categories of assumptions lead to different methods, constraint-based and Bayesian learning, and in each case we review both the basic ideas and some recent extensions and alternatives to them.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-2.pdf
2011,Supervised dimension reduction mappings,"Kerstin Bunte, Michael Biehl, Barbara Hammer",We propose a general principle to extend dimension  reduction tools to explicit dimension reduction mappings and we show that this can serve as an interface to incorporate prior knowledge in the form of class labels. We explicitly demonstrate this technique by combining locally linear mappings which result from matrix learning vector quantization schemes with the t-distributed stochastic neighbor embedding cost function. The technique is tested on several benchmark data sets.,Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-73.pdf
2011,Probabilistic Fisher discriminant analysis,"Charles Bouveyron, Camille Brunet","Fisher Discriminant Analysis (FDA) is a popular method for dimensionality reduction and classification but has poor performances in the cases of label noise and sparse labeled data. To overcome these limitations, we propose a probabilistic framework for FDA and extend it to the semi-supervised case. Experiments on real-world datasets show that the proposed approach works as well as FDA in standard situations and outperform it in the label noise and sparse label cases.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-19.pdf
2011,Mutual information for feature selection with missing data,"Gauthier Doquire, Michel Verleysen","Feature selection is an important task for many machine learning applications; moreover missing data are encoutered very often in practice.  This paper proposes to adapt a nearest neighbors based mutual information estimator to handle missing data and to use it to achieve feature selection.  Results on articial and real world datasets show that the method is able to select important features without the need for any imputation algorithm. Moreover, experiments also indicate that selecting the features before imputing the data generally increases the precision of the prediction models.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-50.pdf
2011,Class-Specific Feature Selection for One-Against-All Multiclass SVMs,"Gaël de Lannoy, Damien Francois, Michel Verleysen","This paper proposes a method to perform class-specific feature selection in multiclass addressed solved with the one-against-all strategy. The main issue arises at the final step of the classification process, where binary classifier outputs must be compared one against another to elect the winning class. This comparison may be biased towards one specific class when the binary classifiers are built on distinct feature subsets. This paper proposes a normalization of the binary classifiers outputs that allows fair comparisons in such cases.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-8.pdf
2011,Maximal Discrepancy vs. Rademacher Complexity for error estimation,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella","The Maximal Discrepancy and the Rademacher Complexity are powerful statistical tools that can be exploited to obtain reliable, albeit not tight, upper bounds of the generalization error of a classifier. We study the different behavior of the two methods when applied to linear classifiers and suggest a practical procedure to tighten the bounds. The resulting generalization estimation can be succesfully used for classifier model selection.",Learning theory,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-78.pdf
2012,Weighted/Structured Total Least Squares problems and polynomial system solving,"Philippe Dreesen, Kim Batselier, Bart De Moor","Weighted and Structured Total Least Squares (W/STLS) problems are generalizations of Total Least Squares with additional weighting and/or structure constraints. W/STLS are found at the heart of several mathematical engineering techniques, such as statistics and systems theory, and are typically solved by local optimization methods, having the drawback that one cannot guarantee global optimality of the retrieved solution. This paper employs the Riemannian SVD formulation to write the W/STLS problem as a system of polynomial equations. Using a novel matrix technique for solving systems of polynomial equations, the globally optimal solution of the W/STLS problem is retrieved.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-170.pdf
2012,Deconvolution in nonparametric statistics,"Kris De Brabanter, Bart De Moor","In this tutorial paper we give an overview of deconvolution problems in nonparametric statistics. First, we consider the problem of density estimation given a contaminated sample. We illustrate that the classical Rosenblatt-Parzen kernel density estimator is unable to capture the full shape of the density while the presented method experiences almost no problems. Second, we use the previous estimator in a nonparametric regression framework with errors-in-variables.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-10.pdf
2012,Image reconstruction using an iterative SOM based algorithm,"jouini Manel, Thiria Sylvie, crépon Michel","The frequent presence of clouds in optical remotely sensed imagery prevents space and time continuity and limits its exploitation. The aim of this study is to propose a new statistical processing approach for the reconstruction of areas covered by clouds in a time sequence of optical satellite images. The approach is  an iterative SOM based algorithm and was applied to reconstruct ocean color images. It used the information contained in color images and a set of satellite-derived dynamic ocean products (sea surface temperature: SST, altimetry: SSH) to reproduce the local spatio temporal relationships of the cloudy images.  The reconstruction method is general and can be applied to fill gaps in mutli-dimensional and correlated data.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-78.pdf
2012,Robust clustering of high-dimensional data,"Anastasios Bellas, Charles Bouveyron, Marie Cottrell, Jérôme Lacaille","We address the problem of robust clustering of high - dimensional data, which is recurrent in real-world applications. Existing robust clustering methods are unfortunately sensitive in high dimension, while existing approaches for high-dimensional data are in general not robust. We propose a hybrid iterative EM-based algorithm that combines an efficient high-dimensional clustering algorithm and the trimming technique. We test our algorithm on synthetic and real-world data from the domain of aircraft engine health monitoring and show its efficiency for high-dimensional noisy datasets.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-52.pdf
2012,Unsupervised learning of motion patterns,"Thomas Guthier, Julian Eggert, Volker Willert","Neurophysiological findings suggest that the visual cortex of mammals contains neural populations that are sensitive to specific motion patterns. In this paper, we present a new method to learn such patterns in an unsupervised way. To represent motion, dense optical flow fields of videos containing humans performing several actions like walking and running are estimated. We introduce VNMF, an extension of the translation invariant NMF that works on flow fields, along with a new energy term that enforces parts-basedness. VNMF incorporates three principles found in neural motion processing: Sparsity, non-negativity and direction selectivity. We find that the extracted motion patterns are shaped like body parts, which supports the idea that the representation of biological motion is directly linked to the shape of an object.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-48.pdf
2012,Hybrid hierarchical clustering: cluster assessment via cluster validation indices,"Mark Embrechts, Jonathan Linton, Christopher Gatti","This paper introduces a novel method for speeding up hier- archical clustering with cluster seeding with the clusters obtained from a different clustering method (e.g., K-means). A benchmark study compares the cluster performance of hierarchical clustering and hierarchical cluster- ing with cluster seeding based on several cluster performance indices using a wide variety of real-world and artificial benchmark data sets. While cluster seeding can significantly speed up agglomerative hierarchical clus- tering, it will also affect the cluster quality, and thus the validation indices as well. Extensive benchmarks show that the impact of cluster seeding is often rather small.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-163.pdf
2012,From neuronal cost-based metrics towards sparse coded signals classi&#64257;cation,"Anthony Mouraud, Quentin Barthélemy, Aurélien Mayoue, Cédric Gouy-Pailler, Anthony Larue, Hélène Paugam-Moisy","Sparse signal decompositions are keys to e&#64259;cient compression, storage and denoising, but they lack appropriate methods to exploit this sparsity for a classi&#64257;cation purpose. Sparse coding methods based on dictionary learning may result in spikegrams, a sparse and temporal representation of signals by a raster of kernel occurrences through time. This paper proposes a method for coupling spike train cost-based metrics (from neuroscience) with spikegram sparse decompositions, for clustering multivariate signals. Experiments on character trajectories, recorded by sensors from natural handwriting, prove the validity of the approach, compared with currently available classi&#64257;cation performance in literature.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-152.pdf
2012,magnitude sensitive competitive learning,"Enrique Pelayo, David Buldain, Carlos Orrite","This paper presents a new algorithm, Magnitude Sensitive Competitive Learning (MSCL), which has the ability of distributing the unit weights following any magnitude calculated from the unit parameters or the input data inside the Voronoi region of the unit. This controlled behavior permits to surpass other standard Competitive Learning algorithms that only tend to concentrate neurons accordingly to the input data density. Some application examples applying different magnitude functions show the MSCL possibilities.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-31.pdf
2012,EMFit based Ultrasonic Phased Arrays with evolved Weights for Biomimetic Target Localization,"Jan Steckel, Andre Boen, Dieter Vanderest, Herbert Peremans","Bats use the spatial filtering performed by their pinnae in localization tasks. We propose a similar localization scheme based on the spatial filtering of the received echoes by a phased array. By evolving the weights of a linear phased array using a genetic algorithm, a very efficient spatial filter can be implemented. The localization performance of the evolved array in combination with the biomimetic localization algorithm is compared to a standard phased array localization scheme.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-33.pdf
2012,learning task relatedness via dirichlet process priors for linear regression models,"Marcel Hermkes, Nicolas Kuehn, Carsten Riggelsen","In this paper we present a hierarchical model of linear regression functions in the context of multi-task learning. The parameters of the linear model are coupled by a Dirichlet Process (DP) prior, which implies a clustering of related functions for different tasks. To make approximate Bayesian inference under this model we apply the Bayesian Hierarchical Clustering (BHC) algorithm. The experiments are conducted on two real world problems: (i) school exam score prediction  and (ii) prediction of ground-motion parameters. In comparison to baseline methods with no shared prior the results show an improved prediction performance when using the hierarchical model.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-27.pdf
2012,An analysis of Gaussian-binary restricted Boltzmann machines for natural images,"Nan Wang, Jan Melchior, Laurenz Wiskott","A Gaussian-binary restricted Boltzmann machine is a widely used energy-based model for continuous data distributions,  although many authors reported difficulties in training on natural images. To clarify the model's capabilities and limitations we derive a rewritten formula of the probability density function as a linear superposition of Gaussians. Based on this formula we show how Gaussian-binary RBMs learn natural image statistics. However the probability density function is not a good representation of the data distribution.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-95.pdf
2012,Functional Mixture Discriminant Analysis with hidden process regression for curve classification,"Faicel Chamroukhi, Hervé Glotin, Céline Rabouy",We present a new mixture model-based discriminant analysis approach for functional data using a specific hidden process regression model. The approach allows for fitting flexible curve-models to each class of complex-shaped curves presenting regime changes. The model parameters are learned by maximizing the observed-data log-likelihood for each class by using a dedicated expectation-maximization (EM) algorithm. Comparisons on simulated data with alternative approaches show that the proposed approach provides better results.,"Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-165.pdf
2012,Assessment of sequential Boltmann machines on a lexical processing task,"Alberto Testolin, Alessandro Sperduti, Ivilin Stoianov, Marco Zorzi","Recently, a promising probabilistic model based on Boltzmann Machines, i.e. the Recurrent Temporal RBM, has been proposed. It is able to learn physical dynamics (e.g. videos of bouncing balls), however up to now it was not clear whether this ability could apply to symbolic tasks. Here we assess its capabilities on  learning graphotactic rules from a set of English words.  It emerged that the model is able to extract local transition rules between items of a sequence, but it does not seem to be suited to encode a whole word.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-94.pdf
2012,Sparse Nonparametric Topic Model for Transfer Learning,"Ali Faisal, Jussi Gillberg, Jaakko Peltonen, Gayle Leen, Samuel Kaski","Count data arises for example in bioinformatics or analysis of text documents represented as word count vectors. With several data sets available from related sources, like papers in related conference tracks, exploiting their similarities by transfer learning can improve models compared to modeling sources independently. We introduce a Bayesian generative transfer learning model which represents similarity across document collections by sparse sharing of latent topics controlled by an Indian Buffet Process. Unlike Hierarchical Dirichlet Process based multi-task learning, our model decouples topic sharing probability from topic strength, making sharing of low-strength topics easier, and outperforms the HDP approach in experiments.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-183.pdf
2012,The stability of feature selection and class prediction from ensemble tree classifiers,"Jérôme Paul, Michel Verleysen, Pierre Dupont","The bootstrap aggregating procedure at the core of ensemble tree classifiers reduces, in most cases, the variance of such models while offering good generalization capabilities. The average predictive performance of those ensembles is known to improve up to a certain point while increasing the ensemble size. The present work studies this convergence in contrast to the stability of the class prediction and the variable selection performed while and after growing the ensemble. Experiments on several biomedical datasets, using random forests or bagging of decision trees, show that class prediction and, most notably, variable selection typically require orders of magnitude more trees to get stable.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-158.pdf
2012,Linear kernel combination using boosting,"Alexis Lechervy, Philippe-Henri Gosselin, Frédéric Precioso","In this paper, we propose a novel algorithm to design multiclass kernels based on an iterative combination of weak kernels in a schema inspired from boosting framework. Our solution has a linear complexity in the number of training dataset size. We evaluate our method for classification first on a toy example by integrating our multi-class kernel into a kNN classifier and comparing our results with a reference iterative kernel design method, and then for image categorization by considering a classic image database and comparing our boosted linear kernel combination with the direct linear combination of all features in a linear SVM.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-156.pdf
2012,Recent developments in clustering algorithms,"Charles Bouveyron, Barbara Hammer, Thomas Villmann",,Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-5.pdf
2012,The `K' in K-fold Cross Validation,"Davide Anguita, Luca Ghelardoni, Alessandro Ghio, Luca Oneto, Sandro Ridella","The K-fold Cross Validation (KCV) technique is one of the most used approaches by practitioners for model selection and error estimation of classifiers. The KCV consists in splitting a dataset into k subsets; then, iteratively, some of them are used to learn the model, while the others are exploited to assess its performance. However, in spite of the KCV success, only practical rule-of-thumb methods exist to choose the number and the cardinality of the subsets. We propose here an approach, which allows to tune the number of the subsets of the KCV in a data-dependent way, so to obtain a reliable, tight and rigorous estimation of the probability of misclassification of the chosen model.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-62.pdf
2012,Adaptive Optimization for Cross Validation,"Rudi Alessandro, Chiusano Gabriele, Alessandro Verri","The process of model selection and assessment aims at finding a subset of parameters that minimize the expected test error for a model related to a learning algorithm. Given a subset of tuning parameters, an exhaustive grid search is typically performed. In this paper an automatic algorithm for model selection and assessment is proposed. It adaptively learns the error function in the parameters space, making use of the Scale Space theory and the Statistical Learning theory in order to estimate a reduced number of models and, at the same time, to make them more reliable. Extensive experiments are perfomed on the MNIST dataset.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-32.pdf
2012,Recognition of HIV-1 subtypes and antiretroviral drug resistance using weightless neural networks,"Caio Souza, Flavio Nobre, Priscila Lima, Robson Silva, Rodrigo Brindeiro, Felipe França","This work presents an application of an improved version of the WiSARD weightless neural network in the recognition of different mutation types of HIV-1 and in the determination of antiretroviral drugs resistence. The data set used consists of 1205 gene sequence of the HIV-1 protease of subtypes B, C and F from patients under treatment failure. Experiments performed with the bleaching technique over the WiSARD model under different data representation strategies have shown promising results, both in terms of accuracy and standard deviation.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-154.pdf
2012,Matrix relevance LVQ in steroid metabolomics based classification of adrenal tumors,"Michael Biehl, Petra Schneider, David Smith, Han Stiekema, Angela Taylor, Beverly Hughes, Cedric Shackleton, Paul Stewart, Wiebke Arlt","We present a machine learning system for the differential  diagnosis of benign adrenocortical adenoma (ACA) vs.  malignant adrenocortical carcinoma (ACC). The data employed for the classification are urinary excretion values of 32 steroid metabolites. We apply prototype-based classification techniques to discriminate the classes, in particular, we use modifications of Generalized Learning Vector Quantization including matrix relevance learning. The obtained system achieves high sensitivity and specificity and outperforms previously used approaches  for the detection of adrenal malignancy. Moreover, the method identifies a subset of most discriminative markers  which facilitates its future use as a non-invasive high-throughput diagnostic tool.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-86.pdf
2012,Supervised and unsupervised classification approaches for human activity recognition using body-mounted sensors,"Dorra Trabelsi, Samer Mohammed, Faicel Chamroukhi, Latifa Oukhellou, Yacine Amirat","In this paper, the activity recognition problem from 3-d acceleration data measured with body-worn accelerometers is formulated as a problem of multidimensional time series segmentation and classication. More specically, the proposed approach uses a statistical model based on Multiple Hidden Markov Model Regression (MHMMR) to automatically analyze the human activity. The method takes into account the sequential appearance and temporal evolution of the data to easily detect activities and transitions. Classication results obtained by comparing the proposed approach to those of the standard supervised classication approaches as well as the standard hidden Markov model show that the proposed approach is promising.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-81.pdf
2012,Classifying Scotch Whisky from near-infrared Raman spectra with a Radial Basis Function Network with Relevance Learning,"Andreas Backhaus, Praveen Cheriyan Ashok, Bavishna Balagopal Praveen, Kishan Dholakia, Udo Seiffert",The instantaneous assessment of high-priced liquor products with minimal sample volume and no special preparation is an important task for quality monitoring and fraud detection. In this contribution the automated classification of Raman spectra acquired with a special optofluidic chip is performed with the use of a number of Artificial Neural Networks. A standard Radial Basis Function Network is adopted to incorporate relevance learning and showed robust classification performance across classification tasks. The acquired relevance weighting per feature dimension can be used to reduce the number of features while retaining a high level of accuracy.,Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-139.pdf
2012,One-class classi&#64257;er based on extreme value  statistics,"David Martínez-Rego, Evan Kriminger, Jose C. Principe, Oscar Fontenla-Romero, Amparo Alonso-Betanzos","Interest in One-Class Classi&#64257;cation methods has soared in  recent years due to its wide applicability in many practical problems where  classi&#64257;cation in the absence of counterexamples is needed. In this paper,  a new one class classi&#64257;cation rule based on order statistics is presented.  It only relies on the embedding of the classi&#64257;cation problem into a metric  space, so it is suitable for Euclidean or other structured mappings. The  suitability of the proposed method is assessed through a comparison both  for arti&#64257;cial and real life data sets. The good results obtained pave the  road to its application on practical novelty detection problems",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-13.pdf
2012,A CUSUM approach for online change-point detection on curve sequences,"Nicolas CHEIFETZ, Allou Samé, Patrice Aknin, Emmanuel DE VERDALLE","Anomaly detection on sequential data is common in many domains such as fraud detection for credit cards, intrusion detection for cyber-security or military surveillance. This paper addresses a new CUSUM-like method for change point detection on curves sequences in a context of preventive maintenance of transit buses door systems. The proposed approach is derived from a specific generative modeling of curves. The system is considered out of control when the parameters of the curves density change. Experimental studies performed on real world data demonstrate the promising behavior of the proposed method.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-176.pdf
2012,Automatic Group-Outlier Detection,"Amine Chaibi, Azzag Hanane, mustapha lebbah",We propose in this paper a new measure called GOF (Group Outlier Factor) to detect groups outliers. To validate this measure we integrated it in a clustering process using Self organizing Map. The proposed approach is based on relative density of each group of data and simultaneously provides a partitioning of data and a quantitative indicator (GOF). The obtained results are very encouraging to continue in this direction.,Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-111.pdf
2012,Adaptive learning for complex-valued data,"Kerstin Bunte, Frank-Michael Schleif, Michael Biehl","In this paper we propose a variant of the Generalized Matrix Learning Vector Quantization (GMLVQ) for dissimilarity learning on complex-valued data. Complex features can be encountered in various data domains,  e.g. stemming from Fourier transform ion cyclotron resonance mass spectrometry and image analysis. Current approaches deal with complex inputs by ignoring the imaginary parts or concatenating real and imaginary parts to a longer real valued vector.  In this contribution we propose a prototype based classification method, which allows to deal with complex-valued data in its natural form. The algorithm is demonstrated on a benchmark data set and for leave recognition using Zernike moments. We observe that the complex version converges much faster compared to the original GMLVQ evaluated on the real parts only. The complex version has less free parameters than using a concatenated vector and is thus computationally more efficient than original GMLVQ.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-85.pdf
2012,RNN Based Batch Mode Active Learning Framework,"Gaurav Maheshwari, Vikram Pudi","Active Learning has been applied in many real world classification tasks to reduce the amount of labeled data required for training a classifier. However most of the existing active learning strategies select only a single sample for labeling by the oracle in every iteration. This results in retraining the classifier after each sample is added which is quite computationally expensive. Also many of the existing sample selection strategies are not suitable for the multi-class classification tasks. To overcome these issues, we propose an efficient batch mode framework for active learning using the notion of influence sets based on Reverse Nearest Neighbor, which is applicable for multi-class classification as well. To demonstrate the effectiveness of our technique, we compare its performance against existing active learning techniques on real life datasets. Experimental results show that our technique outperforms existing active learning methods significantly especially on multi-class datasets.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-88.pdf
2012,L1-based compression of random forest models,"Arnaud Joly, François Schnitzler, Pierre Geurts, Louis Wehenkel","Random forests are effective supervised learning methods applicable to large-scale datasets. However, the space complexity of tree ensembles, in terms of their total number of nodes, is often prohibitive, specially in the context of problems with very high-dimensional input spaces. We propose to study their compressibility by applying a L1-based regularization to the set of indicator functions defined by all their nodes. We show experimentally that preserving or even improving the model accuracy while significantly reducing its space complexity is indeed possible.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-43.pdf
2012,maximum likelihood estimation and polynomial system solving,"Kim Batselier, Philippe Dreesen, Bart De Moor","This article presents an alternative method to find the global maximum likelihood estimates of the mixing probabilities of a mixture of multinomial distributions. For these mixture models it is shown that the maximum likelihood estimates of the mixing probabilities correspond with the roots of a multivariate polynomial system. A new algorithm, set in a linear algebra framework, is presented which allows to find all these roots by solving a generalized eigenvalue problem.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-37.pdf
2012,Averaging of kernel functions,"Lluís Belanche, Alessandra Tosi","In kernel-based machines, the integration of several kernels to build more flexible learning methods is a promising avenue for research. In particular, in Multiple Kernel Learning a compound kernel is build by learning a kernel that is the weighted mean of several sources. We show in this paper that the only feasible average for kernel learning is precisely the arithmetic average. We also show that three familiar means (the geometric, inverse root mean square and harmonic means) for positive real values actually generate valid kernels.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-60.pdf
2012,Joint Regression and Linear Combination of Time Series for Optimal Prediction,"Dries Geebelen, Kim Batselier, Philippe Dreesen, Signoretto Marco, Johan Suykens, Bart De Moor, Joos Vandewalle",In most machine learning applications the time series to predict is fixed and one has to learn a prediction model that causes the smallest error. In this paper choosing the time series to predict is part of the optimization problem. This time series has to be a linear combination of a priori given time series. The optimization problem that we have to solve can be formulated as choosing the linear combination of a priori known matrices such that the smallest singular vector is minimized. This problem has many local minima and can be formulated as a polynomial system which we will solve using a polynomial system solver. The proposed prediction algorithm has applications in algorithmic trading in which a linear combination of stocks will be bought.,Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-149.pdf
2012,The Exploration vs Exploitation Trade-Off in Bandit Problems: An Empirical Study,"Bernard Manderick, Saba Yahyaa",We compare well-known action selection policies used in reinforcement learning like epsilon-greedy and softmax with lesser known ones like the Gittins index and the knowledge gradient on bandit problems. The latter two are in comparison very performant. Moreover the knowledge gradient can be generalized to other problems.,"Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-172.pdf
2012,Highly efficient localisation utilising weightless neural systems,"Ben McElroy, Gillham Michael, Gareth Howells, Sarah Spurgeon, Kelly Michael, John Batchelor, Pepper Matthew","Efficient localization is a highly desirable property for an autonomous navigation system. Weightless neural networks offer a real-time approach to robotics applications by reducing hardware and software requirements for pattern recognition techniques. Such networks offer the potential for objects, structures, routes and locations to be easily identified and maps constructed from fused limited sensor data as information becomes available. We show that in the absence of concise and complex information, localisation can be obtained using simple algorithms from data with inherent uncertainties using a combination of Genetic Algorithm techniques applied to a Weightless Neural Architecture.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-138.pdf
2012,A generative model that learns Betti numbers from a data set,"Maxime Maillot, Michaël Aupetit, Gérard Govaert","Analysis of multidimensional data is challenging. Topological invariants can be used to summarize essential features of such data sets. In this work, we propose to compute the Betti numbers from a generative model based on a simplicial complex learnt from the data. We compare it to the Witness Complex, a geometric technique based on nearest neighbors. Our results on different data distributions with known topology show that Betti numbers are well recovered with our method.",Nonlinear dimensionality reduction and topological learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-157.pdf
2012,Out-of-sample kernel extensions for nonparametric dimensionality reduction,"Andrej Gisbrecht, Wouter Lueks, Bassam Mokbel, Barbara Hammer","Nonparametric dimensionality reduction (DR) techniques such as locally linear embedding or t-distributed stochastic neighbor embedding (t-SNE) constitute standard tools to visualize high dimensional and complex data  in the Euclidean plane. With increasing data volumes and streaming applications, it is often no longer possible to project all data points at once. Rather, out-of-sample extensions (OOS) derived from a small subset of all data points are used. In this contribution, we propose a kernel mapping for OOS in contrast to direct techniques based on the DR method.  This can be trained based on a given example set, or it can be trained indirectly based on the cost function of the DR technique. Considering t-SNE as an example and several benchmarks, we show that a kernel mapping outperforms direct OOS as provided by t-SNE.",Nonlinear dimensionality reduction and topological learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-25.pdf
2012,Type 1 and 2 symmetric divergences for stochastic neighbor embedding,John Lee,"Stochastic neighbor embedding (SNE) is a method of dimensionality reduction (DR) that involves softmax similarities measured between all pairs of data points. In order to build a low-dimensional embedding, SNE tries to reproduce the similarities observed in the high-dimensional data space. The capability of softmax similarities to fight the phenomenon of norm concentration has been studied in previous work. This paper investigates a complementary aspect, namely, the cost function that quantifies the mismatch between the high- and low-dimensional similarities. We show experimentally that switching from a simple Kullback-Leibler divergences to symmetric mixtures of divergences increases the quality of DR. This modification brings SNE to the performance level of its Student $t$-distributed variant, without the need to resort to non-identical similarity definitions in the high- and low-dimensional spaces. These results allow us to conclude that future improvements in similarity-based DR will likely emerge from better definitions of the cost function.",Nonlinear dimensionality reduction and topological learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-3.pdf
2012,Range-based non-orthogonal ICA using cross-entropy method,"Easter Selvan Suviseshamuthu, Amit Chattopadhyay, Umberto Amato, Pierre-Antoine Absil","A derivative-free framework for optimizing a non-smooth range-based contrast function in order to estimate independent components is presented. The proposed algorithm employs the von-Mises Fisher (vMF) distribution to draw random samples in the cross-entropy (CE) method, thereby intrinsically maintaining the unit-norm constraint that removes the scaling indeterminacy in independent component analysis (ICA) problem. Empirical studies involving natural images show how this approach outperforms popular schemes [1] in terms of the separation performance.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-97.pdf
2012,enhanced emotion recognition by feature selection to animate a talking head,"Hela Daassi-Gnaba, Yacine OUSSAR","It is known that deaf and hard of hearing people can sub- stantially improve their skill to lip reading if they have access to speaker emotion. Moreover, it has been shown that animating an artificial talking head can provide this modality. In this paper, we assume that emotion recognition to animate such talking head can be performed using a small set of relevant features extracted from the speech signal. More precisely, we show that the implementation of linear classifiers using Support Vector Machines (SVM) with the involvement of a feature selection method leads to a promising performance which confirms our assumption.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-133.pdf
2012,Cluster homogeneity as a semi-supervised principle for feature selection using mutual information,"Frederico Coelho, Antonio Padua Braga, Michel Verleysen","In this work the principle of homogeneity between labels and data clusters is exploited in order to develop a semi-supervised Feature Selection method. This principle will permit the use of cluster information to improve the estimation of feature relevance in order to increase selection performance. Mutual Information is used in a Forward-Backward search process, on this filter aproach, in order to evaluate the relevance of each feature to the data distribution and the existent labels, in a context of few labeled and many unlabeled instances.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-68.pdf
2012,On the Potential Inadequacy of Mutual Information for Feature Selection,"Benoît Frénay, Gauthier Doquire, Michel Verleysen","Despite its popularity as a relevance criterion for feature selection, the mutual information can sometimes be inadequate for this task. Indeed, it is commonly accepted that a set of features maximising the mutual information with the target vector leads to a lower probability of misclassification. However, this assumption is in general not true. Justifications and illustrations of this fact are given in this paper.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-120.pdf
2012,How regular is neuronal activity?,"Lubomir Kostal, Petr Lansky, Ondrej Pokora","We propose and investigate two information-based measures of statistical dispersion  of neuronal firing: the entropy-based dispersion and Fisher information-based dispersion. The measures are compared with the standard deviation.  Although the standard deviation is used routinely, we show, that it is not well suited to quantify some aspects of dispersion that are often expected intuitively, such as the degree of randomness. The proposed dispersion measures are not entirely independent, although each describes the firing regularity from a different point of view.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-12.pdf
2012,Relevance learning for time series inspection,"Andrej Gisbrecht, Dusan Sovilj, Barbara Hammer, Amaury Lendasse","By means of local neighborhood regression and time windows, the generative  topographic mapping (GTM) allows to predict and visually inspect time series data. GTM itself, however, is  fully unsupervised.  In this contribution, we propose an extension of relevance learning to time series  regression with GTM.  This way, the metric automatically adapts according to the relevant time  lags resulting in a  sparser representation, improved accuracy, and smoother visualization of the data.",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-188.pdf
2012,Dissimilarity Clustering by Hierarchical Multi-Level Refinement,"Brieuc Conan-Guez, Fabrice Rossi",We introduce in this paper a new way of optimizing the natural extension of   the quantization error using in k-means clustering to dissimilarity   data. The proposed method is based on hierarchical clustering analysis   combined with multi-level heuristic refinement. The method is   computationally efficient and achieves better quantisation errors than the   relational k-means.,Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-132.pdf
2012,A Discussion on Parallelization Schemes for Stochastic Vector Quantization Algorithms,"Matthieu Durut, Benoit Patra, Fabrice Rossi","This paper studies parallelization schemes for stochastic Vector Quantization algorithms in order to obtain time speed-ups using distributed resources. We show that the most intuitive parallelization scheme does not lead to better performances than the sequential algorithm. Another distributed scheme is therefore introduced which obtains the expected speed-ups. Then, it is improved to fit implementation on distributed architectures where communications are slow and inter-machines synchronization too costly. The schemes are tested with simulated distributed architectures and, for the last one, with Microsoft Windows Azure platform obtaining speed-ups up to $32$ VMs.",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-127.pdf
2012,modularity-based clustering for network-constrained trajectories,"Mohamed Khalil El Mahrsi, Fabrice Rossi",We present a novel clustering approach for moving object trajectories that are constrained by an underlying road network. The approach builds a similarity graph based on these trajectories then uses modularity-optimization hiearchical graph clustering to regroup trajectories with similar profiles. Our experimental study shows the superiority of the proposed approach over classic hierarchical clustering and gives a brief insight to visualization of the clustering results.,Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-107.pdf
2012,Modified Conn-Index for the evaluation of fuzzy clusterings,"Tina Geweniger, Marika Kästner, Mandy Lange, Thomas Villmann","We propose an extension of the Conn-Index to evaluate fuzzy cluster solutions obtained from fuzzy prototype vector quantization, whereas the original Conn-Index was designed for crisp vector quantization models. The fuzzy index explicitly takes the fuzzy assignments resulting from fuzzy vector quantization into account. This avoids the information loss which would occur if the original crisp index is applied to fuzzy solutions.",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-22.pdf
2012,Curves clustering with approximation of the density of functional random variables,"Julien Jacques, Cristian Preda",Model-based clustering for functional data is considered. An alternative to model-based clustering using the functional principal components is proposed by approximating the density of functional random variables. The EM algorithm is used for parameter estimation and the maximum a posteriori rule provides the clusters. Real data application illustrate the interest of the proposed methodology.,Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-30.pdf
2012,gNBXe -- a Reconfigurable Neuroprocessor for Various Types of Self-Organizing Maps,"Jan Lachmair, Erzsebet Merenyi, Mario Porrmann, Ulrich Rückert","In this paper we present the FPGA-based hardware accelerator gNBXe for  emulation of classical Self-Organizing Maps (SOMs) and Conscience SOM (CSOM) in a multi-FPGA environment. After discussing how the CSOM is mapped to a resource-efficient digital hardware implementation, we present how the modular system architecture can be flexibly adapted to various application datasets. The hardware costs and scalability of a multi-FPGA based accelerator using Xilinx Virtex2 and Virtex4 FPGAs are discussed. Compared to a state-of-the-art multi-core PC, a speedup of 9.1 is achieved for a CSOM with 4,840 neurons and 196 synaptic weights.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-161.pdf
2012,A hybrid CMOS/memristive nanoelectronic circuit for programming synaptic weights,"Arne Heittmann, Tobias G. Noll","In this paper a hybrid circuit is presented which comprises nanoelectronic resistive switches based on the electrochemical memory effect (ECM) as well as devices from a standard 40nm-CMOS process. A closed ECM device model, which is based on device physics, was used for simulations allowing for a precise prediction of the expected I-V characteristics. The device is used as a non-volatile and/or programmable synapse in a neuromorphic architecture. Expected performance figures are derived such as write time as well as robustness with regard to variations of supply voltage and timing errors. The results show that ECM cells are prospective devices for hybrid neuromorphic systems.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-146.pdf
2012,Implementation Issues of Kohonen Self-Organizing Map Realized on FPGA,"Rafal Dlugosz, Marta Kolasa, Michal Szulc, Witold Pedrycz, Pierre-Andre Farine","Presented are the investigations showing an impact of the length of data signals in hardware implemented Kohonen Self-Organizing Maps (SOM) on the quality of the learning process. The aim of this work was to determine the allowable reduction of the number of bits in particular signals that does not deteriorate the network behavior. The efficiency of the learning process has been quantified by using the quantization error. The results obtained for the SOM realized on Field Programmable Gate Array (FPGA), as well as by means of the software model of the SOM show that the smallest allowable resolution (expressed in bits) of the weight signals equals seven, while the minimal bit length of the neighborhood signal ranges from 3 to 6 (depending on the map topology). For such values and properly selected values of other parameters the learning process remains undisturbed. Reducing the number of bits has an influence on the number of neurons that can be synthesized on a single FPGA device.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-137.pdf
2012,Hardware accelerated real time classification of hyperspectral imaging data for coffee sorting,"Andreas Backhaus, Jan Lachmair, Ulrich Rückert, Udo Seiffert",Hyperspectral imaging has been proven to be a viable tool for automated food inspection that is non-invasive and on-line capable. In this contribution a hardware implemented Self-Organizing Feature Map with Conscience (C-SOM) is presented that is capable of on-line adaptation and recall in order to learn to classify green coffee varieties as well as coffee of different roast stages. The C-SOM showed favourable results in some datasets compared to a number of classical supervised neural network classifiers. The massive parallel neural hardware architecture allows for constant processing times at different map sizes.,Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-110.pdf
2012,Parallelization of Deep Networks,"Michele De Filippo De Grazia, Ivilin Stoianov, Marco Zorzi","Learning multiple levels of feature detectors in Deep Belief Networks is a promising approach both for neuro-cognitive modeling and for practical applications, but it comes at the cost of high computational requirements. Here we propose a method for the parallelization of unsupervised generative learning in deep networks based on distributing training data among multiple computational nodes in a cluster. We show that this approach almost linearly reduces the training time with very limited cost on performance.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-71.pdf
2012,Low-Power Manhattan Distance Calculation Circuit for Self-Organizing Neural Networks Implemented in the CMOS Technology,"Rafal Dlugosz, Tomasz Talaska, Witold Pedrycz, Pierre-Andre Farine","The paper presents an analog, current-mode circuit that calculates a distance between the neuron weights vectors W and the input learning patterns X. The circuit can be used as a component of different self-organizing neural networks (NN) implemented at the transistor level in the CMOS technology. In Self-Organizing Maps (SOM) as well as in NNs using the Neural Gas or the Winner Takes All (WTA) learning algorithms, to calculate a distance between the X and the W vectors, the same circuit can be used that makes the proposed circuit a universal solution. Earlier detailed simulations carried out by means of the software model of the WTA NN and the Kohonen SOM showed that using both the Euclidean (L2) and the Manhattan (L1) distance measures leads to similar learning results. For this reason, the L1 measure has been implemented, as in this case the circuit is much simpler than in the L2 case, resulting in very low chip area and low power dissipation. This enables including even large NNs in miniaturized portable devices, such as sensors in Wireless Sensor Networks (WSN) or Wireless Body Area Networks (WBAN).",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-54.pdf
2012,A GPU-accelerated algorithm for self-organizing maps in a distributed environment,"Peter Wittek, Sándor Darányi","In this paper we introduce a MapReduce-based implementation of self-organizing maps that performs compute-bound operations on distributed GPUs. The kernels are optimized to ensure coalesced memory access and effective use of shared memory. We have performed extensive tests of our algorithms on a cluster of eight nodes with two NVidia Tesla M2050 attached to each, and we achieve a 10x speedup for self-organizing maps over a distributed CPU algorithm.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-35.pdf
2012,Towards biologically realistic multi-compartment neuron model emulation in analog VLSI,"Sebastian Millner, Andreas Hartel, Johannes Schemmel, Karlheinz Meier","We present a new concept for multi-compartment emulation on neuromorphic hardware based on the BrainScaleS wafer-scale system. The implementation features complex dendrite routing capabilities, realistic scaling of compartmental parameters and active spike propagation. Simulations proof the circuit’s capability of reproducing passive dendritic properties of a model from literature.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-44.pdf
2012,Parallel neural hardware: the time is right,"Ulrich Rückert, Erzsebet Merenyi","It seems obvious that the massively parallel computations inherent in artificial neural networks (ANNs) can only be realized by massively parallel hardware. However, the vast majority of the many ANN applications simulate their ANNs on sequential computers which, in turn, are not resource-efficient. The increasing availability of parallel standard hardware such as FPGAs, graphics processors, and multi-core processors offers new scopes and challenges in respect to resource-efficiency and real-time applications of ANNs. Within this paper we will discuss some key issues for parallel ANN implementation on these standard devices compared to special purpose ANN implementations.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-8.pdf
2012,Using event-based metric for event-based neural network weight adjustment,"Thierry Vieville, Rodrigo Salas, Bruno Cessac","The problem of adjusting the parameters of an event-based network model is addressed here at the programmatic level.   Considering temporal processing, the goal is to adjust the network units weights so that the outcoming events correspond to what is desired.   The present work proposes a way to adapt, in the deterministic and discrete case, usual alignment metrics in order to derive suitable adjustment rules.   At the numerical level, the stability and unbiasness of the method is verified.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-82.pdf
2012,Recurrent Neural State Estimation in Domains with Long-Term Dependencies,"Siegmund Duell, Lina Weichbrodt, Alexander Hans, Steffen Udluft","This paper presents a state estimation approach for reinforcement learning (RL) of a partially observable Markov decision process. It is based on a special recurrent neural network architecture, the Markov decision process extraction network with shortcuts (MPEN-S). In contrast to previous work regarding this topic, we address the problem of long-term dependencies, which cause major problems in many real-world applications. The architecture is designed to model the reward-relevant dynamics of an environment and is capable to condense large sets of continuous observables to a compact Markovian state representation. The resulting estimate can be used as input for RL methods that assume the underlying system to be a Markov decision process. Although the approach was developed with RL in mind, it is also useful for general prediction tasks.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-174.pdf
2012,Manifold-based non-parametric learning of action-value functions,"Hunor Jakab, Lehel Csato","Finding good approximations to state-action value functions is a central problem in model-free on-line reinforcement learning. The use of non-parametric function approximators enables us to simultaneously  represent model and confidence. Q functions are often discontinuous and we present a novel Gaussian process (GP) kernel function to cope with this problem. We use a manifold-based distance measure in our kernels, the manifold being induced by the graph structure extracted from data. Using on-line learning, the graph formation is parallel with the main algorithm. This results in a compact and efficient graph structure, eliminates the need for predefined basis functions  and improves the accuracy of estimated value functions, as tested on simulated robotic control tasks.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-179.pdf
2012,Fast calibration of hand movements-based interface for arm exoskeleton control,"Hugo Martin, Sylvain Chevallier, Eric Monacelli","Several muscular degenerative diseases alter motor abilities of large muscles but spare smaller muscles, e.g. keeping hand motor skills relatively unaffected while upper limbs ones are altered. Thus, hand movements could be be used to control an arm exoskeleton for rehabilitation and assistive purpose. Using an infra-red sensors (IR) based interface for the exoskeleton control, this paper describes the learning part of the system, endowing the system with a fast online calibration and adaptation abilities. This learning component shows good results and have been succesfully implemented on the real system.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-102.pdf
2012,A discrete/rhythmic pattern generating RNN,"Tim Waegeman, Francis Wyffels, Benjamin Schrauwen","Biological research supports the concept that advanced motion emerges from modular building blocks, which generate both rhythmical and discrete patterns. Inspired by these ideas, roboticists try to implement such building blocks using different techniques. In this paper, we show how to build such module by using a recurrent neural network (RNN) to encapsulate both discrete and rhythmical motion patterns into a single network. We evaluate the proposed system on a planar robotic manipulator. For training, we record several handwriting motions by back driving the robot manipulator. Finally, we demonstrate the ability to learn multiple motions (even discrete and rhythmic) and evaluate the pattern generation robustness in the presence of perturbations.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-90.pdf
2012,Complex Valued Artificial Recurrent Neural Network as a Novel Approach to Model the Perceptual Binding Problem,"Alexey Minin, Alois Knoll, Hans-Georg Zimmermann","The brain is constantly faced with the task of grouping together features of objects that it perceives, in order to arrive at a coherent representation of these objects. Such features are, for example, shape, motion, color, depth, but also other aspects of perception. There is experimental evidence and a large body of theoretical work that supports the hypothesis that brains solve this so-called “binding” problem by synchronizing the temporal firing patterns in neuronal assemblies, with neurons that are sensitive to different features. According to this hypothesis, temporal correlations between neuronal impulses represent the fact that different perceived features have to be associated with one and the same object.   In this paper we suggest a new model for solving the binding problem by introduc-ing complex-valued recurrent networks. These networks can represent sinusoidal oscillations and their phase, i.e., they can model the binding problem of neuronal assemblies by adjusting the relative phase of the oscillations of different feature detectors. As feature examples, we use color and shape – but the network would also function with any combination of other features.        The suggested network architecture performs image generalization but can also be used as an image memory. The information about object color is represented in the phase of the network weights, while the spatial distribution of the neurons codes represent the object’s shape. We will show that the architecture can generalize ob-ject shapes and recognize object color with very low computational overhead.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-24.pdf
2012,intrinsic plasticity via natural gradient descent,"Klaus Neumann, Jochen J. Steil","This paper introduces the natural gradient for intrinsic plasticity, which tunes a neuron’s activation function such that its output distribution becomes exponentially distributed. The information-geometric properties of the intrinsic plasticity potential are analyzed and the improved learning dynamics when using the natural gradient are evaluated for a variety of input distributions. The applied measure for evaluation is the relative geodesic length of the respective path in parameter space.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-15.pdf
2012,Regularized Committee of Extreme Learning Machine for Regression Problems,"Pablo Escandell-Montero, José M. Martínez-Martínez, Emilio Soria-Olivas, Josep Guimerá-Tomás, Marcelino Martínez-Sober, Antonio J. Serrano-López",Extreme learning machine (ELM) is an efficient learning algorithm for single-hidden layer feedforward networks (SLFN). This paper proposes the combination of ELM networks using a regularized committee. Simulations on many real-world regression data sets have demonstrated that this algorithm generally outperforms the original ELM algorithm.,Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-26.pdf
2012,Distributed learning via Diffusion adaptation with application to ensemble learning,"Zaid Towfic, Jianshu Chen, Ali Sayed","We examine the problem of learning a set of parameters from a distributed dataset. We assume the datasets are collected by agents over a distributed ad-hoc network, and that the communication of the actual raw data is prohibitive due to either privacy constraints or communication constraints. We propose a distributed algorithm for online learning that is proved to guarantee a bounded excess risk and the bound can be made arbitrary small for sufficiently small step-sizes. We apply our  framework to the expert advice problem where nodes learn the weights for the trained experts distributively.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-141.pdf
2012,Introducing diversity among the models of multi-label classification ensemble,"Lena Chekina, Lior Rokach, Bracha Shapira","A number of ensemble algorithms for solving multi-label classification problems have been proposed in recent years. Diversity among the base learners is known to be important for constructing a good ensemble. In this paper we define a method for introducing diversity among the base learners of one of the previously presented multi-label ensemble classifiers. An empirical comparison on 10 datasets demonstrates that model diversity leads to an improvement in prediction accuracy in 80% of the evaluated cases. Additionally, in most cases the proposed ""diverse"" ensemble method outperforms other multi-label ensembles as well.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-121.pdf
2012,On the Independence of the Individual Predictions in Parallel Randomized Ensembles,"Daniel Hernández-Lobato, Gonzalo Martínez-Muñoz, Alberto Suárez","In randomized parallel ensembles the class label predictions for a particular instance by different ensemble classifiers are independent random variables. Taking advantage of this independence we design a statistical test to identify instances near the decision borders, which are difficult to classify because of their proximity to these borders. For these instances, the performance of the ensemble is poor and approaches random guessing. The validity of this analysis and the usefulness of the statistical test proposed are illustrated in several real-world classification problems.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-19.pdf
2012,An Exploration of Research Directions in Machine Ensemble Theory and Applications,"Anibal Figueiras-Vidal, Lior Rokach","A concise overview of the fundamentals and the main types of machine ensembles serves to propose a structured perspective for the papers that are included in this special session. The subsequent brief discussion of the works, emphasizing their principal contributions, permits an extraction of a series of suggestions for further research in the fruitful area of ensemble learning.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-9.pdf
2012,Discriminant functional gene groups identification with machine learning and prior knowledge,"Grzegorz Zycinski, Margherita Squillario, Annalisa Barla, Tiziana Sanavia, Alessandro Verri, Barbara Di Camillo","In computational biology, the analysis of high-throughput data poses several issues on the reliability, reproducibility and interpretability of the results. It has been suggested that one reason for these inconsistencies may be that in complex diseases, such as cancer, multiple genes belonging to one or more physiological pathways are associated with the outcomes. Thus, a possible approach to improve list interpretability is to integrate biological information from genomic databases in the learning process. Here we propose SVS, a machine learning based pipeline that incorporates domain biological knowledge a priori to structure the data matrix before the feature selection and classification phases. The pipeline is completed by a final step of semantic clustering and visualization. The clustering phase provides further interpretability of the results, allowing the identification of their biological meaning. To prove the efficacy of this procedure we analyzed a public dataset on prostate cancer.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-167.pdf
2012,Similarity networks for heterogeneous data,"Lluís Belanche, Jerónimo Hernández","A two-layer neural network is developed in which the neuron model computes a user-defined similarity function between inputs and weights. The neuron model is formed by the composition of an adapted logistic function with the mean of the partial input-weight similarities. The model is capable of dealing directly with variables of potentially different nature (continuous, ordinal, categorical); there is also provision for missing values. The network is trained using a fast two-stage procedure and involves the setting of only one parameter. In our experiments, the network achieves slightly superior performance on a set of challenging problems with respect to both RBF nets and RBF-kernel SVMs.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-148.pdf
2012,Integration of Structural Expert Knowledge about Classes for Classification Using the Fuzzy Supervised Neural Gas,"Marika Kästner, Wieland Hermann, Thomas Villmann","In this paper we describe a methodology how structural expert knowledge about class relations can be integrated in classification schemes, if these models judge class dissimilarities using an unary class coding scheme. In particular, we suggest for those models to incorporate these informations into the class dissimilarity measure.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-57.pdf
2012,Cartogram representation of the batch-SOM magnification factor,"Alessandra Tosi, Alfredo Vellido","Model interpretability is a problem of knowledge extraction from the patterns found in raw data. One key source of knowledge is information visualization, which can help us to gain insights into a problem through graphical representations and metaphors. Nonlinear dimensionality reduction techniques can provide flexible visual insight, but the locally varying representation distortion they produce makes interpretation far from intuitive. In this paper, we define a cartogram method, based on techniques of geographic representation, that allows reintroducing this distortion, measured as a magnification factor, in the visual maps of the batch-SOM model. It does so while preserving the topological continuity of the representation.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-29.pdf
2012,extended visualization method for classification trees,"José M. Martínez-Martínez, Pablo Escandell-Montero, Emilio Soria-Olivas, José D. Martín-Guerrero, Juan Gómez-Sanchis, Joan Vila-Francés","Classification tree analysis is one of the main techniques used in Data Mining, and nowadays there is a lack of a visualization method that support this tool. Therefore, graphical procedures can be developed in order to help simplify interpretation and to obtain a better understanding. This paper proposes a method for representing the input data distribution for each class presented in each terminal node. For this purpose, the new visualization method Sectors on Sectors (SonS), proposed in [1], is used. The methodology is tested in two real data sets.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-28.pdf
2012,Constructing similarity networks using the Fisher information metric,"Héctor Ruiz, Sandra Ortega, Ian Jarman, José D. Martín-Guerrero, Paulo Lisboa","The Fisher information metric defines a Riemannian space where distances reflect similarity with respect to a given probability distribution. This metric can be used during the process of building a relational network, resulting in a structure that is informed about the similarity criterion. Furthermore, the relational nature of this network allows for an intuitive interpretation of the data through their location within the network and the way it relates to the most representative cases or prototypes.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-169.pdf
2012,Unmixing Hyperspectral Images with Fuzzy Supervised Self-Organizing Maps,"Thomas Villmann, Erzsebet Merenyi, William H. Farrand","We propose a powerful alternative to customary linear spectral unmixing, with a new neural model, which achieves locally linear but globally non-linear unmixing. This enables unmixing with respect to a large number of endmembers, while traditional linear unmixing is limited to a handful of endmembers.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-162.pdf
2012,Visualizing the quality of dimensionality reduction,"Bassam Mokbel, Wouter Lueks, Andrej Gisbrecht, Michael Biehl, Barbara Hammer","Many different evaluation measures for dimensionality reduction  can be summarized based on the co-ranking framework  [Lee and Verleysen, 2009].  Here, we extend this framework in two ways: (i) we show that the current parameterization of the quality shows unpredictable behavior, even in simple settings, and we propose a different parameterization which yields more intuitive results; (ii) we propose how to link the quality to point-wise quality measures which can directly be integrated into the visualization.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-99.pdf
2012,Interval coded scoring systems for survival analysis,"Vanya Van Belle, Sabine Van Huffel, Johan Suykens, Stephen Boyd","Black-box mathematical models are powerful tools in classi- fication and regression problems. Thanks to the use of (unknown) transformations of the inputs, the outcome can be estimated, improving performance in comparison to standard statistical models. A disadvantage of these complex models however, is their lack of interpretability. This work illustrates how advanced methods can be made interpretable. Using constant B-spline kernel functions and sparsity constraints, interval coded scoring models for survival analysis are presented.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-36.pdf
2012,Making machine learning models interpretable,"Alfredo Vellido, José D. Martín-Guerrero, Paulo Lisboa","Data of different levels of complexity and of ever growing diversity of characteristics are the raw materials that machine learning practitioners try to model using their wide palette of methods and tools. The obtained models are meant to be a synthetic representation of the available, observed data that captures some of their intrinsic regularities or patterns. Therefore, the use of machine learning techniques for data analysis can be understood as a problem of pattern recognition or, more informally, of knowledge discovery and data mining. There exists a gap, though, between data modeling and knowledge extraction. Models, depending on the machine learning techniques employed, can be described in diverse ways but, in order to consider that some knowledge has been achieved from their description, we must take into account the human cognitive factor that any knowledge extraction process entails. These models as such can be rendered powerless unless they can be interpreted, and the process of human interpretation follows rules that go well beyond technical prowess. For this reason, interpretability is a paramount quality that machine learning methods should aim to achieve if they are to be applied in practice. This paper is a brief introduction to the special session on interpretable models in machine learning, organized as part of the 20th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. It includes a discussion on the several works accepted for the session, with an overview of the context of wider research on interpretability of machine learning models.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-7.pdf
2012,Incremental feature building and classification for image segmentation,"Guillaume Bernard, Michel Verleysen, John Lee","Image segmentation problems can be solved with classification algorithms. However, their use is limited to features derived from intensities of pixels or patches. Features such as contiguity of two regions cannot be considered without prior knowledge of one of the two class labels. Instead of stacking various classification algorithms, we describe an incremental scheme with a KNN classifier that works in a space where feature relevance is progressively updated. Feature relevance can smoothly vary from total ignorance to absolute certainty. Experiments on artificial images demonstrate the capabilities of this incremental scheme.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-185.pdf
2012,Learning Object-Class Segmentation with Convolutional Neural Networks,"Hannes Schulz, Sven Behnke","After successes at image classification, segmentation is the next step towards image understanding for neural networks. We propose a  convolutional network architecture that includes innovative elements,   such as multiple output maps, suitable loss functions, supervised pretraining, multiscale inputs,   reused outputs, and pairwise class location filters.   Experiments on three data sets show that our method performs on par with current in computer vision methods with regards to accuracy and exceeds them in speed.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-160.pdf
2012,texture classification based on symbolic data analysis,"Carlos de Almeida, Renata Souza, Ana Lucia Candeias",This article presents a hybrid approach for texture-based image classification using the gray-level co-occurrence matrices (GLCM) and a new Fuzzy Kohonen Clustering Network for Symbolic Interval Data (IFKCN). The GLCM matrices extracted from an image database are processed to create the training data set using IFKCN algorithm. The IFKCN organizes and extracts prototypes from processed GLCM matrices. The experimental results demonstrate that the proposed method is encouraging with an average successful rate of 97.39%.,Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-124.pdf
2012,Application of Dynamic Time Warping on Kalman Filtering Framework for Abnormal ECG Filtering,"Mohammad Niknazar, Bertrand Rivet, Christian Jutten","Existing nonlinear Bayesian filtering frameworks serve as an effective tool for the model-based filtering of noisy ECG recordings. However, since these methods are based on linear phase assumption, for some heart defects where abnormal waves only appear in certain cycles of the ECG, they are unable to simultaneously filter the normal and abnormal ECG segments. In this paper, a new method based on Dynamic Time Warping (DTW), which benefits information of all channels for nonlinear phase state calculation is presented. Results on real and synthetic data show that the new method can be successfully applied for filtering normal and abnormal ECG segments simultaneously.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-171.pdf
2012,Hidden Markov models for time series of counts with excess zeros,"Madalina Olteanu, James Ridgway","Integer-valued time series are often modeled with Markov models or hidden Markov models (HMM). However, when the series represents count data it is often subject to excess zeros. In this case, usual distributions such as binomial or Poisson are unable to estimate the zero mass correctly. In order to overcome this issue, we introduce  zero-inflated distributions in the hidden Markov model. The empirical results on simulated and real data show good convergence properties, while excess zeros are better estimated than with classical HMM.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-187.pdf
2012,Combined scattering for rotation invariant texture analysis,"Laurent Sifre, Stéphane Mallat","This paper introduces a combined scattering representation for texture classification, which is invariant to rotations and stable to de- formations. A combined scattering is computed with two nested cascades of wavelet transforms and complex modulus, along spatial and rotation variables. Results are compared with state-of-the-art algorithms, with a K-nearest neighbor classifier.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-47.pdf
2012,Semi-Supervised Neural Gas for Adaptive Brain-Computer Interfaces,"Hannes Riechmann, Andrea Finke","Non-stationarity is inherent in EEG data. We propose a concept for an adaptive brain computer interface (BCI) that adapts a classifier to the changes in EEG data. It combines labeled and unlabeled data acquired during normal operation of the system. The classifier is based on Fuzzy Neural Gas (FNG), a prototype-based classifier. Based on four data sets we show that retraining the classifier significantly increases classification accuracy. Our approach smoothly adapts to the session-to-session variations in the data.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-140.pdf
2012,The error-related potential and BCIs,"Sandra Rousseau, Christian Jutten, Marco Congedo","The error-related potential is an event-related potential triggered by errors. Recently it has been the subject of many attentions notably for its possible use in BCI systems. Since it is linked to error occurrence, it could be used in the design of control loop to build more robust systems. In this paper we studied the characteristics of the error potential and present how it could be used for BCI systems improvement.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-46.pdf
2012,Automatic selection of the number of spatial filters for motor-imagery BCI,"Yuan Yang, Sylvain Chevallier, Joe Wiart, Isabelle BLOCH","Common spatial pattern (CSP) is widely used for constructing spatial filters to extract features for motor-imagery-based BCI. One main parameter in CSP-based classification is the number of spatial filters used. An automatic method relying on Rayleigh quotient is presented to estimate its optimal value for each subject. Based on an existing dataset, we validate the contribution of the proposed method through a study of the effect of this parameter on the classification performance. The evaluation on testing data shows that the estimated subject-specific optimal values yield better performances than the recommended value in the literature.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-40.pdf
2012,One Class SVM and Canonical Correlation Analysis increase performance in a c-VEP based Brain-Computer Interface (BCI),"Martin Spüler, Wolfgang Rosenstiel, Martin Bogdan","The goal of a Brain-Computer Interface (BCI) is to enable communication by pure brain activity without the need for muscle control. Recently BCIs based on code-modulated visual evoked potentials (c-VEPs) have shown great potential to establish high-performance communication. In this paper we present two new methods to improve classification in a c-VEP BCI. Canonical correlation analysis can be used to build an optimal spatial filter for detection of c-VEPs, while the use of a one class support vector machine (OCSVM) makes the BCI more robust in terms of artefacts and thus increases performance. We show both methods to increase performance in an offline analysis on data from 8 subjects. As a proof of concept both methods are tested online with one subject, who achieved an average performance of 133 bit/min, which is higher than any other bitrate reported so far for a non-invasive BCI.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-18.pdf
2012,BCI Signal Classification using a Riemannian-based kernel,"Alexandre Barachant, Stephane Bonnet, Marco Congedo, Christian Jutten","The use of spatial covariance matrix as feature is investigated for motor imagery EEG-based classification. A new kernel is derived by establishing a connection with the Riemannian geometry  of symmetric positive definite matrices. Different kernels are tested, in combination with support vector machines, on  a past BCI competition dataset. We demonstrate that this new approach outperforms  significantly state of the art results without the need for spatial filtering.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-130.pdf
2012,Learning visuo-motor coordination for pointing without depth calculation,"Ananda Freire, Andre Lemme, Jochen J. Steil, Guilherme Barreto","Pointing refers to orienting a hand, arm, head or body towards an object and is possible without calculating the object's depth and 3D position. We show that pointing can be learned as holistic direct mapping from an object's pixel coordinates in the visual field to joint angles, which define pose and orientation of a human or robot. To this  aim, we record real world and noisy training images together with corresponding robot pointing postures for the humanoid robot iCub. We then learn and comparatively evaluate pointing with an multi-layer perceptron, an extrem learning machine and a reservoir network, but also demonstrate that  learning fails at reconstructing the depth of trained objects.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-173.pdf
2012,Real time drunkenness analysis in a realistic car simulation,"Audrey Robinel, Didier Puzenat","This paper describes a blood alcohol content estimation method for car driver, based on a comportment analysis performed within a realistic simulation. An artificial neural network learns how to estimate subject's blood alcohol content. Low-level recording of user actions on the steering wheel and pedals are used to feed a multilayer perceptron, and a breathalyzer is used to build the learning examples set (desired output). Results are compared with a successful previous work based on a simple video game and demonstrate the ``complexity scalability'' of the approach.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-177.pdf
2012,Learning geometric combinations of Gaussian kernels with alternating Quasi-Newton algorithm,"David Picard, Nicolas Thome, Matthieu Cord, Alain Rakotomamonjy","We propose a novel algorithm for learning a geometric combination of   Gaussian kernel jointly with a SVM classifier. This problem is the   product counterpart of MKL, with restriction to Gaussian   kernels. Our algorithm finds a local solution by alternating a   Quasi-Newton gradient descent over the kernels and a classical SVM   solver over the instances. We show promising results on well known   data sets which suggest the soundness of the approach.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-80.pdf
2012,Effects of noise-reduction on neural function approximation,"Frank-Florian Steege, Volker Stephan, Horst-Michael Groß",Noise disturbance in training data prevents a good approximation of a function by neural networks. To achieve better approximation results we combine neural networks with noise reduction algorithms. We compare different methods to distinguish between samples with high noise level (outliers) in a dataset and samples with low noise level. Drawbacks of common outlier detection approaches are analysed and a new approach is defined which increases the quality of network function approximations. We demonstrate the effects of noise reduction on artificial datasets and on real data from the process control domain.,Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-65.pdf
2012,Posterior regularization and attribute assessment of under-determined linear mappings,"Marc Strickert, Michael Seifert","Linear mappings are omnipresent in data processing analysis ranging from regression to distance metric learning. The interpretation of coefficients from under-determined mappings raises an unexpected challenge when the original modeling goal does not impose regularization. Therefore, a general posterior regularization strategy is presented for inducing unique results, and additional sensitivity analysis enables attribute assessment for facilitating model interpretation. An application to infrared spectra reflects data smoothness and indicates improved generalization.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-4.pdf
2012,Quantile regression with multilayer perceptrons.,"joseph Rynkiewicz, Solohaja-Faniaha Dimby","We consider nonlinear quantile regression involving multilayer perceptrons (MLP). In this paper we investigate the asymptotic behavior of quantile regression in a general framework. First by allowing possibly non-identifiable regression models like MLP's with redudant hidden units, then by relaxing the conditions on the density of the noise. We present an universal bound for the overfitting of such models under weak assumptions. The main application of this bound is to give a hint about determining the true architecture of the MLP quantile regression model.  As an illustration, we use this theoretical result to propose and compare effective criteria to find the true architecture of quantile MLP regression model.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-159.pdf
2012,Structural Risk Minimization and Rademacher Complexity for Regression,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella","The Structural Risk Minimization principle allows estimating the generalization ability of a learned hypothesis by measuring the complexity of the entire hypothesis class. Two of the most recent and effective complexity measures are the Rademacher Complexity and the Maximal Discrepancy, which have been applied to the derivation of generalization bounds for kernel classifiers. In this work, we extend their application to the regression framework.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-61.pdf
2012,Supervised learning to tune simulated annealing for in silico protein structure prediction,"Alejandro Marcos Alvarez, Francis Maes, Louis Wehenkel",Simulated annealing is a widely used stochastic optimization algorithm whose efficiency essentially depends on the  proposal distribution used to generate the next search state at each step. We propose to adapt this distribution to a family of parametric optimization problems by using supervised machine learning on a sample of search states derived from a set of typical runs of the algorithm over this family. We apply this idea in the context of in silico protein structure prediction.,Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-51.pdf
2012,Short Term Memory Quantifications in Input-Driven Linear Dynamical Systems,"Tino Peter, Ali Rodan","We investigate the relation between two quantitative measures characterizing short term memory in input driven dynamical systems, namely the short term memory capacity (MC)  and the Fisher memory curve (FMC). We show that under some assumptions, the two quantities can be interpreted as squared `Mahanabolis' norms of images of the input vector under the system's dynamics and that even though MC  and FMC map the memory structure of the system from two quite different perspectives, they can be linked by a close relation.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-189.pdf
2012,Process Mining in Non-Stationary Environments,"Phil Weber, Tino Peter, Behzad Bordbar","Process Mining uses event logs to discover and analyse business processes, typically assumed to be static.  However as businesses adapt to change, processes can be expected to change.  Since one application of process mining is ensuring conformance to prescribed processes or rules, timely detection of change is important.  We consider process mining in such non-stationary environments and show that using a probabilistic view of processes, timely and confident detection of change is possible.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-123.pdf
2012,Constructive Reservoir Computation with Output Feedbacks for Structured Domains,"Claudio Gallicchio, Alessio Micheli, Giulio Visco","We introduce a novel constructive algorithm which progressively builds the architecture of GraphESN, which generalizes Reservoir Computing to learning in graph domains. Exploiting output feedback signals in a forward fashion in such construction, allows us to introduce supervision in the reservoir encoding process. The potentiality of the proposed approach  is experimentally assessed on real-world tasks from  Toxicology.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-89.pdf
2012,Input-Output Hidden Markov Models for trees,"Davide Bacciu, Alessio Micheli, Alessandro Sperduti",The paper introduces an input-driven generative model for tree-structured data that extends the bottom-up hidden tree Markov model with non-homogenous transition and emission probabilities. The advantage of introducing an input-driven dynamics in structured-data processing is experimentally investigated. The results of this preliminary analysis suggest that input-driven models can capture more discriminative structural information than non-input-driven approaches.,Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-45.pdf
2012,Balancing of neural contributions for multi-modal hidden state association,"Christian Emmerich, R. Felix Reinhart, Jochen J. Steil",We generalize the formulation of associative reservoir computing networks to multiple input modalities and demonstrate applications in image and audio processing scenarios.Robust association with reservoir networks requires to cope with potential error amplification of output feedback dynamics and to handle differently sized input and output modalities. We propose a dendritic neuron model in combination with a modified reservoir regularization technique to address both issues.,Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-175.pdf
2012,Simple reservoirs with chain topology based on a single time-delay nonlinear node,"José Manuel Gutiérrez, D. San-Martín, Silvia Ortin, Luis Pesquera",A physical scheme based on a single nonlinear dynamical system with delayed feedback has been recently proposed for Reservoir Computing (RC) [1]. In this paper we present a computational implementation of this idea using a simple chain topology with properties derived from its physical counterpart (e.g. the reservoir is defined by two tunable parameters related to feedback- and input-strength terms). An application to time series prediction is described and a comparison with other standard reservoir computing methods is given.,Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-142.pdf
2012,Theory of Input Driven Dynamical Systems,"Manjunath Gandhi, Tino Peter, Herbert Jaeger","Most dynamic models of interest in machine learning, robotics, AI or cognitive science are nonautonomous and input-driven. In the last few years number of important innovations have occurred in mathemati- cal research on nonautonomous systems. In understanding the long term behavior of nonautonomous systems, the notion of an attractor is fun- damental. With a time varying input, it turns out that for a notion of an attractor to be useful, the attractor cannot a single subset, but must be conceived as a sequence of sets varying with time as well. The aim of this tutorial is to illuminate useful notions of attractors of nonautonomous systems, and also introduce some newly emerging concepts of dynamical systems theory which are particularly relevant for input driven systems.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-6.pdf
2013,Hierarchical and multiscale Mean Shift segmentation of population grids,"Johanna Baro, Etienne Côme, Patrice Aknin, Olivier Bonin",The Mean Shift (MS) algorithm allows to identify clusters that are catchment areas of modes of a probability density function (pdf). We propose to use a multiscale and hierarchical implementation of the algorithm to process grid data of population and identify automatically urban centers and their dependant sub-centers through scales. The multiscale structure is obtained by increasing iteratively the bandwidth of the kernel used to define the pdf on which the MS algorithm works. This will induce a hierarchical structure over clusters since modes will merge together when the bandwidth parameter increases.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-69.pdf
2013,Delaunay simplices pruning based clustering,"Octavio Razafindramanana, Gilles Venturini",We introduce in this paper a new clustering method using the Delaunay triangulation of a set of points as an input. The proposed method is based on pruning away extra simplices of a triangulation accord- ing to a local heterogeneity measure which we introduce. This measure provides good clustering results as it yields to better inter-cluster simplices detection. Our introduced measure is evaluated on 2-D shape data set.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-89.pdf
2013,Clustering the Vélib’ origin-destinations flows by means of Poisson mixture models,"Andry Randriamanamihaga, Etienne Côme, Latifa Oukhellou, Gérard Govaert","Studies based on human mobility, including Bycicle Sharing System (BSS) traffic analysis, has expanded over the past few years. They give insight of the underlying urban phenomena linked to city dynamics. This paper presents a generative count-series model using Poisson mixtures to automatically analyse and find temporal-based partitions over the Vélib’ origin-destination (OD) flow-data. Such an approach may provide latent factors that reveal how regions of different usage interact over the time. More generally, the proposed methodology can be used to cluster edges of temporal valued graph with respect to their temporal profiles",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-95.pdf
2013,Content-based image retrieval with hierarchical Gaussian Process bandits with self-organizing maps,"Ksenia Konyushkova, Dorota Glowacka",A content-based image retrieval system based on relevance feedback is proposed. The system relies on an interactive search paradigm where at each round a user is presented with k images and selects the one closest to her target. The approach based on hierarchical Gaussian Process bandits is used to trade exploration and exploitation in presenting the images in each round. Experimental results show that the new approach compares favorably with previous work.,Machine Learning for multimedia applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-111.pdf
2013,Learning associative spatiotemporal features with non-negative sparse coding,"Thomas Guthier, Steve Gerges, Volker Willert, Julian Eggert","Motion features based on optical flow are very powerful in tasks such as the recognition of human actions or gestures. Usually, they are combined with gradient information to form a set of spatiotemporal features. However, humans can recognize gestures and actions and thus derive the implied motion out of static images alone. We model this associative recognition within a learned hierarchy of non-negative sparse coding layers. In the first stages, topology preserving gradient and motion features are processed separately. Afterwards, they are projected onto a combined inner representation, that is learned during the training phase. We show, that during recognition the learned, combined representation improves the recognition of human actions, even in the absence of explicit motion information.",Machine Learning for multimedia applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-109.pdf
2013,Machine Learning and Content-Based Multimedia Retrieval,"Philippe-Henri Gosselin, David Picard",,Machine Learning for multimedia applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-13.pdf
2013,Dynamic Placement with Connectivity for RSNs based on a Primal-Dual Neural Network,"Rafael Lima Carvalho, Lunlong Zhong, Felipe França, Félix Mora-Camino","The present work deals with the dynamic placement of a set of pursuers and a set of relay devices so that the mean distance to a set of moving targets is minimized along a given period of time. The relay devices are here in charge of maintaining the communication between the pursuers. Moving targets, relay devices and pursuers are limited in their movements from one period to the next. The periodic problem is formulated as a linear quadratic programming model and a primal-dual neural network is proposed to solve from one stage to the next the current optimization problem. Moreover, the feasibility of the proposed approach is displayed through a numerical example.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-62.pdf
2013,Binary particle swarm optimisation with improved scaling behaviour,Denise Gorse,A boolean particle swarm optimisation (PSO) algorithm  is presented that builds on the strengths of earlier proposals but which by introducing a wholly random element into the search process shows greatly improved performance in higher dimensional search spaces in comparison also to the binary PSO algorithm of Kennedy and Eberhart.,"Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-91.pdf
2013,Least-squares temporal difference learning based on extreme learning machine,"Pablo Escandell-Montero, José M. Martínez-Martínez, José D. Martín-Guerrero, Emilio Soria-Olivas, Juan Gómez-Sanchis","This paper proposes a least-squares temporal difference (LSTD) algorithm based on extreme learning machine that uses a single-hidden layer feedforward network to approximate the value function. While LSTD is typically combined with local function approximators, the proposed approach uses a global approximator that allows better scalability properties. The results of the experiments carried out on four Markov decision processes show the usefulness of the proposed approach.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-2.pdf
2013,Hierarchical Reinforcement Learning for Robot Navigation,"Bastian Bischoff, Duy Nguyen-Tuong, I-Hsuan Lee, Felix Streichert, Alois Knoll","For complex tasks, such as manipulation and robot navigation, reinforcement learning (RL) is well-known to be difficult due to the curse of dimensionality. To overcome this complexity and making RL feasible, hierarchical RL (HRL) has been suggested. The basic idea of HRL is to divide the original task into elementary subtasks, which can be learned using RL. In this paper, we propose a HRL architecture for learning robot's movements, e.g. robot navigation. The proposed HRL consists of two layers: (i) movement planning and (ii) movement execution. In the planning layer, e.g. generating navigation trajectories, discrete RL is employed while using movement primitives. Given the movement planning and corresponding primitives, the policy for the movement execution can be learned in the second layer using continuous RL. The proposed approach is implemented and evaluated on a mobile robot platform for a navigation task.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-19.pdf
2013,An empirical analysis of reinforcement learning using design of experiments,"Christopher Gatti, Mark Embrechts, Jonathan Linton","This study uses a design of experiments approach to understand the behavior of a neural network to learn the mountain car domain using reinforcement learning. A large experiment is first performed to characterize the probability of empirical convergence based on three reinforcement learning algorithm parameters (&#955;, &#947;, &#949;), and a logistic regression model is fitted to this data. A detailed analysis of a subset of the parameter space finds that, upon convergence, algorithm parameters have significant effects on the convergence speed and mean performance, though performance differences are minimal.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-68.pdf
2013,Ensembles for Continuous Actions in Reinforcement Learning,"Siegmund Duell, Steffen Udluft","Data efficient reinforcement learning methods allow to optimize controllers (policies) for complex technical systems in a data-driven manner. Still there is the risk that, when running such a policy on the real system, it performs considerably worse than expected. For policies with discrete actions it has been shown, that this risk can be reduced considerably, when, instead of just using a single policy, that by chance might be inferior, a whole ensemble of policies is used to select the final policy by an aggregation like,  e.g., majority voting. In this paper we extend the applicability of the ensemble approach  to vector-valued, continuous actions.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-93.pdf
2013,Learning control under uncertainty: A probabilistic Value-Iteration approach,"Bastian Bischoff, Duy Nguyen-Tuong, Heiner Markert, Alois Knoll","In this paper, we introduce a probabilistic version of the well-studied Value-Iteration approach, i.e. Probabilistic Value-Iteration (PVI). The PVI approach can handle continuous states and actions in an episodic Reinforcement Learning (RL) setting, while using Gaussian Processes to model the state uncertainties. We further show, how the approach can be efficiently realized making it suitable for learning with large data. The proposed PVI is evaluated on a benchmark problem, as well as on a real robot for learning a control task. A comparison of PVI with two state-of-the-art RL algorithms shows that the proposed approach is competitive in performance while being efficient in learning.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-26.pdf
2013,Locally Weighted Least Squares Temporal Difference Learning,"Matthew Howard, Yoshihiko Nakamura","This paper introduces locally weighted temporal difference learning for evaluation of a class of policies whose value function is non-linear in the state. Least squares temporal difference learning is used for training local models according to a distance metric in state-space. Empirical evaluations are reported demonstrating learning performance on a number of strongly non-linear value functions, without the need for prior knowledge of features or a specific functional form.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-73.pdf
2013,Fast online adaptivity with policy gradient: example of the BCI ``P300''-speller,"Emmanuel DaucÃ©, Timothée Proix, Liva Ralaivola","We tackle the problem of reward-based online learning of multiclass classifiers and consider a policy gradient ascent to solve this problem in the linear case.  We apply it to the online adaptation of an EEG-based ``P300''-speller. When applied from scratch, a robust classifier is obtained in few steps.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-100.pdf
2013,Bayesian non parametric inference of discrete valued networks,"Laetitia Nouedoui, Pierre Latouche","We present a non parametric bayesian inference strategy to automatically infer the number of classes during the clustering process of a discrete valued random network. Our methodology is related to the Dirichlet process mixture models and inference is performed using a Blocked Gibbs sampling procedure. Using simulated data, we show that our approach improves over competitive variational inference clustering methods.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-87.pdf
2013,Read classification for next generation sequencing,"James Hogan, Peter Holland, Alex Holloway, Robert Petit, Timothy Read","Next Generation Sequencing (NGS) technologies have revolutionised molecular biology, allowing clinical sequencing to become a matter of routine, and a method of considerable diagnostic value. NGS data sets consist of short sequence reads obtained from the machine, given context and meaning through downstream assembly and annotation. For these techniques to operate successfully, it is necessary to ensure that the collected reads are consistent with the species or species group assumed, and not corrupted in some way. The bacterium Staphylococcus aureus is a common infectious agent in hospitals, causing severe and potentially life-threatening infections, with some strains exhibiting antibiotic resistance. In this paper, we apply a Support Vector Machine classifier to the important problem of distinguishing S. aureus sequencing projects from a range of alternatives, including other pathogens and closely related Staphylococci. Using a representation based on sequence  k-mers of various lengths, we are able to make the correct prediction in over 95% of cases, while reporting almost no false positives, and implicating features with important functional associations in the bacterium.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-115.pdf
2013,support vector machine-based aproach for multi-labelers problems,"Santiago Murillo Rendón, Diego Peluffo-Ordoñez, Germán Castellanos-Dominguez","We propose a first approach to quantify the panelist's labeling generalizing a soft-margin support vector machine classifier to multi-label analysis. Such variation consist of formulating the optimization problem within a quadratic programming framework instead of using a heuristic search algorithm. Our method's outcomes are penalty or relevance values associated with each panelist, pointing out a well performing labeler when lower is its value. For experiments, two databases are considered. Firstly, the well-known Iris with multiple artificial labels. Secondly, a multi-label speech database for detecting hypernasality. Obtained penalty factors are compared with both standard supervised and non-supervised measurements. The results are promising to asses the concordance among panelists taking into account the structure of data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-118.pdf
2013,Optimization by Variational Bounding,"Joe Staines, David Barber",We discuss a general technique that forms a differentiable bound on non-differentiable objective functions by bounding the function optimum by its expectation with respect to a parametric variational distribution.  We describe sufficient conditions for the bound to be convex with respect to the variational parameters.  As  example applications we consider variants of sparse linear regression and SVM training.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-65.pdf
2013,A Learning Machine with a Bit-Based Hypothesis Space,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella","We propose in this paper a bit-based classifier, picked from an hypothesis space described accordingly to sparsity and locality principles: the complexity of the corresponding space of functions is controlled through the number of bits needed to represent it, so that it will include the classifiers that will be most likely chosen by the learning procedure. Through an introductory example, we show how the number of bits, the sparsity of the representation and the local definition approach affect the complexity of the space of functions, where the final classifier is selected from.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-75.pdf
2013,A dictionary learning based method for aCGH segmentation,"Salvatore Masecchia, Saverio Salzo, Annalisa Barla, Alessandro Verri","The starting point of our work is to devise a model for segmentation of aCGH data.  We propose an optimization method based on dictionary learning  and regularization and we compare it with a state-of-the-art approach, presenting our experimental results on synthetic data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-104.pdf
2013,A competitive approach for human activity recognition on smartphones,"Attila Reiss, Gustaf Hendeby, Didier Stricker","This paper describes a competitive approach developed for an activity recognition challenge. The competition was defined on a new and publicly available dataset of human activities, recorded with smartphone sensors. This work investigates different feature sets for the activity recognition task of the competition. Moreover, the focus is also on the introduction of a new, confidence-based boosting algorithm called ConfAdaBoost.M1. Results show that the new classification method outperforms commonly used classifiers, uch as decision trees or AdaBoost.M1.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-122.pdf
2013,A sparse kernelized matrix learning vector quantization model for human activity recognition,"Marika Kästner, Marc Strickert, Thomas Villmann","The contribution describes the application of the 'Computational Intelligence Group' from the University of Applied Sciences Mittweida (Germany) to the ESANN'2013 Competition on 'Human Activity Recognition (HAR)' using Android-OS smartphone sensor signals. We applied a kernel variant of learning vector quantization with metric adaptation with only one prototype vector per class (sparse model). This model obtains very good accuracies and additionally provides class correlation information. Further, the model allows an optimized class visualization.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-123.pdf
2013,A One-Vs-One Classifier Ensemble With Majority Voting for Activity Recognition,"Bernardino Romera-Paredes, M. S. H. Aung, Nadia Bianchi-Berthouze","A solution for the automated recognition of six full body motion activities is proposed. This problem is posed by the release of the Activity Recognition database and forms the basis for a classification competition at the European Symposium on Artificial Neural Networks 2013. The data-set consists of motion characteristics of thirty subjects captured using a single device delivering accelerometric and gyroscopic data. Included in the released data-set are 561 processed features in both the time and frequency domains. The proposed recognition framework consists of an ensemble of linear support vector machines each trained to discriminate a single motion activity against another single activity. A majority voting rule is used to determine the final outcome. For comparison, a six ""winner take all"" multiclass support vector machine ensemble and k-  Nearest Neighbour models were also implemented. Results show that the system accuracy for the one versus one ensemble is 96.4% for the competition test set. Similarly, the multiclass SVM ensemble and k-Nearest Neighbour returned accuracies of 93.7% and 90.6% respectively. The outcomes of the one versus one method were submitted to the competition resulting in the winning solution.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-124.pdf
2013,A Public Domain Dataset for Human Activity Recognition using Smartphones,"Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge Luis Reyes-Ortiz","Human-centered computing is an emerging research field that aims to understand human behavior and integrate users and their social context with computer systems. One of the most recent, challenging and appealing applications in this framework consists in sensing human body motion using smartphones to gather context information about people actions. In this context, we describe in this work an Activity Recognition database, built from the recordings of 30 subjects doing Activities of Daily Living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors, which is released to public domain on a well-known on-line repository. Results, obtained on the dataset by exploiting a multiclass Support Vector Machine (SVM), are also acknowledged.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-84.pdf
2013,Multi-user Blood Alcohol Content estimation in a realistic simulator using Artificial Neural Networks and Support Vector Machines,"Audrey Robinel, Didier Puzenat","We instrumented a realistic car simulator to extract low level data related to the driver's use of the vehicle controls. After proceeding these data, we generated features that were fed to a Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM) in order to determine weather the driver was over a blood alcohol content threshold, and even estimate the BAC value. We discuss the results of the prototype using the MLP and SVM (or SVR) algorithms in both single-user and multi-user context.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-88.pdf
2013,Sensor Positioning for Activity Recognition Using Multiple Accelerometer-Based Sensors,"Lei Gao, Alan Bourke, John Nelson","Physical activity has a positive impact on people’s well-being and it can decrease the occurrence of chronic disease. To date, there has been a substantial amount of research studies, which focus on activity recognition using accelerometer and gyroscope-based sensors. However, the sensor position and the sensor combination, which have the best recognition performance with minimum sensor number, have not been investigated enough. This study proposes a method to adopt multiple accelerometer-based sensors on different body locations to investigate this problem. The dataset was collected in a study conducted by the eCAALYX project. Eight subjects were recruited to perform eight normal scripted activities in different life scenarios, and each repeated three times. Thus a total of 192 activities were recorded. The collected dataset was used to find the most suitable sensor-subset for recognizing Activities of Daily Living (ADLs).",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-76.pdf
2013,Long term analysis of daily activities in smart home,"Labiba Gillani Fahad, Arshad Ali, Muttukrishnan Rajarajan","In this paper, we propose the approach to monitor a change in the daily routine of a person using the long term analysis of the activities performed in a smart home. The proposed approach comprises of two steps; first is the activity recognition, in which the newly detected activity instances are labeled using the learning model probabilistic neural network. In the second step, the daily routine of the occupant in the smart home is analyzed by exploiting the group of activities of a day performed over a period of time. We apply K-means clustering to separate the normal routine to unusual and suspected routines. The proposed approach is validated on a publicly available dataset.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-71.pdf
2013,A heterogeneous database for movement knowledge extraction in Parkinson’s disease,"Albert Samà, Carlos Pérez-López, Daniel Rodríguez-Martín, Joan Cabestany, Juan Manuel Moreno-Arostegui, Alejandro Rodríguez-Molinero","This paper presents the design and methodology used to create a heterogeneous database for knowledge movement extraction in Parkinson's Disease. This database is being constructed as part of REMPARK project and is composed of movement measurements acquired from inertial sensors, standard medical scales as Unified Parkinson's Disease Rating Scale, and other information obtained from 90 Parkinson's Disease patients. The signals obtained will be used to create movement disorder detection algorithms using supervised learning techniques. The different sources of information and the need of labelled data pose many challenges which the methodology described in this paper addresses. Some preliminary data obtained are presented.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-57.pdf
2013,Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,"Jorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra, Davide Anguita, Joan Cabestany, Andreu Català","The rise of ubiquitous computing systems in our environment is engendering a strong need of novel approaches of human-computer interaction. Either for extending the existing range of possibilities and services available to people or for providing assistance the ones with limited conditions. Human Activity Recognition (HAR) is playing a central role in this task by offering the input for the development of more interactive and cognitive environments. This has motivated the organization of the ESANN 2013 Special Session in Human Activity and Motion Disorder Recognition and the execution of a competition in HAR. Here, a compilation of the most recent proposals in the area are exposed accompanied by the results of the contest calling for innovative approaches to recognize activities of daily living (ADL) from a recently published data set.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-11.pdf
2013,Handling missing values in kernel methods with application to microbiology data,"Vladimer Kobayashi, Tomas Aluja, Lluís Belanche","We discuss several approaches that make possible for kernel methods to deal with missing values. The first two are extended kernels able to handle missing values without data preprocessing methods. Another two methods are derived from a sophisticated multiple imputation technique involving logistic regression as local model learner. The performance of these approaches is compared using a binary data set that arises typically in microbiology (the microbial source tracking problem). Our results show that the kernel extensions demonstrate competitive performance in comparison with multiple imputation in terms of predictive  accuracy. However, these results are achieved with a simpler and deterministic methodology and entail a much lower computational effort.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-105.pdf
2013,Multi-scale Support Vector Machine Optimization by Kernel Target-Alignment,"María Pérez-Ortiz, Pedro A. Gutiérrez, Javier Sánchez-Monedero, César Hervás-Martínez","The problem considered is the optimization of a multi-scale kernel, where a different width is chosen for each feature. This idea has been barely studied in the literature, and through the use of evolutionary or gradient descent approaches, which explicitly train the learning machine and thereby incur high computacional cost. To cope with this limitation, the problem is explored by making use of an analytical methodology known as kernel-target alignment, where the kernel is optimized by aligning it to the so-called ideal kernel matrix. The results show that the proposal leads to better performance and simpler models at limited computational cost when applying the binary Support Vector Machine (SVM) paradigm.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-21.pdf
2013,Visualizing dependencies of spectral features using mutual information,"Andrej Gisbrecht, Yoan Miché, Barbara Hammer, Amaury Lendasse","The curse of dimensionality leads to problems in machine learning when dealing with  high dimensionality. This aspect is particularly pronounced if intrinsically infinite dimensionality is faced such as present for spectral or functional data. Feature selection constitutes one  possibility to deal with this problem. Often, it relies on mutual information as an evaluation tool for the feature importance, however, it might be overlaid by intrinsic biases such as a high correlation of neighbored function values for functional data. In this paper we propose to asses feature correlations of spectral data by an overlay of prior dependencies due to the functional nature and its similarity as measured by mutual information, enabling a quick overall assessment of the relationships between features. By integrating the Nyström approximation technique, the usually time consuming step to compute all  pairwise mutual informations can be reduced to only linear complexity in the number of features.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-86.pdf
2013,Visualizing pay-per-view television customers churn using cartograms and flow maps,"David L. García, Angela Nebot, Alfredo Vellido","Media companies aggressively compete for their share of the pay-per-view television market. Such share can only be kept or improved by avoiding customer defection, or churn. The analysis of customers' data should provide insight into customers' behavior over time and help preventing churn. Data visualization can be part of this analysis. Here, a database of pay-per-view television customers is visualized using a nonlinear manifold learning model. This visualization is enhanced through, first, the reintroduction of the local nonlinear distortion using a cartogram technique and, second, the visualization of customer migrations using flow maps. Both techniques are inspired by geographical representation.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-83.pdf
2013,ManiSonS: A New Visualization Tool for Manifold Clustering,"José M. Martínez-Martínez, Pablo Escandell-Montero, José D. Martín-Guerrero, Joan Vila-Francés, Emilio Soria-Olivas","Manifold learning is an important theme in machine learning. This paper proposes a new visualization approach to manifold clustering. The method is based on pie charts in order to obtain meaningful visualizations of the clustering results when applying a manifold technique. In addition to this, the proposed approach extracts all the existing relationships among the attributes of the different clusters and find the most important variables of the manifold in order to distinguish among the different clusters. The methodology is tested in one synthetic data set and one real data set. Achieved results show the suitability and usefulness of the proposed approach.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-44.pdf
2013,Robust cartogram visualization of outliers in manifold learning,"Alessandra Tosi, Alfredo Vellido","Most real data sets contain atypical observations, often referred to as outliers. Their presence may have a negative impact in data modeling using machine learning. This is particularly the case in data density estimation approaches. Manifold learning techniques provide low-dimensional data representations, often oriented towards visualization. The visualization provided by density estimation manifold learning methods can be compromised by the presence of outliers. Recently, a cartogram-based representation of model-generated distortion was presented for nonlinear dimensionality reduction. Here, we investigate the impact of outliers on this visualization when using manifold learning techniques that behave robustly in their presence.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-36.pdf
2013,Sparse approximations for kernel learning vector quantization,"Daniela Hofmann, Barbara Hammer","Various prototype based learning techniques have recently been extended to similarity data by means of kernelization. While state-of-the-art classification results can be achieved this way, kernelization loses one important property of prototype-based techniques: a representation of the solution in terms of few characteristic prototypes which can directly be inspected by experts. In this contribution, we introduce several different ways to obtain sparse representations for kernel learning vector quantization and compare its efficiency and performance in connection to the underlying data characteristics in diverse benchmark scenarios.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-63.pdf
2013,Learning regression models with guaranteed error bounds,Clemens Otte,"The combination of a symbolic regression model with a residual Gaussian Process is proposed for providing an interpretable model with improved accuracy.  While the learned symbolic model is highly interpretable the residual model usually is not.  However, by limiting the output of the residual model to a defined range a worst-case guarantee can be given in the sense that the maximal deviation from the symbolic model is always below a defined limit. When ranking the accuracy and interpretability of several different approaches on the SARCOS data benchmark the proposed combination yields the best result.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-3.pdf
2013,Research directions in interpretable machine learning models,"Vanya Van Belle, Paulo Lisboa",,Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-14.pdf
2013,Cost-sensitive cascade graph neural networks,"Van Tuc Nguyen, Ah Chung Tsoi, Markus Hagenbuchner","This paper introduces a novel cost sensitive approach to a cascade of Graph Neural Networks for learning from unbalanced data in the graph structured domain. The proposed method is shown to be very effective in addressing the un- desirable effects of unbalanced data distribution on learning systems. The proposed idea is based on a weighting mechanism which forces the network to encode mis- classified graphs (or nodes) more strongly. The idea is applied to Graph Neural Networks which are capable of encoding complex graph structured data. We evalu- ate the model through an application to a well known Web spam detection problem, and demonstrate that the general network performance is improved as a result.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-72.pdf
2013,WIPS: the WiSARD Indoor Positioning System,"D.O. Cardoso, J. Gama, Massimo De Gregorio, Felipe França, Maurizio Giordano, Priscila Lima","In this paper, we present a WiSARD-based system facing the problem of Indoor Positioning (IP) by taking advantage of pervasively available infrastructures (WiFi Access Points – AP). The goal is to develop a system to be used to position users in indoor environments, such as: museums, malls, factories, offshore platforms etc. Based on the fingerprint approach, we show how the proposed weightless neural system provides very good results in terms of performance and positioning resolution. Both the approach to the problem and the system will be presented through two correlated experiments.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-101.pdf
2013,B-bleaching: Agile Overtraining Avoidance in the WiSARD Weightless Neural Classifier,"Danilo Carvalho, Hugo Carneiro, Felipe França, Priscila Lima","Weightless neural networks constitute a still not fully explored Machine Learning paradigm, even if its first model, WiSARD, is considered. Bleaching, an improvement on WiSARD's learning mechanism was recently proposed in order to avoid overtraining. Although presenting very good results in different application domains, the original sequential bleaching and its confidence modulation mechanisms still offer room for improvement. This paper presents a new variation of the bleaching mechanism and compares the three strategies performance on a complex domain, that of multilingual grammatical categorization. Experiments considered both number of iterations and accuracy. Results show that binary bleaching allows for a considerable improvement to number of iterations whilst not introducing loss of accuracy.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-22.pdf
2013,Border sensitive fuzzy vector quantization in semi-supervised learning,"Tina Geweniger, Marika Kästner, Thomas Villmann","We propose a semi-supervised fuzzy vector quantization method for the classification of incompletely labeled data. Since information contained within the structure of the data set should not be neglected, our method considers the whole data set during the learning process. In difference to known methods our approach uses neighborhood cooperativeness for stable prototype learning known from Neural Gas. Further improvement of the classification accuracy is achieved by including class border sensitivity inspired by Support Vector Machines again improved by neighborhood learning.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-59.pdf
2013,Prior knowledge in an end-user trainable machine vision framework,"Klaas Dijkstra, Walter Jansen, Jaap van de Loosdrecht","The increasing popularity of machine vision based solutions in common applications calls for a structured approach for incorporating the end user's domain knowledge and limiting the solution's dependency on expert knowledge. We propose a framework facilitating optimized classification results and will show several approaches in which prior knowledge of the solution is captured in a neural network or in a geometric pattern matcher. The methodology is applied to disc print reading for antibiotic susceptibility testing by disc diffusion. Results show that increased prior knowledge produces better classifiers, and that more thorough optimization is required to increase the accuracy of classifiers which use less prior knowledge.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-15.pdf
2013,DYNG: Dynamic Online Growing Neural Gas for stream data classification,"Oliver Beyer, Philipp Cimiano","In this paper we introduce Dynamic Online Growing Neural Gas (DYNG), a novel online stream data classification approach based on Online Growing Neural Gas (OGNG). DYNG exploits labelled data during processing to adapt the network structure as well as the speed of growth of the network to the requirements of the classification task. It thus speeds up learning for new classes/labels and dampens growth of the subnetwork representing the class once the class error converges. We show that this strategy is beneficial in life-long learning settings involving non-stationary data, giving DYNG an increased performance in highly non-stationary phases compared to OGNG.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-61.pdf
2013,Efficient prediction of x-axis intercepts of discrete impedance spectra,"Thomas Schmid, Dorothee GÃ¼nzel, Martin Bogdan","In impedance spectroscopy of epithelial cell layers, it is a common task to extrapolate discrete two-dimensional plots in order to determine electrical properties associated with axis intercepts. Here, we investigate how implicit properties of such curves can be used to predict the x-axis intercept where explicitly determined properties fail to do so. We perform feature extraction, algorithmic feature ranking and dimension reduction on model impedance spectra derived from a tissue-equivalent electric circuit. Selected feature subsets are assessed by training arti&#64257;cial neural networks to predict the intercept. Results show that subsets of three or less implicit features provide a reasonable basis for predictions.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-116.pdf
2013,Feature Selection for Footwear Shape Estimation,"Fernando Mateo, Mónica Millán-Giraldo, Juan J. Carrasco, Enrique Montiel, Jose A. Bernabeu, José D. Martín-Guerrero","This study proposes feature selection techniques to obtain a set of significant foot anthropometric measurements that can assist custumers in the choice of footwear size and width. The results given by a number of methods are averaged to provide a reliable set of features. Several machine learning methods are used to evaluate the classification (for the width) and regression (for the size) accuracies before and after feature selection. The results prove the benefits of carrying out feature selection, especially for the shoe width.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-52.pdf
2013,A distributed wrapper approach for feature selection,"Veronica Bolon-Canedo, Noelia Sánchez-Maroño, Amparo Alonso-Betanzos","In recent years, distributed learning has been the focus of much attention due to the proliferation of big databases, usually distributed. In this context, machine learning can take advantage of feature selection methods to deal with these datasets of high dimensionality. However, the great majority of current feature selection algorithms are designed for centralized learning. To confront the problem of distributed feature selection, in this paper we propose a distributed wrapper approach. In this manner, the learning accuracy can be improved, as well as obtaining a reduction in the memory requirements and execution time. Four representative datasets were selected to test the approach, paving the way to its application over extremely-high data which prevented previously the use of wrapper approaches.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-41.pdf
2013,Random Brains: An ensemble method for feature selection with neural networks,"Mark Embrechts, Jonathan Linton, Jorge Santos","The purpose of this paper is to introduce and validate Random Brains, a novel artificial neural network based feature selection technique. Feature selection is widely used in high-dimensional data and it aims on removing irrelevant or redundant data, providing faster predictors without a significant decrease in model performance. Random Brains, inspired by Breiman’s Random Forests, are bagged ensembles of predictive neural network models that use randomly selected subsets of features. This paper validates Random Brains on several classification and regression benchmark data sets by comparing its performance to similar models with features selected based on sensitivity analysis.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-67.pdf
2013,Risk Estimation and Feature Selection,"Gauthier Doquire, Benoît Frénay, Michel Verleysen","For classification problems, the risk is often the criterion to be eventually minimised. It can thus naturally be used to assess the quality of feature subsets in feature selection. However, in practice, the probability of error is often unkwown and must be estimated. Also, mutual information is often used as a criterion to assess the quality of feature subsets, since it can be seen as an imperfect proxy for the risk and can be reliably estimated.  In this paper, two different ways to estimate the risk using the Kozachenko-Leonenko probability density estimator are proposed.  The resulting estimators are compared on feature selection problems with a mutual information estimator based on the same density estimator.  Along the line of our previous works, experiments show that using an estimator of either the risk or the mutual information give similar results.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-77.pdf
2013,GA-KDE-Bayes: an evolutionary wrapper method based on non-parametric density estimation applied to bioinformatics problems,"Maria Fernanda Wanderley, Vincent Gardeux, René Natowicz, Antônio Braga","This paper presents an evolutionary wrapper method for feature selection that uses a non-parametric density estimation method and a Bayesian Classifier. Non-parametric methods are a good alternative for scarce and sparse data, as in Bioinformatics problems, since they do not make any assumptions about its structure and all the information come from data itself. Results show that local modeling provides small and relevant subsets of features when comparing to results available on literature.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-117.pdf
2013,Unsupervised non-linear neural networks capture aspects of floral choice behaviour,"Levente Orbán, Sylvain Chartier","Two unsupervised neural networks were tested to understand the extent to which they capture elements of bumblebees’ unlearned preferences towards flower-like visual properties. The networks, which are based on Independent Component Analysis and Feature-Extracting Bidirectional Associative Memory use images of test-patterns that are identical to ones used in behavioural studies. While both models show consistency with behavioural results, the ICA model matches behavioural results sub- stantially better in terms of image reconstruction quality of radial and concentric patterns, and foliage background. Both models generated a novel prediction of an interaction between spatial frequency and symmetry. These results are interpreted to support the hypothesis that flower displays are adapted to pollinators’ information processing constraints.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-6.pdf
2013,Machine Learning Techniques for Short-Term  Electric Power Demand Prediction,"Fernando Mateo, Juan J. Carrasco, Mónica Millán-Giraldo, Abderrahim Sellami, Pablo Escandell-Montero, José M. Martínez-Martínez, Emilio Soria-Olivas","Since several years ago, power consumption forecast has attracted considerable attention from the scienti&#64257;c community. Although there exist several works that deal with this issue, it remains open. The good management of energy consumption in HVAC (Heating, Ventilation and Air Conditioning ) systems for large households and public buildings  may bene&#64257;t from a sustainable development in terms of economy and environmental preservation. In this paper, several Machine Learning techniques are evaluated and compared with a linear technique (Robust Multiple Linear Regression) and a naïve method. All methods have been applied to &#64257;ve buildings of the University of León (Spain), the results indicate nonlinear techniques outperform the linear one in most scenarios.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-45.pdf
2013,Dimension reduction for individual ica to decompose FMRI during real-world experiences: principal component analysis  vs. canonical correlation analysis,"Valeri Tsatsishvili, Fengyu Cong, Tuomas Puoliväli, Vinoo Alluri, Petri Toiviainen, Asoke K. Nandi, Elvira Brattico, Tapani Ristaniemi","Data analysis for functional magnetic resonance imaging collected during real-world experiences is critical. Independent component analysis (ICA) has been used to extract desired spatial maps. Before ICA, dimension reduction is used to separate the signal and the noise subspaces. Recently, in addition to the widely used Principal component analysis (PCA) and model order selection, canonical correlation analysis (CCA) has been exploited to find the correlated and uncorrelated subspaces between two datasets. This study compares CCA and PCA for dimension reduction for ICA to decompose very noisy fMRI elicited by natural and continuous music. We find that their performances are comparable.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-64.pdf
2013,Automatic Singular Spectrum Analysis for Time-Series Decomposition,"Andres Marino Alvarez-Meza, Carlos Daniel Acosta-Medina, Germán Castellanos-Dominguez","An automatic singular spectrum analysis - SSA based methodology is proposed to decompose and reconstruct time-series. We suggest a clustering based procedure to decompose the main dynamics of the input signal. A subset of orthogonal basis computed from the input are selected using a power based criterion. Then, the subset of basis are represented by a discrete fourier transform, to identify basis encoding similar data structures, which are employed to infer the hidden components of the signal. Our approach is tested over some synthetic and real-world datasets, showing that our algorithm is a good tool to interpret and decomposes time-series.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-48.pdf
2013,Non-Euclidean independent component analysis and Oja's learning,"Mandy Lange, Michael Biehl, Thomas Villmann","In the present contribution we tackle the problem of nonlinear independent component analysis by non-Euclidean Hebbian-like learning. Independent component analysis (ICA) and blind source separation originally were introduced as tools for the linear unmixing of the signals to detect the underlying sources. Hebbian methods became very popular and succesfully in this context. Many nonlinear ICA extensions are known. A promising strategy is the application of kernel mapping. Kernel mapping realizes an usually nonlinear but implicite data mapping of the data into a reproducing kernel Hilbert space. After that a linear demixing can be carried out there. However, explicit handling in this non-Euclidean kernel mapping space is impossible. We show in this paper an alternative using an isomorphic mapping space. In particular, we show that the idea of Hebbian-like learning of \emph{kernel }ICA can be transferred to this non-Euclidean space realizing an non-Euclidean ICA.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-42.pdf
2013,Novelty detection in image recognition using IRF Neural Networks properties,"Philippe Smagghe, Jean-Luc Buessler, Jean-Philippe Urban","Image Receptive Fields Neural Network (IRF-NN) is a variant of feedforward multi-layer perceptrons adapted to image recognition. It shows very fast training as well as robust and accurate results on supervised classification tasks. This paper presents another property of IRF-NN: responses of trained networks can be analysed to detect unknown images. Several discriminative and efficient novelty criteria are introduced and tested successfully on the ALOI image dataset. A combination of novelty detection and object recognition is illustrated with a robust, pose invariant application of multi-object localization in various backgrounds","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-60.pdf
2013,Activity Date Estimation in Timestamped Interaction Networks,"Fabrice Rossi, Pierre Latouche",We propose in this paper a new generative model for graphs that uses a latent space approach to explain timestamped interactions. The model is designed to provide global estimates of activity dates in historical networks where only the interaction dates between agents are known with reasonable precision. Experimental results show that the model provides better results than local averages in dense enough networks.,"Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-82.pdf
2013,Frequency-Dependent Peak-Over-Threshold algorithm for fault detection in the spectral domain,"Aurélien Hazan, Kurosh Madani","An original novelty detection algorithm in the Fourier domain, using extreme value theory (EVT) is considered in this article.   Periodograms may be considered as frequency-dependent random variables, and this can be taken into account when designing statistical tests. Frequency-Dependent Peak-Over-Threshold (FDPOT) puts special emphasis on the frequency dependence of extreme value statistics, thanks to Vector Generalized Additive Models (VGAM) estimation.  An application is discussed in the field of mechanical vibrations. It is first shown that performance increases compared to POT detection. Then FDPOT is compared to state-of-the-art algorithms such as KPCA.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-56.pdf
2013,A nuclear-norm based convex formulation for informed source separation,"Augustin Lefèvre, François Glineur, P.A. Absil","Abstract.	We study the problem of separating audio sources from a single linear mixture. The goal is to find a decomposition of the single channel spectrogram into a sum of individual contributions associated to a certain number of sources. In this paper, we consider an informed source separation problem in which the input spectrogram is partly annotated. We propose a convex formulation that relies on a nuclear norm penalty to induce low rank for the contributions. We show experimentally that solving this model with a simple subgradient method outperforms a previ- ously introduced nonnegative matrix factorization (NMF) technique, both in terms of source separation quality and computation time.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-112.pdf
2013,A new metric for dissimilarity data classification based on Support Vector Machines optimization,"Agata Manolova, Anne Guerin-Dugue","Dissimilarities are extremely useful in many real-world pattern classification problems, where the data resides in a complicated, complex space, and it can be very difficult, if not impossible, to find useful feature vector representations. In these cases a dissimilarity representation may be easier to come by. The goal of this work is to provide a new technique based on Support Vector Machines (SVM) optimization that can be a good alternative in terms of accuracy compared to known methods using dissimilarities such as k nearest neighbor classifier (kNN), prototype-based dissimilarity classifiers and distance kernel based SVM classifiers.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-107.pdf
2013,Evolutionary computation based system decomposition with neural networks,"Robert Kaltenhaeuser, Erik Schaffernicht, Frank-Florian Steege, Horst-Michael Gross","We present an evolutionary approach to divide a complex control system into smaller sub-systems with the help of neural networks. Thereto, measured channels are partitioned into several disjunct sets, representing possible sub-problems, while the networks are used to assess the quality of the resulting decomposition. We show that this approach is well suited to calculate correct decompositions of complex control systems. Furthermore, the obtained neural networks are used to predict important process factors with considerable better approximation quality than monolithic approaches that have to deal with all input channels in parallel.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-58.pdf
2013,Synthetic over-sampling in the empirical feature space,"María Pérez-Ortiz, Pedro A. Gutiérrez, César Hervás-Martínez","The imbalanced nature of some real-world data is one of the current challenges for machine learning, giving rise to different approaches to handling it. However, preprocessing methods operate in the original input space, presenting distortions when combined with the kernel classifiers, which make use of the feature space. This paper explores the notion of empirical feature space (a Euclidean space which is isomorphic to the feature space) to develop a kernel-based synthetic over-sampling technique, which maintains the main properties of the kernel mapping. The proposal achieves better results than the same oversampling method applied to the original input space.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-103.pdf
2013,A quotient basis kernel for the prediction of mortality in severe sepsis patients,"Vicent Ribas Ripoll, Enrique Romero, Juan Carlos Ruiz-Rodríguez, Alfredo Vellido","In this paper, we describe a novel kernel for multinomial distributions, namely the Quotient Basis Kernel (QBK), which is based on a suitable reparametrization of the input space through algebraic geometry and statistics. The QBK is used here for data transformation prior to classification in a medical problem concerning the prediction of mortality in patients suffering severe sepsis. This is a common clinical syndrome, often treated at the Intensive Care Unit (ICU) in a time-critical context. Mortality prediction results with Support Vector Machines using QBK compare favorably with those obtained using alternative kernels and standard clinical procedures.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-29.pdf
2013,Developments in kernel design,Lluís Belanche,,Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-10.pdf
2013,Forecasting Financial Markets with Classified Tactical Signals,"Patrick Kouontchou, Amaury Lendasse, Yoan Miché, Bertrand Maillet","The financial market dynamics can be characterized by macro-economic, micro-financial and market risk indicators, used as lead- ing indicators by market professionals. In this article, we propose a method to identify market states integrating two classification algorithms: a Robust Kohonen Self-Organising Maps one and a CART one. After studying the market’s states separation using the former, we use the latter to characterize the economic conditions over time and to compute the conditional probabilities of related market states.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-121.pdf
2013,Temperature Forecast in Buildings Using  Machine Learning Techniques,"Fernando Mateo, Juan J. Carrasco, Mónica Millán-Giraldo, Abderrahim Sellami, Pablo Escandell-Montero, José M. Martínez-Martínez, Emilio Soria-Olivas","Energy e&#64259;ciency in buildings requires having good prediction of the variables that de&#64257;ne the power consumption in the building. Temperature is the most relevant of these variables because it a&#64256;ects the operation of the cooling systems in summer and the heating systems in winter, while being also the main variable that de&#64257;nes comfort. This paper presents the application of classical methods of time series forecasting, such as Autoregressive (AR), Multiple Linear Regression (MLR) and Robust MLR (RMLR) models, along with others derived from more complex machine learning techniques, including Multilayer Perceptron with Non-linear Autoregressive Exogenous (MLP-NARX) and Extreme Learning Machine (ELM), to forecast temperature in buildings. The results obtained in the temperature prediction of several rooms of a building show the goodness  of machine learning methods as compared to traditional approaches.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-43.pdf
2013,Detection and quantification in real-time polymerase chain reaction,"Abou KEITA, Romain HERAULT, Colas CALBRIX, Stéphane Canu","The estimation of the concentration of an infectious agent in the environment is a key step to trigger an alert when there is a biological threat. This concentration can be obtained trough a quantitative polymerase chain reaction (qPCR). Nevertheless, standard real-time procedure do not address detection delay which is a main concern in alert triggering. Therefore, we propose a method based on Lasso regression and CUSUM change detection to accurately estimate the concentration while minimizing the detection delay. We compare our results with those found by a standard method (threshold method) and promising results are obtained.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-92.pdf
2013,Are Rosenblatt multilayer perceptrons more powerfull than sigmoidal multilayer perceptrons? From a counter example to a general result,Jose Fonseca,"In the eighties the problem of the lack of an efficient algorithm to train multilayer Rosenblatt perceptrons was solved by sigmoidal neural networks and backpropagation. But should we still try to find an efficient algorithm to train multilayer hardlimit neuronal networks, a task known as a NP-Complete problem? In this work we show that this would not be a waste of time by means of a counter example where a two layer Rosenblatt perceptron with 21 neurons showed much more computational power than a sigmoidal feedforward two layer neural network with 300 neurons trained by backpropagation for the same classification problem. We show why the synthesis of logical functions with threshold gates or hardlimit perceptrons is an active research area in VLSI design and nanotechnology and we review some of the methods to synthesize logical functions with a multilayer hardlimit perceptron and we propose the search for an efficient method to synthesize any classification problem with analogical inputs with a two layer hardlimit perceptron as a near future objective. Nevertheless we recognize that with hardlimit multilayer perceptrons we cannot approximate continuous functions as we can easily do with multilayer sigmoidal neural networks, with multilayer hardlimit perceptrons we can only solve any classification problem, as we plan to demonstrate in a near future.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-35.pdf
2013,Optimization of Gaussian process hyperparameters using Rprop,"Manuel Blum, Martin Riedmiller","Gaussian processes are a powerful tool for non-parametric regression. Training can be realized by maximizing the likelihood of the data given the model. We show that Rprop, a fast and accurate gradient-based optimization technique originally designed for neural network learning, can outperform more elaborate unconstrained optimization methods on real world data sets, where it is able to converge more quickly and reliably to the optimal solution.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-51.pdf
2013,Ensembles of genetically trained artificial neural networks for survival analysis,"Jonas Kalderstam, Patrik Edén, Mattias Ohlsson","We have developed a prognostic index model for survival data based on an ensemble of artificial neural networks that optimizes directly on the concordance index. Approximations of the c-index are avoided with the use of a genetic algorithm, which does not require gradient information. The model is compared with Cox proportional hazards (COX) and three support vector machine (SVM) models by Van Belle et al. on two clinical data sets, and only with COX on one artificial data set. Results indicate comparable performance to COX and SVM models on clinical data and superior performance compared to COX on non-linear data.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-79.pdf
2013,Neurally imprinted stable vector fields,"Andre Lemme, Klaus Neumann, Felix Reinhart, Jochen Steil","We present a novel learning scheme to imprint stable vector fields into Extreme Learning Machines (ELMs). The networks represent movements, where asymptotic stability is incorporated through constraints derived from a Lyapunov function. We show that our approach successfully performs stable and smooth point-to-point movements learned from human handwriting movements.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-98.pdf
2013,Decoding stimulation intensity from evoked ECoG activity using support vector regression,"Armin Walter, Georgios Naros, Martin Spüler, Alireza Gharabaghi, Wolfgang Rosenstiel, Martin Bogdan","One of the unsolved problems of the application of cortical stimulation for therapeutic means is the selection of optimal stimulation parameters. Using support vector regression, we demonstrate that the intensity of single pulse electrical stimulation can be decoded from the waveform of the evoked electrocorticographic (ECoG) activity, even if intensities used for training and testing of the regression model are disjoint. This was most effective when stimulation was applied directly over the motor cortex, less so for pre-motor and sensory cortex. Thus, if the optimal shape of the evoked neural response to stimulation is known, a regression model trained on the responses to a small set of stimulation intensities could be sufficient to determine the optimal stimulation intensity.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-81.pdf
2013,Network community detection with edge classifiers trained on LFR graphs,"Twan van Laarhoven, Elena Marchiori","A popular method for generating graphs with known community structure is the Lancichinetti-Fortunato-Radicchi (LFR) model. This paper investigates the use of LFR graphs as training data for learning classifiers that discriminates between edges that are 'within' a community and 'between' network communities. We trained linear edge-wise weighted support vector machine classifiers on LFR graphs generated with different amounts of mixing between communities. Results of a comparative experimental analysis show that a classifier trained on a graph with more mixing also work well when tested on LFR benchmark graphs generated using less mixing, while it achieves mixed performance on real-life networks, with a tendency towards finding many communities.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-33.pdf
2013,Normalized cuts clustering with prior knowledge and a pre-clustering stage,"Diego Peluffo-Ordoñez, Andrés Eduardo Castro-Ospina, Diego Chavez-Chamorro, Carlos Daniel Acosta-Medina, Germán Castellanos-Dominguez","Clustering is of interest in cases when data are not labeled enough and a prior training stage is unfeasible. In particular, spectral clustering based on graph partitioning is of interest to solve problems with highly non-linearly separable classes. However, spectral methods, such as the well-known normalized cuts, involve the computation of eigenvectors that is a highly time-consuming task in case of large data. In this work, we propose an alternative to solve the normalized cuts problem for clustering, achieving same results as conventional spectral methods but spending less processing time. Our method consists of a heuristic search to find the best cluster binary indicator matrix, in such a way that each pair of nodes with greater similarity value are first grouped and the remaining nodes are clustered following a heuristic algorithm to search into the similarity-based representation space. The proposed method is tested over a public domain image data set. Results show that our method reaches comparable results with a lower computational cost.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-90.pdf
2013,Linear spectral hashing,"Zalán Bodó, Lehel Csato","Spectral hashing assigns binary hash keys to data points. This is accomplished via thresholding the eigenvectors of the graph Laplacian and obtaining binary codewords. While calculation for inputs in the training set is straightforward, an intriguing and difficult problem is how to compute the hash codewords for unseen data. A second problem we address is the computational difficulties when using the Gaussian similarity measure in spectral hashing: for specific problems -- mainly the processing of large text databases -- we propose linear scalar products as similarity measures and analyze the performance of the algorithm. We implement the linear algorithm and provide an inductive -- generative -- formula  that leads to a prediction method similar to locality-sensitive hashing for a new data point. Experiments on document retrieval show promising results.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-113.pdf
2013,ONP-MF: An Orthogonal Nonnegative Matrix Factorization Algorithm with Application to Clustering,"Filippo Pompili, Nicolas Gillis, François Glineur, P.A. Absil","Given a nonnegative matrix M, the orthogonal nonnegative matrix factorization (ONMF) problem consists in finding a nonnegative matrix $U$ and an orthogonal nonnegative matrix V such that the product UV is as close as possible to M in the sense of the Frobenius norm. The importance of ONMF comes from its tight connection with data clustering. In this paper, we propose a new ONMF method, called ONP-MF, and we show that it outperforms other clustering methods (including ONMF-based methods) in terms of accuracy on several datasets in text clustering and hyperspectral unmixing.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-20.pdf
2013,Sensitivity to parameter and data variations in dimensionality reduction techniques,"Francisco J. García-Fernández, Michel Verleysen, John A. Lee, Ignacio Díaz","Dimensionality reduction techniques aim at representing high-dimensional data in a meaningful and lower dimensional space, improving the human comprehension and interpretation of data. In recent years, newer nonlinear techniques have been proposed in order to address the limitation of linear techniques. This paper presents a study of the stability of some of these dimensionality reduction techniques, analyzing their behavior under changes in the parameters and the data. The performances of these techniques are investigated on artificial datasets. The paper presents these results by identifying the weaknesses of each technique, and suggests some data-processing tasks to improve the stability.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-66.pdf
2013,Semi-Supervised Vector Quantization for proximity data,"Xibin Zhu, Frank-Michael Schleif, Barbara Hammer","Semi-supervised learning (SSL) is focused on learning from labeled and unlabeled data by incorporating structural and statistical information of the available unlabeled data. The amount of data is dramatically increasing, but few of them are fully labeled, due to cost and time constraints. Even more challenging are non-vectorial, so called proximity data, with data given by pairwise proximity values, like score-values in sequence alignments, having no regular vector-space representation. Only few methods  provide SSL for this data, limited to positive-semi-definite (psd) data. They also lack  interpretable models, which is a relevant aspect in life-sciences where most of these data are found. This paper provides a prototype based SSL approach for proximity data.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-38.pdf
2013,Multiple Kernel Self-Organizing Maps,"Madalina Olteanu, Nathalie Villa-Vialaneix, Christine Cierco-Ayrolles","In a number of real-life applications, the user is interested in analyzing several sources of information together: a graph together with additional information known on its nodes, numerical variables measured on individuals together with factors describing these individuals... The combination of all the sources of information can help him to better understand the dataset in its whole. The present article focuses on such an issue, by using self-organizing maps. Using a kernel version of the algorithm makes it possible to combine various types of information (graph, numerical values, factors, strings...) and to automatically find a good trade-off between all sources of data, but using an automated procedure to tune the data combination. This approach is illustrated on several examples.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-99.pdf
2013,Soft rank neighbor embeddings,"Marc Strickert, Kerstin Bunte","Correlation-based multidimensional scaling is proposed for  reconstructing pairwise dissimilarity or score relationships in a Euclidean space. Pearson correlation between pairs of objects in source and target space can be directly maximized by  gradient methods, while gradient optimization of Spearman rank correlation  profits from a numerically soft formulation introduced in this work. Scale and shift invariance properties of correlation help circumventing typical distance concentration problems.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-46.pdf
2013,Efficient VLSI Architecture for Spike Sorting Based on Generalized Hebbian Algorithm,"Wen-Jyi Hwang, Hao Chen","A novel hardware architecture for fast spike sorting is presented in this paper. The architecture is able to perform feature extraction based on the Generalized Hebbian Algorithm (GHA). The employment of GHA allows efficient computation of principal components for subsequent clustering and classification operations. The hardware implementations of GHA features high throughput, low power dissipation, and low area costs. The proposed architecture is implemented by Field Programmable Gate Array (FPGA). It is embedded in a System-On-Programmable-Chip(SOPC) platform for performance measurement. Experimental results show that the proposed architecture is an efficient spike sorting design for attaining low hardware resource utilization and high speed computation.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-5.pdf
2013,Percolation model of axon guidance,"Gaetano Liborio Aiello, Valentino Romano","In the developing brain neurons interconnect via the action of molecules that guide the axon to its targets, thus allowing the proper wiring scheme to emerge. It is not fully understood whether the underlying mechanism is wholly deterministic or not. The existence of “choice-points” and “decision-regions” suggest that options are available to the growth cone. The guidance mechanism is here simulated by equating the axonal trajectory to that of a trickle of ground water sipping through a bed of sand. Decision regions are implemented by assigning each site of the percolation lattice a set of probabilities ruling the possible moves.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-23.pdf
2013,Analysis of Synaptic Weight Distribution in an Izhikevich Network,"Li Guo, Zhijun Yang, Qingbao Zhu","Izhikevich network is a relatively new neuronal network, which consists of cortical spiking model neurons with axonal conduction delays and spike-timing-dependent plasticity (STDP) with hard bound adaptation. In this work, we use uniform and Gaussian distributions respectively to initialize the weights of all excitatory neurons. After the network undergoes a few minutes of STDP adaptation, we can see that the weights of all synapses in the network, for both initial weight distributions, form a bimodal distribution, and numerically the established distribution presents dynamic stability.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-27.pdf
2013,Automated operational states detection for drilling systems control in critical conditions,"Galina Veres, Zoheir Sabeur","Critical events in industrial drilling should be overcome by engineers while they maintain safety and achieve their operational drilling plans. Complex geophysical drilling requires maximum awareness of critical situations such as “Kicks”, “Fluid loss” or “Stuck pipe”. These may compromise safety and potentially halt operations with the need of staff evacuations from rigs rapidly. In this paper, a robust method for the detection of operational states is proposed. Specifically, Echo State Networks (ESNs) were benchmarked and tested rigorously despite of the challenging training datasets that exhibited imbalance problem issues. These issues were overcome and led to good ESNs performances.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-7.pdf
2013,Using Wikipedia with associative networks for document classification,"Niels Bloom, Mariet Theune, Franciska de Jong","We demonstrate a new technique for building associative networks based on Wikipedia, comparing them to WordNet-based associative networks that we used previously, finding the Wikipedia-based networks to perform better at document classification. Additionally, we compare the performance of associative networks to various other text classication techniques using the Reuters-21578 dataset, establishing that associative networks can achieve comparable results.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-106.pdf
2013,Perceptual grouping through competition in coupled oscillator networks,"Martin Meier, Robert Haschke, Helge Ritter","In this paper we present a novel approach to model perceptual grouping based on synchronization in a network of coupled oscillators. To this end, the concept of excitatory and inhibitory connections between recurrent neurons is transfered from the Competitive Layer Model to a network of Kuramoto oscillators, which realizes grouping by phase and frequency synchronization. While preserving the excellent grouping capabilities of the CLM, this approach boosts the computational performance (due its simplicity), which is verified in several experiments.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-94.pdf
2013,Error entropy criterion in echo state network training,"Levy Boccato, Daniel G. Silva, Denis Fantinato, Kenji Nose Filho, Rafael Ferrari, Romis Attux, Aline Neves, Jugurta Montalvão, João Marcos T. Romano","Echo state networks offer a promising possibility for an effective use of recurrent structures as the presence of feedback is accompanied with a relatively simple training process. However, such simplicity, which is obtained through the use of an adaptive linear readout that minimizes the mean-squared error, limits the capability of exploring the statistical information of the involved signals. In this work, we apply an information-theoretic learning framework, based on the error entropy criterion, to the ESN training, in order to improve the performance of the neural model, whose advantages are analyzed in the context of supervised channel equalization problem.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-47.pdf
2013,Auto-encoder pre-training of segmented-memory recurrent neural networks,"Stefan Glüge, Ronald Böck, Andreas Wendemuth","The extended Backpropagation Through Time (eBPTT) learning algorithm for Segmented-Memory Recurrent Neural Networks (SMRNNs) yet lacks the ability to reliably learn long-term dependencies. The alternative learning algorithm, extended Real-Time Recurrent Learning (eRTRL), does not suffer from this problem but is computationally very inefficient, such that it is impractical for the training of large networks. The positive results reported with the pre-training of deep neural networks give rise to the hope that SMRNNs could also benefit from a pre-training procedure. In this paper, we introduce a layer-local pre-training procedure for SMRNNs. Using the information latching problem as a benchmark task, the comparison of randomly initialised and pre-trained networks shows the beneficial effect of the unsupervised pre-training. It significantly improves the learning of long-term dependencies in the supervised eBPTT training.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-50.pdf
2013,"Mixed order associative networks for function approximation, optimisation and sampling","Kevin Swingler, Leslie Smith","A mixed order associative neural network with n neurons and a modified Hebbian learning rule can learn any function f:{-1,1}^n = R and reproduce its output as the network's energy function. The network weights are equal to Walsh coefficients, the fixed point attractors are local maxima in the function, and partial sums across the weights of the network calculate averages for hyperplanes through the function. If the network is trained on data sampled from a distribution, then marginal and conditional probability calculations may be made and samples from the distribution generated from the network. These qualities make the network ideal for optimisation fitness function modelling and make the relationships amongst variables explicit in a way that architectures such as the MLP do not.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-4.pdf
2013,Regularization in relevance learning vector quantization using l1-norms,"Martin Riedel, Fabrice Rossi, Marika Kästner, Thomas Villmann","We propose in this contribution a method for $l_{1}$-regularization in prototype based relevance learning vector quantization (LVQ) for sparse relevance profiles. Sparse relevance profiles in hyperspectral data analysis fade down those spectral bands which are not necessary for classification. In particular, we consider the sparsity in the relevance profile enforced by LASSO optimization. The latter one is obtained by a gradient learning scheme using a differentiable parametrized approximation of the $l_{1}$-norm, which has an upper error bound. We extend this regularization idea also to the matrix learning variant of LVQ as the natural generalization of relevance learning.",Machine Learning Methods for Processing and Analysis of Hyperspectral Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-54.pdf
2013,Multi-view feature extraction for hyperspectral image classification,"Michele Volpi, Giona Matasci, Mikhaïl Kanevski, Devis Tuia","We study the multi-view feature extraction (MV-FE) framework for the classification of hyperspectral images acquired from airborne and spaceborne sensors. This type of data is naturally composed by distinct blocks of spectral channels, forming the hypercube. To reduce the dimensionality of the data by taking advantage of this particular structure, an unsupervised multi-view feature extraction method is applied prior to classification. First, a technique to automatically obtain the blocks, based on the global spectral correlation matrix, is applied. Then, the kernel canonical correlation analysis is performed in a multi-view setting (MV-kCCA) to find projections of the data blocks in a correlated subspace, gaining thus discriminant power. Experiments using the linear discriminant classifier (LDA) show the appropriateness of adopting a MV-FE prior to classification, which outperforms standard approaches.",Machine Learning Methods for Processing and Analysis of Hyperspectral Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-34.pdf
2013,Processing Hyperspectral Data in Machine Learning,"Thomas Villmann, Marika Kästner, Andreas Backhaus, Udo Seiffert","The adaptive and automated analysis of hyperspectral data is mandatory in many areas of research such as physics, astronomy and geophysics, chemistry, bioinformatics, medicine, biochemistry, engineering, and others. Hyperspectra differ from other spectral data that a large frequency range is uniformly sampled. The resulting discretized spectra have a huge number of spectral bands and can be seen as good approximations of the underlying continuous spectra. The large dimensionality causes numerical difficulties in efficient data analysis. Another aspect to deal with is that the amount of data may range from several billion samples in geophysics to only a few in medical applications. In consequence, dedicated machine learning algorithms and approaches are required for precise while efficient processing of hyperspectral data, which should include also expert knowledge of the application domain as well as mathematical properties of the hyperspectral data.",Machine Learning Methods for Processing and Analysis of Hyperspectral Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-9.pdf
2014,Direct Model-Predictive Control,"Jean-Joseph Christophe, Jérémie Decock, Olivier Teytaud","Due to simplicity, efficiency and convenience, Model Predictive Control, which consists in optimizing future decisions based on a pessimistic deterministic forecast of the random processes, is one of the main tools for stochastic control. Yet, it suffers from a large computation time, unless the tactical horizon (i.e. the number of future time steps included in the optimization) is strongly reduced, and lack of real stochas ticity handling. We here propose a combination between Model Predictive Control and Direct Policy Search (using Neural Networks), combining the best of both worlds.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-132.pdf
2014,Ensembles of extreme learning machine networks for value prediction,"Pablo Escandell-Montero, José María Martínez Martínez, Emilio Soria-Olivas, Joan Vila-Francés, José David Martín-Guerrero","Value prediction is an important subproblem of several reinforcement learning (RL) algorithms. In previous work, it has been shown that the combination of least-squares temporal-difference learning with ELM (extreme learning machine) networks is a powerful method for value prediction in continuous-state problems. This work work proposes the use of ensembles to improve the approximation capabilities of ELM networks in the context of RL.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-127.pdf
2014,An application of the temporal difference algorithm to the truck backer-upper problem,"Christopher Gatti, Mark Embrechts","We use a reinforcement learning approach to learn a real world control problem, the truck backer-upper problem. In this problem, a tractor trailer truck must be backed into a loading dock from an arbitrary location and orientation. Our approach uses the temporal difference al- gorithm using a neural network as the value function approximator. The novelty of this work is that our implementation is simple, yet it is able to successfully back the truck into the loading dock from random initial locations and orientations.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-108.pdf
2014,Application of Newton's Method to action selection in continuous state- and action-space reinforcement learning,"Barry Nichols, Dimitris Dracopoulos","An algorithm based on Newton's Method is proposed for action selection in continuous state- and action-space reinforcement learning without a policy network or discretization. The proposed method is validated on two benchmark problems: Cart-Pole and double Cart-Pole on which the proposed method achieves comparable or improved performance with less parameters to tune and in less training episodes than CACLA, which has previously been shown to outperform many other continuous state- and action-space reinforcement learning algorithms.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-175.pdf
2014,Linear Scalarized Knowledge Gradient in the Multi-Objective Multi-Armed Bandits Problem,"Saba Yahyaaa, Madalina  Drugan, Bernard Manderick","The multi-objective, multi-armed bandits (MOMABs) problem is a Markov decision process with stochastic rewards.  Each arm generates a vector of rewards instead of a single reward and these multiple rewards might be conflicting. The agent has a set of optimal arms and the agent's goal is not only finding the optimal arms, but also playing them fairly. To find the optimal arm set, the agent uses a linear scalarized (LS) function which converts the multi-objective arms into one-objective arms. LS function is simple, however it can not find all the optimal arm set. As a result, we extend knowledge gradient (KG) policy to LS function. We propose two variants of linear scalarized-KG, LS-KG across arms and dimensions. We experimentally compare the two variant,  LS-KG across arms finds the optimal arm set, while LS-KG across dimensions plays fairly the optimal arms.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-39.pdf
2014,Improving the firefly algorithm through the Barnes-Hut tree code,Kiril Ralinovski,"The firefly algorithm is a nature-inspired meta-heuristic algorithm that has a variety of applications such as multimodal optimization, clustering and finding good solutions for NP-hard problems. The original algorithm and modifications thereof have so far always calculated interactions between all fireflies individually which leads to a complexity of O(n^2). In this paper we present a novel approach to reduce the complexity to O(n log(n)) in lower dimensions by using the Barnes-Hut tree code, which is used for n-body simulations in physics. This is possible due to the similar nature of both problems and requires only small modifications.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-114.pdf
2014,Improved Cat Swarm Optimization approach applied to reliability-redundancy problem,"Carlos E. Klein, Leandro Coelho, Ângelo M. O. Sant’Anna, Roberto Z. Freire, Viviana C. Mariani","System reliability-redundancy optimization plays a vital role in real-world applications. Recently, a new meta-heuristic based on swarm intelligence called cat swarm optimization (CSO) algorithm has emerged. CSO is a stochastic optimization paradigm inspired from the natural behavior of cats. To enhance the performance of the CSO algorithm, an improved adaptive CSO (ICSO) algorithm is presented. Both CSO and ICSO approaches were applied to an overspeed protection system for a gas turbine, a benchmark in the reliability-redundancy mixed-integer optimization field.  Better results obtained by the ICSO show that the algorithm can be an efficient alternative for solving reliability problems.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-106.pdf
2014,Relevance Learning for Dimensionality Reduction,"Alexander Schulz, Andrej Gisbrecht, Barbara Hammer","Nonlinear dimensionality reduction (NDR) techniques offer powerful data visualization schemes capturing nonlinear effects of the data at the costs of a decreased interpretability of the  projection: Unlike for linear counterparts such as principal component analysis, the relevance of the original feature dimensions for the NDR projection is not clear. In this contribution we propose relevance learning schemes for NDR which enable to judge the relevance of a feature dimension for the projection. This technique can be extended to a metric learning scheme which opens a way to imprint the information as provided by a given visualization on the data representation in the original feature space.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-165.pdf
2014,Dimensionality reduction in decentralized networks by Gossip aggregation of principal components analyzers,"Jérôme FELLUS, David Picard, Philippe-Henri Gosselin","This paper considers dimensionality reduction in large decentralized networks with limited node-local computing and memory resources and unreliable point-to-point connectivity (e.g, peer-to-peer, sensors or ad-hoc mobile networks). We propose an asynchronous decentralized algorithm built on a Gossip consensus protocol that perform Principal Components Analysis (PCA) of data spread over such networks. All nodes obtain the same local basis that span the global principal subspace. Reported experiments show that obtained bases both reach a consensus and accurately estimate the global PCA solution.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-76.pdf
2014,Multiscale stochastic neighbor embedding: Towards parameter-free dimensionality reduction,"John A. Lee, Diego H. Peluffo-Ordonez, Michel Verleysen","Stochastic neighbor embedding (SNE) is a method of dimensionality reduction that involves softmax similarities measured between all pairs of data points. To build a suitable embedding, SNE tries to reproduce in a low-dimensional space the similarities that are observed in the high-dimensional data space. Previous work has investigated the immunity of such similarities to norm concentration, as well as enhanced cost functions. This paper proposes an additional refinement, in the form of multiscale similarities, namely weighted sums of softmax ratios with decreasing bandwidths. The objective is to maximize the embedding quality at all scales, with a better preservation of both local and global neighborhoods, and also to exempt the user from having to fix a scale arbitrarily. Experiments on several data sets show that this multiscale version of SNE, combined with an appropriate cost function (sum of Jensen-Shannon divergences), outperforms all previous variants of SNE.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-64.pdf
2014,Interactive dimensionality reduction for visual analytics,"Ignacio Diaz-Blanco, Abel A. Cuadrado-Vega, Daniel Perez-Lopez, Francisco Garcia-Fernandez, Michel Verleysen","In this work, we present a novel approach for data visualization based on interactive dimensionality reduction (iDR). The main idea of the paper relies on considering for visualization the intermediate results of non-convex DR algorithms under changes on the metric of the input data space driven by the user. With an appropriate visualization interface, our approach allows the user to focus on the relationships among dynamically selected groups of variables, as well as to assess the impact of a single variable or groups of variables in the structure of the data.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-75.pdf
2014,Recent methods for dimensionality reduction: A brief comparative analysis,"Diego H. Peluffo-Ordonez, John A. Lee, Michel Verleysen","Dimensionality reduction is a key stage for both the design of a pattern recognition system or data visualization. Recently, there has been a increasing interest on those methods aimed at preserving the data topology. Among them, Laplacian eigenmaps (LE) and stochastic neighbour embedding (SNE) are the most representative. In this work, we present a brief comparative among very recent methods being alternatives to LE and SNE. Comparisons are done mainly on two aspects: algorithm implementation, and complexity. Also, relations between methods are depicted. The goal of this work is providing with some discussion and criterion decision to chose a method according to the user's needs and/or keeping a good trade-off between performance and required processing time.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-170.pdf
2014,Capturing confounding sources of variation in DNA methylation data by spatiotemporal independent component analysis,"Emilie Renard, Andrew Teschendorff, Pierre-Antoine Absil","Confounding sources of variation, which are often either unknown or known with error, are widespread in genomic datasets, and failing to adjust for them may adversely impact statistical inference. In this context, we propose a `spatiotemporal' independent component analysis method that possesses a novel invariance property, and we show that that spatiotemporal aspect may increase the ability of the method to model confounding sources of variation.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-123.pdf
2014,Towards an effective multi-map self organizing recurrent neuronal network,"Denis Baheux, Hervé Frezza-Buet, Jeremy Fix",This paper presents a multi-map joint self-organizing architecture able to represent non-markovian temporal sequences. The proposed architecture is inspired by previous works based on dynamic neural fields. It provides a faster and easier to handle architecture making it easier to scale to higher dimensional machine learning problems.,Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-126.pdf
2014,Iterative ARIMA-multiple support vector regression models for long term time series prediction,"João Oliveira, Teresa B. Ludermir","Support Vector Regression (SVR) has been widely applied in time series forecasting. Considering long term predictions, iterative predictions perform many one-step-ahead predictions until the desired horizon is achieved. This process accumulates the error from previous predictions and may affect the quality of forecasts. In order to improve long term iterative predictions a hybrid multiple Autoregressive Integrated Moving Average(ARIMA)-SVR model is applied to perform predictions considering linear and non-linear components from the time series. The results show that the proposed method produces more accurate predictions in the long term context.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-94.pdf
2014,Spiking AGREL,"Davide Zambrano, Jaldert O. Rombouts, Cecilia Laschi, Sander Bohte","Spiking neural networks are characterised by the spiking neuron models they use and how these spiking neurons process information communicated through spikes - the neural code. We demonstrate a plausible spiking neural network based on Spike Response Models and predictive spike-coding. When combined with a plausible reinforcement learning strategy - Attention Gated REinforcement Learning (AGREL), we show that for the first time, such plausible spiking neural networks can compute non-linear mapping, including XOR.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-112.pdf
2014,Analysis of the Weighted Fuzzy C-means in the problem of source location,"Everton Z. Nadalin, Rodrigo C. Silva, Romis Attux, João M. T. Romano","This paper proposes the use of the clustering method called Weighted Fuzzy C-means to solve the problem of mixing matrix estimation in underdetermined source separation based on sparse component analysis. The performed comparative analysis shows that the approach has a significant application potential, especially if the distributions of the columns of the mixing matrix has a non-uniform character.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-142.pdf
2014,An Optimized Learning Algorithm Based on Linear Filters Suitable for Hardware implemented Self-Organizing Maps,"Marta Kolasa, Rafal Dlugosz, Talaska Tomasz, Pedrycz Witold","In this study, we present a fast and energy efficient learning algorithm suitable for Self-Organizing Maps (SOMs) realized in hardware. The proposed algorithm is an extension of the classical algorithm used in Kohonen SOM. It is based on the observation that the quantization error that is a typical quality measure of the learning process, does not decrease linearly along the learning process. One can observe the phases of the increased ‘activity’, during which the quantization error rapidly decreases, followed by ‘stagnation’ phases, during which its values are almost the same. The activity phases occur just after decreasing the neighborhood radius, R. A set of finite impulse response (FIR) filters is used to detect both phases. This enables an automatic switching the radius R to a smaller value that shorts a given stagnation phase and starts a new activity phase. Comprehensive investigations carried out by means of the software model of the SOM show that the learning process can be shorten even by 80-95% that allows for reduction of energy consumption even by 70-90%.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-125.pdf
2014,Enhanced NMF initialization using a physical model for pollution source apportionment,"Marc Plouvin, Abdelhakim Limem, Matthieu Puigt, Gilles Delmaire, Gilles Roussel, Dominique Courcot","In a previous work, we proposed an informed Non-negative Matrix Factorization (NMF) with a specific parametrization which involves constraints about some known components of the factorization. In this paper we extend the above work by adding some information provided by a physical dispersion model. In particular, we derive a special structure of one of the factorizing matrices, which provides a better initialization of the NMF procedure. Experiments on simulated mixtures of particulate matter sources show that our new approach outperforms both our previous one and the state-of-the-art NMF methods.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-115.pdf
2014,A New Error-Correcting Syndrome Decoder with Retransmit Signal Implemented with an Hardlimit Neural Network,Jose Fonseca,"Still today the problem of counting the errors of a noisy received word is an open problem in literature. This means that when we use an error correcting code we cannot control if the number of errors of the received noisy word is greater than the error correction capability of the code of k errors,  k=(d-1)/2, where d is the minimum Hamming distance of the code. The main advantage of our proposal results from the introduction of the Retransmit signal when the syndrome decoder detects an ambiguity situation and cannot correct the noisy word. These ambiguity situations occur when happens one more error than the error correction capability of the error correcting code. This property of the error correcting syndrome scheme allows increasing the error correction capability of an error correcting code by one error at a little increment of bandwidth or delay in the transmission. Although there are some proposals of implementation of error-correcting decoders with neural networks in literature our work is completely different in what concerns three main aspects. First we propose the implementation of the retransmit signal based on the detection of ambiguity of the minimum Hamming distance between the received word and each of the codewords, i.e. when there are more than one codeword at the minimum Hamming distance to the too noisy received word. Second we use a constructive approach that does not need training. And finally we use hardlimit neurons that can be implemented in hardware by a single transistor in a high gain setup. We begin with two exhaustive simulation experiments where we introduced all manners of occurrence of two errors in all codewords of two codes with minimum Hamming distances 3 and 4, respectively, which only guarantee all possible one error good corrections, to show how the ambiguities arise in the decoding process. Next we present the building blocks of the error correcting decoder based in hardlimit multilayered perceptrons and then we assembled all them out and show an example for an error correcting decoder for a four codewords error correcting code. Finally we discuss the advantages of our proposal and the consequences of the introduction of the Retransmit signal and define possible ways of evolution of our work.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-14.pdf
2014,Recent trends in learning of structured and non-standard data,"Frank-Michael Schleif, Peter Tino, Thomas Villmann","In many application domains data are not given in a classical vector space but occur in form of  structural, sequential, relational characteristics or other non-standard formats. These data are often represented  as graphs or by means of proximity matrices.  Often these data sets are also huge and mathematically  complicated to treat requesting for new efficient analysis algorithms which are the focus of this tutorial.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-11.pdf
2014,Support Vector Ordinal Regression using Privileged Information,"Fengzhen Tang, Peter Tino, Pedro Antonio Gutiérrez, Huanhuan Chen","We introduce a new methodology, called SVORIM+, for utilizing privileged information of the training examples, unavailable in the test regime, to improve generalization performance in ordinal regression.  The privileged information is incorporated during the training by modelling the slacks through correcting functions for each of the parallel hyperplanes separating the ordered classes.  The experimental results on several benchmark and time series datasets show that inclusion of the privileged information during training can boost the generalization performance significantly.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-58.pdf
2014,Segmented shape-symbolic time series representation,"Herbert Teun Kruitbosch, Ioannis Giotis, Michael Biehl",This work introduces a symbolic time series representation using monotonic sub-sequences and bottom up segmentation. The representation minimizes the square error between the segments and their approximation by monotonic functions. The representation can robustly classify the direction of a segment and is scale invariant with respect to the time and value dimensions. This paper describes two experiments. The first shows how accurately the monotonic functions are able to discriminate between different segments. The second tests how well the segmentation technique recognizes segments and classifies them with correct symbols. Finally this paper illustrates the new representation on real-world data.,Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-70.pdf
2014,Adaptive distance measures for sequential data,"Bassam Mokbel, Benjamin Paassen, Barbara Hammer","Recent extensions of learning vector quantization (LVQ) to general (dis-)similarity data have paved the way towards LVQ classifiers for possibly discrete, structured objects such as sequences addressed by classical alignment. In this contribution, we propose a metric learning scheme based on this framework which allows for autonomous learning of the underlying scoring matrix according to a given discriminative task. Besides facilitating the often crucial and problematic choice of the scoring matrix in applications, this extension offers an increased interpretability of the results by pointing out structural invariances for the given task.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-82.pdf
2014,Applications of lp-Norms and their Smooth Approximations for Gradient Based Learning Vector Quantization,"Mandy Lange, Dietlind Zühlke, Olaf Holz, Thomas Villmann","Learning vector quantization applying non-standard metrics became quite popular for classification performance improvement compared to standard approaches using the Euclidean distance. Kernel metrics and quadratic forms belong to the most promising approaches. In this paper we consider Minkowski distances ($l_{p}$-norms). In particular, $l_{1}$-norms are known to be robust against noise in data, such that, if this structural knowledge is available in advance about the data, this norm should be utilized. However, application in gradient based learning algorithms based on distance evaluations need to calculate the respective derivatives. Because $l_{p}$-distance formulas contain the absolute approximations thereof are required. We consider in this paper several approaches for smooth consistent approximations for numerical evaluations and demonstrate the applicability for exemplary real world applications.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-153.pdf
2014,Utilization of Chemical Structure Information for Analysis of Spectra Composites,"Kristin Domaschke, André Roßberg, Thomas Villmann","In this paper, we propose the utilization of structural information of spectral data during the preprocessing to extend the ability of subsequent analysis methods. Specifically, a composite dataset of measured spectra is given containing a mixtures of only a few spectral components. Using the mixture information for a small subset and additional chemical knowledge, theoretical component spectra are generated, which can be used as additional data with known mixture information in further data processing. The resulting extended data set is analyzed using a self-organizing map to predict the unknown mixture ratios of the remaining subset by an associative learning.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-155.pdf
2014,Weighted tree kernels for sequence analysis,"Christopher Bowles, James Hogan","Genomic sequences are fundamentally text documents, admitting a number of representations according to need and tokenization. Control of gene expression depends crucially on the binding of enzymes to the DNA sequence at a number of small, often poorly conserved, binding sites, precluding successful application of standard pattern search tools. However some progress is possible due to the regular syntactic structure of the enzyme's component proteins and the corresponding binding sites, allowing us to view the problem as one of detecting grammatically correct genomic phrases. In this paper we propose new kernels which extend existing tree kernels for application to weighted trees, in order to capture the features which underpin this prediction task. Experimentally, we find that these kernels provide performance comparable with state of the art approaches for this problem, while offering significant computational advantages over earlier methods. The  methods  proposed may be applied to a broad range of sequence or tree-structured data, including many other word-based classification tasks in molecular biology and other domains.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-190.pdf
2014,Easy multiple kernel learning,"Fabio Aiolli, Michele Donini","The goal of Multiple Kernel Learning (MKL) is to combine kernels derived from multiple sources in a data-driven way with the aim to enhance the accuracy of a kernel based machine. In this paper, we propose a time and space efficient MKL algorithm that can easily cope with hundreds of thousands of kernels and more. We compared our algorithm with other baselines plus three state-of-the-art MKL methods showing that our approach is often superior.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-129.pdf
2014,Joint SVM for Accurate and Fast Image Tagging,"Hanchen Xiong, Sandor Szedmak, Justus Piater","This paper studies how joint training of multiple support vector machines (SVMs) can improve the effectiveness and efficiency of au- tomatic image annotation. We cast image annotation as an output-related multi-task learning framework, with the prediction of each tag’s presence as one individual task. Evidently, these tasks are related via correlations between tags. The proposed joint learning framework, which we call joint SVM, can encode the correlation between tags by defining appropriate ker- nel functions on the outputs. Another practical merit of the joint SVM is that it shares the same computational complexity as one single conven- tional SVM, although multiple tasks are solved simultaneously. According to our empirical results on an image-annotation benchmark database, our joint training strategy of SVMs can yield substantial improvements, in terms of both accuracy and efficiency, over training them independently. In particular, it outperforms many other state-of-the-art algorithms.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-35.pdf
2014,Kernel methods for mixed feature selection,"Jérôme Paul, Pierre Dupont",This paper introduces two feature selection methods to deal with heterogeneous data that include continuous and categorical variables. We propose to plug a dedicated kernel that handles both kind of variables into a Recursive Feature Elimination procedure using either a non-linear SVM or Multiple Kernel Learning. These methods are shown to offer significantly better predictive results than state-of-the-art alternatives on a variety of high-dimensional classification tasks.,Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-59.pdf
2014,The one-sided mean kernel: a positive definite kernel for time series,"Nicolas Chrysanthos, Pierre Beauseroy, Hichem Snoussi, Edith Grall-Maes, Fabrice Ferrand","We propose in this paper a new kernel for time series in the dynamic time warping family. We demonstrate using the theory of infinitely divisible kernels that this kernel is positive definite. We also illustrate many other interesting practical properties: it is a radial basis kernel, has no issues of diagonal dominance, and presents a consistent behavior in the case of time series sub-sampling.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-147.pdf
2014,Naive Augmenting Q-Learning to Process Feature-Based Representations of States,Janis Zuters,"Temporal difference algorithms perform well on discrete and small problems. This paper proposes a modification of the Q-learning algorithm towards natural ability to receive a feature list instead of an already identified state in the input. Complete observability is still assumed. The algorithm, Naive Augmenting Q-Learning, has been designed through building a hierarchical structure of input features (a kind of feature-state mapping) to avoid a direct state identification, thus potentially optimizing the required resources for storing and processing action values.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-136.pdf
2014,Tensor decomposition of dense SIFT descriptors in object recognition,"Tan Vo, Dat Tran, Ma Wanli","In machine vision, Scale-invariant feature transform (SIFT) and its variants have been widely used in image classification task. However, the high dimensionality nature of SIFT features, usually in the order of multiple thousands per image, would require careful consideration in place to achieve accurate and timely categorization of objects within images. This paper explores the possibility of processing SIFT features as tensors and uses tensor decomposition techniques on high-order SIFT tensors for dimensionality reduction. The method focuses on both accuracy and efficiency aspects and the validation result with the Caltech 101 dataset confirms the improvement with notable margins.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-34.pdf
2014,Fine-tuning of support vector machine parameters using racing algorithms,"Péricles Miranda, Ricardo Silva, Ricardo Prudêncio","This paper investigates the iterative racing approach, I/F-Race, for selecting parameters of SVMs. As a racing algorithm, I/F-Race eliminates candidate models as soon as there is sufficient statistical evidence of their inferiority relative to other models with respect to the objective. The results revealed that the I/F-Race algorithm was able to achieve better parameter values in comparison to default parameters used in literature and parameters suggested by particle swarm optimization techniques.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-28.pdf
2014,reject option paradigm for the reduction of support vectors,"Sousa Ricardo, Ajalmar R. da Rocha Neto, Guilherme Barreto, Jaime S. Cardoso, Miguel T. Coimbra","In this paper we introduce a new conceptualization for the reduction of the number of support vectors (SVs) for an efficient design of support vector machines (SVMs). The techniques here presented provide a good balance between SVs reduction, performance accuracies and generalization capability. Our proposal explores concepts from classification with reject option mechanisms, which output a third class (the rejected instances) for a binary problem when a prediction cannot be given with sufficient confidence. Rejected instances along with misclassified ones are discarded from the original data to give rise to a classification problem that can be linearly solved. Our experimental study on two benchmark datasets show significant gains in terms of SVs reduction with competitive performances.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-4.pdf
2014,The Choquet kernel for monotone data,"Ali Fallah Tehrani, Marc Strickert, Eyke Hüllermeier","In this paper, we introduce a kernel for monotone data derived from the Choquet integral with its underlying fuzzy measure. % for monotone learning. While a na\""ive computation of this  kernel has a complexity that is exponential in the number of data attributes, we propose a more efficient approach with quadratic time complexity. Kernel PCA and SVM classification are employed to illustrate characteristics and benefits of the new Choquet kernel in two experiments related to decision-making and pricing.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-156.pdf
2014,Learning and modeling big data,"Barbara Hammer, Haibo He, Thomas Martinetz","Caused by powerful sensors, advanced digitalisation techniques, and dramatically increased storage capabilities, big data in the sense of large or streaming data sets,  very high dimensionality, or complex data formats constitute one of the major challenges  faced by machine learning today.  In this realm, a couple of typical assumptions of machine learning can no longer be met,  such as e.g. the possibility to deal with all data in batch mode or data being identically distributed; this  causes the need for novel algorithmic developments and paradigm shifts, or for the adaptation of  existing ones to cope with such situations. The goal of this tutorial is to give an overview about recent machine learning approaches for big data, with a focus on principled algorithmic ideas in the field.",Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-8.pdf
2014,Agglomerative hierarchical kernel spectral clustering for large scale networks,"Mall Raghvendra, Langone Rocco, Suykens Johan",We propose an agglomerative hierarchical kernel spectral clustering (AH-KSC) model for large scale complex networks. The kernel spectral clustering (KSC) method uses a primal-dual framework to build a model on a subgraph of the network. We exploit the structure of the projections in the eigenspace to automatically identify a set of distance thresholds. These thresholds lead to the different levels of hierarchy in the network. We use these distance thresholds on the eigen-projections of the entire network to obtain a hierarchical clustering in an agglomerative fashion. The proposed approach locates several levels of hierarchy which have clusters with high modularity (Q) and high adjusted rand index (ARI) w.r.t. the groundtruth communities. We compare AH-KSC with $2$ state-of-the-art large scale hierarchical community detection techniques.,Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-61.pdf
2014,Proximity learning for non-standard big data,Frank-Michael Schleif,"Complicated data sets, by means of high volume and variety are more and more common. In the life science domain for example, modern measurement systems generate huge amounts of data, which are only partially structured but have to be analyzed in reasonable time to trigger decisions and further analysis steps. Available algorithms to analyze such data do often not scale to larger problems or are inaccessible due to the variety of the data formats. Relational learning methods, as effective computational intelligence algorithms, can be used only for moderately large metric datasets. Here we discuss novel strategies to open relational methods for non-standard data formats at large scale, applied to a very large protein sequence database.",Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-33.pdf
2014,Predicting Grain Protein Content of Winter Wheat,"Mansouri Majdi, Marie-France Destain , Benjamin Dumont","The objective of this paper is to propose to use a new Improved Particle Filtering (IPF) based on minimizing Kullback-Leibler divergence for crop models' predictions. The performances of the method are compared with those of the conventional Particle Filtering (PF) at a complex crop model (AZODYN) to predict an important winter-wheat quality criterion, namely the grain protein content.  Furthermore, the effect of measurement noise (e.g., different signal-to-noise ratios) on the performances of PF and IPF is investigated.  The results of the comparative studies show that the IPF provides a significant improvement over the PF because, unlike the PF which depends on the choice of sampling distribution used to estimate the posterior distribution, the IPF yields an optimum choice of the sampling distribution, which also accounts for the observed data. The efficiency of IPF is expressed in terms of estimation accuracy (root mean square error).",Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-36.pdf
2014,On the complexity of shallow and deep neural network classifiers,"Monica Bianchini, Franco Scarselli","Recently, deep networks were proved to be more effective  than shallow architectures to face complex real--world applications. However, theoretical results supporting this claim are still few and incomplete. In this paper, we propose a new topological measure to study how the depth of feedforward networks impacts on their ability of implementing high complexity functions. Upper and lower bounds on network complexity are established, based on the number of hidden units and on their activation functions, showing that deep architectures are able, with the same number of resources, to address more difficult classification problems.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-44.pdf
2014,Evidence build-up facilitates on-line adaptivity in dynamic environments: example of the BCI P300-speller,"Emmanuel Daucé, Eoin Thomas",We consider a P300 BCI application where the subjects have to spell-out figures and letters in an unsupervised fashion. We (i) show that a generic speller can attain the state-of-the-art accuracy without any training phase or calibration and (ii) present an adaptive setup that consistently increases the  bit rate for most of the subjects.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-188.pdf
2014,Choosing the Metric in High-Dimensional Spaces Based on Hub Analysis,"Dominik Schnitzer, Arthur Flexer","To avoid the undesired effects of distance concentration in high dimensional spaces, previous work has already advocated the use of fractional lp norms instead of the ubiquitous Euclidean norm. Closely related to concentration is the emergence of hub and anti-hub objects. Hub objects have a small distance to an exceptionally large number of data points while anti-hubs lie far from all other data points. The contribution of this work is an empirical examination of concentration and hubness, resulting in an unsupervised approach for choosing an lp norm by minimizing hubs while simultaneously maximizing nearest neighbor classification.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-16.pdf
2014,Robust outlier detection with L0-SVDD,"Meriem El Azami, Carole Lartizien, Stéphane Canu","The problem of outlier detection consists in finding data that is not representative of the population from which it was ostensibly derived. Recently, to solve this problem, Liu et al. have proposed a two step hypersphere-based approach, taking into account a confidence score pre-calculated for each input data. However, these scores are defined in a first phase, independently from the second one, making  this approach is not well-suited for large stream data. To solve these difficulties, we propose a global reformulation of the support vector data description (SVDD) problem based on the L0 norm, well suited for {outlier detection}. We demonstrate that this L0-SVDD problem can be solved using an iterative procedure  providing data specific weighting terms. We show that our approach outperforms state of the art outlier detection techniques using both synthetic and real clinical data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-62.pdf
2014,Toward parallel feature selection from vertically partitioned data,"Veronica Bolon-Canedo, Noelia Sánchez-Maroño, Joana Cervino-Rabunal","Feature selection is often required as a preliminary step for many pattern recognition problems. In recent years, parallel learning has been the focus of much attention due to the advent of high dimensionality. Still, most of the existing algorithms only work in a centralized manner, i.e. using the whole dataset at once. This paper proposes a parallel filter approach for vertically partitioned data. The idea is to split the data by features and then apply a filter at each partition performing several rounds to obtain a stable set of features. Later, a merging procedure is carried out to combine the results into a single subset of relevant features. Experiments on three representative datasets show that the execution time is considerably shortened whereas the performance is maintained or even improved compared to the standard algorithms applied to the non-partitioned datasets. The proposed approach can be used with any filter algorithm, so it could be seen as a general framework for parallel feature selection.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-45.pdf
2014,Modeling consumption of contents and advertising in online newspapers,"Iago Porto-Díaz, David Martínez-Rego, Oscar Fontenla-Romero, Amparo Alonso-Betanzos","This paper presents the design of a system for personalization of contents and advertising for readers of online newspapers. This software is conceived to work in a context of high network traffic with millions of URLs served each day. The model is divided into two subsystems. The first one takes care of the recommendation of news items. The mathematical model is based on the PageRank algorithm and considers several practical day-to-day scenarios. The second one, which is the subsystem of personalization of advertising, uses a multinomial logistic regression model in order to predict categories of advertising for banners within the news content. The system has obtained practical satisfactory results using real data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-100.pdf
2014,Reweighted l1 Dual Averaging Approach for Sparse Stochastic Learning,"Jumutc Vilen, Suykens Johan",Recent advances in stochastic optimization and regularized dual averaging approaches revealed a substantial interest for a simple and scalable stochastic method which is tailored to some more specific needs. Among the latest one can find sparse signal recovery and l0-based sparsity inducing approaches. These methods in particular can force many components of the solution shrink to zero thus clarifying the importance of the features and simplifying the evaluation. In this paper we concentrate on enhancing sparsity of the recently proposed l1 Regularized Dual Averaging (RDA) method with a simple reweighting iterative procedure which in a limit applies the l0-norm penalty. We present some theoretical justifications of a bounded regret for a sequence of convex repeated games where every game stands for a separate reweighted l1-RDA problem. Numerical results show an enhanced sparsity of the proposed approach and some improvements over the l1-RDA method in generalization error.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-99.pdf
2014,Region of interest detection using MLP,"Tommi Kärkkäinen, Alexandr Maslov, Pekka Wartiainen",A novel technique to detect regions of interest in a time series as deviation from the characteristic behavior is proposed. The deterministic form of a signal is obtained using a reliably trained MLP neural network with detailed complexity management and cross-validation based generalization assurance. The proposed technique is demonstrated with simulated and real data.,Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-69.pdf
2014,Machine learning techniques to assess the performance of a gait analysis system,"Sébastien Piérard, Rémy Phan-Ba, Marc Van Droogenbroeck","This paper presents a methodology based on machine learning techniques to assess the performance of a system measuring the trajectories of the lower limbs extremities for the follow-up of patients with multiple sclerosis. We show how we have established, with the help of machine learning, four important properties about this system: (1) an automated analysis of gait characteristics provides an improved analysis with respect to that of a human expert, (2) after learning, the gait characteristics provided by this system are valuable compared to measures taken by stopwatches, as used in the standardized tests, (3) the motion of the lower limbs extremities contains a lot of useful information about the gait, even if it is only a small part of the body motion, (4) a measurement system combined with a machine learning tool is sensitive to intra-subject modifications of the walking pattern.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-159.pdf
2014,A Random Forest proximity matrix as a new measure for gene annotation,"Jose A. Seoane, Ian N.M. Day, Juan P. Casas, Colin Campbell, Tom R. Gaunt","In this paper we present a new score for gene annotation. This new score is based on the proximity matrix obtained from a trained Random Forest (RF) model. As an example application, we built this model using the association p-values of genotype with blood phenotype as input and the association of genotype data with coronary heart disease as output. This new score has been validated by comparing the Gene Ontology (GO) annotation using this score versus the score obtained from the gene annotation “String” tool. Using the new proximity based measure results in more accurate annotation, especially in the GO categories Molecular Function and Biological Process",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-144.pdf
2014,Neural network based 2D/3D fusion for robotic object recognition,"Louis-Charles Caron, Yang Song, Filliat David, Alexander Gepperth","We present a neural network based fusion approach for robotic object recognition which integrates 2D and 3D descriptors in a flexible way. The presented recognition architecture is coupled to a real-time segmentation step based on 3D data, since a focus of our investigations is real-world operation. In the light of the fact that recognition must operate on less-than-perfect segmentation results (which is a very realistic assumption for real-time robotic implementation), we conduct tests of recognition performance using complex everyday objects in order to quantify the overall gain of performing 2D/3D fusion, and to discover where it is particularly useful. We find that the fusion approach ist most powerful when generalization is required, for example to significant viewpoint changes, and that a perfect segmentation is apparently not a necessary prerequisite for successful object discrimination.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-149.pdf
2014,Discrimination of visual pedestrians data by combining projection and prediction learning,"Mathieu Lefort, Alexander Gepperth","PROPRE is a generic and semi-supervised neural learning paradigm that extracts meaningful concepts of multimodal data flows based on predictability across modalities. It consists on the combination of two computational paradigms. First, a topological projection of each data flow on a self-organizing map (SOM) to reduce input dimension. Second, each SOM activity is used to predict activities in all other SOMs. Predictability measure, that compares predicted and real activities, is used to modulate the SOM learning to favor mutually predictable stimuli. In this article, we study PROPRE applied to a classical visual pedestrian data classification task. The SOM learning modulation introduced in PROPRE improves significantly classification performance.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-148.pdf
2014,FINGeR: Framework for interactive neural-based gesture recognition,"German Ignacio Parisi, Pablo Barros, Stefan Wermter","For operating in real world scenarios, the recognition of human gestures must be adaptive, robust and fast. Despite the prominent use of Kinect-like range sensors for demanding visual tasks involving motion, it still remains unclear how to process depth information for efficiently extrapolating the dynamics of hand gestures. We propose a learning framework based on neural evidence for processing visual  information. We first segment and extract spatiotemporal hand properties from RGB-D videos. Shape and motion features are then processed by two parallel streams of hierarchical self-organizing maps and subsequently combined for a more robust representation. We provide experimental results to show how multi-cue integration increases recognition rates over a single-cue approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-138.pdf
2014,Beyond histograms: why learned structure-preserving descriptors outperform HOG,"Thomas Guthier, Volker Willert, Julian Eggert","Statistical image descriptors based on histograms (e.g. SIFT, HOG) are widely used in image processing, because they are fast and simple methods with high classification performance. However, they discard the local spatial topology and thus lose discriminative information contained in the image. We discuss the relations between HOG and VNMF descriptors, i.e. structure free histograms versus learned structure-preserving patterns. VNMF is a shift-invariant, sparse, non-negative unsupervised learning algorithm, that provides a distinct decomposition of the input into its parts. The VNMF descriptor outperforms the statistical HOG descriptor, because it preserves spatial topology leading to better classification results on real-world human action recognition benchmarks.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-168.pdf
2014,NMF-Density: NMF-Based Breast Density Classifier,"Lahouari Ghouti, Abdullah Owaidh","The amount of tissue available in the breast, commonly characterized by the breast density, is highly correlated  with breast cancer. In fact, dense breasts have higher risk of developing breast cancer. On the other hand, breast density influences the mammographic interpretation  since it decreases the sensitivity of breast cancer detection. This sensitivity decrease is due to the fact that both cancerous regions and tissue appear as white areas in breast mammograms. This paper introduces new features to improve the classification of breast density in digital mammograms according to the commonly used radiological lexicon (BI-RADS). These features are extracted from non-negative matrix factorization (NMF) of mammograms and classified using machine learning classifiers. Using ground truth mammographic data, the classification performance of the proposed features is assessed. Simulation results show that the latter  significantly outperforms existing density features based on principal component analysis (PCA)  by achieving higher classification accuracy.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-151.pdf
2014,Implicitly and explicitly constrained optimization problems for training of recurrent neural networks,Carl-Johan Thore,"Training of recurrent neural networks is typically formulated as unconstrained optimization problems. There is, however, an implicit constraint stating that the equations of state must be satisfied at every iteration in the optimization process. Such constraints can make a problem highly non-linear and thus difficult to solve. A potential remedy is to reformulate the problem into one in which the parameters and state are treated as independent variables and all constraints appear explicitly. In this paper we compare an implicitly and an explicitly constrained formulation of the same problem. Reported numerical results suggest that the  latter is in some respects superior.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-49.pdf
2014,A HMM-based pre-training approach for sequential data,"Luca Pasa, Alberto Testolin, Alessandro Sperduti","Much recent research highlighted the critical role of unsupervised pre-training to improve the performance of neural network models. However, extensions of those architectures to the temporal domain introduce additional issues, which often prevent to obtain good performance in a reasonable time. We propose a novel approach to pre-train sequential neural networks in which a simpler, approximate distribution generated by a linear model is first used to drive the weights in a better region of the parameter space. After this smooth distribution has been learned, the network is fine-tuned on the more complex real dataset. The benefits of the proposed method are demonstrated on a prediction task using two datasets of polyphonic music, and the general validity of this strategy is shown by applying it to two different recurrent neural network architectures.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-166.pdf
2014,Exploiting similarity in system identification tasks with recurrent neural networks,"Sigurd Spieckermann, Siegmund Düll, Steffen Udluft, Alexander Hentschel, Thomas Runkler","A new dual-task learning approach based on recurrent neural networks with factored tensor components for system identification tasks is presented. The overall goal is to identify the underlying dynamics of a system given few observations which are complemented by auxiliary data from similar systems. The resulting system identification is motivated by various real-world industrial use cases, e.g. gas or wind turbine modeling for optimization and monitoring. The problem is formalized and the effectiveness of the proposed method is assessed on the cart-pole benchmark.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-162.pdf
2014,Comparison of local and global undirected graphical models,"Zhemin Zhu, Djoerd Hiemstra, Peter Apers, Andreas Wombacher","CRFs are discriminative undirected models which are globally normalized. Global normalization preserves CRFs from the label bias problem which most local models suffer from. Recently proposed co-occurrence rate networks (CRNs) are also discriminative undirected models. In contrast to CRFs, CRNs are locally normalized. It was established that CRNs are immune to the label bias problem even they are local models. In this paper, we further compare ECRNs (using fully empirical relative frequencies, not by support vector regression\footnote{This is different from our another later paper, in which we use support vector regression. }) and CRFs. The connection between Co-occurrence Rate, which is the exponential function of pointwise mutual information, and Copulas is built in continuous case. Also they are further evaluated statistically by experiments.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-60.pdf
2014,Meta Online Learning: Experiments on a Unit Commitment Problem,"Jialin Liu, Olivier Teytaud","Online learning is machine learning, in real time from successive data samples. Meta online learning consists in combining several online learning algorithms from a given set (termed portfolio) of algorithms. The goal can be (i) mitigating the effect of a bad choice of online learning algorithms (ii) parallelization (iii) combining the st rengths of different algorithms. We propose a methodology, termed lag, adapted to black-box online learning.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-139.pdf
2014,DELA: A Dynamic Online Ensemble Learning Algorithm,"Hamid Bouchachia, Emili Balaguer-Ballester","Abstract. The present paper investigates the problem of prediction in the context of dynamically changing environment, where data arrive over time. A Dynamic online Ensemble Learning Algorithm (DELA) is introduced. The adaptivity concerns three levels: structural adaptivity, combination adaptivity and model adaptivity. In particular, the structure of the ensemble is sought to evolve in order to be able to deal with the problem of data drift. The proposed online ensemble is evaluated on the stagger data set to show its predictive power in presence of data drift.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-189.pdf
2014,Advances on Weightless Neural Systems,"Massimo De Gregorio, Felipe M. G. França, Priscila M. V. Lima, Wilson R. de Oliveira",,Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-7.pdf
2014,Learning state prediction using a weightless neural explorer,"Igor Aleksander, Helen Morton","A weightless neural state machine acting as an exploratory automaton changes its position in a simulated toy world by its own actions. A popular question is asked: how might the automaton ‘become conscious of’ the effect of its own actions? Here we develop previously defined iconic learning in such weightless machines so that this knowledge can be achieved. Weightlessness, iconic learning are expressed in terms of state equations. Experimental results that show the conditions under which correct predictions can be obtained on a neural simulator are presented. Issues of information integration and memory implication are briefly considered at the end of the paper.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-51.pdf
2014,A robust regularization path for the Doubly Regularized Support Vector Machine,"Antoine Lachaud, Stéphane Canu, David Mercier, Frederic Suard","The Doubly Regularized SVM (DrSVM) is an extension of SVM using a mixture of L2 and L1 norm penalties. This kind of penalty, sometimes referred as the elastic net, allows to perform variable selection while taking into account correlations between variables.  Introduced by Wang an efficient algorithm to compute the whole DrSVM solution path has been proposed.  Unfortunately, in some cases, this path is discontinuous, and thus not piecewise linear. To solve this problem, we propose here a new sub gradient formulation of the DrSVM problem. This led us to propose an alternative L1 regularization path algorithm.  This reformulation efficiently addresses the aforementioned problem and makes the initialization step more generic.  The results show the validity of our sub-gradient formulation and the efficiency compared to the initial formulation.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-150.pdf
2014,Credit analysis with a clustering RAM-based neural classifier,"Douglas Cardoso, Danilo Carvalho, Daniel Alves, Diego Souza, Hugo Carneiro, Carlos Pedreira, Priscila M. V. Lima, Felipe M. G. França","Datasets with a large amount of noisy data are quite common in real-world classification problems. Robustness is an important characteristic of state-of-the-art classifiers that use error minimization techniques, thus requiring a long time to converge. This paper presents ClusWiSARD, a clustering customization of the WiSARD weightless neural network model, applied to credit analysis, a non-trivial real-world problem. Experimental evidence shows that ClusWiSARD is very competitive with SVM in respect to accuracy. Nonetheless, ClusWiSARD outperforms SVM in both training time, being two orders of magnitude faster, and test time, being two to three times faster.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-107.pdf
2014,Training a classical weightless neural network in a quantum computer,"Adenilton J. da Silva, Wilson R. de Oliveira, Teresa B. Ludermir",The purpose of this paper is to investigate a new quantum learning algorithm for classical weightless neural networks. The learning algorithm creates a superposition of all possible neural network configurations for a given architecture. The performance of the network over the training set is stored entangled with neural configuration and quantum search is performed to amplify the probability amplitude of the network with desired performance.,Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-182.pdf
2014,"Extracting rules from DRASiW’s ""mental images""","Paulo Coutinho, Hugo Carneiro, Danilo Carvalho, Felipe M. G. França","DRASiW is an extension of the WiSARD weightless neural model that provides the ability of producing examples/prototypes, called ""mental images"", from learnt categories. This work introduces a novel way of performing rule extraction by applying the WiSARD/DRASiW RAM-based neural model upon a well-known machine learning benchmark. A functional exploration is offered in order to demonstrate how the new rule extraction mechanism behaves under different system configurations. Experimental results suggest that the rules conformance to data increases proportionally to the corresponding classifier accuracy. Furthermore, comparison with C4.5 decision tree algorithm shows that the DRASiW-based technique produces more compact sets of rules.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-167.pdf
2014,Vector space weightless neural networks,"Wilson R. de Oliveira, Adenilton J. da Silva, Teresa B. Ludermir","By embedding the boolean space $Z_2$ as an orthonormal basis of vector space we can treat the RAM based neuron as a matrix (operator) acting the vector space. We show how this model (inspired by our research on quantum neural networks) is of sufficient generality as to have classical weighted (perceptron-like), classical weightless (RAM-based, PLN, etc), quantum weighted and quantum weightless neural models as particular cases. It is also indicated  how one could use it to solve 3-SAT and briefly mention how could one train this novel model.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-176.pdf
2014,Online tracking of multiple objects using WiSARD,"Rafael Lima de Carvalho, Danilo Carvalho, Priscila M. V. Lima, Félix Mora-Camino, Felipe M. G. França","This paper evaluates the WiSARD weightless model as a classification system on the problem of tracking multiple objects in realtime. Exploring the structure of this model, the proposed solution applies a re-learning stage in order to avoid interferences caused by background noise or variations in the target shape. Once the tracker finds a target at the first time, it applies only local searches around the neighbourhood in order to have fast response. This approach is evaluated through some  experiments on real-world video data.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-89.pdf
2014,Probabilistic automata simulation with single layer weightless neural networks,"Adenilton J. da Silva, Wilson R. de Oliveira, Teresa B. Ludermir","Computability of weightless neural networks is the major topic of this paper. In previous works it has been shown that, one can simulate a Turing machine with a weightless neural network (WNN) with an infinite tape. And it has also been shown that one can simulate probabilistic automata with a WNN with two queues. In this paper, we will show that is possible to simulate a probabilistic automata with a single layer WNN with no auxiliary data structures.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-83.pdf
2014,Optimal Data Projection for Kernel Spectral Clustering,"Diego H. Peluffo-Ordonez, Carlos Alzate, Suykens Johan, Germán Castellanos-Dominguez","Spectral clustering has taken an important place in the context of pattern recognition, being a good alternative to solve problems with non-linearly separable groups. Because of its unsupervised nature, clustering methods are often parametric, requiring then some initial parameters. Thus, clustering performance is greatly dependent on the selection of those initial parameters. Furthermore, tuning such parameters is not an easy task when the initial data representation is not adequate. Here, we propose a new projection for input data to improve the cluster identification within a kernel spectral clustering framework. The proposed projection is done from a feature extraction formulation, in which a generalized distance involving the kernel matrix is used. Data projection shows to be useful for improving the performance of kernel spectral clustering.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-163.pdf
2014,Supporting GNG-based clustering with local input space histograms,"Jochen Kerdels, Gabriele Peters",This paper presents an extension to the growing neural gas (GNG) algorithm that allows to capture local characteristics of the input space. Using these characteristics clustering schemes based on the GNG network can be improved by discarding uncertain edges of the network and identifying edges that span discontinuous regions of input space. We applied the described approach to different two-dimensional data sets found in the literature and obtained comparable results.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-119.pdf
2014,The Sum-over-Forests clustering,"Mathieu Senelle, Marco Saerens, François Fouss","This work introduces a novel way to identify dense regions in a graph based on a mode-seeking clustering technique, relying on the Sum-Over-Forests (SoF) density index (which can easily be computed in closed form through a simple matrix inversion) as a local density estimator. We first identify the modes of the SoF density in the graph. Then, the nodes of the graph are assigned to the cluster corresponding to the nearest mode, according to a new kernel, also based on the SoF framework. Experiments on artificial and real datasets show that the proposed index performs well in nodes clustering.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-104.pdf
2014,Bayesian non-parametric parsimonious clustering,"Faicel Chamroukhi, Marius Bartcus, Hervé Glotin","This paper proposes a new Bayesian non-parametric approach for clustering. It relies on an infinite Gaussian mixture model with a Chinese Restaurant Process (CRP) prior, and an eigenvalue decomposition of the covariance matrix of each cluster. The CRP prior allows to control the model complexity in a principled way and to automatically learn the number of clusters. The covariance matrix decomposition allows to fit various parsimonious models going from simplest spherical ones to the more complex general one. We develop an MCMC Gibbs sampler to learn the models. First results obtained on both simulated and real data highlight the interest of the proposed infinite parsimonious mixture model.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-46.pdf
2014,Learning predictive partitions for continuous feature spaces,"Björn Weghenkel, Laurenz Wiskott","Any non-trivial agent (biological or algorithmical) that interacts with its environment needs some representation about its current state. Such a state should enable it to make informed decisions that lead to some desired outcome in the future. In practice, many learning algorithms assume states to come from a discrete set while real-world learning problems often are continuous in nature. We propose an unsupervised learning algorithm that finds discrete partitions of a continuous feature space that are predictive with respect to the future. More precisely, the learned partitions induce a Markov chain on the data with high mutual information between the current state and the next state. Such predictive partitions can serve as an alternative to classical discretization algorithms in cases where the predictable time-structure of the data is of importance.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-98.pdf
2014,An adjustable p-exponential clustering algorithm,"Valmir Macario, Francisco de Assis Tenório De Carvalho",This paper proposes a new exponential clustering algorithm (XPFCM) by reformulating the clustering's objective function with an additional paramter p to adjust the exponential behavior for membership assignment. The clustering experiments show that the proposed method assigns data to the clusters better than other fuzzy C-means (FCM) variants.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-164.pdf
2014,Self-organizing map for determination of goal candidates in mobile robot exploration,"Jan Faigl, Peter Vanìk, Miroslav Kulich","This paper addresses a problem of determining goal candidates in the frontier-based mobile robot exploration. The proposed solution is based on self-organizing map for the traveling salesman problem with neighborhoods and it allows to study the exploration formulated as a problem of repeated coverage of the current frontiers where the minimal number of goal candidates is determined simultaneously together with the expected cost to visit the candidates. The early results enabled by the proposed self-organizing map-based solution indicate exploration improvement for the proposed problem formulation. Thus, the presented work demonstrates how neural network approach can provide interesting insights and ground for studying optimizations problems arising in robotics.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-116.pdf
2014,Parameter-free regularization in Extreme Learning Machines with affinity matrices,"Leonardo Silvestre, André P. Lemos, João P. Braga, Antônio P. Braga","This paper proposes a novel regularization approach for Extreme Learning Machines. Regularization is performed using a priori spacial information expressed by an affinity matrix. We show that the use of this type of a priori information is similar to perform Tikhonov regularization. Furthermore, if a parameter free affinity matrix is used, like the cosine similarity matrix, regularization is performed without any need for parameter tunning. Experiments are performed using classification problems to validate the proposed approach.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-66.pdf
2014,Feature selection in environmental data mining combining Simulated Annealing and Extreme Learning Machine,"Michael Leuenberger, Mikhaïl Kanevski","Due to the large amount and complexity of data available in geosciences, machine learning nowadays plays an important role in environmental data mining. In many real data cases, we face the need to design input space with the most relevant features. Because the main goal is to understand and find relationships between phenomena and features, feature selection is preferred to feature transformation or extraction. To deal with the high-dimensional space of environmental data, a wrapper method based on Extreme Learning Machine and global optimization algorithm (Simulated Annealing) is proposed. This paper investigates the whole methodology and shows promising results for environmental data feature selection and modelling.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-90.pdf
2014,Using Shannon Entropy as EEG Signal Feature for Fast Person Identification,"Dinh Phung, Dat Tran, Ma Wanli, Phuoc Nguyen, Pham Tien","Identification accuracy and speed are important factors in automatic person identification systems. In this paper, we propose a feature extraction method to extract brain wave features from different brain rhythms of electroencephalography (EEG) signal for the purpose of fast, yet accurate person identification. The proposed feature extraction method is based on the fact that EEG signal is complex, non-stationary, and non-linear. With this fact, non-linear analysis like entropy would be more appropriate. Shannon entropy (SE) based EEG features from alpha, beta, and gamma wave bands are extracted and evaluated for person identification. Experimental results show that SE features provide high person identification rates yet with a low feature dimension, thus better performance.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-121.pdf
2014,An Extreme Learning Approach to Active Learning,"Euler Horta, Antônio P. Braga",We propose in this paper a new active learning method that makes no considerations about the data distribution and does not need to adjust any free parameter. The proposed algorithm is based on extreme learning machines (ELM) and a perceptron with analytical calculation of weights. We show that the proposed model have good results using a reduced set of patterns.,"Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-184.pdf
2014,A new model selection approach for the ELM network using metaheuristic optimization,"Ananda Freire, Guilherme Barreto","We propose a novel approach for architecture selection and hidden neurons excitability improvement for the Extreme Learning Machine (ELM). Named Adaptive Number of Hidden Neurons Approach (ANHNA), the proposed approach relies on a new general encoding scheme of the solution vector that automatically estimates the number of hidden neurons and adjust their activation function parameters (slopes and biases). Due to its general nature, ANHNA's encoding scheme can be used by any metaheuristic algorithm for continuous optimization. Computer experiments were carried out using Differential Evolution (DE) and Particle Swarm Optimization (PSO) metaheuristics, with promising results being achieved by the proposed method in benchmarking regression problems.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-180.pdf
2014,Extreme learning machines for Internet traffic classification,"Joseph Ghafari, Emmanuel Herbert, Stephane  Senecal, Daniel Migault, Stanislas Francfort, Ting Liu",Network packet transport services (namely the Internet) are subject to significant security issues. This paper aims to apply Machine Learning methods based on Neural Networks (Extreme Learning Machines or ELM) to analyze the Internet traffic in order to detect specific malicious activities. This is performed by classifying traffic for a key service run over the internet: the Domain Name System (DNS). The ELM models and algorithms are run on DNS traffic data extracted from operating networks for botnet detection.,"Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-29.pdf
2014,Electric load forecasting using wavelet transform and extreme learning machine,"Song Li, Peng Wang, Lalit Goel","This paper proposes a novel method for load forecast, which integrates wavelet transform and extreme learning machine. In order to capture more internal features, wavelet transform is used to decompose the load series into a set of sub-components, which are more predictable. Then all the components are separately processed by extreme learning machine. Numerical testing shows that the proposed method is able to improve the forecast performance with much less computational cost compared with other benchmarking methods.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-23.pdf
2014,Swim velocity profile identification through a Dynamic Self-adaptive Multiobjective Harmonic Search and RBF neural networks,"Helon V. H. Ayala, Luciano F. da Cruz, Leandro Coelho, Roberto Z. Freire","Technology has been successfully applied in sports, where biomechanical analysis is one of the most important area used to raise the performance of athletes. In this context, this paper focuses on swim velocity profile identification using Radial Basis Functions Neural Networks (RBF-NN) trained by the Gustafson-Kessel clustering combined with a novel Dynamic Self-adaptive Multiobjective Harmony Search (DS-MOHS). One study case is analyzed, from real data acquired of an elite female athlete, swimming breaststroke style. Better results are obtained by DS-MOHS when compared with standard multiobjective harmony search in terms of accuracy and generalization of the model.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-133.pdf
2014,Dynamic ensemble selection and instantaneous pruning for regression,"Kaushala Dias, Terry Windeatt","A novel dynamic method of selecting pruned ensembles of predictors for regression problems is presented. The proposed method, known henceforth as DESIP, enhances the prediction accuracy and generalization ability of pruning methods. Pruning heuristics attempt to combine accurate yet complementary members, therefore DESIP enhances the performance by modifying the pruned aggregation through distributing the ensemble member selection over the entire dataset. Four static ensemble pruning approaches used in regression are compared to highlight the performance improvement yielded by the dynamic method. Experimental comparison is made using Multiple Layer Perceptron predictors on benchmark datasets.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-173.pdf
2014,Data normalization and supervised learning to assess the condition of patients with multiple sclerosis based on gait analysis,"Samir Azrour, Sébastien Piérard, Pierre Geurts, Marc Van Droogenbroeck","Gait impairment is considered as an important feature of disability in multiple sclerosis but its evaluation in the clinical routine remains limited. In this paper, we assess, by means of supervised learning, the condition of patients with multiple sclerosis based on their gait descriptors obtained with a gait analysis system. As the morphological characteristics of individuals influence their gait while being in first approximation independent of the disease level, an original strategy of data normalization with respect to these characteristics is described and applied beforehand in order to obtain more reliable predictions. In addition, we explain how we address the problem of missing data which is a common issue in the field of clinical evaluation. Results show that, based on machine learning combined to the proposed data handling techniques, we can predict a score highly correlated with the condition of patients.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-178.pdf
2014,Sparse one hidden layer MLPs,"Alberto Torres, David Díaz, José R. Dorronsoro","We discuss how to build sparse one hidden layer MLP replac- ing the standard l2 weight decay penalty on all weights by an l1 penalty on the linear output weights. We will propose an iterative two step training procedure where the output weights are found using FISTA proximal op- timization algorithm to solve a Lasso-like problem and the hidden weights are computed by unconstrained minimization. As we shall discuss, the procedure has a complexity equivalent to that of standard MLP training, yields MLPs with similar performance and, as a by product, automatically selects the number of hidden units.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-95.pdf
2014,Multi-Step Ahead Forecasting of Road Condition Using Least Squares Support Vector Regression,"Konsta Sirvio, Jaakko Hollmén","Network-level multi-step road condition forecasting is an important step in accurate road maintenance planning, where correct maintenance activities are defined in place and time of road networks. Forecasting methods have developed from engineering models to non-linear machine learning methods that make use of the collected condition and traffic data of the road network. Least Squares Support Vector Regression gives signicantly the best results.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-37.pdf
2014,A comprehensive introduction to label noise,"Benoît Frénay, Ata Kaban","In classification, it is often difficult or expensive to obtain completely accurate and reliable labels. Indeed, labels may be polluted by label noise, due to e.g. insufficient information, expert mistakes, and encoding errors. The problem is that errors in training labels that are not properly handled may deteriorate the accuracy of subsequent predictions, among other effects. Many works have been devoted to label noise and this paper provides a concise and comprehensive introduction to this research topic. In particular, it reviews the types of label noise, their consequences and a number of state of the art approaches to deal with label noise.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-10.pdf
2014,Improving the Robustness of Bagging with Reduced Sampling Size,"Maryam Sabzevari, Gonzalo Martínez-Muñoz, Alberto Suárez","Bagging is a simple and robust classification algorithm in the presence of class label noise. This algorithm builds an ensemble of classifiers by bootstrapping samples with replacement of size equal to the original training set. However, several studies have shown that this choice of sampling size is arbitrary in terms of generalization performance of the ensemble. In this study we discuss how small sampling ratios can contribute to the robustness of bagging in the presence of class label noise. An empirical analysis on two datasets is carried out using different noise rates and bootstrap sampling sizes. The results show that, for the studied datasets, sampling rates of 20% clearly improve the performance of the bagging ensembles in the presence of class label noise.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-185.pdf
2014,Credal decision trees in noisy domains,"Carlos J. Mantas, Joaquín Abellán","Credal Decision Trees (CDTs) are algorithms to design classifiers based on imprecise probabilities and uncertainty measures. In this paper, the C4.5 and CDT procedures are combined in a new one. This depends on a parameter $s$. Several experiments are carried out with different values for $s$. C4.5 and the new procedure, varying the value of its parameter, are compared on data sets with different noise levels.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-72.pdf
2014,Finding Originally Mislabels with MD-ELM,"Anton Akusok, David Veganzones, Yoan Miché, Eric Severin, Amaury Lendasse","This paper presents a method which aims at detecting mislabeled samples, with a practical example in the eld of bankruptcy prediction. Mislabeled samples are found in many classication problems and can bias the training of the desired classier. This paper is proposing a new method based on Extreme Learning Machine (ELM) which allows for identification of the most probable mislabeled samples. Two datasets are used in order to validate and test the proposed methodology: a toy example (XOR problem) and a real dataset from corporate nance (bankruptcy prediction).",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-18.pdf
2014,Misclassification of class C G-protein-coupled receptors as a label noise problem,"Caroline König, Alfredo Vellido Alcacena, René Alquézar Mancho, Jesús Giraldo","G-Protein-Coupled Receptors (GPCRs) are cell membrane proteins of relevance to biology and pharmacology. Their supervised classification in subtypes is hampered by label noise, which stems from a combination of expert knowledge limitations and lack of clear correspondence between labels and different representations of the protein primary sequences. In this brief study, we describe a systematic approach to the analysis of GPCR misclassifications using Support Vector Machines and use it to assist the discovery of database labeling quality problems and investigate the extent to which GPCR sequence physicochemical transformations reflect GPCR subtype labeling. The proposed approach could enable a filtering approach to the label noise problem.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-118.pdf
2014,A multi-class extension for multi-labeler support vector machines,"Diego H. Peluffo-Ordonez, Santiago Murillo-Rendón, Julián Arias-Londoño, Germán Castellanos-Dominguez","In recent years, there has been an increasing interest in the design of pattern recognition systems able to deal with labels coming from multiple sources. To avoid bias during the learning process, in some applications it is strongly recommended to learn from a set of panelists or experts instead of only one. In particular, two aspects are of interest, namely: discriminating between confident and unconfident labelers, and determining the suitable ground truth. This work presents an extension of a previous work, which consists of a generalization of the two class case via a modified one-against-all approach. This approach uses modified classifiers able to learn from multi-labeler settings. This is done within a soft-margin support vector machine framework. Proposed method provides ranking values for panelist as well as an estimate of the ground truth.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-169.pdf
2014,Can you follow that guy?,"Mariacarla Staffa, Massimo De Gregorio, Maurizio Giordano, Silvia Rossi",,Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-160.pdf
2014,Mobility Prediction Using Fully-Complex Extreme Learning Machines,Lahouari Ghouti,"Efficient planning and improved quality of service (QoS) in wireless networks call for the use of mobility prediction schemes. Such schemes ensure accurate mobility prediction of wireless users and units  which plays a major role in optimized planning and management of the available bandwidth and power resources. In this paper, fully-complex extreme learning machines (CELMs), known for their universal approximation, model and predict the mobility patterns of arbitrary nodes in a mobile ad hoc network (MANET). Unlike their real-valued counterparts, CELMs properly capture the existing interaction/correlation between the nodes' location coordinates leading to more realistic and accurate prediction. Simulation results using standard mobility models and real-world mobility data clearly show that the proposed complex-valued prediction algorithm outperforms many existing real-valued learning machines in terms of prediction accuracy.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-79.pdf
2014,Toward STDP-based population action in large networks of spiking neurons,Emmanuel Daucé,"We present simulation results that clarify the role of Spike-Timing Dependent Plasticity (STDP) in brain processing as a putative mechanism to transfer spatio-temporal regularities, as observed  in sensory signals, toward action, expressed as a global increase of the target population activity,  followed by a reset. The repetition of this activation-reset mechanism gives rise to a series of synchronous  waves of activity when the same stimulus is repeated over and over. Our simulation results are obtained in recurrent networks of conductance-based neurons under realistic coupling contraints.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-186.pdf
2014,Supervised Generative Models for Learning Dissimilarity Data,"David Nebel, Barbara Hammer, Thomas Villmann","Exemplar based techniques such as affinity propagation \cite{ap}  represent data in terms of typical exemplars. This has two benefits: (i)  the resulting models are directly interpretable by humans since representative exemplars can be inspected in the same way as data points, (ii) the model can be applied to any dissimilarity measure including non-Euclidean or non-metric settings. Most exemplar based techniques have been proposed in the unsupervised setting only, such that their performance in supervised learning tasks can be weak depending on the given data. Here, we address the problem of learning exemplar-based models for general dissimilarity data in a discriminative framework. For this purpose, we extend a generative model proposed in \cite{srlvq} to an exemplar based scenario using a generalized EM framework for its optimization. The resulting classifiers represent data in terms of sparse models while keeping high performance in state-of-the art benchmarks.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-91.pdf
2014,Rejection strategies for learning vector quantization,"Lydia Fischer, Barbara Hammer, Heiko Wersing","We present prototype-based classification schemes, e. g. learning vector quantization, with cost-function-based and geometrically motivated reject options. We evaluate the reject schemes in experiments on artificial and benchmark data sets. We demonstrate that reject options improve the accuracy of the models in most cases, and that the performance of the proposed schemes is comparable to the optimal reject option of the Bayes classifier in cases where the latter is available.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-131.pdf
2014,Optimization of General Statistical Accuracy Measures for Classification Based on Learning Vector Quantization,"Marika Kaden, Wieland Hermann, Thomas Villmann","We propose a framework for classification learning based on generalized learning vector quantization using statistical quality measures as cost function. Statistical measures like the $F$-measure or the Matthews correlation coefficient reflect better the performance for two-class classification problems than the simple accuracy, in particular if the data classes are imbalanced. For this purpose, we introduce soft approximations of those quantities contained in the confusion matrix, which are the basis for the calculation of the quality measures.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-93.pdf
2014,Augmented hashing for semi-supervised scenarios,"Zalán-Péter Bodó, Lehel Csato","Hashing methods for fast approximate nearest-neighbor search are getting more and more attention with the excessive growth of the available data today. Embedding the points into the Hamming space is an important question of the hashing process. Analogously to machine learning there exist unsupervised, supervised and semi-supervised hashing methods. In this paper we propose a generic procedure to extend unsupervised codeword generators using error correcting codes and semi-supervised classifiers. To show the effectiveness of the method we combine linear spectral hashing and two semi-supervised algorithms in the experiments.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-96.pdf
2014,Improving accuracy by reducing the importance of hubs in nearest-neighbor recommendations,"François Fouss, Clémentine Van Parijs","A traditional approach for recommending items to persons consists of including a step of forming neighborhoods of users/items. This work focuses on such nearest-neighbor approaches and, more specically, on a particular type of neighbors, the ones frequently appearing in the neighborhoods of users/items (i.e., very similar to many other users/items in the data set), referred to as hubs in the literature. The aim of this paper is to explore through experiments how the presence of hubs aects the accuracy of nearest-neighbor recommendations.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-57.pdf
2014,A new approach for multiple instance learning based on a homogeneity bag operator,"Alexandre Wagner Chagas Faria, David Menotti, André P. Lemos, Antônio P. Braga","Multiple Instance Learning (MIL) proposes a new paradigm when instance labeling, in the learning step, is not possible or infeasible, by assigning a single label (positive or negative) to a set of instances called bag. In this paper, an operator based on homogeneity of positive bags for MIL is introduced. Our method consists in removing instances from the positives bags according to their similarity with the ones from the negative bags. The experimental results show that our operator always increases the accuracy of the Citation kNN algorithm achieving the best results in 2 out of 4 datasets when compared with other classic methods in the literature.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-174.pdf
2014,Byte The Bullet: Learning on Real-World Computing Architectures,"Alessandro Ghio, Luca Oneto","Fast, effective, and reliable models: these are the desiderata of every theorist and practitioner. Machine Learning (ML) algorithms, proposed in the last decades, proved to be effective and reliable in solving complex real-world problems, but they are usually designed without taking into account the underlying computing architecture. On the contrary, the effort of contemplating the exploited computing device is often motivated by application-specific and real-world requirements, such as the need to accelerate the learning process with dedicated/distributed hardware, or to foster energy-sparing requirements of applications based on mobile standalone devices. The ESANN 2014 ""Byte The Bullet: Learning on Real-World Computing Architectures"" special session has pooled a compilation of the most recent proposals in this area, by encouraging submissions related to the development and the application of fast, effective, reliable techniques, which consider possibilities, potentialities and constraints of real-world computing architectures as basic cornerstones and motivations.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-12.pdf
2014,Learning with few bits on small-scale devices: From regularization to energy efficiency,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella","The implementation of Machine Learning (ML) algorithms on stand-alone small-scale devices allows incorporating in these systems new services and advanced functionalities without the need of resorting to remote computing systems. Despite having undeniable advantages with respect to conventional general-purpose devices, e.g. in terms of cost/performance ratios, small-scale systems suffer of issues related to their resource-limited nature, like limited battery capacity and processing power. In order to deal with such limitations, we propose to merge local Rademacher Complexities and bit-based hypothesis spaces to build thrifty models, which can be effectively implemented on small-scale resource-limited devices. Experiments, carried out on a smartphone in a Human Activity Recognition application, show the benefits of the proposed approach in terms of model accuracy and battery duration.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-27.pdf
2014,Speedy greedy feature selection: Better redshift estimation via massive parallelism,"Fabian Gieseke, Kai Polsterer, Cosmin Eugen Oancea, Christian Igel","Nearest neighbor models are among the most basic tools in machine learning, and recent work has demonstrated their effectiveness in the field of astronomy. The performance of these models crucially depends on the underlying metric, and in particular on the selection of a meaningful subset of informative features. The feature selection is task-dependent and usually very time-consuming. In this work, we propose an efficient parallel implementation of incremental feature selection for nearest neighbor models utilizing nowadays graphics processing units. Our framework provides significant computational speed-ups over its sequential single-core competitor of up to two orders of magnitude. We demonstrate the applicability of the overall scheme on one of the most challenging tasks in astronomy: the detection of distant galaxies.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-171.pdf
2014,Context- and cost-aware feature selection in ultra-low-power sensor interfaces,"Steven Lauwereins, Komail Badami, Wannes Meert, Marian Verhelst","This paper introduces the use of machine learning to drastically improve efficiency of ultra-low-power sensor interfaces. Adaptive feature extraction circuits are assisted by hardware embedded learning to dynamically activate only most relevant features. This selection is done in a context and power cost-aware way, through modification of the C4.5 algorithm. Furthermore, context dependence of different feature sets is explained. As proof-of-principle, a Voice Activity Detector is expanded with the proposed context- and cost-dependent voice/noise classifier, resulting in an average circuit power savings of 75%, with negligible accuracy loss.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-179.pdf
2014,Lightning fast asynchronous distributed k-means clustering,"Árpád Berta, István Heged&#369;s, Róbert Ormándi","One of the most fundamental data processing approach is the clustering. This is even true when the computational environment is radically different from the usual centralized  architectures. Here we focus on the problem of designing efficient and fast K-Means approaches  which work in fully distributed, asynchronous networks without any central control.  We assume that the network has a huge number of computational units  (even orders of magnitude more than the number of computational units in a general cloud). Additionally, we allow that network failures occur and the computational units leave and join the network through the computation. Our approaches apply online learning clustering models which take different random walks in the network,  while they update themselves using the data points stored by the computational units, and various ensemble techniques combine them to get a faster convergence. We define different instantiations of the general framework that applies various ensemble techniques. We evaluate them empirically against several state-of-the-art distributed baseline algorithms in different computational scenarios. The results of our experiments indicate that our methods robust against network failure, while they produce accurate clustering and converge extremely fast.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-140.pdf
2014,Selective Neural Network Ensembles in Reinforcement Learning,"Stefan Faußer, Friedhelm Schwenker","Ensemble models can achieve more accurate predictions than single learners. Selective ensembles further improve the predictions by selecting an informative subset of the full ensemble. We consider reinforcement learning ensembles, where the members are neural networks. In this context we study a new algorithm for ensemble subset selection in reinforcement learning scenarios. The aim of the proposed learning strategy is to minimize the Bellman errors of the collected states. In the empirical evaluation, two benchmark applications with large state spaces have been considered, namely SZ-Tetris and generalized maze. Here, our selective ensemble algorithm significantly outperforms other approaches.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-128.pdf
2014,Learning resets of neural working memory,"Jaldert O. Rombouts, Pieter Roelfsema, Sander Bohte","Working memory is a key component of intelligence that the brain implements as persistent neural activations. How do persistent neurons learn to store information, and how can they be made to forget this information once it is no longer relevant? When animals learn episodic tasks, neurons in prefrontal cortex learn to represent task ends. We show that a biologically plausible neural network model equipped with persistent memory and a `reset' action can learn to store and forget information at task ends by reinforcement learning. The new model has competitive performance compared to a variety of (biologically implausible) models.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-130.pdf
2014,Classifying Patterns in a Spiking Neural Network,"Brian Gardner, André Grüning","Learning rules for spiking neural networks have emerged that can classify spatio-temporal spiking patterns as precise target spike trains, although there remains uncertainty in which rule to select that offers  the greatest performance. Here, we quantify the performance of a stochastic neuron model in learning to classify input patterns by precise target responses as outputs, and compare its performance against other learning rules. We achieve a level of performance that is comparable with that found previously for alternative neuron models, and demonstrate the advantages of classifying inputs by multiple-spike timings: both by increasing the performance and the reliability of classifications.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-172.pdf
2014,A new biologically plausible supervised learning method for spiking neurons,"Aboozar Taherkhani, Ammar Belatreche, Yuhua Li, Liam Maguire","STDP is believed to play an important role in learning and memory. Additionally, experimental evidence shows that a few strong neural inputs can drive a neuron response and subsequently affect learning of other inputs. Furthermore, recent studies have shown that local dendritic depolarization can impact STDP induction. This paper integrates these three biological concepts to devise a new biologically plausible supervised learning method for spiking neurons. Experimental results show that the proposed method can effectively map a random spatiotemporal input pattern to a random target output spike train with a much faster learning speed than ReSuMe.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-50.pdf
2014,Spiking Neural Networks: Principles and Challenges,"André Grüning, Sander Bohte",,Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-13.pdf
2015,A WiSARD-based multi-term memory framework for online tracking of objects,"Daniel Nascimento, Rafael Carvalho, Félix Mora-Camino, Priscila Lima, Felipe França","In this paper it is proposed a generic object tracker with real- time performance. The proposed tracker is inspired on the hierarchical short-term and medium-term memories for which patterns are stored as discriminators of a WiSARD weightless neural network. This approach is evaluated through benchmark video sequences published by Babenko et al. Experiments show that the WiSARD-based approach outperforms most of the previous results in the literature, with respect to the same dataset.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-26.pdf
2015,Certainty-based prototype insertion/deletion for classification with metric adaptation,"Lydia Fischer, Barbara Hammer, Heiko Wersing","We propose an extension of prototype-based classification models to automatically adjust model complexity, thus offering a powerful technique for online, incremental learning tasks. The incremental technique is based on the notion of the certainty of an observed classification. Unlike previous work, we can incorporate matrix learning into the framework by relying on the cost function of generalised learning vector quantisation (GLVQ) for prototype insertion, deletion, as well as training. In several benchmarks, we demonstrate that the proposed method provides comparable results to offline counterparts and an incremental support vector machine, while enabling a better control of the required memory.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-88.pdf
2015,Combining dissimilarity measures for prototype-based classification,"Ernest Mwebaze, Gjalt Bearda, Michael Biehl, Dietlind Zuehlke","Prototype-based classification has been used successfully for classification tasks where interpretability of the output of the system is key.  Prototypes are representative of the data and, together with a suitable measure of dissimilarity,  parameterize the classifier. In many practical problems, the same object is represented by a collection of qualitatively different subsets of features, each of which might require a different dissimilarity measure. In this paper we present a novel technique for combining different dissimilarity measures into one classification scheme for heterogeneous, mixed data.  To illustrate the method we apply a select class of prototype-based classifiers, LVQ, to the problem of diagnosing viral crop disease in cassava plants. We combine different dissimilarity measures related to features extracted from leaf images including histograms (HSV) and shape features (SIFT). Our results show the feasibility of the method, increased performance compared to previous methods and improved interpretability of the systems.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-73.pdf
2015,Multi-objective optimization perspectives on reinforcement learning algorithms using reward vectors,Madalina  Drugan,"Reinforcement learning is a machine learning area that studies which actions an agent can take in order to optimize a cumulative reward function.  Recently, a new class of reinforcement learning algorithms with multiple, possibly conflicting, reward functions was proposed. We call this class of algorithms the multi-objective reinforcement learning (MORL) paradigm. We give an overview on multi-objective optimization techniques imported in MORL and their theoretical simplified variant with a single state, namely the multi-objective multi-armed bandits (MOMAB) paradigm.",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-15.pdf
2015,Thompson Sampling for Multi-Objective Multi-Armed Bandits Problem,"Saba Yahyaa, Bernard Manderick","The multi-objective, multi-armed bandit (MOMAB) problem is a Markov decision process with stochastic rewards. Each arm generates a vector of rewards instead of a single scalar reward. Moreover, these multiple rewards might be conflicting. The MOMAB-problem has a set of Pareto optimal arms and an agent's goal is not only to find that set but also to play evenly or fairly the arms in that set.  To find the Pareto optimal arms, linear scalarized function or Pareto dominance relations approach can be used. The linear scalarized function converts the multi-objective optimization problem into a single objective one and is very popular approach because of its simplicity. The Pareto dominance relations optimizes directly the multi-objective problem. In this paper, we extend Thompson Sampling policy to be used in the $MOMAB$ problem. We propose Pareto Thompson Sampling and linear scalarized Thompson Sampling approaches. We compare empirically between Pareto Thompson Sampling and linear scalarized Thompson Sampling on a test suite of MOMAB problems with Bernoulli distributions. Pareto Thompson Sampling is the approach with the best empirical performance.",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-27.pdf
2015,Learning matrix quantization and variants of relevance learning,"Kristin Domaschke, Marika Kaden, Mandy Lange, Thomas Villmann","We propose an extension of the learning vector quantization framework for matrix data. Data in matrix form occur in several areas like gray-scale images, time dependent spectra or fMRI data. If the matrix data are vectorized, important spatial information may be lost. Thus, processing matrix data in matrix form seems to be more appropriate. However, it requires matrix dissimilarities for data comparison. Here Schatten-$p$-norms come into play. We show that they can be used in a natural way replacing the vector dissimilarities in the learning framework. Moreover, we transfer the concept of vector relevance learning also to this new matrix variant. We apply the resulting learning matrix quantization approach to the classification of time-dependent fluorescence spectra as an exemplary real world application.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-35.pdf
2015,Pareto Local Search for MOMDP Planning,"Chiel Kooijman, Maarten De Waard, Maarten Inja, Diederik Roijers, Shimon Whiteson","Standard single-objective methods such as dynamic programming are not applicable to Markov decision processes (MDPs) with multiple objectives because they depend on a maximization function over rewards, which is not defined if the rewards are multi-dimensional. As a result, special multi-objective algorithms are needed to find a set of policies that contains all optimal trade-offs between objectives, i.e. a set of Pareto-optimal policies. In this paper, we propose Pareto Local Policy Search (PLoPS), a new planning method for multi-objective MDPs (MOMDPs) based on Pareto Local Search (PLS). This method produces a good set of policies by iteratively scanning the neighbourhood of locally non-dominated policies for improvements. It is fast because neighbouring policies can be quickly identified as improvements, and their values can be computed incrementally. We test the performance of PLoPS on several MOMDP benchmarks, and compare it to popular decision-theoretic and evolutionary alternatives. The results indicate that PLoPS outperforms the alternatives.",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-65.pdf
2015,Bernoulli bandits: an empirical comparison,"Nixon Ronoh, Reuben Odoyo, Edna Milgo, Madalina  Drugan, Bernard Manderick","We compare empirically a representative sample of action selection policies on a test suite of Bernoulli multi-armed bandit problems. For such problems the rewards are either success or failure having a Bernoulli distribution with unknown success probability. The number of arms in our test suite ranges from small to large and for each number of arms we consider several distributions of the success probabilities. Our selection consists of the following action selection policies: &#949;-greedy, UCB1- Tuned, Thompson sampling, the Gittins index policy, and the knowledge gradient. In this paper, we report the case of ten arms. A forthcoming technical report will include other than Bernoulli bandits and it describes the experimental results for all multi-armed bandit problems for several parameter settings.",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-33.pdf
2015,Comparison of Numerical Models and Statistical Learning for Wind Speed Prediction,"Nils André Treiber, Stephan Späth, Justin Heinermann, Lueder von Bremen, Oliver Kramer","After decades of dominating wind forecasts based on numerical weather predictions, statistical models gained attention for shortest-term forecast horizons in the recent past. A rigorous experimental comparison between both model types is rare. In this paper, we compare COSMO-DE EPS forecasts from the German Meteorological Service (DWD) post-processed with non-homogeneous Gaussian regression to a multivariate support vector regression model. Further, a hybrid model is introduced that employs a weighted prediction of both approaches.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-31.pdf
2015,Learning Recurrent Dynamics using Differential Evolution,"Sebastian Otte, Fabian Becker, Martin V. Butz, Marcus Liwicki, Andreas Zell","This paper presents an efficient and powerful approach for learning dynamics with Recurrent Neural Networks (RNNs). No specialized or fine-tuned RNNs are used but rather standard RNNs with one fully connected hidden layer. The training procedure bases on a variant of Differential Evolution (DE) with a novel mutation schema that allows to reduce the population size in our setup down to five, but still yields very good results even within a few generations. For several common Multiple Superimposed Oscillator (MSO) instances new state-of-the-art results are presented, which are across the board multiple magnitudes better than the achieved results published so far. Furthermore, for new and even more difficult instances, i.e., MSO9-MSO12, our setup achieves lower error rates than reported previously for the best system on MSO8.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-118.pdf
2015,Solar PV Power Forecasting Using Extreme Learning Machine and Information Fusion,"Hélène Le Cadre, Ignacio Aravena, Anthony Papavasiliou","We provide a learning algorithm combining distributed Extreme Learning Machine and an information fusion rule based on the aggregation of experts advice, to build day ahead probabilistic solar PV power production forecasts. These forecasts use, apart from the current day solar PV power production, local meteorological inputs, the most valu- able of which is shown to be precipitation. Experiments are then run in one French region, Provence-Alpes-Côte d'Azur, to evaluate the algorithm performance.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-39.pdf
2015,Gaussian process modelling of multiple short time series,"Hande Topa, Antti Honkela","We study effective Gaussian process (GP) modelling of multiple short time series. These problems are common for example when applying GP models independently to each gene in a gene expression time series data set. Such sets typically contain very few time points and hence naive application of common GP modelling techniques can lead to severe overfitting in a significant fraction of the fitted models, depending on the details of the data set. We propose avoiding overfitting by constraining the GP length-scale to values that are compatible with the spacing of the time points. We demonstrate that this eliminates otherwise serious overfitting in real experiment using GP model to rank SNPs based on their likelihood of being under natural selection.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-54.pdf
2015,Long Short Term Memory Networks for Anomaly Detection in Time Series,"Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, Puneet Agarwal","Long Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length, due to their ability to maintain long term memory. Stacking recurrent hidden layers in such networks also enables the learning of higher level temporal features, for faster learning with sparser representations. In this paper, we use stacked LSTM networks for anomaly/fault detection in time series.  A network is trained on non-anomalous data and used as a predictor over a number of time steps. The resulting prediction errors are modeled as a multivariate Gaussian distribution, which is used to assess the likelihood of anomalous behavior. The efficacy of this approach is demonstrated on four datasets: ECG, space shuttle, power demand, and multi-sensor engine dataset.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-56.pdf
2015,Memory Transfer in DRASiW–like Systems,"De gregorio Massimo, Giordano Maurizio","DRASiW is an extension of a Weightless NN model, namely WiSARD, with the capability of storing, in an internal data structure called “mental image” (MI), the frequencies of seen patterns during the training stage. Due to these capabilities together with the possibility to reversely process MIs to generate synthetic prototypes of train samples, in this paper we show how, in DRASiW–like systems, it is possible to transfer the memory between different systems preserving the functionalities.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-100.pdf
2015,Median-LVQ for classification of dissimilarity data based on ROC-optimization,"David Nebel, Thomas Villmann","In this article we consider a median variant of the learning vector quantization (LVQ) classifier for classification of dissimilarity data. However, beside the median aspect, we propose to optimize the receiver-operating characteristics (ROC) instead of the classification accuracy. In particular, we present a probabilistic LVQ model with an adaptation scheme based on a generalized Expectation-Maximization-procedure, which allows a maximization of the area under the ROC-curve for those dissimilarity data. The basic idea behind is the utilization of ordered pairs as a structured input for learning. The new scheme can be seen as a supplement to the recently introduced LVQ-scheme for ROC-optimization of vector data.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-68.pdf
2015,Learning features on tear film lipid layer classification,"Beatriz Remeseiro, Veronica Bolon-Canedo, Amparo Alonso-Betanzos, Manuel G. Penedo","Dry eye is a prevalent disease which leads to irritation of the ocular surface, and is associated with symptoms of discomfort and dryness. The Guillon tear film classification system is one of the most common procedures to diagnose this disease. Previous research has demonstrated that this classification can be automatized by means of image processing and machine learning techniques. However, all approaches for automatic classification have been focused on dark eyes, since they are most common in humans. This paper introduces a methodology making use of feature selection methods, to learn which features are the most relevant for each type of eyes and, thus, improving the automatic classification of the tear film lipid layer independently of the color of the eyes. Experimental results showed the adequacy of the proposed methodology, achieving classification rates over 90%, while producing unbiased results and working in real-time.",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-83.pdf
2015,ESNigma: efficient feature selection for echo state networks,"Davide Bacciu, Filippo Benedetti, Alessio Micheli","The paper introduces a feature selection wrapper designed specifically for Echo State Networks. It defines a feature scoring heuristics, applicable to generic subset search algorithms, which allows to reduce the need for model retraining with respect to wrappers in literature. The experimental assessment on real-word noisy sequential data shows that the proposed method can identify a compact set of relevant, highly predictive features with as little as $60\%$ of the time required by the original wrapper.",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-104.pdf
2015,Discovering temporally extended features for reinforcement learning in domains with delayed causalities,"Robert Lieck, Marc Toussaint","Discovering temporally delayed causalities from data raises notoriously hard problems in reinforcement learning. In this paper we define a space of temporally extended features, designed to capture such causal structures, using a generating operation. Our discovery algorithm PULSE exploits the generating operation to efficiently discover a sparse subset of features. We provide convergence guarantees and apply our method to train a model-based as well as a model-free agent in different domains. In terms of achieved rewards and the number of required features our methods can achieve much better results than other feature expansion methods.",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-52.pdf
2015,Feature and kernel learning,"Veronica Bolon-Canedo, Michele Donini, Fabio Aiolli","Feature selection and weighting has been an active research area in the last few decades finding success in many different applications. With the advent of Big Data, the adequate identification of the relevant features has converted feature selection in an even more indispensable step. On the other side, in kernel methods features are implicitly represented by means of feature mappings and kernels. It has been shown that the correct selection of the kernel is a crucial task, as long as an erroneous selection can lead to poor performance. Unfortunately, manually searching for an optimal kernel is a time-consuming and a sub-optimal choice. This tutorial is concerned with the use of data to learn features and kernels automatically. We provide a survey of recent methods developed for feature selection/learning and their application to real world problems, together with a review of the contributions to the ESANN 2015 special session on Feature and Kernel Learning.",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-13.pdf
2015,I see you: on neural networks for indoor geolocation,"Johannes Pohl, Andreas Noack","We propose a new passive system for indoor localization of mobile nodes. After the setup, our system only relies on arbitrary wireless communication from the nodes, whereby neither the mobile nodes nor the communication needs to be under our control. The presented system is composed of three Artificial Neural Networks (ANN) using a radiomap approach and the Received Signal Strength (RSS) for localization. A Probabilistic Neural Network (PNN) decides between two Generalized Regression Neural Networks (GRNN) that process the actual RSS measurement. In practical experiments we achieve a mean location error of 0.58m which is 22.64% better than a single GRNN approach in our setup.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-2.pdf
2015,The use of RBF neural network to predict building’s corners hygrothermal behavior,"Roberto Z. Freire, Gerson H. dos Santos, Leandro dos S. Coelho, Viviana C. Mariani, Divani da S. Carvalho","In this paper, a radial basis function neural network (RBF-NN) was combined with two optimization techniques, the expectation-maximization clustering method was used to tune the Gaussian activation functions centers, and the differential evolution was adopted to optimize the spreads and to local search of the centers. The modified RBF-NN was employed to predict building corners hygrothermal behavior. These specific regions of buildings are still barely explored due to modelling complexity, high computer run time, numerical divergence and highly moisture-dependent properties. Moreover, these specific building areas are constantly affected by moisture accumulation and mould growth, conditions that favor structure damages.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-67.pdf
2015,Predicting the profitability of agricultural enterprises in dairy farming,"Maria Yli-Heikkilä, Jukka Tauriainen, Mika Sulkava","Profitability and other economic aspects of agriculture can be analyzed using various machine learning methods. In this paper, we compare linear, additive and recursive partitioning -based models for predicting the profitability of farms using information easily available to a dairy farmer. We find that an ensemble of recursive partitioning methods provides the best prediction accuracy. We also analyze the importance of the predictor variables. These findings may turn out to be useful in increasing our understanding of the factors affecting farm profitability and developing a web-service for farmers to predict the performance of their own farm enterprise.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-29.pdf
2015,Measuring scoring efficiency through goal expectancy estimation,"Héctor Ruiz, Paulo Lisboa, Paul Neilson, Warren Gregson","Association football is characterized by the lowest scoring rate of all major sports. A typical value of less than 3 goals per game makes it difficult to find strong effects on goal scoring. Instead of goals, one can focus on the production of shots, increasing the available sample size. However, the value of shots depends heavily on different factors, and it is important to take this variability into account. In this paper, we use a multilayer perceptron to build a goal expectancy model that estimates the conversion probability of shots, and use it to evaluate the scoring performance of Premier League footballers.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-126.pdf
2015,A new fuzzy neural system with applications,"Yuanyuan Chai, Jun Chen, Wei Luo","Through a comprehensive study of existing fuzzy neural systems, this paper presents a Choquet integral-OWA operator based fuzzy neural system named AggFNS as a new hybrid method of CI, which has advantages in universal fuzzy inference operators and importance factor expression during reasoning process. AggFNS was applied in traffic level of service evaluation problem and the experimental results showed that AggFNS has great nonlinear mapping function and approximation capability by training, which could be used for complex systems modeling, prediction and control.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-23.pdf
2015,Reducing offline evaluation bias of collaborative filtering,"Arnaud de Myttenaere, Boris Golden, Bénédicte Le Grand, Fabrice Rossi","Recommendation systems have been integrated into the majority of large online systems to filter and rank information according to user profiles. This process influences the way users interact with the system and, as a consequence,bias the evaluation of a recommendation algorithm computed using historical data (via offline evaluation). This paper presents the state of the art of the solutions to reduce this bias and a new application for a collaborative filtering.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-90.pdf
2015,Training Multi-Layer Perceptron with Multi-Objective Optimization and Spherical Weights Representation,"Honovan Rocha, Marcelo Costa, Antônio Braga",This paper proposes a novel representation of the parameters of neural networks in which the weights are projected into a new space defined by a radius r and a vector of angles theta. This spherical representation further simplifies the multi-objective learning problem in which error and norm functions are optimized to generate Pareto sets. Using spherical weights the error is minimized using a mono objective problem to the vector of angles whereas the radius (or norm) is fixed. Results indicate that spherical weights generate more reliable and accurate Pareto set estimates as compared to standard multi-objective approach.,Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-125.pdf
2015,Ensemble Learning with Dynamic Ordered Pruning for Regression,"Kaushala Dias, Terry Windeatt","A novel method of introducing diversity into ensemble learning predictors for regression problems is presented. The proposed method prunes the ensemble while simultaneously training, as part of the same learning process. Here not all members of the ensemble are trained, but selectively trained, resulting in a diverse selection of ensemble members that have strengths in different parts of the training set. The result is that the prediction accuracy and generalization ability of the trained ensemble is enhanced. Pruning heuristics attempt to combine accurate yet complementary members; therefore this method enhances the performance by dynamically modifying the pruned aggregation through distributing the ensemble member selection over the entire dataset. A comparison is drawn with Negative Correlation Learning and a static ensemble pruning approach used in regression to highlight the performance improvement yielded by the dynamic method. Experimental comparison is made using Multiple Layer Perceptron predictors on benchmark datasets.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-135.pdf
2015,Survival Analysis with Cox Regression and Random Non-linear Projections,"Samuel Branders, Benoît Frénay, Pierre Dupont","Proportional Cox hazard models are commonly used in survival analysis, since they define risk scores which can be directly interpreted in terms of hazards.  Yet they cannot account for non-linearities in their covariates.  This paper shows how to use random non-linear projections to efficiently address this limitation.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-81.pdf
2015,Using the Mean Absolute Percentage Error for Regression Models,"Arnaud de Myttenaere, Boris Golden, Bénédicte Le Grand, Fabrice Rossi",We study in this paper the consequences of using the Mean Absolute Percentage Error (MAPE) as a measure of quality for regression models. We show that finding the best model under the MAPE is equivalent to doing weighted Mean Absolute Error (MAE) regression. We show that universal consistency of Empirical Risk Minimization remains possible using the MAPE instead of the MAE.,Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-107.pdf
2015,Using self-organizing maps for regression: the importance of the output function,"Thomas Hecht, Mathieu Lefort, Alexander Gepperth","Self-organizing map (SOM) is a powerful paradigm that is extensively applied for clustering and visualization purpose. It is also used for regression learning, especially in robotics, thanks to its ability to provide a topological projection of high dimensional non linear data. In this case, data extracted from the SOM are usually restricted to the best matching unit (BMU), which is the usual way to use SOM for classification, where class labels are attached to individual neurons. In this article, we investigate the influence of considering more information from the SOM than just the BMU when performing regression. For this purpose, we quantitatively study several output functions for the SOM, when using these data as input of a linear regression, and find that the use of additional activities to the BMU can strongly improve regression performance. Thus, we propose an unified and generic framework that embraces a large spectrum of models from the traditional way to use SOM, with the best matching unit as output, to models related to the radial basis function network paradigm, when using local receptive field as output.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-77.pdf
2015,"Hierarchical, prototype-based clustering of multiple time series with missing values","Pekka Wartiainen, Tommi Kärkkäinen","A novel technique to divide a given set of multiple time series containing missing values into disjoint subsets is proposed. With the hierarchical approach that combines a robust clustering algorithm and multiple cluster indices, we are able to generate a dynamic decision tree like structure to represent the original data in the leaf nodes. The whole algorithm is first described and then experimented with one particular data set from the UCI repository, already used in [Kärkkäinen et al., 2014] for a similar exploration. The obtained results are very promising.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-91.pdf
2015,Graphs in machine learning. An introduction,"Pierre Latouche, Fabrice Rossi",,Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-14.pdf
2015,Exact ICL maximization in a non-stationary time extension of latent block model for dynamic networks,"Marco Corneli, Pierre Latouche, Fabrice Rossi","The latent block model (LBM) is a powerful probabilistic tool to describe  interactions between node sets in bipartite networks, but it does not account for interactions of time varying intensity between nodes in unknown  classes. Here we propose a non stationary temporal extension of the  LBM that clusters simultaneously the two node sets of  a bipartite network and constructs classes of time intervals on which interactions are stationary.  The number of clusters as well as the membership to classes are obtained by maximizing the exact complete-data integrated likelihood by means of a greedy search approach. Experiments on simulated and real data  illustrate the potentialities of such a model.",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-106.pdf
2015,Exploiting the ODD framework to define a novel effective graph kernel,"Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti","In this paper, we show how the Ordered Decomposition DAGs kernel framework,  a framework that allows the definition of graph kernels from tree kernels, allows to easily define new state-of-the-art graph kernels. Here we consider a quite fast graph kernel based on the Subtree kernel (ST), and we improve it by increasing its expressivity by adding new features involving partial tree features. While the worst-case complexity of the new obtained graph kernel does not increase, its effectiveness is improved, as shown on several chemical datasets, reaching state-of-the-art performances.",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-130.pdf
2015,Gabriel Graph for Dataset Structure and Large Margin Classification: A Bayesian Approach,"Luiz Carlos Torres, Cristiano Castro, Antônio Braga","This paper presents a geometrical approach for obtaining large margin classifiers. The method aims at exploring the geometrical properties of the dataset from the structure of a Gabriel graph, which represents pattern relations according to a given distance metric, such as the Euclidean distance. Once the graph is generated, geometric vectors, analogous to SVM's support vectors are obtained in order to yield the final large margin solution from a Gaussian mixture model approach. Preliminary experiments have shown that the solutions obtained with the proposed method are close to those obtained with SVMs.",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-132.pdf
2015,Supervised Manifold Learning with Incremental Stochastic Embeddings,Oliver Kramer,"[Comment: paper may also fit into Session: ""Unsupervised nonlinear dimensionality reduction?""]  In this paper, we introduce an incremental dimensionality reduction approach for labeled data. The algorithm incrementally samples in latent space and chooses a solution that minimizes the nearest neighbor classification error taking into account label information. We introduce and compare two optimization approaches to generate supervised embeddings, i.e., an incremental solution construction method and a re-embedding approach. Both methods have in common that the objective is to minimize the nearest neighbor classification error computed in the low-dimensional space. The resulting  embedding is a surrogate of the high-dimensional labeled set. The set allows conclusions about the data set structure and can be used as preprocessing step for classification of labeled patterns.",Manifold learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-109.pdf
2015,Rank-constrained optimization: a Riemannian manifold approach,"Guifang Zhou, Wen Huang, Gallivan Kyle, Van Dooren Paul, Pierre-Antoine Absil",This paper presents an algorithm that solves  optimization problems on a matrix manifold $mathcal{M} subseteq mathbb{R}^{m times n}$  with an additional rank inequality constraint. New geometric objects are defined to facilitate efficiently finding a suitable rank. The convergence properties of the algorithm are given and a weighted low-rank approximation problem is used to illustrate the efficiency and effectiveness of the algorithm.,Manifold learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-99.pdf
2015,A State-Space Model for the Dynamic Random Subgraph Model,"RAwyia zreik, Pierre Latouche, Charles Bouveyron","In recent years, many random graph models have been proposed to extract information from networks. The principle is to look for groups of vertices with  homogenous connection profiles. Most of these models are suitable for static networks and can handle different types of edges. This work is motivated by the need of analyzing an evolving network describing email communications between employees of the Enron compagny where social positions play an important role. Therefore, in this paper, we consider the random subgraph model (RSM) which was proposed recently to model networks through latent clusters built within known partitions. Using a state space model to characterize the cluster proportions, RSM is then extended in order to deal with dynamic networks. We call the latter the dynamic random subgraph model (dRSM).",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-87.pdf
2015,Model Selection for Big Data: Algorithmic Stability and Bag of Little Bootstraps on GPUs,"Luca Oneto, Bernardo Pilarz, Alessandro Ghio, Davide Anguita","Model selection is a key step in learning from data, because it allows to select optimal models, by avoiding both under- and over-fitting. However, in the Big Data framework, the effectiveness of a model selection approach is assessed not only through the accuracy of the learned model but also through the time and computational resources needed to complete the procedure. In this paper, we propose two model selection approaches for Least Squares Support Vector Machine (LS-SVM) classifiers, based on Fully-empirical Algorithmic Stability (FAS) and Bag of Little Bootstraps (BLB). The two methods scale sub-linearly respect to the size of the learning set and, therefore, are well suited for big data applications. Experiments are performed on a Graphical Processing Unit (GPU), showing up to 30x speed-ups with respect to conventional CPU-based implementations.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-50.pdf
2015,Solving constrained Lasso and Elastic Net using nu-SVMs,"Carlos M. Alaíz, Alberto Torres, José R. Dorronsoro","Many important linear sparse models have at its core the Lasso problem, for which the GLMNet algorithm is often considered as the current state of the art. Recently M. Jaggi has observed that Constrained Lasso (CL) can be reduced to a SVM-like problem, which opens the way to use efficient SVM algorithms to solve CL. We will refine Jaggi's arguments to reduce CL as well as constrained Elastic Net to a Nearest Point Problem and show experimentally that the well known LIBSVM library results in a faster convergence than GLMNet for small problems and also, if properly adapted, for larger ones.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-95.pdf
2015,Assessment of feature saliency of MLP using analytic sensitivity,Tommi Kärkkäinen,"A novel technique to determine the saliency of features for the multilayer perceptron (MLP) neural network is presented. It is based on the analytic derivative of the feedforward mapping with respect to inputs, which is then integrated over the training data using the mean of the absolute values. Experiments demonstrating the viability of the approach are given with small benchmark data sets. The cross-validation based framework for reliable determination of MLP that has been used in the experiments was introduced in Kärkkäinen et al. (ESANN 2014, pp. 213-218) and Kärkkäinen (LNCS 8621, pp. 291-300).","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-10.pdf
2015,Morisita-based feature selection for regression problems,"Jean Golay, Michael Leuenberger, Mikhaïl Kanevski","Data acquisition, storage and management have been improved, while the factors of many phenomena are not well known. Consequently, irrelevant and redundant features artificially increase the size of datasets, which complicate learning tasks, such as regression. To address this problem, feature selection methods have been proposed. This research introduces a new supervised filter based on the Morisita estimator of intrinsic dimension. The algorithm is simple and does not rely on arbitrary parameters. It is applied to both synthetic and real data and a comparison with a wrapper based on extreme learning machine is conducted.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-41.pdf
2015,A new genetic algorithm for multi-label correlation-based feature selection,"Suwimol Jungjit, Alex Freitas","This paper proposes a new Genetic Algorithm for Multi-Label Correlation-Based Feature Selection (GA-ML-CFS). This GA performs a global search in the space of candidate feature subsets, in order to select a high-quality feature subset that is used by a multi-label classification algorithm – in this work, the Multi-Label k-NN algorithm. We compare the results of GA-ML-CFS with the results of the previously proposed Hill-Climbing for Multi-Label Correlation-Based Feature Selection (HC-ML-CFS), across 10 multi-label datasets","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-48.pdf
2015,Search Strategies for Binary Feature Selection for a Naive Bayes Classifier,"Tsirizo Rabenoro, Jérôme Lacaille, Marie Cottrell, Fabrice Rossi",We compare in this paper several feature selection methods for the Naive   Bayes Classifier (NBC) when the data under study are described by a large   number of redundant binary indicators. Wrapper approaches guided by the NBC   estimation of the classification error probability outperform filter   approaches while retaining a reasonable computational cost.,"Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-102.pdf
2015,Advances in learning analytics and educational data mining,"Mehrnoosh Vahdat, Alessandro Ghio, Luca Oneto, Davide Anguita, Mathias Funk, Matthias Rauterberg","The growing interest in recent years towards Learning Analytics (LA) and Educational Data Mining (EDM) has enabled novel approaches and advancements in educational settings. The wide variety of research and practice in this context has enforced important possibilities and applications from adaptation and personalization of Technology Enhanced Learning (TEL) systems to improvement of instructional design and pedagogy choices based on students needs. LA and EDM play an important role in enhancing learning processes by offering innovative methods of development and integration of more personalized, adaptive, and interactive educational environments. This has motivated the organization of the ESANN 2015 Special Session in Advances in Learning Analytics and Educational Data Mining. Here, a review of research and practice in LA and EDM is presented accompanied by the most central methods, benefits, and challenges of the field. Additionally, this paper covers a review of novel contributions into the Special Session.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-18.pdf
2015,Asynchronous decentralized convex optimization through short-term gradient averaging,"Jérôme FELLUS, David Picard, Philippe-Henri Gosselin","This paper considers decentralized convex optimization over a network in large scale contexts, where large simultaneously applies to number of training examples, dimensionality and number of networking nodes. We first propose a centralized optimization scheme that generalizes successful existing methods based on gradient averaging, improving their flexibility by making the number of averaged gradients an explicit parameter of the method. We then propose an asynchronous distributed algorithm that implements this original scheme for large decentralized computing networks.",Manifold learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-131.pdf
2015,Data Analytics for Drilling Operational States Classifications,"Galina Veres, Zoheir Sabeur","This paper provides benchmarks for the identification of best performance classifiers for the detection of operational states in industrial drilling operations. Multiple scenarios for the detection of the operational states are tested on a rig with various drilling wells. Drilling data are extremely challenging due to their non-linear and stochastic natures, notwithstanding the embedded noise in them and unbalancing. Nevertheless, there is a possibility to deploy robust classifiers to overcome such challenges and achieve good automated detection of states. Three classifiers with best classification rates of drilling operational states were identified in this study.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-85.pdf
2015,Prediction of concrete carbonation depth using decision trees,"Woubishet Taffese, Esko Sistonen , Jari  Puttonen","In this paper, three carbonation depth predicting models using decision tree approach are developed. Carbonation, in urban area, is the major causes of reinforcement steel corrosion that causes premature degradation, loss of serviceability and safety of reinforced concrete structures. The adopted decision trees are regression tree, bagged ensemble and reduced bagged ensemble regression tree. The evaluation of the models predictions performance reveals that all three models perform reasonably well. Among the models, reduced bagged ensemble regression tree has a highest prediction and generalization capability.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-79.pdf
2015,Powered-Two-Wheeler safety critical events recognition using a mixture model with quadratic logistic functions,"Ferhat ATTAL, Abderrahmane Boubezoul, Allou Samé, Latifa Oukhellou","This paper presents a simple and efficient methodology that uses both acceleration and angular velocity signals to detect critical safety events for Powered Two Wheelers (PTW). The problem of recognition of critical events has been performed with the help of two steps: (1) the feature extraction step, where the multidimensional time trajectories of accelerometer/gyroscope data were modelled and segmented by using a specific mixture model with quadratic logistic functions; (2) the classifica- tion step, which consists in using the k-nearest neighbor (k-NN) algorithm in order to assign each trajectory characterized by its extracted features to one of the three classes namely Fall, near Fall and Naturalistic riding. The results show the ability of the proposed methodology to detect critical safety events for Powered Two Wheelers (PTW).",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-66.pdf
2015,Real-time activity recognition via deep learning of motion features,"Kishore Konda, Pramod Chandrashekhariah, Roland Memisevic, Jochen Triesch","Activity recognition is a challenging computer vision problem with countless applications. Here we present a real time activity recognition system using deep learning of local motion feature representations. Our approach learns to directly extract energy based motion features from video blocks. We implement the system on a distributed computing architecture and evaluate its performance on the iCub humanoid robot. We demonstrate real time performance using GPUs, paving the way for wide deployment of activity recognition systems in real world scenarios.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-76.pdf
2015,Designing semantic feature spaces for brain-reading,"Luepol Pipanmaekaporn, Ludmilla Tajtelbom, Vincent Guigue, thierry Artieres","We focus on a brain-reading task which consists in discovering the word a person is thinking of from an fMRI image of his brain. Previous studies have demonstrated the feasibility of this brain-reading task through the design of what has been called a semantic space, i.e. a continuous low dimensional space reflecting the similarity between words. Up to now better results are achieved when carefully designing the semantic space by hand, which limits the generality of the method. We propose to automatically design several semantic space from linguistic resources and to combine them in a principled way so as to reach results as accurate as when using a manually built semantic space.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-115.pdf
2015,Learning objects from RGB-D sensors using point cloud-based neural networks,"Marcelo Borghetti Soares, Pablo Barros, German Ignacio Parisi, Stefan Wermter","In this paper we present a scene understanding approach for assistive robotics based on learning to recognize different  objects from RGB-D devices. Using the depth information it is possible to compute descriptors that capture the geometrical relations among the points that constitute an object or extract features from multiple viewpoints. We developed a framework for testing different neural models that receive this depth information as input. Also, we propose a novel approach using three-dimensional RGB-D information as input to Convolutional Neural Networks. We found F1-scores greater than 0.9 for the majority of the objects tested, showing that the adopted approach is effective as well for classification.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-124.pdf
2015,A Robust Neural Robot Navigation Using a Combination of Deliberative and Reactive Control Architectures,"Dalia Marcela Rojas Castro, Arnaud Revel, Michel Ménard","This paper proposes a hybrid neural-based control architecture for robot indoor navigation. This architecture preserves all the advantages of reactive architectures such as rapid responses to unforeseen problems in dynamic environments while combining them with the global knowledge of the world used in deliberative architectures. In order to take the right decision during navigation, the reactive module allows the robot to corroborate the dynamic visual perception with the a priori knowledge of the world gathered from a previously examined floor plan. Experiments with the robot functioning based on the proposed architecture in a simple navigation scenario prove the feasibility of the approach.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-116.pdf
2015,Robust Visual Terrain Classification with Recurrent Neural Networks,"Sebastian Otte, Stefan Laible, Richard Hanten, Marcus Liwicki, Andreas Zell","A novel approach for robust visual terrain classification by generating feature sequences on repeatedly mutated image patches is presented. These sequences providing the feature vector progress under a certain image operation are learned with Recurrent Neural Networks (RNNs). The approach is studied for image patch based terrain classification for wheeled robots. Thereby, various RNN architectures, namely, standard RNNs, Long Short Term Memory networks (LSTMs), Dynamic Cortex Memory networks (DCMs) as well as bidirectional variants of the mentioned architecture are investigated and compared to recently used state-of-the-art methods for real-time terrain classification. The results show that the presented approach outperforms previous methods significantly.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-122.pdf
2015,Revisiting ant colony algorithms to seismic faults detection,"Walther Maciel, Cristina Vasconcelos, Pedro Silva, Marcelo Gattass","Seismic fault extracting is a time consuming task that can be aided by image enhancement of fault areas. The recent literature address this task by using ant colony optimization (ACO) algorithms to highlight the fault edges. This work proposes improvements to current state of the art methodologies by revisiting and/or reincorporating classic aspects of ACO, such as ant distribution, pheromone evaporation and deposition, not previously considered in this seismic fault enhancement scenario.The proposed approach arrives at good results presenting images with little noise and great localization of fault edges.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-89.pdf
2015,Depth and height aware semantic RGB-D perception with convolutional neural networks,"Hannes Schulz, Nico Höft, Sven Behnke","Convolutional neural networks are popular for image labeling tasks, because of built-in translation invariance.     They do not adopt well to scale  changes, however, and cannot easily adjust to classes     which regularly  appear in certain  scene regions.  This  is especially     true  when the  network is  applied in a  sliding window.     When depth data is available, we can address both problems.  We propose     to adjust the size of processed windows to the  depth and to supply  inferred height     above ground to the  network, which significantly improves object-class     segmentation results on the NYU depth dataset.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-101.pdf
2015,A simple technique for improving multi-class classification with neural networks,"Thomas Kopinski, Alexander Gepperth, Uwe Handmann","We present a novel method to perform multi-class pattern classification with neural networks and test it on a challenging 3D hand gesture recognition problem. Our method consists of a standard one-against-all (OAA) classification, followed by another network layer classifying the resulting class scores, possibly augmented by the original raw input vector. This allows the network to disambiguate hard-to-separate classes as the distribution of class scores carries considerable information as well, and is in fact often used for assessing the confidence of a decision. We show that by this approach we are able to significantly boost our results, overall as well as for particular difficult cases, on the hard 10-class gesture classification task.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-136.pdf
2015,Dynamic gesture recognition using Echo State Networks,"Doreen Jirak, Pablo Barros, Stefan Wermter","In the last decade, training recurrent neural networks (RNN) using techniques from the area of reservoir computing (RC) became popular for learning sequential data due to the ease of network training. Although successfully applied in the language- and speech research, only little is known about using RC techniques for dynamic gesture recognition. We therefore conduct experiments on command gestures using Echo State Networks (ESN) to investigate both the effect of different gesture sequence representations and different parameter configurations. For recognition we employ the ensemble technique, i.e. using ESN's as weak classifiers. Our results show that using ESN is a promising approach, thus we give indications for future experiments in this research area.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-128.pdf
2015,A flat neural network architecture to represent movement primitives with integrated sequencing,"Andre Lemme, Jochen Steil","The paper proposes a minimalistic network to learn a set of movement primitives and their sequencing in one single feedforward  network. Utilizing an extreme learning machine  with output feedback and a simple inhibition mechanism,  this approach can sequence movement primitives  efficiently with very moderate network size. It can interpolate movement primitives to create new motions. This work thus demonstrates that an unspecific single hidden layer, that is a flat representation is sufficient to efficiently compose complex sequences, a task which  usually requires hierarchiy, multiple timescales and multi-level control mechanisms.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-127.pdf
2015,Unsupervised dimensionality reduction: the challenge of big data visualization,"Kerstin Bunte, John Aldo Lee",,Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-16.pdf
2015,Autoencoding time series for visualisation,"Nikolaos Gianniotis, Sven Dennis Kügler, Peter Tino, Kai Polsterer, Ranjeev Misra","We present an algorithm for the visualisation of time series. To that end we employ echo state networks to convert time series into a suitable vector representation which is capable of capturing the latent dynamics of the time series. Subsequently, the obtained vector representations are put through an autoencoder and the visualisation is constructed using the activations of the “bottleneck”. The crux of the work lies with defining an objective function that quantifies the reconstruction error of these representations in a principled manner. We demonstrate the method on synthetic and real data.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-37.pdf
2015,Fast greedy insertion and deletion in sparse Gaussian process regression,"Jens Schreiter, Duy Nguyen-Tuong, Heiner Markert, Michael Hanselmann, Marc Toussaint","In this paper, we introduce a new and straightforward criterion for successive insertion and deletion of training points in sparse Gaussian process regression. Our novel approach is based on an approximation of the selection technique proposed by Smola and Bartlett. It is shown that the resulting selection strategies are as fast as the purely randomized schemes for insertion and deletion of training points. Experiments on real-world robot data demonstrate that our obtained regression models are competitive with the computationally intensive state-of-the-art methods in terms of generalization accuracy.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-12.pdf
2015,Human Algorithmic Stability and Human Rademacher Complexity,"Mehrnoosh Vahdat, Luca Oneto, Alessandro Ghio, Davide Anguita, Mathias Funk, Matthias Rauterberg","In Machine Learning (ML), the learning process of an algorithm given a set of evidences is studied via complexity measures. The way towards using ML complexity measures in the Human Learning (HL) domain has been paved by a previous study, which introduced Human Rademacher Complexity (HRC): in this work, we introduce Human Algorithmic Stability (HAS). Exploratory experiments, performed on a group of students, show the superiority of HAS against HRC, since HAS allows grasping the nature and complexity of the task to learn.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-49.pdf
2015,High-School Dropout Prediction Using Machine Learning: A Danish Large-scale Study,"Nicolae-Bogdan Sara, Rasmus Halland, Christian Igel, Stephen Alstrup","Pupils not finishing their secondary education are a big societal problem. Previous studies indicate that machine learning can be used to predict high-school dropout, which allows early interventions.  To the best of our knowledge, this paper presents the first large-scale study of that kind. It considers pupils that were at least six months into their Danish high-school education, with the goal to predict dropout in the subsequent three months.  We combined information from the MaCom Lectio study administration system, which is used by most Danish high schools, with data from public online sources (name database, travel planner, governmental statistics).  In contrast to existing studies that were based on only a few hundred students, we considered a considerably larger sample of 36299 pupils for training and 36299 for testing.  We evaluated different machine learning methods.  A random forest classifier achieved an accuracy of 93.47% and an area under the curve of 0.965. Given the large sample, we conclude that machine learning can be used to reliably detect high-school dropout given the information already available to many schools.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-86.pdf
2015,The prediction of learning performance using features of note taking activities,"Minoru Nakayama, Kouichi Mutsuura, Hiroh Yamamoto","To promote effective learning in online learning environments, the  prediction of learning performance is necessary, using various features  of learning behaviour.  In a blended learning course, participant's note taking activity  reflects learning performance, and the possibility of predicting  performance in final exams is examined using metrics of participant's   characteristics and features of the contents of notes taken during the  course.  According to the results of this prediction performance, features of  note-taking activities are a significant source of information to  predict the score of final exams.  Also, the accuracy of this prediction was evaluated using factors of  the feature extraction procedure and the course instructions.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-22.pdf
2015,"Enhancing learning at work. How to combine theoretical and data-driven approaches, and multiple levels of data?","Virpi Kalakoski, Henriikka Ratilainen, Linda Drupsteen","This research plan focuses on learning at work. Our aim is to gather empirical data on multiple factors that can affect learning for work, and to apply computational methods in order to understand the preconditions of effective learning. The design will systematically combine theory- and data-driven approaches to study (i) whether principles of effective learning found in previous studies apply to real life settings, (ii) what interactions between individual and organizational factors are related to learning outcomes, and (iii) new connections and phenomena relevant to enhance learning in real life.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-113.pdf
2015,Weighted Clustering of Sparse Educational Data,"Mirka Saarela, Tommi Kärkkäinen","Clustering as an unsupervised technique is predominantly used in unweighted settings. In this paper, we present an efficient version of a robust clustering algorithm for sparse educational data that takes the weights, aligning a sample with the corresponding population, into account. The algorithm is utilized to divide the Finnish student population of PISA 2012 (the latest data from the Programme for International Student Assessment) into groups, according to their attitudes and perceptions towards mathematics, for which one third of the data is missing. Furthermore, necessary modifications of three cluster indices to reveal an appropriate number of groups are proposed and demonstrated.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-24.pdf
2015,An affinity matrix approach for structure selection of extreme learning machines,"David Pinto, Andre Lemos, Antônio Braga","This paper proposes a novel pruning approach for Extreme Learning Machines. Hidden neurons ranking and selection are performed using a priori information expressed by affinity matrices. We show that the similarity between the affinity matrix of the input patterns and the affinity matrix of the hidden layer output patterns can be seen as a measure of the data structural retention through the network. However, from a certain similarity level, adding new hidden nodes will have small or no effect on the amount of information propagated from the input. The proposed approach automatically determines this level and hence the suitable number of hidden nodes. Experiments are performed using classification problems to validate the proposed approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-32.pdf
2015,A generalised label noise model for classification,Jakramate Bootkrajang,"Learning from labelled data is becoming more and more challenging due to inherent imperfection of training labels.  In this paper, we propose a new, generalised label noise model which is able to withstand the negative effect of both random noise and a wide range of non-random label noises.    Empirical studies using three real-world datasets with inherent annotation errors demonstrate that the proposed generalised label noise model improves, in terms of classification accuracy, over existing label noise modelling approaches.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-80.pdf
2015,On the use of machine learning techniques for the analysis of spontaneous reactions in automated hearing assessment,"Veronica Bolon-Canedo, Alba Fernández, Amparo Alonso-Betanzos, Marcos Ortega, Manuel G. Penedo","Lack of hearing is one of the most frequent sensory deficits among elder population. Its correct assessment becomes complicated for audiologists when there are severe difficulties in the communication with the patient. Trying to facilitate this task, this paper proposes a methodology for the correct classification of eye gestural reactions to the auditory stimuli by using machine learning approaches. After extracting the features from the existing videos, we applied several classifiers and managed to improve the detection of the most important classes through the use of oversampling techniques in a novel way. This methodology showed promising results, with true positive rates over 0.96 for the critical classes and global classification rates over 97%, paving the way to its inclusion in a fully automated tool.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-84.pdf
2015,Combining higher-order N-grams and intelligent sample selection to improve language modeling for Handwritten Text Recognition,"Jafar Tanha, Jesse De Does, Katrien Depuydt","We combine two techniques to improve the language mod- eling component of a Handwritten Text Recognition (HTR) system. On the one hand, we apply a previously developed intelligent sample selection approach to language model adaptation for handwritten text recognition, which exploits a combination of in-domain and out-of-domain data for construction of language models. On the other hand, we apply rescoring methods to enable more complex language modeling in HTR. It is shown that these techniques complement each other very well, and that the combination leads to a significant error reduction in a practical HTR task for historical data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-120.pdf
2015,Learning Sparse Feature Representations using Probabilistic Quadtrees and Deep Belief Nets,"Saikat Basu, Manohar Karki, Sangram Ganguly, Robert DiBiano, Supratik Mukhopadhyay, Ramakrishna Nemani","Learning sparse feature representations is a useful instrument for solving an unsupervised learning problem. In this paper, we present three labeled handwritten digit datasets, collectively called n-MNIST. Then, we propose a novel framework for the classification of handwritten digits that learns sparse representations using probabilistic quadtrees and Deep Belief Nets. On the MNIST and n-MNIST datasets, our framework shows promising results and significantly outperforms traditional Deep Belief Networks.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-40.pdf
2015,Optimal transport for semi-supervised domain adaptation,"Denis Rousselle, Stéphane Canu","Domain adaption for semi-supervised learning is still a challenging task. Indeed, available solutions are often slow and fail to provide relevant interpretations. Here we propose a new algorithm to solve this problem of semi-supervised domain adaptation efficiently, by using an adapted combination of transportation algorithms. Our empirical evidence supports our initial intuition showing the interest of the proposed method.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-61.pdf
2015,Resource-efficient Incremental learning in very high dimensions,"Alexander Gepperth, Mathieu Lefort, Thomas Hecht","We propose a three-layer neural architecture for incremental multi-class learning that remains resource-efficient even when the number of input dimensions is very high ($\ge 1000$). This so-called projection-prediction (PROPRE) architecture is strongly inspired by biological information processing in that it uses a prototype-based, topologically organized hidden layers trained with the SOM learning rule controlled by a global, task-related error signal. Furthermore, the SOM learning adapts only the weights of localized neural sub-populations that are similar to the input, which explicitly avoids the catastrophic forgetting effect of MLPs in case new input statistics are presented to the architecture. As the readout layer uses simple linear regression, the approach essentially applies locally linear models to ""receptive fields"" (RF) defined by SOM prototypes, whereas RF shape is implicitly defined by adjacent prototypes (which avoids the storage of covariance matrices that gets prohibitive for high input dimensionality). Both RF centers and shapes are jointly adapted w.r.t. input statistics and the classification task. Tests on the MNIST dataset show that the algorithm achieves compares favorably compared to the state-of-the-art LWPR algorithm at vastly decreased resource requirements.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-46.pdf
2015,One-vs-all binarization technique in the context of random forest,"Md Nasim Adnan, Md Zahidul Islam","Binarization techniques are widely used to solve multi-class classification problems. These techniques reduce the classification complexity of multi-class classification problems by dividing the original data set into two-class segments or replicas. Then a set of simpler classifiers are learnt from the two-class segments or replicas. The outputs from these classifiers are combined for final classification. Binarization can improve prediction accuracy when compared to a single classifier. However, to be declared as a superior technique, binarization techniques need to prove themselves in the context of ensemble classifiers such as Random Forest. Random Forest is a state-of-the-art popular decision forest building algorithm which focuses on generating diverse decision trees as the base classifiers. In this paper we evaluate one-vs-all binarization technique in the context of Random Forest. We present an elaborate experimental result involving ten widely used data sets from the UCI Machine Learning Repository. The experimental results exhibit the effectiveness of one-vs-all binarization technique in the context of Random Forest.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-5.pdf
2015,Improving the random forest algorithm by randomly varying the size of the bootstrap samples for low dimensional data sets,"Md Nasim Adnan, Md Zahidul Islam","The Random Forest algorithm generates quite diverse decision trees as the base classifiers for high dimensional data sets. However, for low dimensional data sets the diversity among the trees falls sharply. In Random Forest, the size of the bootstrap samples generally remains the same every time to generate a decision tree as the base classifier. In this paper we propose to vary the size of the bootstrap samples randomly within a predefined range in order to increase diversity among the trees. We conduct an elaborate experimentation on several low dimensional data sets from UCI Machine Learning Repository. The experimental results show the effectiveness of our proposed technique.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-21.pdf
2015,An Ensemble Learning Technique for Multipartite Ranking,"Stéphan Clémençon, Sylvain Robbiano","Decision tree induction algorithms, possibly combined with a consensus technique, have been recently successfully extended to multipartite ranking. It is the goal of this paper to address certain aspects of their weakness, instability and lack of smoothness namely, by proposing dedicated ensemble learning strategies. A shown by numerical experiments, bootstrap aggregation combined with a certain amount of feature randomization dramatically improve performance of such ranking methods, in terms of accuracy and robustness both at the same time.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-112.pdf
2015,PCA-based algorithm for feature score measures ensemble construction,"Andrey Filchenkov, Vladislav Dolganov, Ivan Smetannikov",Feature filtering algorithms are commonly used in feature selection for high-dimensional datasets due to their simplicity and efficacy. Each of these algorithms has its own strengths and weaknesses. Ensemble of different ranking methods is a way to provide a stable and efficacious ranking algorithm. We propose a PCA-based algorithm for filter ranking algorithms ensemble. We compared this algorithm with four other rank aggregation algorithms on five different datasets used in the NIPS-2003 feature selection challenge. We evaluated the stability of the resulting rankings and the AUC score for four classifiers learnt on resulting feature sets. The proposed method has shown better stability and above-average efficacy.,Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-114.pdf
2015,"Online multiclass learning with ""bandit"" feedback under a Passive-Aggressive approach","Hongliang Zhong, Emmanuel Daucé, Liva Ralaivola","This paper presents a new  approach to online multi-class learning with  bandit feedback. This algorithm, named PAB (Passive Agressive in Bandit) is  a variant of Online Passive-Aggressive Algorithm proposed by [Crammer, 2006], the latter being an effective framework for performing max-margin online learning. We analyze some of its operating principal, and show it to provide a good and scalable solution to the bandit classification problem,  in particular in the case of a real-world dataset where it is found to outperform the best existing methods.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-82.pdf
2015,Learning missing edges via kernels in partially-known graphs,"Senka Krivic, Sandor Szedmak, Hanchen Xiong, Justus Piater","This paper deals with the problem of learning unknown edges with attributes in a partially given multigraph. The method is an extension of the Maximum Margin Multi-Valued Regression (M³VR) to the case where those edges are characterized by different attributes. It is applied on a large scale problem where an agent tries to learn unknown object-object relations by exploiting known such relations. The method can handle not only binary relations but also complex structured relations such as text, images, collections of labels, categories, etc., which can be represented by kernels. We compared the performance with specialized state-of-art matrix completion method.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-69.pdf
2015,Pareto front of bi-objective kernel-based nonnegative matrix factorization,"Fei Zhu, Paul Honeine","The nonnegative matrix factorization (NMF) is a powerful data analysis and dimensionality reduction technique. So far, the NMF has been limited to a single-objective problem in either its linear or nonlinear kernel-based formulation. This paper presents a novel bi-objective NMF model based on kernel machines, where the decomposition is performed simultaneously in both input and feature spaces. The problem is solved employing the sum-weighted approach. Without loss of generality, we study the case of the Gaussian kernel, where the multiplicative update rules are derived and the Pareto front is approximated. The performance of the proposed method is demonstrated for unmixing hyperspectral images.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-59.pdf
2015,SMO Lattices for the Parallel Training of Support Vector Machines,"Markus Kächele, Günther Palm, Friedhelm Schwenker","In this work, a method is proposed to train Support Vector Machines in parallel. The difference to other parallel implementations is that the problem is decomposed into hierarchically connected nodes and that each node does not have to fully optimize its local problem. Instead Lagrange multipliers are filtered and transferred between nodes during runtime, with important ones ascending and unimportant ones descending inside the architecture. Experimental validation  demonstrates the advantages in terms of speed in comparison to other approaches.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-110.pdf
2015,I/S-Race: An iterative Multi-Objective Racing Algorithm for the SVM Parameter Selection Problem,"Miranda Péricles, Ricardo Silva, Ricardo Prudêncio","Finding appropriate values for the parameters of an algorithm is an important and time consuming task. Recent studies have shown that racing algorithms can effectively handle this task. This paper presents a multi-objective racing algorithm called iterative S-Race (I/S-Race), which efficiently addresses multi-objective model selection problems in the sense of Pareto optimality. We evaluate the I/S-Race for selecting parameters of SVMs, considering 20 widely-used classification datasets. The results revealed that the I/S-Race is an efficient and effective algorithm for automatic model selection, when compared to a brute-force multi-objective selection approach and the S-Race algorithm.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-34.pdf
2015,Online One-class Classification for Intrusion Detection Based on the Mahalanobis Distance,"Patric Nader, Paul Honeine, Pierre Beauseroy","Machine learning techniques have been very popular in the past decade for their ability to detect hidden patterns in large volumes of data. Researchers have been developing online intrusion detection algorithms based on these techniques. In this paper, we propose an online one-class classification approach based on the Mahalanobis distance which takes into account the covariance in each feature direction and the different scaling of the coordinate axes. We define the one-class problem by two concentric hyperspheres enclosing the support vectors of the description. We update the classifier at each time step. The tests are conducted on real data.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-45.pdf
2015,Online Learning with Operator-valued Kernels,"Julien Audiffren, Hachem Kadri","We consider the problem of learning a vector-valued function f in an online learning setting. The function f is assumed to lie in a reproducing Hilbert space of operator-valued kernels. We describe an online algorithm for learning f while taking into account the output structure. This algorithm, OLOK, extends the standard kernel-based online learning algorithm NORMA from scalar-valued to operator-valued setting. We report a cumulative error bound that holds both for classification and regression. Our experiments show that the proposed algorithm achieves good performance results with low computational cost.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-111.pdf
2015,Probabilistic Classification Vector Machine at large scale,"Frank-Michael Schleif, Andrej Gisbrecht, Peter Tino",Probabilistic kernel classifiers are effective approaches to solve classification problems but only few of them can be applied to indefinite kernels as typically observed in life science problems and are often limited to rather  small scale problems. We provide a novel batch formulation of  the Probabilistic Classification Vector Machine for large scale metric and non-metric data.,Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-7.pdf
2015,An objective function for self-limiting neural plasticity rules.,"Rodrigo Echeveste, Claudius Gros","Self-organization provides a framework for the study of systems in which complex patterns emerge from simple rules, without the guidance of external agents or fine tuning of parameters. Within this framework, one can formulate a guiding principle for plasticity in the context of unsupervised learning, in terms of an objective function. In this work we derive Hebbian, self-limiting synaptic plasticity rules from such an objective function and then apply the rules to the non-linear bars problem.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-58.pdf
2015,Towards a Tomographic Index of Systemic Risk Measures,"Kaj-Mikael Bjork, Patrick Kouontchou, Amaury Lendasse, Yoan Miché, Betrand Maillet","Due to the recent financial crisis, several systemic risk measures have been proposed in the literature for quantifying financial system wide distress. In this note we propose an aggregated Index for financial systemic risk measurement based on EOF and ICA analyses on the several systemic risk measures released in the recent literature. We use this index to further identify the states of the market as suggested in Kouontchou et al. [2013]. We show, by characterizing markets conditions with a robust Kohonen Self-Organizing Maps algorithm that this measure is directly linked to crises markets states and there is a strong link between return and systemic risk.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-108.pdf
2015,Ranking Overlap and Outlier Points in Data using Soft Kernel Spectral Clustering,"Raghvendra Mall, Rocco Langone, Johan Suykens","Soft clustering algorithms can handle real-life datasets better as they capture the presence of inherent overlapping clusters. A soft kernel spectral clustering (SKSC) method proposed in [1] exploited the eigen-projections of the points to assign them different cluster membership probabilities. In this paper, we detect points in dense overlapping regions as overlap points. We also identify the outlier points by exploiting the eigen-projections. We then propose novel ranking techniques using structure and similarity properties in the eigen-space to rank these overlap and outlier points. By ranking the overlap and outlier points we provide an order for the most and least influential points in the dataset. We demonstrate the effectiveness of our ranking measures on several datasets.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-64.pdf
2015,On the equivalence between regularized NMF and similarity-augmented graph partitioning,"Anthony Coutant, Hoel Le Capitaine, Philippe Leray","Many papers pointed out the interest of (co-)clustering both data and features in a dataset to obtain better performances than methods focused on data only. In addition, recent work have shown that data and features lie in low dimensional manifolds embedded into the original space and this information has been introduced as regularization terms in clustering objectives. Very popular and recent examples are regularized NMF algorithms. However, these techniques have difficulties to avoid local optima and require high computation times, making them inadequate for large scale data. In this paper, we show that NMF with manifolds  regularization on a binary matrix is mathematically equivalent to an edgecut partitioning in a graph augmented with manifolds information in the case of hard co-clustering. Based on these results, we explore experimentally the efficiency of regularized graph partitioning methods for hard coclustering on more relaxed datasets and show that regularized multi-level graph partitioning is much faster and often find better clustering results than regularized NMF, and other well-known algorithms.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-28.pdf
2015,Geometrical homotopy for data visualization,"Diego Hernán Peluffo-Ordóñez, Juan Carlos Alvarado-Pérez, John Aldo Lee, Michel Verleysen","This work presents an approach allowing for an interactive visualization of dimensionality reduction outcomes, which is based on an extended view of conventional homotopy. The pairwise functional followed from a simple homotopic function can be incorporated within a geometrical framework in order to yield a bi-parametric approach able to combine several kernel matrices. Therefore, the users can establish the mixture of kernels in an intuitive fashion by only varying two parameters. Our approach is tested by using kernel alternatives for conventional methods of spectral dimensional reduction such as multidimensional scalling, locally linear embedding and laplacian eigenmaps. Provided mixture represents every single dimensional reduction approach as well as helps users to find a suitable representation of embedded data.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-137.pdf
2015,NLDR methods for high dimensional NIRS dataset : application to vineyard soils characterization,"Clément Delion, Ludovic Journaux, Aurore Payen, Lucile Sautot, Emmanuel Chevigny, Pierre Curmi",In the context of vineyard soils characterizationn this paper explores and compare dierent recent Non Linear Dimensionality Reduction (NLDR) methods on a high-dimensional Near InfraRed Spectroscopy (NIRS) dataset. NLDR methods are based on k-neighborhood criterion and Euclidean and fractional distances metrics are tested.  esults show that Multiscale Jensen-Shannon Embedding (Ms JSE) coupled with euclidean distance outperform all over methods. Application on data is made at global scale and at dierent scale of depth of soil.,Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-75.pdf
2015,Efficient unsupervised clustering for spatial birds population analysis along the river Loire,"Aurore Payen, Ludovic Journaux, Clément Delion, Lucile Sautot, Bruno Faivre","This paper focuses on application and comparison of Non Linear Dimensionality Reduction (NLDR) methods on natural high dimensional bird communities dataset along the Loire River (France). In this context, biologists usually use the well-known linear PCA on their data in order to explain the longitudinal distribution pattern and find discontinuities along the upstream-downstream gradient. Unfortunately this method was unsuccessful on this kind of nonlinear dataset. The goal of this paper is to compare recent NLDR methods coupled with different data transformations in order to find out the best approach on this nonlinear real-life dataset. Results show that Multiscale Jensen-Shannon Embedding (Ms JSE) is the more successful method on this dataset.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-74.pdf
2015,Unsupervised Dimensionality Reduction for Transfer Learning,"Patrick  Blöbaum, Alexander Schulz, Barbara Hammer","We investigate the suitability of unsupervised dimensionality reduction (DR)   for transfer learning in the context of different representations of the source and target domain. Essentially, unsupervised DR establishes a link of source and target domain by representing the data in a common latent space. We consider two settings: a linear DR of source and target data which establishes correspondences of the data and an according transfer, and its combination with a nonlinear DR which allows to adapt to  more complex data characterised by a global nonlinear structure.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-134.pdf
2015,Adaptive structure metrics for automated feedback provision in Java programming,"Benjamin Paassen, Bassam Mokbel, Barbara Hammer","Today's learning supporting systems for programming mostly rely on pre-coded feedback provision, such that their applicability is restricted to modelled tasks. In this contribution, we investigate the suitability of machine learning techniques to automate this process by means of a presentation of similar solution strategies from a set of stored examples. To this end we apply structure metric learning methods in local and global alignment which can be used to compare Java programs. We demonstrate that automatically adapted metrics better identify the underlying programming strategy as compared to their default counterparts in a benchmark example from programming.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-43.pdf
2015,Diffusion Maps parameters selection based on neighbourhood preservation,"Carlos M. Alaíz, Ángela Fernández, José R. Dorronsoro","Diffusion Maps is one of the leading methods for dimensionality reduction, although it requires to fix a certain number of parameters that can be crucial for its performance. This parameter selection is usually based on the expertise of the user, as there are no unified criterion for evaluating the quality of the embedding. We propose to use a neighbourhood preservation measure as the criterion for fixing these parameters. As we shall see, this approach provides good embedding parameters without needing problem specific knowledge.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-97.pdf
2016,Deep neural network analysis of go games: which stones motivate a move?,"Thomas Burwick, Luke Ewig","Recently, deep learning was used to construct deep convolution network models for move prediction in Go. Here, we develop methods to analyze the inner workings of the resulting deep architectures. Our example network is learned and tested using a database of over 83,000 expert games with over 17 million moves. We present ways of visualizing the learned features (“shapes”) and a method to derive aspects of the motivation behind the expert’s moves. The discussed methods are inspired by recent progress made in constructing saliency maps for image classification.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-98.pdf
2016,Deep multi-task learning with evolving weights,"Soufiane Belharbi, Romain HERAULT, Clément Chatelain, Sébastien Adam",Pre-training of deep neural networks has been abandoned in the last few years. The main reason is the difficulty to control the over-fitting and tune the consequential raised number of hyper-parameters. In this paper we use a multi-task learning framework that gathers weighted supervised and unsupervised tasks. We propose to evolve the weights along the learning epochs in order to avoid the break in the sequential transfer learning used in the pre-training scheme. This framework allows the use of unlabeled data. Extensive experiments on MNIST showed interesting results.,"Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-87.pdf
2016,Adaptive dissimilarity weighting for prototype-based classification optimizing mixtures of dissimilarities,"Marika Kaden, David Nebel, Thomas Villmann","In this paper we propose an adaptive bilinear mixing of dissimilarities for better classification learning. In particular, we focus on prototype based learning like learning vector quantization. In this sense the learning of the mixture can be seen as a kind of dissimilarity learning as counterpart to dissimilarity selection in advance. We demonstrate this approach working for relational as well as median variants of prototype learning for proximity data.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-100.pdf
2016,"Study on the loss of information caused by the ""positivation"" of graph kernels for 3D shapes",Gaelle Loosli,"In the presented experimental study, we compare the classification power of two variations of the same graph kernel. One variation is designed to produce semi-definite positive kernel matrices (Kmatching) and is an approximation of  the other one, which is indefinite (Kmax).  We show that using adaptated tools to deal with indefiniteness (KSVM), the original indefinite kernel outperforms its positive definite approximate version.  We also propose a slight improvement of the KSVM method, with produces non sparse solution, by adding a fast post-processing step that gives a sparser solution.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-14.pdf
2016,Discriminative dimensionality reduction in kernel space,"Alexander Schulz, Barbara Hammer","Modern nonlinear dimensionality reduction (\DR) techniques enable an  efficient visual data inspection in the form of scatter plots, but they suffer from the fact that \DR\ is  inherently ill-posed. Discriminative dimensionality reduction (\didi) offers one remedy, since it allows a practitioner to identify  what is relevant and what should be regarded as noise by means of auxiliary information such as class labels. Powerful \didi\ methods  exist, but they are restricted to vectorial data only. In this contribution, we extend one particularly promising approach  to non-vectorial data characterised by a kernel. This enables us to apply discriminative dimensionality reduction to complex, possibly discrete or structured data.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-186.pdf
2016,Learning in inde&#64257;nite proximity spaces - recent trends,"Frank-Michael Schleif, Peter Tino, Yingyu Liang","E&#64259;cient learning of a data analysis task strongly depends on the data representation. Many methods rely on symmetric similarity or dissimilarity representations by means of metric inner products or dis-tances, providing easy access to powerful mathematical formalisms like kernel approaches. Similarities and dissimilarities are however often natu-rally obtained by non-metric proximity measures which can not easily be handled by classical learning algorithms. In the last years major e&#64256;orts have been undertaken to provide approaches which can either directly be used for such data or to make standard methods available for these type of data. We provide an overview about recent achievements in the &#64257;eld of learning with inde&#64257;nite proximities.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-22.pdf
2016,neuro-percolation as a superposition of random-walks,Gaetano Aiello,"Axons of pioneers neurons are actively directed towards their targets by signaling molecules. The result is a highly stereotyped axonal trajectory. The tip of the axon appears to proceed erratically, which has favored models of axon guidance as random-walk processes. In reality, axon guidance is basically a deterministic process, although largely unknown. Random-walk models assume noise as a representation of what is actually unknown. Wadsworth's guidance gives an experimental account of the axonal bending as induced by addition/subtraction of specific guidance agents. The axonal trajectory, however, is not a simple random-walk but a series of Wiener-Lévy stochastic processes.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-5.pdf
2016,Extending a two-variable mean to a multi-variable mean,"Estelle Massart, Julien Hendrickx, Pierre-Antoine Absil","We consider the problem of extending any two-variable mean M(·,·) to a multi-variable mean, using no other tool than M(·,·) itself. Pálfia proposed an iterative procedure that consists in evaluating successively two-variable means according to a cyclic pattern. We propose here a variant of his procedure to improve the convergence speed. Our approach consists in re-ordering the iterates after each iteration in order to speed up the transfer of information between successive iterates.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-164.pdf
2016,Bayesian semi non-negative matrix factorisation,"Albert Vilamala, Alfredo Vellido, Lluís A. Belanche","Non-negative Matrix Factorisation (NMF) has become a standard method for source identification when data, sources and mixing coefficients are constrained to be positive-valued. The method has recently been extended to allow for negative-valued data and sources in the form of Semi- and Convex-NMF. In this paper, we re-elaborate Semi-NMF within a full Bayesian framework. This provides solid foundations for parameter estimation and, importantly, a principled method to address the problem of choosing the most adequate number of sources to describe the observed data. The proposed Bayesian Semi-NMF is preliminarily evaluated here in a real neuro-oncology problem.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-62.pdf
2016,Multi-task learning for speech recognition: an overview,"Gueorgui Pironkov, Stéphane Dupont, Thierry Dutoit","Generalization is a common issue for automatic speech recognition. A successful method used to improve recognition results consists of training a single system to solve multiple related tasks in parallel. This overview investigates which auxiliary tasks are helpful for speech recognition when multi-task learning is applied on a deep learning based acoustic model. The impact of multi-task learning on speech recognition related tasks, such as speaker adaptation, or robustness to noise, is also examined.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-154.pdf
2016,Localized discriminative Gaussian process latent variable model for text-dependent speaker verification,"Nooshin Maghsoodi, Hossein Sameti, Hossein Zeinali","The duration of utterances is one of the effective factors on the performance of speaker verification systems. Text dependent speaker verification suffers from both short duration and unmatched content between enrollment and test segments. In this paper, we use Discriminative Gaussian Process Latent Variable Model (DGPLVM) to deal with the uncertainty caused by short duration. This is the first attempt to utilize Gaussian Process for speaker verification. Also, to manage the unmatched content between enrollment and test segments we proposed the localized-DGPLVM that trains DGPLVM for each phrase in dataset. Experiments show the relative improvement of 27.4% in EER on RSR2015.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-79.pdf
2016,Word Embeddings for Morphologically Rich Languages,Pyry Takala,"Word-embedding models commonly treat words as unique symbols, for which a lower-dimensional embedding can be looked up. These representations generalize poorly with morphologically rich languages, as vectors for all possible inflections cannot be stored, and words with the same stem do not share a similar representation.  We study alternative representations for words, including one subword-model and two character-based models. Our methods outperform classical word embeddings for a morphologically rich language, Finnish, on tasks requiring sophisticated understanding of grammar and context. Our embeddings are easier to implement than previously proposed methods, and can be used to form word-representations for any common language processing tasks.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-121.pdf
2016,On the equivalence between algorithms for Non-negative Matrix Factorization and Latent Dirichlet Allocation,"Thiago de Paulo Faleiros, Alneu Lopes","LDA (Latent Dirichlet Allocation ) and NMF (Non-negative Matrix Factorization) are two popular techniques to extract topics in a textual document corpus. This paper shows that NMF with Kullback-Leibler divergence approximate the LDA model under a uniform Dirichlet prior, therefore the comparative analysis can be useful to elucidate the implementation of variational inference algorithm for LDA.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-162.pdf
2016,Semi-Supervised Classification of Social Textual Data Using WiSARD,"Fabio Rangel, Fabrício de Faria, Priscila Lima, Jonice Oliveira","Text categorization is a problem which can be addressed by a semi-supervised learning classifier, since the annotation process is costly and ponderous. The semi-supervised approach is also adequate in context of social network text categorization, due to its adaptation in class distribution changes. This article presents a novel approach for semi-supervised learning based on WiSARD classifier (SSW), and compares it to others already established mechanisms (S3VM and NB-EM), over three different datasets. The novel approach shown to be up to fifty times more faster than S3VM and EM-NB with competitive accuracies.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-161.pdf
2016,Maximum likelihood learning of RBMs with Gaussian visible units on the Stiefel manifold,"Ryo Karakida, Masato Okada, Shun-ichi Amari","The restricted Boltzmann machine (RBM) is a generative model widely used as an essential component of deep networks. However, it is hard to train RBMs by using maximum likelihood (ML) learning because many iterations of Gibbs sampling take too much computational time. In this study, we reveal that, if we consider RBMs with Gaussian visible units and constrain the weight matrix to the Stiefel manifold, we can easily compute analytical values of the likelihood and its gradients. The proposed algorithm on the Stiefel manifold achieves comparable performance to the standard learning algorithm.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-170.pdf
2016,"Feature binding in deep convolution networks with recurrences, oscillations, and top-down modulated dynamics","Martin Mundt, Sebastian Blaes, Thomas Burwick","Deep convolution networks are extended with an oscillatory phase dynamics and recurrent couplings that are based on convolution and deconvolution. Moreover, top-down modulation is included that enforces the dynamical selection and grouping of features of the recognized object into assemblies based on temporal coherence. With respect to image processing, it is demonstrated how the combination of these mechanisms allow for the segmentation of the parts of the objects that are relevant for its classification.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-105.pdf
2016,Enhanced learning for agents in quantum-accessible environments,"Jacob Taylor, Hans  Briegel, Vedran Dunjko","In this paper we provide a broad framework for describing learning agents in general quantum environments. We analyze the types of classically specified environments which allow for quantum enhancements in learning, by contrasting environments to quantum oracles. We show that whether or not quantum improvements are at all possible depends on the internal structure of the quantum environment. If the environments have an appropriate structure, we show that near-generic improvements in learning times are possible in a broad range of scenarios.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-7.pdf
2016,"Supervised quantum gate ""teaching"" for quantum hardware design","Leonardo Banchi, Nicola Pancotti, Sougato Bose",We show how to train a quantum network of pairwise interacting qubits such that its evolution implements a target quantum algorithm into a given network subset. Our strategy is inspired by supervised learning and is designed to help the physical construction of a quantum computer which operates with minimal external classical control.,Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-47.pdf
2016,Performance assessment of quantum clustering in non-spherical data distributions,"Raul V. Casaña-Eslava, José D. Martín-Guerrero, Ian H. Jarman, Paulo J. G. Lisboa","This work deals with the performance of Quantum Clustering (QC) when applied to non-spherically distributed data sets; in particular, QC outperforms K-Means when applied to a data set that contains information of different olive oil areas. The Jaccard score can be set depending on QC parameters; this enables to find local maxima by tuning QC parameters, thus showing up the underlying data structure. In conclusion, QC appears as a promising solution to deal with non-spherical data distributions; however, some improvements are still needed, for example, in order to find out a way to detect the appropriate number of clusters for a given data set.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-171.pdf
2016,How machine learning won the Higgs boson challenge,"Claire Adam-Bourdarios, Glen Cowan, Cecile Germain, Isabelle Guyon, Balazs Kegl, David Rousseau","In 2014 we ran a very successful machine learning challenge in High Ernergy physics attracting 1785 teams, which exposed the machine learning community for the first time to the problem of ""learning to discover"" (www.kaggle.com/c/higgs-boson). While physicists had the opportunity to improve on the state-of-the-art using ""feature engineering"" based on physics principles, this was not the determining factor in winning the challenge. Rather, the challenge revealed that the central difficulty of the problem is to develop a strategy to optimize directly the Approximate Median Significance (AMS) objective function, which is a particularly challenging and novel problem. This objective function aims at increasing the power of a statistical test. The top ranking learning machines span a variety of techniques including deep learning and gradient tree boosting. This paper presents the problem setting and analyzes the results.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-181.pdf
2016,Controlling adaptive quantum-phase estimation with scalable reinforcement learning,"Pantita Palittapongarnpim, Peter Wittek, Barry C. Sanders","We develop a reinforcement learning algorithm to construct a feedback policy that delivers quantum-enhanced interferometric phase estimation up to 100 photons in a noisy environment. We ensure scalability of the calculations by distributing the workload in a cluster and by vectorizing time-critical operations. We also improve running time by introducing accept-reject criteria to terminate calculation when a successful result is reached. Furthermore, we make the learning algorithm robust to noise by fine-tuning how the objective function is evaluated. The results show the importance and relevance of well-designed classical machine learning algorithms in quantum physics problems.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-12.pdf
2016,Physics and Machine Learning: Emerging Paradigms,"José D. Martín-Guerrero, Paulo J. G. Lisboa, Alfredo Vellido",,Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-20.pdf
2016,Assessment of diabetic retinopathy risk with random forests,"Silvia Sanromà, Antonio Moreno, Aida Valls, Pedro Romero, Sofia De La Riva, Ramon Sagarra","Diabetic retinopathy is one of the most usual morbidities associated to diabetes. Its appropriate control requires the implementation of expensive screening programs. This paper reports the use of Random Forests to build a classifier which may determine, with sensitivity and especifity levels over 80%, whether a diabetic person is likely to develop retinopathy. The use of this model in a decision support tool may help doctors to determine the best screening periodicity for each person, so that an appropriate care is provided and human, material and economic resources are more efficiently employed.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-11.pdf
2016,Unsupervised Cross-Subject BCI Learning and Classification using Riemannian Geometry,"Samaneh Nasiri Ghosheh Bolagh, Mohammad Bagher SHAMSOLLAHI, Christian Jutten, Marco Congedo","The inter-subject variability poses a challenge in cross-subject Brain-Computer Interface learning and classification. As a matter of fact, in cross-subject learning not all available subjects may improve the performance on a test subject. In order to address this problem we propose a subject selection algorithm and we investigate the use of this algorithm in the Riemannian geometry classification framework. We demonstrate that this new approach can significantly improve cross-subject learning without the need of any labeled data from test subjects.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-167.pdf
2016,Spatiotemporal ICA improves the selection of differentially expressed genes,"Emilie Renard, Andrew E. Teschendorff, Pierre-Antoine Absil","Selecting differentially expressed genes with respect to some phenotype of interest is a difficult task, specially in the presence of confounding factors. We propose to use a spatiotemporal independent component analysis to model those factors, and to combine information from different spatiotemporal parameter values to improve the set of selected genes. We show on real datasets that the proposed method allows to significantly increase the proportion of genes related to the phenotype of interest in the final selection.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-145.pdf
2016,Multi-step strategy for mortality assessment in cardiovascular risk patients with imbalanced data,"Fernando Mateo, Emilio Soria-Olivas, Marcelino Martínez-Sober, Maria Tellez-Plaza, Juan Gómez-Sanchis, Josep Redon","The assessment of mortality in patients with cardiovascular disease (CVD) risk factors is typically a challenging task given the large amount of collected variables and the imbalance between classes. This is the case of the ESCARVAL-RISK dataset, a large cardiovascular follow-up record spanning 4 years. This study intends to give insight into: a) the performance of variable selection methods, b) the best class balancing method and c) choosing an adequate classifier to predict mortality. We conclude that combining ADASYN with SVM classifiers without and with AUC score-based feature selection, and RUSBoost combined with boosting tree ensembles are the most suitable methodologies among the tested.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-60.pdf
2016,Data complexity measures for analyzing the effect of SMOTE over microarrays,"Laura Morán-Fernández, Veronica Bolon-Canedo, Amparo Alonso-Betanzos","Microarray classification is a challenging issue for machine learning researchers mainly due to the fact that there is a mismatch between gene dimension and sample size. Besides, this type of data have other properties that can complicate the classification task, such as class imbalance. A common approach to deal with the problem of imbalanced datasets is the use of a preprocessing step trying to cope with this imbalance.. In this work we analyze the usefulness of the data complexity measures in order to evaluate the behavior of the SMOTE algorithm before and after applying feature gene selection.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-134.pdf
2016,A fast learning algorithm for high dimensional problems: an application to microarrays,"Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas, Beatriz Pérez-Sánchez, Diego Rego-Fernández, David Martínez-Rego","In this work, a new learning method for one-layer neural network based on a singular value decomposition is presented. The optimal parameters of the model can be obtained by means of a system of linear equations, which complexity depends on the number of samples. This approach provides a fast learning algorithm for huge dimensional problems where the number of inputs is higher than the number of data points. This kind of situations appears, for example, in DNA microarrays scenarios. An experimental study over eleven microarray datasets shows that the proposed method is able to defeat other representative classifiers, in terms of CPU time, without significant loss of accuracy.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-67.pdf
2016,Using a feature selection ensemble on DNA microarray datasets,"Borja Seijo-Pardo, Veronica Bolon-Canedo, Amparo Alonso-Betanzos","DNA microarray has brought a difficult challenge for researchers due to the high number of gene expression contained and the small samples size. Therefore, feature selection has become an indispensable preprocessing step. In this paper we propose an ensemble for feature selection based on combining rankings of features. The individual rankings are combined with different aggregation methods, and a practical subset of features is selected according to a data complexity measure -the inverse of Fisher discriminant ratio-. The proposed ensemble, tested on seven different DNA microarray datasets using a Support Vector Machine as classifier, was able to obtain the best results in different scenarios.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-133.pdf
2016,On the analysis of feature selection techniques in a conjunctival hyperemia grading framework,"Maria Luisa Sanchez Brea, Noelia Barreira Rodríguez, Noelia Sánchez Maroño, Antonio Mosquera González, Carlos García Resúa, Eva Yebra-Pimentel Vilar","Hyperemia is a parameter that describes the degree of redness in a tissue. When it affects the bulbar conjunctiva, it can serve as an early indicator for pathologies such as dry eye syndrome. Hyperemia is measured using scales, which are collections of images that show different severity levels. Features computed from the images can be used to develop an automatic grading system with the help of machine learning algorithms. In this work, we present a methodology that analyses the influence of each feature when determining the hyperemia level.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-49.pdf
2016,Initializing nonnegative matrix factorization using the successive projection algorithm for multi-parametric medical image segmentation,"Nicolas Sauwen, Marjan Acou, Halandur Nagaraja Bharath, Diana Sima, Jelle Veraart, Frederik Maes, Uwe Himmelreich, Eric Achten, Sabine Van Huffel","As nonnegative matrix factorization (NMF) represents a non-convex problem, the quality of its solution will depend on the initialization of the factor matrices. This study proposes the Successive Projection Algorithm (SPA) as a feasible NMF initialization method. SPA is applied to a multi-parametric MRI dataset for automated NMF brain tumor segmentation. SPA provides fast and reproducible estimates of the tissue sources, and segmentation quality is found to be similar compared to repetitive random initialization.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-152.pdf
2016,Bag-of-Steps: predicting lower-limb fracture rehabilitation length,"Albert Pla, Beatriz López, Cristofor Nogueira, Natalia Mordvaniuk, Taco J. Blokhuis, Herman R Holtslag","This paper presents bag-of-steps, a new methodology to predict the rehabilitation length of a patient by monitoring the weight he is bearing in his injured leg and using a predictive model based on the bag-of-words technique. A force sensor is used to monitor and characterize the patient's gait, obtaining a set of step descriptors. These are later used to define a vocabulary of steps that can be used to describe rehabilitation sessions. Sessions are finally fed to a support vector machine classifier that performs the final rehabilitation estimation.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-39.pdf
2016,Policy-gradient methods for Decision Trees,"Aurélia Léon, Ludovic Denoyer","We propose a new type of decision trees able to learn at the same time how inputs fall in the tree and which predictions are associated to the leaves. The main advantage of this approach is to be based on the optimization of a global loss function instead of using heuristic-based greedy techniques, while keeping the good characteristics of decision trees. The learning algorithm is inspired by reinforcement learning and based on gradient-descent based methods, allowing a fast optimization. Moreover the algorithm is not limited to (mono-label) classification task and can be used for any predictive problem while a derivable loss function exist. Experimental results show the effectiveness of the method w.r.t baselines.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-102.pdf
2016,The WiSARD Classifier,"Massimo De Gregorio, Maurizio Giordano","WiSARD is a weightless neural model which essentially uses look up tables to store the function computed by each neuron rather than storing it in weights of neuron connections. Although WiSARD was originally conceived as a pattern recognition device mainly focusing on image processing, in this work we show how it is possible to build a multi–class classifier method in Machine Learning (ML) domain based on WiSARD that shows equivalent performances to ML state–of-the–art methods.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-63.pdf
2016,Random Forests Model Selection,"Ilenia Orlandi, Luca Oneto, Davide Anguita","Random Forests (RF) of tree classifiers are a popular ensemble method for classification. RF have shown to be effective in many different real world classification problems and nowadays are considered as one of the best learning algorithms in this context. In this paper we discuss the effect of the hyperparameters of the RF over the accuracy of the final model, with particular reference to different theoretically grounded weighing strategies of the tree in the forest. In this way we go against the common misconception which considers RF as an hyperparameter-free learning algorithm. Results on a series of benchmark datasets show that performing an accurate Model Selection procedure can greatly improve the accuracy of the final RF classifier.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-48.pdf
2016,Tuning the Distribution Dependent Prior in the PAC-Bayes Framework based on Empirical Data,"Luca Oneto, Sandro Ridella, Davide Anguita","In this paper we further develop the idea that the PAC-Bayes prior can be defined based on the data-generating distribution. In particular, following Catoni, we refine some recent generalisation bounds on the risk of the Gibbs Classifier, when the prior is defined in terms of the data generating distribution, and the posterior is defined in terms of the observed one. Moreover we show that the prior and the posterior distributions can be tuned based on the observed samples without worsening the convergence rate of the bounds and with a marginal impact on their constants.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-46.pdf
2016,Active transfer learning for activity recognition,"Tom Diethe, Niall Twomey, Peter Flach","We examine activity recognition from accelerometers, which provides at least two major challenges for machine learning. Firstly, the deployment context is likely to differ from the learning context. Secondly, accurate labelling of training data is time-consuming and error-prone. This calls for a combination of active and transfer learning. We derive a hierarchical Bayesian model that is a natural fit to such problems, and provide empirical validation on synthetic and publicly available datasets. The results show that by combining active and transfer learning, we can achieve faster learning with fewer labels on a target domain than by either alone.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-99.pdf
2016,Using semantic similarity for multi-label zero-shot classification of text documents,"Prateek Veeranna Sappadla, Jinseok Nam, Eneldo Loza Mencía, Johannes Fürnkranz","In this paper, we examine a simple approach to zero-shot multi-label text classification, i.e., to the problem of predicting multiple, possibly previously unseen labels for a document. In particular, we propose to use a semantic embedding of label and document words and base the prediction of previously unseen labels on the similarity between the label name and the document words in this embedding. Experiments on three textual datasets across various domains show that even such a simple technique yields considerable performance improvements over a simple uninformed baseline.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-174.pdf
2016,anomaly detection on spectrograms using data-driven and fixed dictionary representations,"Mina ABDEL-SAYED, Daniel Duclos, Gilles Faÿ, Jérôme Lacaille, Mathilde Mougeot","Spectrograms provide a visual representation of the vibrations of civil aircraft engines. The vibrations contain information relative to damage in the engine, if any. This representation is noisy, high dimensional and the relevant signatures relative to damages concern only a small part of the spectrogram. All these arguments lead to difficulties to automatically detect anomalies in the spectrogram. Adequate lower dimensional representations of the spectrograms are needed. In this paper, we study two types of representations with dictionary, a data-driven one and a non-adaptive one and we show their benefits for automatic anomaly detection.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-104.pdf
2016,Sparse Least Squares Support Vector Machines via Multiresponse Sparse Regression,"David Vieira, Ajalmar Rocha Neto, Antonio Wendell Rodrigues","Least Square Suppor Vector Machines (LSSVMs) are an alternative to SVMs because the training process for LSSVMs is based on solving a linear equation system while the training process for SVMs relies on solving a quadratic programming optimization problem.  Despite solving a linear system is easier than solving a quadratic programming optimization problem, the absence of sparsity in the Lagrange multiplier vector obtained after training a LSSVM model is an important drawback. To overcome this drawback, we present a new approach for sparse LSSVM called Optimally Pruned LSSVM (OP-LSSVM). Our proposal is based on a ranking method, named Multiresponse Sparse Regression (MRSR), which is used to sort the patterns in terms of relevance. After that, the leave-one-out (LOO) criterion is also used in order to select an appropriate number of support vectors. Our proposal was inspired by a recent methodology called OP-ELM, which prunes hidden neurons of Extreme Learning Machines. Therefore, in this paper, we  put LSSVM and MRSR to work togheter in order to achieve sparse classifiers, as well as one can see that we achieved equivalent (or even superior) performance for real-world classification tasks.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-53.pdf
2016,Parallelized rotation and flipping INvariant Kohonen maps (PINK) on GPUs,"Kai Lars Polsterer, Fabian Gieseke, Christian Igel, Bernd Doser, Nikolaos Gianniotis","Morphological classification is one of the most demanding challenges in astronomy. With the advent of all-sky surveys, an enormous amount of imaging data is publicly available. These data are typically analyzed by experts or encouraged amateur volunteers. For upcoming surveys with billions of objects, however, such an approach is not feasible anymore. In this work, we present a simple yet effective variant of a rotation-invariant self-organizing map that is suitable for many analysis tasks in astronomical. We show how to reduce the computational complexity via modern GPUs and apply the resulting framework to galaxy data for morphological analysis.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-116.pdf
2016,Boosting face recognition via neural Super-Resolution,"Guillaume Berger, Clément Peyrard, Moez Baccouche","We propose a two-step neural approach for face Super-Resolution (SR) to improve face recognition performances. It consists in first performing generic SR on the entire image, based on Convolutional Neural Networks, followed by a specific local SR step for each facial component, using neural autoencoders. Obtained results on the LFW dataset for a ×4 upscaling factor demonstrate that the method improves both image reconstruction (+2.80 dB in PSNR) and recognition performances (+3.94 points in mean accuracy), compared with ×4 bicubic interpolation.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-144.pdf
2016,Towards incremental deep learning: multi-level change detection in a hierarchical visual recognition architecture,"Thomas Hecht, Alexander Gepperth","We present a hierarchical recognition architecure capable of detecting newness (or outliers) at all hierarchical levels. As the ability to detect newness is an import prerequisite for incremental learning, this contribution paves the way for deep neural architectures that are able to learn in an incremental fashion. We verify the ability to detect newness by conducting experiments on the MNIST database, where we introduce either localized changes, by adding noise to a small patch of the input, or global changes, by combining the left and right half of two different samples which is not detectable at the local but only at the global level.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-160.pdf
2016,Memory management for data streams subject to concept drift,"Pierre-Xavier Loeffel, Christophe Marsala, Marcin Detyniecki","Learning on data streams subject to concept drifts is a challenging task. A successful algorithm must be able to keep memory consumption constant regardless of the amount of data processed, and at the same time, retain good adaptation and prediction capabilities by effectively selecting which observations should be stored into memory. We claim that, instead of using a temporal window to discard observations with a time stamp criterion, it is better to retain observations that minimize the change in outputted prediction and rule learned with the full memory case. Experimental results for the Droplets algorithm, on 6 artificial and semi-artificial datasets reproducing various types of drifts back this claim.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-97.pdf
2016,"Watch, Ask, Learn, and Improve: a lifelong learning cycle for visual recognition","Christoph Käding, Erik Rodner, Alexander Freytag, Joachim Denzler","We present WALI, a prototypical system that learns object categories over time by continuously watching online videos. WALI actively asks questions to a human annotator about the visual content of observed video frames. Thereby, WALI is able to receive information about new categories and to simultaneously improve its generalization abilities. The functionality of WALI is driven by scalable active learning, efficient incremental learning, as well as state-of-the-art visual descriptors. In our experiments, we show qualitative and quantitative statistics about WALI's learning process. WALI runs continuously and regularly asks questions.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-91.pdf
2016,Distributed learning algorithm for feedforward neural networks,"Oscar Fontenla-Romero, Beatriz Pérez-Sánchez, Bertha Guijarro-Berdiñas, Diego Rego-Fernández","With the appearance of huge data sets new challenges have risen regarding the scalability and efficiency of Machine Learning algorithms, and both distributed computing and randomized algorithms have become effective ways to handle them. Taking advantage of these two approaches, a distributed learning algorithm for two-layer neural networks is proposed. Results demonstrate a similar accuracy when compare to an equivalent non-distributed approach whilst providing some advantages that make it specially well-suited for Big Data sets: over 50\% savings in computational time; low communication and storage cost; no hyperparameters to be tuned; it allows online learning and it is privacy-preserving.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-9.pdf
2016,Choosing the best algorithm for an incremental on-line learning task,"Viktor Losing, Barbara Hammer, Heiko Wersing","Recently, incremental and on-line learning gained more attention  especially in the context of big data and learning from data streams, conflicting with the traditional assumption of complete data availability. Even though  a variety of different methods are available, it often remains unclear which of them is suitable for a specific task and how they perform in comparison to each other.  We analyze the key properties of seven incremental methods representing different algorithm classes. Our extensive evaluation on data sets with different characteristics gives an overview of the performance with respect to accuracy as well as model complexity, facilitating the choice of the best method for a given application.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-71.pdf
2016,Incremental learning algorithms and applications,"Alexander Gepperth, Barbara Hammer","Incremental learning refers to learning from streaming data, which arrive over time, with limited memory resources and, ideally, without sacrificing model accuracy. This setting fits different application scenarios where lifelong learning is relevant, e.g. due to changing environments, and it offers an elegant scheme for  big data processing by means of its sequential treatment. In this contribution, we formalise the concept of incremental learning, we discuss particular challenges which arise in this setting, and we give an overview about popular approaches, its theoretical foundations, and applications, which emerged in the last years.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-19.pdf
2016,Fast Support Vector Clustering,"Tung Pham, Trung Le, Hoang-Thai Le, Dat Tran","Support-based clustering has recently drawn plenty of attention because of its applications in solving the difficult and diverse clustering or outlier detection problem. Support-based clustering method undergoes two phases: finding the domain of novelty and doing clustering assignment. To find the domain of novelty, the training time given by the current solvers is typically quadratic in the training size. It precludes the usage of support-based clustering method for the large-scale datasets. In this paper, we propose applying Stochastic Gradient Descent framework to the first phase of support-based clustering for finding the domain of novelty in form of a half-space and a new strategy to do the clustering assignment. We validate our proposed method on the well-known datasets for clustering to show that the proposed method offers a comparable clustering quality to Support Vector Clustering while being faster than this method.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-77.pdf
2016,Spatial Chirp-Z Transformer Networks,"Jonas Degrave, Sander Dieleman, Joni Dambre, Francis Wyffels","Convolutional Neural Networks are often used for computer vision solutions, because of their inherent modeling of the translation invariance in images. In this paper, we propose a new module to model rotation and scaling invariances in images. To do this, we rely on the chirp-Z transform to perform the desired translation, rotation and scaling in the frequency domain. This approach has the benefit that it scales well and that it is differentiable because of the computationally cheap sinc-interpolation.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-107.pdf
2016,Learning Embeddings for Completion and Prediction of Relationnal Multivariate Time-Series,"Ali Ziat, Gabriella Contardo, Nicolas Baskiotis, Ludovic Denoyer","We focus on learning over multivariate and relational time-series where relations are modeled by a graph. We propose a model that is able to simultaneously fill in missing values and predict future ones. This approach is based on representation learning techniques, where temporal data are represented in a latent vector space so as to capture the dynamicity of the process and also the relations between the different sources. Information completion (missing values) and prediction are performed simultaneously using a unique formalism, whereas most often they are addressed separately using different methods.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-103.pdf
2016,Comparison of Four- and Six-Layered Configurations for Deep Network Pretraining,"Tommi Karkkainen, Jan Hanninen","Using simpler building blocks to initially construct a deep network, with their finetuning for the full architecture, is known to improve the deep learning process. However, in many cases the pretrained networks are obtained using different training algorithms than used in their final combination. Here we introduce and compare four possible architectures to pretrain a deep, feedforward network architecture, using exactly the same formulation throughout. Based on the analytical formulations and experimental results, one of the tested configurations is concluded as the recommended approach for the initial phase of deep learning.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-45.pdf
2016,An Experiment in Pre-Emphasizing Diversified Deep Neural Classifiers,"Ricardo Alvear-Sandoval, Anibal Figueiras-Vidal","We explore if adding a pre-emphasis step to diversified deep auto-encoding based classifiers serves to further improve their performance with respect to those obtained just separately using pre-emphasis or diversification. An experiment with the MNIST database, a well-known benchmark problem for this type of designs, shows that further improvement does appear, the main condition for it simply being to select general and flexible enough pre-emphasis forms. Other manners of combining diversity and pre-emphasis require more research effort, as well as to investigate if other deep architectures can also obtain benefits from these ideas.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-27.pdf
2016,Stochastic gradient estimate variance in contrastive divergence and persistent contrastive divergence,Mathias Berglund,"Contrastive Divergence (CD) and Persistent Contrastive Divergence (PCD) are popular methods for training Restricted Boltzmann Machines. However, both methods use an approximate method for sampling from the model distribution. As a side effect, these approximations yield significantly different biases and variances for stochastic gradient estimates of individual data points. It is well known that CD yields a biased gradient estimate. In this paper we however show empirically that CD has a lower stochastic gradient estimate variance than unbiased sampling, while the mean of subsequent PCD estimates has a higher variance than independent sampling. The results give one explanation to the finding that CD can be used with smaller minibatches or higher learning rates than PCD.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-6.pdf
2016,Augmenting a convolutional neural network with local histograms - A case study in crop classification from high-resolution UAV imagery,"Julien Rebetez, Héctor F. Satizábal, Matteo Mota, Dorothea Noll, Lucie Büchi, Marina Wendling, Bertrand Cannelle, Andres Perez-Uribe, Stéphane Burgos",The advent of affordable drones capable of taking high resolution images of agricultural fields creates new challenges and opportunities in aerial scene understanding. This paper tackles the problem of recognizing crop types from aerial imagery and proposes a new hybrid neural network architecture which combines histograms and convolutional units. We evaluate the performance of the proposed model on a 23-class classification task and compare it to other models. The result is an improvement of the classification performance.,Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-74.pdf
2016,Multispectral Pedestrian Detection using Deep Fusion Convolutional Neural Networks,"Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke","Robust vision-based pedestrian detection is a crucial feature of future autonomous systems. Thermal cameras provide an additional input channel that helps solving this task and deep convolutional networks are the currently leading approach for many pattern recognition problems, including object detection. In this paper, we explore the potential of deep models for multispectral pedestrian detection. We investigate two deep fusion architectures and analyze their performance on multispectral data. Our results show that a pre-trained late-fusion architecture significantly outperforms the current state-of-the-art ACF+T+THOG solution.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-118.pdf
2016,Deep Learning Vector Quantization,"Harm de Vries, Roland Memisevic, Aaron Courville","While deep neural nets (DNN's) achieve impressive performance on image recognition tasks, previous studies have reported that DNN's give high confidence predictions for unrecognizable images. Motivated by the observation that such \emph{fooling examples} might be caused by the extrapolating nature of the log-softmax, we propose to combine neural network with Learning Vector Quantization (LVQ). Our proposed method, called Deep LVQ (DLVQ), achieves comparable performance on MNIST while being more robust against fooling and adversarial examples.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-112.pdf
2016,Deep Reservoir Computing: A Critical Analysis,"Claudio Gallicchio, Alessio Micheli","In this paper we propose an empirical analysis of deep recurrent neural networks (RNNs) with stacked layers. The analysis aims at the study and proposal of approaches to develop and enhance multiple timescale and hierarchical dynamics in deep recurrent architectures, within the efficient Reservoir Computing (RC) approach for RNN modeling. Results point out the actual relevance of layering and RC parameters aspects on the diversification of temporal representations in deep recurrent models.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-175.pdf
2016,Challenges in Deep Learning,"Plamen Angelov, Alessandro Sperduti",,Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-23.pdf
2016,Converting SVDD scores into probability estimates,"Meriem El Azami, Carole Lartizien, Stéphane Canu","To enable post-processing, the output of a support vector data description (SVDD) should be a calibrated probability as done for SVM. Standard SVDD does not provide such probabilities. To create probabilities, we first generalize the SVDD model and propose two calibration functions. The first one uses a sigmoid model and the other one is based on a generalized extreme distribution model. To estimate calibration parameters, we use the consistency property of the estimator associated with a single SVDD model. A synthetic dataset and datasets from the UCI repository are used to compare the performance against a robust kernel density estimator.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-158.pdf
2016,One-class classification algorithm based on convex hull,"Diego Fernandez-Francos, Oscar Fontenla-Romero, Amparo Alonso-Betanzos","A new version of a one-class classification algorithm is  in this paper. In it, convex hull (CH) is used to define the boundary of the target class defining the one-class problem. Expansion and reduction of the CH prevents over-fitting. An approximation of the D-dimensional CH decision is made by using random projections and an ensemble of models in very low-dimensional spaces. A different method to obtain the expanded polytope is proposed in order to avoid some undesirable behavior detected in the original algorithm in certain situations. Besides, this modification allows the use of a new parameter, the CH center, that provides even more flexibility to our proposal. Experimental results showed that the new algorithm is significantly better, regarding accuracy, than the original one on a large number of datasets.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-136.pdf
2016,From User-independent to Personal Human Activity Recognition Models Using Smartphone Sensors,"Pekka Siirtola, Heli Koskimäki, Juha Röning","In this study, a novel method to obtain user-dependent human activity recognition models unobtrusively by using the sensors of a smartphone is presented. The recognition consists of two models: sensor fusion-based user-independent model for data labeling and single sensor-based user-dependent model for final recognition. The functioning of the presented method is tested with human activity data set, including data from accelerometer and magnetometer, and with two classifiers. Comparison of the detection accuracies of the proposed method to traditional user-independent model shows that the presented method has potential, in nine cases out of ten it is better than the traditional method, but more experiments using different sensor combinations should be made to show the full potential of the method.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-126.pdf
2016,Activity recognition with echo state networks using 3D body joints and objects category,"Luiza Mici, Xavier Hinaut, Stefan Wermter","In this paper we present our experiments with an echo state network (ESN) for the task of classifying high-level human activities from video data. ESNs are recurrent neural networks which are biologically plausible, fast to train and they perform well in processing arbitrary sequential data. We focus on the integration of body motion with the information on objects manipulated during the activity, in order to overcome the visual ambiguities introduced by the processing of articulated body motion. We investigate the outputs learned and the accuracy of classification obtained with ESNs by using a challenging dataset of long high-level activities. We finally report the results achieved on this dataset",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-120.pdf
2016,Multicriteria optimized MLP for imbalanced learning,"Paavo Nieminen, Tommi Karkkainen","Classifier construction for data with imbalanced class frequencies needs special attention if good classification accuracy for all the classes is sought. When the classes are not separable, i.e., when the distributions of observations in the classes overlap, it is impossible to achieve ideal accuracy for all the classes at once. We suggest a versatile multicriteria optimization formulation for imbalanced classification and demonstrate its applicability using a single hidden layer perceptron as the classifier model.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-113.pdf
2016,A state-space model on interactive dimensionality reduction,"Ignacio Diaz-Blanco, Abel Alberto Cuadrado-Vega, Michel Verleysen","In this work, we present a conceptual approach to the convergence dynamics of interactive dimensionality reduction (iDR) algorithms from the perspective of a well stablished theoretical model, namely state-space theory. The expected benefits are twofold: 1) suggesting new ways to import well known ideas from the state-space theory that help in the characterization and development of iDR algorithms and 2) providing a conceptual model for user interaction in iDR algorithms, that can be easily adopted for future interactive machine learning (iML) tools.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-41.pdf
2016,Human-centered machine learning through interactive visualization: review and open challenges,"Dominik Sacha, Michael Sedlmair, Leishi Zhang, John Lee, Daniel Weiskopf, Stephen North, Daniel Keim","The goal of visual analytics (VA) systems is to solve complex problems by integrating automated data analysis methods, such as machine learning (ML) algorithms, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and makes the crucial interplay between automated algorithms and interactive visualizations more concrete. The framework is illustrated through several examples. We derive three open research challenges at the intersection of ML and visualization research that will lead to more effective data analysis.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-166.pdf
2016,Informative data projections: a framework and two examples,"Tijl De Bie, Jefrey Lijffijt, Raul Santos-Rodriguez, Bo Kang","Projection Pursuit aims to facilitate visual exploration of high-dimensional data by identifying interesting low-dimensional projections. A major challenge in Projection Pursuit is the design of a projection index–a suitable quality measure to maximise. We introduce a strategy for tackling this problem based on quantifying the amount of information a projection conveys, given a user’s prior beliefs about the data. The resulting projection index is a subjective quantity, explicitly dependent on the intended user. As an illustration, we developed this principle for two kinds of prior beliefs; the first leads to PCA, the second leads to a novel projection index, which we call t-PCA, that can be regarded as a robust PCA-variant. We demonstrate t-PCA’s usefulness in comparative experiments against PCA and FastICA, a popular PP method.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-123.pdf
2016,Enhancing a social science model-building workflow with interactive visualisation,"Cagatay Turkay, Aidan Slingsby, Kaisa Lahtinen, Sarah Butt, Jason Dykes","Although automated methods are helping produce significantly better models for various phenomena in scientific research, they often reduce the ability for the  scientist to inform the model building with their theoretical knowledge. Such incorporation of prior knowledge is crucial when scientists aim to understand and defend their models. In this paper, we report our ongoing studies as a team of computer and social scientists where we use interactive visualisation techniques to improve the efficiency of the model building workflow. We do this by designing methods to incorporate theory, interactively build models, and keep a record of the decisions made.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-147.pdf
2016,"Information visualisation and machine learning: characteristics, convergence and perspective","Benoît Frénay, Bruno Dumas","This paper discusses how information visualisation and machine learning can cross-fertilise.  On the one hand, the user-centric field of information visualisation can help machine learning to better integrate users in the learning, assessment and interpretation processes.  On the other hand, machine learning can provide powerful algorithms for clustering, dimensionality reduction, data cleansing, outlier detection, etc.  Such inference tools are required to create efficient visualisations.  This paper highlight opportunities to collaborate for experts in both fields.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-18.pdf
2016,Parallelized unsupervised feature selection for large-scale network traffic analysis,"Bruno Ordozgoiti, Sandra Gómez Canaval, Alberto Mozo","In certain domains, where model interpretability is highly valued, feature selection is often the only possible option for dimensionality reduction. However, two key problems arise. First, the size of data sets today makes it unfeasible to run centralized feature selection algorithms in reasonable amounts of time. Second, the impossibility of labeling data sets rules out supervised techniques. We propose an unsupervised feature selection algorithm based on a new formulation of the leverage scores. We derive an extremely efficient parallelized approach over the Resilient Distributed Datasets abstraction, making it applicable to the enormous data sets often present in network traffic analysis.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-84.pdf
2016,Spatio-temporal feature selection for black-box weather forecasting,"Zahra Karevan, Johan A. K. Suykens","In this paper, a data-driven modeling technique is proposed for temperature forecasting. Due to the high dimensionality, LASSO is used as feature selection approach. Considering spatio-temporal structure of the weather dataset, first LASSO is applied in a spatial and temporal scenario, independently. Next, a feature is included in the model if it is selected by both. Finally, Least Squares Support Vector Machines (LS-SVM) regression is used to learn the model. The experimental results show that spatio-temporal LASSO improves the performance and is competitive with the state-of-the-art methods. As a case study, the prediction of the temperature in Brussels is considered.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-143.pdf
2016,Instance and feature weighted k-nearest-neighbors algorithm,"Gabriel Prat, Lluís A. Belanche","We present a novel method that aims at providing a more stable   selection of feature subsets when variations in the training process   occur. This is accomplished by using an instance-weighting process   --assigning different importances to instances-- as a preprocessing   step to a feature weighting method that is independent of the   learner, and then making good use of both sets of computed weigths   in a standard Nearest-Neighbours classifier. We report extensive   experimentation in well-known benchmarking datasets as well as some   challenging microarray gene expression problems. Our results show   increases in FSS stability for most subset sizes and most problems,   without compromising prediction accuracy.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-178.pdf
2016,K-means for Datasets with Missing Attributes: Building Soft Constraints with Observed and Imputed Values,"Diego Mesquita, Joao Gomes, Leonardo Rodrigues","Clustering methods have a wide range of applications. However, the presence of missing attribute values on the dataset may limit the use of clustering methods. Developing clustering methods that can deal with missing data has been a topic of interest among researchers in recent years. This work presents a variant of the well known k-means algorithm that can handle missing data. The proposed algorithm uses one type of soft constraints for observed data and a second type for imputed data. Four public datasets were used in the experiments in order to compare the performance of the proposed model with a traditional k-means algorithm and an algorithm that uses soft constraints only for observed data. The results showed that the proposed method outperformed the benchmark methods for all datasets considered in the experiments.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-188.pdf
2016,RBClust: High quality class-specific clustering using rule-based classification,"Michael Siers, Md Zahidul Islam","Within a class-labeled dataset, there are typically two or more possible class labels. Class-specific subsets of the dataset have the same class label for each record. Class-specific clusters are the groups of similar records within these subsets. There exists many machine learning techniques which require class-specific clusters. We propose RBClust, a rule based method for finding class-specific clusters. We demonstrate that when compared to traditional clustering methods, the proposed method achieves better cluster quality, and computation time is significantly lower.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-124.pdf
2016,Initialization of big data clustering using distributionally balanced folding,"Joonas Hämäläinen, Tommi Karkkainen","Use of distributionally balanced folding to speed up the initialization phase of K-means++ clustering method, targeting for big data applications, is proposed and tested. The approach is &#64257;rst described and then experimented, by focusing on the e&#64256;ects of the sampling method when the number of folds created is varied. In the tests, quality of the &#64257;nal clustering results were assessed and scalability of a distributed implementation was demonstrated. The experiments support the viability of the proposed approach.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-93.pdf
2016,PSCEG: an unbiased parallel subspace clustering algorithm using exact grids,"Bo Zhu, Alberto Mozo, Bruno Ordozgoiti","The quality of grid-based subspace clustering is highly dependent on the grid size and the positions of dense units, and many existing methods use sensitive global density thresholds that are difficult to set a priori. We propose PSCEG, a new approach that generates an exact grid without the need to specify its size based on the distribution of each dimension. In addition, we define an adaptive density estimator that avoids dimensionality bias. A parallel implementation of our algorithm using Resilient Distributed Datasets achieves a significant speedup w.r.t. the number of cores in high dimensional scenarios. Experimental results on synthetic and real datasets show PSCEG outperforms existing alternatives.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-85.pdf
2016,"Genetic Algorithm with Novel Crossover, Selection and Health Check for Clustering","Abul Hashem Beg, Md Zahidul Islam","We propose a genetic algorithm for clustering records, where the algorithm contains new approaches for various genetic operations including crossover and selection. We also propose a health check operation that finds sick chromosomes of a population and probabilistically replaces them with healthy chromosomes found in the previous generations. The proposed approaches improve the chromosome quality within a population, which then contribute in achieving good clustering solution. We use fifteen datasets to compare our technique with five existing techniques in terms of two cluster evaluation criteria. The experimental results indicate a clear superiority of the proposed technique over the existing techniques.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-37.pdf
2016,Clustering from two data sources using a kernel-based approach with weight coupling,"Lynn Houthuys, Rocco Langone, Johan A. K. Suykens","In many clustering problems there are multiple data sources which are available. Although each one could individually be used for clustering, exploiting information from all data sources together can be relevant to nd a clustering that is more accurate. Here a new model is proposed for clustering when two data sources are available. This model is called Binary View Kernel Spectral Clustering (BVKSC) and is based on a constrained optimization formulation typical to Least Squares Support Vector Machines (LS-SVM). The model includes a coupling term, where the weights of the two dierent data sources are coupled in the primal model. This coupling term makes it possible to exploit the additional information from each other data source. Experimental comparisons with a number of similar methods show that using two data sources can improve the clustering results and that the proposed method is competitive in performance to other state-of-the-art methods.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-28.pdf
2016,Spectral clustering and discriminant analysis for unsupervised feature selection,"Xiucai Ye, Kaiyang Ji, Tetsuya Sakurai","In this paper, we propose a novel method for unsupervised feature selection, which utilizes spectral clustering and discriminant analysis to learn the cluster labels of data. During the learning of cluster labels, feature selection is performed simultaneously. By imposing row sparsity on the transformation matrix, the proposed method optimizes for selecting the most discriminative features which better captures both the global and local structure of data. We develop an iterative algorithm to effectively solve the optimization problem in our method. Experimental results on different real-world data demonstrate the effectiveness of the proposed method.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-78.pdf
2016,Fast in-memory spectral clustering using a fixed-size approach,"Rocco Langone, Raghvendra Mall, Vilen Jumutc, Johan A. K. Suykens","Spectral clustering represents a successful approach to data clustering. Despite its high performance in solving complex tasks, it is often disregarded in favor of the less accurate k-means algorithm because of its computational inefficiency. In this article we present a fast in-memory spectral clustering algorithm, which can handle millions of datapoints at a desktop PC scale. The proposed technique relies on a kernel-based formulation of the spectral clustering problem, also known as kernel spectral clustering. In particular, we use a fixed-size approach based on an approximation of the feature map via the Nystrom method to solve the primal optimization problem. We experimented on several small and large scale real-world datasets to show the computational efficiency and clustering quality of the proposed algorithm.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-72.pdf
2016,Human detection and classification of landing sites for search and rescue drones,"Felipe Martins, Marc de Groot, Xeryus Stokkel, Marco Wiering","Search and rescue is often time and labour intensive. We present a system to be used in drones to make search and rescue operations more effective. The system uses a drone downward facing camera to detect people and to evaluate potential sites as being safe or not for the drone to land. Histogram of Oriented Gradients (HOG) features are extracted and a Support Vector Machine (SVM) is used as classifier. Our results show good performance on classifying frames as containing people (Sensitivity > 78%, Specificity > 83%), and distinguishing between safe and dangerous landing sites (Sensitivity > 87%, Specificity > 98%).",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-75.pdf
2016,Incremental hierarchical indexing and visualisation of large image collections,"Frédéric Rayar, Sabine Barrat, Fatma Bouali, Gilles Venturini","Ever-growing image collections are common in several fields such as health, digital humanities or social networks. Nowadays, there is a lack of visualisation tools to browse such large image collection. In this work, the incremental indexing and the visualisation of large image collections is done jointly. The BIRCH algorithm is improved to incrementally yield a hierarchical indexing structure. A custom web platform is presented to visualise the structure that is built. The proposed method is tested with two large image collections, up to one million images.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-29.pdf
2016,Learning contextual affordances with an associative neural architecture,"Francisco Cruz, German Parisi, Stefan Wermter","Affordances are an effective method to anticipate the effect of actions performed by an agent interacting with objects. In this work, we present a robotic cleaning task using contextual affordances, i.e. an extension of affordances which takes into account the current state. We implement an associative neural architecture for predicting the effect of performed actions with different objects to avoid failed states. Experimental results on a simulated robot environment show that our associative memory is able to learn in short time and predict future states with high accuracy.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-54.pdf
2016,Neural fitted actor-critic,"Matthieu Zimmer, Yann Boniface, Alain Dutech","A novel reinforcement learning algorithm that deals with both continuous state and action spaces is proposed. Domain knowledge requirements are kept minimal by using non-linear estimators and since the algorithm does not need prior trajectories or known goal states. The new actor-critic algorithm is on-policy, offline and model-free. It considers discrete time, stationary policies, and maximizes the discounted sum of rewards. Experimental results on two common environments, showing the good performance of the proposed algorithm, are presented.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-94.pdf
2016,Simultaneous estimation of rewards and dynamics from noisy expert demonstrations,"Michael Herman, Tobias Gindele, Jörg Wagner, Felix Schmitt, Wolfram Burgard","Inverse Reinforcement Learning (IRL) describes the problem of learning an unknown reward function of a Markov Decision Process (MDP) from demonstrations of an expert. Current approaches typically require the system dynamics to be known or additional demonstrations of state transitions to be available to solve the inverse problem accurately. If these assumptions are not satisfied, heuristics can be used to compensate the lack of a model of the system dynamics. However, heuristics can add bias to the solution. To overcome this, we present a gradient-based approach, which simultaneously estimates rewards, dynamics, and the parameterizable stochastic policy of an expert from demonstrations, while the stochastic policy is a function of optimal Q-values.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-114.pdf
2016,On the improvement of static force capacity of humanoid robots based on plants behavior,"Juliano Pierezan, Roberto Zanetti Freire, Lucas Weihmann, Gilberto Reynoso-Meza, Leandro dos Santos Coelho","Humanoid robots need to interact with the environment and are constantly in rigid contact with objects. When a task must be performed, multiple contact points are responsible to add a degree of complexity to their control and, due to excessive efforts in joints, the durability of the components may be affected. This work presents the use of a recent proposed metaheuristic called Runner-Root Algorithm (RRA) applied on the static force capacity optimization of a humanoid robot. The performance of this algorithm was evaluated and compared to four well stablished methods showing promising results for RRA in this type of application.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-125.pdf
2016,Grounding the experience of a visual field through sensorimotor contingencies,"Alban Laflaquiere, Michael Garcia Ortiz, Ahmed Faraz Khan","Artificial perception is traditionally handled by hand-designing specific algorithms. However, a truly autonomous robot should develop perceptive abilities on its own by interacting with its environment. The sensorimotor contingencies theory proposes to ground those abilities in the way the agent can actively transform its sensory inputs. This work presents an application of this approach to the discovery of a visual field. It shows how an agent can capture regularities induced by its visual sensor in a sensorimotor predictive model. A formalism is proposed to address this problem and tested on a simulated system.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-148.pdf
2016,Semantic Role Labelling for Robot Instructions using Echo State Networks,"Johannes Twiefel, Xavier Hinaut, Stefan Wermter","To control a robot in a real-world robot scenario, a real-time parser is needed to create semantic representations from natural language which can be interpreted. The parser should be able to create the hierarchical tree-like representations without consulting external systems to show its learning capabilities. We propose an efficient Echo State Network-based parser for robotic commands and only relies on the training data. The system generates a single semantic tree structure in real-time which can be executed by a robot arm manipulating objects. Four of six other approaches, which in most cases generate multiple trees and select one of them as the solution, were outperformed with 64.2% tree accuracy on difficult unseen natural language (74.1% under best conditions) on the same dataset.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-168.pdf
2016,Visualizing stacked autoencoder language learning,"Trevor Barron, Matthew Whitehead","Visualizing the features of unsupervised deep networks is an important part of understanding what a network has learned.  In this paper, we present a method for visualizing a deep autoencoder's hidden layers when trained on natural language data.  Our method provides researchers insight into the semantic language features the network has extracted from the dataset.  It can also show a big picture view of what a network has learned and how the various features the network has extracted relate to one another in semantic hierarchies.  We hope that these visualizations will aid human understanding of deep networks and can help guide future experiments.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-70.pdf
2016,Machine learning for medical applications,"Veronica Bolon-Canedo, Beatriz Remeseiro, Amparo Alonso-Betanzos, Aurélio Campilho","Machine learning has been well applied and recognized as an effective tool to handle a wide range of real situations, including medical applications. In this scenario, it can help to alleviate problems typically suffered by researchers in this field, such as saving time for practitioners and providing unbiased results. This tutorial is concerned with the use of machine learning techniques to solve different medical problems. We provide a survey of recent methods developed or applied to this context, together with a review of novel contributions to the ESANN 2016 special session on Machine learning for medical applications.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-17.pdf
2016,Gesture Recognition with a Convolutional Long Short-Term Memory Recurrent Neural Network,"Eleni Tsironi, Pablo Barros, Stefan Wermter","Inspired by the adequacy of convolutional neural networks in implicit extraction of visual features and the efficiency of Long Short-Term Memory Recurrent Neural Networks in dealing with long-range temporal dependencies, we propose a Convolutional Long Short-Term Memory Re- current Neural Network (CNNLSTM) for the problem of dynamic gesture recognition. The model is able to successfully learn gestures varying in duration and complexity and proves to be a significant base for further development. Finally, the new gesture command TsironiGR-dataset for human-robot interaction is presented for the evaluation of CNNLSTM.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-139.pdf
2016,A new penalisation term for image retrieval in clique neural networks,"Romain Huet, Nicolas Courty, Sébastien Lefèvre","Neural networks that are able to retrieve store and retrieve information constitue an old but still active area of research. Among the dierent existing architectures, recurrent networks that combine as- sociative memory with error correcting properties based on cliques have recently shown good performances on storing arbitrary random messages. However, they fail in scaling up to large dimensions data such as images, mostly because the distribution of activated neurons is not uniform in the network. We propose in this paper a new penalization term that alle- viates this problem, and shows its eciency on partially erased images reconstruction problem.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-122.pdf
2016,"An Immune-Inspired, Dependence-Based Approach to Blind Inversion of Wiener Systems","Stephanie Alvarez Fernandez, Romis Attux, Denis G. Fantinato, Jugurta Montalvão, Daniel Silva","In this work, we present a comparative analysis of two methods --- based on the autocorrelation and autocorrentropy functions --- for representing the time structure of a given signal in the context of the unsupervised inversion of Wiener systems by Hammerstein systems. Linear stages with and without feedback are considered and an immune-inspired algorithm is used to allow parameter optimization without the need for manipulating the cost function, and also with a significant probability of global convergence. The results indicate that both functions provide effective means for system inversion and also illustrate the effect of linear feedback on the overall system performance.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-81.pdf
2016,Differentiable piecewise-Bézier interpolation on Riemannian manifolds,"Pierre-Antoine Absil, Pierre-Yves Gousenbourger, Paul Striewski, Benedikt Wirth","Given a set of manifold-valued data points associated to a regular 2D grid, we propose a method to interpolate those by means of a C1-Bézier surface. To this end, we generalize classical Euclidean piecewise-Bézier surfaces to manifolds. We then propose an efficient algorithm to compute the control points defining the surface based on the Euclidean concept of natural C2-splines and show examples on different manifolds.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-96.pdf
2016,Bayesian mixture of spatial spline regressions,Faicel Chamroukhi,"We introduce a Bayesian mixture of spatial spline regressions with mixed-effects (BMSSR) for density estimation and model-based clustering of spatial functional data. The model, through its Bayesian formulation, allows to integrate possible prior knowledge on the data structure and constitute a good alternative to a recent mixture of spatial spline regressions model estimated in a maximum likelihood framework via the expectation-maximization (EM) algorithm. The Bayesian model inference is performed by Markov Chain Monte Carlo (MCMC) sampling. We derive a Gibbs sampler to infer the model and apply it on simulated surfaces and a real problem of handwritten digit recognition using the MNIST data.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-179.pdf
2016,Comparison of three algorithms for parametric change-point detection,"Cynthia Faure, Jean-Marc Bardet, Madalina Olteanu, Jérôme Lacaille","Numerous sensors on SNECMA's engines capture a considerable amount of data during tests or flights. In order to detect potential crucial changes of characteristic variables, it is relevant to develop powerful statistical algorithms. This manuscript is devoted to offline change-point detection, in piecewise linear models with an unknown number of change-points. In this context, three recent algorithms are considered, implemented and applied to simulated and real data.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-159.pdf
2016,A reservoir activation kernel for trees,"Davide Bacciu, Claudio Gallicchio, Alessio Micheli",We introduce an efficient tree kernel for reservoir computing models exploiting the recursive encoding of the structure in the state activations of the untrained recurrent layer. We discuss how the contractive property of the reservoir induces a topographic organization of the state space that can be used to compute structural matches in terms of pairwise distances between points in the state space. The experimental analysis shows that the proposed kernel is capable of achieving competitive classification results by relying on very small reservoirs comprising as little as $10$ sparsely connected recurrent neurons.,Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-172.pdf
2016,Measuring the Expressivity of Graph Kernels through the Rademacher Complexity,"Luca Oneto, Nicolò Navarin, Michele Donini, Alessandro Sperduti, Fabio Aiolli, Davide Anguita","Graph kernels are widely adopted in real-world applications that involve learning on graph data.  Different graph kernels have been proposed in literature, but no theoretical comparison among them is present.  In this paper we provide a formal definition for the expressiveness of a graph kernel by means of the Rademacher Complexity, and analyze the differences among some state-of-the-art graph kernels.  Results on real world datasets confirm some known properties of graph kernels, showing that the Rademacher Complexity is indeed a suitable measure for this analysis.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-150.pdf
2016,RNAsynth: constraints learning for RNA inverse folding.,"Fabrizio Costa, Parastou Kohvaei, Robert Kleinkauf","RNA polymers are an important class of molecules: not only they are involved in a variety of biological functions, from coding to decoding, from regulation to expression of genes, but crucially, they are nowadays easily synthesizable, opening interesting application scenarios in biotechnological and biomedical domains. Here we propose a constructive machine learning framework to aid in the rational design of such polymers. Using a graph kernel approach in a supervised setting we define an importance notion over molecular parts. We then convert the set of most important parts into specific sequence and structure constraints. Finally an inverse folding algorithm uses these constraints to compute the desired RNA sequence.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-137.pdf
2016,Kernel based collaborative filtering for very large scale top-N item recommendation,"Fabio Aiolli, Mirko Polato","The increasing availability of implicit feedback datasets has raised the interest in developing effective collaborative filtering techniques able to deal asymmetrically with unambiguous positive feedback and ambiguous negative feedback.  In this paper, we propose a principled kernel-based collaborative filtering method for top-N item recommendation with implicit feedback.  We present an efficient implementation using the linear kernel, and how to generalize it to other kernels preserving efficiency.  We compare our method with the state-of-the-art algorithm on the Million Songs Dataset achieving an execution about 5 time faster, while having comparable effectiveness.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-111.pdf
2016,Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,"Luca Oneto, Nicolò Navarin, Michele Donini, Fabio Aiolli, Davide Anguita","Kernel methods consistently outperformed previous generations of learning techniques. They provide a flexible and expressive learning framework that has been successfully applied to a wide range of real world problems but, recently, novel algorithms, such as Deep Neural Networks and Ensemble Methods, have increased their competitiveness against them. Due to the current data growth in size, heterogeneity and structure, the new generation of algorithms are expected to solve increasingly challenging problems. This must be done under growing constraints such as computational resources, memory budget and energy consumption. For these reasons, new ideas have to come up in the field of kernel learning, such as deeper kernels and novel algorithms, to fill the gap that now exists with the most recent learning paradigms. The purpose of this special session is to highlight recent advances in learning with kernels. In particular, this session welcomes contributions toward the solution of the weaknesses (e.g. scalability, computational efficiency and too shallow kernels) and the improvement of the strengths (e.g. the ability of dealing with structural data) of the state of the art kernel methods. We also encourage the submission of new theoretical results in the Statistical Learning Theory framework and innovative solutions to real world problems.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-21.pdf
2016,"Feature definition, analysis and selection for lung nodule classification in chest computerized tomography images","Luis Gonçalves, Jorge Novo, Aurélio Campilho","This work presents the results of the characterization of lung nodules in chest Computerized Tomography for benign/malignant classification. A set of image features was used in the Computer-aided Diagnosis system to distinguish benign from malignant nodules and, therefore, diagnose lung cancer. A filter-based feature selection approach was used in order to define an optimal subset with higher accuracy.  A large and heterogeneous set of 293 features was defined, including shape, intensity and texture features. We used different KNN and SVM classifiers to evaluate the features subsets. The estimated results were tested in a dataset annotated by radiologists. Promising results were obtained with an area under the Receiver Operating Characteristic curve (AUC value) of 96.2 ± 0.5 using SVM.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-142.pdf
2016,A machine learning pipeline for supporting differentiation of glioblastomas from single brain metastases,"Victor Mocioiu, Nuno Miguel Pedrosa de Barros, Sandra Ortega-Martorell, Johannes Slotboom, Urspeter Knecht, Carles Arús, Alfredo Vellido, Margarida Julià-Sapé","Machine learning has provided, over the last decades, tools for knowledge extraction in complex medical domains. Most of these tools, though, are ad hoc solutions and lack the systematic approach that would be required to become mainstream in medical practice. In this brief paper, we define a machine learning-based analysis pipeline for a difficult problem in the field of neuro-oncology, namely the discrimination of brain glioblastomas from single brain metastases. This pipeline involves source extraction using k-Means-initialized Convex Non-negative Matrix Factorization and a collection of classifiers, including Logistic Regression, Linear Discriminant Analysis, AdaBoost, and Random Forests.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-82.pdf
2016,Stacked denoising autoencoders for the automatic recognition of microglial cells’ state,"Sofia Fernandes, Ricardo Sousa, Renato Socodato, Luis Silva","We present the first study for the automatic recognition of microglial cells' state using stacked denoising autoencoders. Microglia has a pivotal role as sentinel of neuronal diseases where its state (resting, transition or active) is indicative of what is occurring in the Central Nervous System. In this work we delve on different strategies to best learn a stacked denoising autoencoder for that purpose and show that the transition state is the most hard to recognize while an accuracy of approximately 64% is obtained with a  dataset of 45 images.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-8.pdf
2016,Interpretability of machine learning models and representations: an introduction,"Adrien Bibal, Benoît Frénay","Interpretability is often a major concern in machine learning.  Although many authors agree with this statement, interpretability is often tackled with intuitive arguments, distinct (yet related) terms and heuristic quantifications.  This short survey aims to clarify the concepts related to interpretability and emphasises the distinction between interpreting models and representations, as well as heuristic-based and user-based approaches.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-141.pdf
2016,RSS-based Robot Localization in Critical Environments using Reservoir Computing,"Mauro Dragone, Claudio Gallicchio, Roberto Guzman, Alessio Micheli","Supporting both accurate and reliable localization in critical environments is key to increasing the potential of logistic mobile robots. This paper presents a system for indoor robot localization based on Reservoir Computing from noisy radio signal strength index (RSSI) data generated by a network of sensors. The proposed approach is assessed under different conditions in a real-world hospital environment. Experimental results show that the resulting system represents a good trade-off between localization performance and deployment complexity, with the ability to recover from cases in which permanent changes in the environment affect its generalization performance.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-176.pdf
2016,Using Robust Extreme Learning Machines to Predict Cotton Yarn Strength and Hairiness,"Diego Mesquita, Antonio Araujo Neto, Jose Queiroz Neto, Joao Gomes, Leonardo Rodrigues","Cotton yarn is often spun from a mixture of distinct cotton  bales. Although many studies have presented eorts to predict hairiness and strength from cotton properties, the heterogeneity of this mixture and its influence in such values have been neglected so far. In this work the properties of the cotton bale mixture are modeled as random variables and a robust variant of the Extreme Learning Machine (ELM) to address the cotton quality prediction problem is proposed. A real world dataset collected from a textile industry was used to compare the performance of the proposed model with a traditional ELM and a linear regression model. The results showed that the proposed method outperformed the benchmark methods in terms of Average Root Mean Square Error (ARMSE).",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-187.pdf
2016,Auto-adaptive Laplacian Pyramids,"Ángela Fernández, Neta Rabin, Dalia Fishelov, José R. Dorronsoro","An important challenge in Data Mining and Machine Learning is the proper analysis of a given dataset, especially for understanding and working with functions defined over it. In this paper we propose Auto-adaptive Laplacian Pyramids (ALP) for target function smoothing when the target function is defined on a high-dimensional dataset. The proposed algorithm automatically selects the optimal function resolution (stopping time) adapted to the data defined and its noise. We illustrate its application on a radiation forecasting example.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-131.pdf
2016,Modelling of parameterized processes via regression in the model space,"Witali Aswolinskiy, Rene Felix Reinhart, Jochen Steil","We consider the modelling of parameterized processes, where the goal is to model the process for new parameter value combinations. We compare the classical regression approach to a modular approach based on regression in the model space: First, for each process parametrization a model is learned, second, a mapping from process parameters to model parameters is learned. We evaluate both approaches on a real and a synthetic dataset and show the advantages of the regression in the model space.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-169.pdf
2016,Efficient low rank approximation via alternating least squares for scalable kernel learning,"Piyush Bhardwaj, Harish Karnick","Kernel approximation is an effective way of dealing with the scalability challenges of computing, storing and learning with kernel matrix. In this work, we propose an $O(|\Omega|r^2)$ time algorithm for rank $r$ approximation of the kernel matrix by computing $|\Omega|$ entries. The proposed algorithm solves a non-convex optimization problem by random sampling of the entries of the kernel matrix followed by a matrix completion step using alternating least squares (ALS). Empirically, our method shows better performance than other baseline and state-of-the-art kernel approximation methods on several standard real life datasets. Theoretically, we extend the current guarantees of ALS for kernel approximation.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-115.pdf
2016,Gaussian process prediction for time series of structured data,"Benjamin Paassen, Christina Göpfert, Barbara Hammer","Time series prediction constitutes a classic topic in machine learning with wide-ranging applications, but mostly restricted to the domain of vectorial sequence entries.  In recent years, time series of structured data (such as sequences, trees or graph structures) have become more and more important, for example in social network analysis or intelligent tutoring systems.  In this contribution, we propose an extension of time series models to strucured data based on Gaussian processes and structure kernels. We also provide speedup techniques for predictions in linear time, and we evaluate our approach on theoretical as well as real data.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-109.pdf
2016,Learning with hard constraints as a limit case of learning with soft constraints,"Giorgio Gnecco, Marco Gori, Stefano Melacci, Marcello Sanguineti","We refer to the framework of learning with mixed hard/soft pointwise constraints considered in Gnecco et al., IEEE TNNLS, vol. 26, pp. 2019-2032, 2015. We show that the optimal solution to the learning problem with hard bilateral and linear pointwise constraints stated therein can be obtained as the limit of the sequence of optimal solutions to the related learning problems with soft bilateral and linear pointwise constraints, when the penalty parameter tends to infinity.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-32.pdf
2016,Automatic detection of EEG arousals,"Isaac Fernández-Varela, Elena Hernández-Pereira, Diego Álvarez-Estévez, Vicente Moret-Bonillo","Fragmented sleep is commonly caused by arousals that can be detected with the observation of electroencephalographic (EEG) signals. As this is a time consuming task, automatization processes are required. A method using signal processing and machine learning models, for arousal detection, is presented. Relevant events are identified in the EEG signals and in the electromyography, during the signal processing phase. After discarding those events that do not meet the required characteristics, the resulting set is used to extract multiple parameters. Several machine learning models -Fisher's Linear Discriminant, Artificial Neural Networks and Support Vector Machines- are fed with these parameters. The final proposed model, a combination of the different individual models, was used to conduct experiments on 26 patients, reporting a sensitivity of 0.72 and a specificity of 0.89, while achieving an error of 0.13, in the arousal events detection.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-138.pdf
2017,Dropout Prediction at University of Genoa: a Privacy Preserving Data Driven Approach,"Luca Oneto, Anna Siri, Gianvittorio Luria, Davide Anguita","Nowadays many educational institutions crucially need to understand the dynamics at the basis of the university dropout (UD) phenomenon. However, the most informative educational data are personal and subject to strict privacy constraints. The challenge is therefore to develop a data driven system which accurately predicts students dropouts while preserving the privacy  of individual data instances. In the present paper we investigate this problem, making use of data collected at University of Genoa as a case study.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-54.pdf
2017,An EM transfer learning algorithm with applications in bionic hand prostheses,"Benjamin Paassen, Alexander Schulz, Janne Hahne, Barbara Hammer","Modern bionic hand prostheses feature unprecedented functionality, permitting simultaneous motion in multiple degrees of freedom. An intuitive user interface based on muscle signals requires machine learning models. However, current models are not yet sufficiently robust to everyday disturbances, such as electrode shifts. We propose a novel expectation maximization approach for transfer learning to rapidly recalibrate a machine learning model if disturbances occur. In our experimental evaluation we show that even under conditions of incomplete class coverage and few data points our approach finds a viable transfer mapping which improves classification accuracy significantly.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-57.pdf
2017,Distance metric learning: a two-phase approach,"Bac Nguyen, Carlos Morell, Bernard De Baets","Distance metric learning has been successfully incorporated in many machine learning applications. The main challenge arises from the positive semidefiniteness constraint on the Mahalanobis matrix, which results in a high computational cost. In this paper, we develop a novel approach to reduce this computational burden. We first map each training example into a new space by an orthonormal transformation. Then, in the transformed space, we simply learn a diagonal matrix. This two-phase approach is thus much easier and less costly than learning a full Mahalanobis matrix in one phase as is commonly done.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-8.pdf
2017,Fine-grained event learning of human-object interaction with LSTM-CRF,"Tuan Do, James Pustejovsky","Event learning is one of the most important problems in AI. However, notwithstanding significant research efforts, it is still a very complex task, especially when the events involve the interaction of humans or agents with other objects, as it  requires modeling human kinematics and object movements. This study proposes a methodology for learning  complex human-object interaction (HOI) events, involving the recording, annotation and classification of event interactions. For annotation, we allow multiple interpretations of a motion capture by slicing over its temporal span; for classification, we use Long-Short Term Memory (LSTM) sequence models with Conditional Randon Field (CRF) for constraints of outputs. Using a setup involving captures of human-object interaction as three dimensional inputs, we argue that this approach could be used for event types involving complex spatio-temporal dynamics.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-34.pdf
2017,Random projection initialization for deep neural networks,"Piotr Iwo Wójcik, Marcin Kurdziel","In this work we propose to initialize rectifier neural networks with random projection matrices. We focus on Convolutional Neural Networks and fully-connected networks with pretraining. Our results show, that in convolutional networks a well designed random projection initialization can perform better than the current state-of-the-art He's initialization. Specifically, in our evaluation, initialization based on the Subsampled Randomized Hadamard Transform consistently outperformed He's initialization on several evaluated image classification datasets.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-43.pdf
2017,Advanced query strategies for Active Learning with Extreme Learning Machines,"Anton Akusok, Emil Eirola, Yoan Miché, Andrey Gritsenko, Amaury Lendasse","This work addresses an important part of solving applied problems that is data acquisition. Often raw data is cheap while labeling is an expensive manual job. Active Learning reduces the labeling effort by suggesting particular samples with a query strategy. The paper proposes three new query strategies built on recent developments in extreme learning machines: based a committee of class-weighted ELM, based on prediction intervals found with ELM, and based on mislabeled samples detection with ELM. The proposed strategies perform on the state-of-the-art level on three real world datasets.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-92.pdf
2017,ELM Preference Learning for Physiological Data,"Davide Bacciu, Michele Colombo, Davide Morelli, David  Plans","The work confronts two approaches to realize preference learning using Extreme Learning Machine networks, relaying on limited and subject-dependant information concerning pairwise relations between data samples. We describe an application within the context of assessing the effect of breathing exercises on heart-rate variability, using a dataset of over $19$K exercising sessions. Results highlight the importance of using weight sharing architectures to learn smooth e generalizable complete orders induced by the preference relation.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-27.pdf
2017,Physical activity recognition from sub-bandage sensors using both feature selection and extraction,"Thiago Turchetti Maia, Fabio Di Francesco, Valentina Dini, Beatrice Lazzerini, Marco Romanelli, Pietro Salvo","In this paper, we present a neural network-based approach to classify the activities performed by 40 subjects by analyzing sub-bandage pressure signals. The approach includes an input dimensionality reduction obtained employing both feature extraction and feature selection techniques. The results show that our model is able to classify the activities performed with 98.12% accuracy.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-70.pdf
2017,Bridging deep and kernel methods,"Lluís Belanche, Marta Costa-jussa",,Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-5.pdf
2017,Scalable Hybrid Deep Neural Kernel Networks,"Siamak Mehrkanoon, Andreas Zell, Johan A. K. Suykens","This paper introduces a novel hybrid deep neural kernel framework. The proposed deep learning model follows a combination of neural networks based architecture and a kernel based model. In particular, here an explicit feature map, based on random Fourier features, is used to make the transition between the two architectures more straightforward as well as making the model scalable to large datasets by solving the optimization problem in the primal. The introduced framework can be considered as the first building block for the development of even deeper models and more advanced architectures. Experimental results show a significant improvement over shallow models on several medium to large scale real-life datasets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-97.pdf
2017,Structure optimization for deep multimodal fusion networks using graph-induced kernels,"Dhanesh Ramachandram, Michal Lisicki, Timothy J. Shields, Mohamed R. Amer, Graham W. Taylor","A popular testbed for deep learning has been multimodal recognition of human activity or gesture involving diverse inputs such as video, audio, skeletal pose and depth images. Deep learning architectures have excelled on such problems due to their ability to combine modality representations at different levels of nonlinear feature extraction. However, designing an optimal architecture in which to fuse such learned represen- tations has largely been a non-trivial human engineering effort. We treat fusion structure optimization as a hyper-parameter search and cast it as a discrete optimization problem under the Bayesian optimization frame- work. We propose a novel graph-induced kernel to compute structural similarities in the search space of tree-structured multimodal architectures and demonstrate its effectiveness using two challenging multimodal human activity recognition datasets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-108.pdf
2017,Algebraic multigrid support vector machines,"Ehsan Sadrfaridpour, Sandeep Jeereddy, Ken Kennedy, Andre Luckow, Talayeh Razzaghi, Ilya Safro","The support vector machine is a flexible optimization-based technique widely used for classification problems. In practice, its training part becomes computationally expensive on large-scale data sets because of such reasons as the complexity and number of iterations in the parameter fitting methods, underlying optimization solvers, and nonlinearity of kernels. We introduce a fast multilevel framework for solving support vector machine models that is inspired by the algebraic multigrid. Significant improvement in the running has been achieved without any loss in the quality. The proposed technique is highly beneficial on imbalanced sets. We demonstrate computational results on publicly available and industrial data sets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-37.pdf
2017,Support vector components analysis,"Michiel van der Ree, Jos Roerdink, Christophe Phillips, Gaëtan Garraux, Eric Salmon, Marco Wiering","In this paper we propose a novel method for learning a distance metric in the process of training Support Vector Machines (SVMs) with various kernels. A transformation matrix is adapted in such a way that the SVM dual objective of a classification problem is optimized. By using a wide transformation matrix the method can effectively be used as a means of supervised dimensionality reduction. We compare our method with other algorithms on a toy dataset and on PET-scans of patients with various Parkinsonisms, finding that our method either outperforms or performs on par with the other algorithms.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-63.pdf
2017,Attention-based Information Fusion using Multi-Encoder-Decoder Recurrent Neural Networks,"Stephan Baier, Sigurd Spieckermann, Volker Tresp","With the rising number of interconnected devices and sensors, modeling distributed sensor networks is of increasing interest. Recurrent neural networks (RNN) are considered particularly well suited for modeling sensory and streaming data. When predicting future behavior, incorporating information from neighboring sensor stations is often beneficial. We propose a new RNN based architecture for context specific information fusion across multiple spatially distributed sensor stations. Hereby, latent representations of multiple local models, each modeling one sensor station, are jointed and weighted, according to their importance for the prediction. The particular importance is assessed depending on the current context using a separate attention function. We demonstrate the effectiveness of our model on three different real-world sensor network datasets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-135.pdf
2017,Learning dot-product polynomials for multiclass problems,"Ivano Lauriola, Michele Donini, Fabio Aiolli","Several mechanisms exist in the literature to solve a multiclass classification problem exploiting a binary kernel-machine. Most of them are based on problem decomposition that consists on splitting the problem in many binary tasks. These tasks have different complexity and they require different kernels. Our goal is to use the Multiple Kernel Learning (MKL) paradigm to learn the best dot-product kernel for each decomposed binary task. In this context, we propose an efficient learning procedure to reduce the searching space of hyperparameters, showing its empirically effectiveness.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-120.pdf
2017,A multi-criteria meta-learning method to select under-sampling algorithms for imbalanced datasets,"Romero Morais, Péricles Miranda, Ricardo Silva","Standard classifiers consider a balanced distribution of examples' classes in the data, thus, imbalanced datasets may hinder the learning process. Sampling techniques balance the data by adjusting the examples' classes distribution. However, selecting an appropriate sampling technique and its parameters for a given imbalanced dataset is still an open problem. This work proposes a method that uses Meta-Learning to recommend a technique for an imbalanced dataset considering multiple performance criteria. The experiments revealed that the proposal reached results comparable to those achieved by the brute-force approach, overcame the techniques with their default parameters most of the time, and always surpassed the random search approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-11.pdf
2017,Large-scale nonlinear dimensionality reduction for network intrusion detection,"Yasir Hamid, Ludovic Journaux, John Aldo Lee, Lucile Sautot, Nabi Bushra, M. Sugumaran","Network intrusion detection (NID) is a complex classification problem. In this paper, we combine classification with recent and scalable nonlinear dimensionality reduction (NLDR) methods. Classification and DR are not necessarily adversarial, provided adequate cluster magnification occurring in NLDR methods like t-SNE: DR mitigates the curse of dimensionality, while cluster magnification can maintain class separability. We demonstrate experimentally the effectiveness of the approach by analyzing and comparing results on the big KDD99 dataset, using both NLDR quality assessment and classification rate for SVMs and random forests. Since data involves features of mixed types (numerical and categorical), the use of Gower’s similarity coefficient as metric further improves the results over the classical similarity metric.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-71.pdf
2017,Acceleration of Prototype Based Models with Cascade Computation,"Cem Karaoguz, Alexander Gepperth","Prototype-based generative description of data space is shown to be effective in incremental learning. However, computation of similarities of input vectors to prototypes may be demanding especially in the face of high input dimensions and high number of prototypes. The main contribution of the paper is the acceleration of the prototype-based model by a cascade computation approach.  The evaluation of the presented architecture on a human detection and pose estimation problem shows that the cascade computation results in a significant reduction of computational resource requirements at the expense of minor degradations in the classification performance.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-117.pdf
2017,Automatic crime report classication through a weightless neural network,"Rafael Adnet Pinho, Walkir Brito, Claudia Motta, Priscila Lima",Anonymous crime reporting is a tool that helps to reduce and prevent crime occurrences. The classification of the crime reports received by the call center is necessary for the data organization and also to stipulate the importance of a particular report and its relation to others. The objective of this work is to develop a system that assists the call center's operator by recommending classification to new reports. The system uses a weightless neural network that automatically attribute a class to a report. At the end of this work it was possible to observe that automatic classifications of crime reports with high accuracy are possible using a weightless neural network.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-42.pdf
2017,Efficient Neural-based patent document segmentation with Term Order Probabilities,"Danilo Silva de Carvalho, Minh-Le Nguyen","The internationally growing trend of patent applications puts great pressure on the agents involved in managing this kind of information and creates a demand for efficient and effective patent analysis methods. This work presents an computationally efficient approach for patent document segmentation based on structured ANNs and a simple distributional semantics composition method. The conducted experiments indicate effectiveness of the approach, which benefits a wide array of patent processing techniques that work upon structured inputs.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-123.pdf
2017,Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,"Gyan Bhanot, Michael Biehl, Thomas Villmann, Dietlind Zühlke",,Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-2.pdf
2017,Feature Relevance Bounds for Linear Classification,"Christina Göpfert, Lukas Pfannschmidt, Barbara Hammer","Biomedical applications often aim for an identification of relevant features for a given classification task, since         these carry the promise of semantic insight into the underlying process.         For correlated input dimensions,         feature relevances are not unique, and the identification of meaningful subtle biomarkers remains a challenge. One approach is to identify           intervals for the possible relevance         of given features, a problem related to all relevant feature determination.         In this contribution, we address the important case of linear classifiers and         we transfer the problem how to infer feature relevance bounds to a convex optimization problem.         We demonstrate the superiority of the resulting technique in comparison to popular          feature-relevance determination methods in several benchmarks.",Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-67.pdf
2017,Prediction of preterm infant mortality with Gaussian process classification,"Olli-Pekka Rinta-Koski, Simo Särkkä, Jaakko Hollmén, Markus Leskinen, Sture Andersson","We present a method for predicting preterm infant in-hospital-mortality using Bayesian Gaussian process classification. We combined features extracted from sensor measurements, made during the first 24 hours of care for 581 Very Low Birth Weight infants, with standard clinical features calculated on arrival at the Neonatal Intensive Care Unit. We achieved a classification result with area under curve of 0.94 (standard error 0.02), which is in excess of the results achieved by using the clinical standard SNAP-II and SNAPPE-II scores.",Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-86.pdf
2017,Comparison of strategies to learn from imbalanced classes for computer aided diagnosis of inborn steroidogenic disorders,"Sreejita Ghosh, Elizabeth Sarah Baranowski, Rick van Veen, Gert-Jan de Vries, Michael Biehl, Wiebke Arlt, Peter Tino, Kerstin Bunte",,Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-94.pdf
2017,Environmental signal processing: new trends and applications,"Matthieu Puigt, Gilles Delmaire, Gilles Roussel",,Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-1.pdf
2017,Solving Inverse Source Problems for Sources with Arbitrary Shapes using Sensor Networks,"John Murray-Bruce, Pier Luigi Dragotti","Recently, the use of wireless sensor networks for environmental monitoring has been a topic of intensive research. The sensor nodes obtain spatiotemporal samples of physical fields over the region of interest. For most cases these fields are driven by well-known partial differential equations---the diffusion and wave equations for example---and this prior knowledge can be used to solve such \textit{physics-driven} inverse source problems (ISPs). In this work, we demonstrate how to estimate the unknown source shape inducing the field by assuming that it can be described by a model having a finite number of unknown parameters.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-103.pdf
2017,Non-negative decomposition of geophysical dynamics,"Manuel Lopez-Radcenco, Abdeldjalil Aïssa-El-Bey, Pierre Ailliot, Ronan Fablet","The decomposition of geophysical processes into relevant modes is a key issue for characterization, forecasting and reconstruction problems. The blind separation of contributions from different sources is a well-studied problem in signal and image processing. Recently, significant advances have been reported with the introduction of non-negative and sparse formulations. In this work, we address an extension to the blind decomposition of linear operators or transfer functions between variables of interest with an emphasis on a non-negative setting. As illustrated here, such decompositions are of key interest for the analysis of geophysical dynamics and the relationships between different geophysical variables.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-83.pdf
2017,Impact of the initialisation of a blind unmixing method dealing with intra-class variability,"Charlotte REVEL, Yannick Deville, Véronique ACHARD, Xavier BRIOTTET","In hyperspectral imagery, unmixing methods are often used to analyse the composition of the pixels. Such methods usually suppose that a single spectral signature, called an endmember, can be associated with each pure material present in the scene. Such an assumption is no more valid for materials that exhibit spectral variability due to illumination conditions, weathering, slight variations of the composition, etc. In this paper, we investigate a new method based on the assumption of a linear mixing model, that deals with intra-class spectral variability. A new formulation of the linear mixing is provided. In our model a pure material cannot be described by a single spectrum in the image but it can in a pixel. A method is presented to handle this new model. It is based on a pixel-by-pixel Nonnegative Matrix Factorization (NMF) methods. The method is tested on a semi-synthetic data set built with spectra extracted from a real hyperspectral image and mixtures of these spectra. We particularly focused our tests to study the impact of the initialisation of our method.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-74.pdf
2017,Application of Tensor and Matrix Completion on Environmental Sensing Data,"Michalis Giannopoulos, Sofia Savvaki, Grigorios Tsagkatakis, Panagiotis Tsakalides","As environmental resources utilization becomes more and more crucial, Wireless Sensor Networks (WSNs) are introduced in order to capture the variation of diverse parameters. However, limitations such as network connectivity, power consumption, and storage capacity lead to missing measurements from such networked sensors. To address this problem, we investigate the potential of recovering high dimensional environmental signals from small sets of observations. To account for the dimen- sionality of the data, we invoke tensor modelling and we propose a low-rank tensor recovery formulation. Experimental results using real WSN data from an indoor industrial environment as well as from an outdoor natural environment demonstrate that the estimation of missing measurements is much better addressed when structural information is considered.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-136.pdf
2017,Indoor air pollutant sources using Blind Source Separation Methods,"Rachid OUARET, Anda IONESCU, Olivier RAMALHO, Yves CANDAU","The objective of this study is to separate different sources of variability of air pollutant concentrations time series of particulate matter (PM) monitored in real indoor environments. Different blind source separation (BSS) methods (ICA, PMF, NMF) were applied in order to identify the PM sources and their contributions. The source profiles were characterized by their autocorrelation functions (ACF) which were compared to the ACFs of other variables. Their interpretation was completed by the analysis of polar plots including exogenous factors. Source contributions were also quantified.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-131.pdf
2017,High dimensionality voltammetric biosensor data processed with artificial neural networks,"Andreu González-Calabuig, Georgina Faura, Manel del Valle","This work report the coupling of an array of voltammetric sensors with artificial neural networks (ANN), usually named Electronic Tongue, for the simultaneous quantification of tryptophan, tyrosine and cysteine aminoacids. The obtained signals were compressed using fast Fourier transform (FFT) and then the ANN model was constructed from a set of low-frequency components. An ANN predictive model was obtained by back-propagation, which had 160 input neurons, one hidden layer with 7 neurons and used purelin and satlins functions in the hidden and output layer respectively, trained with a factorial design scheme . The model attained a total normalized root mean square error of 0.032 for an independent test set of data (n=15).",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-149.pdf
2017,Fusion of Stereo Vision for Pedestrian Recognition using Convolutional Neural Networks,"Danut Ovidiu Pop, Alexandrina Rogozan, Fawzi Nashashibi, Abdelaziz Bensrhair","Pedestrian detection is a highly debated issue in scientific world due to its outstanding importance for a large number of applications, especially in the fields of automotive safety, robotics and surveillance. In spite of the widely varying methods developed in recent years, pedestrian detection is still an open challenge whose accuracy and robustness has to  be improved. Therefore, in this paper, we focus on the improvement of the classification component in the pedestrian detection task on the Daimler stereo vision data set by adopting two approaches:  1) by combining three image modalities (intensity, depth and flow) to feed a unique convolutional neural network (CNN) and 2) by fusing the results of three independent CNNs.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-96.pdf
2017,Training convolutional networks with weight–wise adaptive learning rates,"Alan Mosca, George Magoulas","Current state–of–the–art Deep Learning classification with Convolutional Neural Networks achieves very impressive results, which are, in some cases, close to human level performance. However, training these methods to their optimal performance requires very long training periods, usually by applying the Stochastic Gradient Descent method. We show that by applying more modern methods, which involve adapting a different learning rate for each weight rather than using a single, global, learning rate for the entire network, we are able to reach close to state–of–the–art performance on the same architectures, and improve the training time and accuracy.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-50.pdf
2017,Invariant representations of images for better learning,"Muthuvel Murugan Issakkimuthu, Subrahmanyam K. V.","We study the problem of obtaining representations of images which are invariant to transformation of the image under rotations, towards improving supervised learning. We show that using simple ideas from group representation theory we get invariant representations of images. Off the shelf learning algorithms perform much better on such representations.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-130.pdf
2017,Feature Extraction for On-Road Vehicle Detection Based on Support Vector Machine,"Samuel Giatti Silva Filho, Roberto Freire, Leandro dos Santos Coelho","Inspired by alarming statistics of deaths and injuries in car accidents, this work presents the development of vehicles detection method, which is part of an Advanced Driving Assistance System. A computer vision software capable to interpret real-time events on roads, that can identify vehicles based on Support Vector Machine, was presented and evaluated by adopting two distinct techniques for features extraction. Comparisons between two feature extraction techniques (Invariant Features Transform and Histogram of Oriented Gradients) were presented, and promising results in terms of vehicles identification accuracy were obtained when a frame scan technique was integrated to the system.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-112.pdf
2017,Predicting Time Series with Space-Time Convolutional and Recurrent Neural Networks,"Wolfgang Groß, Sascha Lange, Joschka Bödecker, Manuel Blum","We present a novel approach to predict time series with a deep recurrent and convolutional neural network. In order to apply modern deep learning techniques to financial time series, deep neural networks have to learn problem-specific, spatio-temporal features. In computer vi- sion, convolutional neural networks with their ability to learn useful spatial features have given rise to groundbreaking results, but spatio-temporal patterns—as they arise in multivariate financial time series—pose additional challenges. We demonstrate that the features the model learns are better than hand-crafted features of a professional trader. We also show that our model beats other models at predicting the price development on the European Power Exchange (EPEX).",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-38.pdf
2017,Randomized Machine Learning Approaches: Recent Developments and Challenges,"Claudio Gallicchio, José D. Martín-Guerrero, Alessio Micheli, Emilio Soria-Olivas",,Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-4.pdf
2017,Fisher memory of linear Wigner echo state networks,Peter Tino,"We study asymptotic properties of Fisher memory of linear Echo State Networks with randomized reservoir coupling prescribed by the class of Wigner matrices.  Three properties of Fisher memory normalized per state space dimension are derived: (1) as the system size grows, the contribution of self-coupling of self-loops on reservoir units to the Fisher memory is negligible; (2) the maximal Fisher memory is achieved when the input-to-state coupling is collinear with the dominant eigenvector of the state space coupling matrix; and (3) when the input-to-state coupling is collinear with the sum of eigenvectors of the state space coupling, the expected normalized memory is four time smaller than the maximal memory value.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-69.pdf
2017,Generalization Performances of Randomized Classifiers and Algorithms built on Data Dependent Distributions,"Luca Oneto, Sandro Ridella, Davide Anguita","In this paper we prove that a randomized algorithm based on the data generating dependent prior and data dependent posterior Boltzmann distributions of Catoni (2007) is Differentially Private (DP) and shows better generalization properties than the Gibbs (randomized) classifier associated to the same distributions. For this purpose, we will develop a sharper DP-based generalization bounds, which improve over the current state-of-the-art Hoeffding-type bound.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-53.pdf
2017,A Simple Cluster Validation Index with Maximal Coverage,"Susanne Jauhiainen, Tommi Karkkainen","Clustering is an unsupervised technique to detect general, distinct profiles from a given dataset. Similarly to the existence of various different clustering methods and algorithms, there exists many cluster validation methods and indices to suggest the number of clusters. The purpose of this paper is, firstly, to propose a new, simple internal cluster validation index. The index has a maximal coverage: also one cluster, i.e., lack of division of a dataset into disjoint subsets, can be detected. Secondly, the proposed index is compared to the available indices from five different packages implemented in R or Matlab to assess its utilizability. The comparison also suggests many interesting findings in the available implementations of the existing indices. The experiments and the comparison support the viability of the proposed cluster validation index.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-24.pdf
2017,Fast hyperparameter selection for graph kernels via subsampling and multiple kernel learning,"Michele Donini, Nicolò Navarin, Ivano Lauriola, Fabio Aiolli, Fabrizio Costa","Model selection is one of the most computationally expensive tasks in a machine learning application. When dealing with kernel methods for structures, the choice with the largest impact on the overall performance is the selection of the feature bias, i.e. the choice of the concrete kernel for structures. Each kernel in turn exposes several hyper-parameters which also need to be fine tuned. Multiple Kernel Learning offers a way to approach this computational bottleneck by generating a combination of different kernels under different parametric settings. However, this solution still requires the computation of many large kernel matrices. In this paper we propose a method to efficiently select a small number of kernels on a subset of the original data, gaining a dramatic reduction in the runtime without a significant loss of predictive performance.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-140.pdf
2017,Approximated Neighbours MinHash Graph Node Kernel,"Nicolò Navarin, Alessandro Sperduti","In this paper, we propose a scalable kernel for nodes in a (huge) graph. In contrast with other state-of-the-art kernels that scale more than quadratically in the number of nodes, our approach scales lin- early in the average out-degree and quadratically in the number of nodes (for the Gram matrix computation). The kernel presented in this paper considers neighbours as sets, thus it ignores edge weights. Nevertheless, experimental results on real-world datasets show promising results.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-134.pdf
2017,ELM vs. WiSARD: a performance comparison,"Luiz Oliveira, Felipe França","The Extreme Learning Machine (ELM) is known for being a fast learning neural model. This work presents a performance comparison between ELM and the WiSARD weightless neural network model, regarding training and testing times, and classification accuracy  as well. The two models were implemented in the same programming language and experiments were carried out on the same hardware environment. By using a group of datasets from the public repositories UCI and Statlog, experimental results shows that the WiSARD presented training times approximately one order of magnitude smaller than ELM, while classification accuracy varied according the number of classes involved. However, while WiSARD's architecture setups were not exhaustively searched, architecture setups for ELM were kept the same as the ones found in the literature as the best for each given dataset.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-141.pdf
2017,Complex activity patterns generated by short-term synaptic plasticity,"Bulcsu Sandor, Claudius Gros","Short-term synaptic plasticity (STSP) affects the efficiency of synaptic transmission for persistent presynaptic activities. We consider attractor neural networks, for which the attractors are given, in the absence of STSP, by cell assemblies of excitatory cliques. We show that STSP may transform these attracting states into attractor relics, inducing ongoing transient-state dynamics in terms of sequences of transiently activated cell assemblies, the former attractors. Subsequent cell assemblies may be both disjoint or partially overlapping. It may hence be possible to use the resulting dynamics for the generation of motor control sequences.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-47.pdf
2017,Imitation learning for a continuum trunk robot,"Milad Malekzadeh Shafaroudi, Jeffrey F. Queißer, Jochen J. Steil","The paper applies learning from demonstration (LfD) for high-level trajectory planning and movement control of the Bionic Handling Assistant (BHA) robot. For such soft continuum robot with mechanical elasticity and complex dynamics it is difficult to use kinesthetic teaching to collect demonstration data. We propose to use an active compliant controller to this aim and record both position and orientation of the BHA's end-effector. Subsequently, this data is then encoded with a state-of-the-art task-parameterized probabilistic Gaussian mixture model and its performance and generalization is experimentally evaluated.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-80.pdf
2017,Scholar Performance Prediction using Boosted Regression Trees Techniques,"Bernardo Stearns, Fabio Rangel, Flavio Rangel, Fabrício Faria, Jonice Oliveira",The possibility of predicting a student performance based only on their socioeconomic status may help to infer what cultural features are important in education. This work was based on scores and socioeconomic data from the most popular exam to enter universities in Brazil: the National High School Exam. Statistical and computational methods used in data mining were applied on a data set of 8 millions data points from Brazil's National High School Exam to examine the predictability of the performance in Mathematics based on socioeconomic status. The results showed that it is possible to predict a students' scores using two ensemble techniques: AdaBoost and Gradient Boosting. The latter presented better results.,"Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-65.pdf
2017,Criticality in Biocomputation,Tjeerd olde Scheper,"Complexity in biological computation is one of the recognised means by which biological systems manage to function in a complex chaotic world. The ability to function and solve problems irrespective of scale and relative complexity, including higher-order interactions, is essential to the efficacy of biological systems. However, it has been  unclear how the required complexity can be introduced to allow these functions to be realised. Nonlinear local interactions are required to combine into a global stable system. The property of criticality, that is exhibited by many nonlinear physical systems, can be exploited to allow local nonlinear oscillators to interact, resulting in a globally stable system. This concept introduces robustness, as well as, a means to control global stability.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-89.pdf
2017,A novel principle for causal inference in data with small error variance,"Patrick  Blöbaum, Shohei Shimizu, Takashi Washio","Causal inference addresses the problem of identifying cause and effect variables in observed data. While most of the current techniques base heavily on exploiting asymmetries in the error noise, these techniques struggle in data that only contain small noise. We present a novel principle for causal inference in data with small error variance. For this, we exploit an asymmetry in the prediction error under the assumption of additive noise and an independence between data generating mechanism and its input. The advantages of our approach is corroborated with empirical evaluations in artificial and real-world data sets.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-12.pdf
2017,Learning null space projections fast,"Jeevan Manavalan, Matthew Howard","Typically robot interactions with the environment may involve some type of constraint which impedes the motion of the system. This paper proposes an approach to learn kinematic constraints from observed movements. Our method derives the null space projection of a kinematically constrained system using gradient descent. Moreover, we compare this method to the existing brute force-based approach for learning constraints on datasets of different dimensionality, to demonstrate how it can learn constraints from datasets of a much higher dimensionality.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-10.pdf
2017,Comparison of adaptive MCMC methods,"Edna Milgo, Nixon Ronoh, Peter Waiganjo Wagacha, Bernard Manderick",We compare three adaptive MCMC samplers to Metropolis-Hastings algorithm with optimal proposal distribution as our benchmark. We transform a simple Evolution Strategy algorithm into a sampler and  show that it already outperforms the other samplers on the test suite used in the initial research on adaptive MCMC.,"Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-98.pdf
2017,Degrees of Freedom in Regression Ensembles,"Reeve Henry, Gavin Brown","Negative correlation learning is an effective approach to ensemble learning in which model diversity is encouraged through a correlation penalty term. The level of emphasis placed upon the correlation penalty term is controlled by the diversity parameter. We shall provide a degrees of freedom analysis of negative correlation learning. Our contributions are as follows: we give an exact formula for the effective degrees of freedom in a negative correlation ensemble with fixed basis functions; we show that the effective degrees of freedom is a continuous, convex and monotonically increasing function of the diversity parameter; finally, we show that the degrees of freedom formula gives rise to an efficient way to tune the diversity parameter on large data sets.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-110.pdf
2017,Supporting generative models of spatial behavior by user interaction,"Ronny Hug, Wolfgang Hübner, Michael Arens","The analysis of spatial behavior in terms of motion profiles recorded along trajectories is a widely used technique in video analysis. Inherent to this approach is the problem to assign a meaningful score to observations. This score builds the basis for classification, ranking, or to generate user feedback. Score assignment can be done in terms of deviations from normal behavior, where normality is determined by learning a generative model. A general drawback is that the unsupervised learning process often assigns non-intuitive scores. In order to address this problem this paper proposes the usage of interactive concepts, which support the learning process. Interaction thereby strongly utilizes the generative models capabilities to synthesize samples, to give insight into the underlying representation. Initial results are shown on a trajectory rating task, illustrating the feasibility of the proposed approach.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-91.pdf
2017,Scalable approximate k-NN Graph construction based on Locality Sensitive Hashing,"Carlos Eiras-Franco, Leslie Kanthan, Amparo Alonso-Betanzos, David Martínez-Rego","Nearest neighbours graphs are a pervasive basic construct in areas such as Data mining, Machine Learning and Information Retrieval. Among them, the k Nearest Neighbours Graph (kNNG), is probably the most studied of all. Unfortunately, its na&#305;&#776;ve construction is in O(n 2 ) for n data points, which becomes a quagmire when scaling to Big Data. However sub-quadratic construction of kNNG remains an open question. This paper explores an adaptive algorithm based on Locality Sensitive Hashing which presents good performance on distributed architectures.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-35.pdf
2017,Partition-wise Recurrent Neural Networks for Point-based AIS Trajectory Classification,"Xiang Jiang, Erico N de  Souza, Xuan Liu, Behrouz Haji Soleimani, Xiaoguang Wang, Daniel L. Silver, Stan Matwin","We present Partition-wise Recurrent Neural Networks (pRNNs) for point-based trajectory classification to detect fishing activities in the ocean.  This method partitions each feature and uses region-specific parameters for distinct partitions, which can greatly improve the expressive power of deep recurrent neural networks on low-dimensional yet heterogeneous trajectory data. We show that our approach outperforms the state-of-the-art systems.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-18.pdf
2017,Algorithmic challenges in big data analytics,"Veronica Bolon-Canedo, Beatriz Remeseiro, Konstantinos Sechidis, David Martínez-Rego, Amparo Alonso-Betanzos","This session studies specific challenges that Machine Learning (ML) algorithms have to tackle when faced with Big Data problems. These challenges can arise when any of the dimensions in a ML problem grows significantly: a) size of training set, b) size of test set or c) dimensionality. The studies included in this edition explore the extension of previous ML algorithms and practices to Big Data scenarios. Namely, specific algorithms for recurrent neural network training, ensemble learning, anomaly detection and clustering are proposed. The results obtained show that this new trend of ML problems presents both a challenge and an opportunity to obtain results which could allow ML to be integrated in many new applications in years to come.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-6.pdf
2017,Outlining a simple and robust method for the automatic detection of EEG arousals,"Isaac Fernández-Varela, Diego Álvarez-Estévez, Elena Hernández-Pereira, Vicente Moret-Bonillo","This work proposes a new technique for the automatic detection of electroencephalographic (EEG) arousals in sleep polysomnographic recordings. We have developed a non-computationally complex algorithm with the idea of providing an easy integration into different software platforms. The approach combines different well-known signal analyses to identify relevant arousal patterns. Special emphasis is carried out to produce a robust, artifact tolerant algorithm. The resulting approach was tested using a database of 6 polysomnographic recordings from real patients, achieving an average kappa index of 0.77 with respect to the visual scorings made by clinical experts.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-36.pdf
2017,Hyper-spectral frequency selection for the classification of vegetation diseases,"Klaas Dijkstra, Jaap van de Loosdrecht, Lambert Schomaker, Marco Wiering","Reducing the use of pesticides by early visual detection of diseases in precision agriculture is important. Because of the color similarity between potato-plant diseases, narrow band hyper-spectral imaging is required. Payload restrains on unmanned aerial vehicles require reduction of spectral bands. Therefore, we present a methodology for per-pixel classification combined with hyper-spectral band selection. In controlled experiments performed on a set of individual leaves, we measure the performance of five classifiers and three dimensionality-reduction methods with three patch sizes. With the best-performing classifier an error rate of 1.5\% is achieved for distinguishing two important potato-plant diseases.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-40.pdf
2017,Myoelectrical signal classification based on S transform and two-directional 2DPCA,"Hong-Bo Xie, Hui Liu","In order to extract discriminative information, time-frequency matrix is often transformed into a 1D vector followed by principal component analysis. This study contributes a two-directional two-dimensional principal component analysis (2D2PCA) based technique for time-frequency feature extraction. 2D2PCA is directly conducted on the time-frequency matrix obtained from the S transform rather than 1D vectors for feature extraction. The proposed method can significantly reduce the computational cost while capture the directions of maximal time-frequency matrix variance.  The efficiency and effectiveness of the proposed method is demonstrated by classifying eight hand motions using four-channel myoelectric signals recorded in health subjects and amputees.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-16.pdf
2017,Viral initialization for spectral clustering,"Vahan Petrosyan, Alexandre Proutiere","Spectral Clustering is one of the most widely used clustering algorithms. To find k clusters, it runs the K-means algorithm on the top k eigenvectors of a Laplacian matrix constructed from the data. As a consequence, it inherits the initialization issues of K-means. In this paper, we propose Viral Initialization (VI), a novel initialization procedure implemented in the Spectral Clustering algorithm before K-means is applied. VI is designed so that the resulting clusterings exhibit low normalized cut (Ncuts) values. This design principle is aligned with the recent observation that ""good"" clusterings have low Ncuts values. We show, through extensive numerical experiments, that the Spectral Clustering algorithm with VI consistently outperforms other state-of-the-art clustering techniques.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-49.pdf
2017,Accelerating stochastic kernel SOM,"Jérôme Mariette, Fabrice Rossi, Madalina Olteanu, Nathalie Villa-Vialaneix","Analyzing non vectorial data has become a common trend in a number of real-life applications. Various prototype-based methods have been extended to answer this need by means of kernalization that embed data into an (implicit) Euclidean space. One drawback of those approaches is their omplexity, which is commonly of order the square or the cube of the number of observations. In this paper, we propose an efficient method to reduce complexity of the stochastic kernel SOM. The results are illustrated on large datasets and compared to the standard kernel SOM. The approach has been implemented in the last version of the R package SOMbrero version 1.2.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-41.pdf
2017,Reducing variance due to importance weighting in covariate shift bias correction,"Van-Tinh Tran, Alex Aussem","Covariate shift is a problem in machine learning when the input distributions of training and test data are different (p(x)&#8800; p&#8242;(x))while their conditional distribution p(y|x) is the same.  A common technique to deal with this problem, called importance weighting, amounts to reweighting the training instances in order to make them resemble the test distribution.  However this usually comes at the expense of a reduction of the effective sample size, which is harmful when the initial training sample size is already small.  In this paper, we show that there exists a weighting scheme on the unlabeled data such that the combination of the weighted unlabeled data and the labeled training data mimics the test distribution.We further prove that the labels are missing at random in this combined data set and thus can be imputed safely.  Imputing the missing labels mitigates the undesirable sample-size-reduction effect of importance weighting.A series of experiments on synthetic and real-world data are conducted to demonstrate the efficiency of our approach.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-95.pdf
2017,Piecewise-Bézier C1 smoothing on manifolds with application to wind field estimation,"Pierre-Yves Gousenbourger, Estelle Massart, Antoni Musolas, Pierre-Antoine Absil, Julien M. Hendrickx, Laurent Jacques, Youssef Marzouk","We propose an algorithm for fitting C1 piecewise-Bézier curves to (possibly corrupted) data points on manifolds. The curve is chosen as a compromise between proximity to data points and regularity. We apply our algorithm as an example to fit a curve to a set of low-rank covariance matrices, a task arising in wind field modeling. We show that our algorithm has denoising abilities for this application.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-77.pdf
2017,The Top 10 Topics in Machine Learning Revisited: A Quantitative Meta-Study,"Patrick Glauner, Manxing Du, Victor Paraschiv, Andrey Boytsov, Isabel Lopez Andrade, Jorge Augusto Meira, Petko Valtchev, Radu State","Which topics of machine learning are most commonly addressed in research? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers. In our study, we revisit this question from a quantitative perspective. Concretely, we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences. We then use machine learning in order to determine the top 10 topics in machine learning. We not only include models, but provide a holistic view across optimization, data, features, etc. This quantitative approach allows reducing the bias of surveys. It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are. This allows researchers to identify popular topics as well as new and rising topics for their research.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-17.pdf
2017,Collaborative filtering with neural networks,"Josef Feigl, Martin Bogdan","Collaborative filtering methods try to determine a user's preferences given their historical usage data. In this paper, a flexible neural network architecture to solve collaborative filtering problems is reviewed and further developed. It will be shown how modern adaptive learning rate methods can be modified to allow the network to be trained in about half the time without sacrificing any predictive performance. Additionally, the effects of Dropout on the performance of the model are evaluated. The results of this approach are demonstrated on the Netflix Prize dataset.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-23.pdf
2017,Detection of non-recurrent road traffic events based on clustering indicators,"Pierre-Antoine Laharotte, Romain Billot, Nour-Eddin El Faouzi",We propose a new indicator for detecting non recurrent road traffic conditions. The idea is based on the perplexity of a generative probabilistic model (LDA) used for predicting traffic pattern.  The resulting filter method reduces the inaccuracies of comparable detection method and enables a better separation between usual traffic pattern and non-recurrent situations.,"Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-73.pdf
2017,Multiscale Spatio-Temporal Data Aggregation and Mapping for Urban Data Exploration,"Anaïs Remy, Etienne Côme","Maps seem the most intuitive way to visualize massive urban data but they also raise some well-known graphical problems (such as visual clutter, etc.). This paper focuses on processing massive spatio-temporal data in order to ease multi-scale exploration. To this end, we describe a preprocessing tool that enables the automatic creation of a multi-resolution grid from a high resolution grid of spatio-temporal data in a format compatible with webmapping applications (vector tiles). The use of this tool is exemplified through a prototype that offers the possibility to navigate into a massive itinerary request dataset collected in the Ile-de-France region.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-72.pdf
2017,Extracting urban water usage habits from smart meter data: a functional clustering approach,"Nicolas CHEIFETZ, Allou Samé, Zineb Sabir, Anne-Claire Sandraz, Cédric Féliers","The recent development of smart grids offers, through automated meter reading systems, the opportunity for an efficient and responsible management of water resources. In this framework, the present paper describes a novel methodology for identifying relevant usage profiles from hourly water consumption series collected by smart meters located on a water distribution network. The proposed approach operates in two stages. First, an additive time series decomposition model is used in order to extract seasonal patterns from the time series, which are intended to represent the customers habits in terms of water consumption. Then, two functional clustering approaches are used to group the extracted seasonal patterns into homogeneous clusters: a functional version of the well-known K-means algorithm, and a Fourier regression mixture-model-based algorithm. The two clustering strategies are applied to real world data from a smart grid deployed on a large water distribution network in France and a realistic interpretation of the consumption habits is given to each cluster.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-31.pdf
2017,Non-negative matrix factorization as a pre-processing tool for travelers temporal profiles clustering,"Léna Carel, Pierre Alquier",We propose to use non-negative matrix factorization (NMF) to build a dictionary of travelers temporal profiles. Clustering based on decomposition in this dictionary rather than on the full profiles (as in previous works) lead to more interpretable clusters.,"Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-22.pdf
2017,A neuro-symbolic approach to GPS trajectory classification,"Diego Carvalho, Felipe França, Raul Barbosa, Douglas Cardoso",This paper proposes approaches to GPS trajectory classification problem in the context of the Rio de Janeiro's public transit system. The approaches are inspired by the neuro-symbolic sense of adding knowledge from the domain as opposed to the use of a raw machine learning approach. Experimental results show performance boosts when using these strategies.,"Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-138.pdf
2017,Using degree constrained gravity null-models to understand the structure of journeys' networks in bicycle sharing systems,"Remy Cazabet, Pierre Borgnat, Pablo Jensen","Bicycle Sharing Systems are now ubiquitous in large cities around the world. In most of these systems, journeys' data can be extracted, providing rich information to better understand it. Recent works have used network analysis, and in particular space-corrected community detection, to analyse such datasets. In this paper, we show that spatial-null models used in previous methods have a systematic bias, and we propose a degree-contrained null-model to improve the results. We finally apply the proposed method on the BSS of a city.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-25.pdf
2017,Anomaly detection and characterization in smart card logs using NMF and Tweets,"Emeric Tonnelier, Nicolas Baskiotis, Vincent Guigue, Patrick Gallinari","This article describes a novel approach to detect anomalies in smart card logs. In this study, we chose to work on a 24h base for every station in the Parisian metro network. We also consider separately the 7 days of the week. We first build a robust averaged reference for (day,station) couples and then, we focus on the difference between particular situations and references. All experiments are conducted both on the raw data and using an NMF denoised approximation of the log flow. We demonstrate the interest and the robustness of the latter strategy. Then we mine RATP Twitter account to obtain ground truth information about operating incidents. This synchronized flow is used  to evaluate our models.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-93.pdf
2017,"Processing, mining and visualizing massive urban data","Pierre Borgnat, Etienne Côme, Latifa Oukhellou","The development of smart technologies and the advent of new observation capabilities have increased the availability of massive urban datasets that can greatly benefit urban studies. For example, a large amount of urban data is collected by various sensors, such as smart meters, or provided by GSM, Wi-Fi or Bluetooth records, ticketing data, geo-tagged posts on social networks, etc. Analysis of such digital records can help to build decision-making tools (for analytical, forecasting and display purposes) with a view to better understanding the operating of urban systems, to enable urban stakeholders to plan better when extending infrastructures and to provide better services to citizens in order to assist the development of the city and improve quality of life. This paper will focus on three main domains of application: transportation and mobility, water and energy.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-3.pdf
2017,A Robust Minimal Learning Machine based on the M-Estimator,"Joao Gomes, Diego Mesquita, Ananda Freire, Amauri Souza Junior, Tommi Karkkainen",In this paper we propose a robust Minimal Learning Machine (R-RLM) for regression problems. The proposed method uses a robust M-estimator to generate a linear mapping between input and output distances matrices of MLM. The R-MLM was tested on one synthetic and three real world datasets that were contaminated with an increasing number of outliers. The method achieved a performance comparable to the robust Extreme Learning Machine (R-RLM) and thus can be seen as a valid alternative for regression tasks on datasets with outliers.,"Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-44.pdf
2017,Moving Least Squares Support Vector Machines for weather temperature prediction,"Zahra Karevan, Yunlong Feng, Johan A. K. Suykens","Local learning methods have been investigated by many  researchers. While global learning methods consider the same weight for all training points in model fitting, local learning methods assume that the training samples in the test point region are more influential. In this paper, we propose Moving Least Squares Support Vector Machines (M-LSSVM) in which each training sample is involved in the model fitting depending on the similarity between its feature vector and the one of the test point. The experimental results on an application of weather forecasting indicate that the proposed method can improve the prediction performance.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-55.pdf
2017,Spikes as regularizers,Anders Søgaard,"We present a confidence-based single-layer feed-forward learning algorithm {\sc Spiral}~(Spike Regularized Adaptive Learning) relying on an encoding of activation {\em spikes}. We adaptively update a weight vector relying on confidence estimates and activation offsets relative to previous activity. We regularize updates proportionally to item-level confidence and weight-specific support, loosely inspired by the observation from neurophysiology that high spike rates are sometimes accompanied by low temporal precision. Our experiments suggest that the new learning algorithm {\sc Spiral} is more robust and less prone to overfitting than both the averaged perceptron and {\sc Arow}","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-32.pdf
2017,Pseudo-analytical solutions for stochastic options pricing using Monte Carlo simulation and Breeding PSO-trained neural networks,"Sam Palmer, Denise Gorse","A neural network is trained using a novel form of particle swarm optimisation to learn the pricing formula for European call options using training samples generated via a Monte Carlo process. The trained neural network has  effectively learnt an approximate analytical solution, with errors shown statistically comparable to Monte Carlo pricing, alleviating the need to re-run computationally costly simulations for different model parameter settings.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-113.pdf
2017,POKer: a Partial Order Kernel for Comparing Strings with Alternative Substrings,"Maryam Abdollahyan, Fabrizio Smeraldi","We introduce a Partial Order Kernel (POKer) on the weighted sum of local alignment scores that can be used for comparison and classification of strings containing alternative substrings of variable length. POKer is defined over the product of two directed acyclic graphs, each representing a string with alternative substrings, and is computed efficiently using dynamic programming. We evaluate the performance of POKer with Support Vector Machines on a dataset of strings generated by detecting overlapping motifs in a set of simulated DNA sequences. Compared to a generalization of a state-of-the-art string kernel, POKer achieves a higher classification accuracy.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-66.pdf
2017,The Conjunctive Disjunctive Node Kernel,"Dinh Tran Van, Alessandro Sperduti, Fabrizio Costa","Gene-disease associations are inferred on the basis of similarities between genes. Biological relationships that are exploited to define similarities range from interacting proteins, proteins that participate in pathways and gene expression profiles. Though graph kernel methods have become a prominent approach for association prediction, most solutions are based on a notion of information diffusion that does not capture the specificity of different network parts. Here we propose a graph kernel method that explicitly models the configuration of each gene’s context. An empirical evaluation on several biological databases shows that our proposal is competitive w.r.t. state-of-the-art kernel approaches.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-127.pdf
2017,Learning sparse models of diffusive graph signals,"Shuyu Dong, Dorina Thanou, Pierre-Antoine Absil, Pascal Frossard","Graph signals that describe data living on irregularly structured domains provide a generic representation for structured information in very diverse applications. The effective analysis and processing of such signals however necessitate good models that identify the most relevant signal components. In this paper, we propose to learn sparse representation models for graph signals that describe heat diffusion processes. This consists in learning a dictionary that incorporates spectral properties of an implicit graph diffusion kernel. The underlying formulation enables the identification of both sparse features and an adaptive graph structure from mere signal observations. Experiments on synthetic and real datasets show that the proposed dictionaries not only reflect the underlying diffusion process but also significantly reduce over-fitting of data in comparison to state-of-the-art methods.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-116.pdf
2017,Mutual information for improving the efficiency of the SCH algorithm,"Diego Fernandez-Francos, Oscar Fontenla-Romero, Amparo Alonso-Betanzos, Gavin Brown","A new approach to improve the efficiency of a one-class classification algorithm making it more suitable for big datasets is presented in this work. The original algorithm, called SCH (Scaled Convex Hull) algorithm, approximates a D-dimensional convex hull decision by means of random projections and an ensemble of 2-dimensional decisions. With this new approach we try to get rid of the redundant projections that lead to similar classification models in the low dimensional space. After the training phase, a new stage based on mutual information is added to the original algorithm in order to select the essential projections and remove the unnecessary ones, providing a lightweight classification model. This reduces significantly the computational complexity of the testing phase and preserves the performance of the original method. Finally, some experimental results are given to demonstrate the effectiveness and efficiency of these approach.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-82.pdf
2017,Learning Semantic Prediction using Pretrained Deep Feedforward Networks,"Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke","The ability to predict future environment states is crucial for anticipative behavior of autonomous agents. Deep learning based methods have proven to solve key perception challenges but currently mainly operate in a non-predictive fashion. We bridge this gap by proposing an approach to transform trained feed-forward networks into predictive ones via a combination of a recurrent predictive module with a teacher-student training strategy. This transformation can be conducted without the need of labeled data in a fully self-supervised fashion. Using simulated data, we demonstrate the ability of the resulting model to temporally predict a task-specific representation and additionally show the benefits of using our approach even when no corresponding feed-forward model is available.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-61.pdf
2017,Local Lyapunov Exponents of Deep RNN,"Claudio Gallicchio, Alessio Micheli, Luca Silvestri","The study of deep Recurrent Neural Network (RNN) models represents a research topic of increasing interest. In this paper we investigate layered recurrent architectures under a dynamical system point of view, focusing on characterizing the fundamental aspect of stability. To this end we provide a framework that allows the analysis of deepRNN dynamical regimes through the study of the maximum among the local Lyapunov exponents. Applied to the case of Reservoir Computing networks,  our investigation also provides insights on the true merits of layering in RNN architectures, effectively showing how increasing the number of layers eventually results in progressively less stable global dynamics.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-48.pdf
2017,A distributed approach for classification using distance metrics,"Laura Morán-Fernández, Veronica Bolon-Canedo, Amparo Alonso-Betanzos","To cope with the huge quantity of data that fast development of sensoring, networking and inexpensive data storage has come, many distributed approaches have been developed during the last years. The main reason is that, when dealing with large datasets, most existing data mining algorithms do not scale well, and their efficiency may significantly deteriorate. Thus, we present a distributed approach by samples in which the original dataset will be divided into several nodes or processors. For classifying a new test sample, first we compute the distance to the data on each node, and then it will be classified by the model learned from the ""closest"" data. The proposed method has proved to be useful, demonstrating important savings in runtime and satisfactory performance.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-87.pdf
2017,Deep convolutional neural networks for detecting noisy neighbours in cloud infrastructure,"Bruno Ordozgoiti, Alberto Mozo, Sandra Gómez Canaval, Udi Margolin, Elisha Rosensweig, Itai Segall","Cloud infrastructure in data centers is expected to be one of the main technologies supporting Internet communications in the next few years.  Virtualization is employed to achieve the flexibility and dynamicity required by the wide variety of applications used today. Therefore, optimal allocation of virtual machines is key to ensuring performance and efficiency. Noisy neighbor is a term used to describe virtual machines competing for physical resources and thus disturbing each other, a phenomenon that can dramatically degrade their performance. Detecting noisy neighbors using simple thresholding approaches is ineffective. To exploit the time-series nature of cloud infrastructure monitoring data, we propose an approach based on deep convolutional networks. We test it on real infrastructure data and show that it outperforms well-known classifiers in the detection of noisy neighbors.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-102.pdf
2017,Learning convolutional neural network to maximize Pos@Top performance measure,"Yanyan Geng, Liang Ru-Ze , Weizhi Li, Jingbin Wang, Liang Gaoyuan , Xu Chenhao , Wang Jing-Yan","In the machine learning problems, the performance measure is used to evaluate the machine learning models. Recently, the number positive data points ranked at the top positions (Pos@Top) has been a popular performance measure in the machine learning community. In this paper, we propose to learn a convolutional neural network (CNN) model to maximize the Pos@Top performance measure. The CNN model is used to represent the multi-instance data point, and a classifier function is used to predict the label from the its CNN representation. We propose to minimize the loss function of Pos@Top over a training set to learn the filters of CNN and the classifier parameter. The classifier parameter vector is solved by the Lagrange multiplier method, and the filters are updated by the gradient descent method alternately in an iterative algorithm. Experiments over benchmark data sets show that the proposed method outperforms the state-of-the-art Pos@Top maximization methods.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-33.pdf
2017,Approximate operations in Convolutional Neural Networks with RNS data representation,"Valentina Arrigoni, Beatrice Rossi, Pasqualina Fragneto, Giuseppe Desoli","In this work we modify the inference stage of a generic CNN by approximating computations using a data representation based on a Residue Number System at low-precision and introducing rescaling stages for weights and activations. In particular, we exploit an innovative procedure to tune up the system parameters that handles the reduced resolution while minimizing rounding and overflow errors. Our method decreases the hardware complexity of dot product operators and enables a parallelized implementation operating on values represented with few bits, with minimal loss in the overall accuracy of the network.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-30.pdf
2017,Real-time convolutional networks for sonar image classification in low-power embedded systems,Matias Valdenegro-Toro,"Deep Neural Networks have impressive classification performance, but this comes at the expense of significant computational resources at inference time. Autonomous Underwater Vehicles use low-power embedded systems for sonar image perception, and cannot execute large neural networks in real-time. We propose the use of max-pooling aggressively, and we demonstrate it with a Fire-based module and a new Tiny module that includes max-pooling in each module. By stacking them we build networks that achieve the same accuracy as bigger ones, while reducing the number of parameters and considerably increasing computational performance. Our networks can classify a 96 × 96 sonar image with 98.8 &#8722; 99.7% accuracy on only 41 to 61 milliseconds on a Raspberry Pi 2, which corresponds to speedups of 28.6 &#8722; 19.7.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-109.pdf
2017,A Deep Q-Learning Agent for L-Game with Variable Batch Training,"Petros Giannakopoulos, Yannis Cotronis","We employ the Deep Q-Learning algorithm with Experience Replay to train an agent capable of achieving a high-level of play in the L-Game while self-learning from low-dimensional states. We also employ variable batch size for training in order to mitigate the loss of the rare reward signal and significantly accelerate training. Despite the large action space due to the number of possible moves, the low-dimensional state space and the rarity of rewards, which only come at the end of a game, DQL is successful in training an agent capable of strong play without the use of any search methods or domain knowledge.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-115.pdf
2017,TimeNet: Pre-trained deep recurrent neural network for time series classification,"Pankaj Malhotra, VIshnu TV, Lovekesh Vig, Puneet Agarwal, Gautam Shroff","Inspired by the tremendous success of deep Convolutional Neural Networks as generic feature extractors for images, we propose TimeNet: a deep recurrent neural network (RNN) trained on diverse time series in an unsupervised manner using sequence to sequence (seq2seq) models to extract features from time series. Rather than relying on data from the problem domain, TimeNet attempts to generalize time series representation across domains by ingesting time series from several domains simultaneously. Once trained, TimeNet can be used as a generic off-the-shelf feature extractor for time series. The representations or embeddings given by a pre-trained TimeNet are found to be useful for time series classification (TSC). For several publicly available datasets from UCR TSC Archive and an industrial telematics sensor data from vehicles, we observe that a classifier learned over the TimeNet embeddings yields significantly better performance compared to (i) a classifier learned over the embeddings given by a domain-specific RNN, as well as (ii) a nearest neighbor classifier based on Dynamic Time Warping.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-100.pdf
2017,Uncertain photometric redshifts via combining deep convolutional and mixture density networks,"Antonio D'Isanto, Kai Lars Polsterer","The need for accurate photometric redshifts estimation is a major subject in Astronomy. This is due to the necessity of efficiently obtaining redshift information without the need for spectroscopic analysis. We propose a method for determining accurate multi-modal predictive densities for redshift, using Mixture Density Networks and Deep Convolutional Networks. A comparison with the Random Forest is carried out and superior performance of the proposed architecture is demonstrated.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-56.pdf
2017,Active learning strategy for CNN combining batchwise Dropout and Query-By-Committee,"Melanie Ducoffe, Frédéric Precioso","While the current trend is to increase the depth of neural networks to improve their performance, the size of the training database has to grow accordingly. We thus notice an emergence of tremendous databases, although providing labels to build a training set still remains a very expensive task. In this paper, we tackle the problem of selecting the samples to be labeled in an online fashion. We present an active learning strategy based on query by committee and dropout technique to train a Convolutional Neural Network (CNN). We evaluate our active learning strategy for CNN on MNIST and USPS benchmarks, showing in particular that selecting less than 22 % from the annotated database is enough to get similar error rate as using the full training set.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-122.pdf
2017,Feature Extraction and Learning for RSSI based Indoor Device Localization,"Stavros Timotheatos, Grigorios Tsagkatakis, Panagiotis Tsakalides, Panos Trahanias","In this paper, we study and experimentally compare two state-of-the-art methods for low dimensional feature extraction, within the context of RSSI fingerprinting for localization. On one hand, we consider Stacked Autoencoders, a prominent example of a deep learning architecture, while on the other hand, we explore Random Projections, a universal feature extraction approach. Experimental results suggest that feature learning has a dramatic impact on the subsequent analysis like location based classification.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-90.pdf
2017,Learning human behaviors and lifestyle by capturing temporal relations in mobility patterns,"Eyal Ben Zion, Boaz Lerner","Many applications benefit from learning human behaviors and lifestyle. Different trajectories can represent a behavior, and previous behaviors and trajectories can influence decisions on further behaviors and on visiting future places and taking familiar or new trajectories. To more accurately explain and predict personal  behavior, we extend a topic model to capture temporal relations among previous trajectories/weeks and current ones. In addition, we show how different trajectories may have the same latent cause, which we relate to lifestyle. The code for our algorithm is available online.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-152.pdf
2017,WiSARDrp for Change Detection in Video Sequences,"Massimo De Gregorio, Giordano Maurizio","Weightless neural networks have been successfully used as learners and detectors of background regions in video processing, as they feature fast learning algorithm, noise tolerance and an incremental update of learnt knowledge, also referred to as online training. These features make weightless neural networks suitable and effective to be used for change (motion) detection in scenarios in which environmental changes (light, camera view, cluttered background) and moving objects force the modeling of background regions to change continuously and in drastic ways. In this paper, we present a change detection method in video processing that uses a weightless neural system, called WiSARDrp, as underlying learning mechanism, equipped with a reinforcing/weakening scheme, that builds and continuously updates a model of background at pixel-level. The performance of the proposed background modeling and change detection techniques are evaluated on the ChangeDetection.net video archive.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-133.pdf
2017,Investigating optical transmission error correction using wavelet transforms,"Weam Binjumah, Alexey Redyuk, Rod Adams, Neil Davey, Yi Sun","Reducing bit error rate and improving performance of modern coherent optical communication system is a significant issue. As the distance travelled by the information signal increases, bit error rate will degrade. Support Vector Machines are the most up to date machine learning method for error correction in optical transmission systems. Wavelet transform has been a popular method to signals processing. In this study, results show that the bit error rate can be improved by using classification based on wavelet transforms (WT) and support vector machine (SVM).","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-45.pdf
2017,A decision support system based on cellular automata to help the control of late blight in tomato cultures,"Gizelle Vianna, Gustavo Oliveira, Gabriel Cunha","We designed and implemented a decision support system for small tomatoes producers that investigates ways to recognize the late blight disease from the analysis of digital images of tomatoes, using a pair of multilayer perceptron neural network. The networks outputs are used to calculate the damage level at each plant and to construct a situation map of a farm where a cellular automata simulates the outbreak evolution over the fields. The simulator can test different pesticides actions, helping in the decision on when to start the spraying and in the analysis of losses and gains of each choice of action.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-39.pdf
2017,Comparison of manual and semi-manual delineations for classifying glioblastoma multiforme patients based on histogram and texture MRI features,"Adrian Ion-Margineanu, Sofie Van Cauter, Diana M Sima, Frederik Maes, Stefaan Sunaert, Uwe Himmelreich, Sabine Van Huffel",In this paper we study the task of classifying the follow-up course of brain tumour patients that had surgery. Multiple magnetic resonance imaging brain scans were taken for each patient. We propose a simple method of delineating the contrast enhancing tumour lesion based on the total tumour region. We compare balanced accuracy values after tuning SVM-lin and SVM-rbf on histogram and 3-D texture features extracted from semi-manual and manual delineations. Results show that our proposed delineating method outperforms the classical method.,"Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-139.pdf
2017,Latent variable analysis in hospital electric power demand using non-negative matrix factorization,"Diego García, Ignacio Díaz, Daniel Pérez, Abel Cuadrado, Manuel Domínguez","Energy disaggregation techniques have recently attracted much interest, since they allow to obtain latent patterns from power demand data in buildings, revealing useful information to the user. Unsupervised methods are specially attractive, since they do not require labeled datasets. Particularly, non-negative matrix factorization (NMF) methods allow to decompose a single power demand measurement over a certain time period into a set of components or ""parts"" that are sparse, non-negative and sum up the original measured quantity. Such components reveal hidden temporal patterns and events along this period, related to scheduling events and/or demand patterns from subsystems in the network, that are very useful within an energy efficiency context. In this paper we use this approach on demand data from a hospital during a one-year period, using a calendar visualization of the components, revealing relevant facts about the energy expenditure.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-60.pdf
2017,Hierarchical Combination of Video Features for Personalised Pain Level Recognition,"Patrick Thiam, Viktor Kessler, Friedhelm Schwenker","In this work, we present a personalized participant independent pain recognition system based on the video channel. Instead of using an entire annotated dataset to train a classification model that would be later applied to an unseen participant, a similarity metric is used to select the most interesting annotated samples based on the data of the unseen participant. These samples are subsequently used to train a model adapted to the unseen participant. The selection process helps to avoid redundant and irrelevant data samples, thus improves the performance as well as the efficiency of the trained model. From the video channel, several features are extracted and subsequently fed into an hierarchical fusion architecture to further improve the performance of the system.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-104.pdf
2017,A performance acceleration algorithm of spectral unmixing via subset selection,"Jing Ke, Yi Guo, Arcot Sowmya, Tomasz Bednarz",An acceleration algorithm for spectral unmixing approach is proposed based on subset selection. The method classifies the pixels in a spectral image into accurate and approximated unmixing groups based on the similarity and dissimilarity of geomorphological features in neighboring areas. Real spectral images are used for unmixing benchmark tests for accuracy and performance verification. The results reveal good performance speedup with only small accuracy loss.,"Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-29.pdf
2018,transferring style in motion capture sequences with adversarial learning,"QI WANG, Mickael CHEN, thierry Artieres, Ludovic Denoyer","We focus on style transfer for sequential data in a supervised setting. Assuming sequential data include both content and style information we want to learn models able to transform a sequence into another one with the same content information but with the style of another one, from a training dataset where content and style labels are available. Following works on image generation and edition with adversarial learning, we explore the design of neural network architectures for the task of sequence edition that we apply to motion capture sequences.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-188.pdf
2018,Efficient accuracy estimation for instance-based incremental active learning,"Christian Limberg, Heiko Wersing, Helge Ritter","Estimating system's accuracy is crucial for applications of incremental learning. In this paper, we introduce the Distogram Estimation (DGE) approach to estimate the accuracy of instance-based classifiers. By calculating relative distances to samples it is possible to train an offline regression model, capable of predicting the classifier's accuracy on unseen data. Our approach requires only a few supervised samples for training and can instantaneously be applied on unseen data afterwards. We evaluate our method on five benchmark data sets and for a robot object recognition task. Our algorithm clearly outperforms two baseline methods both for random and active selection of incremental training examples.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-127.pdf
2018,Boolean kernels for interpretable kernel machines,"Mirko Polato, Fabio Aiolli","Most of the machine learning (ML) community's efforts in the last decades have been devoted to improving the power and the prediction quality of ML models at the expense of their interpretability. However, nowadays, ML is becoming more and more ubiquitous and it is increasingly demanded the need for models that can be interpreted. To this end, in this work we propose a method for extracting explanation rules from a kernel machine. The core idea is based on using kernels with feature spaces composed by logical propositions. On top of that, a searching algorithm tries to retrieve the most relevant features/rules that can be used to explain the trained model. Experiments on several benchmarks and artificial datasets show the effectiveness of the proposed approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-168.pdf
2018,The minimum effort maximum output principle applied to Multiple Kernel Learning,"Ivano Lauriola, Mirko Polato, Fabio Aiolli","The Multiple Kernel Learning (MKL) paradigm aims at  learning the representation from data reducing the effort devoted to the choice of  kernel's hyperparameters. Typically, the resulting kernel is obtained as the maximal margin combination of a set of base kernels. When too expressive base kernels are provided to the MKL algorithm, the solution found by these algorithms can overfit data. In this paper, we propose a novel MKL algorithm which takes into consideration the expressiveness of the obtained representation in its objective function in such a way that a trade-off between large margins and simple hypothesis spaces can be found. Moreover, an empirical comparison against hard baselines and state-of-the-art MKL methods on several real-world datasets is presented showing the merits of the proposed algorithm especially with respect to the robustness to overfitting.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-181.pdf
2018,One-class Autoencoder approach to classify Raman spectra outliers,"Katharina Hofer-Schmitz, Phuong-Ha Nguyen, Kristian Berwanger","We present an one-class Anomaly detector based on (deep) Autoencoder for Raman spectra. Omitting preprocessing of the spectra, we use raw data of our main class to learn the reconstruction, with many typical noise sources automatically reduced as the outcome. To separate anomalies from the norm class, we use several, independent statistical metrics for a majority voting. Our evaluation shows a f1-score of up to 99% success.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-113.pdf
2018,Radar Based Pedestrian Detection using Support Vector Machine and the Micro Doppler Effect,"Joao Victor Bruneti Severino, Alessandro Zimmer, Leandro dos Santos Coelho, Roberto Zanetti Freire","Based on alarming statistics related to both pedestrian fatalities and injuries in traffic accidents, this paper presents the development of a pedestrian detection method for an Advanced Driving Assistance System (ADAS). Using a 79GHz automotive radar, a signal processing application that can early identify pedestrians in short range situations using Support Vector Machine (SVM) was presented and evaluated in order to improve the velocity resolution for the micro Doppler effects extraction. By assuming pre-processing multiobjective optimization, promising results in terms of velocity resolution and measuring time were obtained, improving the accuracy of the classifier.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-161.pdf
2018,Opposite neighborhood: a new method to select reference points of minimal learning machines,"Madson Dias, Lucas Sousa, Ajalmar Rocha Neto, Amauri Souza Junior","This paper introduces a new approach to select reference points of minimal learning machines (MLMs) for classification tasks. The MLM training procedure is related to the selection of a subset of the training set, named reference points (RPs), that is used to build a mapping between the input geometric configurations and their corresponding labels. We propose a method, named opposite neighborhood (ON), that explores the Euclidean distance in input space to select RPs. Experiments were performed using UCI data sets. The proposal was able to both reduce the number of reference points and achieve competitive performance when compared to conventional approaches for selecting RPs.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-198.pdf
2018,A neural network cost function for highly class-imbalanced data sets,"David  Twomey, Denise Gorse","We introduce a new cost function for the training of a neural network classifier in conditions of high class imbalance. This function, based on an approximate confusion matrix, represents a balance of sensitivity and specificity and is thus well suited to problems where cost functions such as the mean squared error and cross entropy are prone to overpredicting the majority class. The benefit of the new measure is shown on a set of common class-imbalanced datasets using the Matthews Correlation Coefficient as an independent scoring measure.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-60.pdf
2018,Properties of adv&#8722;1 – Adversarials of Adversarials,"Nils Worzyk, Oliver Kramer","Neural networks are very successful in the domain of image processing, but they are still vulnerable against adversarial images – carefully crafted images to fool the neural network during image classification. There are already some attacks to create those adversarial images, therefore the transition from original images to adversarial images is well understood. In this paper we apply adversarial attacks on adversarial images. These new images are called adv&#8722;1. The goal is to investigate the transition from adversarial images to adv&#8722;1 images. This knowledge can be used to 1.) identify adversarial images and 2.) to find the original class of adversarial images.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-164.pdf
2018,An analysis of subtask-dependency in robot command interpretation with dilated CNNs,"Manfred Eppe, Tayfun Alpay, Fares Abawi, Stefan Wermter","In this paper, we tackle sequence-to-tree transduction for language processing with neural networks implementing several subtasks, namely tokenization, semantic annotation, and tree generation. Our research question is how the individual subtasks influence the overall end-to-end learning performance in case of a convolutional network with dilated perceptive fields. We investigate a benchmark problem for robot command interpretation and conclude that dilation has a strong positive effect for performing character-level transduction and for generating parsing trees.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-96.pdf
2018,Image retrieval and ranking through Deep Comparative Neural Networks,"Aymen Cherif, Salim Jouili",Information retrieval is the task of extracting the most accurate documents from an existing collection with respect to a certain query. We focus our work to instance-level image retrieval. We approach this problem from the point of view of learning to rank. We explore the idea of using the pair-wise ranking model instead of simply providing a similarity measure between a query and a candidate document. We also investigate the ability of this a model to capture high level features that are query-document joint features and category independent.,Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-200.pdf
2018,Incremental learning with deep neural networks using a test-time oracle,"Alexander Gepperth, Saad Abdullah Gondal","We present a simple idea to avoid catastrophic forgetting when training deep neural networks (DNNs) on  class-incremental tasks. This means that initial training is conducted on a sub-task described by a dataset $D1$, whereas re-training  is conducted subsequently, on a sub-task described by a dataset $D2$ that is composed of different classes.  As our recent work suggest that DNNs perform very poorly at this problem,  we propose a simple extension that proposes an individually trained readout layer for each sub-task. While this is unproblematic for training, a clustering method is used at test time to determine to which sub-task a sample  most likely belongs. Experiments on simple benchmarks derived from MNIST show the effectiveness of this method for which a  dedicated TensorFlow implementation is made available.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-154.pdf
2018,Image-to-Text Transduction with Spatial Self-Attention,"Sebastian Springenberg, Egor Lakomkin, Cornelius  Weber, Stefan Wermter","Attention mechanisms have been shown to improve recurrent encoder-decoder architectures in sequence-to-sequence learning scenarios. Recently, the Transformer model has been proposed which only applies dot-product attention and omits recurrent operations to obtain a source-target mapping. This paper shows that the concepts of self- and inter-attention can effectively be applied in an image-to-text task. The encoder applies pre-trained convolution and pooling operations followed by self-attention to obtain an image feature representation. Self-attention combines image features of regions based on their similarity before they are made accessible to the decoder through inter-attention.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-162.pdf
2018,Hierarchical Recurrent Filtering for Fully Convolutional DenseNets,"Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke","Generating a robust representation of the environment is a crucial ability of learning agents. Deep learning based methods have greatly improved perception systems but still fail in challenging situations. These failures are often not solvable on the basis of a single image. In this work, we present a parameter-efficient temporal filtering concept which extends an existing single-frame segmentation model to work with multiple frames. The resulting recurrent architecture temporally filters representations on all abstraction levels in a hierarchical manner, while decoupling temporal dependencies from scene representation. Using a synthetic dataset, we show the ability of our model to cope with data perturbations and highlight the importance of recurrent and hierarchical filtering.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-88.pdf
2018,Towards cognitive automotive environment modelling: reasoning based on vector representations,"Florian Mirus, Terrence C. Stewart, Jörg Conradt","In this paper, we propose a novel approach to knowledge representation for automotive environment modelling based on Vector Symbolic Architectures (VSAs). We build a vector representation describing structured information and relations within the current scene based on high-level object-lists perceived by individual sensors. Such a representation can be applied to different tasks with little modifications. In a sample instantiation, we focus on two example tasks, namely driving context classification and simple behavior prediction, to demonstrate the general applicability of our approach. Allowing efficient implementation in Spiking Neural Networks (SNNs), we envision to improve task performance of our approach through online-learning.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-70.pdf
2018,Inferencing based on unsupervised learning of disentangled representations,"Tobias Hinz, Stefan Wermter","Combining Generative Adversarial Networks (GANs) with encoders that learn to encode data points has shown promising results in learning data representations in an unsupervised way. We propose a framework that combines an encoder and a generator to learn disentangled representations which encode meaningful information about the data distribution without the need for any labels. While current approaches focus mostly on the generative aspects of GANs, our framework can be used to perform inference on both real and generated data points. Experiments on several data sets show that the encoder learns interpretable, disentangled representations which encode descriptive properties and can be used to sample images that exhibit specific characteristics.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-61.pdf
2018,Regularize and explicit collaborative filtering with textual attention,"Charles-Emmanuel Dias, Vincent Guigue, Patrick Gallinari","Recommendation can be seen as tantamount to blind sentiment analysis, i.e. a sentiment prediction without text data. In that sense, we aim at encoding priors on users and items while reading their reviews, using a deep architecture with personalized attention modeling. Following this idea, we build an hybrid hierarchical sentiment classifier which is then used as a recommender system in inference.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-152.pdf
2018,Adaptive random forests for data stream regression,"Heitor Murilo Gomes, Jean Paul Barddal, Luis Eduardo Boiko, Albert Bifet","Data stream mining is a hot topic in the machine learning community that tackles the problem of learning and updating predictive models as new data becomes available over time. Even though several new methods are proposed every year, most focus on the classi&#64257;cation task and overlook the regression task. In this paper, we propose an adaptation to the Adaptive Random Forest so that it can handle regression tasks, namely ARF-Reg. ARF-Reg is empirically evaluated and compared to existing works of the area, thus highlighting its applicability in di&#64256;erent data stream scenarios.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-183.pdf
2018,Cache-efficient Gradient Descent Algorithm,"imen chakroun, Tom Vander Aa, thomas ashby","Best practice when using Stochastic Gradient Descent (SGD) suggests randomising the order of training points and streaming the whole set through the learner. This results in extremely low temporal locality of access to the training set and thus makes minimal use of the small, fast layers of memory in an HPC memory hierarchy. While mini-batch SGD is often used to control the noise on the gradient and make convergence smoother and more easy to identify than SGD, it suffers from the same extremely low temporal locality. In this paper we introduce Sliding Window SGD (SW-SGD) which uses temporal locality of training point access in an attempt to combine the advantages of SGD with mini batch-SGD by leveraging HPC memory hierarchies. We give initial results on a classification and a regression problems using the MNIST and CHEMBL datasets showing that memory hierarchies can be used to improve the performances of gradient algorithms.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-33.pdf
2018,Sensitivity analysis for predictive uncertainty,"Stefan Depeweg, José Miguel  Hernández-Lobato, Steffen Udluft, Thomas Runkler",We derive a novel sensitivity analysis of input variables for predictive epistemic and aleatoric uncertainty. We use Bayesian neural networks with latent variables as a model class and illustrate the usefulness of our sensitivity analysis on real-world datasets. Our method increases the interpretability of complex black-box probabilistic models.,Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-73.pdf
2018,Revisiting FISTA for Lasso: Acceleration Strategies Over The Regularization Path,"Alejandro Catalina, Carlos M. Alaíz, José R. Dorronsoro","In this work we revisit FISTA algorithm for Lasso showing that recent acceleration techniques may greatly improve its basic version, resulting in a much more competitive procedure. We study the contribu- tion of the different improvement strategies, showing experimentally that the final version becomes much faster than the standard one.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-81.pdf
2018,Shallow and Deep Models for Domain Adaptation problems,"Siamak Mehrkanoon, Matthew  Blaschko , Johan Suykens","Manual labeling of sufficient training data for diverse application domains is a costly, laborious task and often prohibitive. Therefore, designing models that can leverage rich labeled data in one domain and be applicable to a different but related domain is highly desirable. In particular, domain adaptation or transfer learning algorithms seek to generalize a model trained in a source domain to a new target domain. Recent years has witnessed increasing interest in these types of models due to their practical importance in real-life applications. In this paper we provide a brief overview of recent techniques with both shallow and deep architectures for domain adaptation models.",Shallow and Deep models for transfer learning and domain adaptation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-5.pdf
2018,Unsupervised domain adaptation of deep object detectors,"Debjeet Majumdar, Vinay Namboodiri","Domain adaptation has been understood and adopted in vision. Recently with the advent of deep learning there are a number of techniques that propose methods for deep learning based domain adaptation. However, the methods proposed have been used for adapting object classification techniques. In this paper, we solve for domain adaptation of object detection that is more commonly used. We adapt deep adaptation techniques for the Faster R-CNN framework. The techniques that we adapt are the recent techniques based on Gradient Reversal and Maximum Mean Discrepancy (MMD) reduction based techniques. Among them we show that the MK-MMD based method when used appropriately provides the best results. We analyze our model with standard real world settings by using Pascal VOC as source and MS-COCO as target and show a gain of 2.5 mAP at IoU of 0.5 over a source only trained model. We show that this improvement is statistically significant.",Shallow and Deep models for transfer learning and domain adaptation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-145.pdf
2018,Machine learning and data analysis  in astroinformatics,"Michael Biehl, Kerstin Bunte, Giuseppe Longo, Peter Tino","Astroinformatics is a new discipline at the cross-road of as- tronomy, advanced statistics and computer science. With next generation sky surveys, space missions and modern instrumentation astronomy will enter the Petascale regime raising the demand for advanced computer sci- ence techniques with hard- and software solutions for data management, analysis, efficient automation and knowledge discovery. This tutorial re- views important developments in astroinformatics over the past years and discusses some relevant research questions and concrete problems. The contribution ends with a short review of the special session papers in these proceedings, as well as perspectives and challenges for the near future.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-2.pdf
2018,Interactive dimensionality reduction of large datasets using interpolation,"Ignacio Diaz-Blanco, Daniel Pérez, Abel A. Cuadrado, Diego Garcia-Perez, Dominguez Manuel","In this work we present an approach to achieve interactive dimensionality reduction (iDR) on large datasets. The main idea of the paper relies on using generalized regression neural network (GRNN) interpolation to obtain massive out of sample projections from iDR projections obtained on a reduced sample of the original dataset. The proposed method allows to achieve fluid iDR interaction on datasets between 45 times and 100 times larger than with the original DR method for similar latencies, yet achieving good distance preservation. The paper includes a rank-based comparison between the proposed method and the DR method used alone for different datasets and parameter values.",Interaction and User Integration in Machine Learning for Information Visualisation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-47.pdf
2018,Perplexity-free t-SNE and twice Student tt-SNE,"Cyril de Bodt, Dounia Mulders, Michel Verleysen, John A. Lee","In fields of dimensionality reduction and data visualisation, t-SNE has become recently a very popular method. In this paper, we propose two variants to the Gaussian neighbourhoods used to characterise the neighbourhoods around each high-dimensional datum in t-SNE. A first alternative is to use t distributions just like they are used already in the low-dimensional embedding space; a variable degree of freedom accounts for the intrinsic dimensionality of data. The second variant relies on compounds of Gaussian neighbourhoods with growing widths, thereby suppressing the for the user to adjust a single size or perplexity. In both cases, neighbourhoods with heavy tails are thus used in the data space. Experiments show that both variants are competitive, with no extra cost.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-185.pdf
2018,Generative Kernel PCA,"Joachim Schreurs, Johan Suykens","Kernel PCA has shown to be a powerful feature extractor within many applications. Using the Restricted Kernel Machine formulation, a representation using visible and hidden units is obtained. This enables the exploration of new insights and connections between Restricted Boltzmann machines and kernel methods. This paper explores these connections, introducing a generative kernel PCA which can be used to generate new data, as well as denoise a given training dataset. Moreover, relations with linear PCA and a pre-image reconstruction method are introduced in this paper.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-173.pdf
2018,Extensive assessment of Barnes-Hut t-SNE,"Cyril de Bodt, Dounia Mulders, Michel Verleysen, John A. Lee","Stochastic Neighbor Embedding (SNE) and variants are dimensionality reduction (DR) methods able to foil the curse of dimensionality to deliver outstanding experimental results. Mitigating the crowding problem, t-SNE became an extremely popular DR scheme. Its quadratic time complexity in the number of samples is nevertheless unaffordable for big data sets. This motivates its Barnes-Hut (BH) acceleration for large-scale use. Although the latter is faster by orders of magnitude, few studies quantify its DR quality with respect to t-SNE. Extensive comparisons between t-SNE and its BH version are conducted using neighborhood preservation-based criteria. Both methods perform very similarly, suggesting the BH scheme superiority thanks to its reduced time complexity.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-76.pdf
2018,Understanding wafer patterns in semiconductor production with variational auto-encoders,"Tiago Santos, Roman Kern","Semiconductor manufacturing processes critically depend on hundreds of highly complex process steps, which may cause critical deviations in the end-product. Hence, a better understanding of wafer test data patterns, which represent stress tests conducted on devices in semiconductor material slices, may lead to an improved production process. However, the shapes and types of these wafer patterns, as well as their relation to single process steps, are unknown. In a first step to address these issues, we tailor and apply a variational auto-encoder (VAE) to wafer pattern images. We find the VAE's generator allows for explorative wafer pattern analysis, and its encoder provides an effective dimensionality reduction algorithm, which, in a clustering application, performs better than several baselines such as t-SNE and yields interpretable clusters of wafer patterns.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-41.pdf
2018,Feature noise tuning for resource efficient Bayesian Network Classifiers,"Laura Isabel Galindez Olascoaga, Jonas Vlasselaer, Wannes Meert, Marian Verhelst","Emerging portable applications require always-on sensing technologies to continuously monitor the environment and their user's needs. Yet, the high power consumption that results from this continuous sensing, often hampers these systems' always-on functionality.  In this paper we propose a hardware-aware Machine Learning scheme that exploits the devices' ability to trade-off the quality of its sensors versus its power consumption. We introduce a technique that extends Bayesian Network classifiers with hardware description nodes that encode the probabilistic relation between sensory features and their degraded versions. We show how this allows to tune the hardware device's power consumption versus inference accuracy trade-off space with fine granularity, resulting in operating points that achieve significant power savings at almost no accuracy loss. This is empirically shown on various Machine Learning benchmarking datasets.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-53.pdf
2018,Reliable Patient Classification in Case of Uncertain Class Labels Using a Cross-Entropy Approach,"Andrea Villmann, Marika Kaden, Sascha Saralajew, Wieland Hermann, Thomas Villmann","Classification learning crucially depends on the correct label information in training data. We consider the problem that a respective uncertainty can neither be neglected nor it can be approximated by a statistical model. In the proposed approach each training data is equipped with a certainty value reflecting the probability of the label correctness. This information is used in the learning process for the classifier. For this purpose, we adopt the cross-entropy cost function from deep learning for a modified learning vector quantization model. We show the usefulness of this knowledge integration in medical diagnostic data analysis for detection of Wilson's disease as an example.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-97.pdf
2018,behaviour-based working memory capacity classification using recurrent neural networks,"Mazen Salous, Felix Putze","A user's working memory capacity is a crucial factor for successful Human Computer Interaction. While reliable tests for working memory capacity are available, they are time-consuming, stressful, and not well-integrated into HCI applications. This paper presents a classifier based on Long Short Term Memory networks to exploit sparse temporal dependencies in behavioural data, collected in a complex, memory-intense interaction task, to classify working memory capacity. A cognitive user simulation is introduced to generate additional training data episodes that follow the behaviour of existing real data. We show that the classifier outperforms a linear baseline especially for short segments of data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-108.pdf
2018,Sleep staging with deep learning: a convolutional model,"Isaac Fernández-Varela, Dimitrios Athanasakis, Samuel Parsons, Elena Hernández-Pereira, Vicente Moret-Bonillo","Sleep staging is a crucial task in the context of sleep studies that involves the analysis of multiple signals, thus being a very tedious and complex task. Even for a trained expert, it can take several hours to annotate the signals recorded from a patient's sleep during a single night. To solve this problem several automatic methods have been developed, although most of them rely on hand engineered features. To address the inner problems of this approach, in this work we explore the possibility of solving this problem with a deep learning network that can self-learn the relevant features from the signals. Particularly, we propose a convolutional network, obtaining higher performance than in previous methods, achieving an average precision of 0.91, recall of 0.90, and F-1 score of 0.90.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-59.pdf
2018,Interpreting deep learning models for ordinal problems,"José P. Amorim , Inês Domingues, Pedro Henriques Abreu, João Santos","Machine learning algorithms have evolved by exchanging simplicity and interpretability for accuracy, which prevents their adoption in critical tasks such as healthcare. Progress can be made by improving interpretability of complex models while preserving performance. This work introduces an extension of interpretable mimic learning which teaches interpretable models to mimic predictions of complex deep neural networks, not only on binary problems but also in ordinal settings. The results show that the mimic models have comparative performance to Deep Neural Network models, with the advantage of being interpretable.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-82.pdf
2018,Non-negative Matrix Factorization for Medical Imaging,"Miguel Atencia, Ruxandra Stoean","A non-negative matrix factorization approach to dimensionality reduction is proposed to aid classification of images. The original images can be stored as  lower-dimensional columns of a matrix that hold degrees of belonging to feature components, so they can be used in the training phase of the classification at lower runtime and without loss in accuracy. The extracted features can be visually examined and images reconstructed with limited error. The proof of concept is performed on a benchmark of handwritten digits, followed by the application to histopathological colorectal cancer slides. Results are encouraging, though dealing with real-world medical data raises a number of issues.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-62.pdf
2018,Multi-omics data integration using cross-modal neural networks,"Ioana Bica, Petar Velickovic, Hui Xiao","Successful integration of multi-omics data for prediction tasks can bring significant advantages to precision medicine and to understanding molecular systems. This paper introduces a novel neural network architecture for exploring and integrating modalities in omics datasets, especially in scenarios with a limited number of training examples available. The proposed cross-modal neural network achieves up to 99% accuracy on omics datasets and it can be reliably used as a tool for performing inference. Moreover, we show how analysis of the weights and activations in the network can give us biological insights into understanding which genes are most relevant for the decision process and how different types of omics influence each other.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-93.pdf
2018,DEEP: decomposition feature enhancement procedure for graphs,"Van Dinh Tran, Nicolò Navarin, Alessandro Sperduti","When dealing with machine learning on graphs, one of the most successfully approaches is the one of kernel methods. Depending if one is interested in predicting properties of graphs (e.g. graph classification) or to predict properties of nodes in a single graph (e.g. graph node classification), different kernel functions should be adopted. In the last few years, several kernels for graphs have been defined in literature that extract local features from the input graphs, obtaining both efficiency and state-of-the-art predictive performances. Recently, some work has been done in this direction also regarding graph node kernels, but the majority of the graph node kernels available in literature consider only global information, that can be not optimal for many tasks. In this paper, we propose a procedure that allows to transform a local graph kernel in a kernel for nodes in a single, huge graph. We apply a specific instantiation to the task of disease gene prioritization from the bioinformatics domain, improving the state of the art in many diseases.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-131.pdf
2018,Deep Echo State Networks for Diagnosis of Parkinson's Disease,"Claudio Gallicchio, Alessio Micheli, Luca Pedrelli","In this paper, we introduce a novel approach for diagnosis of Parkinson's Disease (PD) based on deep Echo State Networks (ESNs). The identi&#64257;cation of PD is performed by analyzing the whole time-series collected from a tablet device during the sketching of spiral tests, without the need for feature extraction and data preprocessing. We evaluated the proposed approach on a public dataset of spiral tests. The results of experimental analysis show that deepESNs perform signi&#64257;cantly better than shallow ESN model. Overall, the proposed approach obtains state-of-the-art results in the identi&#64257;cation of PD on this kind of temporal data.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-163.pdf
2018,Capturing variabilities from Computed Tomography images with Generative Adversarial Networks (GANs),"UMAIR JAVAID, John A. Lee","With the advent of Deep Learning (DL) techniques, especially Generative Adversarial Networks (GANs), data augmentation and generation are quickly evolving domains that have raised much interest recently. However, the DL techniques are data demanding and since, medical data is not easily accessible, they suffer from the data insufficiency. To deal with this limitation, different data augmentation techniques are used. Here, we propose a novel unsupervised data-driven approach for data augmentation that can generate 2D Computed Tomography (CT) images using a simple GAN. The generated CT images have good global and local features of a real CT image and can be used to augment the training datasets for effective learning. In this proof-of-concept study, we show that our proposed solution using GANs is able to capture some of the global and local CT variabilities. Our network is able to generate visually realistic CT images and we aim to further enhance its output by scaling it to a higher resolution and potentially from 2D to 3D.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-180.pdf
2018,Pollen grain recognition using convolutional neural network,"Natalia Khanzhina, Evgeny Putin, Andrey Filchenkov, Elena Zamyatina","This paper addresses two problems: the automated pollen species recognition and counting them on an image obtained with a lighting microscope. Automation of pollen recognition is required in several domains, including allergy and asthma prevention in medicine and honey quality control in the nutrition industry. We propose a deep learning solution based on a convolutional neural network for classification, feature extraction and image segmentation. Our approach achieves state-of-the-art results in terms of accuracy. For 5 species, the approach provides 99.8% of accuracy, for 11 species - 95.9%.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-199.pdf
2018,Self-learning assembly systems during ramp-up,"Ralf Schönherr, Maximilian  Knaller, Markus Philipp","Achieving the targeted production volume during the ramp-up phase plays an important role for the economic success of manufacturing companies. But ramp-up phases are usually characterized by a high degree of uncertainty, as many situations arise for the first time. These unexpected events lead to errors and faults in automated processes which cause losses in the overall production volume. This paper proposes an architecture for assembly systems to predict and avoid faults of the assembly process during ramp-up through self-learning. Different algorithms for self-learning components are evaluated. By using real production data sets, neural networks could be identified as the best solution.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-78.pdf
2018,Feasibility based Large Margin Nearest Neighbor metric learning,"Babak Hosseini, Barbara Hammer","Large margin nearest neighbor (LMNN) is a metric learner which optimizes the performance of the popular $k$NN classifier. However, its resulting metric relies on pre-selected target neighbors. In this paper, we address the feasibility of LMNN's optimization constraints regarding these target points, and introduce a mathematical measure to evaluate the size of the feasible region of the optimization problem. We enhance the optimization framework of LMNN by a weighting scheme which prefers data triplets which yield a larger feasible region. This increases the chances to obtain a good metric as the solution of LMNN's problem. We evaluate the performance of the resulting feasibility-based LMNN algorithm using synthetic and real datasets. The empirical results show an improved accuracy for different types of datasets in comparison to regular LMNN.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-87.pdf
2018,"Combining latent tree modeling with a random forest-based approach, for genetic association studies","Christine Sinoquet, Kamel MEKHNACHA","Association studies have been widely used to discover the genetic basis of complex phenotypes. However, standard univariate tests, and their alternatives, do not fully exploit the dependences between genetic markers. In this paper, we propose Sylva, a hybrid approach in which a random forest framework based on embedded trees benefits from a probabilistic graphical model. The latter is a collection of tree-shaped Bayesian networks with latent variables. We extensively compared Sylva and T-Trees, on simulated and real data. Sylva outperforms the already highly performant T-Trees, in a vast majority of cases.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-101.pdf
2018,Graph based neural networks for automatic classification of multiple sclerosis clinical courses,"Francesco Calimeri, Aldo Marzullo, Claudio Stamile, Giorgio Terracina","Automatic classification of biomedical imaging became an important field of research within the scientific community, in the latest years. Indeed, advances in image acquisition and processing techniques, along with the success of novel deep learning methods and architectures, represented a considerable support in providing better biomarkers for the characterization of several diseases, and brain diseases in particular. In this work we propose a novel neural network approach that is applied to graphs generated from MRI data in order to make predictions about the clinical status of a patient. Results show high performances in classification tasks and open interesting perspectives in the field.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-63.pdf
2018,Extreme Minimal Learning Machine,Tommi Kärkkäinen,"Extreme Learning Machine (ELM) and Minimal Learning Machine (MLM) are nonlinear and scalable machine learning techniques with randomly generated basis. Both techniques share a step where a matrix of weights for the linear combination of the basis is recovered. In MLM, the kernel in this step corresponds to distance calculations between the training data and a set of reference points, whereas in ELM transformation with a sigmoidal activation function is most commonly used. MLM then needs additional interpolation step to estimate the actual distance-regression based output. A natural combination of these two techniques is proposed here, i.e., to use a distance-based kernel characteristic in MLM in ELM. The experimental results show promising potential of the proposed technique.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-72.pdf
2018,Learning with a Fisher surrogate loss in a small data regime,"Moussab Djerrab, Alexandre Garcia","We introduce a novel framework, Output Fisher Embedding Regression (OFER), that makes use of a Fisher vector representation of the outputs and provides prediction by solving an appropriate pre-image problem.  OFER takes advantage of the implicit structure of the marginal probability distribution of the output to improve performance in prediction. Although the proposed approach is general and versatile, we put a stress on the Gaussian mixture model for modelling the output data and design a closed-form solution for the corresponding pre-image problem. Numerical results are presented on a drug activity prediction task and a multi-class classification problem cast into a semantic regression problem and show the relevance of the approach in small data regime.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-182.pdf
2018,Fast Power system security analysis with Guided Dropout,"Benjamin Donnot, Isabelle Guyon, Antoine MAROT, Marc Schoenauer, Patrick Panciatici","We propose a new method to efficiently compute load-flows (the steady-state of the power-grid for given productions, consumptions and grid topology), substituting conventional simulators based on differential equation solvers. We use a deep feed-forward neural network trained with load-flows precomputed by simulation. Our architecture permits to train a network on so-called ``n-1'' problems, in which load flows are evaluated for every possible line disconnection, then generalize to ``n-2'' problems without re-training (a clear advantage because of the combinatorial nature of the problem). To that end, we developed a technique bearing similarity with ``dropout'', which we named ``guided dropout''.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-94.pdf
2018,Neural Networks for Implicit Feedback Datasets,"Josef Feigl, Martin Bogdan","Most users typically interact with products only through implicit feedback such as clicks or purchases rather than explicit user-provided information like product ratings. Learning to rank products according to individual preferences using only this implicit feedback can be helpful to make useful recommendations. In this paper, a neural network architecture to solve collaborative filtering problems for personalized rankings on implicit feedback datasets is presented. It is shown how a layer of constant weights forces the network to learn pairwise rankings. Additionally, similarities between the network and a matrix factorization model trained with Bayesian Personalized Ranking are proven. The experiments indicate state-of-the-art performance for the task of personalized ranking.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-51.pdf
2018,Efficient approximate representations for computationally expensive features,"Raul Santos-Rodriguez, Niall Twomey","High computational complexity is often a barrier to achieving desired representations in resource-constrained settings. This paper introduces a simple and computationally cheap method of approximating complex features. We do so by carefully constraining the architecture of a neural network and regress from raw data to the desired feature representation. Our analysis focuses on spectral features, and demonstrate how low-capacity networks can capture the end-to-end dynamics of cascaded composite functions. Not only do approximating neural networks simplify the analysis pipeline, but our approach produces feature representations up to 20 times more quickly. Excellent feature fidelity is achieved in our experimental analysis with feature approximations, but we also report nearly indistinguishable predictive performance when comparing between exact and approximate representations.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-122.pdf
2018,Regularised maximum-likelihood inference of mixture of experts for regression and clustering,"Bao Tuyen Huynh, Faicel Chamroukhi","Variable selection is fundamental to high-dimensional statistical modeling, and is challenging in particular in unsupervised modeling, including mixture models.  We propose a regularised maximum-likelihood inference of the Mixture of Experts model which is able to deal with potentially correlated features and encourages sparse models in a potentially high-dimensional scenarios.  We develop a hybrid Expectation-Majorization-Maximization (EM/MM) algorithm for model fitting.   Unlike state-of-the art regularised ML inference [1,2], the proposed modeling doesn't require an approximate of the regularisation.  The proposed algorithm allows to automatically obtain sparse solutions without thresholding, and includes coordinate descent updates avoiding matrix inversion.  An experimental study shows the capability of the algorithm to retrieve sparse solutions and for model fitting in model-based clustering of  regression data.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-167.pdf
2018,Feature selection for label ranking,"Noelia Sánchez-Maroño, Beatriz Pérez-Sánchez","Over the last years, feature selection and label ranking have attracted considerable attention in Artificial Intelligence research. Feature selection has been applied to many machine learning problems with excellent results. However, studies about its combination with label ranking are undeveloped. This paper presents a novelty work that uses feature selection filters as a preprocessing step for label ranking. Experimental results show a significant reduction, up to 33%,  in the number of features used for the label ranking problems whereas the performance results are competitive in terms of similarity measure.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-179.pdf
2018,A novel filter algorithm for unsupervised feature selection based on a space filling measure,"Mohamed Laib, Mikhaïl Kanevski","The research proposes a novel filter algorithm for the unsupervised feature selection problems based  on a space filling measure. A well-known criterion of space filling design, called the coverage measure, is adapted to dimensionality reduction problems. Originally, this measure was developed to judge the quality of a space filling design. In this work it is used to reduce the redundancy in data. The proposed algorithm is evaluated on simulated data with several scenarios of noise injection. Furthermore, a comparison with some benchmark methods of feature selection is performed on real UCI datasets.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-57.pdf
2018,Asymptotic statistics for multilayer perceptron with ReLu hidden units,joseph Rynkiewicz,"We consider regression models involving multilayer perceptrons (MLP) with rectified linear unit (ReLu) functions for hidden units.  It is a difficult task to study statistical properties of such models for several reasons: A first difficulty is that these activation functions are not differentiable everywhere, a second reason  is also that in practice these models may be heavily overparametrized.  In general, the estimation of the parameters of the MLP is done by minimizing a cost function, we focus here on the sum of square errors (SSE) which is the standard cost function for regression purpose.  In this framework,  we can characterize the asymptotic behavior of the SSE of estimated models which give information on the possible overfitting of such models.  This task is done using recent methodology introduced to deal with models with a loss of identifiability which is very flexible. So, we don't have to assume that a true model exits or that a finite set of parameters realize the best regression function.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-45.pdf
2018,Local Rademacher Complexity Machine,"Luca Oneto, Sandro Ridella, Davide Anguita","In this paper we present the Local Rademacher Complexity Machine, a transposition of the Local Rademacher Complexity Theory into a learning algorithm. By exploiting a series of real world small-sample datasets, we show the advantages of our proposal with respect to the Support Vector Machines, i.e. the transposition of the milestone results of V. N. Vapnik and A. Chervonenkis into a learning algorithm.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-139.pdf
2018,A sharper bound on the Rademacher complexity of margin multi-category classifiers,"Khadija Musayeva, Fabien Lauer, Yann Guermeur","One of the main open problems in the theory of margin multi-category pattern classification is the dependency of a guaranteed risk on the number C of categories, the sample size m and the margin parameter gamma. This paper derives a new bound on the probability of error of margin multi-category classifiers under minimal learnability assumptions. It improves the dependency on C over the state of the art. This is achieved through the introduction of a new Sauer-Shelah lemma.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-174.pdf
2018,Slowness-based neural visuomotor control with an Intrinsically motivated Continuous Actor-Critic,"Muhammad Burhan Hafez, Matthias Kerzel, Cornelius  Weber, Stefan Wermter","In this paper, we present a new visually guided exploration approach for autonomous learning of visuomotor skills. Our approach uses hierarchical Slow Feature Analysis for unsupervised learning of efficient state representation and an Intrinsically motivated Continuous Actor-Critic learner for neuro-optimal control. The system learns online an ensemble of local forward models and generates an intrinsic reward based on the learning progress of each learned forward model. Combined with the external reward, the intrinsic reward guides the system’s exploration strategy. We evaluate the approach for the task of learning to reach an object using raw pixel data in a realistic robot simulator. The results show that the control policies learned with our approach are significantly better both in terms of length and average reward than those learned with any of the baseline algorithms.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-123.pdf
2018,Anomaly detection in star light curves using hierarchical Gaussian processes,"Haoyan Chen, Tom Diethe, Niall Twomey, Peter Flach","Here we examine astronomical time-series called light-curve data, which represent the brightness of celestial objects over a period of time. We focus specifically on the task of finding anomalies in three sets of light-curves of periodic variable stars. We employ a hierarchical Gaussian process to create a general and stable model of time series for anomaly detection, and apply this approach to the light curve problem. Hierarchical Gaussian processes require only a few additional parameters than Gaussian processes and incur negligible additional complexity. Additionally, the additional parameters are objectively optimised in a principled probabilistic framework. Experimentally, our approach outperforms several baselines and highlight several anomalous light curves in the datasets investigated.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-125.pdf
2018,Latent representations of transient candidates from an astronomical image difference pipeline using Variational Autoencoders,"Pablo Huijse, Nicolas Astorga, Pablo Estevez, Giuliano Pignata","The Chilean Automatic Supernovae SEarch (CHASE) is a survey designed to detect early Supernovae. In this paper we explore deep autoencoders  to obtain a compressed latent space for a large transient candidate database from the CHASE image difference pipeline. Compared to conventional methods, the latent variables obtained with variational autoencoders preserve more information and are more discriminative towards real astronomical transients.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-130.pdf
2018,Globular Cluster Detection in the Gaia Survey,"Mohammad Mohammadi, Reynier Peletier, Frank-Michael Schleif, Nicolai Petkov, Kerstin Bunte","Existing algorithms for the detection of stellar structures in the Milky Way are most efficient when full phase-space and color information is available. This, however, is not often the case. Since recently, the Gaia satellite surveys the whole sky and is providing highly accurate positions for more than one billion sources. In this contribution we propose two independent strategies to find globular clusters in this database, based on magnitude distributions only. One approach is a nearest neighbor retrieval and the other an anomaly detection. Both techniques are able to find known globular clusters within our test frame consistently, as well as additional candidates for further investigation.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-86.pdf
2018,stellar formation rates in galaxies using machine learning models,"Michele Delli Veneri, Stefano Cavuoti, Massimo Brescia, Giuseppe Riccio, Giuseppe Longo",Global Stellar Formation Rates or SFRs are crucial to constrain theories of galaxy formation and evolution. SFR’s are usually estimated via spectroscopic observations which require too much previous telescope time and therefore cannot match the needs of modern precision cosmology. We therefore propose a novel method to estimate SFRs for large samples of galaxies using a variety of supervised ML models.,Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-100.pdf
2018,Prototype-based analysis of GAMA galaxy catalogue data,"Aleke Nolte , Lingyu Wang, Michael Biehl","We present a prototype-based machine learning analysis of labeled galaxy catalogue data containing parameters from the Galaxy and Mass Assembly (GAMA) survey. Using both an unsupervised and supervised method, the Self-Organizing Map and Generalized Relevance Matrix Learning Vec- tor Quantization, we find that the data does not fully support the popular visual-inspection-based galaxy classification scheme employed to categorize the galaxies. In particular, only one class, the Little Blue Spheroids, is consistently separable from the other classes. In a proof-of-concept experiment, we present the galaxy parameters that are most discriminative for this class.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-115.pdf
2018,Bioinformatics and medicine in the era of deep learning,"Davide Bacciu, Paulo Lisboa, José D. Martín, Ruxandra Stoean, Alfredo Vellido","Many of the current scientific advances in the life sciences have their origin in the intensive use of data for knowledge discovery. In no area this is so clear as in bioinformatics, led by technological breakthroughs in data acquisition technologies. It has been argued that bioinformatics could quickly become the field of research generating the largest data repositories, beating other data-intensive areas such as high-energy physics or astroinformatics. Over the last decade, deep learning has become a disruptive advance in machine learning, giving new live to the long-standing connectionist paradigm in artificial intelligence. Deep learning methods are ideally suited to large-scale data and, therefore, they should be ideally suited to knowledge discovery in bioinformatics and biomedicine at large. In this brief paper, we review key aspects of the application of deep learning in bioinformatics and medicine, drawing from the themes covered by the contributions to an ESANN 2018 special session devoted to this topic.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-1.pdf
2018,Controlling biological neural networks with deep reinforcement learning,"Jan Wülfing, Sreedhar Saseendran Kumar, Joschka Boedecker, Martin Riedmiller, Ulrich Egert","Targeted interaction with networks in the brain is of immense therapeutic relevance. The highly dynamic nature of neuronal networks and changes with progressive diseases create an urgent need for closed-loop control. Without adequate mathematical models of such complex networks, however, it remains unclear how tractable control problems can be formulated for neurobiological systems. Reinforcement learning (RL) could be a promising tool to address such challenges. Nevertheless, RL methods have rarely been applied to live, plastic neural networks. This study demonstrates that RL methods could help control response properties of biological neural networks with little prior knowledge of their complex dynamics.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-128.pdf
2018,Learning compressed representations of blood samples time series with missing data,"Filippo Maria Bianchi, Karl Øyvind Mikalsen, Robert Jenssen","Clinical measurements collected over time are naturally represented as multivariate time series (MTS), which often contain missing data. An autoencoder can learn low dimensional vectorial representations of MTS that preserve important data characteristics, but cannot deal explicitly with missing data. In this work, we propose a new framework that combines an autoencoder with the Time series Cluster Kernel (TCK), a kernel that accounts for missingness patterns in MTS. Via kernel alignment, we incorporate TCK in the autoencoder to improve the learned representations in presence of missing data.  We consider a classification problem of MTS with missing values, representing blood samples of patients with surgical site infection.  With our approach, rather than with a standard autoencoder, we learn representations in low dimensions that can be classified better.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-14.pdf
2018,Temporal transfer learning for drift adaptation,"Daegun Won, Peter Jansen, Jaime Carbonell","Whereas detecting and adapting to concept drift has been well studied, predicting temporal drift of decision boundaries has received much less attention.  This paper proposes a method for drift prediction, drift projection, and active-learning for adjusting the projected decision boundary so as to regain accuracy with minimal additional labeled samples.  The method works with different underlying learning algorithms. Results on several data sets with translational and rotational drift and corresponding boundary projection  show regained accuracy with significantly fewer labeled samples, even in the presence of noisy drift.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-202.pdf
2018,LANN-DSVD: A privacy-preserving distributed algorithm for machine learning,"Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas, Beatriz Pérez-Sánchez, Marcelo  Gómez-Casal","In the Big Data era new challenges have arisen for the machine learning field related with the Volume (a high number of samples or variables), the Velocity, etc. making many of the classic and brilliant methods not applicable anymore.  One of these concerns derives from with Privacy issues when data is distributed and it cannot be shared. In this paper we present the LANN-DSVD algorithm a non iterative method for One-Layer Neural Networks that allows distributed learning guaranteeing privacy among locations.  Moreover, it is non iterative, parameter-free and provides incremental learning, thus making it very suitable to manage huge and/or continuous data. Results demonstrate its competitiveness both in efficiency and efficacy.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-140.pdf
2018,Vector Field Based Neural Networks,"Daniel Vieira, Fabio Rangel, Fabrício Firmino, Joao Paixao",A novel Neural Network architecture is proposed using the mathematically and physically rich idea of vector fields as hidden layers to perform nonlinear transformations in the data. The data points are interpreted as particles moving along a flow defined by the vector field which intuitively represents the desired movement to enable classification. The architecture moves the data points from their original configuration to a new one following the streamlines of the vector field with the objective of achieving a final configuration where classes are separable. An optimization problem is solved through gradient descent to learn this vector field.,Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-192.pdf
2018,Non-Negative Tensor Dictionary Learning,"Abraham Traoré, Maxime Berar, Alain Rakotomamonjy","A challenge faced by dictionary learning and non-negative ma- trix factorization is to eciently model, in a context of feature learning, temporal patterns for data presenting sequential (two-dimensional) structure such as spectrograms. In this paper, we address this issue through tensor factorization. For this purpose, we make clear the connection between dictionary learning and tensor factorization when several examples are available. From this connection, we derive a novel (supervised) learning problem which induces emergence of temporal patterns in the learned dictionary. Obtained features are compared in a classication framework with those obtained by NMF and achieve promising results.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-156.pdf
2018,An extension of nonstationary fuzzy sets to heteroskedastic fuzzy time series,"Marcos Antonio Alves, Petrônio Cândido de Lima e Silva, Carlos Alberto Severiano Junior, Gustavo Linhares Vieira, Frederico Gadelha Guimarães, Hossein Javedani Sadaei","Most applications deal with unconditional variance of the time series. Fuzzy time series allow an inexpensive computation to forecasting dynamic processes and uncertainties. In this paper we have extended the concept of nonstationary fuzzy sets to Fuzzy Time Series, termed Nonstationary Fuzzy Time Series (NSFTS). While some models require new data before adapting, the NSFTS is capable of adapting to heteroskedastic time series. In the experiments, NSFTS outperformed other known FTS methods with box-cox transformations available. Statistical tests in three different datasets indicate that the results achieved by the proposed model are either superior or non-inferior to other FTS models.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-157.pdf
2018,Surprisal-based activation in recurrent neural networks,"Tayfun Alpay, Fares Abawi, Stefan Wermter","Learning hierarchical abstractions from sequences is a challenging and open problem for Recurrent Neural Networks (RNNs). This is mainly due to the difficulty of detecting features that span over long distances with also different frequencies. In this paper, we address this challenge by introducing surprisal-based activation, a novel method to preserve activations contingent on encoding-based self-information. The preserved activations can be considered as temporal shortcuts with perfect memory. We evaluate surprisal-based activation on language modelling by testing it on the Penn Treebank corpus and find that it can improve performance when compared to a baseline RNN.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-120.pdf
2018,K-spectral centroid: extension and optimizations,"Brieuc Conan-Guez, Alain Gély, Lydia Boudjeloud-Assala, Alexandre Blansché","In this work, we address the problem of unsupervised classification of large time series datasets.  We focus on K-Spectral Centroid (KSC), a k-means-like model, devised for time series clustering.  KSC relies on a custom dissimilarity measure between time series, which is invariant to time shifting and Y-scaling. KSC has two downsides: firstly its dissimilarity measure only makes sense for non negative time series. Secondly the KSC algorithm is relatively demanding in terms of computation time. In this paper, we present a natural extension of the KSC dissimilarity measure to time series of arbitrary signs. We show that this new measure is a metric distance.  We propose to speed up this extended KSC (EKSC) thanks to four exact optimizations.  Finally, we compare EKSC to a similar model, K-Shape, on real world datasets.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-116.pdf
2018,Temporal modeling of ALS using longitudinal data and long-short term memory-based algorithm,"Aviv Nahon, Boaz Lerner","ALS is a neurodegenerative disease where factors such as disease progression rate and pattern vary greatly among patients. Since patient functionality deteriorates over time, we model ALS temporally to mimic the physician's reasoning by incorporating old with new information using a long-short term memory (LSTM) network. We demonstrate that the LSTM achieves a higher accuracy than a random forest in disease state prediction, and improves accuracy with data from additional clinic visits. Being an anytime predictor, our model can help physicians and caregivers to adjust patients' treatment and living environment along the disease period, improving patients' life quality.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-133.pdf
2018,Randomized Recurrent Neural Networks,"Claudio Gallicchio, Alessio Micheli, Peter Tino",,Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-6.pdf
2018,Bidirectional deep-readout echo state networks,"Filippo Maria Bianchi, Simone Scardapane, Sigurd Løkse, Robert Jenssen","We propose a deep architecture for the classification of multivariate time series. By means of a recurrent and untrained reservoir we generate a vectorial representation that embeds temporal relationships in the data. To improve the memorization capability, we implement a bidirectional reservoir, whose last state captures also past dependencies in the input. We apply dimensionality reduction to the final reservoir states to obtain compressed fixed size representations of the time series. These are subsequently fed into a deep feedforward network trained to perform the final classification. We test our architecture on benchmark datasets and on a real-world use-case of blood samples classification. Results show that our method performs better than a standard echo state network and, at the same time, achieves results comparable to a fully-trained recurrent network, but with a faster training.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-49.pdf
2018,Forecasting Business Failure in Highly Imbalanced Distribution  based on Delay Line Reservoir,"Ali Rodan, Pedro A. Castillo, Hossam Faris, A.M. Mora, Huthaifa Jawazneh","Bankruptcy is a critical financial problem that affects a high number of companies around the world. Thus, in recent years an increasing number of researchers have tried to solve it by applying different machine-learning models as  powerful tools for the different economical agents related to the company. In this work, we propose the use of a simple deterministic delay line reservoir (DLR) state space by combining it with three popular classification algorithms (J48, k-NN, and MLP) as an efficient and accurate solution to the bankruptcy prediction problem. The proposed approach is evaluated on a real world dataset collected from Spanish companies. Obtained results show that the proposed models have a higher predictive ability than traditional classification approaches (without DLR reservoir state), resulting in a suitable and efficient alternative approach to solve this complex problem.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-105.pdf
2018,Estimation of the Human Concentration using Echo State Networks,"Hikmat Dashdamirov, Sebastián Basterrech","We introduce a very simple and portable device for estimating the human concentration. We developed a Brain-Computer Interface system based on EEG signals which is able to produce highly accurate prediction of the human activities. There are two types of mental activities, one requires high concentration and another one requires relaxation. We show that it is possible to estimate the human concentration with few brain signals. The classification problem is solved using Neural Networks. In particular, we obtain a very accurate classifier using the fast and robust Echo State Network method.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-172.pdf
2018,Quantifying the Reservoir Quality using Dimensionality Reduction Techniques,"Tomas Burianek, Sebastián Basterrech","Echo State Network is a particular type of Recurrent Neural Networks that combines principles from kernels, linear  regression and dynamical systems. The neural network has a random initialized hidden-hidden weights (reservoir) that keeps fixed during the training. The reservoir projects the input patterns onto a feature map. Here, we present a correlation analysis between the input space and the feature map. We use a dimensionality reduction technique (Sammon Mapping) for representing the input space. We show a correlation between the Sammon energy and the model accuracy, which can be useful for defining good reservoir topologies.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-176.pdf
2018,Scalable robust clustering method for large and sparse data,"Joonas Hämäläinen, Tommi Kärkkäinen, Tuomo Rossi","Datasets for unsupervised clustering can be large and sparse, with significant portion of missing values. We present here a scalable version of a robust clustering method with the available data strategy. More precisely, a general algorithm is described and the accuracy and scalability of a distributed implementation of the algorithm is tested. The obtained results allow us to conclude the viability of the proposed approach.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-134.pdf
2018,clustering with decision trees: divisive and agglomerative approach,"Lauriane Castin, Benoît Frénay","Decision trees are mainly used to perform classification tasks. Samples are submitted to a test in each node of the tree and guided through the tree based on the result. Decision trees can also be used to perform clustering, with a few adjustments. On one hand, new split criteria must be discovered to construct the tree without the knowledge of samples labels. On the other hand, new algorithms must be applied to merge sub-clusters at leaf nodes into actual clusters. In this paper, new split criteria and agglomeration algorithms are developed for clustering, with results comparable to other existing clustering techniques.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-22.pdf
2018,Comparison of cluster validation indices with missing data,"Marko Niemelä, Sami Äyrämö, Tommi Kärkkäinen","Clustering is an unsupervised machine learning technique, which aims to divide a given set of data into subsets. The number of hidden groups in cluster analysis is not always obvious and, for this purpose, various cluster validation indices have been suggested. Recently some studies reviewing validation indices have been provided, but any experiments against missing data are not yet available. In this paper, performance of ten well-known indices on ten synthetic data sets with various ratios of missing values is measured using squared euclidean and city block distances based clustering. The original indices are modified for a city block distance in novel way. Experiments illustrate different degree of stability for the indices with respect to the missing data.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-16.pdf
2018,Evolutionary RL for Container Loading,"Sarmimala Saikia, Richa Verma, Puneet Agarwal, Gautam Shroff, Lovekesh Vig, Ashwin Srinivasan","Loading the containers on the ship from a yard, is an important part of port operations. Finding the optimal sequence for loading of containers, is known to be computationally hard and is an example of combinatorial optimization, leading to usage of simple heuristics in practice. In this paper, we propose an approach which uses a mix of Evolutionary Strategies and Reinforcement Learning (RL) technique to find an approximation of the optimal solution. The RL based agent uses Policy Gradient method, an evolutionary reward strategy and a Pool of good (not-optimal) solutions to find the approximation. We find that the RL agent learns near-optimal solutions that outperforms the heuristic solutions. We also observe that the RL agent assisted with a pool generalizes better for unseen problems than an RL agent without a pool. We present our results on synthetic data as well as real-world data taken from container terminal. The results validate that our approach does comparatively better than the heuristics solutions available, and adapts to unseen problems better.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-149.pdf
2018,"Enhancement of a stochastic Markov-blanket framework with ant colony optimization, to uncover epistasis in genetic association studies","Christine Sinoquet, Clément Niel","In association genetics, many studies rely on univariate statistical tests to reveal genotype-phenotype relationships, and are thus prone to miss the situations of epistasis (interaction between genes). We designed SMMB (Multiple Stochastic Markov blankets), and SMMB-ACO, a variant combined with ant colony optimization, to detect epistasis. We compare our proposals with three other methods. SMMB-ACO outperforms the other methods for 50% of simulated datasets. On real datasets, the detection ability of SMMB-ACO is close to that of the best approach, which is a slow method, and SMMB-ACO is the fastest algorithm behind a much less performing method.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-175.pdf
2018,Meerkats-inspired Algorithm for Global Optimization Problems,"Carlos Eduardo Klein, Leandro dos Santos Coelho","Bio-inspired computing has been a relevant topic in scientific, computing and engineering fields in recent years. Most bio-inspired metaheuristics model a specific phenomenon or mechanism based on which they tackle optimization problems. This paper introduced the meerkats-inspired algorithm (MEA) a novel population-based swarm intelligence algorithm for global optimization in the continuous domain. The performance of MEA is showcased on six classical constrained engineering problems from literature. Numerical results and comparisons with other state of the art stochastic algorithms are also provided. Results analysis reveal that the MEA produced consistent results when compared with other optimizers.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-35.pdf
2018,Cheetah Based Optimization Algorithm: A Novel Swarm Intelligence Paradigm,"Carlos Eduardo Klein, Viviana Cocco Mariani, Leandro dos Santos Coelho","All the new gadgets, systems and advances in technology are bringing the actual engineers problems with increasing complexity. To solve those problems, the optimization algorithms are popping up to support and even improve the actual scenario. Several stochastic optimization paradigms called metaheuristics are being proposed each year and the inspiration comes from animals, plants, experiments, chemical processes or simply math. In this paper, a cheetah based optimization algorithm (CBA) is proposed, capturing the social behavior from those animals. The proposed CBA is validated against seven known optimizers using three different benchmark problems. Finally, some considerations about research issues and directions in the CBA design are given.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-18.pdf
2018,Evolutionary Composition of Customized Fault Localization Heuristics,"Diogo de-Freitas, Plinio Leitao-Junior, Celso Camilo-Junior, Rachel Harrison",Fault localisation is one of the most difficult and costly parts in software debugging. Researchers have tried to automate this process by formulating measures for assessment of code elements suspiciousness. This paper reports an evolutionary-based approach to combine non-linearly 34 previous measures to formulate a new program oriented fault localisation heuristic. The method was evaluated with 107 single-bug programs and compared against 35 approaches -- 34 spectrum-based heuristics and a previous evolutionary linear combination approach. The experiments have shown that the proposal consistently achieved competitive results related to the others according to several effectiveness metrics.,Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-77.pdf
2018,Order Crossover for the Inventory Routing Problem,"Mohamed Salim Amri Sakhri, Mounira Tlili, Hamid Allaoui, Ouajdi Korbaa","In this paper, we aim to find a solution that reduces the logistical activity costs by using new hybrid meta-heuristics. We develop, in this work, a genetic algorithm (GA) with a hybrid crossing operator. The operator considered is the Order Crossover (OX); we will test our hybrid algorithm in a Periodic Inventory Routing Problem (PIRP). Our study proves the performance of the hybrid operator OX compared with the classic GA, demonstrate the competitiveness of this innovative approach to solve the large-scale instances and bring a better quality of the solution.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-90.pdf
2018,A variable projection method for block term decomposition of higher-order tensors,"Guillaume Olikier, Pierre-Antoine Absil, Lieven De Lathauwer","Higher-order tensors have become popular in many areas of applied mathematics such as statistics, scientific computing, signal processing or machine learning, notably thanks to the many possible ways of decomposing a tensor. In this paper, we focus on the best approximation in the least-squares sense of a higher-order tensor by a block term decomposition. Using variable projection, we express the tensor approximation problem as a minimization of a cost function on a Cartesian product of Stiefel manifolds. We present numerical experiments where variable projection makes a steepest-descent method approximately twice faster.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-177.pdf
2018,Reinforcement Learning for High-Frequency Market Making,"Ye-Sheen Lim, Denise Gorse","In this paper we present the first practical application of reinforcement learning to optimal market making in high-frequency trading. States, actions, and reward formulations unique to high-frequency market making are proposed, including a novel use of the CARA utility as a terminal reward for improving learning. We show that the optimal policy trained using Q-learning outperforms state-of-the-art market making algorithms. Finally, we analyse the optimal reinforcement learning policies, and the influence of the CARA utility from a trading perspective.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-50.pdf
2018,Emerging trends in machine learning: beyond conventional methods and data,"Luca Oneto, Nicolò Navarin, Michele Donini, Davide Anguita","Recently, new promising theoretical results, techniques, and methodologies have attracted the attention of many researchers and have allowed to broaden the range of applications in which machine learning can be effectively applied in order to extract useful and actionable information from the huge amount of heterogeneous data produced everyday by an increasingly digital world. Examples of these methods and problems are: learning under privacy and anonymity constraints, learning from structured, semi-structured, multi-modal (heterogeneous) data, constructive machine learning, reliable machine learning, learning to learn, mixing deep and structured learning, semantics-enabled recommender systems, reproducibility and interpretability in machine learning, human-in-the-loop, adversarial learning. The focus of this special session is to attract both solid contributions or preliminary results which show the potentiality and the limitations of new ideas, refinements, or contaminations between the different fields of machine learning and other fields of research in solving real world problems. Both theoretical and practical results are welcome to our special session.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-4.pdf
2018,Finding the most interpretable MDS rotation for sparse linear models based on external features,"Adrien Bibal, Rebecca Marion, Benoît Frénay","One approach to interpreting multidimensional scaling (MDS) embeddings is to estimate a linear relationship between the MDS dimensions and a set of external features. However, because MDS only preserves distances between instances, the MDS embedding is invariant to rotation. As a result, the weights characterizing this linear relationship are arbitrary and difficult to interpret. This paper proposes a procedure for selecting the most pertinent rotation for interpreting a 2D MDS embedding.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-89.pdf
2018,Mixture of Hidden Markov Model as Tree Encoder,"Davide Bacciu, Daniele Castellana",The paper introduces a new probabilistic tree encoder based on a mixture of Bottom-up Hidden Markov Tree Models. The ability to recognise similar structures in data is experimentally assessed both in clusterization and classification tasks. The results obtained on this preliminary experiment suggests that this model can be used successfully to compress the tree information content in a fixed representation.,Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-112.pdf
2018,Set point thresholds from topological data analysis and an outlier detector,Alessio Carrega,"We provide an algorithm for unsupervised or semi-supervised learning to determine, once the input settings are given, a very easily described zone of optimal execution settings for a production. A region is very easily described if anyone can determine whether a point is inside it and select a point on it with a certain range of choice. This can be applied both in production optimization and in predictive maintenance. Part of the method is based on a topological data analysis tool: Mapper. We also provide a method to detect outliers on new data.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-143.pdf
2018,Differential private relevance learning,"Johannes Brinkrolf, Kolja Berger, Barbara Hammer","Digital information is collected daily in growing volumes. Mutual benefits drive the demand for the exchange and publication of data among parties. However, it is often unclear how to handle these data properly in the case that the data contains sensitive information. Differential privacy has become a powerful principle for privacy-preserving data analysis tasks in the last few years, since it entails a formal privacy guarantee for such settings. This is obtained by a separation of the utility of the database and the risk of an individual to lose his/her privacy. In this contribution, we introduce the Laplace mechanism and a stochastic gradient descent methodology which guarantee differential privacy. Then, we show how these paradigms can be incorporated into two popular machine learning algorithm, namely GLVQ and GMLVQ. We demonstrate the results of privacy-preserving LVQ based on three benchmarks.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-119.pdf
2018,On aggregation in ranking median regression,"Stéphan Clémençon, Anna Korba","In the present era of personalized customer services and recommender systems, predicting the preferences of an individual/user over a set of items indexed by $\n=\{1,\; \ldots,\; n\}$, $n\geq 1$, based on its characteristics, modelled as a r.v. $X$ say, is an ubiquitous issue. Though easy to state, this predictive problem referered to as \textit{ranking median regression} (RMR in short) is very difficult to solve in practice. The major challenge lies in the fact that, here, the (discrete) output space is the symmetric group $\mathfrak{S}_n$, composed of all permutations of $\n$, of explosive cardinality $n!$, and which is not a subset of a vector space. It is thus far from straightforward to build predictive rules taking their values in $\mathfrak{S}_n$, except by means of ranking aggregation techniques implemented at a local level, as proposed in \cite{YWL10} or \cite{CKS17bis}. However, such local learning techniques exhibit high instability and it is the main goal of this paper to investigate to which extent Kemeny ranking aggregation of randomized RMR rules may remedy this drawback. Beyond a theoretical analysis establishing its validity, the relevance of this novel ensemble learning technique is supported by experimental results.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-124.pdf
2018,Person Identification and Discovery With Wrist Worn Accelerometer Data,"Ryan McConville, Raul Santos-Rodriguez, Niall Twomey","Internet of Things devices with embedded accelerometers continue to grow in popularity. These are often attached to individuals, whether they are a mobile phone in a pocket or a wrist-worn smartwatch, capturing data of a personal nature. In this work we propose a method for person identification using accelerometer data via supervised machine learning techniques. Further, we introduce the first unsupervised method for discovering individuals using the same accelerometer data. We report high performance both in terms of classification and clustering using a publicly available dataset covering a large number of activities of daily living. While this has numerous benefits in tasks such as activity recognition, this work also motivates the debate and discussion around privacy concerns of the analysis of accelerometer data.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-190.pdf
2018,CDTW-based classification for Parkinson's Disease diagnosis,"Nicolas KHOURY , Ferhat ATTAL, Yacine Amirat, Abdelghani CHIBANI, Samer Mohammed","This paper presents a new classification approach for Parkinson's Disease (PD) diagnosis using Continuous Dynamic Time Warping (CDTW) technique and gait cycles data. These data are the vertical Ground Reaction Forces (vGRFs) recordings collected from eight force sensors placed in each shoe sole worn by each subject. The proposed approach exploits the principle of the repetition of gait cycle patterns to discriminate healthy subjects from PD subjects. The repetition of gait cycles is evaluated using the similarity of the time-series corresponding to stance phases estimated by applying the CDTW technique. The CDTW distances, extracted from gait cycles, are used as inputs of a binary classifier discriminating healthy subjects from PD subjects. Different classification methods are evaluated, including four supervised methods: K-Nearest Neighbours (K-NN), Decision Tree (DT), Random Forest (RF), and Support Vector Machines (SVM), and two unsupervised ones: Gaussian Mixture Model (GMM), and K-means. The proposed approach compares favorably with a classification based on standard features.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-203.pdf
2018,Personalizing human activity recognition models using incremental learning,"Pekka Siirtola, Heli Koskimäki, Juha Röning","In this study, the aim is to personalize inertial sensor data-based human activity recognition models using incremental learning. At first, the recognition is based on user-independent model. However, when personal streaming data becomes available, the incremental learning-based recognition model can be updated, and therefore personalized, based on the data without user-interruption. The used incremental learning algorithm is Learn++ which is an ensemble method that can use any classifier as base classifier. In fact, study compares three different base classifiers: linear discriminant analysis (LDA), quadratic discriminant analysis (QDA) and classification and regression tree (CART). Experiments are based on publicly open data set and they show that already a small personal training data set can improve the classification accuracy. Improvement using LDA as base classifier is 4.6 percentage units, using QDA 2.0 percentage units, and 2.3 percentage units using CART. However, if the user-independent model used in the first phase of the recognition process is not accurate enough, personalization cannot improve recognition accuracy.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-48.pdf
2018,Short-term Memory of Deep RNN,Claudio Gallicchio,"The extension of deep learning towards temporal data processing is gaining an increasing research interest. In this paper we investigate the properties of state dynamics developed in successive levels of deep recurrent neural networks (RNNs) in terms of short-term memory abilities. Our results reveal interesting insights that shed light on the nature of layering as a factor of RNN design. Noticeably, higher layers in a hierarchically organized RNN architecture results to be inherently biased towards longer memory spans even prior to training of the recurrent connections. Moreover, in the context of Reservoir Computing framework, our analysis also points out the benefit of a layered recurrent organization as an efficient approach to improve the memory skills of reservoir models.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-107.pdf
2018,Effect of context in swipe gesture-based continuous authentication on smartphones,"Pekka Siirtola, Jukka Komulainen, Vili Kellokumpu","This work investigates how context should be taken into account when conducting continuous authentication of a smartphone user based on touchscreen and accelerometer readings from swipe gestures. The study is based on publicly open data set consisting of 100 study subjects performing pre-defined reading and navigation tasks while sitting or walking. It is shown that context-specific models are needed for different smartphone usage and human activity scenarios to minimize authentication error. Also, the experimental results suggests that utilization of phone movement improves swipe gesture-based verification performance only when the user is moving.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-104.pdf
2018,Impact of Biases in Big Data,"Patrick Glauner, Petko Valtchev, Radu State","The underlying paradigm of big data-driven machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. Is having simply more data always helpful? In 1936, The Literary Digest collected 2.3M filled in questionnaires to predict the outcome of that year's US presidential election. The outcome of this big data prediction proved to be entirely wrong, whereas George Gallup only needed 3K handpicked people to make an accurate prediction. Generally, biases occur in machine learning whenever the distributions of training set and test set are different. In this work, we provide a review of different sorts of biases in (big) data sets in machine learning. We provide definitions and discussions of the most commonly appearing biases in machine learning: class imbalance and covariate shift. We also show how these biases can be quantified and corrected. This work is an introductory text for both researchers and practitioners to become more aware of this topic and thus to derive more reliable models for their learning problems.",Impact of Biases in Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-7.pdf
2018,Analysis of imputation bias for feature selection with missing data,"Borja Seijo-Pardo, Amparo Alonso-Betanzos, Kristin Bennett, Veronica Bolon-Canedo, Isabelle Guyon, Julie  Josse, Mehreen Saeed",We study risk/benefit tradeoff of missing value imputation in the context of feature selection. We caution against using imputation methods that may yield false positives: features not associated to the target becoming dependent as a result of imputation. We also investigate situations in which imputing missing values may be beneficial to reduce false negatives. We use causal graphs to characterize when structural bias arises and introduce a de-biased version of the t-test.,Impact of Biases in Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-58.pdf
2018,Systematics aware learning : a case study in high energy physics,"Victor Estrade, Cecile Germain, Isabelle Guyon, David Rousseau",Experimental science often has to cope with systematic errors that coherently bias data. We analyze this issue on the analysis of data produced by experiments of the Large Hadron Collider at CERN as a case of supervised domain adaptation. Systematics-aware learning should create an efficient representation that is insensitive to perturbations induced by the systematic effects. We present an experimental comparison of the adversarial knowledge-free approach and a less data-intensive alternative.,Impact of Biases in Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-99.pdf
2018,interpretation of convolutional neural networks for speech regression from electrocorticography,"Miguel Angrick, Christian Herff, Garett Johnson, Jerry Shih, Dean Krusienski, Tanja Schultz","The direct synthesis of continuously spoken speech from neural activity is envisioned to enable fast and intuitive Brain-Computer Interfaces. Earlier results indicate that intracranial recordings reveal very suitable signal characteristics for direct synthesis. To map the complex dynamics of neural activity to spectral representations of speech, Convolutional Neural Networks (CNNs) can be trained. However, the resulting networks are hard to interpret and thus provide little opportunity to gain insights on neural processes underlying speech. Here, we show that CNNs are useful to reconstruct speech from intracranial recordings of brain activity and propose an approach to interpret the trained CNNs.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-102.pdf
2018,Dynamic autonomous image segmentation based on Grow Cut,"Alexandru-Ion Marinescu, Zoltán Bálint, Laura Dio&#537;an, Anca Andreica","The main incentive of this paper is to provide an enhanced approach for 2D medical image segmentation based on the Unsupervised Grow Cut algorithm, a method that requires no prior training. This paper assumes that the reader is, to some extent, familiar with cellular automata and their function as they make up the core of this technique. The benchmarks were performed on 2D MRI images of the heart and chest cavity. We obtained a significant increase in the output quality as compared to classical Unsupervised Grow Cut by using standard measures, based on the existence of accurate ground truth. This increase was obtained by dynamically altering the local threshold parameter. In conclusion, our approach provides the opportunity to become a building block of a computer aided diagnostic system.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-32.pdf
2018,Continuous convolutional object tracking,"Peer Springstübe, Stefan Heinrich, Stefan Wermter","Tracking arbitrary objects is a challenging task in visual computing. A central problem is the need to adapt to the changing appearance of an object, particularly under strong transformation and occlusion. We propose a tracking framework that utilises the strengths of Convolutional Neural Networks (CNNs) to create a robust and adaptive model of the object from training data produced during tracking. An incremental update mechanism provides increased performance and reduces training during tracking, allowing its real-time use.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-169.pdf
2018,Active Learning based on Transfer Learning Techniques for Image Classification,"Daniela Onita, Adriana Birlutiu","In many imaging tasks  only an expert can annotate the data. Though domain experts are available, their labor is expensive and we would like to avoid querying them whenever possible. Our task is to make use of our resources as efficient as possible for a learning task. There are various ways of working in cases of labelled data shortage. This type of learning problems can be approached with Active and Transfer Learning techniques. Active Learning and Transfer Learning have demonstrated their efficiency and ability to train accurate models with significantly reduced amount of training data in many real-life applications. In this paper we investigate the combination of Active and Transfer Learning for building an efficient algorithm for image  classification. The experimental results show that by combining active and transfer learning, we can learn faster with fewer labels on a target domain than by random selection.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-155.pdf
2018,Near-optimal facial emotion classification using a WiSARD-based weightless system,"Leopoldo Lusquino Filho, Felipe França, Priscila Lima","The recognition of facial expressions through the use of a WiSARD-based n-tuple classifier is explored in this work. The competitiveness of this weightless neural network is tested in the specific challenge of identifying emotions from photos of faces, limited to the six basic emotions described in the seminal work of Ekman and and Friesen (1977) on the identification of facial expressions. Current state-of-the-art for this problem uses a convolutional neural network (CNN), with accuracy of 100% and 99.6% in the Cohn-Kanade and MMI datasets, respectively, with the proposed WiSARD-based architecture reaching accuracy of 100% and 99.4% in the same datasets.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-141.pdf
2018,Spatial pooling as feature selection method for object recognition,"Murat Kirtay, Lorenzo Vannucci, Ugo Albanese, Alessandro Ambrosano, Egidio Falotico, Cecilia Laschi","This paper reports our work on object recognition by using the spatial pooler of Hierarchical Temporal Memory (HTM) as a method for feature selection. To perform recognition task, we employed this pooling mechanism to select features from COIL-100 dataset. We benchmarked the results with the state-of-the-art feature extraction methods while using different amounts of training data (from 5% to 45%). The results indicate that the performed method is effective for object recognition with a low amount of training data in which the hand-engineered state-of-the-art feature extraction methods show limitations.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-142.pdf
2018,Information visualisation and machine learning: latest trends towards convergence,"Benoît Frénay, Bruno Dumas, John A. Lee","Many methods have been developed in machine learning (ML) for information visualisation (infovis). For example, PCA, MDS, t-SNE and improvements are standard tools to reduce the dimensionality of high dimensional datasets for visualisation purposes. However, multiple other means are regularly used in the field of infovis when tackling datasets with high dimensionality. Letting the user manipulate the visualisation is one of these means, either through selection, navigation or filtering. Introducing manipulation of the visualisation also integrates the user as a core aspect of a given system. In the context of machine learning, beyond the informational and exploratory use of infovis, users' feedback can for example be highly informational to drive the dimensionality reduction process.  This special session of the ESANN conference is a followup of the special session on ""Information Visualisation and Machine Learning: Techniques, Validation and Integration"" at ESANN 2016. It aims to gather researchers that integrate users in the core of ML methods for infovis. New algorithms and frameworks are welcome, as well as experimental use cases that bring new insight in the integration of interaction and user integration in ML for infovis. This special session aims to provide practitioners from both communities a common forum of discussion where issues at the crossroads of machine learning and information visualisation could be discussed.",Interaction and User Integration in Machine Learning for Information Visualisation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-3.pdf
2018,VisCoDeR: A tool for visually comparing dimensionality reduction algorithms,"Rene Cutura, Stefan Holzer, Michaël Aupetit, Michael Sedlmair","We propose VisCoDeR, a tool that leverages comparative visualization to support learning and analyzing different dimensionality reduction (DR) methods. VisCoDeR fosters two modes. The Discover mode allows to qualitatively compare several DR results by juxtaposing and linking the resulting scatterplots. The Explore mode allows for analyzing hundreds of differently parameterized DR results in a quantitative way. We present use cases that show that our approach helps to understand similarities and differences between DR algorithms.",Interaction and User Integration in Machine Learning for Information Visualisation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-74.pdf
2018,G-Rap: interactive text synthesis using recurrent neural network suggestions,"Udo Schlegel, Eren Cakmak, Juri Buchmüller, Daniel Keim","Finding the best neural network configuration for a given goal can be challenging, especially when it is not possible to assess the output quality of a network automatically. We present G-Rap, an interactive interface based on Visual Analytics principles for comparing outputs of multiple RNNs for the same training data. G-Rap enables an iterative result generation process that allows a user to already work productively while evaluating the outputs with contextual statistics at the same time. We demonstrate the applicability of G-Rap at the example of interactive music lyrics generation.",Interaction and User Integration in Machine Learning for Information Visualisation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-158.pdf
2018,Structuring and Solving Multi-Criteria Decision Making Problems using Artificial Neural Networks: a smartphone recommendation case,"Victor Amaral De Sousa, Anthony Simonofski, Monique Snoeck, Ivan Jureta","Several techniques can be used to solve multi-criteria decision making (MCDM) problems and to provide a global ranking of the alternatives considered. However, in a context with a high number of alternatives and where decision criteria relate to soft goals, the decision problem is particularly hard to solve. This paper analyzes the use of artificial neural networks to improve the relevance of the ranking of alternatives delivered by MCDM problem-solving techniques. Afterwards, a model using a combination of artificial neural networks and of the weighted sum model, a particular MCDM problem-solving technique, is built to recommend smartphones.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-118.pdf
2018,A Sub-Layered Hierarchical Pyramidal Neural Architecture for Facial Expression Recognition,"Henrique Siqueira, Pablo Barros, Sven Magg, Cornelius  Weber, Stefan Wermter","In domains where computational resources and labeled data are limited, such as in robotics, deep networks with millions of weights might not be the optimal solution. In this paper, we introduce a connectivity scheme for pyramidal architectures to increase their capacity for learning features. Experiments on facial expression recognition of unseen people demonstrate that our approach is a potential candidate for applications with restricted resources, due to good generalization performance and low computational cost. We show that our approach generalizes as well as convolutional architectures in this task but uses fewer trainable parameters and is more robust for low-resolution faces.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-166.pdf
2019,Graph generation by sequential edge prediction,"Davide Bacciu, Alessio Micheli, Podda Marco","Graph generation with Machine Learning models is a challenging problem with applications in various research fields. Here, we propose a recurrent Deep Learning based model to generate graphs by learning to predict their ordered edge sequence. Despite its simplicity, our experiments on a wide range of datasets show that our approach is able to generate graphs originating from very different distributions, outperforming canonical graph generative models from graph theory, and reaching performances comparable to the current state of the art on graph generation.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-107.pdf
2019,Embeddings and Representation Learning for Structured Data,"Benjamin Paaßen, Claudio Gallicchio, Alessio Micheli, Alessandro Sperduti","Learning models of structured data, such as sequences, trees, and graphs, has become a rich and promising research objective in many fields of machine learning, such as (deep) neural networks, probabilistic models, kernels, metric learning, and dimensionality reduction. All these seemingly disparate approaches are connected by their construction of vectorial representations and embeddings of structured data, be it implicit or explicit, fixed or learned, deterministic or stochastic. Such embeddings can not only be utilized for classification or regression, but for generation of structured data, visualization, and interpretation.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-4.pdf
2019,TrIK-SVM : an alternative decomposition for kernel methods in Kre&#305;&#774;n spaces,Gaelle Loosli,"The proposed work aims at proposing a alternative kernel decomposition in the context of kernel machines with indefinite kernels. The original paper of KSVM (SVM in Kre&#305;&#774;n spaces) uses the eigen-decomposition, our proposition avoids this decompostion. We explain how it can help in designing an algorithm that won’t require to compute the full kernel matrix. Finally we illustrate the good behavior of the proposed method compared to KSVM.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-58.pdf
2019,MAP best performances prediction for endurance runners,"Ángel Campo, Marc Francaux, Laurent Baijot, Michel Verleysen","The preparation of long-distance runners requires to estimate their potential race performances beforehand. Athlete performances can be modeled based on their past records, but the task is made difficult because of the high variability in runner race performances. This paper presents a maximum a posteriori (MAP) estimation that addresses the issues related to this high variability. The inclusion of athlete priors and a specific residual model are inferred with the help of a large set of race results.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-154.pdf
2019,A Simple and Effective Scheme for Data Pre-processing in Extreme Classification,"Sujay Khandagale, Rohit Babbar","Extreme multi-label classification (XMC) refers to supervised multi-label learning involving hundreds of thousand or even millions of labels. It has been shown to be an effective framework for addressing crucial tasks such as recommendation, ranking and web-advertising. In this paper, we propose a method for effective and well-motivated data pre-processing scheme in XMC. We show that our proposed algorithm, PrunEX, can remove upto 90% data in the input which is redundant from a classification view-point. Our scheme is universal in the sense it is applicable to all known public datasets in the domain of XMC.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-167.pdf
2019,Hybrid vibration signal monitoring approach for rolling element bearings,"Jarno Kansanaho, Tommi Kärkkäinen","New approach to identify different lifetime stages of rolling element bearings,to improve early bearing fault detection, is presented. We extract characteristic features from vibration signals generated by rolling element bearings. This data is first pre-labelled with an unsupervised clustering method. Then, supervised methods are used to improve the labelling. Moreover, we assess feature importance with each classifier. From the practical point of view, the classifiers are compared on how early emergence of a bearing fault is being suggested. The results show that all of the classifiers are usable for bearing fault detection and the importance of the features was consistent.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-90.pdf
2019,On overfitting of multilayer perceptrons for classification,joseph Rynkiewicz,"In this paper, we consider classification models involving multilayer perceptrons (MLP) with rectified linear (ReLU) functions for activation units. It is a difficult task to study the statistical properties of such models. The main reason is that in practice these models may be heavily overparameterized. We study the asymptotic behavior of the difference between the loss function of estimated models and the loss function of the theoretical best model. These theoretical results give us information on the overfitting properties of such models. Some simulations illustrate our theoretical finding and raise new questions.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-80.pdf
2019,Modal sense classification with task-specific context embeddings,"Bo Li, Mathieu Dehouck, Pascal Denis","Sense disambiguation of modal constructions is a crucial part of natural language understanding. Framed as a supervised learning task, this problem heavily depends on an adequate feature representation of the modal verb context. Inspired by recent work on general word sense disambiguation, we propose a simple approach of modal sense classification in which standard shallow features are enhanced with task-specific context embedding features. Comprehensive experiments show that these enriched contextual representations fed into a simple SVM model lead to significant classification gains over shallow feature sets.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-93.pdf
2019,On the definition of complex structured feature spaces,"Nicolò Navarin, Dinh Van Tran, Alessandro Sperduti","In this paper, we propose a graph kernel whose feature space is  defined  combining  pairs  of  features  of  an  existing base graph  kernel. Furthermore, we propose a variation where the feature space is adaptive with  respect  to  the  learning  task  at  hand,  allowing  to  learn  a  representation suited to it.  Experimental results on six real-world graph datasets from different domains show that the proposed kernels are able to get a consistent performance improvement over the considered base kernel, and over previously defined feature combination methods in literature.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-137.pdf
2019,Application of deep neural networks for automatic planning in radiation oncology treatments,"Ana Barragan Montero, Dan Nguyen, Weiguo Lu, Mu-Han Lin, Xavier Geets, edmond sterpin, Steve Jiang","Treatment planning for radiotherapy patients is a time-consuming and manual process. In this work, we investigate the use of deep neural networks to learn from previous clinical cases and directly predict the optimal dose distribution for a new patient. The proposed model combines two architectures, UNet and DenseNet, and used mean squared error as loss function. Ten input channels were used to include dosimetric and anatomical information. A set of 100 patients was used for training/validation and 29 for testing. Dice similarity coefficients &#8805; 0.9 for the isodose-lines in the predicted versus the clinical dose showed the excellent accuracy of the model.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-174.pdf
2019,Deep Weisfeiler-Lehman assignment kernels via multiple kernel learning,Nils Morten Kriege,Kernels for structured data are commonly obtained by decomposing objects into their parts and adding up the similarities between all pairs of parts measured by a base kernel. Assignment kernels are based on an optimal bijection between the parts and have proven to be an effective alternative to the established convolution kernels. We explore how the base kernel can be learned as part of the classification problem. We build on the theory of valid assignment kernels derived from hierarchies defined on the parts. We show that the weights of this hierarchy can be optimized via multiple kernel learning. We apply this result to learn vertex similarities for the Weisfeiler-Lehman optimal assignment kernel for graph classification. We present first experimental results which demonstrate the feasibility and effectiveness of the approach.,Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-60.pdf
2019,Efficient learning of email similarities for customer support,"Jelle Bakker, Kerstin Bunte","One way to increase customer satisfaction is e&#64259;cient and con-sistent customer email support. In this contribution we investigate the use of dimensionality reduction, metric learning and classi&#64257;cation methods to predict answer templates that can be used by an employee or retrieve his-toric conversations with potential suitable answers given an email query. The strategies are tested on email data and the publicly available Reuters data. We conclude that prototype-based metric learning is fast to train and the parameters provide a compressed representation of the database enabling e&#64259;cient content based retrieval. Furthermore, learning customer email embeddings based on the similarity of employee answers is a promising direction for computer aided customer support.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-79.pdf
2019,Nonnegative matrix factorization with polynomial signals via hierarchical alternating least squares,"Cécile Hautecoeur, François Glineur","Nonnegative matrix factorization (NMF) is a widely used tool in data analysis due to its ability to extract significant features from data vectors. Among algorithms developed to solve NMF, hierarchical alternative least squares (HALS) is often used to obtain state-of-the-art results. We generalize HALS to tackle an NMF problem where both input data and features consist of nonnegative polynomial signals. Compared to standard HALS applied to a discretization of the problem, our algorithm is able to recover smoother features, with a computational time growing moderately with the number of observations compared to existing approaches.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-140.pdf
2019,Deep Embedded SOM: joint representation learning and self-organization,"Florent Forest, Lebbah Mustapha, Azzag Hanane, Jérôme Lacaille","In the wake of recent advances in joint clustering and deep learning, we introduce the Deep Embedded Self-Organizing Map, a model that jointly learns representations and the code vectors of a self-organizing map. Our model is composed of an autoencoder and a custom SOM layer that are optimized in a joint training procedure, motivated by the idea that the SOM prior could help learning SOM-friendly representations. We evaluate SOM-based models in terms of clustering quality and unsupervised clustering accuracy, and study the benefits of joint training.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-30.pdf
2019,Deep convolutional neural network for survival estimation of Amyotrophic Lateral Sclerosis patients,"Enrico Grisan, Alessandro Zandonà, Barbara Di Camillo","We propose a convolutional neural network (CNN) coupled with a fully connected top layer for survival estimation. We design an objective function to directly estimate the probability of survival at discrete time intervals, conditional to the patient not having incurred any adverse event at previous time points. We test our CNN and objective function on a large dataset of longitudinal data of patients with Amyotrophic Lateral Sclerosis (ALS). We compare our CNN and the objective function against other neural networks designed for survival analysis, and against the optimization of Cox-partial-likelihood or a simple logistic classifier. The use of our objective function outperforms both Cox-partial-likelihood and logistic classifier, independently of the network architecture, and our deep CNN provides the best results in terms of AU-ROC, accuracy and mean absolute error.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-48.pdf
2019,Detecting adversarial examples with inductive Venn-ABERS predictors,"Jonathan Peck, Bart Goossens, Yvan Saeys","Inductive Venn-ABERS predictors (IVAPs) are a type of probabilistic predictors with the theoretical guarantee that their predictions are perfectly calibrated. We propose to exploit this calibration property for the detection of adversarial examples in binary classification tasks. By rejecting predictions if the uncertainty of the IVAP is too high, we obtain an algorithm that is both accurate on the original test set and significantly more robust to adversarial examples. The method appears to be competitive to the state of the art in adversarial defense, both in terms of robustness as well as scalability.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-89.pdf
2019,Learning Rich Event Representations and Interactions for Temporal Relation Classification,"Onkar Pandit, Pascal Denis, Liva Ralaivola","Most existing systems for identifying temporal relations between events heavily rely on hand-crafted features derived from event words and explicit temporal markers. Besides, less attention has been given to automatically learning contextualized event representations or to finding complex interactions between events. This paper fills this gap in showing that a combination of rich event representations and interaction learning is essential to more accurate temporal relation classification. Specifically, we propose a neural architecture, in which i) Recurrent Neural Network (RNN) is used to extract contextual information for pairs of events, and ii) a deep Convolutional Neural Network (CNN) architecture is used to find out intricate  interactions between events. We show that the proposed approach outperforms most existing systems on commonly used datasets, while using fully automatic feature extraction and simple local inference.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-113.pdf
2019,L1-norm double backpropagation adversarial defense,"Ismaila Seck, Gaelle Loosli, Stéphane Canu","Adversarial examples are a challenging open problem for deep neural networks.  We propose in this paper to add a penalization term that forces the decision function to be flat in some regions of the input space, such that it becomes, at least locally, less sensitive to attacks. Our proposition is theoretically motivated and shows on a first set of carefully conducted experiments that it behaves as expected when used alone, and seems promising when coupled with adversarial training.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-156.pdf
2019,Metric learning with submodular functions,"Jiajun Pan, Hoel Le Capitaine","Metric learning mainly focuses on learning distances (or similarities) that use single feature weights with Lp norms, or pair of features with Mahalanobis distances. In this paper, we consider higher order interactions in the feature space, by the help of submodular set-functions. We propose to define a distance metric for continuous features based on submodular functions, and then present a dedicated metric learning approach. This is naturally at the price of higher complexity, so that we propose a method allowing to decrease this complexity, by reducing the order of interactions that are taken into account. This approach finally gives a computationally feasible problem. Experiments on various datasets show the effectiveness of the approach.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-49.pdf
2019,Conditional WGAN for grasp generation,"Florian Patzelt, Robert Haschke, Helge Ritter","This work proposes a new approach to robotic grasping exploiting conditional Wasserstein generative adversarial networks (WGANs), which output promising grasp candidates from depth image inputs. In contrast to discriminative models, the WGAN approach enables deliberative navigation in the set of feasible grasps and thus allows a smooth integration with other motion planning tools. We find that the training autonomously partitioned the space of feasible grasps into several regions corresponding to different grasp types. Each region forms a smooth grasp manifold with latent parameters corresponding to important grasp parameters like approach direction.   We evaluate the model in simulation on the multi-fingered Shadow Robot hand, comparing it a) to a classical grasp planner for primitive geometric object shapes and b) to a state-of-the-art discriminative network model. The proposed generative model matches the grasp success rate of its trainer models and exhibits better generalization.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-25.pdf
2019,Multilingual short text categorization using convolutional neural network,"Liriam Enamoto, Li Weigang","One of the most meaningful use of online social media is to communicate quickly during emergency. In case of global emergency, the threat might cross countries borders, affect different cultures and languages. This article aims to explore Convolutional Neural Network (CNN) for multilingual short text categorization in English, Japanese and Portuguese to identify useful information in social media. A CNN is constructed for this special purpose. The experiment results show that CNN model performs better than SVM even in small dataset. And more interestingly, the cross languages test suggests that English, Japanese and Portuguese text can use the same model with few hyperparameters changes.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-19.pdf
2019,Fast and reliable architecture selection for convolutional neural networks,"Lukas Hahn, Lutz Roese-Koerner, Klaus Friedrichs, Anton Kummert","The performance of a Convolutional Neural Network (CNN) depends on its hyperparameters, like the number of layers, kernel sizes, or the learning rate for example. Especially in smaller networks and applications with limited computational resources, optimisation is key.\\ We present a fast and efficient approach for CNN architecture selection. Taking into account time consumption, precision and robustness, we develop a heuristic to quickly and reliably assess a network's performance. In combination with Bayesian optimisation, to effectively cover the vast parameter space, our contribution offers a plain and powerful architecture search for this machine learning technique.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-26.pdf
2019,On the Speedup of Deep Reinforcement Learning Deep Q-Networks (RL-DQNs),"Anas Albaghajati, Lahouari Ghouti","Deep reinforcement learning (DRL) merges reinforcement (RL) and deep learning (DL). In DRL-based agents rely on high-dimensional imagery inputs to make accurate decisions. Such excessively high-dimensional inputs and sophisticated algorithms require very powerful computing resources and longer training times. To alleviate the need for powerful resources and reduce the training times, this paper proposes novel solutions to mitigate the curse-of-dimensionality without compromising the DRL agent performance. Using these solutions, the deep Q-network model (DQN) and its improved versions require less training times while achieving better performance.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-32.pdf
2019,Deep Autoencoder Feature Extraction for Fault Detection of Elevator Systems,"Krishna Mohan Mishra, Tomi Krogerus , Kalevi Huhtala","In this research, we propose a generic deep autoencoder model for automated feature extraction from the elevator sensor data. Extracted deep features are classified with random forest algorithm for fault detection. Sensor data are labelled as healthy or faulty based on the maintenance actions recorded. In our research, we have included all fault types present for each elevator. The remaining healthy data is used for validation of the model to prove its efficacy in terms of avoiding false positives. We have achieved nearly 100% accuracy in fault detection along with avoiding false positives based on new extracted deep features, which outperform the results using existing features.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-37.pdf
2019,Detecting Ghostwriters in High Schools,"Magnus Stavngaard, August Sørensen, Stephan Lorenzen, Niklas Hjuler, Stephen Alstrup","Students hiring ghostwriters to write their assignments is an increasing problem in educational institutions all over the world, with companies selling these services as a product. In this work, we develop automatic techniques with special focus on detecting such ghostwriting in high school assignments.  This is done by training deep neural networks on an unprecedented large amount of data  supplied by the Danish company MaCom, which covers 90% of Danish high schools.  We achieve an accuracy of 0.875 and a AUC score of 0.947 on an evenly split data set.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-121.pdf
2019,Design of Power-Efficient FPGA Convolutional Cores with Approximate Log Multiplier,"Leonardo Tavares Oliveira, Min Soo Kim, Alberto Antonio Del Barrio García, Nader Bagherzadeh, Ricardo Menotti","This paper presents the design of a convolutional core that utilizes an approximate log multiplier to significantly reduce the power consumption of FPGA acceleration of convolutional neural networks. The core also exploits FPGA reconfigurability as well as the parallelism and input sharing opportunities in convolutional layers to minimize the costs. The simulation results show reductions up to 78.19% of LUT usage and 60.54% of power consumption compared to the core that uses exact fixed-point multiplier, while maintaining comparable accuracy on a subset of MNIST dataset.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-125.pdf
2019,PAC-Bayes and Fairness: Risk and Fairness Bounds on Distribution Dependent Fair Priors,"Luca Oneto, Michele Donini, Massimiliano Pontil","We address the problem of algorithmic fairness: ensuring that sensitive information does not unfairly influence the outcome of a classifier. We face this issue in the PAC-Bayes framework and we present an approach which trades off and bounds the risk and the fairness of the Gibbs Classifier measured with respect to different state-of-the-art fairness measures. For this purpose, we further develop the idea that the PAC-Bayes prior can be defined based on the data-generating distribution without actually needing to know it. In particular, we define a prior and a posterior which gives more weight to functions which exhibit good generalization and fairness properties.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-77.pdf
2019,DropConnect for Evaluation of Classification Stability in Learning Vector Quantization,"Jensun Ravichandran, Sascha Saralajew, Thomas Villmann","In this paper we consider DropOut/DropConnect techniques known from deep neural networks to evaluate the stability of learning vector quantization classifiers (LVQ). For this purpose, we consider the LVQ as a multilayer network and transfer the respective concepts to LVQ. Particularly, we consider the output as a stochastic ensemble such that an information theoretic measure is obtained to judge the stability level.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-131.pdf
2019,Pixel-wise Conditioning of Generative Adversarial Networks,"Cyprien Ruffino, Romain HERAULT, Eric Laloy, Gilles Gasso","Generative Adversarial Networks (GANs) have proven successful for unsupervised image generation. Several works extended GANs to image inpainting by conditioning the generation with parts of the image one wants to reconstruct. However, these methods have limitations in settings where only a small subset of the image pixels is known beforehand. In this paper, we study the effectiveness of conditioning GANs by adding an explicit regularization term to enforce pixel-wise conditions when very few pixel values are provided. In addition, we also investigate the influence of this regularization term on the quality of the generated images and the satisfaction of the conditions. Conducted experiments on MNIST and FashionMNIST show evidence that this regularization term allows for controlling the trade-off between quality of the generated images and constraint satisfaction.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-189.pdf
2019,Committees as Artificial Organisms - Evolution and Adaptation,Roberto Alamino,"Generalised committee machines are here proposed to model an organism's DNA interaction with its environment, which are shown to induce a unique genotype-phenotype map. An application to organisms being subjected to a toxic environment is shown to allow antagonistic pleiotropy. The same scenario is studied in order to show the difference in adaptation when there is a fitness cost given by a lower reproduction rate.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-142.pdf
2019,Towards a device-free passive presence detection system with Bluetooth Low Energy beacons,"Maximilian Münch, Karsten Huffstadt, Frank-Michael Schleif","In an era of smart information systems and smart buildings, detecting, tracking and identifying the presence of attendants inside of enclosed rooms have evolved to a key challenge in the research area of smart building systems. Therefore, several types of sensing systems were proposed over the past decade to tackle these challenge. Depending on the component’s arrangement, a distinction is made between so-called device-based active and device-free passive sensing systems. Here we focus on the device-free passive concept and introduce a strategy of using Bluetooth Low Energy beacons for passive presence detection.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-68.pdf
2019,Defending against poisoning attacks in online learning settings,"Greg Collinge, Emil C Lupu, Luis Muñoz-González","Machine learning systems are vulnerable to data poisoning, a coordinated attack where a fraction of the training dataset is manipulated by an attacker to subvert learning. In this paper we first formulate an optimal attack strategy against online learning classifiers to assess worst-case scenarios. We also propose two defence mechanisms to mitigate the effect of online poisoning attacks by analysing the impact of the data points in the classifier and by means of an adaptive combination of machine learning classifiers with different learning rates. Our experimental evaluation supports the usefulness of our proposed defences to mitigate the effect of poisoning attacks in online learning settings.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-84.pdf
2019,Progress Towards Graph Optimization: Efficient Learning of Vector to Graph Space Mappings,"Stefan Mautner, Rolf Backofen, Fabrizio Costa","Optimization in vector space domains is well understood. However, in high dimensional settings or when dealing with structured data such as sequences and graphs, optimization becomes difficult. A possible strategy is to map graphs to vector codes and use machine learning to learn a map from codes back to graphs. This in turn allows to employ standard optimization techniques over vectors to optimize graphs. Here we propose an approach to invert a vector mapping based on a combination of graph kernels and graph grammars. We evaluate the proposed approach in an artificial setup and on real molecular graphs.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-115.pdf
2019,Interpolation on the manifold of fixed-rank positive-semidefinite matrices for parametric model order reduction: preliminary results,"Estelle Massart, Pierre-Yves Gousenbourger, Thanh Son Nguyen, Tatjana Stykel, Pierre-Antoine Absil","We present several interpolation schemes on the manifold of fixed-rank positive-semidefinite (PSD) matrices. We explain how these techniques can be used for  model order reduction of parameterized linear dynamical systems, and obtain preliminary results on an application.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-164.pdf
2019,Minimax center to extract a common subspace from multiple datasets,"Emilie Renard, Pierre-Antoine Absil, Kyle Gallivan","We address the problem of extracting common information from multiple datasets. More specifically, we look for a common subspace minimizing the maximal dissimilarity with all datasets and we propose an algorithm derived from the first order necessary conditions of optimality. On synthetic datasets the proposed method gives as good results as a Riemannian based approach, but also provides an evaluation on how far the iterate is from a critical point.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-87.pdf
2019,Sparse minimal learning machine using a diversity measure minimization,"Madson Dias, Lucas Sousa, Ajalmar Rocha Neto, Cesar Mattos, Joao Gomes, Tommi Kärkkäinen","The minimal learning machine (MLM) training procedure consists in solving a linear system with multiple measurement vectors (MMV) created between the geometric configurations of points in the input and output spaces. Such geometric configurations are built upon two matrices created using subsets of input and output points, named reference points (RPs). The present paper considers an extension of the focal underdetermined system solver (FOCUSS) for MMV linear systems problems with additive noise, named regularized MMV FOCUSS (regularized M FOCUSS), and evaluates it in the task of selecting input  reference points for regression settings. Experiments were carried out using UCI datasets, where the proposal was able to produce sparser models and achieve competitive performance when compared to the regular strategy of selecting MLM input RPs.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-178.pdf
2019,Very Simple Classifier: a concept binary classifier to investigate features based on subsampling and locality,"Luca Masera, Enrico Blanzieri",We propose Very Simple Classifier (VSC) a novel method designed to incorporate the concepts of subsampling and locality in the definition of features to be used as the input of a perceptron. The rationale is that locality theoretically guarantees a bound on the generalization error. Each feature in VSC is a max-margin classifier built on randomly-selected pairs of samples. The locality in VSC is achieved by multiplying the value of the feature by a confidence measure that can be characterized in terms of the Chebichev inequality. The output of the layer is then fed in a output layer of neurons. The weights of the output layer are then determined by a regularized pseudoinverse. Extensive comparison of VSC against 9 competitors in the task of binary classification is carried out. Results on 22 benchmark datasets with fixed parameters show that VSC is competitive with the Multi Layer Perceptron (MLP) and outperforms the other competitors. An exploration of the parameter space shows VSC can outperform MLP.,Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-141.pdf
2019,Predicting vehicle behaviour using LSTMs and a vector power representation for spatial positions,"Florian Mirus, Peter Blouw, Stewart Terrence, Jörg Conradt","Predicting future vehicle behaviour is an essential task to enable safe and situation-aware automated driving. In this paper, we propose to encapsulate spatial information of multiple objects in a semantic vector-representation. Assuming that future vehicle motion is influenced not only by past positions but also by the behaviour of other traffic participants, we use this representation as input for a Long Short-Term Memory (LSTM) network for sequence to sequence prediction of vehicle positions. We train and evaluate our system on real-world driving data collected mainly on highways in southern Germany and compare it to other models for reference.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-67.pdf
2019,Prediction of palm oil production with an enhanced n-Tuple Regression Network,"Leopoldo Lusquino Filho, Luiz Oliveira, Aluizio Lima Filho, Gabriel Guarisa, Priscila Machado Vieira Lima, Felipe  Maia Galvão França","This paper introduces Regression WiSARD and ClusRegression WiSARD, two new weightless neural network models that were applied in the challenging task of predicting the total palm oil production of a set of 28 differently located sites under different climate and soil profiles. Both models were derived from the n-tuple regression weightless neural model and obtained error rates of 8.737% and 8.938%, respectively, which are very competitive with the state-of-art (7.569%), whilst being four (4) orders of magnitude faster during the training phase.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-108.pdf
2019,Systems with 'subjective feelings' - the perspective from weightless automata,"Igor Aleksander, Helen Morton",,60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-1.pdf
2019,Complex Valued Gated Auto-encoder for Video Frame Prediction,"Niloofar Azizi, Nils Wandel, Sven Behnke","Over recent years, complex-valued artificial neural networks have gained increasing interest as they allow neural networks to learn richer representations while potentially incorporating less parameters. Especially in the domain of computer graphics, many traditional operations such as image smoothing/sharpening rely heavily on computations in the complex domain thus complex valued neural networks apply naturally.  In this paper, we perform frame predictions in video sequences using a complex valued gated auto-encoder with tied input weights. First, our method is motivated showing how the Fourier transform can be seen as the basis for translational operations. Then, we present how a complex neural network can learn such transformations and compare its performance and parameter efficiency to a real valued gated auto-encoder. Furthermore, we show how extending both --- the real and the complex valued --- neural networks by using convolutional units can significantly improve prediction performance and parameter efficiency.  All networks are assessed on the bouncing ball dataset.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-176.pdf
2019,Societal Issues in Machine Learning: When Learning from Data is Not Enough,"Davide Bacciu, Battista Biggio, Paulo Lisboa, José D. Martín, Luca Oneto, Alfredo Vellido","It has been argued that Artificial Intelligence (AI) is experiencing a fast process of commodification. Such characterization is on the interest of big IT companies, but it correctly reflects the current industrialization of AI. This phenomenon means that AI systems and products are reaching the society at large and, therefore, that societal issues related to the use of AI and Machine Learning (ML) cannot be ignored any longer. Designing ML models from this human-centered perspective means incorporating human-relevant requirements such as safety, fairness, privacy, and interpretability, but also considering broad societal issues such as ethics and legislation. These are essential aspects to foster the acceptance of ML-based technologies, as well as to ensure compliance with an evolving legislation concerning the impact of digital technologies on ethically and privacy sensitive matters. The {ESANN} special session for which this tutorial acts as an introduction aims to showcase the state of the art on these increasingly relevant topics among ML theoreticians and practitioners. For this purpose, we welcomed both solid contributions and preliminary relevant results showing the potential, the limitations and the challenges of new ideas, as well as refinements, or hybridizations among the different fields of research, ML and related approaches in facing real-world problems involving societal issues.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-6.pdf
2019,Direct calculation of out-of-sample predictions in multi-class kernel FDA,Treder Matthias,"After a two-class kernel Fisher Discriminant Analysis (KFDA) has been trained on the full dataset,  matrix inverse updates allow for the direct calculation of out-of-sample predictions for different test sets. Here, this approach is extended to the multi-class case by casting KFDA in an Optimal Scoring framework. In simulations using 10-fold cross-validation and permutation tests the approach is shown to be more than 1000x faster than retraining the classifier in each fold. Direct out-of-sample predictions can be useful on large datasets and in studies with many training-testing iterations.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-194.pdf
2019,A WNN model based on Probabilistic Quantum Memories,"Priscila G.M. dos Santos, Rodrigo S Sousa, Adenilton J. da Silva","In this work, we evaluate a Weightless Neural Network model based on a Probabilistic Quantum Memory. The model does not require any training  and performs the classification by calculating the Hamming distance between a   new sample and the training samples stored on the quantum memory. In order to  evaluate the classification capabilities of this quantum model, we  conducted classical experiments using an equivalent classical description of  the Probabilist Quantum Memory algorithm. We present the first evaluation of a quantum weightless  neural networks on public benchmark datasets.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-56.pdf
2019,Weightless neural systems for deforestation surveillance and image-based navigation of UAVs in the Amazon forest,"Eduardo Ribeiro, Vitor Torres, Brayan James, Mateus Braga, Elcio Shiguemori, Haroldo Velho, Luiz Torres, Antônio Braga","This work proposes a novel methodology for the recognition of deforestation areas in tropical forests using weightless neural systems in UAVs. The weightless neural systems embedded in hardware brings a considerable improvement in the speed of processing of image-based navigation of UAVs. In our approach the UAV navigates at the frontier of the deforestation area by means of previously trained descriptors, being able to monitor the increase of deforestation area. Experiments using images of the Amazon rainforest have been performed to validate the proposed approach.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-153.pdf
2019,An evolutionary approach for optimizing weightless neural networks,"Maurizio Giordano, Massimo De Gregorio",WiSARD is a weightless neural network model using RAMs to store the function computed by each neuron rather than storing it in connection weights between neurons. Non-linearity in WiSARD is imple- mented by a mapping that splits the binary input into tuples of bits and associate these tuples to neurons. In this work we apply an evolutionary al- gorithm to make evolve an initial population of mappings by combinations and mutations toward the generation of new mappings granting significant improvements in classification accuracy in the conducted experiments.,60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-54.pdf
2019,Modeling  Sparse Data as Input for Weightless Neural Network,"Luis Kopp, Jose Barbosa Filho, Priscila Machado Vieira Lima, Claudio de Farias","Dealing with large and sparse input data has been a challenge to machine learning algorithms. In Natural Language Processing (NLP), the number of words used in a text is only a small fraction of a dictionary with all possible words and leads to very sparse matrix. In this paper we propose an alternative method for constructing the input vector in a Weightless Neural Network model using WiSARD. Our algorithm significantly outperformed the benchmark method in accuracy by 3.7\% on average when aggregating columns in groups of 3 or 6 words.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-187.pdf
2019,Multi-target feature selection through output space clustering,"Konstantinos Sechidis, Eleftherios  Spyromitros-Xioufis, Ioannis Vlahavas","A key challenge in information theoretic feature selection is to estimate mutual information expressions that capture three desirable terms: the relevancy of a feature with the output, the redundancy and the complementarity between groups of features.  The challenge becomes more pronounced in multi-target problems, where the output space is multi-dimensional. Our work presents a generic algorithm that captures these three desirable terms and is suitable for the well-known multi-target prediction settings of multi-label/dimensional classification and multivariate regression. We achieve this by combining two ideas: deriving low-order information theoretic approximations for the input space and using clustering for deriving low-dimensional approximations of the output space.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-20.pdf
2019,Feature relevance bounds for ordinal regression,"Lukas Pfannschmidt, Jonathan Jakob, Michael Biehl, Peter Tino, Barbara Hammer","The increasing occurrence of ordinal data, mainly sociodemographic, led to a renewed research interest in ordinal regression, i.e. the prediction of ordered classes. Besides model accuracy, the interpretation of these models itself is of high relevance, and existing approaches therefore enforce e.g. model sparsity. For high dimensional or highly correlated data, however, this might be misleading due to strong variable dependencies. In this contribution, we aim for an identification of feature relevance bounds which – besides identifying all relevant features – explicitly differentiates between strongly and weakly relevant features.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-162.pdf
2019,User-steering interpretable visualization with probabilistic principal components analysis,"Viet Minh Vu, Benoît Frénay",The lack of interpretability generally in machine learning and specifically in visualization is often encountered. Integration of user's feedbacks into visualization process is a potential solution. This paper shows that the user's knowledge expressed by the positions of fixed points in the visualization can be transferred directly into a probabilistic principal components analysis (PPCA) model to help user steer the visualization. Our proposed interactive PPCA model is evaluated with different datasets to prove the feasibility of creating explainable axes for the visualization.,Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-44.pdf
2019,Analyzing spatial dissimilarities in high-resolution geo-data : a case study of four European cities,"Julien Randon-Furling, William Clark, Madalina Olteanu","The analysis of spatial dissimilarities across cities often relies on pre-defined areal units, leading to problems of scale, interpretability and cross-comparisons. Furthermore, traditional measures of dissimilarities tend to be single-number indices that fail to capture the complexity of segregation patterns. We present in this paper a method that allows one to extract and analyze information on all scales, at every point in the city, through a stochastic sequential aggregation procedure based on high-resolution data. This method provides insightful visual representations, as well as mathematical characterizations of segregation phenomena.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-175.pdf
2019,Fusing Features based on Signal Properties and TimeNet for Time Series Classification,"Arijit Ukil, Pankaj Malhotra, Soma Bandyopadhyay, Tulika Bose, Ishan Sahu, Ayan Mukherjee, Lovekesh Vig, Arpan Pal, Gautam Shroff","Automated feature extraction from time series to capture statistical, temporal, spectral, and morphololgical properties is highly desirable but challenging due to diverse nature of real-world time series applications. In this paper, we consider extracting a rich and robust set of time series features encompassing signal processing based features as well as generic hierarchical features extracted via deep neural networks. We present SPGF-TimeNet: a generic feature extractor for time series that allows fusion of signal processing, information-theoretic, and statistical features (Signal Properties based Generic Features (SPGF)) with features from an off-the-shelf pre-trained deep recurrent neural network (TimeNet). Through empirical evalution on diverse benchmark datasets from the UCR Time Series Classication (TSC) Archive, we show that classfiers trained on SPGF-TimeNet-based hybrid and generic features outperform state-of-the-art TSC algorithms such as BOSS, while being computationally efficient.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-135.pdf
2019,Metric learning with relational data,"Jiajun Pan, Hoel Le Capitaine","The vast majority of metric learning approaches are meant to be applied on data described by feature vectors, with some notable exceptions such as times series, trees or graphs. The objective of this paper is to propose metric learning algorithms that consider multi-relational data. More specifically, we present a metric learning approach taking into account the features of the observations, as well as the relationships between observations.Experiments and comparisons of the two settings for a collective classification task on real-world datasets show that our method i) presents a better performance than other approaches in both settings, and ii) scales well with the volume of the data.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-51.pdf
2019,Feature and Algorithm Selection for Capacitated Vehicle Routing Problems,"Jussi Rasku, Nysret Musliu, Tommi Kärkkäinen","Many exact, heuristic, and metaheuristic algorithms have been proposed to effectively produce high quality solutions to vehicle routing problems. However, it remains an open question which algorithm is the most appropriate for solving a given problem instance, mostly because the different strengths and weaknesses of algorithms are still not well understood. We propose an extensive feature set for describing capacitated vehicle routing problem instances and illustrate how it can be used in algorithm selection, and how different feature selection approaches can be used to recognize the most relevant features for this task.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-110.pdf
2019,Topic-based historical information selection for personalized sentiment analysis,"Siwen Guo, Sviatlana Höhn, Christoph Schommer","In this paper, we present a selection approach designed for personalized sentiment analysis with the aim of extracting related information from a user's history. Analyzing a person's past is key to modeling individuality and understanding the current state of the person. We consider a user's expressions in the past as historical information, and target posts from social platforms for which Twitter texts are chosen as exemplary. While implementing the personalized model PERSEUS, we observed information loss due to the lack of flexibility regarding the design of the input sequence. To compensate this issue, we provide a procedure for information selection based on the similarities in the topics of a user's historical posts. Evaluation is conducted comparing different similarity measures, and improvements are seen with the proposed method.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-112.pdf
2019,Bridging face and sound modalities through domain adaptation metric learning,"Christos Athanasiadis, Enrique Hortal, Stylianos Asteriadis","Robust emotion recognition systems require extensive training by employing huge number of training samples with purpose of generating sophisticated models. Furthermore, research is mostly focused on facial expression recognition due, mainly to, the wide availability of related datasets. However, the existence of rich and publicly available datasets is not the case for other modalities like sound and so forth. In this work, a heterogeneous domain adaptation framework is introduced for bridging two inherently different domains (namely face and audio). The purpose is to perform affect recognition on the modality where only a small amount of data is available, leveraging large amounts of data from another modality.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-143.pdf
2019,Model selection for Extreme Minimal Learning Machine using sampling,Tommi Kärkkäinen,"A combination of Extreme Learning Machine (ELM) and Minimal Learning Machine (MLM)-to use a distance-based basis from MLM in the ridge regression like learning framework of ELM-was proposed in [8]. In the further experiments with the technique [9], it was concluded that in multilabel classification one can obtain a good validation error level without overlearning simply by using the whole training data for constructing the basis. Here, we consider possibilities to reduce the complexity of the resulting machine learning model, referred as the Extreme Minimal Leaning Machine (EMLM), by using a bidirectional sampling strategy: To sample both the feature space and the space of observations in order to identify a simpler EMLM without sacrificing its generalization performance.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-18.pdf
2019,Knowledge Discovery in Quarterly Financial Data of Stocks Based on the Prime Standard using a Hybrid of a Swarm with SOM,Michael Thrun,"Stocks of the German Prime standard have to publish financial reports every three months which were not used fully for fundamental analysis so far. Through web scrapping, an up-to-date high-dimensional dataset of 45 features of 269 companies was extracted, but finding meaningful cluster structures in a high-dimensional dataset with a low number of cases is still a challenge in data science. A hybrid of a swarm with a SOM called Databionic swarm (DBS) found meaningful structures in the financial reports. Using the Chord distance the DBS algorithm results in a topographic map of high-dimensional structures and a clustering. Knowledge from the clustering is acquired using CART. The cluster structures can be explained by simple rules that allow predicting which future stock courses will fall with a 70% probability.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-34.pdf
2019,Improving Pedestrian Recognition using Incremental Cross Modality Deep Learning,"Danut Ovidiu Pop, Alexandrina Rogozan, Fawzi Nashashibi, Abdelaziz Bensrhair","Late fusion schemes with deep learning classification patterns set up with multi-modality images have an essential role in pedestrian protection systems since they have achieved prominent results in the pedestrian recognition task. In this paper, the late fusion scheme merged with Convolutional Neural Networks (CNN) is investigated for pedestrian recognition based on the Daimler stereo vision data sets. An independent CNN-based classifier for each imaging modality (Intensity, Depth, and Optical Flow) is handled before the fusion of its probabilistic output scores with a Multi-Layer Perceptron which provides the recognition decision. In this paper, we set out to prove that the incremental cross-modality deep learning approach enhances pedestrian recognition performances. It also outperforms state-of-the-art pedestrian classifiers on the Daimler stereo-vision data sets.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-144.pdf
2019,Machine learning in research and development of new vaccines products: opportunities and challenges,"Paul Smyth, Gaël de Lannoy, Moritz Von Stosch, Alexander Pysik, Amin Khan","Modern high-throughput technologies deployed in research and development of new vaccine products have opened the door to machine learning applications that allow the automation of tasks and support for data-driven risk-based decision making. In this paper, the opportunities and the challenges faced for the deployment of machine learning algorithms in the field of vaccines development are discussed.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-152.pdf
2019,Real-time Convolutional Neural Networks for emotion and gender classification,"Matias Valdenegro-Toro, Octavio Arriaga, Paul Plöger","Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-157.pdf
2019,Experimental study of the neuron-level mechanisms emerging from backpropagation,"Simon Carbonnelle, Christophe De Vleeschouwer","The backpropagation algorithm is the most successful learning algorithm for training deep artificial neural networks. Its inner workings are in stark contrast with other learning rules, as it is based on a global, black box optimization procedure rather than the repetition of a local, neuron-level procedure (e.g. like hebbian learning). In this paper, we present preliminary evidence suggesting that local, neuron-level mechanisms are in fact emerging during backpropagation-based training of neural networks and describe what could be key components of it.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-57.pdf
2019,Learning multimodal fixed-point weights using gradient descent,"Lukas Enderich, Fabian Timm, Lars Rosenbaum, Wolfram Burgard","Due to their high computational complexity, deep neural networks are still limited to powerful processing units. To promote a reduced model complexity by dint of low-bit fixed-point quantization, we propose a gradient-based optimization strategy to generate a symmetric mixture of Gaussian modes (SGM) where each mode belongs to a particular quantization stage. We achieve 2-bit state-of-the-art performance and illustrate the model's ability for self-dependent weight adaptation during training.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-69.pdf
2019,Preconditioned conjugate gradient algorithms for graph regularized matrix completion,"Shuyu Dong, Pierre-Antoine Absil, Kyle Gallivan","Low-rank matrix completion is the problem of recovering the missing entries of a data matrix by using the assumption that a good low-rank approximation to the true matrix is possible. Much attention has been put recently to exploiting correlations between the column/row entities through side information to improve the matrix completion quality. In this paper, we propose an efficient algorithm for solving the low-rank matrix completion with graph-based regularizers. Experiments on synthetic data show that our approach achieves significant speedup compared to the alternating minimization scheme.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-133.pdf
2019,Reactive Soft Prototype Computing for frequent reoccurring Concept Drift,"Christoph Raab, Moritz Heusinger, Frank-Michael Schleif","Todays datasets, especially in stream context, are more and more non-static and require algorithms to detect and adapt to change. Recent work shows vital research in the field, but mainly lack stable performance during model adaptation. In this work, a bound detection strategy followed by a prototype based insertion strategy is proposed. Validated through experimental results on a variety of typical non-static data, our solution provides stability and quick adjustment in times of change.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-33.pdf
2019,Online Bayesian Shrinkage Regression,"Waqas Jamil, Abdelhamid Bouchachia","The present work introduces a new online regression method that extends the Shrinkage via Limit of Gibbs sampler (SLOG) in the context of online learning. In particular, we theoretically demonstrate that the proposed Online SLOG (OSLOG) is derived using the Bayesian framework without resorting to the Gibbs sampler. We also prove the performance guarantee of OSLOG.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-105.pdf
2019,"Recent trends in streaming data analysis, concept drift and analysis of dynamic data sets","Albert Bifet, Barbara Hammer, Frank-Michael Schleif","Today, many data are not any longer static but occur as dynamic data streams with high velocity, variability and volume. This leads to new challenges to be addressed by novel or adapted algorithms. In this tutorial we provide an introduction into the field of streaming data analysis summarizing its major characteristics and highlighting important research directions in the analysis of dynamic data.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-3.pdf
2019,Variational auto-encoders with Student’s t-prior,"Najmeh Abiri, Mattias Ohlsson","We propose a new structure for the variational autoencoder (VAE) prior, with the weakly informative multivariate Student-t distribution. In the proposed model all distribution parameters are trained, thereby allowing for a more robust approximation of the underlying data distribution. We used Fashion-MNIST data in two experiments to compare the proposed VAE with the standard Gaussian prior. Both experiments showed a better reconstruction of the images with VAE using Student-t prior distribution.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-42.pdf
2019,Class-aware t-SNE: cat-SNE,"Cyril de Bodt, Dounia Mulders, Daniel Lopez-Sanchez, Michel Verleysen, John Lee","Stochastic Neighbor Embedding (SNE) and variants like $t$-distributed SNE are popular methods of unsupervised dimensionality reduction (DR) that deliver outstanding experimental results. Regular $t$-SNE is often used to visualize data with class labels in colored scatterplots, even if those labels are actually not involved in the DR process. This paper proposes a modification of $t$-SNE that uses class labels to adjust the individual widths of the Gaussian neighborhoods around each datum, instead of deriving those from a perplexity set by the user. The widths are adjusted such that neighbors of the same class around a datum exceed a certain fraction of the probability, typically above $50\%$. Doing so tends to shrink the bulk of the classes and to stretch their separation. Experimental results show that the proposed class-aware $t$-SNE ($\mathrm{ca}t$-SNE) outperforms regular $t$-SNE in a $K$NN classification task carried in the embedding.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-117.pdf
2019,Dimensionality reduction in a hydraulic valve positioning application,Travis Wiens,"This paper presents an application of neural network signal processing to estimate the position of a hydraulic valve spool, based on acoustic excitement of the spool's end chamber. The spool's end chamber acts somewhat like a Helmholtz resonator whose frequency response changes based on its volume (and therefore spool position).  However, non-ideal characteristics of the system including wave propagation effects and distributed parameters mean that estimating the volume is more complicated than simply evaluating the resonant frequency. In this case the frequency response has high dimensionality with high redundancy and noise. We present the use of linear and nonlinear principal component analysis to preprocess the frequency response data prior to neural network regression.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-55.pdf
2019,Tensor factorization to extract patterns in multimodal EEG data,"Dounia Mulders, Cyril de Bodt, Nicolas Lejeune, John Lee, André Mouraux, Michel Verleysen","Noisy multi-way data sets are ubiquitous in many domains. In neuroscience, electroencephalogram (EEG) data are recorded during periodic stimulation from different sensory modalities, leading to steady-state (SS) recordings with at least four ways: the channels, the time, the subjects and the modalities. Improving the signal-to-noise ratio (SNR) of the SS responses is crucial to enable their practical use. Supervised spatial filtering methods can be considered for this purpose to relevantly guide the extraction of specific activity patterns. Nevertheless, such approaches are difficult to validate with few subjects and can process at most two data ways simultaneously, the remaining ones being either averaged or considered independently despite their dependencies. This paper hence designs unsupervised tensor factorization models to enable identifying meaningful underlying structures characterized in all ways of multimodal SS data. We show on EEG recordings from 15 subjects that such factorizations faithfully reveal consistent spatial topographies, time courses with enhanced SNR and subject variations of the periodic brain activity.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-130.pdf
2019,Multiple-Kernel dictionary learning for reconstruction and clustering of unseen multivariate time-series,"Babak Hosseini, Barbara Hammer","There exist many approaches for description and recognition of unseen classes in datasets. Nevertheless, it becomes a challenging problem when we deal with multivariate time-series (MTS) (e.g., motion data), where we cannot apply the vectorial algorithms directly to the inputs. In this work, we propose a novel multiple-kernel dictionary learning (MKD) which learns semantic attributes based on specific combinations of MTS dimensions in the feature space. Hence, MKD can fully/partially reconstructs the unseen classes based on the training data (seen classes). Furthermore, we obtain sparse encodings for unseen classes based on the learned MKD attributes, and upon which we propose a simple but effective incremental clustering algorithm to categorize the unseen MTS classes in an unsupervised way. According to the empirical evaluation of our MKD framework on real benchmarks, it provides an interpretable reconstruction of unseen MTS data as well as a high performance regarding their online clustering.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-126.pdf
2019,Transfer Learning for transferring machine-learning based models among hyperspectral sensors,"Patrick Menz, Andreas Backhaus, Udo Seiffert",Using previously generated machine learning models under changing sensor hardware with nearly the same performance is a desirable goal. This constitutes a model transfer problem. We compare a Radial Basis Function Network adapted for transfer learning to a classical data alignment approach. This approach to transfer machine-learning models is tested on a task of material classification using hyperspectral imaging recorded with different camera systems and the aim to make camera systems interchangeable. The results show that a machine-learning based algorithm outperforms a state-of-the-art hyperspectral data alignment algorithm.,Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-123.pdf
2019,Active one-shot learning with Prototypical Networks,"Rinu Boney, Alexander Ilin",We consider the problem of active one-shot classification where a classifier needs to adapt to new tasks by requesting labels for one example per class from (potentially many) unlabeled examples. We propose a clustering approach to the problem. The features extracted with Prototypical Networks are clustered using K-means and the label for one representative sample from each cluster is requested to label the whole cluster. We demonstrate good performance of this simple active adaptation strategy using image data.,Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-81.pdf
2019,LEAP nets for power grid perturbations,"Benjamin Donnot, Balthazar Donon, Isabelle Guyon, Liu ZHENGYING, Antoine MAROT, Patrick Panciatici, Marc Schoenauer","We propose a novel neural network embedding approach to model power transmission grids, in which high voltage lines are disconnected and re-connected with one-another from time to time, either accidentally or willfully.  We call our architeture LEAP net, for Latent Encoding of Atypical Perturbation.  Our method implements a form of transfer learning, permitting to train on a few source domains, then generalize to new target domains, without learning on any example of that domain. We evaluate the viability of this technique to rapidly assess curative actions that human operators take in emergency situations, using real historical data, from the French high voltage power grid.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-46.pdf
2019,A best-first branch-and-bound search for solving the transductive inference problem using support vector machines,"Hygor Xavier Araújo, Raul Fonseca Neto, Saulo Moraes Villela",In this paper we present a new method for solving the transductive inference problem whose objective is predicting the binary labels of a subset of points of interest of an unknown decision function. We attempt to learn a decision boundary using SVM. To obtain the maximal-margin hypothesis over labeled and unlabeled samples we employ an admissible best-first search based on margin values. Empirical evidence suggests that this globally optimal solution can obtain excellent results in the transduction problem. Due to the selection strategy used the search algorithm explores only a small fraction of unlabeled samples making it efficiently applicable to median-sized datasets. We compare our results with the results obtained from the TSVM demonstrating better results in margin values.,Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-201.pdf
2019,Computerized tool for identification and enhanced visualization of Macular Edema regions using OCT scans,"Iago Otero Coto, Plácido Francisco Lizancos Vidal, Joaquim de Moura, Jorge Novo, Marcos Ortega","We propose a novel methodology using Optical Coherence Tomography (OCT) images to detect the 3 clinically defined types of Macular Edema, which is among the main causes of blindness: Diffuse Retinal Thickening (DRT), Cystoid Macular Edema (CME) and Serous Retinal Detachment (SRD). To perform this detection, we sample the images and train models to create an intuitive color map that represents the 3 pathologies to facilitate the clinical evaluation. The proposed method was tested using a dataset composed by 96 OCT images. The system provided satisfactory results with accuracy values of 90.49%, 93.23% and 88.87% for the CME, SRD and DRT detections, respectively.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-21.pdf
2019,Learning super-resolution 3D segmentation of plant root MRI images from few examples,"Ali Oguz Uzman, Jannis Horn, Sven Behnke","Analyzing  plant roots is crucial to understand  plant performance in different soil environments. While magnetic resonance imaging (MRI) can be used to  obtain 3D images of  plant roots, extraction of the root structural model is challenging due to highly noisy soil environments and low-resolution of  MRI images. To improve both contrast and resolution, we adapt the state-of-the-art method RefineNet for 3D segmentation of the plant root MRI images in super-resolution. The networks are trained from few manual segmentations that are augmented by geometric transformations, realistic noise, and other variabilities.  The resulting segmentations contain most root structures including branches not extracted by human supervision.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-100.pdf
2019,A document detection technique using convolutional neural networks for optical character recognition systems,"Lorand Dobai, Mihai Teletin","An important part of an optical character recognition pipeline is the preprocessing step, whose purpose is to enhance the conditions under which the text extraction is later performed. In this paper, we present a novel deep learning based preprocessing method to jointly detect and deskew documents in digital images. Our work intends to improve the optical recognition performance, especially on frames which are skewed (slightly rotated) or have cluttered backgrounds.  The proposed method achieves good document detection and deskewing results on a dataset of photos of cash receipts.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-17.pdf
2019,Blind-spot network for image anomaly detection: A new approach to diabetic retinopathy screening,"Shaon Sutradhar, José Rouco, Marcos Ortega","The development of computer-aided screening (CAS) systems is motivated by the high prevalence and severity of the target disease along with the time taken to manually assess each case. This is the case with diabetic retinopathy screening, that is based on the manual grading of retinography images. The development of CAS systems, however, usually involves data-driven approaches that require extensive and usually scarce manually labeled datasets. With this in mind, we propose the use of unsupervised anomaly detection methods for screening that can take advantage of the large amount of healthy cases available. Concretely, we focus on reconstruction-based anomaly detection methods, which are usually approached with autoencoders. We propose a new network architecture, the Blind-Spot Network, that, according to the presented experiments, improves the performance of autoencoders in this setting.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-71.pdf
2019,Short-term trajectory planning using reinforcement learning within a neuromorphic control architecture,"Florian Mirus, Benjamin Zorn, Jörg Conradt","In this paper, we present a first step towards neuromorphic vehicle control. We propose a modular and hierarchical system architecture entirely implemented in a spiking neuron substrate, which allows for adjustment of individual components trough either supervised or reinforcement learning as well as future deployment on dedicated neuromorphic hardware. In a sample instantiation, we investigate automated training of a neuromorphic trajectory selection module using reinforcement learning to demonstrate the general feasibility of our approach. We evaluate our system using the open-source race car simulator TORCS.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-65.pdf
2019,visualizing image classification in fourier domain,"Florian Franzen, Chunrong Yuan","Image classification is successfully done with Convolutional Neural Networks (CNN). Alternatively  it can be done  in Fourier domain avoiding the convolution process. In this work, we develop several neural networks (NN) for classifying images  in Fourier domain. In order to understand and explain the behaviour of the built NNs, we visualize neuron activities and analyze the underlying patterns relevant for the learning and classification process.  We have carried out comparative study based on several datasets. By using images of objects with partial occlusion, we are able to find out the parts that are important for the classification of certain objects.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-66.pdf
2019,Deep hybrid approach for 3D plane segmentation,"Felipe Gomez Marulanda, Pieter Libin, Timothy Verstraeten, Ann Nowe","We address the limitations of Deep learning models for 3D geometry segmentation by using Conditional Random fields (CRF). We show that CRFs can take advantage of the       neighbouring structure of point clouds to assist the learning of the Deep Learning models (DL). Our hybrid  PN-CRF model is able to learn more optimal weights by taking    advantage of equal-segmentation assignments to neighbouring points. As a result, it increases the robustness in the model specially for segmentation tasks where correctly  detecting the boundaries between segmentations is very important.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-169.pdf
2019,Noise helps optimization escape from saddle points in the neural dynamics,"Fang Ying, Yu Zhaofei, Chen Feng","Synaptic connectivity in the brain is thought to encode the long-term memory of an organism. But experimental data point to surprising ongoing fluctuations in synaptic activity. Assuming that the brain computation and plasticity can be understood as probabilistic inference, one of the essential roles of noise is to efficiently improve the performance of optimization in the form of stochastic gradient descent. The strict saddle condition for synaptic plasticity is deduced and under such condition noise can help escape from saddle points on high dimensional domains. The theoretical result explains the stochasticity of synapses and guides us how to make use of noise. Our simulation results manifest that in the learning and test phase, the accuracy of synaptic sampling is almost 20% higher than that without noise.",Statistical physics of learning and inference,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-92.pdf
2019,On-line learning dynamics of ReLU neural networks using statistical physics techniques,"Michiel Straat, Michael Biehl","We introduce exact macroscopic on-line learning dynamics of two-layer neural networks with ReLU units in the form of a system of differential equations, using techniques borrowed from statistical physics. For the first experiments, numerical solutions  reveal similar behavior compared to sigmoidal activation researched in earlier work. In these experiments the theoretical results show good correspondence with simulations. In overrealizable and unrealizable learning scenarios, the learning behavior of ReLU networks shows distinctive characteristics compared to sigmoidal networks.",Statistical physics of learning and inference,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-173.pdf
2019,Memory Efficient Weightless Neural Network using Bloom Filter,"Leandro Santiago de Araújo, Letícia  Dias Verona, Fábio Medeiros Rangel, Fabricio  Firmino de Faria, Daniel Sadoc Menasche, Wouter  Caarls, Maurício Breternitz, Sandip Kundu, Priscila Machado Vieira Lima, Felipe  Maia Galvão França","Weightless Neural Networks are Artificial Neural Networks based on RAM memory broadly explored as solution for pattern recognition applications. Due to its memory approach, it can be easily implemented in hardware and software providing efficient learning mechanism. Unfortunately, the straightforward implementation requires a large amount of memory resources making its adoption impracticable on memory constraint systems. In this paper, we propose a new model of Weightless Neural Network which utilizes Bloom Filters to implement RAM nodes. By using Bloom Filters, the memory resources are widely reduced allowing false positives entries. The experiment results show that our model using Bloom Filters achieves competitive accuracy, training time and testing time, consuming up to 6 order of magnitude less memory resources in comparison with the standard Weightless Neural Network model.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-83.pdf
2019,Statistical physics of learning and inference,"Michael Biehl, Nestor Caticha, Manfred Opper, Thomas Villmann",,Statistical physics of learning and inference,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-2.pdf
2019,Explaining classification systems using sparse dictionaries,"Andrea Apicella, Fracesco Isgro, Roberto Prevete, Andrea Sorrentino, Guglielmo Tamburrini","A pressing research topic is to find ways to explain the decisions of machine learning systems to end users, data officers, and other stakeholders. These explanations must be understandable to  human beings. Much work in this field focuses on image classification, as the required explanations can rely on images, therefore making communication relatively easy, and may take into account the image as a whole. Here, we propose to exploit the representational power of sparse dictionaries to determine image local properties that can be used as crucial ingredients of humanly understandable explanations of classification decisions.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-124.pdf
2019,Deep RL for autonomous robots: limitations and safety challenges,"Olov Andersson, Patrick Doherty","With the rise of deep reinforcement learning, there has also been a string of successes on continuous control problems using physics simulators. This has lead to some optimism regarding use in autonomous robots and vehicles. However, to successful apply such techniques to the real world requires a firm grasp of their limitations. As recent work has raised questions of how diverse these simulation benchmarks really are, we here instead analyze a popular deep RL approach on toy examples from robot obstacle avoidance. We find that these converge very slowly, if at all, to safe policies. We identify convergence issues on stochastic environments and local minima as problems that warrant more attention for safety-critical control applications.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-97.pdf
2019,Detecting Black-box Adversarial Examples through Nonlinear Dimensionality Reduction,"Francesco Crecchi, Davide Bacciu, Battista Biggio","Deep neural networks are vulnerable to adversarial examples,i.e., carefully-perturbed input samples aimed to mislead classification.  In this work,  we propose a detection method based on t-SNE,  a  powerful nonlinear dimensionality reduction technique. Our empirical findings show that the proposed approach is able to effectively detect black-box adversarial examples, i.e., adversarial perturbations not carefully tuned to also bypass the detection method.  While we believe that our method may also improve the robustness of deep nets against white-box adversarial examples, we leave a more detailed investigation of this issue to future work.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-120.pdf
2019,Dynamic fairness - Breaking vicious cycles in automatic decision making,"Benjamin Paaßen, Astrid Bunge, Carolin Hainke, Leon Sindelar, Matthias Vogelsang","In recent years, machine learning techniques have been increasingly applied in sensitive decision making processes, raising fairness concerns. Past research has shown that machine learning may reproduce and even exacerbate human bias due to biased training data or flawed model assumptions, and thus may lead to discriminatory actions. To counteract such biased models, researchers have proposed multiple mathematical definitions of fairness according to which classifiers can be optimized. However, it has also been shown that the outcomes generated by some fairness notions may be unsatisfactory.  In this contribution, we add to this research by considering decision making processes in time. We establish a theoretic model in which even perfectly accurate classifiers which adhere to almost all common fairness definitions lead to stable long-term inequalities due to vicious cycles. Only demographic parity, which enforces equal rates of positive decisions in all groups, avoids these effects and establishes instead a virtuous cycle leading to perfectly accurate and fair classification in the long term.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-134.pdf
2019,Fairness and Accountability of Machine Learning Models in Railway Market: are Applicable Railway Laws Up to Regulate Them?,"Charlotte Ducuing, Luca Oneto, Canepa Renzo","In this work we discuss whether the law is up to regulate the use of machine learning model in the context of the railway public transportation system. In particular, we deal with the problems of fairness and accountability of these models when exploited in the context of train traffic management. Railway sector-specific regulation, in their quality as network industry, hereby serves as a pilot. We show that, even where technological solutions are available, the law needs to keep up to support and accurately regulate the use of the technological solutions and we identify stumble points in this regard.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-78.pdf
2019,Privacy Preserving Synthetic Health Data,"Andrew Yale, Saloni Dash, Ritik Dutta, Isabelle Guyon, Adrien Pavao, Kristin Bennett","We examine the feasibility of using synthetic medical data generated by GANs in the classroom, to teach data science in health infor- matics. We present an end-to-end methodology to retain instructional utility, while preserving privacy to a level, which meets regulatory re- quirements: (1) a GAN is trained by a certified medical-data security-aware agent, inside a secure environment; (2) the GAN is used outside of the secure environment by external users (instructors or researchers) to gener- ate synthetic data. This second step facilitates data handling for external users, by avoiding de-identification, which may require special user training, be costly, and/or cause loss of data fidelity. We benchmark our proposed GAN versus various baseline methods using a novel set of metrics. At equal levels of privacy and utility, GANs provide small footprint models, meeting the desired specifications of our application domain. Data, code, and a challenge that we organized for educational purposes are available.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-29.pdf
2019,training networks separately on static and dynamic obstacles improves collision avoidance during indoor robot navigation,"Viktor Schmuck, David Meredith","Autonomous robot navigation and dynamic obstacle avoidance in complex, cluttered, indoor environments is a challenging task. A robust solution would allow robots to be deployed in hospitals, airports or shopping centres to serve as guides and fulfil other functions requiring safe human--robot interaction. Previous studies have explored various approaches to selecting sensor types, collecting data, and training models capable of safely avoiding unmapped, possibly dynamic obstacles in an indoor environment. In this paper we address the problem of recognizing and anticipating  collisions, in order to determine when avoidance manoeuvres are required. We propose and compare two sensor-fusion and neural-network-based solutions, one in which models are trained separately on static and dynamic samples and another in which a model is trained on samples of collisions with both dynamic and static obstacles. The measured accuracies confirmed that the separately trained, ensemble models had better recognition performance, but were slower at calculation than the models trained without taking the obstacle types into account.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-129.pdf
2019,Importance of user inputs while using incremental learning to personalize human activity recognition models,"Pekka Siirtola, Heli Koskimäki, Juha Röning","In this study, importance of user inputs is studied in the context of personalizing human activity recognition models using incremental learning. Inertial sensor data from three body positions are used, and the classification is based on Learn++ ensemble method. Three different approaches to update models are compared: non-supervised, semi-supervised and supervised. Non-supervised approach relies fully on predicted labels, supervised fully on user labeled data, and the proposed method for semi-supervised learning, is a combination of these two. In fact, our experiments show that by relying on predicted labels with high confidence, and asking the user to label only uncertain observations (from 12% to 26% of the observations depending on the used base classifier), almost as low error rates can be achieved as by using supervised approach. In fact, the difference was less than 2%-units. Moreover, unlike non-supervised approach, semi-supervised approach does not suffer from drastic concept drift, and thus, the error rate of the non-supervised approach is over 5%-units higher than using semi-supervised approach.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-63.pdf
2019,Beta Distribution Drift Detection for Adaptive Classifiers,"Lukas Fleckenstein, Sebastian Kauschke, Johannes Fürnkranz","With today's abundant streams of data, the only constant we can rely on is change. For stream classification algorithms, it is necessary to adapt to concept drift. This can be achieved by monitoring the model error, and triggering counter measures as changes occur. In this paper, we propose a drift detection mechanism that fits a beta distribution to the model error, and treats abnormal behavior as drift. It works with any given model, leverages prior knowledge about this model, and allows to set application-specific confidence thresholds. Experiments confirm that it performs well, in particular when drift occurs abruptly.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-59.pdf
2019,Human feedback in continuous actor-critic reinforcement learning,"Cristian Millán, Bruno Fernandes, Francisco Cruz","Reinforcement learning methods are used when an agent tries to learn from a changing environment. With continuous actions, the performance is significantly better, but the learning requires excessive time to find the proper policy. In this work, we focused on including human feedback in reinforcement learning continuous action space. We joint the policy with the feedback to favor actions in regions of low density. We compare the performance of the feedback over continuous actor-critic algorithm and evaluate it in the cart-pole balancing task. The obtained results show that our approach increases the accumulated reward and improves performance during the task.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-149.pdf
2019,"Trust, law and ideology in a NN agent model of the US Appellate Courts","Nestor Caticha, Felippe Alves","Interacting NN are used to model US Appellate Court three judge panels.   Agents, whose initial states have three contributions derived from  common knowledge of the law, political affiliation and  personality,  learn by exchange of opinions,  updating their state and trust about other agents. The model replicates data patterns  only if initially the agents  trust each other and are certain about their trust independently of party affiliation, showing evidence of ideological voting, dampening  and amplification. Absence of law or party contribution destroys the theoretical-empirical  agreement. We identify quantitative signatures for different levels of  the law, ideological or idiosyncratic contributions.",Statistical physics of learning and inference,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-72.pdf
2019,time series modelling of market price in real-time bidding,"Manxing Du, Christian Hammerschmidt, Georgios Varisteas, Radu State, Mats Brorsson, Zhu Zhang","Real-Time-Bidding (RTB) is one of the most popular online advertisement selling mechanisms. Modeling the highly dynamic bidding environment is crucial for making good bids.  Market prices of auctions fluctuate heavily within short time spans. State-of-the-art methods neglect the temporal dependencies of bidders' behaviors. In this paper, the bid requests are aggregated by time and the mean market price per aggregated segment is modeled as a time series. We show that the Long Short Term Memory (LSTM) neural network outperforms the state-of-the-art univariate time series models by capturing the nonlinear temporal dependencies in the market price.   We further improve the predicting performance by adding a summary of exogenous features from bid requests.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-99.pdf
2019,Chasing the Echo State Property,Claudio Gallicchio,"Reservoir Computing (RC) provides an efficient way for designing dynamical recurrent neural models. While training is restricted to a simple output component, the recurrent connections are left untrained after initialization, subject to stability constraints specified by the Echo State Property (ESP). Literature conditions for the ESP typically fail to properly account for the effects of driving input signals, often limiting the potentialities of the RC approach. In this paper, we study the fundamental aspect of asymptotic stability of RC models in presence of driving input, introducing an empirical ESP index that enables to easily analyze the stability regimes of reservoirs. Results on two benchmark datasets reveal interesting insights on the dynamical properties of input-driven reservoirs, suggesting that the actual domain of ESP validity is much wider than what covered by literature conditions commonly used in RC practice.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-76.pdf
2019,Comparison between DeepESNs and gated RNNs on multivariate time-series prediction,"Claudio Gallicchio, Alessio Micheli, Luca Pedrelli","We propose an experimental comparison between Deep Echo State Networks (DeepESNs) and gated Recurrent Neural Networks (RNNs) on multivariate time-series prediction tasks. In particular, we compare reservoir and fully-trained RNNs able to represent signals featured by multiple time-scales dynamics. The analysis is performed in terms of efficiency and prediction accuracy on 4 polyphonic music tasks. Our results show that DeepESN is able to outperform ESN in terms of prediction accuracy and efficiency. Whereas, between fully-trained approaches, Gated Recurrent Units (GRU) outperforms Long Short-Term Memory (LSTM) and simple RNN models in most cases. Overall, DeepESN turned out to be extremely more efficient than others RNN approaches and the best solution in terms of prediction accuracy on 3 out of 4 tasks.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-184.pdf
2019,Autoregressive Convolutional Recurrent Neural Network for Univariate and Multivariate Time Series Prediction,"Matteo  Maggiolo , Gerasimos Spanakis","Time Series forecasting (univariate and multivariate) is a problem of high complexity due the different patterns that have to be detected in the input, ranging from high to low frequencies ones. In this paper we propose a new model for timeseries prediction that utilizes convolutional layers for feature extraction, a recurrent encoder and a linear autoregressive component. We motivate the model and we test and compare it against a baseline of widely used existing architectures for univariate and multivariate timeseries. The proposed model appears to outperform the baselines in almost every case of the multivariate timeseries datasets, in some cases even with 50% improvement which shows the strengths of such a hybrid architecture in complex timeseries.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-159.pdf
2019,Using Deep Learning and Evolutionary Algorithms for Time Series Forecasting,"Rafael Thomazi Gonzalez, Dante Augusto Couto Barone","Deep Learning is one of the latest approaches in the field of artificial neural networks. Since they were first proposed, Deep Learning models have obtained state-of-art results in some problems related to classification and pattern recognition. However, such models have been little used in time series forecasting. This work aims to investigate the use of some of these architectures in this kind of problem. Another contribution is the use of one Evolutionary Algorithm to optimize the hyperparameters of these models. The advantage of the proposed method is shown on two artificial time series datasets and one electricity load demand dataset.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-15.pdf
2019,Conditional BRUNO: a neural process for exchangeable labelled data,"Iryna Korshunova, Yarin Gal, Arthur Gretton, Joni Dambre","We present a neural process that models exchangeable sequences of high dimensional complex observations conditionally on a set of labels or tags. Our model combines the expressiveness of deep neural networks with the data-efficiency of Gaussian processes, resulting in a probabilistic model for which the posterior distribution is easy to evaluate and sample from, and the computational complexity scales linearly with the number of observations. The advantages of the proposed architecture are demonstrated on a challenging few-shot view reconstruction task which requires generalisation from short sequences of viewpoints.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-35.pdf
2019,Adversarial robustness of linear models: regularization and dimensionality,"Istvan Megyeri, Istvan Hegedus, Mark Jelasity","Many machine learning models are sensitive to adversarial input, meaning that very small but carefully designed noise added to correctly classified examples may lead to misclassification. The reasons for this are still poorly understood, even in the simple case of linear models. Here, we study linear models and offer a number of novel insights. We focus on the effect of regularization and dimensionality. We show that in very high dimensions adversarial robustness is inherently very low due to some mathematical properties of high-dimensional spaces that have received little attention so far. We also demonstrate that---although regularization may help---adversarial robustness is harder to achieve than high accuracy during the learning process. This is typically overlooked when researchers set optimization meta-parameters.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-114.pdf
2019,interpretable dynamics models for data-efficient reinforcement learning,"Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek","In this paper, we present a Bayesian view on model-based reinforcement learning. We use expert knowledge to impose structure on the transition model and present an efficient learning scheme based on variational inference. This scheme is applied to a heteroskedastic and bimodal benchmark problem on which we compare our results to NFQ and show how our approach yields human-interpretable insight about the underlying dynamics while also increasing data-efficiency.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-98.pdf
2019,Beyond Pham's algorithm for joint diagonalization,"Pierre Ablin, Jean-François Cardoso, Alexandre Gramfort","The approximate joint diagonalization of a set of matrices consists in finding a basis in which these matrices are as diagonal as possible. This problem naturally appears in several statistical learning tasks such as blind signal separation. We consider the diagonalization criterion studied in a seminal paper by Pham (2001), and propose a new quasi-Newton method for its optimization. Through numerical experiments on simulated and real datasets, we show that the proposed method outperforms Pham’s algorithm. An open source Python package is released.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-119.pdf
2019,Frequency Domain Transformer Networks for Video Prediction,"Hafez Farazi, Sven Behnke","The task of video prediction is forecasting the next frames given some previous frames. Despite much recent progress, this task is still challenging mainly due to high nonlinearity in the spatial domain. To address this issue, we propose a novel architecture, Frequency Domain Transformer Network (FDTN), which is an end-to-end learnable model that formulates the transformations of the signal in the frequency domain.  Experimental evaluations show that this approach can outperform some widely used video prediction methods like Video Ladder Network (VLN) and Predictive Gated Pyramids (PGP).",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-50.pdf
2019,lightweight autonomous bayesian optimization of Echo-State Networks,"Cerina Luca, Giuseppe Franco, Marco Domenico Santambrogio","Echo State Networks (ESN) represent a good option to tackle non-linear, time-dependent problems without the training complexity of standard Recurrent Neural Networks (RNNs), thanks to intrinsic dynamics that arise from untrained sparse networks. However, performance and stability of ESN are determined by their hyper-parameters, e.g. Reservoir dimension and sparsity, and the characteristics of the input, whose optimal values required time consuming procedures to be found. Here we propose an efficient automatic optimization framework for ESN based on the Bayesian Optimization given user-defined objectives, and bounded ranges on hyper-parameters. Results shown performance comparable withexhaustive grid-search optimization algorithms.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-103.pdf
2020,Model Variance for Extreme Learning Machine,"Fabian Guignard, Mohamed Laib, Mikhail Kanevski",We derived theoretical formulas for the variance of extreme learning machine ensemble in a general case of a heteroskedastic noise. They provide a decomposition of the variance which helps in the  understanding of how the different sources of randomness contribute. The application of the proposed method to simulated datasets shows the effectiveness of the newly-introduced estimations in replicating the expected variance behaviours.,Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-15.pdf
2020,Problem Transformation Methods with Distance-Based Learning for Multi-Target Regression,"Joonas Hämäläinen, Tommi Kärkkäinen","Multi-target regression is a special subset of supervised machine learning problems. Problem transformation methods are used in the field to improve the performance of basic methods. The purpose of this article is to test the use of recently popularized distance-based methods, the minimal learning machine (MLM) and the extreme minimal learning machine (EMLM), in problem transformation. The main advantage of the full data variants of these methods is the lack of any meta-parameter. The experimental results for the MLM and EMLM show promising potential, emphasizing the utility of the problem transformation especially with the EMLM.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-181.pdf
2020,Gaussian process regression for the estimation of stable univariate time-series processes,"Georgios Birpoutsoukis, Julien M. Hendrickx","In this paper, estimation of AutoRegressive (AR) and AutoRegressive Moving Average (ARMA) models is proposed in a Bayesian framework using  a Gaussian Process Regression (GPR) approach. Impulse response properties of the underlying process to be modeled are exploited during the parameter estimation. As such, models of enhanced predictability can be consistently obtained, even in the case of large model orders. It is also proved that the proposed approach is strongly linked with the Prediction Error (PE) model estimation approaches, if the estimated parameters are regularized. Simulations are provided to illustrate the efficiency of the proposed approach.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-111.pdf
2020,Locally Adaptive Nearest Neighbors,"Jan Philip Göpfert, Heiko Wersing, Barbara Hammer","When training automated systems, it has been shown to be beneficial to adapt the representation of data by learning a problem-specific metric. This metric is global. We extend this idea and, for the widely used family of k nearest neighbors algorithms, develop a method that allows learning locally adaptive metrics. To demonstrate important aspects of how our approach works, we conduct a number of experiments on synthetic data sets, and we show its usefulness on real-world benchmark data sets.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-89.pdf
2020,SDOstream: Low-Density Models for Streaming Outlier Detection,"Alexander Hartl, Félix Iglesias, Tanja Zseby","Data commonly changes over time. Algorithms for anomaly detection must therefore be adapted to overcome the challenges of evolving data. We present SDOstream, a distance-based outlier detection algorithm for stream data that uses low-density models, therefore operating in linear time and avoiding the limitations of sliding windows and instance-based methods. SDOstream is designed to ensure a good integration in applications, hence the definition of ""outlier"" is not predetermined, but can be decided by the application based on distances to representative point locations. We describe the algorithm and evaluate algorithm performance with several datasets.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-143.pdf
2020,Binary and Multi-label Defect Classification of Printed Circuit Board based on Transfer Learning,"George Azevedo, Leandro Silva, Agostinho Junior, Bruno Fernandes, Sérgio Oliveira","Automatic optical inspection for printed circuit board (PCB)is an important step to assure quality control in electronic manufacturing. Recently deep learning models have been used to detect and classify PCB defects. Since public PCB datasets usually are not large enough to train deep models from scratch, transfer learning has proved to bean effective strategy to overcome this limitation. In this paper we evaluate the influence of input image size for non-referential binary classification of PCB images from the DeepPCB dataset and moving further we evaluated a multi-label classification, both based on transfer learning. The best models achieved 99.5% accuracy for binary classification and mean accuracy of 95.16% for multi-label classification.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-194.pdf
2020,Detection of elementary particles with the WiSARD n-tuple classifier,"Pedro Xavier, Massimo De Gregorio, Felipe França, Priscila Lima","This work presents a weightless neural network model that learns multiple elementary particle collision phenomena. Having the AT- LAS Higgs Boson Machine Learning Challenge as the target dataset, a couple of abstractions were developed in order to achieve a fast and sim- ple algorithm that would otherwise require much more sophisticated tools. Experimental results over the Higgs Boson t - t decay and the B + meson decay shows that the WiSARD n-tuple classifier provide a generic and lightweight method for studying a broad range of particle decay modes.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-170.pdf
2020,Automatic Pain Intensity Recognition: Training Set Selection based on Outliers and Centroids,"Peter Bellmann, Patrick Thiam, Friedhelm Schwenker","In this study, we evaluate a person independent pain intensity recognition task, based on the BioVid Heat Pain Database. Previous works show that for such classification tasks, the overall performance can be increased by reducing the training data, based on certain criteria, such as different distance measures. This results in considering only a certain amount of participants from the training set, whose data distributions are defined to be the most similar to the data distribution of the participant from the test set. Counterintuitively, we propose to remove participants, which are identified as central points, from the training set, completely independent from the test set. Our evaluations show that this approach can lead to significant improvement of classification accuracy.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-171.pdf
2020,Multi-Directional Laplacian Pyramids for Completion of Missing Data Entries,Neta Rabin,"A common pre-processing task in machine learning is handling missing data entries, also known as imputation. Standard techniques use mean values, regression or optimization based techniques for predicting the missing data values. In this paper, a kernel based technique is utilized for imputing data in a multi-scale manner. The construction is based on Laplacian pyramids, which operate on the row and column spaces of the data in several scales. Experimental results demonstrate the approach on publicly available datasets, and highlight its simple computational construction and convergence stability.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-72.pdf
2020,Navigational Freespace Detection for Autonomous Driving in Fixed Routes,"aparajit narayan, elio tuci, william sachiti, aaron parsons","Vision-based modules are largely exploited by autonomous driving vehicles to identify the road area and to avoid collisions with other vehicles, pedestrians, etc. This paper illustrates the results of a comparative study in which eight different vision-based modules are evaluated for detecting free navigational space in urban environments. All modules are implemented using Convolutions Neural Networks. The distinctive and innovative feature of these modules is the way in which the navigational feespace is identified in the camera image. The modules generate the co-ordinates of a triangle, whose area represents the navigation freespace. The relative position of the triangle top corner with respect to the image centre points toward the vehicle direction of motion. Thus, when trained on a fixed route, these modules are able to successfully detect the road freepsace and to make appropriate decisions concerning where to go at roundabouts, intersections etc., in order to reach the final destination.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-61.pdf
2020,Adapting Random Forests to Cope with Heavily Censored Datasets in Survival Analysis,"Tossapol Pomsuwan, Alex Freitas","We address a survival analysis task where the goal is to predict the time passed until a subject is diagnosed with an age-related disease. The main challenge is that subjects’ data are very often censored, i.e., their time to diagnosis is only partly known. We propose a new Random Forest variant to cope with censored data, and evaluate it in experiments predicting the time to diagnosis of 8 age-related diseases, for data from the English Longitudinal Study of Ageing (ELSA) database. In these experiments, the proposed Random Forest variant, in general, outperformed a well-known Random Forest variant for censored data.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-117.pdf
2020,Equilibrium Propagation for Complete Directed Neural Networks,"Matilde Tristany Farinha, Sérgio Pequito, Pedro A. Santos, Mário Figueiredo","Artificial neural networks, one of the most successful approaches to supervised learning, were originally inspired by their biological counterparts. However, the most successful learning algorithm for artificial neural networks, backpropagation, is considered biologically implausible. We contribute to the topic of biologically plausible neuronal learning by building upon and extending the equilibrium propagation learning framework. Specifically, we introduce: a new neuronal dynamics and learning rule for arbitrary network architectures; a sparsity-inducing method able to prune irrelevant connections; a dynamical-systems characterization of the models, using Lyapunov theory.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-106.pdf
2020,Machine learning in the biopharma industry,"Gael de Lannoy, Thibault Helleputte, Paul Smyth","Modern high-throughput technologies deployed in R\&D for new health products have opened the door to Machine Learning applications that allow the automation of tasks and support for data-driven risk-based decision making. Appealing opportunities of applying Machine Learning appear for the development of modern complex drugs, for biomanufacturing production lines optimization, or even for elaborating product portfolio strategies. Nevertheless, many practical challenges make it difficult to apply Machine Learning models in the biopharmaceutical field. Innovative approaches must thus be considered in many of these practical cases. This tutorial paper is an attempt to describe the landscape of Machine Learning application to the biopharmaceutical industry along three dimensions: opportunities, specificities or constraints and methods.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-5.pdf
2020,Deep Learning to Detect Bacterial Colonies for the Production of Vaccines,"Paul Smyth, Lee John, Gael de Lannoy, Thomas Beznik","During the development of vaccines, bacterial colony forming units (CFUs) are counted in order to quantify the yield in the fermen- tation process. This is often a manual task that is time-consuming and error-prone. In this work we test multiple segmentation algorithms based on the U-Net CNN architecture and show that these offer robust, auto- mated CFU counting. We show that the multiclass generalisation with a bespoke loss function allows distinguishing virulent and avirulent colonies with acceptable accuracy. While many possibilities are left to explore, our results demonstrate the potential of deep learning for separating and classifying bacterial colonies.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-122.pdf
2020,Pyramidal Graph Echo State Networks,"Filippo Maria Bianchi, Claudio Gallicchio, Alessio Micheli","We analyze graph neural network models that combine iterative message-passing implemented by function with untrained weights and graph pooling operations. In particular, we alternate randomized neural message passing with graph coarsening operations, which provide multiple views of the underlying graph. Each view, is concatenated to build a graph embedding for graph-level classication. The main advantage of the proposed architecture is its speed, further improved by the pooling, in computing graph-level representations. Results obtained on popular graph classication benchmark, comparing dierent topological pooling techniques, support our claim.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-54.pdf
2020,A Systematic Assessment of Deep Learning Models for Molecule Generation,"Davide Rigoni, Nicolò Navarin, Alessandro Sperduti","In recent years the scientific community has devoted much effort in the development of deep learning models for the generation of new molecules with desirable properties (i.e. drugs). This has produced many proposals in literature. However, a systematic comparison among the different VAE methods is still missing. For this reason, we propose an extensive testbed for the evaluation of generative models for drug discovery, and we present the results obtained by many of the models proposed in literature.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-141.pdf
2020,Reservoir memory machines,"Benjamin Paassen, Alexander Schulz","In recent years, Neural Turing Machines have gathered attention by joining the flexibility of neural networks with the computational capabilities of Turing machines. However, Neural Turing Machines are notoriously hard to train, which limits their applicability. We propose reservoir memory machines, which are still able to solve some of the benchmark tests for Neural Turing Machines, but are much faster to train, requiring only an alignment algorithm and linear regression. Our model can also be seen as an extension of echo state networks with an external memory, enabling arbitrarily long storage without interference.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-82.pdf
2020,Frontiers in Reservoir Computing,"Claudio Gallicchio, Mantas Lukoševičius, Simone Scardapane","Reservoir computing (RC) studies the properties of large recurrent networks of artificial neurons, with either fixed or random connectivity. Over the last years, reservoirs have become a key tool for pattern recognition and neuroscience problems, being able to develop a rich representation of the temporal information even if left untrained. The common paradigm has been instantiated into several models, among which the Echo State Network and the Liquid State Machine represent the most widely known ones. Nowadays, RC represents the de facto state-of-the-art approach for efficient learning in the temporal domain. Besides, theoretical studies in RC area can contribute to the broader field of Recurrent Neural Networks research by enabling a deeper understanding of the fundamental capabilities of dynamical recurrent models, even in the absence of training of the recurrent connections. RC paradigm also allows using different dynamical systems, including hardware, for computation. This paper is intended to give an overview on the RC research field, highlighting major frontiers in its development and finally introducing the contributed papers to the ESANN 2020 special session.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-7.pdf
2020,An agile machine learning project in pharma - developing a Mask R-CNN-based web application for bacterial colony counting,"Paul Smyth, Tanguy  Naets, Gael de Lannoy, Laurent Sorber","We present a web application to assist lab technicians with the counting of different types of bacteria colonies. We use a Mask R-CNN model trained and tuned specifically to detect the number of BVG- and BVG+ colonies. We achieve a mAPI oU =.5 of 94 %. With these encouraging results, we see opportunities to bring the benefits of improved accuracy and time saved to nearby problems and labs such as generalising to other bacteria types and viral foci counting.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-178.pdf
2020,Theoretically Expressive and Edge-aware Graph Learning,"Federico Errica, Davide Bacciu, Alessio Micheli","We propose a new Graph Neural Network that combines recent advancements in the field. We give theoretical contributions by proving that the model is strictly more general than the Graph Isomorphism Network and the Gated Graph Neural Network, as it can approximate the same functions and deal with arbitrary edge values. Then, we show how a single node information can flow through the graph unchanged.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-132.pdf
2020,Unsupervised Latent Space Translation Network,"Magda Friedjungová, Daniel Vašata, Tomáš Chobola, Marcel Jiřina","One task that is often discussed in a computer vision is the mapping of an image from one domain to a corresponding image in another domain known as image-to-image translation. Currently there are several approaches solving this task. In this paper, we present an enhancement of the UNIT framework that aids in removing its main drawbacks. More specifically, we introduce an additional adversarial discriminator on the latent representation used instead of VAE, which enforces the latent space distributions of both domains to be similar. On MNIST and USPS domain adaptation tasks, this approach greatly outperforms competing approaches.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-64.pdf
2020,GraN: An Efficient Gradient-Norm Based Detector for Adversarial and Misclassified Examples,"Julia Lust, Alexandru Paul Condurache","Deep neural networks (DNNs) are vulnerable to adversarial examples and other data perturbations. Especially in safety critical applications of DNNs, it is therefore crucial to detect misclassified samples. The current state-of-the-art detection methods require either significantly more runtime or more parameters than the original network itself. This paper therefore proposes GraN, a time- and parameter-efficient method that is easily adaptable to any DNN.  GraN is based on the layer-wise norm of the DNN's gradient regarding the loss of the current input-output combination, which can be computed via backpropagation. GraN achieves state-of-the-art performance on numerous problem set-ups.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-159.pdf
2020,Attacking Model Sets with Adversarial Examples,"István Megyeri, István Hegedűs, Mark Jelasity","Adversarial input perturbation is a well-studied problem in machine learning. Here, we introduce a generalized variant of this problem, where we look for adversarial examples that satisfy multiple constraints simultaneously over a set of multi-class models. For example, we might want to force an entire set of models to make the same mistake over the same example, in order to create transferable attacks. Or we might want to fool just a single model, without fooling the rest of the models, in order to target only a specific manufacturer. Known attacks are not directly suitable for addressing this problem. The generated example has to satisfy multiple constraints and no feasible solution may exist for any amount of perturbation. We introduce an iterative heuristic algorithm inspired by the DeepFool attack. We evaluate our method over the MNIST and CIFAR-10 data sets. We show that it can find feasible multi-model adversarial perturbations, and that the magnitude of these perturbations is similar to the single model case.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-175.pdf
2020,MultiMBNN: Matched and Balanced Causal Inference with Neural Networks,"Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee, Lovekesh Vig, Gautam Shroff","Causal inference (CI) in observational data is extremely relevant in healthcare, education, ad attribution, etc. Confounding is a typical hazard, where the context affects both, the treatment assignment and response. In a multiple treatment scenario, we propose the neural network based MultiMBNN, where we overcome confounding by employing generalized propensity score based matching, and learning balanced representations. We benchmark the performance on synthetic and real-world datasets using PEHE, and mean absolute percentage error over ATE as metrics. MultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and Perfect Match (PM).","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-109.pdf
2020,Efficient computation of counterfactual explanations of LVQ models,"André Artelt, Barbara Hammer","The increasing use of machine learning in practice and  legal regulations like EU's GDPR cause the necessity to be able to explain the prediction and behavior of machine learning models. A prominent example of particularly intuitive explanations of AI models in the context of decision making are counterfactual explanations. Yet,  it is still an open research problem how to efficiently compute counterfactual explanations for many models. We investigate how to efficiently compute counterfactual explanations for an important class of models, prototype-based classifiers such as learning vector quantization models. In particular, we derive specific convex and non-convex programs depending on the used metric.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-55.pdf
2020,Motion Segmentation using Frequency Domain Transformer Networks,"Hafez Farazi, Sven Behnke","Self-supervised prediction is a powerful mechanism to learn representations that capture the underlying structure of the data. Despite recent progress, the self-supervised video prediction task is still challenging. One of the critical factors that make the task hard is motion segmentation, which is segmenting individual objects and the background and estimating their motion separately. In video prediction, the shape and transformation of each object should be understood only by predicting the next frame in pixel space. To address this issue, we propose a novel end-to-end learnable architecture that predicts the next frame by modeling foreground and background separately while simultaneously estimating and predicting the foreground motion using Frequency Domain Transformer Networks. Experimental evaluations show that this yields interpretable representations and that our approach can outperform some widely used video prediction methods like Video Ladder Network (VLN) and Predictive Gated Pyramids (PGP) on synthetic datasets.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-24.pdf
2020,A Real-time PCB Defect Detector Based on Supervised and Semi-supervised Learning,"FAN HE, Sanli Tang,  Siamak  Mehrkanoon, Xiaolin Huang, Jie Yang","This paper designs a deep model to detect PCB defects from an input pair of a detect-free template and a defective tested image. A novel group pyramid pooling module is proposed to efficiently extract features in various resolutions to predict defects in different scales. To train the deep model, a dataset including 6 common types of PCB defects is established, namely DeepPCB, which contains 1,500 image pairs with annotations.Besides, a semi-supervised learning manner is examined to effectively utilize the unlabelled images for training the PCB defect detector. Experiment results validate the effectiveness and efficiency of the proposed model by achieving 98.6% mAP @ 62 FPS on DeepPCB dataset. DeepPCB is now available at: https://github.com/tangsanli5201/DeepPCB.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-33.pdf
2020,Similarities between policy gradient methods in reinforcement and supervised learning,"Eric Benhamou, David Saltiel","Reinforcement learning (RL) is about sequential decision making and is traditionally opposed to supervised learning (SL) and unsupervised learning (USL). In RL, given the current state, the agent makes a decision that may influence the next state as opposed to SL where the next state remains the same, regardless of decisions taken. Although this difference is fundamental, SL and RL are not so different. In particular, we emphasize in this paper that gradient policy methods can be cast as a supervised learning problem where true label are replaced with discounted rewards. We provide a simple experiment where we interchange label and pseudo rewards to show that SL techniques can be directly translated into RL methods.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-34.pdf
2020,On Learning a Control System without Continuous Feedback,"Georgi Angelov, Bogdan Georgiev","We discuss a class of control problems by means of deep neural networks (DNN). Our goal is to develop DNN models that, once trained, are able to produce solutions of such problems at an acceptable error-rate and much faster computation time than an ordinary numerical solver. In the present note we study two such models for the Brockett integrator control problem.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-92.pdf
2020,Resume: A Robust Framework for Professional Profile Learning & Evaluation,"Clara Gainon de Forsan de Gabriac, Constance Scherer, Amina Djelloul, Vincent Guigue, Patrick Gallinari","Professional Profile Extraction is a crucial challenge for any HR department.  In this paper, we propose an approach to learn and evaluate professional embeddings. We first highlight the technical issues associated with this specific data; then, we propose an architecture that compares different language models to encode the textual information; finally, we learn user profiles and propose three original evaluation tasks to illustrate the strengths and weaknesses of our approach.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-158.pdf
2020,Lower bounds on the nonnegative rank using a nested polytopes formulation,"Julien Dewez, François Glineur","Computing the nonnegative rank of a nonnegative matrix has been proven to be, in general, NP-hard [1]. However, this quantity has many interesting applications, e.g., it can be used to compute the extension complexity of polytopes [2]. Therefore researchers have been trying to approximate this quantity as closely as possible with strong lower and upper bounds. In this work, we introduce a new lower bound on the nonnegative rank based on a representation of the matrix as a pair of nested polytopes. The nonnegative rank then corresponds to the minimum number of vertices of any polytope nested between these two polytopes. Using the geometric concept of supporting corner, we introduce a parametrized family of computable lower bounds and present preliminary numerical results on slack matrices of regular polygons.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-157.pdf
2020,Predicting low gamma- from lower frequency band activity in electrocorticography,"Marc Van Hulle, Bob Van Dyck, Wittevrongel Benjamin, Flavio Camarrone, Ine Dauwe, Evelien Carrette, Alfred Meurs, Paul Boon, Dirk Van Roost","Electrocorticography (ECoG) has witnessed increasing interest from brain modelers for spanning a broader spectral band than EEG. As human brain activity exhibits broadband modulations, we hypothesize that this should also be reflected by ECoG signal predictability across frequency bands. As a concrete case, we consider the prediction of low gamma- (40-70 Hz) from lower frequency band non-task related activity using the recently developed Block Term Tensor Regression (BTTR) algorithm. As a result, we achieved prediction accuracies up to 89% (Pearson correlation coefficient), providing evidence for a substantial degree of low gamma predictability.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-149.pdf
2020,Invariant Integration in Deep Convolutional Feature Space,"Matthias Rath, Alexandru Paul Condurache","In this contribution, we show how to incorporate prior knowledge to a deep neural network architecture in a principled manner. We enforce feature space invariances using a novel layer based on invariant integration. This allows us to construct a complete feature space invariant to finite transformation groups.  We apply our proposed layer to explicitly insert invariance properties for vision-related classification tasks, demonstrate our approach for the case of rotation invariance and report state-of-the-art performance on the Rotated-MNIST dataset. Our method is especially beneficial when training with limited data.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-140.pdf
2020,Biochemical Pathway Robustness Prediction with Graph Neural Networks,"Marco Podda, Alessio Micheli, Davide Bacciu, Paolo Milazzo","The robustness property of a biochemical pathway refers to maintaining stable levels of molecular concentration against the perturbation of parameters governing the underlying chemical reactions. Its computation requires an expensive integration in parameter space. We present a novel application of Graph Neural Networks (GNN) to predict robustness indicators on pathways represented as Petri nets, without the need of performing costly simulations. Our assumption is that pathway structure alone is sufficient to be effective in this task. We show experimentally for the first time that this is indeed possible to a good extent, and investigate how different architectural choices influence performances.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-41.pdf
2020,Time Series Prediction using Disentangled Latent Factors,"Perrine Cribier-Delande, Raphaël Puget, Vincent Guigue, Ludovic Denoyer","We propose a new neural architecture to predict time series that are organised based on underlying factors of variations. Our method typically applies to spatio-temporal prediction of missing series where only certain locations and times are observed. The model is based on an encoder-decoder structure where the multiple factors are projected into a latent space which is learned by  combining the latent factors coming from multiple observed series. We show on  several  spatio-temporal datasets that our method is able to predict missing series, for both observed factors values, but also for new ones.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-160.pdf
2020,Adversarial domain adaptation without gradient reversal layer,"Aymen Cherif, Hugo  Serieys","Adversarial Domain adaptation is one of the most efficient ways to deal with the domain shift phenomenon. We propose an improvement to the popular GRL method introduced in \cite{dann}, an unsupervised domain adaptation (i.e. no labels in the target domain) technique easy to implement. We call our method NoGRL, and it is inspired by generative adversarial networks \cite{gan}. Our main idea is to dissociate prediction optimization and domain adaptation optimization. Our method outperforms results obtained by GRL in small image benchmarks.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-114.pdf
2020,Fast and Stable Interval Bounds Propagation for Training Verifiably Robust Models,"Pawel Morawiecki, Przemysław Spurek, Marek Śmieja, Jacek Tabor","We present an efficient technique to train classification networks which are verifiably robust against norm-bounded adversarial attacks. This framework is built upon interval bounds propagation (IBP), which applies the interval arithmetic to bound the activations at each layer and keeps the prediction invariant to the input perturbation. To speed up and stabilize training of IBP, we supply its cost function with an additional term, which encourages the model to keep the interval bounds at hidden layers small. Experimental results demonstrate that the training of our model is faster, more stable and less sensitive to the exact specification of the training process than original IBP","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-57.pdf
2020,Towards Adversarial Attack Resistant Deep Neural Networks,"Tiago Alves, Sandip Kundu","Recent publications have shown that neural network based classifiers are vulnerable to adversarial inputs that are virtually indistinguishable from normal data, constructed explicitly for the purpose of forcing misclassification. Further, it has been demonstrated that private data used for training a neural network model can also be exposed by guided model query, even when adversary lacks access to internal model data. In this paper, we present several defenses to counter these threats. First, we observe that most adversarial attacks succeed by mounting gradient ascent on the confidence returned by the model, which allows adversary to gain understanding of the classification boundary. Our defenses are based on denying access to the precise classification boundary. Our first defense adds a controlled random noise to the output confidence levels, which prevents an adversary from converging in their numerical approximation attack. In a simple solution, such random noise can be zeroed by averaging results from multiple queries with the same input. Our noise injection mechanism addresses this problem. Our next defense is based on the observation that by varying the order of the training, often we arrive at models which offer the same classification accuracy, yet they are different numerically. An ensemble of such models allows us to randomly switch between these equivalent models during query which further blurs the classification boundary. We demonstrate our defense by via an adversarial input generator which defeats previously published defenses but cannot breach the proposed defenses do to their \textit{non-static} nature.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-128.pdf
2020,Estimating Individual Treatment Effects through Causal Populations Identification,"Celine Beji, Eric Benhamou, Michael Bon, Florian Yger, Jamal Atif","Estimating the Individual Treatment Effect from observational data, defined as the difference between outcomes with and without intervention, while observing just one of both, is one of the challenging problems in causal learning. In this paper, we formulate this problem as an inference from hidden variables and enforce causal constraints based on a model of four exclusive causal populations. We propose a new version of the EM algorithm, coined as Expected-Causality-Maximization (ECM) algorithm and provide hints on its convergence under mild conditions. We assess our algorithm on synthetic and real-world data and discuss its performances w.r.t. baseline methods.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-110.pdf
2020,Interpretation of Model Agnostic Classifiers via Local Mental Images,"Aluizio Lima Filho, Gabriel Guarisa, Leopoldo Lusquino, Luiz Oliveira, Carlos Cosenza, Felipe França, Priscila Lima","Although  successful  black-box  learning  models  have  been created, understanding what happens when a machine produces a classification response is still a challenge.  This work introduces FRWI – Fuzzy Regression WiSARD Interpreter, a novel fuzzy rules-based algorithm that is capable of interpreting the responses of black-box classifiers via the production of local mental images from a WiSARD n-tuple classifier.  FRWI is compared with LIME – Local Interpretable Model-Agnostic Explanations, a  pioneering  agnostic  classification  interpreter  model.   To  make  a  quantitative evaluation of interpretable models, a new metric – InterpretationCapacity Score – is proposed.  Using this metric, it is shown that FRWI surpasses LIME in producing coherent interpretations.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-97.pdf
2020,Learning Deep Fair Graph Neural Networks,"Luca Oneto, Nicolò Navarin, Michele Donini","Developing learning methods which do not discriminate subgroups in the population is the central goal of algorithmic fairness. One way to reach this goal is to learn a data representation that is expressive enough to describe the data and fair enough to remove the possibility to discriminate subgroups when a model is learned leveraging on the learned representation. This problem is even more challenging when our data are graphs, which nowadays are ubiquitous and allow to model entities and relationships between them. In this work we measure fairness according to demographic parity, requiring the probability of the possible model decisions to be independent of the sensitive information. We investigate how to impose this constraint in the different layers of a deep graph neural network through the use of two different regularizers. The first one is based on a simple convex relaxation, and the second one inspired by a Wasserstein distance formulation of demographic parity. We present experiments on a real world dataset, showing the effectiveness of our proposal.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-75.pdf
2020,An Empirical Study of Iterative Knowledge Distillation for Neural Network Compression,"Sharan Yalburgi, Tirtharaj Dash, Ramya Hebbalaguppe, Srinidhi Hegde, Ashwin Srinivasan","In this paper we introduce Iterative Knowledge Distillation (IKD), the process of successively minimizing models based on the Knowledge Distillation (KD) approach in [1]. We study two variations of IKD, called parental- and ancestral- training. Both use a single-teacher, and result in a single-student model: the differences arise from which model is used as a teacher. Our results provide support for the utility of the IKD procedure, in the form of increased model compression, without significant losses in predictive accuracy. An important task in IKD is choosing the right model(s) to act as a teacher for a subsequent iteration. Across the variations of IKD studied, our results suggest that the most recent model constructed (parental-training) is the best single teacher for the model in the next iteration. This result suggests that training in IKD can proceed without requiring us to keep all models in the sequence.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-205.pdf
2020,Fast Deep Neural Networks Convergence using a Weightless Neural Model,"Alan T. L. Bacellar, Brunno F. Goldstein, Victor C Ferreira, Leandro Santiago, Priscila Lima, Felipe França","Deep Neural Networks (DNNs) have surged as a promising technique for AI applications combining a huge parametric space with efficient learning algorithms. The efficiency of the training procedure relies on some optimization algorithms which adjust the initial weights to minimize the loss of the model. Such strategies are essential to speed up the convergence of the optimization steps. Nonetheless, a general initialization procedure is still an open problem since the proposed techniques either require a long processing time or take a considerable number of iterations to figure out an acceptable model. This work presents a weight initialization strategy using transfer learning via Weightless Neural Network (WNN). This WNN initialization strategy reaches up to $5.5\times$ accuracy and $15\times$ loss reduction at the first iterations when compared against well-known techniques such as Xavier and He.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-200.pdf
2020,Variational MIxture of Normalizing Flows,"Guilherme Pires, Mário Figueiredo","In the past few years, deep generative models, such as gen-erative adversarial networks, variational autoencoders, and their variants,have  seen  wide  adoption  for  the  task  of  modelling  complex  data  distri-butions.   In  spite  of  the  outstanding  sample  quality  achieved  by  thosemethods, they model the target distributionsimplicitly, in the sense thatthe probability density functions approximated by them are not explicitlyaccessible.  This fact renders those methods unfit for tasks that require,for example, scoring new instances of data with the learned distributions.Normalizing  flows  overcome  this  limitation  by  leveraging  the  change-of-variables  formula  for  probability  density  functions,  and  by  using  trans-formations designed to have tractable and cheaply computable Jacobians.Although flexible,  this framework lacked (until the publication of recentwork) a way to introduce discrete structure (such as the one found in mix-tures) in the models it allows to construct, in an unsupervised scenario.The  present  work  overcomes  this  by  using  normalizing  flows  as  compo-nents  in  a  mixture  model,  and  devising  a  training  procedure  for  such  amodel.  This procedure is based on variational inference, and uses a varia-tional posterior parameterized by a neural network.  As will become clear,this model naturally lends itself to (multimodal) density estimation, semi-supervised learning, and clustering.  The proposed model is evaluated ontwo synthetic datasets, as well as on a real-world dataset.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-188.pdf
2020,Improving Light-weight Convolutional Neural Networks for Face Recognition Targeting Resource Constrained Platforms,"Iulian-Ionut Felea, Radu Dogaru","A thorough investigation of the possibility to optimize deep convolutional neural network architectures for face recognition problems is considered, from the perspective of training very compact models to be further deployed on resource-constrained systems. Latencies in recognition phase and memory usage are minimized while recognition accuracies are maintained close to state of the art performance of more complicated deep neural networks. Using two widely used datasets, namely VGG-Face and YouTube Faces, several modifications of a recent light-weight CNN model are proposed, and for a reasonable accuracy the most compact solutions were identified. Experiments on VGG-Face show that our proposed models achieves 95.5% accuracy, with 5.6 times less memory storage when compared to the reference slim model.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-185.pdf
2020,Fréchet Mean Computation in Graph Space through Projected Block Gradient Descent,"Nicolas Boria, Benjamin Negrevergne, Florian Yger","A fundamental concept in statistics is the concept of Fréchet sample mean. While its computation is a simple task in Euclidian space, the same does not hold for less structured spaces such as the space of graphs, where concepts of distance or mid-point can be hard to compute. We present some work in progress regarding new distance measures and new algorithms to compute the Fréchet mean in the space of Graphs.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-172.pdf
2020,New Results on Sparse Autoencoders for Posture Classification and Segmentation,"Doreen Jirak, Stefan Wermter","This paper is a sequel on posture recognition using sparse autoencoders. We conduct experiments on a posture dataset and show that shallow sparse autoencoders achieve even better performance compared to a convolutional neural network, state-of-the-art model for recognition tasks. Also, our results support robust image representation from the autoencoder model rendering further finetuning unnecessary. Finally, we suggest using sparse autoencoders for image segmentation.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-156.pdf
2020,Random Signal Cut for Improving Multimodal CNN Robustness of 2D Road Object Detection,"Robin Condat, Alexandrina Rogozan, Abdelaziz Bensrhair","Given the large number of deep neural network proposals using only RGB images for 2D object detection for Advanced Driver-Assistance Systems, we propose MMRetina, a CNN taking multimodal data (RGB, Depth from Stereo, Optical Flow, LIDAR) as input for detecting road objects and their 2D localization. We introduce a new data augmentation method, we called Random Signal Cut, to make our multimodal CNN more robust to sensor malfunctions or breakdowns. The experiments show on KITTI dataset that using multimodal data with Random Signal Cut improves significantly CNN robustness without lowering its overall performances when all sensors are well functioning.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-153.pdf
2020,Quantum-Inspired Learning Vector Quantization for Classification Learning,"Thomas Villmann, Jensun Ravichandran, Alexander Engelsberger, Andrea Villmann, Marika Kaden","This paper introduces a variant of the prototype-based generalized 	learning vector quantization (GLVQ) for classification learning inspired 	by quantum computing. Starting from the motivation of kernelized GLVQ, 	the nonlinear transformation of real data and prototypes into quantum 	bit vectors allows to formulate a GLVQ variant in a ($n$-dimensional) 	quantum bit vector space $\mathscr{\mathcal{H}}^{n}$. A key feature 	for this approch is that $\mathscr{\mathcal{H}}^{n}$ is an Hilbert 	space with particular inner product properties, which finally restrict 	the prototype adaptation to be unitary transformations. The resulting approach is denoted as Qu-GLVQ.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-90.pdf
2020,Image completion via nonnegative matrix factorization using B-splines,"Cécile Hautecoeur, François Glineur","When performing image completion, it is common to assume that images are smooth and low-rank, when viewed as matrices of pixel intensities. In this work, we use nonnegative matrix factorization to successively refine the image by representing alternatively rows and columns as smooth signals using splines. Previous work solved this model using an alternating direction method of multipliers. Instead, we propose to use a version of the hierarchical alternating least squares algorithm adapted to handle splines, and show in numerical experiments that it outperforms the existing method. Performance can be further improved by increasing progressively the size of used splines. We also introduce a non iterative algorithm using the same NMF approach, where factorization is computed in a fast and accurate way but for which convergence is harder to achieve.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-116.pdf
2020,ASAP - A Sub-sampling Approach for Preserving Topological Structures,"Abolfazl Taghribi, Kerstin Bunte, Michele Mastropietro, Sven De Rijcke, Peter Tino","Topological data analysis tools enjoy increasing popularity in a wide range of applications. However, due to computational complexity, processing large samples of higher dimensionality quickly becomes infeasible. We propose a novel sub-sampling strategy inspired by Coulomb’s law to decrease the number of data points in d-dimensional point clouds while preserving its Homology. The method is not only capable of reducing the memory and computation time needed for the construction of different types of simplicial complexes but also preserves the size of the voids in d-dimensions, which is crucial e.g. for astronomical applications. We demonstrate and compare the strategy in several synthetic scenarios and an astronomical particle simulation of a Jellyfish galaxy for the detection of superbubbles (supernova signatures).","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-147.pdf
2020,Deep Recurrent Graph Neural Networks,"Luca Pasa, Nicolò Navarin, Alessandro Sperduti","Graph Neural Networks (GNN) show good results in classification and regression on graphs, notwithstanding most GNN models use a limited depth.  Indeed, they are composed of only a few stacked graph  convolutional  layers.   One  reason  for  this  is  the  growing  number of  parameters  with  the  number  of  GNN  layers.   In  this  paper,  we  show how using a recurrent graph convolution layer can help in building deeper GNN, without increasing the complexity of the training phase, while improving on the performances.  We also analyze how the depth of the model influences the final result.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-107.pdf
2020,Linear Graph Convolutional Networks,"Nicolò Navarin, Wolfgang Erb, Luca Pasa, Alessandro Sperduti","Many neural networks for graphs are based on the graph convolution operator, proposed more than a decade ago. Since then, many alternative definitions have been proposed, that tend to add complexity (and non-linearity) to the model. In this paper, we follow the opposite direction by proposing a linear graph convolution operator. Despite its simplicity, we show that our convolution operator is more theoretically grounded than many proposals in literature, and shows improved predictive performance.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-96.pdf
2020,Cost-free resolution enhancement in Convolutional Neural Networks for medical image segmentation,"Oscar J. Pellicer Valero, María J. Rupérez-Moreno, José D. Martín-Guerrero","High-resolution segmentations of medical images are imperative for applications such as treatment planning, image fusion or computer-aided surgery. Nevertheless, these are often hard and time-consuming to produce. This paper presents a method for improving the output resolution of Convolutional Neural Networks (CNNs) for medical image segmentation. It is straightforward to implement and works with any already trained CNN with no modification nor retraining required. It is able to produce better results than binary interpolation methods since it exploits all the contextual information to predict the sought values.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-51.pdf
2020,Verifying Deep Learning-based Decisions for Facial Expression Recognition,"Ines Rieger, Rene Kollmann, Bettina Finzel, Dominik Seuss, Ute Schmid","Neural networks with high performance can still be biased towards non-relevant features. However, reliability and robustness is especially important for high-risk fields such as clinical pain treatment. We therefore propose a verification pipeline, which consists of three steps. First, we classify facial expressions with a neural network. Next, we apply layer-wise relevance propagation to create pixel-based explanations. Finally, we quantify these visual explanations based on a bounding-box method with respect to facial regions. Although our results show that the neural network achieves state-of-the-art results, the evaluation of the visual explanations reveals that relevant facial regions may not be considered.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-49.pdf
2020,Embedding of FRPN in CNN architecture,"Alberto Rossi, Markus Hagenbuchner, Franco Scarselli, Ah Chung Tsoi","This paper extends the fully recursive perceptron network (FRPN) model for vectorial inputs to include deep convolutional neural networks (CNNs) which can accept multi-dimensional inputs. A FRPN consists of a recursive layer, which, given a fixed input, iteratively computes an equilibrium state. The unfolding realized with this kind of iterative mechanism allows to simulate a deep neural network with any number of layers. The extension of the FRPN to CNN results in an architecture, which we call convolutional-FRPN (C-FRPN), where the convolutional layers are recursive. The method is evaluated on several image classification benchmarks. It is shown that the C-FRPN consistently outperforms standard CNNs having the same number of parameters. The gap in performance is particularly large for small networks, showing that the C-FRPN is a very powerful architecture, since it allows to obtain equivalent performance with fewer parameters when compared with deep CNNs.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-46.pdf
2020,Graph Neural Networks for the Prediction of Protein-Protein Interfaces,"Niccolò Pancino, Alberto Rossi, Giorgio Ciano, Giorgia Giacomini, Simone Bonechi, Paolo Andreini, Franco Scarselli, Monica Bianchini, Pietro Bongini","Binding site identification allows to determine the functionality and the quaternary structure of protein-protein complexes. Various approaches to this problem have been proposed without reaching a viable solution. Representing the interacting peptides as graphs, a correspondence graph describing their interaction can be built. Finding the maximum clique in the correspondence graph allows to identify the secondary structure elements belonging to the interaction site. Although the maximum clique problem is NP-complete, Graph Neural Networks make for an approximation tool that can solve the problem in affordable time. Our experimental results are promising and suggest that this direction should be explored further.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-76.pdf
2020,Object-centered Fourier Motion Estimation and Segment-Transformation Prediction,"moritz wolter, Angela Yao, Sven Behnke","The  ability  to  anticipate  the  future  is  essential  for  action planning  in  autonomous  systems.    To  this  end,  learning  video  prediction  methods  have  been  developed,  but  current  systems  often  produce blurred predictions. We address this issue by introducing an object-centered movement estimation,  frame prediction,  and correction framework using frequency-domain approaches.  We transform single objects based on estimated translation and rotation speeds which we correct using a learned encoding  of  the  past.   This  results  in  clear  predictions  with  few  parameters.  Experimental evaluation shows that our approach is accurate and computationally efficient.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-100.pdf
2020,Language Grounded Task-Adaptation in Reinforcement Learning,"Matthias Hutsebaut-Buysse, Kevin Mets, Steven Latré","Over its lifetime, a Reinforcement Learning agent is often instructed to perform different tasks. How to efficiently adapt a previously learned control policy from one task to another, remains an open research question. In this paper, we investigate how instructions formulated in natural language can enable faster and more effective task adaptation. Our proposed method is capable of assessing, given a set of developed base control policies, which base policy will be the most qualified to adapt to a new unseen task.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-108.pdf
2020,Softmax Recurrent Unit:  A new type of RNN cell,"Lucas Vos, Twan van Laarhoven","Recurrent Neural Networks (RNNs) have been very successful in many state-of-the-art solutions for natural language tasks like machine translation. However, LSTM, the most common RNN cell, is complex and utilizes a lot of components. We present the Softmax Recurrent Unit (SMRU), a novel and elegant design of a new type of RNN cell. The SMRU has a simple structure, which is solely based around the softmax function. We present four different variants of the SMRU and compare them to both the LSTM and GRU on various tasks and datasets. These experiments show that the SMRU achieves competitive performance, surpassing either the LSTM or the GRU on any the given task, while having a much simpler design.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-187.pdf
2020,A Distributed Neural Network Architecture for Robust Non-Linear Spatio-Temporal Prediction,"Matthias Karlbauer, Sebastian Otte, Hendrik Lensch, Thomas Scholten, Volker Wulfmeyer, Martin Butz","DISTANA -- a distributed spatio-temporal artificial neural network architecture -- learns to model and predict spatio-temporal time series dynamics. It learns in a parallel, spatially distributed manner while employing a mesh of recurrent, neural prediction kernels (PKs). Individual PKs predict the local data stream and exchange information laterally. DISTANA essentially assumes that generally applicable causes, which may be locally modified, generate the observed data. We show that DISTANA scales and generalizes to large problem spaces, can approximate complex dynamics, and is robust to overfitting, outperforming other competitive ANNs.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-161.pdf
2020,Explorations in Quantum Neural Networks with Intermediate Measurements,"Lukas Franken, Bogdan Georgiev","In this short note we explore a few quantum circuits with the particular goal of basic image recognition. The models we study are inspired by recent progress in Quantum Convolution Neural Networks (QCNN) [Cong et al., 2019]. We present a few experimental results, where we attempt to learn basic image patterns motivated by scaling down the MNIST dataset.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-197.pdf
2020,Approximating Archetypal Analysis Using Quantum Annealing,"Sebastian Feld, Christoph Roch, Katja Geirhos, Thomas Gabor","Archetypes are those extreme values of a data set that can jointly represent all other data points. They often have descriptive meanings and can thus contribute to the understanding of the data.  Such archetypes are identified using archetypal analysis and all data points are represented as convex combinations thereof. In this work, archetypal analysis is linked with quantum annealing. For both steps, i.e. the determination of archetypes and the assignment of data points, we derive a QUBO formulation which is solved on D-Wave's 2000Q Quantum Annealer. For selected data sets, called \textit{toy} and \textit{iris}, our quantum annealing-based approach can achieve similar results to the original R-package ``archetypes''.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-195.pdf
2020,An quantum algorithm for feedforward neural networks tested on existing quantum hardware,"Daniele Bajoni, Dario Gerace, Chiara Macchiavello, Francesco Tacchino, Panagiotis Barkoutsos, Ivano Tavernelli","We present a memory-efficient quantum algorithm implementing the action of an artificial neuron according to a binary-valued model of the classical  perceptron. The algorithm, tested on noisy IBM-Q superconducting real quantum processors, succeeds in elementary classification  and image-recognition tasks through a hybrid quantum-classical training procedure.  Here we also show that this model is amenable to be extended to a multilayered artificial neural network, which is able to solve a task that would be  impossible to a single one of its constituent artificial neurons, thus laying the basis for a fully quantum artificial intelligence algorithm run on noisy intermediate-scale quantum hardware.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-30.pdf
2020,Missing Image Data Imputation using Variational Autoencoders with Weighted Loss,"Ricardo Cardoso Pereira, Joana Cristo Santos, José Pereira Amorim, Pedro Pereira Rodrigues, Pedro Henriques Abreu","Missing data is an issue often addressed with imputation strategies that replace the missing values with plausible ones. A trend in these strategies is the use of generative models, one being Variational Autoencoders. However, the default loss function of this method gives the same importance to all data, while a more suitable solution should focus on the missing values. In this work an extension of this method with a custom loss function is introduced (Variational Autoencoder with Weighted Loss). The method was compared with state-of-the-art generative models and the results showed improvements higher than 40% in several settings.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-193.pdf
2020,Understanding and improving unsupervised training of Boltzman machines,"Przemys{\l}aw Grzybowski, Gorka Muñoz-Gil, Alejandro Pozas-Kerstjens, Miguel Angel Garcia-March, Maciej Lewenstein","We have analyzed the training of Boltzmann machines under the perspective of statistical physics. We argue that training models in spin-glass regime is highly inefficient and unnecessary. To that end, previously we have presented RAPID, a method to control the frustration of spin models and to train them without the need of expensive sampling methods. In this contribution we study effects of initialising Boltzmann machines in easily sampling regime and training with standard methods.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-180.pdf
2020,Machine learning framework for control in classical and quantum domains,"Archismita Dalal, Eduardo J.  P\'aez, Seyed Shakib Vedaie, Barry C. Sanders","Our aim is to construct a framework that relates learning and control for both classical and quantum domains. As an application of the proposed framework, we cast the quantum-control problem of adaptive quantum-enhanced metrology as a supervised learning problem. The novelty of our work lies in the unification of quantum and classical control and learning theories and the pictorial representations of knowledge in these disparate areas. Our work enhances the control toolkit and helps un-confuse this interdisciplinary field of machine learning for control. It also highlights new research directions in areas inter-connecting learning and control.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-203.pdf
2020,Quantum Machine Learning,"José D. Martín-Guerrero, Lucas Lamata","Machine Learning (ML) is becoming a more and more popular field of knowledge, being a term known not only in the academic field due to its successful applications to many real-world problems. The advent of Deep Learning and Big Data in the last decade has contributed to make it even more popular. Many companies, both large ones and SMEs, have created specific departments for ML and data analysis, being in fact their main activity in many cases. This current exploitation of ML should not mislead us; while it is a mature field of knowledge, there is still room for many novel contributions, namely, a better understanding of the underlying Mathematics, proposal and tuning of algorithms suitable for new problems (e.g., Natural Language Processing), automation and optimization of the search of parameters, etc. Within this framework of new contributions to ML, Quantum Machine Learning (QML) has emerged strongly lately, speeding up ML calculations and providing alternative representations to existing approaches.   This special session includes six high-quality papers dealing with some of the most relevant aspects of QML, including analysis of learning in quantum computing and quantum annealers, quantum versions of classical ML models –like neural networks or learning vector quantization–, and quantum learning approaches for measurement and control.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-6.pdf
2020,Anomaly Detection Approach in Cyber Security for User and Entity Behavior Analytics System,"Vladimir Muliukha, Alexey Lukashin, Lev Utkin, Mikhail Popov, Anna Meldo","This paper presents a prototype of an intelligent system for advanced analytics for integrated security of complex information and cyberphysical systems with the implementation of analytical models and software developed in Peter the Great St. Petersburg Polytechnic University. The article discusses the practical aspects of the application of unsupervised machine learning methods to the tasks of identifying abnormal objects in the field of information security in computer networks. The format of presenting initial data on various events in computer networks is described, as well as the process of preparing a training set for machine learning. The results of detecting anomalies by the Isolation Forest and Local Outlier Factor methods are presented, as well as an analysis of the results.","Machine Learning Applied to Computer Networks - organized by Alexander Gepperth (University of Applied Sciences Fulda, Germany), Sebastian Rieger (University of Applied Sciences Fulda, Deutschland)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-191.pdf
2020,A Survey of Machine Learning applied to Computer Networks,"Alexander Gepperth, Sebastian Rieger","We review the current state of the art in the domain of machine learning applied to computer networks. First of all, we describe recent developments in computer networking and outline the potential fields for machine learning that arise from these developments. We discuss challenges for machine learning in this particular field, namely the inherent big data aspect of computer networks, and the fact that learning very often needs to be conducted in a streaming setting with non-stationary data distributions. We discuss practical issues like privacy protection and computing resources before finally outlining potential technological benefits of this emerging scientific field.","Machine Learning Applied to Computer Networks - organized by Alexander Gepperth (University of Applied Sciences Fulda, Germany), Sebastian Rieger (University of Applied Sciences Fulda, Deutschland)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-2.pdf
2020,Sparse K-means for mixed data via group-sparse clustering,"Marie Chavent, Jérôme Lacaille, Alex Mourer, Madalina Olteanu","The present manuscript tackles the issue of variable selection for clustering, in high dimensional data described both by numerical and categorical features. First, we build upon the sparse k-means algorithm with lasso penalty, and introduce the group-L_1 penalty -- already known in regression -- in the unsupervised context. Second, we preprocess mixed data and transform categorical features into groups of dummy variables with appropriate scaling, on which one may then apply the group-sparse clustering procedure. The proposed method performs simultaneously clustering and feature selection, and provides meaningful partitions and meaningful features, numerical and categorical, for describing them.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-103.pdf
2020,Incorporating Human Priors into Deep Reinforcement Learning for Robotic Control,"Manon Flageat, Kai Arulkumaran, Anil A Bharath","Deep reinforcement learning (DRL) shows promise for robotic control, as it scales to high-dimensional observations and does not require a model of the robot or environment. However, properties such as control continuity or movement smoothness, which are desirable for application in the real world, will not necessarily emerge from training on reward functions based purely on task success. Inspired by human neuromotor control and movement analysis literature, we define a modular set of costs that promote more efficient, human-like movement policies. Using a simulated 3-DoF manipulator robot, we demonstrate the benefits of these costs by incorporating them into the training of a model-free DRL algorithm and decision-time planning of a trained model-based DRL algorithm. We also quantify these benefits through metrics based on the same literature, which allows for greater interpretability of learned policies---a common concern when learning policies with powerful and complex function approximators.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-32.pdf
2020,Why state-of-the-art deep learning barely works as good as a linear classifier in extreme multi-label text classification,"Mohammadreza Qaraei, Sujay Khandagale, Rohit Babbar","Extreme Multi-label Text Classification (XMTC) refers to supervised learning of a classifier which can predict a small subset of relevant labels for a document from an extremely large set. Even though deep learning algorithms have surpassed linear and kernel methods for most natural language processing tasks over the last decade; recent works show that state-of-the-art deep learning methods can only barely manage to work as well as a linear classifier for the XMTC task. The goal of this work is twofold : (i) to investigate the reasons for the comparable performance of these two strands of methods for XMTC, and (ii) to document this observation explicitly, as the efficacy of linear classifiers in this regime, has been ignored in many relevant recent works.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-207.pdf
2020,A preconditioned accelerated stochastic gradient descent algorithm,"Alexandru Onose, Seyed Iman Mossavat, Henk-Jan H. Smilde","We propose a preconditioned accelerated stochastic gradient method suitable for large scale optimization. Inspired by recent popular adaptive per-feature algorithms, we propose a specific preconditioner based on the second moment of the gradient. We derive sufficient convergence conditions for the minimization of convex functions using a generic class of diagonal preconditioners and provide a formal convergence proof based on a framework originally used for on-line learning. We show empirical results for the minimization of convex and non-convex cost functions, in the context of neural network training.  The method compares favorably with respect to current, first order, stochastic optimization methods.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-80.pdf
2020,On Feature Selection Using Anisotropic General Regression Neural Network,"Federico Amato, Fabian Guignard, Philippe Jacquet, Mikhail Kanevski","The presence of irrelevant features in the input dataset tends to reduce the interpretability and predictive quality of machine learning models. Therefore, the development of feature selection methods to recognize irrelevant features is a crucial topic in machine learning. Here we show how the General Regression Neural Network used with an anisotropic Gaussian Kernel can be used to perform feature selection.  A number of numerical experiments are conducted using simulated data to study the robustness of the proposed methodology and its sensitivity to sample size.  Finally, a comparison with four other feature selection methods is performed on several real world datasets.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-16.pdf
2020,Random Projection in supervised non-stationary environments,"Moritz Heusinger, Frank-Michael Schleif","Random Projection (RP) is a popular and efficient technique to preprocess high-dimensional data and to reduce its dimensionality. While RP has been widely used and evaluated in stationary data analysis scenarios, non-stationary environments are not well analyzed. In this paper we provide a profound evaluation of RP on streaming data. We discuss how RP can be bounded for streaming data using the Johnson-Lindenstrauss (JL) lemma. In particular we analyze the effect of concept drift, as a key challenge for streaming data. We also provide experiments with RP on streaming data, using state-of-the-art streaming classifiers like Adaptive Hoeffding Tree, to evaluate its efficiency.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-13.pdf
2020,Do we need hundreds of classifiers or a good feature selection?,"Laura Morán-Fernández, Verónica Bolón-Canedo, Amparo Alonso-Betanzos","The task of choosing the appropriate classifier for a problem is not an easy-to-solve question due to the high number of algorithms available belonging to different families. Most of these classification algorithms exhibit a degradation in the performance when faced with many irrelevant and/or redundant features. Thus, in this work we analyze the impact of feature selection in classification. Experimental results over ten synthetic datasets show that the significance of selecting a classifier decreases after applying an appropriate preprocessing step and, not only this alleviates the choice, but it also improves the results in almost all classifiers tested.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-167.pdf
2020,Explaining t-SNE Embeddings Locally by Adapting LIME,"Adrien Bibal, Viet Minh VU, Géraldin Nanfack, Benoit Frénay","Non-linear dimensionality reduction techniques, such as t-SNE, are widely used to visualize and analyze high-dimensional datasets. While non-linear projections can be of high quality, it is hard, or even impossible, to interpret the dimensions of the obtained embeddings. This paper adapts LIME to locally explain t-SNE embeddings. More precisely, the sampling and black-box-querying steps of LIME are modified so that they can be used to explain t-SNE locally. The result of the proposal is to provide, for a particular instance x and a particular t-SNE embedding Y, an interpretable model that locally explains the projection of x on Y.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-105.pdf
2020,Perplexity-free Parametric t-SNE,"Francesco Crecchi, Cyril de Bodt, Michel Verleysen, Lee John, Davide Bacciu","The t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm is a ubiquitously employed dimensionality reduction (DR) method. Its non-parametric nature and impressive efficacy motivated its parametric extension.  It is however bounded to a user-defined perplexity parameter, restricting its DR quality compared to recently developed multi-scale perplexity-free approaches.  This paper hence proposes a multi-scale parametric t-SNE scheme, relieved from the perplexity tuning and with a deep neural network implementing the mapping.  It produces reliable embeddings with out-of-sample extensions, competitive with the best perplexity adjustments in terms of neighborhood preservation on multiple data sets",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-85.pdf
2020,Joint optimization of predictive performance and selection stability,"Victor Hamer, Pierre Dupont","Current feature selection methods, especially applied to high dimensional data, tend to suffer from instability since marginal modifications in the data may result in largely distinct selected feature sets. Such instability strongly limits a sound interpretation  of  the  selected  variables  by  domain  experts. We  address  this  issue  by  optimizing  jointly the predictive accuracy and selection stability and by deriving Pareto-optimal trajectories. Our approach extends the Recursive Feature Elimination algorithm by enforcing the selection of some features based on a stable, univariate criterion. Experiments conducted on several high dimensional microarray datasets  illustrate  that  large  stability  gains  are  obtained with no significant drop of accuracy.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-21.pdf
2020,Sparse Metric Learning in Prototype-based Classification,"Johannes Brinkrolf, Barbara Hammer","Metric learning schemes can greatly enhance distance-based classifiers, and provide additional model   functionality such as interpretability in terms of feature  relevance weights. In particular for high dimensional data, it is desirable to obtain sparse feature relevance weights for higher efficiency and interpretability. In this contribution, a new feature selection scheme is proposed for prototype-based classification models with adaptive metric learning. More precisely, we integrate the group lasso penalty and a subsequent optimization of sparsity  while leaving the mapping invariant. We evaluate the  performance on a variety of benchmarks.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-138.pdf
2020,Visualization of the Feature Space of Neural Networks,"Carlos M. Alaíz, Ángela Fernández, José R. Dorronsoro","Visualization of a learning machine can be crucial to understand its behaviour, specially in the case of (deep) neural networks, since they are quite difficult to interpret. An approach for visualizing the feature space of a neural network is presented, trying to answer to the question ""what representation of the data is the network using to make its decision?"" The proposed method gives a representation of the space where the network is tackling the problem, reducing it while respecting the linearity of the model. As shown experimentally, this technique allows to study the evolution of the model with respect to the training epochs, to have a representation of the data similar to the one used by the neural network, and even to detect groups of patterns that behave differently.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-130.pdf
2020,Investigating 3D-STDenseNet for Explainable Spatial Temporal Crime Forecasting,"Brian Maguire, Faisal Ghaffar","Crime is a well-known social problem faced worldwide. With the availability of large city datasets, scientific community for predictive policing has switched its focus from people-centric to place-centric focusing on heterogeneous data points related to a particular geographic region in predicting crimes. Such data-driven techniques of identify micro-level regions known as hotspots with high crime intensity. In this paper, we adapt the state-of-the-art spatial-temporal prediction model STDenseNetFus to predict crime in geographic region in the presence of external factors such as a region’s demographics, seasonal events, and weather.  We demonstrate that STDenseNet maintains prediction performance compared to previous results [1] on the same dataset despite significantly reduced parameter count. We further extend STDenseNetFus architecture from two-dimensional to three-dimensional convolutions and show that it further improves the prediction results. Finally, we determine the important factors in the dataset affecting the crime predictions by applying the DeepShap model explanation method to our models.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-118.pdf
2020,Detection of abnormal driving situations using distributed representations and unsupervised learning,"Florian Mirus, Terrence C. Stewart, Jörg Conradt","In this paper, we present an anomaly detection system employing an unsupervised learning model trained on the information encapsulated within distributed vector representations of automotive scenes. Our representations allows us to encode automotive scenes with a varying number of traffic participants in a vector of fixed length. We train a neural network autoencoder in unsupervised fashion to detect anomalies based on this representation. We demonstrate the usefulness of our approach through a quantitative analysis on two real-world data-sets.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-81.pdf
2020,Comparison of Cluster Validity Indices and Decision Rules for Different Degrees of Cluster Separation,"Sara Kaczynska, Rebecca Marion, Rainer von Sachs","Clustering algorithms are powerful tools for data exploration but often require the a priori choice of the number of clusters. In practice, cluster validity indices (CVIs) are used to quantify the clustering structure of candidate partitions, then decision rules are applied to the indices to choose the best number of clusters. This study analyzes how dimensionality and the degree of cluster separation impact the choice of the number of clusters according to 7 different indices and various decision rules. In contrast to previous studies, the degree of cluster separation is controlled by a single parameter and several decision rules are tested for each CVI.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-48.pdf
2020,Simplifying Deep Reservoir Architectures,"Claudio Gallicchio, Alessio Micheli, Antonio Sisbarra","We study the impact of architectural simplifications to the design of deep Reservoir Computing (RC) models. To do so, we analyze the effects of shaping the structure of reservoir matrices, reducing the complexity of the deep recurrent network to a minimal setup. Experimental results point out the benefits of a particularly simple deep RC architecture with ring topology in each reservoir layer and deterministically constructed input and inter-reservoir connections.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-112.pdf
2020,Self-organizing maps in manifolds with complex topologies: An application to the planning of closed path for indoor UAV patrols,Hervé Frezza-Buet,"In this paper, the ability of 1D-SOMs to address the Euclidian Travelling Salesperson problem is extended to more irregular topologies, in order to compute short closed paths covering an indoor environment. In such environments, wall constraints makes the topology of the area to be visited by a patroller very irregular. An application to indoor unmanned aerial vehicule (UAV) security patrols is considered.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-40.pdf
2020,Sequence Classification using Ensembles of Recurrent Generative Expert Modules,"Marius Hobbhahn, Martin Butz, Sarah Fabi, Sebastian Otte","Successful discriminative deep learning relies on large amounts of data and proper domain coverage. We introduce an ensemble of recurrent generative modules, achieving robust and effective sequence classification facing sparse data. Each module is an expert for only a few variations of a certain class. Given an input trajectory, the latent codes of the experts are adapted via back-propagation of the reconstruction error and the most accurate expert yields the class. In comparison with direct discriminative models, our approach achieves better classification rates with fewer training examples, can be easily extended (lifelong learning), and provides fully transparent decisions (explainable AI).",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-174.pdf
2020,Handling missing data in recurrent neural networks for air quality forecasting,"Michel Tokic, Anja von Beuningen, Christoph Tietz, Hans-Georg Zimmermann","Practical applications of air quality forecasting, which typically provide  predictions over a horizon of hours and days, often require the handling of missing data due to unobserved relevant variables, sensor defects or communication outages. In this paper we discuss two aspects being important when building air quality forecasting models for essential air pollution parameters such as particular matter and nitrogen dioxides. Using a specialized architecture of a recurrent neural network, we can build models even if (1) unobserved variables or (2) missing data are present.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-23.pdf
2020,Tournament Selection Improves Cartesian Genetic Programming for Atari Games,"Tim Cofala, Lars Elend, Oliver Kramer","The objective of this paper is to extend Cartesian Genetic Programming (CGP) for the evolution of Atari game agents in the Arcade Learning Environment.     Based upon preliminary work on the use of CGP playing Atari games, we propose extensions like the repeated evaluation of elite solutions.     Furthermore, we improve the CGP optimization process by increasing the diversity in the population with tournament selection.     Experimental studies on four exemplary Atari games show that the modifications decrease premature stagnation during the evolutionary optimization process and result in more robust agent strategies.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-204.pdf
2020,Epistemic Risk-Sensitive Reinforcement Learning,"Hannes Eriksson, Christos Dimitrakakis","We develop a framework for risk-sensitive behaviour in reinforcement learning (RL) due to uncertainty about the environment dynamics by leveraging utility-based definitions of risk sensitivity. In this framework, the preference for risk can be tuned by varying the utility function, for which we develop dynamic programming (DP) and policy gradient-based algorithms. The risk-averse behavior is compared with the behavior of risk-neutral policy in environments with epistemic risk.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-84.pdf
2020,Domain Invariant Representations with Deep Spectral Alignment,"Christoph Raab, Peter Meier, Frank-Michael Schleif","Similar as traditional algorithms, deep learning networks struggle in generalizing across domain boundaries. A current solution is the simultaneous training of the classification model and the minimization of domain differences in the deep network. In this work, we propose a new unsupervised deep domain adaptation architecture, which trains a classifier and minimizes the difference of spectral properties of the co-variance matrix of the data. Evaluated against standard architectures and datasets, the approach shows an alignment with respect to the data variance between related domains.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-31.pdf
2020,Zero-shot and few-shot time series forecasting with ordinal regression recurrent neural networks,"Bernardo Pérez Orozco, Stephen J Roberts","Recurrent neural networks (RNNs) are state-of-the-art in several sequential learning tasks, but they often require considerable amounts of data to generalise well. For many time series forecasting (TSF) tasks, only a few dozens of observations may be available at training time, which restricts use of this class of models. We propose a novel RNN-based model that directly addresses this problem by learning a shared feature embedding over the space of many quantised time series. We show how this enables our RNN framework to accurately and reliably forecast unseen time series, even when there is little to no training data available.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-71.pdf
2020,Learning from partially labeled data,"Siamak Mehrkanoon, Xiaolin Huang, Johan Suykens","Providing sufficient labeled training data in many application domains is a laborious and costly task. Designing models that can learn from partially labeled data, or leveraging labeled data in one domain and unlabeled data in a different but related domain is of great interest in many applications. In particular, in this context one can refer to semi-supervised modelling, transfer learning, domain adaptation and multi-view learning among others. There are several possibilities for designing such models ranging from shallow to deep models. These type of models have received increasing interest due to their successful applications in real-life problems. This paper provides a brief overview of recent techniques in learning from partially labeled data.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-1.pdf
2020,CNN Encoder to Reduce the Dimensionality of Data Image for Motion Planning,"Janderson Ferreira, Agostinho Junior, Yves Mendes Galvao, Bruno Fernandes, Pablo Barros","Many real-world applications need path planning algorithms to solve tasks in different areas, such as social applications, autonomous cars, and tracking activities. And most importantly motion planning. Although the use of path planning is sufficient in most motion planning scenarios, they represent potential bottlenecks in large environments with dynamic changes. To tackle this problem, the number of possible routes could be reduced to make it easier for path planning algorithms to find the shortest path with less efforts. An traditional algorithm for path planning is the A*, it uses an heuristic to work faster than other solutions. In this work, we propose a CNN encoder capable of eliminating useless routes for motion planning problems, then we combine the proposed neural network output with A*. To measure the efficiency of our solution, we propose a database with different scenarios of motion planning problems. The evaluated metric is the number of the iterations to find the shortest path. The A* was compared with the CNN Encoder (proposal) with A*. In all evaluated scenarios, our solution reduced the number of iterations by more than 60\%.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-196.pdf
2020,Seq-to-NSeq model for multi-summary generation,"Guillaume Le Berre, Christophe Cerisara","Summaries of texts and documents written by people present a high variability, depending on the information they want to focus on and their writing style. Despite recent progress in generative models and controllable text generation, automatic summarization systems are still relatively limited in their capacity to both generate various types of summaries and capture this variability from a corpus. We propose to address this challenge with a multi-decoder model for abstractive sentence summarization that generates several summaries from a single input text. This model is an extension of a sequence-to-sequence model in which multiple concurrent decoders with shared attention and embeddings are trained to generate different summaries that capture the variability of styles present in the corpus. The full model is trained jointly with an Expectation-Maximization algorithm. A first qualitative analysis of the resulting decoders reveals clusters that tend to be consistent with respect to a given style, e.g., passive vs. active voice.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-37.pdf
2020,Recurrent Feedback Improves Recognition of Partially Occluded Objects,"Markus Roland Ernst, Jochen Triesch, Thomas Burwick","Recurrent connectivity in the visual cortex is believed to aid object recognition for challenging conditions such as occlusion. Here we investigate if and how artificial neural networks also benefit from recurrence. We compare architectures composed of bottom-up, lateral and top-down connections and evaluate their performance using two novel stereoscopic occluded object datasets. We find that classification accuracy is significantly higher for recurrent models when compared to feedforward models of matched parametric complexity. Additionally we show that for challenging stimuli, the recurrent feedback is able to correctly revise the initial feedforward guess.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-123.pdf
2020,Modelling human sound localization with deep neural networks.,"Kiki van der Heijden, Siamak Mehrkanoon","How the brain transforms binaural, real-life sounds into a neural representation of sound location is unclear. This paper introduces a deep learning approach to address these neurocomputational mechanisms: We develop a biological-inspired deep neural network model of sound azimuth encoding operating on auditory nerve representations of real-life sounds. We explore two types of loss functions: Euclidean distance and angular distance. Our results show that a network resembling the early stages of the human auditory pathway can predict sound azimuth location. The type of loss function modulates spatial acuity in different ways. Finally, learning is independent of environment-specific acoustic properties.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-59.pdf
2020,Weighted Emprirical Risk Minimization: Transfer Learning based on Importance Sampling,"Robin Vogel, Mastane Achab, Stéphan Clémençon, Charles Tillier","We consider statistical learning problems, when the distribution $P'$ of the training observations $Z'_1,\; \ldots,\; Z'_n$ differs from the distribution $P$ involved in the risk one seeks to minimize (referred to as the \textit{test distribution}) but is still defined on the same measurable space as $P$ and dominates it. In the unrealistic case where the likelihood ratio $\Phi(z)=dP/dP'(z)$ is known, one may straightforwardly extends the Empirical Risk Minimization (ERM) approach to this specific \textit{transfer learning} setup using the same idea as that behind Importance Sampling, by minimizing a weighted version of the empirical risk functional computed from the 'biased' training data $Z'_i$ with weights $\Phi(Z'_i)$. Although the \textit{importance function} $\Phi(z)$ is generally unknown in practice, we show that, in various situations frequently encountered in practice, it takes a simple form and can be directly estimated from the $Z'_i$'s and some auxiliary information on the statistical population $P$. By means of linearization techniques, we then prove that the generalization capacity of the approach aforementioned is preserved when plugging the resulting estimates of the $\Phi(Z'_i)$'s into the  weighted empirical risk. Beyond these theoretical guarantees, numerical results provide strong empirical evidence of the relevance of the approach promoted in this article.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-120.pdf
2020,3D U-Net for Segmentation of Plant Root MRI Images in Super-Resolution,"Yi Zhao, Nils Wandel, Magdalena Landl, Andrea Schnepf, Sven Behnke","Magnetic resonance imaging (MRI) enables plant scientists to non-invasively study root system development and root-soil interaction. Challenging recording conditions, such as low resolution and a high level of noise hamper the performance of traditional root extraction algorithms, though. We propose to increase signal-to-noise ratio and resolution by segmenting the scanned volumes into root and soil in super-resolution using a 3D U-Net. Tests on real data show that the trained network is capable to detect most roots successfully and even finds roots that were missed by human annotators. Our experiments show that the segmentation performance can be further improved with modifications of the loss function.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-127.pdf
2020,Respiratory Pattern Recognition from Low-Resolution Thermal Imaging,"Salla Aario, Ajinkya Gorad, Miika Arvonen, Simo Sarkka","Remote  monitoring  of  vital  signs  has  a  wide  range  of  applications.   In this paper we propose a method to identify respiratory patterns from low- resolution  thermal  video  data  using  a  nearest  neighbor  data  association (NNDA)  and  nearest  neighbor  Kalman  filter  (NNKF)  based  algorithms along with multi-class support vector machine (SVM). The method in this work is evaluated against a breathing belt data as a reference,  collected from healthy volunteers.  Correlation of the proposed method with airflow derived from breathing belt was found to be 0.7.  The SVM classifier is able  to  distinguish  between  the  breathing  patterns  from  derived  airflow with 60% accuracy.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-182.pdf
2020,On-edge adaptive acoustic models: an application to acoustic person presence detection,"Lode Vuegen, Peter Karsmakers","This paper validates a machine learning framework that enables processing on resource limited devices. The discussed framework allows both inference and learning to be executed on the edge. More specifically, a Least-Squares Support Vector Machine (LS-SVM) framework with a time-recursive learning algorithm is evaluated in an application where person presence is estimated based on acoustic signals only. For this purpose, a real-life acoustical dataset of 555 hours was collected in an office environment for the evaluation of the proposed on-edge machine learning framework.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-129.pdf
2020,Mining Temporal Changes in Strengths and Weaknesses of Cricket Players Using Tensor Decomposition,"Swarup Ranjan Behera, Vijaya Saradhi","In this work, we present an application of tensor decomposition for discrete random variable tensor. In particular, we construct a tensor using cricket short text commentary data by employing domain-specific features. The aim is to understand the temporal changes in the strength rules and weakness rules of a player. Three-way correspondence analysis (TWCA) is employed to obtain the factors that show dependency between batting features, bowling features, and time respectively. Change in strength rules and weakness rules for Australian batsman Steve Smith (Test Rank \#1 ICC player) are presented.","Tensor Decompositions in Deep Learning - organized by Davide Bacciu (Università di Pisa, Italy), Danilo Mandic (Imperial College, United Kingdom)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-202.pdf
2020,Compressive Learning of Generative Networks,"Vincent Schellekens, Laurent Jacques","Generative networks implicitly approximate complex densities from their sampling with impressive accuracy. However, because of the enormous scale of modern datasets, this training process is often computationally expensive. We cast generative network training into the recent framework of compressive learning: we reduce the computational burden of large-scale datasets by first harshly compressing them in a single pass as a single sketch vector. We then propose a cost function, which approximates the Maximum Mean Discrepancy metric, but requires only this sketch, which makes it time- and memory-efficient to optimize.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-176.pdf
2020,Tensor Decompositions in Recursive Neural Networks for Tree-Structured Data,"Daniele Castellana, Davide Bacciu","The paper introduces two new aggregation functions to encode structural knowledge from tree-structured data. They leverage the Canonical and Tensor-Train decompositions to yield expressive context aggregation while limiting the number of model parameters. Finally, we define two novel neural recursive models for trees leveraging such aggregation functions, and we test them on two tree classification tasks, showing the advantage of proposed models when tree outdegree increases.","Tensor Decompositions in Deep Learning - organized by Davide Bacciu (Università di Pisa, Italy), Danilo Mandic (Imperial College, United Kingdom)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-144.pdf
2020,Tensor Decompositions in Deep Learning,"Davide Bacciu, Danilo Mandic","The paper surveys the topic of tensor decompositions in modern machine learning applications. It focuses on three active research topics of significant relevance for the community. After a brief review of consolidated works on multi-way data analysis, we consider the use of tensor decompositions in compressing the parameter space of deep learning models. Lastly, we discuss how tensor methods can be leveraged to yield richer adaptive representations of complex data, including structured information.  The paper concludes with a discussion on interesting open research challenges.","Tensor Decompositions in Deep Learning - organized by Davide Bacciu (Università di Pisa, Italy), Danilo Mandic (Imperial College, United Kingdom)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-3.pdf
2020,Learning Step Size Adaptation in  Evolution Strategies,Oliver Kramer,"Step size adaptation is an essential part of successful evolution strategies in continuous solution spaces as they moderate between exploration and exploitation. We propose to learn step sizes evolved with a sigma-self-adaptive (1+lambda)-ES using LSTMs. Based on input sequences of multi-variate distances between best solutions of successive generations and their step sizes a long short-term memory network (LSTM) is trained. The learned distances-step size pairs guide the search of the LSTM-ES, which is a (1+lambda)-ES with LSTM step size predictions. An experimental analysis illustrates the behavior of the LSTM-ES on the Sphere function with different parameter settings and problem dimensionalities.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-8.pdf
2020,Adversarials-1 in Speech Recognition: Detection and Defence,"Nils Worzyk, Stefan Niewerth, Oliver Kramer","Systems that accept voice commands have become established in our daily lives. To process those commands, modern systems usually use neural networks, which have been shown to be very successful. Nevertheless, they are vulnerable against adversarial attacks---slightly perturbed inputs, to fool the system, but are not recognizable by humans. In this work we extend the adversarial$^{-1}$ concept, introduced in the image domain, to the speech recognition domain. By adapting the methodology we are able to identify adversarial inputs, in certain cases, with an accuracy of 99.9\%, while still detecting benign inputs with an accuracy of 99.8\%, for the investigated attacks. Furthermore, we present a technique to restore the correct label of an adversarial input, with up to 67.6\% accuracy. All program code for this work can be found on \url{https://github.com/OLStefan/Adversarials-1Speech-Recognition.}","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-190.pdf
2020,On the long-term learning ability of LSTM LMs,"Wim Boes, Robbe Van Rompaey, Lyan Verwimp, Joris Pelemans, Hugo Van hamme, Patrick Wambacq","We inspect the long-term learning ability of Long Short-Term Memory language models (LSTM LMs) by evaluating a contextual extension based on the Continuous Bag-of-Words (CBOW) model for both sentence- and discourse-level LSTM LMs and by analyzing its performance. We evaluate on text and speech. Sentence-level models using the long-term contextual module perform comparably to vanilla discourse-level LSTM LMs. On the other hand, the extension does not provide gains for discourse-level models. These findings indicate that discourse-level LSTM LMs already rely on contextual information to perform long-term learning.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-35.pdf
2020,Improving the Union Bound: a Distribution Dependent Approach,"Luca Oneto, Sandro Ridella, Davide Anguita","Statistical Learning Theory deals with the problem of estimating the performance of a learning procedure. Any learning procedure implies making choices and this choices imply a risk. When the number of choices is finite, the state-of-the-art tool for evaluating the total risk of all the choice made is the Union Bound. The problem of the Union Bound is that it is very loose in practice if no a-priori information is available. In fact, the Union Bound considers all choices equally plausible while, as a matter of fact, a learning procedure targets just particular choices disregarding the others. In this work we will show that it is possible to improve the Union Bound based results using a distribution dependent weighting strategy of the true risks associated to each choice. Then we will prove that our proposal outperforms or, in the worst case, it degenerate in the Union Bound.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-74.pdf
2020,Entity-Pair Embeddings for Improving Relation Extraction in the Biomedical Domain,"Farrokh Mehryary, Hans Moen, Tapio Salakoski, Filip Ginter","We introduce a new approach for training named-entity pair embeddings to improve relation extraction performance in the biomedical domain. These embeddings are trained in an unsupervised manner, based on the principles of distributional semantics. By adding them to neural network architectures, we show that improved F-Scores are achieved. Our best performing neural model which utilizes entity-pair embeddings along with a pre-trained BERT encoder, achieves an F-score of 77.19 on CHEMPROT (Chemical-Protein) relation extraction corpus, setting a new state-of-the-art result for the task.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-56.pdf
2020,Self-Organizing Kernel-based Convolutional Echo State Network for Human Actions Recognition,"Gin Chong Lee, Chu Kiong Loo, Wei Shiung Liew, Stefan Wermter",We propose a deterministic initialization of the Echo State Network reservoirs to ensure that the activation of its internal echo state representations reflects similar topological qualities of the input signal which should lead to a self-organizing reservoir. Human actions encoded as a multivariate time series signal are clustered before using the clustered nodes and interconnectivity matrices for initializing the S-ConvESN reservoirs. The capability of S-ConvESN is evaluated using several 3D-skeleton-based action recognition datasets.,"Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-99.pdf
2020,Language processing in the era of deep learning,"Ivano Lauriola, Alberto Lavelli, Fabio Aiolli","Natural Language Processing is a branch of artificial intelligence brimful of intricate, sophisticated, and challenging tasks, such as machine translation, question answering, summarization, and so on. Thanks to the recent advances of deep learning, NLP applications have received an unprecedented boost in performance, generating growing interest from the Machine Learning community. However, even if recent techniques are starting to reach excellent performance on various tasks, there are still several problems that need to be solved, such as the computational cost, the reproducibility of results, and the lack of interpretability. In this contribution, we provide a high-level overview of recent advances in NLP, the role of Machine Learning, and current research directions.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-4.pdf
2020,Modular Length Control for Sentence Generation,"Katya Kudashkina, Peter Wittek, Jamie Kiros, Graham W. Taylor","Generating summary-sentences with preserved meaning is important for the  summarization of longer documents. Length control of summary-sentences is challenging as sentences cannot simply be cut at the desired  length; they must be complete and preserve input meaning. We propose a modular framework for length control of generated sentences: based on sequence-to-sequence models, powered by a two-stage training  process  involving a summarizer that is trained without  explicit length control and a stylizer that is fine-tuned on the output of the summarizer. Our solution achieves the performance of existing models for controlling generated sentence length but light in implementation and model complexity.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-53.pdf
2020,Self-organized dynamic attractors in recurrent neural networks,"Benedikt Vettelschoss, Matthias Freiberger, Joni Dambre","Recurrent neural networks usually rely on either transient or attractor dynamics to implement working memory, and some studies suggest that it requires a combination of the two. These studies introduce attractor states by the supervised training of a network's feedback weights. In this work we report the creation of comparable memory states through unsupervised learning. We introduce attractor dynamics into an echo state network in a self-organized way by applying a differential Hebbian rule to it's feedback weights. We find that this yields periodic and quasiperiodic attractors in most cases. We analyse the linearized system after the learning phase to understand the origin of these attractors, and connect these findings to other results concerning the dynamical changes induced by neural plasticity.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-95.pdf
2020,Exploring the feature space of character-level embeddings,"Ivano Lauriola, Stefano Campese, Alberto Lavelli, Fabio Rinaldi, Fabio Aiolli","Recently, character-level embeddings have become popular in the Natural Language Processing community. These methods provide a representation of a word which depends solely on its inner structure, i.e. the sequence of characters. Convolutional and recurrent neural networks are the undisputed protagonists in this context, and they represent the state of the art for many character-level applications. In this work, we firstly compare different neural architectures against adaptive string kernels in simplified scenarios. Then, we propose a hybrid ensemble that injects structural kernel-based features into a neural architecture, providing an efficient and scalable solution. An all-around experimental assessment has been carried out on several string datasets, including biomedical entity recognition and sentiment analysis.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-104.pdf
2020,Cross-Encoded Meta Embedding towards Transfer Learning,"György Kovács, Rickard Brännvall, Johan Öhman, Marcus Liwicki","In this paper we generate word meta-embeddings from already existing embeddings using cross-encoding.  Previous approaches can only work with words  that  exist  in  each  source  embedding,  while  the  architecture  presented  here  drops  this  requirement.   We  demonstrate  the  method  using two pre-trained embeddings, namely GloVE and FastText.  Furthermore, we propose additional improvements to the training process of the meta-embedding.  Results on six standard tests for word similarity show that the meta-embedding trained outperforms the original embeddings.  Moreover, this  performance  can  be  further  increased  with  the  proposed  improvements, resulting in a competitive performance with those reported earlier.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-36.pdf
2021,"Federated Learning - Methods, Applications and beyond","Moritz Heusinger, Christoph Raab, Fabrice Rossi, Frank-Michael Schleif","In recent years the applications of machine learning models have increased rapidly, due to the large amount of available data and technological progress.  While some domains like web analysis can benefit from this with only minor restrictions, other fields like in medicine with patient data are stronger regulated. In particular \emph{data privacy} plays an important role as recently highlighted by the trustworthy AI initiative of the EU or general privacy regulations in legislation.  Another major challenge is, that the required training \emph{data is} often \emph{distributed} in terms of features or samples and unavailable for classical batch learning approaches. In 2016 Google came up with a framework, called \emph{Federated Learning} to solve both of these problems. We provide a brief overview on existing Methods and Applications in the field of vertical and horizontal \emph{Federated Learning}, as well as \emph{Fderated Transfer Learning}.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-4
2021,Privacy-Preserving Kernel Computation For Vertically Partitioned Data,"Mirko Polato, Alberto Gallinaro, Fabio Aiolli","In this paper, we propose a secure and privacy-preserving technique for computing dot-product kernels on vertically distributed data. Our proposal is based on secure multi-party computation which provides theoretical guarantees on both security and privacy. We also provide a practical application of the method by adapting a kernel-based collaborative filtering technique to the federated setting. An extensive experimental evaluation shows the effectiveness of the proposed approach.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-152
2021,Decay Momentum for Improving Federated Learning,"Miguel Fernandes, Catarina Silva, Joel Arrais, Alberto Cardoso, Bernardete Ribeiro","We propose two novel Federated Learning (FL) algorithms based on decaying momentum (Demon): Federated Demon (FedDemon) and Federated Demon Adam (FedDemonAdam). In particular, we apply Demon to Momentum Stochastic Gradient Descent (SGD) and Adam in a Federated setting, which as shown to improve results in a centralized environment. We empirically show that FedDemon and FedDemonAdam have a faster convergence rate and performance improvements compared to state-of-the-art algorithms including FedAvg, FedAvgM and FedAdam.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-106
2021,Continual Learning at the Edge: Real-Time Training on Smartphone Devices,"Lorenzo Pellegrini, Vincenzo Lomonaco, Gabriele Graffieti, Davide Maltoni","On-device training for personalized learning is a challenging research problem. Being able to quickly adapt deep prediction models at the edge is necessary to better suit personal user needs. However, adaptation on the edge poses some questions on both the efficiency and sustainability of the learning process and on the ability to work under shifting data distributions. Indeed, naively fine-tuning a prediction model only on the newly available data results in catastrophic forgetting, a sudden erasure of previously acquired knowledge. In this paper, we detail the implementation and deployment of a hybrid continual learning strategy (AR1*) on a native Android application for real-time on-device personalization without forgetting. Our benchmark, based on an extension of the CORe50 dataset, shows the efficiency and effectiveness of our solution.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-136
2021,Inductive learning for product assortment graph completion,"Marco Trincavelli, Haris Dukic, Georgios Deligiorgis, Pierpaolo Sepe, Davide Bacciu","Global retailers have assortments that contain hundreds of thousands of products that can be linked by several types of relationships like style compatibility, ""bought together"", ""watched together"", etc. Graphs are a natural representation for assortments, where products are nodes and relations are edges. Relations like style compatibility are often produced by a manual process and therefore do not cover uniformly the whole graph. We propose to use inductive learning to enhance a graph encoding style compatibility of a fashion assortment, leveraging rich node information comprising textual descriptions and visual data. Then, we show how the proposed graph enhancement improves substantially the performance on transductive tasks with a minor impact on graph sparsity.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-73
2021,Transformers for Molecular Graph Generation,"Tim Cofala, Oliver Kramer","This work introduces an autoregressive generative model for graphs which is based on the transformer architecture and applied to the domain of molecular graph generation. Utilizing the multi-head self-attention mechanism to  directly model distributions over atoms and bonds, it can sample new molecular graphs in an autoregressive manner. The benchmark framework MOSES is used to compare the proposed approach to other state-of-the-art molecule generation models.  It is shown that the model is capable of generalizing from the training data to generate novel and realistic molecules.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-112
2021,Tangent Graph Convolutional Network,"Luca Pasa, Nicolò Navarin, Alessandro Sperduti","Most Graph Convolutions (GCs) proposed in the Graph Neural Networks (GNNs) literature share the principle of computing topologically enriched node representations based on the ones of their neighbors. In this paper, we propose a novel GNN named Tangent  Graph Convolutional Network (TGCN) that, in addition to the traditional GC approach, exploits a novel GC that computes node embeddings based on the differences between the attributes of a vertex and the attributes of its neighbors. This allows the GC to characterize each node's neighbor by computing its tangent space representation with respect to the considered vertex.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-143
2021,Application of Graph Convolutions in a Lightweight Model for Skeletal Human Motion Forecasting,"Luca Hermes, Barbara Hammer, Malte Schilling",Prediction of movements is essential for successful cooperation with intelligent systems. We propose a model that integrates organized spatial information as given through the moving body's skeletal structure. This inherent structure is exploited in our model through application of Graph Convolutions and we demonstrate how this allows leveraging the structured spatial information into competitive predictions that are based on a lightweight model that requires a comparatively small number of parameters.,Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-145
2021,Improving Graph Variational Autoencoders with Multi-Hop Simple Convolutions,"Erik Jhones Freitas do Nascimento, Amauri Souza, Diego  Mesquita","Variational auto-encoding architectures represent one of the most popular approaches to graph generative modeling. These models comprise encoder and a decoder networks, which map back and forth between the input and latent spaces. Notably, most of the literature in variational autoencoders (VAEs) for graphs focuses on developing more efficient architectures at the expense of increased complexity. In this work, we pursue an orthogonal direction and leverage multi-hop linear graph convolutional layers to create efficient yet simple encoders, boosting the performance of graph autoencoders. Our results demonstrate that our approach outperforms popular graph VAE baselines in link prediction tasks.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-147
2021,Dynamic Graph Echo State Networks,"Domenico Tortorella, Alessio Micheli","Dynamic temporal graphs represent evolving relations between entities, e.g. interactions between social network users or infection spreading. We propose an extension of graph echo state networks for the efficient processing of dynamic temporal graphs, with a sufficient condition for their echo state property, and an experimental analysis of reservoir layout impact. Compared to temporal graph kernels that need to hold the entire history of vertex interactions, our model provides a vector encoding for the dynamic graph that is updated at each time-step without requiring training. Experiments show accuracy comparable to approximate temporal graph kernels on twelve dissemination process classification tasks.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-70
2021,Deep learning for graphs,"Davide Bacciu, Filippo Maria Bianchi, Benjamin Paassen, CesareC Alippi","Deep learning for graphs encompasses all those models endowed with multiple layers of abstraction, which operate on data represented as graphs. The most common building blocks of these models are graph encoding layers, which compute a vector embedding for each node in a graph based on a sum of messages received from its neighbors. However, the family also includes architectures with decoders from vectors to graphs and models that process time-varying graphs and hypergraphs. In this paper, we provide an overview of the key concepts in the field, point towards open questions, and frame the contributions of the ESANN 2021 special session into the broader context of deep learning for graphs.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-5
2021,Domain Adversarial Tangent Learning Towards Interpretable Domain Adaptation,"Christoph Raab, Sascha Saralajew, Frank-Michael Schleif","Deep learning struggles to generalize well to an unseen target domain of interest. Current domain adaptation methods simultaneously learn a classifier and an adversarial game for invariant representations but inadequately align local structures, while the underlying process is hard to interpret. We propose a new interpretable adversarial domain architecture, matching local manifold approximations across domains. Evaluated against related networks, the approach is competitive, while the adaptation process can be visually verified.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-103
2021,Transfer learning in Bayesian optimization for the calibration of a beam line in proton therapy,"Valentin Hamaide, François Glineur","Bayesian optimization (BO) is a type of black-box method used to optimize a costly objective function for which we have no access to derivatives. In practice, it is frequent that a series of similar problems has to be solved, with the problem data changing moderately between instances. We investigate a transfer learning approach based on BO that reuses information from a previous configuration in order to speed up subsequent optimizations. Our approach involves learning the noise variance to apply to the function values of the previous configuration and adapting the exploration-exploitation trade-off of the acquisition function from the previous configuration. We apply those ideas to the calibration of a beam line in proton therapy where the goal is to find magnet currents to obtain a desired shape for the beam of protons, and for which the calibration has to be repeated for several configurations. We show that reusing information from a previous configuration allows a reduction in the number of iterations by more than 80\%, and that using BO is superior to the conventional Nelder-Mead algorithm for black box optimization and transfer learning.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-79
2021,Sample efficient localization and stage prediction with autoencoders,"Sebastian Hoch, Sascha Lange, Janis Keuper","Engineering, construction and operation of complex machines involves a wide range of complicated, simultaneous tasks, which potentially could be automated. In this work, we focus on perception tasks in such systems, investigating deep learning approaches for multi-task transfer learning with limited training data. We show an approach that takes advantage of a technical systems' focus on selected objects and their properties. We create focused representations and simultaneously solve joint objectives in a system through multi-task learning with convolutional autoencoders. The focused representations are used as a starting point for the data-saving solution of the additional tasks. The efficiency of this approach is demonstrated using images and tasks of an autonomous circular crane with a grapple.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-24
2021,Lifelong Learning from Event-based Data,"Vadym Gryshchuk, Cornelius Weber, Chu Kiong Loo, Stefan Wermter","Lifelong learning is a long-standing aim for artificial agents that act in dynamic environments, in which an agent needs to accumulate knowledge incrementally without forgetting previously learned representations. We investigate methods for learning from data produced by event cameras and compare techniques to mitigate forgetting while learning incrementally. We propose a model that is composed of both, feature extraction and continuous learning. Furthermore, we introduce a habituation-based method to mitigate forgetting. Our experimental results show that the combination of different techniques can help to avoid catastrophic forgetting while learning incrementally from the features provided by the extraction module.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-146
2021,Enhash: A Fast Streaming Algorithm For Concept Drift Detection,"Aashi Jindal, Prashant Gupta, Debarka Sengupta, Jayadeva Jayadeva","We propose Enhash, a fast ensemble learner that detects concept drift in a data stream. A stream may consist of abrupt, gradual, virtual, or recurring events, or a mixture of various types of drift. Enhash employs projection hash to insert an incoming sample. Benchmark tests on 6 artificial and 4 real data sets consisting of various types of drift show that Enhash is competitive with state-of-the-art ensemble learners while being significantly faster. It also has moderate resource requirements.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-43
2021,Unsupervised Word Representations Learning with Bilinear Convolutional Network on Characters,"Thomas Luka, Laure Soulier, David Picard","In this paper, we propose a new unsupervised method for learning word embedding with raw characters as input representations, bypassing the problems arising from the use of a dictionary. To achieve this purpose, we translate the distributional hypothesis into a unsupervised metric learning objective, which allows to consider only an encoder instead of an encoder-decoder architecture. We propose to use a convolutional neural network with bilinear product blocks and residual connections to encode co-occurrences patterns.  We show the efficiency of our approach by comparing it with classical word embedding methods such as fastText and GloVe on several benchmarks.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-38
2021,End-to-end Keyword Spotting using Xception-1d,"Juan Gómez-Sanchis, Juan Gómez-Sanchis, Marcelino Martinez-Sober, Joan Vila-Francés, Antonio-José Serrano López, Emilio Soria Olivas","The field of conversational agents is growing fast and there is an increasing need for algorithms that enhance natural interaction. In this work we show how we achieved state of the art results in the Keyword Spotting field by adapting and tweaking the Xception algorithm, which achieved outstanding results in several computer vision tasks. We obtained about 96\% accuracy when classifying audio clips belonging to 35 different categories, beating human annotation at the most complex tasks proposed.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-21
2021,Weightless Neural Networks for text classification using tf-idf,"Antonio Sorgente, Massimo De Gregorio, Giuseppe Vettigli","While Weightless Neural Networks (WNN) have been proven effective in Natural Language Processing (NLP) applications, they require the use of highly customized features as they work on binary inputs.  However, recent advancements have brought methodologies able to adapt WNN to real numbers showing competitive results on many classification tasks, but they often struggle on sparse data.  In this paper, we show that WNN can successfully use sparse linguistic features, like tf-idf, using appropriate transformations.  We also show that WNN can be used to improve the performances of existing models for Mixed Language Sentiment Analysis and that it has competitive performances for news categorization.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-58
2021,Emotional Intensity Level Analysis of Speech Emotional Intensity Estimation,Megumi Kawase,"An estimation procedure using three models to determine the appropriate emotional intensity from the 10 listed emotional intensity classes for utterances has been developed in order to support better communication between humans and machines. In order to improve estimation performance, utterances were divided into segments and an estimated emotional intensity and its probability were produced as outputs. Two feature vectors were produced from the outputs and these features were used for the utterance-level classification using Support Vector Machine and Random Forest techniques. In the results, the accuracy of emotional intensity estimation in two out of three models was improved using the procedure proposed. In addition, features which contributed to the estimations were analyzed.",Machine Learning for Measuring and Analyzing Online Social Communications,https://doi.org/10.14428/esann/2021.ES2021-118
2021,Toxicity Detection in Online Comments with Limited Data: A Comparative Analysis,"Max Lübbering, Maren Pielka, Kajaree Das, Michael Gebauer, Rajkumar Ramamurthy, Christian Bauckhage, Rafet Sifa","We present a comparative study on toxicity detection, focusing on the problem of identifying toxicity types of low prevalence and possibly even unobserved at training time. For this purpose, we train our models on a dataset that contains only a weak type of toxicity, and test whether they are able to generalize to more severe toxicity types. We find that representation learning and ensembling exceed the classification performance of simple classifiers on toxicity detection, while also providing significantly better generalization and robustness. All models benefit from a larger training set size, which even extends to the toxicity types unseen during training.",Machine Learning for Measuring and Analyzing Online Social Communications,https://doi.org/10.14428/esann/2021.ES2021-48
2021,Machine Learning for Measuring and Analyzing Online Social Communications,"Chris Bronk, Amaury Lendasse, Peggy Lindner, Dan S. Wallach, Barbara Hammer","In this paper, we propose a framework for application of a novel machine learning-based system for analyzing online social communications. As a example, we are targeting anti-Semitic graphical memes posted to social media. We presented very promising preliminary results on a Facebook dataset that consists of a total of 10000 labeled memes. We can conclude that machine learning will soon be able to successfully analyze and monitor complex social communications.",Machine Learning for Measuring and Analyzing Online Social Communications,https://doi.org/10.14428/esann/2021.ES2021-3
2021,Temperature as a Regularizer for Semantic Segmentation,"Chanho Kim, Won-Sook Lee","A data-oriented approach including all deep learning methods is usually suffered by overfitting. A regularizer has been, from the beginning, introduced to resolve this problem. Inspired by Generative Adversarial Network (GAN), our framework generates the adversarial loss to penalize a segmentation model like a regularizer. We introduce temperature as a regularizer when calculating Least-Square losses. Temperature affects losses in both a discriminator and a generator in our DCGAN framework. Our experiment suggests L2 losses on top of the original LSGAN losses for optimization. This new regularizer using temperature improves semantic segmentation accuracy both in Pixel accuracy and mean Intersection-of Union.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-158
2021,Object Detection on Thermal Images: Performance of YOLOv4 Trained on Small Datasets,"Maxence Chaverot, Maxime Carré, Michel Jourlin, Abdelaziz Bensrhair, Richard Grisel","Thermal sensors are underrepresented in the field of Advanced Driver-Assistance Systems whereas their capabilities to acquire images independently of weather or daytime can be very helpful to achieve optimal pedestrian and vehicle detection. This underrepresentation is due to the small amount of available public datasets. This lack of training samples, and the difficulties of building such datasets are a real hurdle to the development of an object detector dedicated to thermal images. Thanks to YOLOv4 and its detection performance, we show in this paper that fine-tuning this neural network requires few samples to achieve satisfying performance, outperforming the results of state-of-the-art detectors.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-130
2021,Fourier-based Video Prediction through Relational Object Motion,"Malte Mosbach, Sven Behnke","The ability to predict future outcomes conditioned on observed video frames is crucial for intelligent decision-making in autonomous systems. Recently, deep recurrent architectures have been applied to the task of video prediction. However, this often results in blurry predictions and requires tedious training on large datasets. Here, we explore a different approach by (1) using frequency-domain approaches for video prediction and (2) explicitly inferring object-motion relationships in the observed scene. The resulting predictions are consistent with the observed dynamics in a scene and do not suffer from blur.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-125
2021,Cross-modal verification for 3D object detection,"Haodi ZHANG, Alexandrina Rogozan, Abdelaziz Bensrhair","To overcome the deficiency in the single modality of LiDAR point cloud, we propose a cross-modal verification (CMV) model for reducing 3D object detection false positives. The abundant color and texture information in image modality allow the classification of the projection region of 3D bounding box proposal in the image plane. Three 3D object detectors are adopted as backbone and eight evaluation metrics are used to fully investigate the proposed model. The experiment results show that the proposed CMV model removes more than 50\% of false positives in 3D object detection proposals and significantly improves the performance of 3D object detection.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-97
2021,Improved and Generalized Vine Line Detection on Aerial Images Using Asymmetrical Neural Networks and ML Subclassifiers,"Jérôme Treboux, Rolf Ingold, Dominique Genoud","It is widely accepted that deep neural networks are very effi- cient for detecting objects in images. They reach their limit when detect- ing multiple instances of long lines in low-resolution images. We present an original methodology for the recognition of vine lines in low-resolution satellite images. The method consists in combining an asymmetrical neural network with a sub-classifier. We first compare a traditional U-Net archi- tecture with an asymmetrical U-Net architecture designed for precision agriculture. We then highlight the significant improvement in vine line detection when a Random Forest is added after the customized U-Net. This methodology addresses the complex task of dissociating vine lines from other agricultural objects. As a result, our experiments improve the precision from 0.83 to 0.94 over our optimized neural network.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-68
2021,Enhancing brain decoding using attention augmented deep neural networks,"Ismail  Alaoui Abdellaoui, Jesús García Fernández, Caner  Sahinli, Siamak Mehrkanoon","Neuroimaging techniques have shown to be valuable when studying brain activity. This paper uses Magnetoencephalography (MEG) data, provided by the Human Connectome Project (HCP), and different deep learning models to perform brain decoding. Specifically, we investigate to which extent one can infer the task performed by a subject based on its MEG data. In order to capture the most relevant features of the signals, self and global attention are incorporated into our models. The obtained results show that the inclusion of attention improves the performance and generalization of the models across subjects.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-67
2021,CAS-Net: A Novel Coronary Artery Segmentation Neural Network,"Rawaa Hamdi, Asma Kerkeni, Mouhamed hédi Bedoui, Asma Ben Abdallah","In conventional X-ray coronary angiography, accurate coronary artery segmentation is a crucial and challenging step in the assessment of coronary artery disease. In this paper, we propose a new architecture (CAS-Net) for coronary artery segmentation. It is based on Residual U-Net and it includes both channel and spatial attention mechanism in the center part to generate hierarchical rich features of coronary arteries. Experiments are conducted on a private dataset of 150 images. The results show that CAS-Net outperforms the state-of-the-art method achieving the highest accuracy of 96.91% and Dice of 82.70%.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-157
2021,Data-Efficient Training of High-Resolution Images in Medical Domain,"Shruti Kunde, Amey Pandit, Kushagra Mahajan, Monika Sharma, Rekha  Singhal, Lovekesh Vig","The ability of Graphical Processor Units (GPUs) to quickly train dataand compute-intensive deep networks has led to rapid advancements across diverse domains such as robotics, medical imaging and autonomous driving. However, memory constraints with GPU-based training for memory-intensive deep networks have forced researchers to adopt various workarounds: 1) resize the input image, 2) divide input image into smaller patches, or use smaller batch-sizes in order to fit both the model and batch training data into GPU memory.While these alternatives perform well when dealing with natural images, they suffer from 1) loss of highresolution information, 2) loss of global context and 3) sub-optimal batch sizes. Such issues will likely to become more pressing for domains like medical imaging, where data is scarce and images are often of very high resolution with subtle features. Therefore, in this paper, we demonstrate that training can be made more data-efficient by using a distributed training setup with high-resolution images and larger effective batch sizes, with batches being distributed across multiple nodes. The distributed GPU training framework, which partitions the data and only shares model parameters across different GPUs, gets around the memory constraints of single GPU training. We conduct a study in which experiments are performed for different image resolutions (ranging from 112112 to 10241024) and different number of images per class to determine the effect of image resolutions on network performance. We illustrate our findings on two medical imaging datasets namely, SD-198 skin-lesion and NIH Chest X-rays.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-57
2021,Comprehensive Analysis of the Screening of COVID-19 Approaches in Chest X-ray Images from Portable Devices,"Daniel Iglesias, Joaquim de Moura, Jorge Novo, Marcos Ortega","Computer-aided diagnosis plays an important role in the COVID-19 pandemic. Currently, it is recommended to use X-ray imaging to diagnose and assess the evolution in patients. Particularly, radiologists are asked to use portable acquisition devices to minimize the risk of cross-infection, facilitating an effective separation of suspected patients with other low-risk cases. In this work, we present an automatic COVID-19 screening, considering 6 representative state-of-the-art deep network architectures on a portable chest X-ray dataset that was specifically designed for this proposal. Exhaustive experimentation demonstrates that the models can separate COVID-19 cases from NON-COVID-19 cases, achieving a 97.68% of global accuracy.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-31
2021,Correlated Weights Neural Layer with external control,Slawomir Golak,"The correlated weights neural layer is a generalization of the convolutional layer constituting the core of CNN networks. The CWNL layer takes advantage of weights correlated with coordinates of a neuron and its inputs, calculated by a dedicated neural subnet. In this work, a modified CWNL layer is proposed, which allows the parameterized spatial manipulation (and any other global transformation) of a pattern. The externally controlled CWNL layer can be used in existing neural network architectures, giving them the ability of internal pattern transformation without any modification of the training process.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-26
2021,"Complex Data: Learning Trustworthily, Automatically, and with Guarantees","Luca Oneto, Nicolò Navarin, Battista Biggio, Federico Errica, Alessio Micheli, Franco Scarselli, Monica Bianchini, Alessandro Sperduti","Machine Learning (ML) achievements enabled automatic extraction of actionable information from data in a wide range of decision-making scenarios. This demands for improving both ML technical aspects (e.g., design and automation) and human-related metrics (e.g., fairness, robustness, privacy, and explainability), with performance guarantees at both levels. The aforementioned scenario posed three main challenges: (i) Learning from Complex Data (i.e., sequence, tree, and graph data), (ii) Learning Trustworthily, and (iii) Learning Automatically with Guarantees. The focus of this special session is on addressing one or more of these challenges with the final goal of Learning Trustworthily, Automatically, and with Guarantees from Complex Data.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-6
2021,Density Independent Self-organized Support for Q-Value Function Interpolation in Reinforcement Learning,"Antonin Calba, Alain Dutech, Jeremy Fix","In this paper, we propose a contribution in the field of Reinforcement Learning (RL)  with continuous state space. Our work is along the line of previous works involving a vector quantization algorithm for learning the state space representation on top of which a function approximation takes place. In particular, our contribution compares the performances of the Kohonen SOM and the Rougier DSOM with the Göppert function approximation scheme on both the mountain car problem. We give a particular focus to DSOM as it is less sensitive to the density of inputs and opens interesting perspectives in RL.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-62
2021,Multiobjective Reinforcement Learning in Optimized Drug Design,"Maryam Abbasi, Tiago Pereira, Beatriz P. Santos, Bernardete Ribeiro, Joel Arrais","Machine learning has been increasingly applied with successes in generating synthetically reasonable molecules. However, a complete system capable of both producing valid molecules and optimizing multiple traits has remained elusive. This paper employs multiobjective reinforcement learning to draw a framework to design compounds. Different multiobjective techniques have been evaluated, such as weighted sum and Chebyshev. The results show that the implemented model can be effectively optimized towards different and competing molecular properties. Nonetheless, the model implemented with the weighted sum scalarization technique with a weight of 0.55 for biological affinity is the one with the most appropriate trade-off for the different evaluated properties.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-87
2021,Behavior Constraining in Weight Space for Offline Reinforcement Learning,"Phillip Swazinna, Steffen Udluft, Daniel Hein, Thomas Runkler","In offline reinforcement learning, a policy needs to be learned from a single pre-collected dataset. Typically, policies are thus regularized during training to behave similarly to the data generating policy, by adding a penalty based on a divergence between action distributions of generating and trained policy. We propose a new algorithm, which constrains the policy directly in its weight space instead, and demonstrate its effectiveness in experiments.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-83
2021,Deep Learning Model for Context-Dependent Survival Analysis,"Raphaël Langhendries, Jérôme Lacaille","In this article, we introduce a deep learning model (denoted thereafter \emph{DCM: Deep Contextual Model}) for survival analysis able of predicting the probability that a subject meets an \emph{event of interest} according to its past life. The subject and the \emph{event of interest} can be diverse depending on the field of application, thus the model can be applied in various contexts. We present an application in the aerospace field that consists in forecasting hot corrosion in turbofan.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-49
2021,Echo-state neural networks forecasting steelworks off-gases for their dispatching in CH4 and CH3OH syntheses reactors,"Ismael Matino, Stefano Dettori, Valentina Colla, Katharina Rechberger, Nina Kieberger","In the era of European Green Deal, steelworks are committed to reduce their CO2 emissions by preserving their competitiveness. One of the options to achieve such aim is the valorization of process off gases. Methane and Methanol production can be obtained by coupling novel reactors with an advanced control system that dispatches these gases after enrichment with green hydrogen. Knowing in advance the gases availability and composition is fundamental. The paper present Echo State Networks based-models that are applied to this aim and achieve adequate forecasting accuracy also in case of highly dynamic processes.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-41
2021,An Algorithmic Approach to Establish a Lower Bound for the Size of Semiring Neural Networks,"Martin Böhm, Thomas Schmid","Semiring neural networks have been introduced as a recurrent neural network-type representation of weighted automata with the potential to learn a recognizable series. Whether a given semiring neural network actually can or cannot compute a recognizable series, however, depends on the size of the network. Therefore, it is desirable to determine whether a proposed size is too small before initiation of the training procedure. Here, we present an algorithm that achieves this in polynomial time. As there is a one-to-one correspondence between semiring neural networks and weighted automata, our algorithm can also be used to derive lower bounds for the size of a recognizing automaton. Our algorithm complements previous work in this area as it works over commutative zero-sum-free semirings.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-33
2021,Deep Echo State Networks for Functional Ambulation Categories Estimation,"Luca Pedrelli, Marco Tramontano, Giuseppe Vannozzi, Andrea Mannini","In this work, we introduce a novel application for the automatic estimation of Functional Ambulatory Category (FAC) based on deep Echo State Networks (ESNs). FAC is a clinical scale for assessing the gait ability used in post-stroke rehabilitation and, in general, for disease monitoring. In this application, the estimation is performed automatically by analyzing signals gathered from wearable sensors (located on both tibiae, pelvis, trunk and head) during the execution of a walking test. This is performed by analysing the whole time series through the DeepESN model without preprocessing. The experimental results show that the use of a deep recurrent neural network allows the model to exploit the richness contained in the whole raw temporal signal improving the performance w.r.t. the shallow recurrent model. Overall, our approach obtained 0.37 of mean absolute error with a maximum error of 0.78 resulting very accurate in the classification of the gait ability through the estimation of the FAC value. Considering the experimental results obtained, the proposed approach represents a good baseline for medical applications based on the automatic estimation of the FAC scale.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-149
2021,Constraint optimization for Echo State Networks applied to satellite image forecasting,"Jochen J. Steil, Yannic Lieder","The paper proposes  to deal with noisy, sparse or short training data sequences by adding domain knowledge to the learning process of Echo State Networks (ESNs). Known constraints like monotony in the output, periodicity or bounds on output values are encoded as inequality constraints on the output weights to be learned. Exploiting that the output of an ESN is linear in the weights, Quadratic  Programming is then used to obtain optimize these.  The method is applied to the prediction of pixel values from monthly, noisy   satellite images of a short history of five years, thereby enabling cleaning of images from   clouds or snow.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-135
2021,Reservoir Computing by Discretizing ODEs,Claudio Gallicchio,"We draw connections between Reservoir Computing (RC) and Ordinary Differential Equations, introducing a novel class of models called Euler State Networks (EuSNs). The proposed approach is featured by system dynamics that are both stable and non-dissipative, hence enabling an effective transmission of input signals over time. At the same time, EuSN is featured by untrained recurrent dynamics, preserving all the computational advantages of RC models. Through experiments on several benchmarks for time-series classification, we empirically show that EuSN can substantially narrow the performance gap between RC and fully trainable recurrent neural networks.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-101
2021,Improvement on Generative Adversarial Network for Targeted Drug Design,"Beatriz P. Santos, Maryam Abbasi, Tiago Pereira, Bernardete Ribeiro, Joel Arrais","This paper provides a generative network framework that can replicate the molecular space distribution to satisfy a set of desirable features. The approach incorporates two effective machine learning techniques:  an Encoder-Decoder architecture that converts the string notations of molecules into latent space and a generative adversarial network to learn the data distribution and generate new compounds. We train this joint model on a dataset that includes stereo-chemical information. The results show an improvement in the Encoder-Decoder performance, reaching 89% of correctly reconstructed molecules. The framework can generate a wide variety of compounds biased towards specific molecular properties using Transfer Learning.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-96
2021,RecLVQ: Recurrent Learning Vector Quantization,"Jensun Ravichandran, Thomas Villmann, Marika Kaden","Learning Vector Quantizers (LVQ) and its cost-function- based variant called Generalized Learning Vector Quanitzation (GLVQ) are powerful, yet simple and interpretable classification models. Even though GLVQ is an effective tool for classifying vectorial data, it can- not handle raw sequence data of potentially different lengths. Usually, this problem is solved by manually engineering fixed-length features or by employing recurrent networks. Therefore, a natural idea is to incorporate recurrent units for data processing into the GLVQ network structure. The processed data can then be compared in a latent space for classification decisions. We demonstrate the ability of this approach on illustrative classification problems.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-90
2021,Continual Learning with Echo State Networks,"Andrea Cossu, Davide Bacciu, Antonio Carta, Claudio Gallicchio, Vincenzo Lomonaco","Continual Learning (CL) refers to a learning setup where data is non stationary and the model has to learn without forgetting existing knowledge. The study of CL for sequential patterns revolves around trained recurrent networks. In this work, instead, we introduce CL in the context of Echo State Networks (ESNs), where the recurrent component is kept fixed. We provide the first evaluation of catastrophic forgetting in ESNs and we highlight the benefits in using CL strategies which are not applicable to trained recurrent models. Our results confirm the ESN as a promising model for CL and open to its use in streaming scenarios.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-80
2021,Towards Robust Auxiliary Tasks for Language Adaptation,"Gil Rocha, Henrique Lopes Cardoso","To overcome the lack of annotated resources in less-resourced languages, unsupervised language adaptation methods have been explored.  Based on multilingual word embeddings, Adversarial Training has been successfully employed in a variety of tasks and languages.  With recent neural language models, empirical analysis on the task of natural language inference suggests that more challenging auxiliary tasks for Adversarial Training should be formulated to further improve language adaptation.  We propose rethinking such auxiliary tasks for language adaptation.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-134
2021,Sparse mixture of von Mises-Fisher distribution,"Florian Barbaro, Fabrice Rossi",Mixtures of von Mises-Fisher distributions can be used to cluster data on the unit hypersphere. This is particularly adapted for high-dimensional directional data such as texts. We propose in this article to estimate a von Mises mixture using a $l_1$ penalized likelihood. This leads to sparse prototypes that improve both clustering quality and interpretability. We introduce an expectation-maximisation (EM) algorithm for this estimation and show the advantages of the approach on real data benchmark. We propose to explore the trade-off between the sparsity term and the likelihood one with a simple path following algorithm.,Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-115
2021,TSR-DSAW: Table Structure Recognition via Deep Spatial Association of Words,"Arushi Jain, Shubham Paliwal, Monika Sharma, Lovekesh Vig","Existing  methods  for  Table  Structure  Recognition  (TSR) from camera-captured or scanned documents perform poorly on complex-tables consisting of nested rows / columns,  multi-line texts and missing cell  data.   This  is  because  current  data-driven  methods  work  by  simply training deep models on large volumes of data and fail to generalize when an  unseen  table  structure  is  encountered.   In  this  paper,  we  propose  to train a deep network to capture the spatial associations between different word pairs present in the table image for unravelling the table structure. We  present  an  end-to-end  pipeline,  named TSR-DSAW: TSR via Deep Spatial Association of Words, which outputs a digital representation of a table image in a structured format such as HTML. Given a table image as input, the proposed method begins with the detection of all the words present  in  the  image  using  a  text-detection  network  like  CRAFT  which is followed by the generation of word-pairs using dynamic programming. These word-pairs are highlighted in individual images and subsequently, fed into a DenseNet-121 classifier trained to capture spatial associations such as same-row,  same-column,  same-cell or none.  Finally,  we perform post-processing on the output of the word-association classifier to generate  the  table  structure  in  HTML  format.   We  evaluate  our  TSR-DSAW pipeline on two publicly available table-image datasets - PubTabNet and ICDAR 2013, and demonstrate improvement over previous methods suchas TableNet and DeepDeSRT.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-109
2021,Combining Attack Success Rate and DetectionRate for effective Universal Adversarial Attacks,"Valentina Poggioni, Alina Elena Baia, Alfredo Milani","In the framework of Adversarial Machine Learning, several detection and protection techniques are used to characterize specific attack-defense scenarios. In this paper, we present universal, unrestricted black-box adversarial attacks based on a multi-objective nested evolutionary algorithm able to incorporate the detection rate and a measure of image quality into the attack building phase.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-160
2021,Semi-supervised learning with Bayesian Confidence Propagation Neural Network,"Naresh Balaji Ravichandran, Anders  Lansner,  Pawel Herman","Learning internal representations from data using no or few labels is useful for machine learning research, as it allows using massive amounts of unlabeled data. In this work, we use the Bayesian Confidence Propagation Neural Network (BCPNN) model developed as a biologically plausible model of the cortex. Recent work has demonstrated that these networks can learn useful internal representations from data using local Bayesian-Hebbian learning rules. In this work, we show how such representations can be leveraged in a semi-supervised setting by introducing and comparing different classifiers. We also evaluate and compare such networks with other popular semi-supervised classifiers.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-156
2021,Impact of data subsamplings in Fast Multi-Scale Neighbor Embedding.,"Pierre Lambert, Lee John, Michel Verleysen, Cyril de Bodt","Fast multi-scale neighbor embedding (f-ms-NE) is an algorithm that maps high-dimensional data to a low-dimensional space by preserving the multi-scale data neighborhoods. To lower its time complexity, f-ms-NE uses random subsamplings to estimate the data properties at multiple scales. To improve this estimation and study the f-ms-NE sensitivity to randomness, this paper generalizes the f-ms-NE cost function by averaging several subsamplings. Experiments reveal that this can slightly improve DR quality while maintaining reasonable computation times. Codes are available at https://github.com/cdebodt/Fast_Multi-scale_NE.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-60
2021,Validating static call graph-based malware signatures using community detection methods,"Attila Mester, Zalán Bodó","Due to the increasing number of new malware appearing daily, it is impossible to manually inspect each sample. By applying data mining techniques to analyze the program code, we can help manual processing. In this paper we propose a method to extract signatures from the executable binary of a malware, in order to query the local neighborhood in real time. The method is validated by applying community detection algorithms on the common fingerprint-based malware graph to identify families, and assessing these with evaluation metrics used in the field (e.g. modularity, family majority, etc.). The signatures are obtained via static code analysis, using function call n-grams and applying locality-sensitive hashing techniques to enable the match between functions with highly similar instruction lists.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-27
2021,Federated Learning approach for SpectralClustering,"Elena Hernández-Pereira, Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas, Beatriz Pérez Sánchez","Spectral clustering is a clustering paradigm that has been shown to be more effective in finding clusters with non-convex shapes than some traditional algorithms such as k-means. However, this algorithm is not directly applicable when the data is naturally distributed in different locations, as it happens in many Internet of Things scenarios. In this work, we propose a distributed spectral clustering to create a cooperative federated model to deal with those cases in which the data is distributed in different sites and with data privacy concerns. We demonstrate that sharing a minimal amount of information allows this distributed version of the spectral clustering to achieve good behavior for clustering several synthetic data sets.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-95
2021,Stochastic quartet approach for fast multidimensional scaling,"Pierre Lambert, Cyril de Bodt, Michel Verleysen, Lee John","Multidimensional scaling is a statistical process that aims to embed high-dimensional data into a lower-dimensional, more manageable space. Common MDS algorithms tend to have some limitations when facing large data sets due to their high time and spatial complexities. This paper attempts to tackle the problem by using a stochastic approach to MDS which uses gradient descent to optimise a loss function defined on randomly designated quartets of points. This method mitigates the quadratic memory usage by computing distances on the fly, and has iterations in O(N) time complexity, with N samples. Experiments show that the proposed method provides competitive results in reasonable time. Public codes are available at https://github.com/PierreLambert3/SQuaD-MDS.git.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-59
2021,Dynamic clustering and modeling of temporal data subject to common regressive effects,"Louise Bonfils, Allou Same, Latifa Oukhellou","Clustering is used in many applicative fields to summarize information into a small number of groups. Motivated by behavioral extraction issues from urban data, the interest of this paper is to propose a classification method that allows modeling the evolution of cluster profiles over time while considering common regressive effects. The parameters of the proposed model are estimated using variational approximation because maximum likelihood estimation is not suitable in this case. The ability of the model to estimate parameters is evaluated using various simulated data and compared with two other models.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-121
2021,Calliope - A Polyphonic Music Transformer,"Andrea Valenti, Stefano Berti, Davide Bacciu","The polyphonic nature of music makes the application of deep learning to music modelling a challenging task. On the other hand, the Transformer architecture seems to be a good fit for this kind of data. In this work,  we present Calliope, a novel autoencoder model based on Transformers for the efficient modelling of multi-track sequences of polyphonic music. The experiments show that our model is able to improve the state of the art on musical sequence reconstruction and generation, with remarkably  good results especially  on  long sequences.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-63
2021,Anomalous Cluster Detection in Large Networks with Diffusion-Percolation Testing,"Corentin Larroche, Johan Mazel, Stéphan Clémençon","We propose a computationally efficient procedure for elevated mean detection on a connected subgraph of a network with node-related scalar observations. Our approach relies on two intuitions: first, a significant concentration of high observations in a connected subgraph implies that the subgraph induced by the nodes associated with the highest observations has a large connected component. Secondly, a greater detection power can be obtained in certain cases by denoising the observations using the network structure. Numerical experiments show that our procedure’s detection performance and computational efficiency are both competitive.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-32
2021,Compact Neural Architecture Search for Local Climate Zones Classification,"Rene Traore, Andrés Camero, Xiaoxiang Zhu","State-of-the-art Computer Vision models achieve impressive performance but with an increasing complexity. Great advances have been made towards automatic model design, but accounting for model performance and low complexity is still an open challenge.  In this study, we propose a neural architecture search strategy for high performance low complexity classification models,  that combines an efficient search algorithm with mechanisms for reducing complexity. We tested our proposal on a real World remote sensing problem, the Local Climate Zone classification. The results show that our proposal achieves state-of-the-art performance, while being at least 91.8 more compact in terms of size and FLOPs.",Model selection,https://doi.org/10.14428/esann/2021.ES2021-55
2021,Pruning Neural Networks with Supermasks,"Vincent Rolfs, Matthias Kerzel, Stefan Wermter","The Lottery Ticket hypothesis by Frankle and Carbin states that a randomly initialized dense network contains a smaller subnetwork that,  when trained in isolation, will match the performance of the original network. However, identifying this pruned subnetwork usually requires repeated training to determine optimal pruning thresholds. We present a novel approach to accelerate the pruning: By methodically evaluating different Supermasks, the threshold for selecting neurons as part of a pruned Lottery Ticket network can be determined without additional training. We evaluate the method on the MNIST dataset and achieve a size reduction of over 60\% without a drop in performance.",Model selection,https://doi.org/10.14428/esann/2021.ES2021-126
2021,NNBMSS: a Novel and Fast Method for Model Structure Selection,"Amaury Lendasse, Kallin Khan, Edward Ratner","In this paper, we present a new method to perform model structure selection. This proposed method can be used to select the complexity of any continuous regression method. We also present an asymptotic mathematical proof of the proposed method and the new method is illustrated on a benchmark. Compared to the well-known 10-fold Cross-Validation, the computational time associated to our new method is approximately divided by a factor 8 as illustrated on the benchmark.",Model selection,https://doi.org/10.14428/esann/2021.ES2021-9
2021,Boundary-Based Fairness Constraints in Decision Trees and Random Forests,"Géraldin Nanfack, Valentin Delchevalerie, Benoit Frénay","Decision Trees (DTs) and Random Forests (RFs) are popular models in Machine Learning (ML) thanks to their interpretability and efficiency to solve real-world problems. However, DTs may sometimes learn rules that treat different groups of people unfairly, by paying attention to sensitive features like for example gender, age, income, language, etc. Even if several solutions have been proposed to reduce the unfairness for different ML algorithms, few of them apply to DTs. This work aims to transpose a successful method proposed by Zafar et al. to reduce the unfairness in boundary based ML models to DTs.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-69
2021,Robust Malware Classification via Deep Graph Networks on Call Graph Topologies,"Federico Errica, Giacomo Iadarola, Fabio Martinelli, Francesco Mercaldo, Alessio Micheli","We propose a malware classification system that is shown to be robust to some common intra-procedural obfuscation techniques. Indeed, by training the Contextual Graph Markov Model on the call graph representation of a program, we classify it using only topological information, which is unaffected by such obfuscations. In particular, we show that the structure of the call graph is sufficient to achieve good accuracy on a multi-class classification benchmark.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-82
2021,Slope: A First-order Approach for Measuring Gradient Obfuscation,"Maura Pintor, Luca Demetrio, Giovanni Manca, Battista Biggio, Fabio Roli","Evaluating adversarial robustness is a challenging problem. Many defenses have been shown to provide a false sense of security by unintentionally obfuscating gradients, hindering the optimization process of gradient-based attacks. Such defenses have been subsequently shown to fail against adaptive attacks crafted to circumvent gradient obfuscation. In this work, we present Slope, a metric that detects obfuscated gradients by comparing the expected and the actual increase of the attack loss after one iteration. We show that our metric can detect the presence of obfuscated gradients in many documented cases, providing a useful debugging tool towards improving adversarial robustness evaluations.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-99
2021,The Benefits of Adversarial Defence in Generalisation,"Luca Oneto, Sandro Ridella, Davide Anguita","Recent researches have been shown that models induced by machine learning, in particular by deep learning, can be easily fooled by an adversary who carefully crafts imperceptible, at least from the human perspective, or physically plausible modifications of the input data. This discovery gave birth to a new field of research, the adversarial machine learning, where new methods of attacks and defence are developed continuously, mimicking what is happening from long time in cybersecurity. In this paper we will show that the drawbacks of inducing models from data less prone to be misled actually provides some benefits when it comes to assess their generalisation abilities.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-28
2021,The Coming of Age of Interpretable and Explainable Machine Learning Models,"Paulo Lisboa, Sascha Saralajew, Alfredo Vellido, Thomas Villmann","Machine learning-based systems are now part of a wide array of real-world applications seamlessly embedded in the social realm. In the wake of this realisation, strict legal regulations for these systems are currently being developed, addressing some of the risks they may pose. This is the coming of age of the interpretability and explainability problems in machine learning-based data analysis, which can no longer be seen just as an academic research problem. In this tutorial, associated to ESANN 2021 special session on Interpretable  Models  in  Machine  Learning  and  Explainable  Artificial  Intelligence, we discuss explainable and interpretable machine learning as post-hoc and ante-hoc strategies to address these problems and highlight several aspects related to them, including their assessment. The contributions accepted for the session are then presented in this context.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-2
2021,A Multi-ELM Model for Incomplete Data,"Baichuan Chi, Amaury Lendasse, Edward Ratner, Renjie Hu","This paper presents a novel model of Extreme Learning Machines (ELMs) for incomplete data. ELMs are fast accurate randomized neu- ral networks. Nevertheless ELM can only be applied on the complete dataset. Therefore, a novel Multi-ELM Model for incomplete data is pro- posed, consisting of multiple secondary ELMs and one primary ELM. The secondary ELMS are approximating the hidden layer output in the primary ELM for the data with missing values. As summarized in the experimental Section, this model can be applied on data with any missing patterns, without using imputations and can outperform the traditional imputation methods within a reasonable fraction of missing values (0% to 20%), as it avoids the noises intruded by imputations.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-162
2021,Estimating Formulas for Model Performance Under Noisy Labels Using Symbolic Regression,"Fech Scen  Khoo, Dawei Zhu, Michael A. Hedderich , Dietrich Klakow","We present a generic formula characterizing the learning of our model under a variety of label-noise settings. This is achieved by using the symbolic regressor model, a genetic programming algorithm, from which we learn functions based on a large set of performance evaluations. Equipped with the knowledge from the regressor, we find a universal formula governing the model performance with respect to noise. This result from our empirical approach could have qualitative applications in mitigating the performance of real-world noisy data and could complement certain noise-robust models.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-65
2021,Orientation Adaptive Minimal Learning Machine for Directions of Atomic Forces,"Antti Pihlajamäki, Joakim Linja, Joonas Hämäläinen, Paavo Nieminen, Sami Malola, Tommi Kärkkäinen, Hannu Häkkinen","Machine learning (ML) force fields are one of the most common applications of ML in nanoscience. However, commonly these methods are trained on potential energies of atomic systems and force vectors are omitted. Here we present a ML framework, which tackles the greatest difficulty on using forces in ML: accurate prediction of force direction. We use the idea of Minimal Learning Machine to device a method which can adapt to the orientation of an atomic environment to estimate the directions of force vectors. The method was tested with linear alkane molecules.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-34
2021,Distribution Preserving Multiple Hypotheses Prediction for Uncertainty Modeling,"Tobias Leemann, Moritz Sackmann, Jörn Thielecke, Ulrich Hofmann","Many supervised machine learning tasks, such as future state prediction in dynamic systems, require precise modeling of a forecast’s uncertainty. The Multiple Hypotheses Prediction (MHP) approach addresses this problem by providing several hypotheses that represent possible outcomes. Unfortunately, with the common l2 loss function, these hypotheses do not preserve the data distribution’s characteristics.We propose an alternative loss for distribution preserving MHP and review relevant theorems supporting our claims. Furthermore, we empirically show that our approach yields more representative hypotheses on a synthetic and a real-world motion prediction data set. The outputs of the proposed method can directly be used in sampling-based Monte-Carlo methods.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-16
2021,Hierarchical Planning in Multilayered State-Action Networks,"Matthias Brucklacher, Hanspeter A.  Mallot, Tristan Baumann","The ability to decompose large tasks into smaller subtasks allows humans to solve complex problems step-by-step. To transfer this ability to an automated system, we propose a spiking neural network inspired by the neurobiological mechanics of spatial cognition to represent space on multiple levels of abstraction. As behavioral experiments suggest that humans integrate spatial knowledge in a graph of places, neurons in the state-action network encode locations while connections between them represent transition actions. In a series of simulation experiments, the influence of hierarchy on planning speed and on the resulting route choice in comparison to single-level models is investigated. We find that the model chooses biased subgoals in line with experiments on human navigation.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-45
2021,Estimating uncertainty in radiation oncology dose prediction with dropout and bootstrap in U-Net models,"Lee John, Alyssa Vanginderdeuren, Margerie Huet-Dastarac, Ana Maria Barragan Montero","Deep learning models, such as U-Net, can be used to efficiently predict the optimal dose distribution in radiotherapy treatment planning. In this work, we want to supplement the prediction model with a measurement of its uncertainty at each voxel. For this purpose, a full Bayesian approach would, however, be too costly. Instead, we compare, based on their correlation with the actual error, three simpler methods, namely, the dropout, the bootstrap and a modification of the U-Net. These methods can be easily adapted to other architectures. 200 patients with head and neck cancer were used in this work.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-117
2021,Functional Gradient Descent for n-Tuple Regression,"Rafael Katopodis, Priscila Lima, Felipe França","n-tuple neural networks have been in the past applied to a wide range of learning domains. However, for the particular area of regression, existing systems have displayed two shortcomings: little flexibility in the objective function being optimized and an inability to handle nonstationarity in an online learning setting. A novel n-tuple system is proposed to address these issues. The new architecture leverages the idea of functional gradient descent,  drawing inspiration from its use in kernel methods. Furthermore, its capabilities are showcased in two reinforcement learning tasks, which involves both nonstationary online learning and task-specific objective functions.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-35
2021,Real-time On-edge Classification: an Application to Domestic Acoustic Event Recognition,"Lode Vuegen, Peter Karsmakers","In this paper two different convolutional neural network (CNN) architectures are investigated for the purpose of real-time on-edge domestic acoustic event classification. For training and evaluation of the models, a real-life acoustical dataset was recorded in 72 different home environments. A quantization-aware training scheme was applied that takes into account that the models need to run on 8-bit fixed-point processing hardware. Once trained, the models were successfully deployed on an ARM cortex-M7 microcontroller unit (i.MX RT1064). This study indicates that the used procedure can lead to an efficient and real-time embedded on-edge implementation of a domestic sound event classifier that does not sacrifices classification performance compared to its floating-point counterpart.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-84
2021,Supervised learning of convex piecewise linear approximations of optimization problems,"Laurine Duchesne, Quentin Louveaux, Louis Wehenkel","We propose to use input convex neural networks (ICNN) to build convex approximations of non-convex feasible sets of optimization problems, in the form of a set of linear equalities and inequalities in a lifted space. Our approach may be tailored to yield both inner- and outer- approximations, or to maximize its accuracy in regions closer to the minimum of a given objective function. We illustrate the method on two-dimensional toy problems and motivate it by various instances of reliability management problems of large-scale electric power systems.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-74
2021,A Lightweight Approach for Origin-Destination Matrix Anonymization,"Benoit Matet, Etienne Come, Angelo Furno, Loïc Bonnetain, Latifa Oukhellou, Nour-Eddin El Faouzi","Personal trajectory data are becoming more and more accessible and have a high value in transport planning and mobility characterisation, at the cost of a risk for user's privacy. Addressing this risk is usually computationally expensive and can lead to losing most of the data utility. We explore a new, light-weight approach to Origin/Destination-matrix anonymization that is easily scalable. We apply it to trip records from New York City Taxi and Limousine Commission (TLC) and measure the resulting utility loss with a generalization error function.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-56
2021,Deep Neural Networks for Classification of Riding Patterns: with a focus on explainability,"milad leyli abadi, abderrahmane boubezoul","The powered two-wheelers (PTW) are among the most vulnerable transport users. It is crucial to identify the appropriate action that should be undertaken during a specific situation to reduce the risk. In this article, the aim is to improve the current state of the art in identification of riding patterns through neural network architectures and to explain how a decision is made by a model which is considered as a black box. In this regard, a new visualization tool specific to time series is suggested to help identify the most influential factors and hopefully to develop appropriate risk mitigation strategies.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-51
2021,In-Station Train Movements Prediction: from Shallow to Deep Multi Scale Models,"Gianluca Boleto, Luca Oneto, Matteo Cardellini, Marco Maratea, Mauro Vallati, Renzo Canepa, Davide Anguita","Public railway transport systems play a crucial role in servicing the global society and are the transport backbone of a sustainable economy. While a lot of effort has been spent in predicting inter-station trains movements to support stakeholders (i.e., infrastructure managers, train operators, and travellers) decisions, the problem of predicting in-station movements, while being crucial to improve train dispatching (i.e., empowering human or automatic dispatchers), has been far more less investigated. In fact, stations are the most critical points in a railway networks: even small improvements in the estimation of the duration of trains movements can strongly improve the dispatching efficiency in coping with the increase in capacity demand and with delays. In this work we will first leverage on state of the art shallow models, fed by domain experts with domain specific features, to improve the current predictive systems. Then, we will leverage on a custom deep multi scale model able to automatically learn a representation and improve the accuracy of the shallow models. Results on real-world data coming from the Italian railway network will support our proposal.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-29
2021,Unsupervised Real-time Anomaly Detection for Multivariate Mobile Phone Traffic Series,"Evelyne Akopyan, Angelo Furno, Nour-Eddin El Faouzi, Eric Gaume",Real-time anomaly detection in urban areas from massive data is a recent research field with challenging requirements. This paper presents a lightweight and robust framework for real-time anomaly detection in multivariate time-series extracted from large-scale Mobile-phone Network Data (MND). Our solution relies on unsupervised machine learning applied to MND collected at individual antennas of a nation-wide French mobile phone network operator. The proposed framework is based on a two-step approach: (i) the offline stage aims at assessing the typical behaviour of the antennas; (ii) the online stage performs real-time comparison of incoming data with respect to the detected typical behaviour. Results related to a real case-study of terrorist attack in the city of Lyon show that our framework can successfully detect an emergency event almost instantaneously and locate the anomalous area with high precision.,Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-113
2021,Multivariate Time Series Multi-Coclustering. Application to Advanced Driving Assistance System Validation,"Etienne Goffinet, Mustapha Lebbah, Hanane Azzag, Loïc Giraldi, Anthony Coutant","Driver assistance systems development remains a technical challenge for car manufacturers. Validating these systems requires to assess the assistance systems performances in a considerable number of driving contexts. Groupe Renault uses massive simulation for this task, which allows reproducing the complexity of physical driving conditions precisely and produces large volumes of multivariate time series. We present the operational constraints and scientific challenges related to these datasets and our proposal of an adapted model-based multiple coclustering approach, which creates several independent partitions by grouping redundant variables. This method natively performs model selection, missing values inference, noisy samples handling, confidence interval production, while keeping a sparse parameter numbers. The proposed model is evaluated on a synthetic dataset, and applied to a driver assistance system validation use-case.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-119
2021,Machine learning and data mining for urban mobility intelligence,"Etienne Come, Latifa Oukhellou, Allou Same, Lijun Sun","The last few decades have seen a faster development of digital systems for observing the mobility of people and goods. Various sensing systems - such as radio communication, Wi-Fi, Bluetooth, validation of smart cards, mobile phone, and road traffic monitoring systems - have enabled researchers and practitioners to acquire large amounts of data, which generally refer to individual and collective trajectories. The mobility data can be further enriched with side information, such as text corpora from social media, survey data, and weather information. These massive data, temporally and spatially structured, can benefit from advanced machine learning and data mining methods, providing decision aid tools, and contributing to the development of safer, cleaner, and more efficient transportation systems. They can also help to implement new mobility services for the user. This article provides an overview of methodological advances in temporal and spatial mobility data processing.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-7
2021,A Relational Model for One-Shot Classification,"Arturs Polis, Alexander Ilin","We show that a deep learning model with built-in relational inductive bias can bring benefits to sample-efficient learning, without relying on extensive data augmentation. The proposed one-shot classification model performs relational matching of a pair of inputs in the form of local and pairwise attention. Our approach solves perfectly the one-shot image classification Omniglot challenge. Our model exceeds human level accuracy, as well as the previous state of the art, with no data augmentation.",Classification,https://doi.org/10.14428/esann/2021.ES2021-75
2021,IF: Iterative Fractional Optimization,"Sarthak Chatterjee, Subhro Das, Sérgio Pequito","Most optimization problems lack closed-form solutions of the argument that minimizes a given function, and even if these were available it might be prohibitive to compute it. As such, we rely on iterative numerical algorithms to find an approximate solution. In this paper, we propose to leverage fractional calculus in the context of time series analysis methods to devise a new iterative algorithm. Specifically, we propose to leverage autoregressive fractional-order integrative moving average time series, whose coefficients encode a proxy for local spatial information. We provide evidence that our algorithm is efficient and particularly suitable for cases where the Hessian is ill-conditioned.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-133
2021,Multi-perspective embedding for non-metric time series classification,"Maximilian Münch, Simon Heilig, Frank-Michael Schleif","The interest in time series analysis is rapidly increasing, providing new challenges for machine learning. Over many decades, Dynamic Time Warping (DTW) is referred to as the de facto standard distance measure for time series and the tool of choice when analyzing such data. Nevertheless, DTW has two major drawbacks: (a) it is non-metric and therefore hard to handle by standard machine learning techniques, and (b) it is not well suited for multi-dimensional time series. For this purpose, we propose a multi-perspective embedding of the time series into a complex-valued vector space and the evaluation by a model that is able to handle complex-valued data. The approach is evaluated on various multi-dimensional time series data and with different classifier techniques.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-114
2021,Convolutional Neural Network Architecture for Classification of Aircraft Engines Flight Time Series,"Delphine Bay, Clémence Bisot","During each flight, an aircraft engine sends data to a ground system. This data corresponds to different sensors measurements (temperatures, pressures, vibrations...) collected at key moments of the flight. It constitutes rich multivariate time series used to monitor the engine's health. In this article, we used flight data to predict the main removal cause of the engine. The problem falls within the framework of time series classification. This article proposes an interpretable neural network architecture which fits with the physical understanding of the modeled phenomenon in order to address the problem on a real-world, industrial dataset.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-91
2021,Fusion of estimations from two modalities using the Viterbi's algorithm: application to fetal heart rate monitoring,"Rémi Souriau, Julie Fontecave-Jallon, Bertrand Rivet","The Viterbi's algorithm allows to estimate latent time series according to observations in a hidden Markov model. This algorithm can be used to merge estimations from different modalities as proposed in this paper. Such a multi-modal estimation is more efficient than mono-modal estimations when the modalities are subject to independent noises.  In this paper, this improvement is evaluated in function of noise level of modalities.  Experiences on toy data and actual signals to estimate the fetal heart rate show that merging modalities will provide better estimations on average than using the modalities separately.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-61
2021,Differentially Private Time Series Generation,"Hiba Arnout, Johanna Bronner, Thomas Runkler","Privacy issues prevent data owner from improving Machine Learning (ML) performance as it makes external collaborations binding. To allow data sharing without confidentiality concerns, we propose in this work methods to generate time series in a privacy preserving manner. We combine the existing generative models for time series namely TimeGAN [1] ClaRe-GAN [2] and C-RNN-GAN [3] with differential privacy. This is achieved by changing their original discriminator with a private discriminator that relies on the differentially private stochastic gradient method (DPSGD) [4]. Our experiments show that the developed methods - in particular TimeGAN and ClaRe-GAN - outperform the existing and unique differentially private model for time series of RCGAN [5] in terms of privacy and accuracy.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-20
2021,Quantifying Resemblance of Synthetic Medical Time-Series,"Karan Bhanot, Saloni Dash, Joseph Pedersen, Isabelle Guyon, Kristin Bennett","Access to medical data is often restricted due to privacy laws e.g. HIPAA and GDPR. We address the viability of substituting real data with synthetic data to protect privacy while maintaining utility. Medical data records are fundamentally longitudinal, with one patient having multiple health events influenced by covariates like gender, age etc. Synthesis of medical data, hence, falls under time-series generative modeling. We demonstrate methods to measure synthetic medical time-series quality on datasets from previously published synthetic data research. We deploy four time-series metrics to quantify resemblance in synthetic and real covariate plots while comparing baseline data generation methods.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-108
2021,A Baseline for Shapley Values in MLPs: from Missingness to Neutrality,"Cosimo Izzo, Aldo Lipani, Ramin Okhrati, Francesca Medda","Deep neural networks have gained momentum based on their accuracy, but their interpretability is often criticised. As a result, they are labelled as black boxes. In response, several methods have been proposed in the literature to explain their predictions. Among the explanatory methods, Shapley values is a feature attribution method favoured for its robust theoretical foundation. However, the analysis of feature attributions using Shapley values requires choosing a baseline that represents the concept of missingness. An arbitrary choice of baseline could negatively impact the explanatory power of the method and possibly lead to incorrect interpretations. In this paper, we present a method for choosing a baseline according to a neutrality value: as a parameter selected by decision-makers, the point at which their choices are determined by the model predictions being either above or below it. Hence, the proposed baseline is set based on a parameter that depends on the actual use of the model. This procedure stands in contrast to how other baselines are set, i.e. without accounting for how the model is used. We empirically validate our choice of baseline in the context of binary classification tasks, using two datasets: a synthetic dataset and a dataset derived from the financial domain.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-18
2021,SmoothLRP: Smoothing LRP by Averaging over Stochastic Input Variations,"Arne Raulf, Sina Däubener, Ben  Hack, Axel Mosig, Asja Fischer","Explanations of neural networks predictions are a necessity for deploying neural network in safety critical domains. Several methods were developed which identify most relevant input features, such as sensitivity analysis and layer-wise relevance propagation (LRP).  It has been shown that the noise in the explanations from the sensitivity analysis can be reduced by averaging over noisy input images, a method referred to as SmoothGrad.  We investigate the application of the same principle to LRP and find that it smooths the resulting relevance function leading to improved explanations. Moreover, it can be applied for restoring the correct label of adversarial examples.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-139
2021,Context-specific sampling method for contextual explanations,"Manik Madhikermi, Avleen Malhi, Kary Främling","Explaining the result of machine learning models is an active research topic in Artificial Intelligence (AI) domain with an objective to provide mechanisms to understand and interpret the results of the underlying black-box model in a human-understandable form. With this objective, several eXplainable Artificial Intelligence (XAI) methods have been designed and developed based on varied fundamental principles. Some methods such as  Local interpretable model agnostic explanations (LIME), SHAP (SHapley Additive exPlanations) are based on the surrogate model while others such as Contextual Importance and Utility (CIU) do not create or rely on the surrogate model to generate its explanation. Despite the difference in underlying principles, these methods use different sampling techniques such as uniform sampling, weighted sampling for generating explanations. CIU, which emphasizes a context-aware decision explanation, employs a uniform sampling method for the generation of representative samples. In this research, we target uniform sampling methods which generate representative samples that do not guarantee to be representative in the presence of strong non-linearities or exceptional input feature value combinations. The objective of this research is to develop a sampling method that addresses these concerns. To address this need, a new adaptive weighted sampling method has been proposed. In order to verify its efficacy in generating explanations, the proposed method has been integrated with CIU, and tested by deploying the special test case.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-124
2021,Geometric Probing of Word Vectors,"Madina Babazhanova, Maxat Tezekbayev, Zhenisbek Assylbekov","This paper studies the informativeness of linguistic properties such as part-of-speech and named entities encoded in word representations. First, we find directions that correspond to these properties using the method of Elazar et al. (2020). Then such directions are compared with the  principal vectors obtained from application of PCA to word embeddings. As a result, we find that the part-of-speech information is more important for word embeddings than the named entity property.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-105
2021,The LVQ-based Counter Propagation Network -- an Interpretable Information Bottleneck Approach,"Marika Kaden, Ronny Schubert, Mehrdad Mohannazadeh Bakhtiari, Lucas Schwarz, Thomas Villmann",In this paper we present a realization of the information-bottleneck-paradigm by means of an improved counter propagation network. It combines an unsupervised vector quantizer for data compression with a subsequent supervised learning vector quantization model. The approach is mathematically justified and yields an interpretable model for classification under the constraint of data compression.,Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-88
2021,The partial response SVM,"Bradley Walters, Sandra Ortega-Martorell, Ivan Olier, Paulo Lisboa",We introduce a probabilistic algorithm for binary classification based on the SVM through the application of the ANOVA decomposition for multivariate functions to express the logit of the Platt estimate of the posterior probability as a non-redundant sum of functions of fewer variables (partial responses) followed by feature selection with the Lasso. The partial response SVM (prSVM) is compared with previous interpretable models of the SVM. Its accuracy and stability are demonstrated with real-world data sets.,Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-36
2021,Handling Correlations in Random Forests: which Impacts on Variable Importance and  Model Interpretability?,"Marie  Chavent, Jérôme Lacaille, Alex Mourer, Madalina  Olteanu","The present manuscript tackles the issues of model interpretability and variable importance in random forests, in the presence of correlated input variables. Variable importance criteria based on random permutations are known to be sensitive when input variables are correlated, and may lead for instance to unreliability in the importance ranking. In order to overcome some of the problems raised by correlation, an original variable importance measure is introduced. The proposed measure builds upon an algorithm which clusters the input variables based on their correlations, and summarises each such cluster by a synthetic variable. The effectiveness of the proposed criterion is illustrated through simulations in a regression context, and compared with several existing variable importance measures.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-155
2021,A Parameterless t-SNE for Faithful Cluster Embeddings from Prototype-based Learning and CONN Similarity,"Josh Taylor, Erzsébet Merényi","We propose an improvement to t-SNE which allows automated specification of its perplexity parameter using topological information about a data manifold revealed through neural prototype-based learning. This information is contained in the CONN (CONNectivity) similarity of neural prototypes, which expresses the strength (weakness) of topological connectivity at various points within the manifold. Experiments show that improvements, collectively called CONNt-SNE, are capable of producing meaningful and trustworthy low-dimensional  embeddings without the need to heuristically optimize over (i.e., grid search) t-SNE's perplexity space.  Data-driven perplexity determination improves our confidence that any structure appearing in the embeddings is valid and not merely an artifact of spurious parameterization.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-138
2021,AGLVQ - Making Generalized Vector Quantization Algorithms Aware of Context,"Torben Graeber, Sebastian Vetter, Sascha Sarajalew, Michael Unterreiner, Dieter Schramm","Generalized Learning Vector Quantization methods are a powerful and robust approach for classification tasks. They compare incoming samples with representative prototypes for each target class. While prototypes are physically interpretable, they do not account for changes in the environment. We propose a novel framework for the incorporation of context information into prototype generation. We can model dependencies in a modular way ranging from polynomials to neural networks. Evaluations on artficial and real-world datasets show an increase in performance and meaningful prototype adaptations.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-40
2021,Instance-Based Multi-Label Classification via Multi-Target Distance Regression,"Joonas Hämäläinen, Paavo Nieminen, Tommi Kärkkäinen","Interest in multi-target regression and multi-label classification techniques and their applications have been increasing lately. Here, we use the distance-based supervised method, minimal learning machine (MLM), as a base model for multi-label classification. We also propose and test a hybridization of unsupervised and supervised techniques, where prototype-based clustering is used to reduce both the training time and the overall model complexity. In computational experiments, competitive or improved quality of the obtained models compared to the state-of-the-art techniques was observed.",Classification,https://doi.org/10.14428/esann/2021.ES2021-104
2021,Gradient representations in ReLU networks as similarity functions,"Bálint Daróczy, Dániel Rácz",Feed-forward networks can be interpreted as mappings with linear decision surfaces at the level of the last layer. We investigate how the tangent space of the network can be exploited to refine the decision in case of ReLU (Rectangular Linear Unit) activations. We show that a simple Riemannian metric parametrized on the parameters of the network forms a similarity function at least as good as the original network and we suggest a sparse metric to increase the similarity gap.,Classification,https://doi.org/10.14428/esann/2021.ES2021-153
2021,A bag of nodes primer on weightless graph classification,"Raul Barbosa, Diego Carvalho, Priscila Lima, Felipe França","This paper proposes a weightless architecture for graph classification scenarios. This architecture is a three-headed arrangement composed of graph hand-picked features, a quantization method and a final classifier. Although multiple new strategies for graph classification have been proposed in recent years, it is still necessary to settle comparable studies with respect to weightless neural networks. The proposed architecture is evaluated along with other baseline classifiers and independent strategies, showing that weightless architectures are able to compete with other well-established methods such as graph kernels.",Classification,https://doi.org/10.14428/esann/2021.ES2021-107
2021,Evolutionary Deep Multi-Task Learning,Oliver Kramer,"Multi-task learning is an approach to reduce the amount of required training data by learning multiple tasks at the same time. In the context of neural networks, multi-task learning is performed by sharing weights or creating dependencies between weights of task-specific networks. In this work, we propose an algorithm that uses a simple evolutionary algorithm, which is able to match and also surpass learned weight sharing. We evaluate the performance of this method on CIFAR-100, cast as a multi-tasking problem, using an 18-layer residual network, and compare our results to literature.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-14
2021,Benign overfitting of fully connected Deep Nets:A Sobolev space viewpoint,"Stephane Chretien, Emmanuel Caron-Parte","Deep neural nets have undergone tremendous improvementsin the last decade, which revolutionised the field of machine learning in abroad and lasting manner, achieving unprecedented performance in suchdiverse fields as image analysis, point cloud registration, natural languageprocessing and model free control.  On the theoretical side, understandingthe underpinnings of deep learning remains a formidable challenge, despiteimpressive breakthroughs in the last decade.  One particularly interestingnew prospect is the analysis of the double descent phenomenon describedin  Belkin  et  al.  [2019],  a  counter-intuitive  theory  bringing  new  insighton the performance of learning systems in the greatly over-parametrisedregime.The list of contribution to the understanding of the double descentparadigm has grown substantially in the last two years, but all availableresults in the literature mainly focus on the linear and the kernel setups.In the present paper,  we study the overparametrised part of the doubledescent curve introduced in Belkin et al. [2019] and propose a new approachto the study of benign overfitting in the setting of learning Sobolev maps.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-37
2021,"Semantic Prediction: Which One Should Come First, Recognition or Prediction?","Hafez Farazi, Jan Nogga, Sven Behnke","The ultimate goal of video prediction is not forecasting future pixel-values given some previous frames. Rather, the end goal of video prediction is to discover valuable internal representations from the vast amount of available unlabeled video data in a self-supervised fashion for downstream tasks. One of the primary downstream tasks is interpreting the scene's semantic composition and using it for decision-making. For example, by predicting human movements, an observer can anticipate human activities and collaborate in a shared workspace. There are two main ways to achieve the same outcome, given a pre-trained video prediction and pre-trained semantic extraction model; one can first apply predictions and then extract semantics or first extract semantics and then predict. We investigate these configurations using the Local Frequency Domain Transformer Network (LFDTN) as the video prediction model and U-Net as the semantic extraction model on synthetic and real datasets.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-23
2021,Deep Graph Convolutional Networks for Wind Speed Prediction,"Tomasz Stańczyk, Siamak Mehrkanoon","In this paper, we introduce a new model for wind speed prediction based on spatio-temporal graph convolutional networks. Here, weather stations are treated as nodes of a graph with a learnable adjacency matrix, which determines the strength of relations between the stations based on the historical weather data. The self-loop connection is added to the learnt adjacency matrix and its strength is controlled by additional learnable parameter. Experiments performed on real datasets collected from weather stations located in Denmark and the Netherlands show that our proposed model outperforms previously developed baseline models on the referenced datasets.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-25
2021,Judging competitions and benchmarks: a candidate election approach,"Adrien Pavao, Isabelle Guyon, Michael Vaccaro","Machine learning progress relies on algorithm benchmarks. We study the problem of declaring a winner, or ranking candidate algorithms, based on results obtained by judges (scores on various tasks). Inspired by social science and game theory on fair elections, we compare various ranking functions, ranging from simple score averaging to Condorcet methods. We devise novel empirical criteria to assess the quality of ranking functions, including the generalization to new tasks and the stability under judge or candidate perturbation. We conduct an empirical comparison on the results of 5 competitions and benchmarks (one artificially generated). While prior theoretical analyses indicate that no single ranking function satisfies all desired properties, our empirical study reveals that the classical average rank method fares well. However, some pairwise comparison methods can get better empirical results.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-122
2021,Predicting employee attrition with a more effective use of historical events,"Abdel-Rahmen Korichi, Hamamache Kheddouci, Daniel West","Attrition prediction research typically focuses on constructing models that involves one observation per employee over a limited time period, while the rest of the employees are discarded. Time-series attributes are transformed to non-time-series ones by applying statistical operations (e.g. sum, max, etc.). Such methods result in information loss and therefore less effective predictions. In this paper, we introduce a dynamic approach to employee attrition prediction, leveraging the longitudinal nature of the data, and allowing the models to generalize across behaviors and providing a closer estimate of the employee risk of leaving.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-110
2021,Investigating Intensity and Transversal Drift in Hyperspectral Imaging Data,"Valerie Vaquet, Patrick Menz, Udo Seiffert, Barbara Hammer","When measuring data with hyperspectral cameras drift in the data distribution occurs over time and when the sensing device is changed. Frequently, this drift is a combination of intensity and wavelength shifts. In this contribution, we demonstrate that  transfer component analysis together with subsampling constitutes a particular efficient and simple technology for spectral offset elimination which is applied to avoid the negative impact of drift on the classification performance. We demonstrate that this approach performs on par or better in comparison to established methods, and we also provide a theoretical motivation why this technology can deal with both, intensity as well as wavelength shift provided bounds on the smoothness of the functional data are given.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-64
2021,Concept Drift Segmentation via Kolmogorov-Trees,"Fabian  Hinder, Barbara Hammer","The notion of concept drift refers to the phenomenon that the data distribution changes over time. If drift occurs, machine learning models need adjustment. Since drift can be inhomogeneous, suitable actions depending on the location in data space. In this paper we address the challenge to partition the data space into segments with homogeneous drift characteristics. We formalize this objective as an independence criterion, and derive a robust and efficient training algorithm based thereon. We evaluate the efficiency of the method in comparison to existing technologies: the identification of drifting clusters, and the estimation of a conditional density distribution.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-93
2021,Federated Learning Vector Quantization,"Johannes Brinkrolf, Barbara Hammer","Prototype-based methods such as LVQ techniques combine discriminative and generative aspects by representing models in terms of representative locations in the data space which enable an intuitive nearest-neighbor based classification. This fact has already been used in the context of incremental learners for streaming data which might be subject to drift. In this contribution, we demonstrate that this intuitive representation enables a very simple strategy for federated learning.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-141
2022,A bayesian variational principle for dynamic self organizing maps,"Anthony Fillion, Thibaut Kulak, François Blayo",We propose organisation conditions that yield a method for training SOM with   adaptative neighborhood radius in a variational Bayesian framework. This   method is validated on a non-stationary setting and compared in an   high-dimensional setting with an other adaptative method.,Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-11
2022,Tutorial - Continual Learning beyond classification,"Alexander Gepperth, Timothée Lesort","Continual Learning (CL, sometimes also termed incremental learning) is a flavor of machine learning where the usual assumption of stationary data distribution is relaxed or omitted. When naively applying, e.g., DNNs in CL problems, changes in the data distribution can cause the so-called catastrophic forgetting (CF) effect: an abrupt loss of previous knowledge. Although many significant contributions to enabling CL have been made in recent years, most works address supervised (classification) problems. This article reviews literature that study CL in other settings, such as learning with reduced supervision, fully unsupervised learning, and reinforcement learning. Besides proposing a simple schema for classifying CL approaches w.r.t. their level of autonomy and supervision, we discuss the specific challenges associated with each setting and the potential contributions to the field of CL in general.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-4
2022,Adaptive Gabor Filters for Interpretable Color Texture Classification,"Gerrit Luimstra, Kerstin Bunte","We introduce the use of trainable feature extractors, based on the Gabor function, into the interpretable machine learning domain.  The use of adaptive Gabor filters allows for interpretable feature extraction to be learned automatically in a domain agnostic way, and comes with the benefit of a large reduction in trainable parameters. We implemented the filters into an image classification variant of learning vector quantization. We extend and compare the image classification variant of learning vector quantization with adaptive Gabor filters and demonstrate the proposed technique on VisTex color texture images.  The adaptive Gabor filters show promising results for interpretable and efficient color texture classification.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-87
2022,Continual Learning for Human State Monitoring,"Federico Matteoni, Andrea Cossu, Claudio Gallicchio, Vincenzo Lomonaco, Davide Bacciu","Continual Learning (CL) on time series data represents a promising but under-studied avenue for real-world applications. We propose two new CL benchmarks for Human State Monitoring. We carefully designed the benchmarks to mirror real-world environments in which new subjects are continuously added. We conducted an empirical evaluation to assess the ability of popular CL strategies to mitigate forgetting in our benchmarks. Our results highlight the fact that, due to the domain-incremental properties of our benchmarks, forgetting can be easily tackled even with a simple finetuning and that existing strategies struggle in accumulating knowledge over a fixed, held-out, test subject.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-38
2022,Constraint Guided Gradient Descent: Guided Training with Inequality Constraints,"Quinten Van Baelen, Peter Karsmakers","Deep learning is typically performed by learning a neural network solely from data in the form of input-output pairs ignoring available domain knowledge. In this work, the Constraint Guided Gradient Descent (CGGD) framework is proposed that enables the injection of domain knowledge into the training procedure.  The domain knowledge is assumed to be described as a conjunction of hard inequality constraints which appears to be a natural choice for several applications. Compared to other neuro-symbolic approaches, the proposed method converges to a model that satisfies any inequality constraint on the training data and does not require to first transform the constraints into some ad-hoc term that is added to the learning (optimisation) objective. Under certain conditions, it is shown that CGGD can converges to a model that satisfies the constraints on the training set, while prior work does not necessarily converge to such a model. It is empirically shown on two independent and small data sets that CGGD makes training less dependent on the initialisation of the network and improves the constraint satisfiability on all data.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-105
2022,A Fast and Simple Evolution Strategy with Covariance Matrix Estimation,Oliver Kramer,With the rise of A.I. methods the demand for efficient optimization methods that are easy to implement and use increases. This paper introduces a simple optimization method for numerical blackbox optimization. It proposes to apply covariance matrix estimation for the (1+1)-ES with Rechenberg's step size control. Experiments on a small set of benchmark functions demonstrate that the approach outperforms its isotropic variant allowing competitive convergence on problems with scaled and correlated dimensions.,Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-112
2022,Sliced-Wasserstein normalizing flows: beyond maximum likelihood training,"Florentin Coeurdoux, Nicolas Dobigeon, Pierre Chainais","Despite their advantages, normalizing flows generally suffer from several shortcomings  including their tendency to generate unrealistic data (e.g., images) and their failing to detect out-of-distribution data. One reason for these deficiencies lies in the training strategy which traditionally exploits a maximum likelihood principle only. This paper proposes a new training paradigm based on a hybrid objective function combining the maximum likelihood principle (MLE) and a Sliced-Wasserstein distance. Results obtained on synthetic toy examples and real image data sets show better generative abilities in terms of both likelihood and visual aspects of the generated samples. Reciprocally, the proposed approach leads to a lower likelihood of out-of-distribution data, demonstrating a greater data fidelity of the resulting flows.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-101
2022,Filtering participants improves generalization in competitions and benchmarks,"Adrien Pavao, Isabelle Guyon, Zhengying Liu","We address the problem of selecting a winning algorithm in a challenge or benchmark.  While evaluations of algorithms carried out by third party organizers eliminate the inventor-evaluator bias, little attention has been paid to the risk of over-fitting the winner's selection by the organizers. In this paper, we carry out an empirical evaluation using the results of several challenges and benchmarks, evidencing this phenomenon. We show that a heuristic commonly used by organizers consisting of pre-filtering participants using a trial run, reduces over-fitting. We formalize this method and derive a semi-empirical formula to determine the optimal number of top k participants to retain from the trial run.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-72
2022,Do We Really Need a New Theory to Understand the Double-Descent?,"Luca Oneto, Sandro Ridella, Davide Anguita","This century saw an unprecedented increase of public and private investments in Artificial Intelligence (AI) and especially in Machine Learning (ML). This led to breakthroughs in their practical ability to solve complex real world problems impacting research and society at large. Instead, our ability to understand the fundamental mechanism behind these breakthroughs has slowed down because of their increased complexity. This questioned researchers about the necessity for a new theoretical framework able to help researchers catch up on this lag. One of the still not well understood mechanisms is the so called over-parametrization, namely the ability of certain models to increasing their generalization performance (reduce test error) when the number of parameters is above the interpolating threshold (zero training error), and the associated double-descent curve. In this paper we will show that this phenomena can be better understood using both known theories, i.e., the algorithmic stability theory, and empirical evidence.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-13
2022,Multioutput Regression Neural Network Training via Gradient Boosting,"seyedsaman emami, Gonzalo Martínez-Muñoz","A novel sequential procedure to train the final layers of a multi-output regression neural network (NN) based on Gradient Boosting is proposed, where the NN is an additive expansion of the Gradient Boosting. The method works by training portions of the network in an iterative manner in such a way that each new portion of the NN is learnt to compensate for the errors of the already trained portions, and the final result of the network forms by provided weight and the last hidden layer output. This is in contrast to the standard training of NNs in which the whole network is trained to learn the concept at hand. Extensive experiments show the good performance of the proposed method with respect to NN.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-95
2022,"Price direction prediction in financial markets, using Random Forest and Adaboost","Mohammadmahdi Ghahramani, Fabio Aiolli","Experience shows trading in financial markets can be highly profitable. In this light, a great deal of effort has been devoted to using machine learning to predict market behavior. By using Random Forest and Adaboost models, we present a novel method for modeling candlestick patterns in financial markets. Our first contribution in the preprocessing part is to prepare data, develop additional features, and modify data. Our second contribution is introducing a novel prediction approach, named dataset ensembling to predict daily prices. Using three-year daily Bitcoin prices, the models are trained, tuned and then tested on one year of unseen data, showing the feasibility of the approach in terms of accuracy.",Classification,https://doi.org/10.14428/esann/2022.ES2022-115
2022,The role of feature selection in personalized recommender systems,"Roger Bagué-Masanés, Verónica Bolón-Canedo, Beatriz Remeseiro","Recommender systems suggest products to users, based on their popularity or the users' preferences. This paper proposes a hybrid personalized recommender system based on users' tastes and also on information available about items. We used a dataset downloaded from TripAdvisor, which contains some information from restaurants (items), such as price range or special diets. Feature selection techniques are employed to analyze the impact that each variable has on personalized recommendations, allowing us to understand not only the process underlying the recommendation to favor the transparency of the system, but also what users value the most when choosing a restaurant.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-43
2022,Distributive Thermometer: A New Unary Encoding for Weightless Neural Networks,"Alan T. L. Bacellar, Zachary Susskind, Luis A. Q. Villon, Igor D. S. Miranda, Leandro Santiago de Araújo, Diego Leonel Cadette Dutra, Mauricio Breternitz Jr., LIZY JOHN, Priscila Lima, Felipe França","The binary encoding of real valued inputs is a crucial part of Weightless Neural Networks. The Linear Thermometer and its variations are the most prominent methods to determine binary encoding for input data but, as they make assumptions about the input distribution, the resulting encoding is sub-optimal and possibly wasteful when the assumption is incorrect. We propose a new thermometer approach that doesn’t require such assumptions. Our results show that it achieves similar or better accuracy when compared to a thermometer that correctly assumes the distribution, and accuracy gains up to 26.3% when other thermometers assume an unsound distribution.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-94
2022,Pruning Weightless Neural Networks,"Zachary Susskind, Alan T. L. Bacellar, Aman Arora, Luis A. Q. Villon, Renan Mendanha, Leandro Santiago de Araújo, Diego Leonel Cadette Dutra, Priscila Lima, Felipe França, Igor D. S. Miranda, Mauricio Breternitz Jr., LIZY JOHN","Weightless neural networks (WNNs) are a type of machine learning model which perform prediction using lookup tables (LUTs) instead of arithmetic operations. Recent advancements in WNNs have reduced model sizes and improved accuracies, reducing the gap in accuracy with deep neural networks (DNNs). Modern DNNs leverage ""pruning"" techniques to reduce model size, but this has not been previously explored for WNNs. We propose a WNN pruning strategy based on identifying and culling the LUTs which contribute least to overall model accuracy. We demonstrate an average 40% reduction in model size with at most 1% reduction in accuracy.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-55
2022,Classification of preclinical markers in Alzheimer's disease via WiSARD classifier,"Massimo De Gregorio, Alfonso Di Costanzo, Andrea Motta, Debora Paris, Antonio Sorgente","Weightless Neural Networks (WNN) showed good results in various classification problems in different domains where a significant number of instances for each class was available. In this work, we present different WiSARD classifiers facing a quite difficult problem  from both the clinical and  the machine learning point of views: the classification of preclinical markers in Alzheimer's disease continuum patients. The four domain classes show overlapping molecular features and each has few instances (around 40).  Together with improved class separation, the confirmation of the goodness of the results is given by a series of experiments that have compared the WiSARD classifiers to many state-of-the-art classifiers, even those ensembles, showing that the obtained results are very close to the top best models.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-63
2022,A WiSARD-based conditional branch predictor,"Luis A. Q. Villon, Zachary Susskind, Alan T. L. Bacellar, Igor D. S. Miranda, Leandro Santiago de Araújo, Priscila Lima, Mauricio Breternitz Jr., LIZY JOHN, Felipe França, Diego Leonel Cadette Dutra","Conditional branch prediction is a technique used to speculatively execute instructions before knowing the direction of conditional branch statements. Perceptron-based predictors have been extensively studied, however, they need large input sizes for the data to be linearly separable. To learn nonlinear functions from the inputs, we propose a conditional branch predictor based on the WiSARD model and compare it with two state-of-the-art predictors, the TAGE-SC-L and the Multiperspective Perceptron. We show that the WiSARD-based predictor with a smaller input size outperforms the perceptron-based predictor by about 0.09% and achieves similar accuracy to that of TAGE-SC-L.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-65
2022,Feature selection for transfer learning using particle swarm optimization and complexity measures,"Verónica Bolón-Canedo, Guillermo Castillo García, Laura Morán-Fernández","Particle Swarm Optimization is an optimization algorithm that explores a search space guided by a fitness function in order to find a good solution. We apply it to perform feature selection for domain adaptation. Usually, classification error is used in the fitness function to evaluate the goodness of subsets of features. In this paper, we propose to employ complexity metrics instead, as we assume that reducing the complexity of the problem will lead to good results while being less computationally demanding and independent from the classifier used for testing. We found out that our method is indeed faster and selects fewer features, obtaining competitive classification accuracy results.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-57
2022,Supervised dimensionality reduction technique accounting for soft classes,"Sorina Mustatea, Michael Aupetit, Jaakko Peltonen, Sylvain Lespinats, Denys Dutykh","Exploratory visual analysis of multidimensional labeled data is challenging. Multidimensional Projections for labeled data attempt to separate classes while preserving neighborhoods. In this work, we consider the case where instances are assigned multiple labels with probabilities or weights: for example, the output of a probabilistic classifier, fuzzy membership functions in fuzzy logic, or the votes of each voters for each candidate in an election. We propose a new technique to better preserve neighborhoods of such data. Our experiments show improved qualitative results compared to unsupervised, and existing dimensionality reduction techniques.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-26
2022,Graph-Induced Geodesics Approximation for Non-Euclidian K-Means,Hervé Frezza-Buet,"In this paper, an adaptation of the k-means algorithm and related methods to non-Euclidian topology is presented. The paper introduces a rationale for approximating the geodesics of that topology, as well as a learning rule that is robust to noise. The first results on artificial but very noisy distributions presented here are promising for further experimentation on real cases.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-14
2022,Modular Representations for Weak Disentanglement,"Andrea Valenti, Davide Bacciu","The recently introduced weakly disentangled representations proposed to relax some constraints of the previous definitions of disentanglement, in exchange for more flexibility. However, at the moment, weak disentanglement can only be achieved by increasing the amount of supervision as the number of factors of variations of the data increase. In this paper, we introduce modular representations for weak disentanglement, a novel method that allows to keep the amount of supervised information constant with respect the number of generative factors. The experiments shows that models using modular representations can increase their performance with respect to previous work without the need of additional supervision.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-52
2022,Continual Incremental Language Learning for Neural Machine Translation,"Michele Resta, Davide Bacciu","The paper provides an experimental investigation of the phenomena of catastrophic forgetting for Neural Machine Translation systems. We introduce and describe the continual incremental language learning setting and its analogy with the classical continual learning scenario. The experiments measure the performance loss of a naive incremental training strategy against a jointly trained baseline, and  we show the mitigating effect of the replay strategy. To this end, we also introduce a prioritized replay buffer strategy informed by the specific application domain.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-80
2022,Diverse Memory for Experience Replay in Continual Learning,"Andrii Krutsylo, Pawel Morawiecki","Neural networks trained on data whose distribution is shifted in time suffer greatly from performance degradation. This problem is known as catastrophic forgetting, i.e. learning new classes leads to loss of accuracy on previously seen ones. A replay buffer can mitigate this problem by storing and reusing some of the data. In this paper, we propose a modification of sampling to the memory buffer using deep features extracted from the classifier itself to increase the diversity of stored samples. Our method demonstrates a consistent reduction in forgetting verified on different settings for MNIST, SVHN and CIFAR-10 datasets.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-83
2022,Model Agnostic Local Explanations of Reject,"André Artelt, Roel Visser, Barbara Hammer","The application of machine learning based decision making systems in safety critical areas requires reliable high certainty predictions.  Reject options are a common way of ensuring a sufficiently high certainty of predictions. While being able to reject uncertain samples is important, it is also of importance to be able to explain why a particular sample was rejected. However, explaining reject options is still an open problem. We propose a model-agnostic method for locally explaining reject options by means of interpretable models and counterfactual explanations.",Classification,https://doi.org/10.14428/esann/2022.ES2022-34
2022,Adaptive multi-modal positive semi-definite and indefinite kernel fusion for binary classification,"Maximilian Münch, Christoph Raab, Simon Heilig, Manuel Röder, Frank-Michael Schleif","Data and information are nowadays frequently available in multiple modalities like different sensor signals, textual descriptions, graph structures, and other formats. The maximum information from these heterogeneous representations can be obtained by fusing the various modalities by specific embeddings or proximity measures. Current approaches are widely limited in the fusion model and the used measures, especially when the data is non-vectorial. We propose a model to learn the spectral properties of the different inner product representations in a joined optimization problem. The approach is evaluated on various multi-modal data and compared to modern multiple-kernel learning and baseline techniques.",Classification,https://doi.org/10.14428/esann/2022.ES2022-70
2022,A Kernel Based Multilinear SVD Approach for Multiple Sclerosis Profiles Classification,"Berardino Barile, Pooya Ashtari, Francoise Durand-Dubief, Frederik Maes, Dominique Sappey-Marinier, Sabine Van Huffel","In machine learning, kernel data analysis represents a new approach to the study of neurological diseases such as Multiple Sclerosis (MS). In this work, a kernelization technique was combined with a tensor factorization method based on Multilinear Singular Value Decomposition (MLSVD) for MS profile classification. Our simple, yet effective, approach generates a meaningful feature embedding of multi-view data, allowing good classification performance. The results presented in this work define an interesting approach, given that only the anatomical T1-weighted image was used, which represents the most important modality in clinical applications.",Classification,https://doi.org/10.14428/esann/2022.ES2022-17
2022,A Machine Learning Approach for School Dropout Prediction in Brazil,"João Gabriel Corrêa Krüger, Jean Paul Barddal, Alceu de Souza Britto Jr.","School dropout is a problem that impacts many socio-economic aspects, including inequality. Dropout prediction algorithms can help remediate this problem, although several past attempts in the literature did so using small datasets. This paper brings forward an experimental approach of machine learning for school dropout prediction in Brazilian schools. The data used for this study was first retrieved from the academic systems of a group of Brazilian private schools, which was later enriched with socio-economic data extracted from governmental sources. Using the dataset to train different types of classifiers, we obtained up to 95.2% precision rates when predicting dropout at different year and educational stages, thus allowing schools to plan and apply retention strategies.",Classification,https://doi.org/10.14428/esann/2022.ES2022-15
2022,An empirical comparison of generators in replay-based continual learning,"NADZEYA DZEMIDOVICH, Alexander Gepperth","This study in the context of continual learning (CL) with DNNs compares several types of generators when performing replay, i.e., the generation of previously seen samples, to avoid catastrophic forgetting. Principal generators are generative adversarial networks (GANs) and variational autoencoders (VAEs). We evaluate these generators in various flavors (conditional, Wasserstein etc.) w.r.t. CL performance on a variety of CL tasks generated from the MNIST benchmark. Concerning generators, we find that VAEs are generally more compatible with CL than GANs. More generally, we find that replay-based CL faces counter-intuitive issues for seemingly simple problems: first, that performance degrades more strongly as less information is added, and, furthermore, that performance degrades even when only known information is added.",Classification,https://doi.org/10.14428/esann/2022.ES2022-111
2022,Machine learning for automated quality control in injection moulding manufacturing,"Steven Michiels, Cédric De Schryver, Lynn Houthuys, Frederik Vogeler, Frederik Desplentere","Machine learning (ML) may improve and automate quality control (QC) in injection moulding manufacturing. As the labelling of extensive, real-world process data is costly, however, the use of simulated process data may offer a first step towards successful implementation. In this study, simulated data was used to develop a predictive model for the product quality of an injection moulded sorting container. The achieved accuracy, specificity and sensitivity on the test set was 99.4%, 99.7% and 94.7%, respectively. This study thus shows the potential of ML towards automated QC in injection moulding and encourages extension to models trained on real-world data.",Classification,https://doi.org/10.14428/esann/2022.ES2022-48
2022,Simple Non Regressive Informed Machine Learning Model for Predictive Maintenance of Railway Critical Assets,"Luca Oneto, Simone Minisi, Andrea Garrone, Renzo Canepa, Carlo Dambra, Davide Anguita","Signals, track circuits, switches, and relay rooms are simultaneously the most critical and most maintained railway assets. A fault of one of these assets may strongly reduce the railway network capacity or even disrupt the circulation. Effectively predicting what assets may need maintenance allows to anticipate the intervention thus avoiding a failure. Currently, this problem is tackled by infrastructure managers mostly relying on operators' experience and with limited support of decision supporting tools. In this paper, we propose a Simple Informed Machine Learning (ML) based model able to automatically predict what asset need to be maintained fully leveraging on the operator experience. However, ML models in modern industrial MLOps pipelines demand continuous data collection, model re-training, testing, and monitoring, creating a large technical debt. In fact, one of the main requirements of these pipelines is to not be regressive, i.e., not simply improve average performances but also not incorrectly predicting an output that was correctly classified by the reference model (negative flips). In this work we face this problem by empowering the proposed ML with Non Regressive properties. Results on real data coming from a portion of an Italian Railway Network managed by Rete Ferroviaria Italiana, the Italian Infrastructure Manager, will support our proposal.",Classification,https://doi.org/10.14428/esann/2022.ES2022-59
2022,Deep latent position model for node clustering in graphs,"Dingge Liang, Marco Corneli, Charles Bouveyron, Pierre Latouche","With the significant increase of interactions between individuals through numeric means, the clustering of vertex in graphs has become a fundamental approach for analysing large and complex networks. We propose here the deep latent position model (DeepLPM), an end-to-end clustering approach which combines the widely used latent position model (LPM) for network analysis with a graph convolutional network (GCN) encoding strategy. Thus, DeepLPM can automatically assign each node to its group without using any additional algorithms and better preserves the network topology. Numerical experiments on simulated data and an application on the Cora citation network are conducted to demonstrate its effectiveness and interest in performing unsupervised clustering tasks.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-30
2022,1D vs 2D convolutional neural networks for scalp high frequency oscillations identification,"Gaëlle MILON-HARNOIS, Nisrine JRAD, Daniel Schang, Patrick VAN BOGAERT, Pierre CHAUVET","Scalp High Frequency Oscillations (HFOs) are promising biomarkers of epileptogenic zones. Since  HFOs visual detection is strenuous, there is a real need to develop accurate HFOs automatic detectors. In this paper, we present a comparative study of two detectors: one-dimensional (1D) Convolutional Neural Networks (CNN) running on High-Density Electroencephalograms signals and two dimensional (2D) CNN on time-frequency maps of those signals. Experimental results show that 1D-CNN enables easy end-to-end learning of preprocessing, feature extraction and classification modules while achieving competitive performance.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-84
2022,Appearance-Context aware Axial Attention for Fashion Landmark Detection,"Nikhil Kilari, Gaurab Bhattacharya, Pavan Kumar Reddy K, Jayavardhana Gubbi, Arpan Pal","Fashion landmark detection is a fundamental task in several fashion image analysis problems. The associated challenges involving non-rigid structures and variations in style and orientation makes it extremely hard to accurately detect the landmarks. In this paper, we propose Appearance-Context network (ACNet), which encapsulates both global and local contextual information extending the axial attention mechanism. We design axial attention augmented local appearance network and introduce a novel Global-Context aware axial attention module which aggregates the global features attending discriminatory cues across height, width and channel axes. The proposed ACNet architecture outperforms existing methods on two large-scale fashion landmark datasets.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-74
2022,Deep Convolutional Neural Networks with Sequentially Semiseparable Weight Matrices,"Matthias Kissel, Klaus Diepold","Modern Convolutional Neural Networks (CNNs) comprise millions of parameters. Therefore, the use of these networks requires high computing and memory resources. We propose to reduce these resource requirements by using structured matrices. For that, we replace weight matrices of the fully connected classifier part of several pre-trained CNNs by Sequentially Semiseparable (SSS) Matrices. By that, the number of parameters in these layers can be reduced drastically, as well as the number of operations required for evaluating the layer. We show that the combination of approximating the original weight matrices with SSS matrices followed by gradient-descent based training leads to the best prediction results (compared to just approximating or training from scratch).","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-21
2022,Deep learning for Parkinson’s disease symptom detection and severity evaluation using accelerometer signal,Tomasz Gutowski,"This paper presents a neural network for predicting the severity/presence of Parkinson’s disease motor symptoms – tremor, bradykinesia and dyskinesia, based on accelerometer signals collected while the patient is executing selected tasks. The suggested network uses accelerometer signals as input along with the type of completed task and the side the device is worn on. The data was collected in the Levodopa Response Study funded by MJFF. The model has been trained for every symptom separately and the results have helped to identify the tasks that result in the best accuracy of symptom detection and evaluation.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-107
2022,ROP inception: signal estimation with quadratic random sketching,"Remi Delogne, Vincent Schellekens, Laurent Jacques","Rank-one projections (ROP) of matrices and quadratic random sketching of signals support several data processing and machine learning methods, as well as recent imaging applications, such as phase retrieval or optical processing units. In this paper, we demonstrate how signal estimation can be operated directly through such quadratic sketches—equivalent to the ROPs of the ""lifted signal"" obtained as its outer product with itself—without explicitly reconstructing that signal. Our analysis relies on showing that, up to a minor debiasing trick, the ROP measurement operator satisfies a generalised sign product embedding (SPE) property. In a nutshell, the SPE shows that the scalar product of a signal sketch with the sign of the sketch of a given pattern approximates the square of the projection of that signal on this pattern. This thus amounts to an insertion (an inception) of a ROP model inside a ROP sketch. The effectiveness of our approach is evaluated in several synthetic experiments.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-97
2022,Semi-synthetic Data for Automatic Drone Shadow Detection,"Mohammed El Amine Mokhtari, Virginie Vandenbulcke, Sohaib Laraba, Matei Mancas, Elias Ennadifi, Mohamed Lamine Tazir, Bernard Gosselin","In this paper, we deal with the problem of shadow detection of UAVs, which impacts their navigation. We propose to generate synthetic images containing shadows in random locations, backgrounds, sizes, and opacities in order to augment our dataset. The generated data is used to train and compare several models to effectively detect, in real-time, UAVs shadows which will help to stabilize their localization and navigation. Deep learning models such as SSD, YOLOv3, and YOLOv5 are tested for the detection part. With our approach, we achieved 99\% of the mean average precision when using the YOLOv5.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-82
2022,Predicting Test Execution Times with Asymmetric Random Forests,"Francisco Pereira, Helio Silva, João Gomes, Javam Machado","Being able to estimate a test execution time is of fundamental importance when you need to prioritize tests. Furthermore, it is also important that an estimation algorithm do not underestimate the execution time, since time can be a hard constraint in many problems. If a test take longer than expected, some test that is planned to be executed in the future may have to be cancelled. Under such scenario, in this paper, we developed two simple variants of the Random Forest regression algorithm to predict test execution times in storage diagnostics tests. The proposed methods are compared to a baseline time estimation method (already available in a commercial product) and other machine learning based models. On the basis of our experiments we can state that the proposed variants achieved promising results when considering an asymmetric error metric.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-114
2022,Gap filling in air temperature series by matrix completion methods,"Benoît Loucheur, Pierre-Antoine Absil, Michel Journée","Quality control of meteorological data is an important part of atmospheric analysis and prediction, as missing or erroneous data can have a negative impact on the accuracy of these environmental products. In practice, the presence of missing data in the weather series is quite common and problematic for many uses. We have compared the performance of matrix completion methods with the state of the art to solve this missing data problem. The experimental results were carried out using the daily minimum and maximum temperature measurements of the network of weather stations operated by the Royal Meteorological Institute (RMI) of Belgium.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-67
2022,Improving Laplacian Pyramids Regression with Localization in Frequency and Time,"Neta Rabin, Ben Hen, Ángela Fernández","Auto-Adaptive Laplacian Pyramids (ALP) is an iterative kernel-based regression model. It constructs a multi-scale representation of the train data, where the multi-scale modes are average residuals. In this work, we demonstrate two extensions of the model. The first is a hybrid approach that combines ALP with Empirical Mode Decomposition to provide localization in the frequency domain. The second modifies ALP to fit datasets with non-uniform noise. This is achieved by computing the optimal stopping criterion in a point-dependent manner. Experimental results demonstrate these  models for solar energy prediction  and for forecasting epidemiology infections.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-106
2022,Minkowski logarithmic error: A physics-informed neural network approach for wind turbine lifetime assessment,"Francisco de Nolasco Santos, Pietro D'Antuono, Nymfa Noppe, Wout Weijtjens, Christof Devriendt","In this contribution we present a physics-informed neural network (PINN) approach for wind turbine fatigue estimation. This PINN incorporates physical information of the structure's fatigue profile in its loss function, referred to as Minkowski logarithmic error (MLE) - an extension of the log loss for any given Lp space. The function is mathematically analysed and differentiated in order to better understand its behaviour. The results obtained using the MLE are favourably compared with previous efforts using the mean squared logarithmic error. Finally, the long-term error is evaluated based on the effect of p.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-16
2022,Dynamics-aware Representation Learning via Multivariate Time Series Transformers,"Michael Potter, ILKAY YILDIZ POTTER, OCTAVIA CAMPS, MARIO SZNAIER","We propose a novel multivariate time series autoencoder, which produces interpretable linear-dynamical latent features that govern the predictions for several downstream tasks. To this end, we combine a transformer autoencoder with a dynamical atoms-based autoencoder to mimic Koopman operators in the latent space, without the need for finding eigenfunctions or their low-dimensional approximations. We demonstrate that our approach significantly outperforms deep Koopman operator learning baselines for time series forecasting on chaotic systems such as the Lorentz Attractor. Furthermore, the dynamics-aware representations, combined with a transformer classifier, lead to state-of-the-art classification accuracy on four benchmark multivariate time series datasets.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-12
2022,Wind power forecasting based on bagging extreme learning machine ensemble model,"Matheus Henrique Dal Molin Ribeiro, Sinvaldo Rodrigues Moreno, Ramon Gomes da Silva, José Henrique Kleinubing Larcher, Cristiane Canton, Viviana Cocco Mariani, Leandro dos Santos Coelho","The wind energy forecast is an useful tool for wind farm production planning, and operation, facilitating decision making in terms of maintenance, electricity market clearing, and load sharing. This study proposes a cooperative ensemble learning model, using time series pre-processing, multi-objective optimization, and artificial intelligence to forecast wind energy generation in two wind farms in Brazil. Multi-objective optimization is employed to combine variational mode decomposition-based components of a model with bootstrap aggregation (bagging) and extreme learning machine models. Forecasting accuracy is evaluated through the root mean squared error, mean absolute error, mean absolute percentage error, and Diebold-Mariano hypothesis test. The empirical results suggest that proposed ensemble learning model achieved better forecasting performance than bootstrap stacking, machine learning, artificial neural networks, and statistical models, with values of approximately 12.76%, 25.25%, 31.91%, and 34.76%, respectively, in terms of root mean squared errors reduction for out-of-sample forecasting.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-117
2022,Detection and Localization of GAN Manipulated Multi-spectral Satellite Images,"Lydia Abady, Giovanna Maria Dimitri, Mauro Barni","Owing to their realistic features and continuous improvements, images manipulated by Generative Adversarial Network (GAN) have become a compelling research topic. In this paper, we apply detection and localization to GAN manipulated images by means of models, based on EfficientNet-B4 architectures. Detection is tested on multiple generated multi-spectral datasets from several world regions and different GAN architectures, whereas localization is tested on an inpainted images dataset of sizes 2048×2048×13. The results obtained for both detection and localization are shown to be promising.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-39
2022,Deep Learning Approaches for mice glomeruli segmentation,"Duccio Meconcelli, Simone Bonechi, Giovanna Maria Dimitri","Deep learning (DL) is widely applied in biomedical image processing nowadays. In this paper, we propose the use of DL architectures for glomerulus segmentation in histopathological images of mouse kidneys. Indeed, in humans, the analysis of the glomeruli is fundamental to decide on the transplantability of the organ. However, no datasets with human samples are publicly available. Therefore, obtaining good segmentation performance on the kidneys of mice could be the first step for a transfer learning approach to humans. We compared the use of two well–known architectures for image segmentation, namely MobileNet and DeepLab V2. Both models showed very promising results.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-40
2022,A Deep Learning approach for oocytes segmentation and analysis,"Paolo Andreini, Niccolò Pancino, Filippo Costanti, Gabriele Eusepi, Barbara Toniella Corradini","Medical Assisted Procreation (MAP) has seen a sharp increase in demand over the past decade, due to a variety of reasons, including genetic factors, health conditions altered by stress and pollution, as well as delayed pregnancy and age-related loss of fertility.  The success of MAP techniques is strongly correlated to the dexterity of a human operator, who is asked to classify and select healthy oocytes to fertilize and return to the uterus. This work describes a deep learning approach to the segmentation of oocyte images, to support operators in their selection, to improve the success probability of MAP.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-44
2022,A weakly supervised approach to skin lesion segmentation,Simone Bonechi,"Early detection of skin cancers greatly increases patients' chances of recovery. To support dermatologists in this diagnosis, many decision support systems based on Convolutional Neural Networks have recently been proposed to segment the lesion and classify it. The use of the information coming from the segmentation, as an additional input to the classifier, proved to be fundamental to increase its performance and, in fact, the shape of the lesion is of diagnostic importance unanimously recognized by clinicians. However, in the ISIC database, the public reference dataset that collects a huge number of skin lesion images, all samples are labeled for classification but only a very small fraction of them are also labeled for segmentation. To overcome this limitation, the present paper proposes a weakly supervised approach to extract the segmentation label maps of approximately 43,000 ISIC images, used to train a segmentation network, with very promising performance.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-46
2022,Deep Semantic Segmentation in Skin Detection,"Daniela Cuza, Andrea Loreggia, Alessandra Lumini, Loris Nanni","Deep semantic segmentation is a task that identifies objects and their boundaries in images, to do that a classification task is performed at the pixel level to tag whether a pixel belongs to an object. In skin detection, areas of images are classified as skin or non-skin regions. In this work, we report a short survey of the recent literature covering the task to help researchers in selecting the most suitable method for their application and to expand the knowledge about the available datasets for this topic. A compact empirical evaluation comparing recent models and a new ensemble model is reported.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-35
2022,Lightening CNN architectures by regularization driven weights' pruning,"Giovanni Bonetta, Rossella Cancelliere","Deep learning models are getting increasingly big, leading towards overparametrized architectures with high computational and storage requirements. This hinders the possibility to train/deploy them on IoT or mobile devices, while also creating concerns about their environmental fingerprint. We propose a regularization technique which allows to selectively shrink the norm of non significant weights in order to subsequently prune them, generating highly compressed models. We tested the proposed technique on three well known image classification tasks, obtaining results on par or better than competitors in terms of sparsity and metrics.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-102
2022,Real-time capable Ensemble Estimation for 2D Object Detection,"Lukas Enderich, Simon Heming","Deep neural networks tend to make overconfident predictions. Although ensemble methods improve the predictive performance by producing better calibrated confidences, they are computationally expensive. Thus, we propose a real-time capable ensemble method for object detection that significantly improves the performance with only a minor increase in runtime. Our method diversifies the prediction of the class probabilities on the anchor space using multiple classification heads. A regularization further increases the diversity of the heads, making ensemble distillation unnecessary. On the KITTI benchmark dataset, our approach increases the mean average precision of an SSD based network from 0.58 to 0.71.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-41
2022,Battery detection of XRay images using transfer learning,"Nermeen Abou Baker, David Rohrschneider, Uwe Handmann","The need for detecting and sorting batteries is drastically increasing for many applications. This study proves the potential of transfer learning in predicting whether the image contains a battery or not, the location and identifying three types of batteries, namely: prismatic, pouch, and cylindrical Lithium-Ion Batteries (LIB). Particularly, it focuses on the transfer learning method in two applications: Training a large-scale dataset to detect electronic devices using a pre-trained YOLOv5m, then using these latter trained weights to detect and classify the batteries. The precision of battery detection achieves 94%, which outperforms the pre-trained YOLOv5m weights with 5%, in 22ms inference time.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-60
2022,PCA improves the adversarial robustness of neural networks,"István Megyeri, Ammar  Al-Najjar","Deep neural networks perform well in many visual recognition tasks, but they are sensitive to adversarial input perturbation. More robust models can be learned when attacks are applied to the training data or preprocessing is used. However, the effect of preprocessing is frequently underestimated and it has not received sufficient attention as it usually does not affect the network's clean accuracy. Here, we seek to demonstrate that preprocessing can play a role in improving adversarial robustness. Our empirical results show that principal component analysis, a simple yet effective preprocessing method, can significantly improve neural networks' robustness for both regular and adversarial training.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-96
2022,Deep networks with ReLU activation functions can be smooth statistical models,Joseph Rynkiewicz,"Most Deep neural networks use ReLU activation functions. Since these functions are not differentiable in $0$, we may believe that such models may have irregular behavior. In this paper, we will show that the issue is more in the data than in the model, and if the data are ``smooth'', the model will be differentiable in a suitable sense. We give a striking illustration of this fact with the example of adversarial attacks.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-20
2022,Challenges in anomaly and change point detection,"Madalina Olteanu, Fabrice Rossi, Florian Yger","This paper presents an introduction to the state-of-the-art in anomaly and change-point detection. On the one hand, the main concepts needed to understand the vast scientific literature on those subjects are introduced. On the other, a selection of important surveys and books, as well as two selected active research topics in the field, are presented.",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-6
2022,Anomaly detections on the oil system of a turbofan engine by a neural autoencoder,"Jean Coussirou, Thomas Vanaret, Jérôme Lacaille",The turbofan engine uses oil to lubricate and cool its components. This extremely sensitive system can cause in-flight engine shutdowns in the event of a failure. This article presents the implementation of a fully automatic anomaly detection system capable of detecting both known phenomena and exceptional cases using weak signals.,Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-24
2022,Contrasting Explanation of Concept Drift,"Fabian  Hinder, André Artelt, Valerie Vaquet, Barbara Hammer","The notion of concept drift refers to the phenomenon that the distribution, which is underlying the observed data, changes over time; as a consequence machine learning models may become inaccurate and need adjustment. While there do exist methods to detect concept drift or to adjust models in the presence of observed drift, the question of explaining drift is still widely unsolved. This problem is of importance, since it enables an understanding of the most prominent drift characteristics. In this work we propose to explain concept drift by means of contrasting explanations describing characteristic changes of spatial features. We demonstrate the usefulness of the explanation in several examples.",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-71
2022,Anomaly detection and representation learning in an instrumented railway bridge,"Yacine Bel-Hadj, Wout Weijtjens, Francisco de Nolasco Santos","In this contribution, the strain measurements of a railway bridge are used for anomaly detection, in the context of Structural Health Monitoring (SHM). The methodology used is a combination of a sparse convolutional autoencoder (CSAE) and a Mahalanobis distance. Due to the lack of labeled anomalous data, a simulated fault is used to evaluate the performance of the algorithm. The proposed approach far outperforms the classical feature-based approach. Finally, the latent dimension of the autoencoder is studied and shown to be structured and representative of the underlying physics of the problem.",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-29
2022,Deep Semantic Segmentation Models in Computer Vision,"Paolo Andreini, Giovanna Maria Dimitri","Recently, deep learning models have had a huge impact on computer vision applications, in particular in semantic segmentation, in which many challenges are open. As an example, the lack of large annotated datasets implies the need for new semi-supervised and unsupervised techniques. This problem is particularly relevant in the medical field due to privacy issues and high costs of image tagging by medical experts. The aim of this tutorial overview paper is to provide a short overview of the recent results and advances regarding deep learning applications in computer vision particularly for what concerns semantic segmentation",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-5
2022,Data stream generation through real concept's interpolation,"Joanna Komorniczak, Pawel Ksieniewicz",Among the recently published works in the field of data stream analysis – both in the context of classification task and concept drift detection – the deficit of real-world data streams is a recurring problem. This article proposes a method for generating data streams with given parameters based on real-world static data. The method uses one-dimensional interpolation to generate sudden or incremental concept drifts. The generated streams were subjected to an exemplary analysis in the concept drift detection task using a detector ensemble. The method has the potential to contribute to the development of methods focused on data stream processing.,Concept drift,https://doi.org/10.14428/esann/2022.ES2022-49
2022,Federated learning vector quantization for dealing with drift between nodes,"Johannes Brinkrolf, Valerie Vaquet, Fabian  Hinder, Patrick Menz, Udo Seiffert, Barbara Hammer",Federated learning is an efficient methodology to reduce the data transmissions to the server when working with large amounts of (sensor) data from diverse physical locations. When using data from different sensor devices concept drift between the single sensors poses an additional challenge. In this contribution we define a formal framework for federated learning with concept drift and propose a version of federated LVQ dealing with concept drift induced by different hyperspectral cameras. We evaluate this approach experimentally and demonstrate its robustness to class imbalance and missing classes.,Concept drift,https://doi.org/10.14428/esann/2022.ES2022-89
2022,From hyperspectral to multispectral sensing – from simulation to reality: A comprehensive approach for calibration model transfer,"Patrick Menz, Valerie Vaquet, Barbara Hammer, Udo Seiffert","High-resolution hyperspectral sensors provide precise but expensive information of the chemical composition of an object in various industries. We present a method to transfer this ability into customized low-budget multispectral solutions. Based on a relevance analysis of spectra for a given problem, we simulated and constructed a multispectral sensor based on inverse spectroscopy. The corresponding calibration model derived from simulation of such a device and linked to the multispectral sensor hardware must not drop in precision significantly. For this purpose, different methods of calibration model transfer were tested, which can cope with a limited subset of the data. The latent space transformation with Chebychev polynomials outperformed all other methods by achieving high performance with the fewest labeled data.",Concept drift,https://doi.org/10.14428/esann/2022.ES2022-56
2022,High Accuracy and Low Regret for User-Cold-Start Using Latent Bandits,"David Young, Douglas Leith","We develop a novel latent-bandit algorithm for tackling the cold-start problem for new users joining a recommender system. This new algorithm significantly outperforms the state of the art, simultaneously achieving both higher accuracy and lower regret.","Natural language processing, and recommender systems",https://doi.org/10.14428/esann/2022.ES2022-79
2022,Neural Architecture Search for Sentence Classification with BERT,"Philip Kenneweg, Sarah Schröder, Barbara Hammer","Pre training of language models on large text corpora is common prac- tice in Natural Language Processing. Following, fine tuning of these models is per- formed to achieve the best results on a variety of tasks. In this paper we question the common practice of only adding a single output layer as a classification head on top of the network. We perform an AutoML search to find architectures that outperform the current single layer at only a small compute cost. We validate our classification architecture on a variety of NLP benchmarks from the GLUE dataset. The source code is open-source and free (MIT licensed) software, available at https://github.com/TheMody/ NASforSentenceEmbeddingHeads.","Natural language processing, and recommender systems",https://doi.org/10.14428/esann/2022.ES2022-45
2022,Attention-based Ingredient Phrase Parser,"Zhengxiang Shi, Pin Ni, Meihui Wang, To Eun Kim, Aldo Lipani","As virtual personal assistants have now penetrated the consumer market, with products such as Siri and Alexa, the research community has produced several works on task-oriented dialogue tasks such as hotel booking, restaurant booking, and movie recommendation. Assisting users to cook is one of these tasks that are expected to be solved by intelligent assistants, where ingredients and their corresponding attributes, such as name, unit, and quantity, should be provided to users precisely and promptly. However, existing ingredient information scraped from the cooking website is in the unstructured form with huge variation in the lexical structure, for example, “1 garlic clove, crushed”, and “1 (8 ounce) package cream cheese, softened”, making it difficult to extract information exactly. To provide an engaged and successful conversational service to users for cooking tasks, we propose a new ingredient parsing model that can parse an ingredient phrase of recipes into the structure form with its corresponding attributes with over 0.93 F1-score. Experimental results show that our model achieves state-of-the-art performance on AllRecipes and Food.com datasets.","Natural language processing, and recommender systems",https://doi.org/10.14428/esann/2022.ES2022-10
2022,Improving Intensive Care Chest X-Ray Classification by Transfer Learning and Automatic Label Generation,"Helen Schneider, David Biesner, Sebastian Nowak, Yannik Layer, Maike Theis, Wolfgang Block, Benjamin Wulff, Alois M. Sprinkart, Ulrike I. Attenberger, Rafet Sifa","Radiologists commonly conduct chest X-rays for the diagnosis of pathologies or the evaluation of extrathoracic material positions in intensive care unit (ICU) patients. Automated assessments of radiographs have the potential to assist physicians by detecting pathologies that pose an emergency, leading to faster initiation of treatment and optimization of clinical workflows. The amount and quality of training data is a key aspect for developing deep learning models with reliable performance.  This work investigates the effects of transfer learning on public data, automatically generated data labels and manual data annotation on the classification of ICU chest X-rays of a German hospital.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-85
2022,Interactive visual analytics for medical data: application to COVID-19 clinical information during the first wave,"Ignacio Diaz-Blanco, Jose M. Enguita-Gonzalez, Diego Garcia-Perez, Maria Dolores Chiara-Romero, Nuria Valdes-Gallego, Ana Gonzalez-Muñiz, Abel A. Cuadrado-Vega","Biomedical data recorded as a result of clinical practice are often multi-domain -involving lab measurements, medication, patient attributes, logistic information-, and also highly unstructured, with high rates of missing data and asynchronously sampled measurements. In this scenario, we need tools capable of providing a broad picture prior to more detailed analyses. We present here a visual analytics approach that uses the morphing projections technique to combine the visualization of a t-SNE projection of clinical time series, with views of other clinical or patient's information. The proposed approach is demonstrated on an application case study of COVID-19 clinical information taken during the first wave.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-31
2022,Efficient classification learning of biochemical structured data by means of relevance weighting for sensoric response features,"Katrin Sophie Bohnsack, Marika Kaden, Julius Voigt, Thomas Villmann","We present an approach for generating vectorial representations of graphs for machine learning applications based on a sensoric response principle and multiple graph kernels. The sensor perspective reduces the graph kernel computations significantly. Thus, multiple kernel (relevance) learning can be realized using the interpretable generalized matrix learning vector quantization (GMLVQ) classifier. Results obtained in small molecule classification serve as proof of concept.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-36
2022,Interactive dual projections for gene expression analysis,"Ignacio Diaz-Blanco, Jose M. Enguita-Gonzalez, Diego Garcia-Perez, Ana Gonzalez-Muñiz, Abel A. Cuadrado-Vega, Maria Dolores Chiara-Romero, Nuria Valdes-Gallego","We present an application of interactive dimensionality reduction (DR) for exploratory analysis of gene expression data that produces two lively updated projections, a sample map and a gene map, by rendering intermediate results of a t-SNE. The user can condition the projections ""on the fly"" by subsets of genes or samples, so updated views reveal co-expression patterns for different cancer types or gene groups.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-22
2022,Tutorial - Machine Learning and Information Theoretic Methods for Molecular Biology and Medicine,"Thomas Villmann, Jonas Almeida, Lee John, Susana Vinga","A short introduction to the application of information-theoretic and machine learning methods to biomolecular  and medical data is provided as the motivating material that supports special session dedicated to this topic at ESANN 2022. In particular, we highlight current developments of foundation such as interpretability and model certainty. Further, we emphasize how theoretic models provide a natural framework to deal with heterogeneous and complex data structures as frequently occurring in biomedical research.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-3
2022,Orthogonality in Additive Echo State Networks,"Andrea Ceni, Claudio Gallicchio","Reservoir computing (RC) is a state-of-the-art approach for efficient training in temporal domains. In this paper, we explore new RC architectures that generalise the popular leaky echo state network model (leaky-ESN) introducing an additive orthogonal term outside the nonlinear part of the ESN equation. We investigate the benefits of employing orthogonal matrices in ESNs both inside the nonlinearity and outside of it. We show empirically how to boost the memory capacity towards the theoretical maximum value while still preserving the power of nonlinear computations. Ergo, we optimise the compromise between computing with memory and computing with nonlinearity. The proposed model demonstrates to outperform both leaky-ESN and orthogonal reservoir ESN models on tasks requiring nonlinear computations with memory.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-47
2022,Towards Better Transition Modeling in Recurrent Neural Networks: the Case of Sign Language Tokenization,"Pierre Poitier, Jérôme Fink, Benoit Frénay","Recurrent neural networks can be used to segment sequences such as videos, where transitions can be challenging to detect.  This paper benchmarks strategies to better model the transition between states.  The specific task of SL video tokenization is chosen for the evaluation, as it remains challenging.  Tokenizers are the cornerstone of natural language processing pipelines.  There exist powerful tokenizers for such data, but sign language (SL) video tokenizers are still under development.  Benchmarked strategies prove to be useful to improve SL videos tokenization, but there is still room for improvement to better model state transitions.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-50
2022,Federated Adaptation of Reservoirs via Intrinsic Plasticity,"Valerio De Caro, Claudio Gallicchio, Davide Bacciu","We propose a novel algorithm for performing federated learning with Echo State Networks (ESNs) in a client-server scenario. In particular, our proposal focuses on the adaptation of reservoirs by combining Intrinsic Plasticity with Federated Averaging. The former is a gradient-based method for adapting the reservoir's non-linearity in a local and unsupervised manner, while the latter provides the framework for learning in the federated scenario. We evaluate our approach on real-world datasets from human monitoring, in comparison with the previous approach for federated ESNs existing in literature. Results show that adapting the reservoir with our algorithm provides a significant improvement on the performance of the global model.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-98
2022,Recurrent Restricted Kernel Machines for Time-series Forecasting,"Arun Pandey, Hannes De Meulemeester, Henri De Plaen, Bart De Moor, Johan Suykens","In this paper, we propose a novel method for time-series modeling and forecasting. It is based on the temporal formulation of Restricted Kernel Machines leading to a dynamical equation in the latent-variables. Forecasting involves finding the next latent variable and then solving a pre-image problem to predict a new-point in the input space. Further, we benchmark our model on several standard data sets against other well-known time-series models.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-120
2022,Input Routed Echo State Networks,"Luca Argentieri, Claudio Gallicchio, Alessio Micheli","We introduce a novel Reservoir Computing (RC) approach for multi-dimensional temporal signals. Our proposal is based on routing the different dimensions of the driving input towards different dynamical sub-modules in a multi-reservoir architecture. At the same time, controllable interconnections among the sub-modules allow modeling the interplay between the different dynamics that might be required by the task. Experiments on synthetic and real-world time-series classification problems clearly show the advantages of the proposed approach in dealing with multi-dimensional signals in comparison to standard RC neural networks.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-90
2022,Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning,"Yi Zhao, Rinu Boney, Alexander Ilin, Juho Kannala,  Joni Pajarinen","Offline reinforcement learning, by learning from a fixed dataset, makes it possible to learn agent behaviors without interacting with the environment. However, depending on the quality of the offline dataset, such pre-trained agents may have limited performance and would further need to be fine-tuned online by interacting with the environment. During online fine-tuning, the performance of the pre-trained agent may collapse quickly due to the sudden distribution shift from offline to online data. We propose to adaptively weigh the behavior cloning loss during online fine-tuning based on the agent's performance and training stability. Moreover, we use a randomized ensemble of Q functions to further increase the sample efficiency of online fine-tuning by performing a large number of learning updates. Experiments show that the proposed method yields state-of-the-art offline-to-online reinforcement learning performance on the popular D4RL benchmark.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-110
2022,Reinforcement learning for constructing low density sign representations of Boolean functions,"Oytun Yapar, Erhan Oztop","Boolean functions (BFs) can be uniquely represented with polynomial functions by representing True and False with ±1. With the ’sign-representation’ framework, i.e., when the sign of the polynomials is used instead of the exact ±1, the representation is not unique anymore, and several measures of sign-representation become the target of research. One such measure is the polynomial threshold function density (PTF density), i.e., the minimum number of monomials that suffices to sign-represent a given BF. Several algorithms can find sign-representations with a low number of monomials; however, to find a representation with the minimum number of monomials possible is a combinatorial search problem. The recent success of reinforcement learning (RL) algorithms in solving combinatorial search problems poses the question of whether RL can perform well in finding sign-representations with a low number of monomials. To address this question, we focused on Deep Q-Networks (DQN) and explored its applicability to the sign-representation problem. To be concrete, we present our work on modeling RL agents for solving the sign-representation problem and give our results on the application of DQN to BFs with a low number of variables (n = 4). Our results indicate that the trained DQN agent generalizes well and  exploits intrinsic structure of BFs, such as their equivalence in terms of certain equivalence relations.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-25
2022,Developmental Modular Reinforcement Learning,"Jianyong Xue, Frédéric Alexandre","In this article, we propose a modular reinforcement learning (MRL) architecture that coordinates the competition and the cooperation between modules, and inspires, in a developmental approach, the generation of new modules in cases where new goals have been detected. We evaluate the effectiveness of our approach in a multiple-goal torus grid world. Results show that our approach has better performance than previous MRL methods in learning separate strategies for sub-goals, and reusing them for solving task-specific or unseen multi-goal problems, as well as maintaining the independence of the learning in each module.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-19
2022,Embedding-based next song recommendation for playlists,"Raphaël Romero, Tijl De Bie","In recent years, music storage and consumption has shifted massively to digital platforms, where large-scale libraries of songs are stored along with their metadata. As a byproduct of this transformation, music is increasingly being organized and accessed in the form of playlists. User-curated playlists have become massively available online, and the challenge of automatically generating playlists has gained popularity in the music information retrieval community. In this paper, we build on link prediction for graphs to propose a flexible music playlist generation method. We transform a playlist dataset into a weighted graph of songs and posit a Poisson model on the count of co-occurence between songs, where the rate is modulated by the euclidean distance between song embeddings. Our method yields prediction results superior to common deterministic baselines, suggesting that the learned embeddings can be used to derive a meaningful notion of song similarity.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-28
2022,Graph Neural Networks for Propositional Model Counting,Gaia Saveri,"Graph Neural Networks (GNNs) have been recently leveraged to solve several logical reasoning tasks. Nevertheless, counting problems such as propositional model counting (#SAT) are still mostly approached with traditional solvers. Here we tackle this gap by presenting an architecture based on the GNN framework for belief propagation (BP) of [Kuck et al., 2020], extended with self-attentive GNN and trained to approximately solve the #SAT problem. We experimentally show that our model, trained on a small set of random Boolean formulae, is able to scale effectively to much larger problem sizes, outperforming state of the art approximate solvers. Moreover, we show that it can be efficiently fine-tuned to provide good generalization results on different formulae distributions.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-88
2022,Revisiting Edge Pooling in Graph Neural Networks,Francesco Landolfi,"Sparse pooling methods for graph neural networks typically perform graph reduction by keeping only the top-k vertices according to an adaptive scoring function. Although fast and scalable, these methods destroy the relational information of the graph or even make it disconnected. EdgePool is one of the few sparse alternatives that preserve the connectivity of the input graph by performing a series of edge contractions according to an adaptive scoring of the edges, but it has the drawback of being sequential and not scalable on large scale graphs. In this paper we show that EdgePool can be efficiently computed using a well-known parallel algorithm from literature, and we also propose a novel, lightweight alternative that leverages on an adaptive scoring function of the nodes. We tested both methods on standard benchmark datasets, showing that they generally outperform other sparse pooling methods from literature.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-92
2022,Size Scaling in Self-Play Reinforcement Learning,"Oren Neumann, Claudius Gros","Performance scaling laws with resources are heavily studied in supervised deep learning models but not in reinforcement learning. We examine the scaling of the AlphaZero algorithm’s performance with model size by training agents on three competitive two-player games, Connect Four, Oware and Pentago. We find that performance, in the form of Elo rating, scales logarithmically with the number of free neural network parameters, a trend consistent across games and when using deeper neural networks. This leads to a universal expression for the average match outcome which depends only on the ratio of sizes between opponents, which is supported by an agnostic rating method.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-53
2022,Hyperspectral Wavelength Analysis with U-Net for Larynx Cancer Detection,"Felix Meyer-Veit, Rania Rayyes, Andreas O. H. Gerstner, Jochen J. Steil","Early detection of laryngeal tumors is critical for their successful therapy. In this paper, we investigate how hyperspectral (HS) imaging can contribute to this aim based on an in-vivo data set of 13 HS image cubes recorded in clinical practice. We perform semantic segmentation with a tailored U-Net trained on labels provided by the clinicians. We specifically investigate the influence of exposure time during image acquisition, the suitable wavelengths to determine the most informative image channels, and present quantitative results on accuracy and the AUC measure.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-100
2022,Feature Compression Using Dynamic Switches in Multi-split CNNs,"Suresh Kirthi  Kumaraswamy, Alexey  Ozerov, Ngoc Q. K. Duong, Anne Lambert, François Schnitzler, Patrick Fontaine","Convolutional neural networks (CNN) are often computationally demanding for mobile devices. Offloading some computation lowers this burden: initial convolutional layers are processed on a smartphone, the resulting high dimensional features transmitted, and latter layers processed in the cloud/edge/another device. To improve this process, we propose Dynamic Switch, a convolutional subnetwork enabling anywhere splittable CNNs with multirate feature compression using a single set of network parameters. We achieve 90% feature compression with at most 3% accuracy loss for MobileNet and MSDNet on ImageNet dataset and at most 4.58% on CIFAR100 dataset with MSDNet, ResNet-18, MobileNet/MobileNetv2 and ShuffleNet/ShuffleNetv2.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-18
2022,Neural-network-based estimation of normal distributions in black-box optimization,"Jiří Tumpach, Jan Koza, Martin Holeňa","The paper presents a novel application of artificial neural networks (ANNs) in the context of surrogate models for black-box optimization, i.e. optimization of objective functions that are accessed through empirical evaluation. For active learning of surrogate models, a very important role plays learning of multidimensional normal distributions, for which Gaussian processes (GPs) have been traditionally used. On the other hand, the research reported in this paper evaluated the applicability of two ANN-based methods to this end: combining GPs with ANNs and learning normal distributions with evidential ANNs. After methods sketch, the paper brings their comparison on a large collection of data from surrogate-assisted black-box optimization. It shows that combining  GPs using linear covariance functions with ANNs yields lower errors than the investigated methods of evidential learning.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-113
2022,Bayes Point Rule Set Learning,"Mirko Polato, Fabio Aiolli, Luca Bergamin, Tommaso Carraro","This paper proposes an effective bottom-up extension of the popular FIND-S algorithm to learn (monotone) DNF-type rulesets. The algorithm greedily finds a partition of the positive examples. The produced monotone DNF is a set of conjunctive rules, each corresponding to the most specific rule consistent with a part of positive and all negative examples.  We also propose two principled extensions of this method, approximating the Bayes Optimal Classifier by aggregating monotone DNF decision rules.  Finally, we provide a methodology to improve the explainability of the learned rules while retaining their generalization capabilities. An extensive comparison with state-of-the-art symbolic and statistical methods on several benchmark data sets shows that our proposal provides an excellent balance between explainability and accuracy.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-108
2022,Beyond Homophily with Graph Echo State Networks,"Domenico Tortorella, Alessio Micheli","Graph Echo State Networks (GESN) have already demonstrated their efficacy and efficiency in graph classification tasks. However, semi-supervised node classification brought out the problem of over-smoothing in end-to-end trained deep models, which causes a bias towards high homophily graphs. We evaluate for the first time GESN on node classification tasks with different degrees of homophily, analyzing also the impact of the reservoir radius. Our experiments show that reservoir models are able to achieve better or comparable accuracy with respect to fully trained deep models that implement ad hoc variations in the architectural bias, with a gain in terms of efficiency.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-58
2022,Biased Edge Dropout in NIFTY for Fair Graph Representation Learning,"Federico Caldart, Luca Pasa, Luca Oneto, Alessandro Sperduti, Nicolò Navarin","Graph Neural Networks (GNNs) are nowadays widely used in many real-world applications. Nonetheless, the data relationships can be a source of biases based on sensitive attributes (e.g., gender or ethnicity). Several methods have been proposed to learn fair graph node representations.  In this work we extend NIFTY, an approach that exploits additional terms in the loss function based on perturbing the input data to enforce the fairness of the GNNs. In particular, we exploit a biased perturbation of the adjacency matrix of the graph able to reduce the edge homophily. We show the effectiveness of our approach in four real-world graph datasets.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-99
2022,Deep Learning for Graphs,"Davide Bacciu, Federico Errica, Nicolò Navarin, Luca Pasa, Daniele Zambon","The flourishing field of deep learning for graphs relies on the layered computation of representations from graph-structured data given as input. A widely used strategy for processing graphs is via message passing, based on exchanging information among the connected nodes of the graph. Subsequently, node representations are employed to address tasks associated with the nodes and edges of a graph, or even entire graphs. The present tutorial paper reviews fundamental concepts and open challenges of deep learning for graphs and summarizes the contributed papers of the ESANN 2022 special session on the topic.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-7
2022,Improving Zorro Explanations for Sparse Observations with Dense Proxy Data,"Andreas Mazur, André Artelt, Barbara Hammer","Explanation methods are considered the most prominent way of achieving the ubiquitous requirement of transparency. Ideally, in order to be useful, explanations should be ""easy to understand'' -- i.e. being of low complexity. In this work, we empirically study explanations generated by Zorro, a prominent explanation method for Graph Neural Networks. We propose a methodology to improve the quality of generated explanations in case of sparse observations in the particular application of a standard reinforcement learning scenario.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-27
2023,"Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness","Maura Pintor, Ambra Demontis, Battista Biggio","In recent years, machine learning has become the most effective way to analyze massive data streams. However, machine learning is also subject to security and reliability issues. These aspects require machine learning to be thoroughly tested before being deployed in unsupervised scenarios, such as services intended for consumers. The goal of this session is to discuss open challenges, both theoretical and practical, related to the security and safety of machine learning. The session will try to address the following challenges: (i) the implementation of efficient tests for Machine Learning in the context of robustness to attacks and natural drifts of data; and (ii) the design of robust and efficient models able to function in the wild and mitigate or detect adversarial attacks.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-5
2023,Secure Federated Learning with Kernel Affine Hull Machines,"Mohit Kumar, Bernhard Moser, Lukas Fischer","The concept of Kernel Affine Hull Machine (KAHM) was recently introduced for representing data via learning in Reproducing Kernel Hilbert Spaces. KAHM defines a bounded geometric body in data space such that a distance measure from the geometric body can be used to aggregate local KAHM-based models to build a global model. This study leverages KAHMs for secure federated learning where data is protected from an aggressive aggregator by fully homomorphic encryption. An accurate and computationally efficient federated learning architecture, that combines local KAHMs-based classifiers in a robust and flexible manner such that the global model can be homomorphically evaluated in an efficient manner, is provided.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-56
2023,Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization,"Giorgio Piras, Giuseppe Floris, Raffaele Mura, Luca Scionis, Maura Pintor, Battista Biggio, Ambra Demontis","Evaluating the adversarial robustness of machine-learning models using gradient-based attacks is challenging. In this work, we show that hyperparameter optimization can improve fast minimum-norm at- tacks by automating the selection of the loss function, the optimizer, and the step-size scheduler, along with the corresponding hyperparam- eters. Our extensive evaluation involving several robust models demon- strates the improved efficacy of fast minimum-norm attacks when hyped up with hyperparameter optimization. We release our open-source code at https://github.com/pralab/HO-FMN.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-164
2023,Graph Representation Learning,"Davide Bacciu, Federico Errica, Alessio Micheli, Nicolò Navarin, Luca Pasa, Marco Podda, Daniele Zambon","In a broad range of real-world machine learning applications, representing examples as graphs is crucial to avoid a loss of information. Due to this in the last few years, the definition of machine learning methods, particularly neural networks, for graph-structured inputs has been gaining increasing attention.  In particular, Deep Graph Networks (DGNs)  are nowadays the most commonly adopted models to learn a representation that can be used to address different tasks related to nodes, edges, or even entire graphs. This tutorial paper reviews fundamental concepts and open challenges of graph representation learning and summarizes the contributions that have been accepted for publication to the ESANN 2023 special session on the topic.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-4
2023,Improving Fairness via Intrinsic Plasticity in Echo State Networks,"Andrea Ceni, Davide Bacciu, Valerio De Caro, Claudio Gallicchio, Luca Oneto","Artificial Intelligence, and in particular Machine Learning, has become ubiquitous in today's society, both revolutionizing and impacting society as a whole. However, it can also lead to algorithmic bias and unfair results, especially when sensitive information is involved. This paper addresses the problem of algorithmic fairness in Machine Learning for temporal data, focusing on ensuring that sensitive time-dependent information does not unfairly influence the outcome of a classifier. In particular, we focus on a class of training-efficient recurrent neural models called Echo State Networks, and show, for the first time, how to leverage local unsupervised adaptation of the internal dynamics in order to build fairer classifiers. Experimental results on real-world problems from physiological sensor data demonstrate the potential of the proposal.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-90
2023,Is Boredom an Indicator on the way to Singularity of Artificial Intelligence? Hypotheses as Thought-Provoking Impulse,Martin Bogdan,"In the past, the question regarding the point of singularity in artificial intelligence - when machines become more intelligent than humans - has been raised again and again. In this publication, a crucial point of human intelligence and the impact on this discussion will be postulated in the form of 3 hypotheses as thought-provoking impulse based on the basic hypothesis, that only systems which can be bored are intelligent. First, boredom is discussed from the perspective of psychology with its influence on human intelligence before deductions are drawn from this to artificial intelligence resp. machine learning. Finally, the hypotheses are formulated and the resulting future investigations are outlined.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-89
2023,Adversarial Auditing of Machine Learning Models under Compound Shift,"Karan Bhanot, Dennis Wei, Ioana Baldini, Kristin Bennett","Machine learning (ML) models often perform differently under distribution shifts, in terms of utility, fairness, and other dimensions. We propose the Adversarial Auditor for measuring the utility and fairness performance of ML models under compound shifts of outcome and protected attributes. We use Multi-Objective Bayesian Optimization (MOBO) to account for multiple metrics and identify shifts where model performance is extreme, both good and bad. Using two case studies, we show that MOBO performed better than random and grid-based approaches in identifying scenarios by adversarially optimizing objectives, highlighting the value of such an auditor for developing fair, accurate and shift-robust models.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-182
2023,Language Modeling in Logistics: Customer Calling Prediction,"Xi Chen, Giacomo Anerdi, Daniel Tan, Stefano Bromuri","Customer centers in logistics companies deal with many customer calls and requests daily.  One of the most common calls is related to requesting an update on the shipment status. Proactively sending message updates to customers can reduce the number of calls. However, naively sending updates to everyone can cause unnecessary anxiety to people who do not want it, thus leading to customer dissatisfaction or even more calls. If a machine learning model could predict shipments leading to a customer call based on its journey, it could be possible to proactively send message updates only to customers likely to make a call. Therefore, reducing the workload in the customer center while increasing customer satisfaction. In large logistic companies where the volume of calls can reach a million calls per month, even 10\% of the reduction of calls could already significantly reduce the additional expenses and workload associated with tracing a shipment.  In this paper, we formulate the shipment journey as a variant of a language model. Specifically, we treat checkpoints (station, facility, time, event code) as tokens and predict the next checkpoint(station, facility, time delta, event code).  Our core insight is that shipment checkpoints follow a set of rules that dictate the possible sequence of checkpoints. This is similar to how grammar rules dictate which words can follow another. Despite remaining a difficult problem, our experiments show that features learned by modeling shipment checkpoints as a language model can improve customer calling prediction.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-78
2023,Learning with Boosting Decision Stumps for Feature Selection in Evolving Data Streams,Daniel  Nowak-Assis,"Feature selection plays an important role in Machine Learning pipelines, and many challenges emerge for feature selection when data arrives continuously as a stream. In this paper, we extend the Adaptive Boosting for Feature Selection (ABFS) algorithm by (i) using a different Online Boosting strategy and (ii) changing the Boosting scaling factor of instances weighting. Results show that our extended ABFS leveraged the predictive performance of classifiers more than the standard ABFS in the most used monolithic classifiers for stream mining.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-16
2023,Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis,"Zhengxiang Shi, Aldo Lipani","In recent years, language models (LMs) have made remarkable progress in advancing the field of natural language processing (NLP). However, the impact of data augmentation techniques on the fine-tuning performance of these LMs has been a topic of ongoing debate. In this study, we evaluate the effectiveness of three different fine-tuning methods in conjugation with back-translation across an array of seven diverse NLP tasks. These tasks encompass classification and regression assignments, involving both single-sentence and sentence-pair challenges. Contrary to prior assumptions that data augmentation does not contribute to the enhancement of LMs’ fine-tuning performance, our findings reveal that continued pre-training on augmented data can effectively improve the fine-tuning performance of the downstream tasks. In the most favorable case, continued pre-training improves the performance of fine-tuning by more than 10% in the few-shot learning setting. Our finding highlights the potential of data augmentation as a powerful tool for bolstering LMs' performance.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-42
2023,On Instance Weighted Clustering Ensembles,"Paul Moggridge, Na Helian, Yi Sun, Mariana Lilley","Ensemble clustering is a technique which combines multiple clustering results, and instance weighting is a technique which highlights important instances in a dataset. Both techniques are known to enhance clustering performance and robustness. In this research, ensembles and instance weighting are integrated with the spectral clustering algorithm. We believe this is the first attempt at creating diversity in the generative mechanism using density based instance weighting for a spectral ensemble. The proposed approach is empirically validated using synthetic datasets comparing against spectral and a spectral ensemble with random instance weighting. Results show that using the instance weighted sub-sampling approach as the generative mechanism for an ensemble of spectral clustering leads to improved clustering performance on datasets with imbalanced clusters.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-91
2023,Fine-tuning is not (always) overfitting artifacts,"Jérémie Bogaert, Emmanuel Jean, Cyril de Bodt, François-Xavier Standaert","Since their release, transformers, and in particular fine-tuned transformers are widely used for text related classification tasks. However, only a few studies try to understand how fine-tuning actually works and existing alternatives, such as feature-based transformers, are often overlooked. In this work, we study a French transformer model, CamemBERT, to compare the fine-tuned and feature-based approaches in terms of their performances, interpretability and embedding space. We observe that while fine-tuning has a limited impact on performances in our case study, it significantly affects the intepretability (by better isolating words that are intuitively connected to the classification task) and embedding space (by summarizing the majority of the relevant information into a fewer dimensions) of the results. We conclude by highlighting open questions regarding the generalization potential of fine-tuned embeddings.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-152
2023,Mixture of stochastic block models for multiview clustering,"Kylliann De Santiago, Marie Szafranski, Christophe Ambroise","In this work, we propose an original method for aggregating multiple clustering coming from different sources of information. Each partition is encoded by a co-membership matrix between observations. Our approach uses a mixture of Stochastic Block Models (SBM) to group co-membership matrices with similar information into components and to partition observations into different clusters, taking into account their specificities within the components. The parameters are estimated using a Variational Bayesian EM algorithm. The Bayesian framework allows for selecting an optimal numbers of clusters and components.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-54
2023,Single-pass uncertainty estimation with layer ensembling for regression: application to proton therapy dose prediction for head and neck cancer,"Ana Maria Barragan Montero, Robin Tilman, Margerie Huet-Dastarac, Lee John","We developed a new uncertainty quantification method for deep learning regression models, based on Layer Ensembles [1], which is competitive with state-of-the-art ensembling and Monte Carlo (MC) dropout techniques. The method was implemented in a UNet-like architecture and applied to predicting 3D dose maps for head and neck cancer patients who are treated with proton therapy. The new approach runs approximately 8 times faster than MC Dropout. Our statistical analysis showed no significant difference in prediction accuracy between the two different methods (p-value = 0.09). Moreover, the correlation uncertainty/error in the body is only -3%. These findings demonstrate the potential of the new method in enabling fast and accurate uncertainty quantification for regression problems and, in particular, for proton therapy dose prediction","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-115
2023,Towards Randomized Algorithms and Models that We Can Trust: a Theoretical Perspective,"Luca Oneto, Sandro Ridella, Davide Anguita","In the last decade it became increasingly apparent the inability of technical metrics to well characterize the behavior of intelligent systems. In fact, they are nowadays requested to meet also ethical requirements such as explainability, fairness, robustness, and privacy increasing our trust in their use in the wild. The final goal is to be able to develop a new generation of more responsible and trustworthy machine learning. In this paper, we focus our attention on randomized machine learning algorithms and models questioning, from a theoretical perspective, if it is possible to simultaneously optimize multiple metrics that are in tension between each other towards randomized machine learning algorithms that we can trust. For this purpose we will leverage the most recent advances coming from the statistical learning theory: distribution stability and differential privacy.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-29
2023,On the Limitations of Model Stealing with Uncertainty Quantification Models,"David Pape, Sina Däubener, Thosten Eisenhofer, Antonio Emanuele  Cinà, Lea Schönherr","Model stealing aims at inferring a victim model's functionality at a fraction of the original training cost. While the goal is clear, in practice the model's architecture, weight dimension, and original training data can not be determined exactly, leading to mutual uncertainty during stealing. In this work, we explicitly tackle this uncertainty by generating multiple possible networks and combining their predictions to improve the quality of the stolen model. For this, we compare five popular uncertainty quantification models in a model stealing task. Surprisingly, our results indicate that the considered models only lead to marginal improvements in terms of label agreement (i.e., fidelity) to the stolen model. To find the cause of this, we inspect the diversity of the model's prediction by looking at the prediction variance as a function of training iterations. We realize that during  training, the models tend to have similar predictions, indicating that the network diversity we wanted to leverage  using uncertainty quantification models is not (high) enough for improvements on the model stealing task.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-125
2023,Sun Tracking using a Weightless Q-Learning Neural Network,"Guilherme Souza, Priscila Lima, Felipe França","Photovoltaic(PV) systems are one of the leading technologies to address climate change. Tracking systems improve energy generation by moving the surface to follow the sun's position however, these methods do not ensure optimal results in cloudy environments. This article proposes a closed-loop control algorithm for tracking based on reinforcement learning and weightless neural networks, compared to an astrological model. The method was applied in a single PV array on a single-axis tracking system, simulated with PVLib. Results showed that the architecture could improve results in cloudy environments but not in a clear-sky situation, as expected for a first approach.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-100
2023,Multi-Fidelity Reinforcement Learning with Control Variates,"Sami Khairy, Prasanna Balaprakash","In this paper, we investigate reinforcement learning (RL) in multi-fidelity environments and enhance agent performance using cross-correlated data. We introduce a multifidelity estimator based on control variates to reduce variance in state-action value function estimation. By employing this estimator, we develop a multifidelity Monte Carlo RL (MFMCRL) algorithm that boosts agent learning in high-fidelity settings. Our experiments show that, given a finite high-fidelity sample budget, the MFMCRL agent outperforms an RL agent relying solely on high-fidelity interactions for policy optimization.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-181
2023,Enhancing Evolution Strategies with Evolution Path Bias,Oliver Kramer,"Evolution Strategies (ES) have emerged as a powerful and effective method for optimization and reinforcement learning tasks, largely due to their simplicity and scalability. However, current ES techniques can be limited in their capacity to quickly converge on the optimal solution. In this paper, we propose a novel approach to enhance ES by incorporating an evolution path-informed bias in the Gaussian mutation operator. This bias is designed to facilitate faster descent on decreasing functions. Our method leverages the evolution path, which represents the historical search directions, to intelligently bias the Gaussian mutation. By doing so, it enables the algorithm to be more sensitive to the underlying function's structure and adaptively exploit this information for more efficient exploration. We validate our approach through experiments on three benchmark functions: a linear function, we call Downhill function here, a Parabolic ridge, and a Sphere function. The results demonstrate that our evolution path-informed bias significantly accelerates convergence on in most of the cases.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-15
2023,Automatic Trade-off Adaptation in Offline RL,"Phillip Swazinna, Steffen Udluft, Thomas Runkler","Recently, offline RL algorithms have been proposed that remain adaptive at runtime. For example, the LION algorithm [1] provides the user with an interface to set the trade-off between behavior cloning and optimality w.r.t. the estimated return at runtime. Experts can then use this interface to adapt the policy behavior according to their preferences and find a good trade-off between conservatism and performance optimization. Since expert time is precious, we extend the methodology with an autopilot that automatically finds the best parameterization of the trade-off, yielding a new algorithm which we term AutoLION.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-46
2023,Feature Selection for Multi-label Classification with Minimal Learning Machine,"Joakim Linja, Joonas Hämäläinen, Tommi Kärkkäinen","Multi-label classification problems, where more than one class can be active in a single instance, generalize the conventional single-label cases. In this article, we continue the research track documented in [1,2], where the Minimal Learning Machine (MLM) was generalized into multi-label problems with competitive results compared to other state-of-the-art techniques. Our current interest is to consider whether we can reduce the complexity of the distance-based regression model in the MLM by performing feature selection. For this purpose, an existing feature selection filter technique is generalized to multi-label problems. Experimental results confirm that the proposed technique provides a useful ranking, which allows one to reduce the number of active features without jeopardizing the quality of the multi-label MLM classifier.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-134
2023,A Counterexample to Ockham's Razor and the Curse of Dimensionality: Marginalising Complexity and Dimensionality for GMMs,Benoit Frénay,"Ockham's razor and the curse of dimensionality are two founding principles in machine learning.  First, simple models should be preferred to complex ones, in order to prevent overfitting.  Second, high-dimensional spaces should be avoided, whenever possible, because learning is easier in lower-dimensional spaces.  These principles are often invoked to justify methodological choices or to preprocess data.  However, this paper shows a counterexample where it is better to first learn a more complex model in a higher-dimensional space, and then to go back to the lower-dimensional space while dropping the additional complexity.  Specifically, experiments demonstrate that Gaussian mixtures models can be learned in a higher-dimensional space and then marginalised to the target dimensionality to improve probability density estimation performances.  The chosen problem is deliberately simple to facilitate the analysis, but it opens the way to similar work for more complex models and tasks.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-18
2023,Robust Feature Selection and Robust Training to Cope with Hyperspectral Sensor Shifts,"Valerie Vaquet, Johannes Brinkrolf, Barbara Hammer","Hyperspectral imaging is a suitable measurement tool across domains. However, when combined with machine learning techniques, frequently intensity and transversal shifts hinder the transfer between different sensors and settings. Established approaches focus on eliminating sensor shifts in the data or recalibrating sensors. In this contribution, we target the training procedure, propose robust training, and derive a robust feature selection strategy that can cope with multiple shift dynamics at the same time. We evaluate our approaches experimentally on artificial and real-world datasets.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-158
2023,On Feature Removal for Explainability in Dynamic Environments,"Fabian Fumagalli, Maximilian Muschalik, Eyke Hüllermeier, Barbara Hammer","Removal-based explanations are a general framework to provide feature importance scores, where feature removal, i.e. restricting a model on a subset of features, is a central component. While many machine learning applications require dynamic modeling environments, where distributions and models change over time, removal-based explanations and feature removal have mainly been considered in a static batch learning environment. Recently, an interventional and observational perturbation method was presented that allows to remove features efficiently in dynamic learning environments with concept drift. In this paper, we compare these two algorithms on two synthetic data streams. We showcase how both yield substantially different explanations when features are correlated and provide guidance on the choice based on the application.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-148
2023,"Nesterov momentum and gradient normalization to improve t-SNE convergence and neighborhood preservation, without early exaggeration","Pierre Lambert, Lee John, Edouard Couplet, Cyril de Bodt",Student t-distributed stochastic neighbor embedding (t-SNE) finds low-dimensional data representations allowing visual exploration of data sets. t-SNE minimises a cost function with a custom two-phase gradient descent. The first phase is called early exaggeration and involves a hyper-parameter whose value can be tricky and time-consuming to set. This paper proposes another way to optimise the cost function without early exaggeration. Empirical evaluation shows that the proposed method of optimization converges faster and yields competitive results in terms of neighborhood preservation.,Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-147
2023,Improved the locally aligned ant technique (LAAT) strategy to recover manifolds embedded in strong noise,"Felipe Contreras, Kerstin Bunte, Reynier Peletier","The automatic detection, extraction, and modeling of manifold structures from large data-sets are of great interest, especially in Astronomy. Existing manifold learning techniques for feature extraction in Computer Vision, Bioinformatics and signal denoising typically fail in astronomical scenarios, since they mostly assume low levels of noise and one manifold of fixed dimension. Therefore, the Locally Aligned Ant Technique (LAAT) was recently proposed to discover multiple faint and noisy structures of varying dimensionality embedded in large amounts of background noise. Although it demonstrates excellent results in multiple scenarios, its performance depends on global thresholding and user tuning. Here, we improve LAAT and replace the global threshold by a flexible local strategy.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-151
2023,Sparse Nyström Approximation for Non-Vectorial Data Using Class-informed Landmark Selection,"Maximilian Münch, Katrin Sophie Bohnsack, Alexander Engelsberger, Frank-Michael Schleif, Thomas Villmann","We introduce an efficient approach for supervised landmark selection in sparse Nyström approximation of kernel matrices. Our method fconverts structured non-vectorial input data such as graphs or text into a vectorial dissimilarity representation, enabling class-informed landmark identification through prototype-based learning. Experimental results show competitive approximation quality compared to existing strategies and demonstrate the positive effect of integrating class information into the selection process of Nystr\""om landmarks making our approach an efficient and versatile solution for large-scale kernel learning.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-136
2023,Improved Interpretation of Feature Relevances:  Iterated Relevance Matrix Analysis (IRMA),"Michael Biehl, Sofie Lövdal","We introduce and investigate the iterated application of Generalized Matrix Relevance Learning for the analysis of feature relevances in classification problems.  The suggested Iterated Relevance Matrix Analysis (IRMA), identifies a linear subspace representing the classification specific information of the considered data sets in feature space using Generalized Matrix Learning Vector Quantization. By iteratively determining a new discriminative direction while projecting out all previously identified ones, all features carrying relevant information about the classification can be found, facilitating a detailed analysis of feature relevances. Moreover, IRMA can be used to generate improved low-dimensional representations and visualizations of labeled data sets.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-127
2023,Feature Selection for Concept Drift Detection,"Fabian  Hinder, Barbara Hammer","Feature selection is one of the most relevant preprocessing and analysis techniques in machine learning. It can dramatically increase the performance of learning algorithms and also provide relevant information on the data. In online and stream learning concept drift, i.e., the change of the underlying distribution over time, can cause tremendous problems for learning models and data analysis. While there do exist feature selection methods for online learning, to the best of our knowledge there do not exist methods to perform feature selection for drift detection, i.e., to increase the performance of drift detectors and to analyze the drift itself. In this work, we study feature selection for concept drift detection and provide a formal derivation and semantic interpretation thereof. We empirically show the relevance of our considerations on several benchmarks.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-55
2023,FouriER: Link Prediction by Mixing Tokens with Fourier-enhanced MetaFormer,"Thanh Vu, Huy Ngo, Bac Le, Thanh Le","Knowledge graph link prediction has been researched for many years. With the steady development of data, the demand for missing link prediction in knowledge bases is growing. In this study, we propose FouriER, a model using Fourier transforms integrated into MetaFormer architecture to learn features from embeddings better but more computationally cost-effective than the self-attention mechanism in Transformer models. Furthermore, we transform embeddings to a 2D form and stack them that benefit the model in learning interactions between entities and relations more efficiently. As a result, we found that our model outperformed baseline models on two benchmark datasets in our experiments.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-73
2023,Graph-based Categorical Embedding,"Weiwei Wang, Stefano Bromuri, Michel  Dumontier","Categorical features are a challenge for most machine learning algorithms that only accept numerical vectors in input. Graph neural networks are revolutionising how machine learning models are applied even to traditional data sets, thanks to the possibility of introducing graph relationships amongst features and samples. In this contribution, we describe an algorithm leveraging the assignment matrix of a DiffPool graph neural network to calculate embeddings for categorical features, using as an adjacency matrix the co-occurrence matrix between the categorical values and as nodes feature the one hot encoded categorical values. We show that the algorithm proposed is scalable and presents a competitive performance in three publicly available data sets presenting both numerical and categorical values.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-32
2023,A Tropical View of Graph Neural Networks,"Francesco Landolfi, Davide Bacciu, Danilo Numeroso","Learning dynamic programming algorithms with Graph Neural Networks (GNNs) is a research direction which is increasingly gaining popularity. Prior work has demonstrated that in order to learn such algorithms, it is necessary to have an ``alignment'' between the neural architecture and the dynamics of the target algorithms, and that GNNs align, in fact, with dynamic programming. Here, we provide a different view of this alignment, studying it through the lens of tropical algebra. We show that GNNs can approximate dynamic programming algorithms up to arbitrary precision, provided that their input and output are appropriately pre- and post-processed.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-27
2023,Multimodal Approach for Harmonized System Code Prediction,"otmane Amel, Sédrick Stassin, Sidi Ahmed Mahmoudi, Xavier Siebert","The rapid growth of e-commerce has placed considerable pressure on customs representatives. Artificial intelligence (AI) systems have emerged as a promising approach to minimize the risks faced in the customs domain. Given that the Harmonized System (HS) code is a crucial element for an accurate customs declaration, we propose a novel multimodal HS code prediction approach using deep learning models exploiting both image and text features obtained through the customs declaration combined with e-commerce platform information. We evaluated two early fusion methods and introduced our MultConcat fusion method. To the best of our knowledge, few studies analyze the feature-level combination of text and image in the state-of-the-art for HS code prediction, which heightens interest in our paper and its findings. The experimental results prove the effectiveness of our approach and fusion method with a top-3 and top-5 accuracy of 93.5% and 98.2% respectively.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-165
2023,Mitigating Robustness Bias: Theoretical Results and Empirical Evidences,"Danilo Franco, Luca Oneto, Davide Anguita","Recent research has shown that some learned classifiers can be more easily fooled by an adversary who carefully crafts imperceptible or physically plausible modifications of the input data regarding particular subgroups of the population (e.g., people with particular gender, ethnicity, or skin color). This form of un-fairness has been just recently studied, noting the fact that classical fairness metrics, which only observe the model outputs, are not enough but also robustness biases need to be measured and mitigated. For this reason, in this paper, we will first develop a new metric of fairness which generalizes the current ones and degenerates in the classical ones and then we will develop a theoretical mitigation framework with consistency results able to generate a new empirical mitigation strategy and explain why the current ones actually work.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-30
2023,End-to-End Neural Network Training for Hyperbox-Based Classification,"Denis Martins, Christian Lülf, Fabian Gieseke","Hyperbox-based classification has been seen as a promising technique in which decisions on the data are represented as a series of orthogonal, multidimensional boxes (i.e., hyperboxes) that are often interpretable and human-readable. However, existing methods are no longer capable of efficiently handling the increasing volume of data many application domains face nowadays. We address this gap by proposing a novel, fully differentiable framework for hyperbox-based classification via neural networks. In contrast to previous work, our hyperbox models can be efficiently trained in an end-to-end fashion, which leads to significantly reduced training times and superior classification results.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-33
2023,TabSRA: An Attention based Self-Explainable Model for Tabular Learning,"Kodjo Mawuena AMEKOE, Mohamed Djallel   DILMI, Hanane AZZAG, Zaineb CHELLY DAGDIA, Mustapha Lebbah, Grégoire  JAFFRE","We propose TabSRA, a novel self-explainable, and accurate model for tabular learning. TabSRA is based on SRA (Self-Reinforcement Attention), new attention mechanism that helps to learn an intelligible representation of the raw input data through element-wise vector multiplication. The learned representation is aggregated by a highly transparent function (e.g linear), which produces the final output. Experimental results on synthetic and real-world classification problems show that the proposed TabSRA solution outperforms existing widely used self-explainable models and performs comparably to full complexity state-of-the-art models in term of accuracy while providing a faithful feature attribution.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-37
2023,CRE: Circle relationship embedding of patches in vision transformer,"Zhengyang Yu, Jochen Triesch","The vision transformer (ViT) utilizes a learnable position embedding (PE) to encode the location of an image patch. However, it is unclear if this learnable PE is vital and what its benefits are. This paper explores an alternative way of encoding patch locations that exploits prior knowledge about their spatial arrangement called circle relationship embedding (CRE). CRE considers the central patch as the center of a circle and measures the distance of remaining image patches from the center based on the four-neighborhood. Our experiments show that combining CRE with PE achieves better performance than using PE alone.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-75
2023,Introducing Convolutional Channel-wise Goodness in Forward-Forward Learning,"Andreas Papachristodoulou, Christos Kyrkou, Stelios Timotheou, Theocharis Theocharides","This paper introduces a Channel-wise Goodness Function (CWG) that enhances the Forward-Forward through the use of Convolutional Neural Networks. The CWG function facilitates simultaneous feature extraction and separation, eliminating the requirement for constructing negative data and leading to faster convergence rates. The approach employs a two-component loss function that maximizes positive goodness and minimizes negative goodness. This enables the model to learn class-specific features to outperform recent non-backpropagation approaches on basic image classification datasets and shorten the gap with the well-established backpropagation methods.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-121
2023,An Alternating Minimization Algorithm with Trajectory for Direct Exoplanet Detection,"Hazan  Daglayan, Simon Vary, Pierre-Antoine Absil","Effective image post-processing algorithms are vital for the successful direct imaging of exoplanets. Existing algorithms use techniques based on a low-rank approximation to separate the rotating planet signal from the quasi-static speckles. In this paper, we present a novel approach that iteratively finds the planet’s flux and the low-rank approximation of quasi-static signals, strengthening the existing model based on low-rank approximations. We implement the algorithm with two different norms and test it on data, showing improvement over classical low-rank approaches. Our results highlight the benefits of iterative refinement of low-rank approximation to enhance planet detection.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-137
2023,Similarity versus Supervision: Best Approaches for HS Code Prediction,"Sédrick Stassin, otmane Amel, Sidi Ahmed Mahmoudi, Xavier Siebert","With growing e-commerce flows and new legislative rules, customs representatives bear a great risk when completing customs declarations for their clients. In the latter, the Harmonized System (HS) code is a crucial component using 10 digits (HS10) to classify products and define national tax rates. In this paper, we compare the performance of first, sentence embedding models using semantic similarity and second, supervised models, to predict up to the HS10 code, where currently, to the best of our knowledge, little research is being conducted. We demonstrate the differences and respective strengths of each approach. Our results show the outstanding performance of the semantic similarity approach with a top-3 and top-5 accuracy of 89% and 94.8% respectively for HS10 prediction.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-163
2023,On Transformer Autoregressive Decoding for Multivariate Time Series Forecasting,"Mohammed Aldosari, John Miller","The success of the Transformer model has promoted recent advances in time series forecasting. This adoption sparked an interest in developing efficient Transformer models that scale well for forecasting long sequences. This involves maintaining non-autoregressive one-time decoding. However, the role of autoregressive decoding is less explored. To address this gap, we revisit an essential idea of the vanilla Transformer model and show that autoregressive decoding works well compared to non-autoregressive decoding using teacher forcing. It also becomes vital for critical forecasting tasks, such as pandemic forecasting, where the stakes are high. Our code and data are publicly available at https://github.com/maldosari1/ar_transformer_tf.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-171
2023,Efficient Knowledge Aggregation Methods for Weightless Neural Networks,"Otávio Napoli, Ana Maria de Almeida, José Miguel Sales Dias, Luís Brás Rosário, Edson Borin, Mauricio Breternitz Jr.","Weightless Neural Networks (WNN) are good candidates for Federated Learning scenarios due to their robustness and computational lightness. In this work, we show that it is possible to aggregate the knowledge of multiple WNNs using more compact data structures, such as Bloom Filters, to reduce the amount of data transferred between devices. Finally, we explore variations of Bloom Filters and found that a particular data-structure, the Count-Min Sketch (CMS), is a good candidate for aggregation. Costing at most 3% of accuracy, CMS can be up to 3x smaller when compared to previous approaches, specially for large datasets.",Classification,https://doi.org/10.14428/esann/2023.ES2023-123
2023,"Improving the DRASiW performance by exploiting its own ""Mental Images""","Gianluca Coda, Massimo De Gregorio, Antonio Sorgente, Paolo Vanacore","Several improvements have been proposed in the literature for the Weightless Neural Networks (WNNs), in particular the DRASiW extension of the WiSARD model with the introduction of mental imagery and bleaching procedure.  We propose a new bleaching procedure called Dynamic Adaptive Bleaching (DAB) and its variant, refined Dynamic Adaptive Bleaching (rDAB),  to improve the WNNs performance  in terms of computational time and classification capabilities.",Classification,https://doi.org/10.14428/esann/2023.ES2023-25
2023,Evaluating Curriculum Learning Strategies for Pancreatic Cancer Prediction,"Eduardo Mosqueira-Rey, David Vázquez-Lema, Elena Hernández-Pereira","In this work we applied Curriculum Learning (CL) to evaluate the performance of a machine learning (ML) model for pancreatic cancer prediction. As the dataset required it, we applied missing value imputation and data augmentation techniques. We compare different curriculum configurations in terms of pacing functions and we perform different experiments concluding that CL helps to train the ML model. Nevertheless, not all the configurations behave in the same way, and the best results were obtained when organizing the curriculum in increasing levels of difficulty following exponential pacing.",Classification,https://doi.org/10.14428/esann/2023.ES2023-141
2023,Performance Evaluation of Activation Functions in Extreme Learning Machine,"Karol Struniawski, Aleksandra Konopka, Ryszard Kozera","This study investigates the performance of 36 different activation functions applied in Extreme Learning Machine on 10 distinct datasets. Results show that Mish and Sexp activation functions exhibit outstanding generalization abilities and consistently perform well across most datasets, while other functions are more dependent on the characteristics of the task at hand. The selection of an activation function is intricately linked to the applied dataset and novel activation functions may possess superior generalization capabilities comparing to commonly employed alternatives. This study provides valuable insight for researchers and practitioners seeking to optimize Extreme Learning Machine performance for solving classification tasks.",Classification,https://doi.org/10.14428/esann/2023.ES2023-31
2023,Policy-Based Reinforcement Learning in the Generalized Rock-Paper-Scissors Game,"Imre Gergely Mali, Gabriela Czibula","The Rock-Paper-Scissors game is a popular zero-sum game of cyclic nature, with a mixed-strategy Nash-equilibrium that has been the subject of a large number of studies and is of particular interest for economy, sociology and artificial intelligence. While there are numerous studies exploring evolutionary dynamics and learning, the overwhelming majority of these consider the game in its classical form, and two important axes with potential relevance remain unexplored. First, studies with policy-based reinforcement algorithms are lacking, and second, few existing investigations attempted to study such cyclic games with more than two players. The present work aims to address both of these matters.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-92
2023,Derivative-Free Optimization Approaches for Force Polytopes Prediction,"Gautier Laisné, Nasser Rezzoug, Jean-Marc Salotti","Hand force capacities reflect an individual's ability to generate forces in all directions, considering a given upper-limb posture. These capacities are described as polytopes by means of an upper-limb musculoskeletal model. However, such a model needs to be adapted to an individual for more accuracy. The model parameter space is investigated using derivative-free algorithms which do not require the optimization function to be differentiable: genetic algorithms and SRACOS, a classification-based algorithm. Results demonstrate that employing a genetic algorithm with a reduced representation of force polytopes (26 vertices) yields the most accurate prediction of force capacities in a validation posture.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-122
2023,A model-based approach to meta-Reinforcement Learning: Transformers and tree search,"Brieuc Pinon, Raphaël Jungers, Jean-Charles Delvenne","Meta-learning is a line of research that develops the ability to leverage past experiences to efficiently solve new learning problems. In the context of Reinforcement Learning (RL), meta-RL methods demonstrate a capability to learn behaviors that efficiently acquire and exploit information on a set of related tasks.      The Alchemy benchmark has been proposed in [Wang & al. 2021] to test such methods. Alchemy features a rich structured latent space that is challenging for state-of-the-art model-free RL methods. These methods fail to learn to properly explore then exploit.      We develop a model-based algorithm. We train a model whose principal block is a Transformer Decoder to fit the symbolic Alchemy environment dynamics. Then we define an online planner with the learned model using a tree search method. This algorithm significantly outperforms previously applied methods on the symbolic Alchemy problem.      Our results reveal the relevance of model-based approaches with online planning to perform exploration and exploitation successfully in meta-RL.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-117
2023,A hidden Markov model with Hawkes process-derived contextual variables to improve time series prediction. Case study in medical simulation.,"Fatoumata Dama, Christine Sinoquet, Corinne Lejus-Bourdeau","So far, models that take advantage of sequences of events to refine time series prediction have only been designed for specific applications. In this paper, we introduce the Non-Homogeneous Markov Chain AutoRegressive (NHMC-AR) model. In our model, the innovation arises from the synchronization of a multivariate Hawkes temporal point process with an autoregressive first-order hidden Markov model, through contextual variables. Experiments on anaesthesia data demonstrate that NHMC-AR has substantially better predictive performance compared to two competing methods.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-57
2023,Probabilistic Adaptation for Meta-Learning,Tameem Adel,"Meta-learning models learn to generalise to unseen tasks at test time. We introduce a meta-learning algorithm which balances (global) generalisation with a (local) adaptive mechanism allowing the meta-learner to deal with potentially substantial heterogeneity in the task distribution. The proposed meta-learner flexibly consolidates shared components (responsible for generalisation) with task-specific components. The latter components are adapted, in a data-driven manner, based on estimating the similarity between the meta-test task in hand and the training tasks. Experiments demonstrate improved performance on few-shot learning benchmarks, both general and others involving a more heterogeneous set of tasks.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-48
2023,Residual Reservoir Computing Neural Networks for Time-series Classification,"Claudio Gallicchio, Andrea Ceni","We introduce a novel class of Reservoir Computing (RC) models, a family of efficiently trainable Recurrent Neural Networks based on untrained connections. Aiming to improve the forward propagation of input information through time, we augment standard Echo State Networks (ESNs) with linear reservoir-skip connections modulated by an untrained orthogonal weight matrix. We analyze the mathematical properties of the resulting reservoir systems and show that the dynamical regime of the proposed class of models is controllably close to the edge of stability.  Experiments on several time-series classification tasks highlight the striking performance advantage of the proposed approach over standard ESNs.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-112
2023,A Protocol for Continual Explanation of SHAP,"Andrea Cossu, Francesco Spinnato, Riccardo Guidotti, Davide Bacciu","Continual Learning trains a model on a stream of data, with the aim of learning new information without forgetting previous knowledge. We study the behavior of SHAP values explanations in Continual Learning and propose an evaluation protocol to robustly assess the change of explanations in Class-Incremental scenarios. We observed that, while Replay strategies enforce the stability of SHAP values in feedforward/convolutional models, they are not able to do the same with fully-trained recurrent models. We show that alternative approaches, like randomized recurrent models, are more effective in keeping the explanations stable over time.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-41
2023,DEFENDER: DTW-Based Episode Filtering Using Demonstrations for Enhancing RL Safety,"André Correia, Luís Alexandre","Deploying reinforcement learning agents in the real world can be challenging due to the risks associated with learning through trial and error. We propose a task-agnostic method that leverages small sets of safe and unsafe demonstrations to improve the safety of RL agents during learning.  The method compares the current trajectory of the agent with both sets of demonstrations at every step, and filters the trajectory if it resembles the unsafe demonstrations. We perform ablation studies on different filtering strategies and investigate the impact of the number of demonstrations on performance. Our method is compatible with any stand-alone RL algorithm and can be applied to any task. We evaluate our method on three tasks from OpenAI Gym's Mujoco benchmark and two state-of-the-art RL algorithms. The results demonstrate that our method significantly reduces the crash rate of the agent while converging to, and in most cases even improving, the performance of the stand-alone agent.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-97
2023,Multispectral Texture Classification in Agriculture,"Mariya Shumska, Kerstin Bunte","Texture classification plays an important role in different domains including agricultural applications, where unmanned vehicles such as drones equipped with multispectral sensors are gaining more attention. Hence, a solution which does not require substantial computational resources is desired for real-time monitoring. In this contribution, we propose an efficient and interpretable Generalized Matrix Learning Vector Quantization based framework to classify multispectral images. We demonstrate the performance of different model designs and compare them to other benchmarks for the classification of a soil data set. Our framework yields comparable accuracy while providing interpretable results.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-110
2023,Automated green machine learning for condition-based maintenance,"Afonso Lourenco, Carolina Ferraz, Jorge Meira, Goreti Marreiros, Verónica Bolón-Canedo, Amparo Alonso-Betanzos","Within the big data paradigm, there is an increasing demand for machine learning with automatic configuration of hyperparameters. Although several algorithms have been proposed for automatically learning time-changing concepts, they generally do not scale well to very large databases. In this context, this paper presents an automated green machine learning approach applied to condition-based maintenance with automatic data fusion and density-based anomaly detection based on locality sensitivity hashing. Experiments on numerical simulations of train-track dynamic interactions demonstrate the utility of the approach to detect railway wheel out-of-roundness. This unlocks the full potential of scalable machine learning, paving the way for environment-friendly systems and automated decision-making.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-85
2023,Efficient feature selection for domain adaptation using Mutual Information Maximization,"Guillermo Castillo García, Laura Morán-Fernández, Verónica Bolón-Canedo","Green AI, an emerging research field, focuses on improving the efficiency of machine learning models. In this paper, we introduce a novel and efficient method for feature selection in domain adaptation, a type of transfer learning where the source and target domains share the feature space and task but differ in their distributions. Instead of using evolutionary algorithms, a typical approach in this field, we propose the use of filter methods, which do not require an iterative search process and are less computationally expensive. Our proposed method is Mutual Information Maximization, and our experiments show that it outperforms Particle Swarm Optimization in terms of efficiency, speed, and the ability to select a reduced subset of features while achieving competitive classification accuracy results.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-61
2023,Logarithmic division for green feature selection: an information-theoretic approach,"Samuel Suárez-Marcote, Laura Morán-Fernández, Verónica Bolón-Canedo","Feature selection is a popular preprocessing step to reduce the dimensionality of the data while preserving the important information. In this paper we propose an efficient and green feature selection method based on information theory, with the novelty of using the logarithmic division and resort to fixed-point precision. The results of experiments conducted on several datasets indicate the potential of our proposal, as it does not incur in significant information loss compared to the standard method, both in the features selected and in the subsequent classification step. This finding opens up possibilities for a new family of green feature selection methods, which would help to minimize energy consumption and carbon emissions.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-77
2023,Green Machine Learning,"Verónica Bolón-Canedo, Laura Morán-Fernández, Brais Cancela, Amparo Alonso-Betanzos","Green machine learning refers to research that is more environmentally friendly and inclusive, not only by producing novel results without increasing the computational cost, but also by ensuring that any researcher with a laptop has the opportunity to perform high-quality research without the need to use expensive cloud servers. Efficient machine learning approaches (especially deep learning) are starting to receive some attention in the research community. This tutorial is concerned with the development of machine learning algorithms that optimize efficiency rather than only accuracy. We provide an overview of this recent field, together with a review of the novel contributions to the ESANN 2023 special session on Green Machine Learning.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-3
2023,Potential analysis of a Quantum RL controller in the context of autonomous driving,"M. Lautaro Hickmann, Arne Raulf, Frank Köster, Friedhelm Schwenker, Hans-Martin Rieser","The potential of quantum enhanced Q-learning with a focus on its applicability to a lane change manoeuvre is investigated. In this context we solve multiple simple reinforcement learning environments using variational quantum circuits. The achieved results were similar to or even better than those of a simple constrained classical agent. We could observe promising behaviour on the more complex lane change manoeuvre task, which has an environment with an observation vector size twice larger than commonly used ones. For the Frozen Lake environment we found indications of possible quantum advantages in convergence rate.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-22
2023,Quantum-ready vector quantization: Prototype learning as a binary optimization problem,"Alexander Engelsberger, Thomas Villmann","Quantum Computing Research proposed strategies to solve binary optimization problems. Application on current and near-term generation Hardware is possible. Even if computational benefits of the strategies are yet to be shown, we want to explore connections to prototype learning schemes. We examine cost functions for vector quantization based on data point selection and how they can be transformed into a common quadratic unconstrained binary optimization formulation (QUBO). There are different approaches for solving QUBO problems using quantum computer or quantum annealer hardware. We look at their current limits and how they might change.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-108
2023,Logarithmic Quantum Forking,Alessandro Berti,"Quantum algorithms evolve an initial quantum state into another during computation to obtain meaningful results. However, this evolution introduces the cost of re-preparing the same initial quantum state for different tasks. Unfortunately, since quantum memory is not yet available, this cost cannot be ignored in Quantum Artificial Intelligence (QAI), where the initial quantum state typically coincides with a quantum dataset. Redundant state preparations for different tasks on the same dataset can reduce the advantages of quantum computation. To address this issue, this work proposes a new technique: the Logarithmic Quantum Forking (LQF). LQF performs state preparation for an initial quantum state once and employs additional qubits to compute an exponential number of tasks over the initial quantum state. LQF enables more efficient use of quantum computation in QAI by amortizing the cost of preparing the initial quantum state.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-93
2023,Quantum Feature Selection with Variance Estimation,"Alessandro Poggiali, Anna Bernasconi, Alessandro Berti, Gianna  Del Corso, Riccardo Guidotti","The promise of quantum computation to achieve a speedup over classical computation led to a surge of interest in exploring new quantum algorithms for data analysis problems. Feature Selection, a technique that selects the most relevant features from a dataset, is a critical step in data analysis. With several Quantum Feature Selection techniques proposed in the literature, this study exhibits the potential of quantum algorithms to enhance Feature Selection and other tasks that leverage the variance. This study proposes a novel quantum algorithm for estimating the variance over a set of real data. Importantly, after state preparation, the algorithm’s complexity exhibits logarithmic characteristics in both its width and depth. The quantum algorithm applies to the Feature Selection problem by designing a Hybrid Quantum Feature Selection (HQFS) algorithm. This work showcases an implementation of HQFS and assesses it on two synthetic datasets and a real dataset.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-99
2023,Quantum Artificial Intelligence: A tutorial,"José D. Martín-Guerrero, Lucas Lamata, Thomas Villmann","Artificial Intelligence (AI), a discipline with decades of history, is living its golden era due to striking developments that solve problems that were unthinkable just a few years ago, like generative models of text, images and video.  The broad range of AI applications has also arrived to Physics, providing solutions to bottleneck situations,  e.g., numerical methods that could not solve certain problems or took an extremely long time, optimization of quantum experimentation, or qubit control.  Besides, Quantum Computing has become extremely popular for speeding up AI calculations, especially in the case of data-driven AI, i.e., Machine Learning (ML).  The term Quantum ML is already known and deals with learning in quantum computers or quantum annealers, quantum versions of classical ML models and different learning approaches for quantum measurement and control. Quantum AI (QAI) tries to take a step forward in order to come up with disruptive concepts, such as, human-quantum-computer interfaces, sentiment analysis in quantum computers or explainability of quantum computing calculations, to name a few.  This special session includes five high-quality papers on relevant topics, like quantum reinforcement learning, parallelization of quantum calculations, quantum feature selection and quantum vector quantization, thus capturing the richness and variability of approaches within QAI.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-2
2023,Combining Stochastic Explainers and Subgraph Neural Networks can Increase Expressivity and Interpretability,"Indro Spinelli, Michele Guerra, Filippo Maria Bianchi, Simone Scardapane","Subgraph-enhanced graph neural networks (SGNN) can increase the expressive power of the standard message-passing framework. This model family represents each graph as a collection of subgraphs, generally extracted by random sampling or with hand-crafted heuristics. Our key observation is that by selecting ""meaningful"" subgraphs, besides improving the expressivity of a GNN, it is also possible to obtain interpretable results. For this purpose, we introduce a novel framework that jointly predicts the class of the graph and a set of explanatory sparse subgraphs, which can be analyzed to understand the decision process of the classifier. The subgraphs produced by our framework allow to achieve comparable performance in terms of accuracy, with the additional benefit of providing explanations.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-13
2023,Don’t waste SAM,"Nermeen Abou Baker, Uwe Handmann","Meta AI has recently released the Segment Anything Model (SAM), which demonstrates exceptional zero-shot image segmentation performance across various tasks with remarkable accuracy. Despite its inability to provide accurate segmentation across multiple research fields, SAM still serves as a valuable starting point for supporting the segmentation pipeline process, particularly for tasks that require extensive and senior skills annotations. This study aims to evaluate the generalization of SAM and fine-tuning SAM models using three waste segmentation datasets. Although they are captured from real scenes as SAM was pretrained on, these datasets present several challenges, including occlusions, deformable objects, transparency, and objects easily confused with backgrounds. In our findings, the fine-tuned SAM-ViT-H model outperforms the state-of-the-art Zerowaste, and TACO datasets with a significant increase of +30 in IoU, and it closely approaches performance levels of TrashCan 1.0, with only a -1.44 difference. After evaluating these popular waste datasets, it became evident that fine-tuning SAM as a foundational model is a crucial step for providing better generalization for downstream waste segmentation tasks. Therefore, SAM should not be disregarded or wasted.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-116
2023,"Layered Neural Networks with GELU Activation, a Statistical Mechanics Analysis","Frederieke Richert, Michiel Straat, Elisa Oostwal, Michael Biehl","Understanding the influence of activation functions on the learning behaviour of neural networks is of great practical interest. The GELU, being similar to swish and ReLU, is analysed for soft committee machines in the statistical physics framework of off-line learning. We find phase transitions with respect to the relative training set size, which are always continuous. This result rules out the hypothesis that convex activation functions cause continuous phase transitions, as e.g. for the ReLU. Moreover, we show that even a small contribution of a sigmoidal function like erf in combination with GELU leads to a discontinuous transition.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-72
2023,Real-time Detection of Evoked Potentials by Deep Learning: a Case Study,"Leonardo Amato, Marta Maschietto, Alessandro Leparulo, Mattia Tambaro, Stefano Vassanelli, Alessandro Sperduti","In Local Field Potential (LFP) recordings it is hard to distinguish Evoked Potentials (EPs) from spontaneous activity. Automatic real-time detection of all EPs in a recording would enable the deployment of neuromorphic prostheses. In this paper, we present a case study involving EPs induced by stimulation of a whisker in rats. We compare the detection performance of three deep learning models: a Temporal Convolutional Network, a Recurrent Neural Network, and a Mixed model. A data augmentation technique for LFP data and a technique to learn the delay of causal models are proposed. Experimental results show that the three deep learning models are capable of detecting most EPs with few false positives, a delay of less than 100ms, and for a pruned TCN, using only 1,282 parameters.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-101
2023,Coordinate descent on the Stiefel manifold for deep neural network training,"Estelle Massart, Vinayak Abrol","To alleviate the cost incurred by orthogonality constraints in optimization and model training, we propose a stochastic coordinate descent algorithm on the Stiefel manifold. We compute expressions for geodesics on the Stiefel manifold with initial velocity aligned with coordinates of the tangent space and show that, analogously to the orthogonal group, iterate updates of coordinate descent methods can be efficiently implemented in terms of multiplications by Givens matrices. We illustrate our proposed algorithm on deep neural network training",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-143
2023,Action-Based ADHD Diagnosis in Video,"Yichun Li, Yuxing Yang, Rajesh Nair, Mohsen  Naqvi","Attention Deficit Hyperactivity Disorder (ADHD) causes significant impairment in various domains. Early diagnosis of ADHD and treatment could significantly improve the quality of life and functioning. Recently, machine learning methods have improved the accuracy and efficiency of the ADHD diagnosis process. However, the cost of the equipment and trained staff required by the existing methods are generally huge. Therefore, we introduce the video-based frame-level action recognition network to ADHD diagnosis for the first time. We also record a real multi-modal ADHD dataset and extract three action classes from the video modality for ADHD diagnosis.  The whole process data have been reported to CNTW-NHS Foundation Trust, which would be reviewed by medical consultants/professionals and will be made public in due course.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-17
2023,Hierarchical priors for Hyperspherical Prototypical Networks,"Samuele Fonio, Lorenzo Paletto, Mattia Cerrato, Dino Ienco, Roberto Esposito","In this paper, we explore the usage of hierarchical priors to improve learning in contexts where the number of available examples is extremely low. Specifically, we consider a Prototype Learning setting where deep neural networks are used to embed data in hyperspherical geometries. In this scenario, we propose an innovative way to learn the prototypes by combining class separation and hierarchical information. In addition, we introduce a contrastive loss function capable of balancing the exploitation of prototypes through a prototype pruning mechanism. We compare the proposed method with state-of-the-art approaches on two public datasets.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-65
2023,Segmentation and Analysis of Lumbar Spine MRI Scans for Vertebral Body Measurements,"Helen Schneider, David Biesner, Akash Ashokan, Maximilian Broß, Rebecca Kador, Sandra Halscheidt, Gabor Bagyo, Peter Dankerl, Haissam Ragab, Jin Yamamura, Christoph Labisch, Rafet Sifa","This paper investigates a data- and knowledge-driven approach to auto- matically analyze lumbar MRI scans. The dataset used is an in-house dataset of 142 sagital lumbar spine images from German radiology prac- tices of the evidia GmbH. We implement state-of-the-art deep learning methods to segment the individual vertebral bodies. Overall, a very accu- rate segmentation performance of 97% Dice Score was achieved. Based on this segmentation, pathologically relevant distances are calculated using rule-based computer vision methods. We focus on the anterior, posterior and middle height of a vertebra and the anterior and posterior distances between two lumbar vertebrae. We demonstrate the clinical value of this approach through a quantitative and qualitative result analysis.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-88
2023,Retinal blood vessel segmentation from high resolution fundus image using deep learning architecture,"henda boudegga, Yaroub Elloumi, Asma Ben Abdallah, Rostom  Kachouri, Mouhamed hédi Bedoui","The Retinal Vascular Tree (RVT) segmentation is required to diagnose various ocular pathologies. Recently, fundus images are acquired with higher resolution, which allows representing a large range of vessel thickness. However, standard Deep Learning (DL) architectures with static and small convolution size have failed to achieve higher segmentation performance. In this paper, we propose a novel DL architecture for RVT segmentation dedicated for high resolution fundus images. The idea consists at extending the U-net architecture by increasing (e.g. decreasing) convolution kernel size through convolution blocs, in correlation with downscale (e.g. upscale) of feature map dimensions. The proposed architecture is validated on HRF database, where average sensitivity is increased from 56% to 84%.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-180
2023,Graph for Transformer Feature: A New Approach for Face Anti-Spoofing,"Quoc-Huy Trinh, Hieu Nguyen, Van Nguyen, Xuan-Mao Nguyen, Hai-Dang Nguyen","Face recognition is popular nowadays, however, Face anti-spoofing (FAS) poses a significant challenge for recognition systems due to the threat of external attacks. While many deep learning methods have been proposed to address this issue, they often face challenges in industry settings. Experiments found that patch extraction modules, such as the Vision Transformer and Swin Transformer, are effective for FAS in single images and perform well in industrial environments. From this point, we propose a model that leverages Transformer features and Graph Neural Networks to learn global information and identify correlations between patch features, which are critical for FAS.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-14
2023,Temporal Ensembling-based Deep k-Nearest Neighbours for Learning with Noisy Labels,Alexandra-Ioana Albu,"Label noise can significantly affect the generalization of deep neural networks. Nevertheless, it is omnipresent in real world applications. This paper introduces an approach for identifying the samples from a dataset which are likely to have correct annotations. The proposed method computes the agreement of a sample with its nearest neighbours retrieved from the feature space provided by a neural network. We introduce a temporal ensembling strategy which takes into account the agreement scores obtained by a sample during previous training epochs. The superiority of our approach over several baselines is shown on image classification datasets.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-144
2023,Evaluation of Contrastive Learning for Electronic Component Detection,"Leandro Silva, Agostinho Junior, Bruno Fernandes, George Azevedo, Sérgio Oliveira","The rapid growth of electronic waste (e-waste) has led to an urgent need for efficient recycling processes to recover valuable materials and reduce environmental impact. Waste Printed Circuit Boards (WPCBs) constitute significant e-waste and contain valuable components and precious metals. Computer vision systems can automate the classification, disassembly, and recycling of WPCBs. However, obtaining large annotated datasets for machine learning in this domain is costly and often unavailable. This paper investigates using few-shot and supervised contrastive learning in electronic component detection. We propose a model incorporating contrastive learning components for detecting electronic components in scenarios with limited training data or annotated labels. Our experimental results show that, in limited-data scenarios, contrastive learning outperforms the original versions of Faster R-CNN object detector. This study contributes to developing efficient recycling solutions for e-waste management and resource recovery.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-167
2023,Revisiting the Mark Conditional Independence Assumption in Neural Marked Temporal Point Processes,"Tanguy Bosser, Souhaib Ben Taieb","Learning marked temporal point process (TPP) models involves modeling both the event arrival times as well as their associated labels, referred to as marks. The recent introduction of deep learning techniques to the field led to better modeling of event sequences thanks to more flexible neural TPP models. However, some of these models make the assumption that event marks are independent of event times given the history of the process, which may not be valid in many applications. We relax this assumption and explicitly parametrize the mark distribution as a function of the current event time. We show that our approach achieves improved performance in predicting future marks compared to baselines on multiple real-world event sequence datasets, without affecting the performance on event time prediction.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-64
2023,Hybrid modelling of dynamic anaerobic digestion process in full-scale with LSTM NN and BMP measurements,"Alberto Meola, Sören Weinrich","Machine learning algorithms allow an accurate description of the anaerobic digestion process, but they are not applied in full-scale reactors due to the lack of physicochemical reliabilty. A hybrid model combining biomethane potential (BMP) tests data and a long short-term memory (LSTM) neural network was developed for providing previous knowledge to the neural network and improving performances. Results show that the best model configuration can predict the methane yield with a 6-hours resolution 1 day in advance with a Root Mean Square Scaled Error (RMSSE) of 36%, compared to an RMSSE of 41% obtained by the pure LSTM model configuration","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-133
2023,Simultaneous failures classification in a predictive maintenance case,"Antoine Hubermont, elio tuci, Nicola De Quattro","In industry 4.0, Machine Learning coupled with sensors monitoring leverages new ways to optimise maintenance strategies.  In a predictive maintenance case, failure diagnoses are an excellent way to prevent any breakdowns. Up to now, failure diagnoses are focused on the classification of only one failure among many (multi-label classification), even if multiple failures can occur simultaneously. This study proposes an extension to classify simultaneous failures with the most popular classification methods such as random forests or artificial neural networks. Validated on a public predictive maintenance dataset, our methodology achieved classification with equal or best accuracy compared to multi-label classification.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-129
2023,Communication-Efficient Ridge Regression in Federated Echo State Networks,"Valerio De Caro, Antonio Di Mauro, Davide Bacciu, Claudio Gallicchio","Federated Echo State Networks represent an efficient methodology for learning in pervasive environments with private temporal data due to the low computational cost required by the learning phase. In this paper, we propose Partial Federated Ridge Regression (pFedRR), an approximate, communication-efficient version of the exact method for learning the readout in a federated setting. Each client compresses the local statistics to be exchanged with the server via an importance-based method, which selects the most relevant neurons with respect to the local distribution. We evaluate the methodology on two Human State Monitoring benchmarks, in comparison with the exact method and a communication-efficient method that randomly selects the information to exchange. Results show that the importance-based selection of the information significantly reduces the communication cost, and fosters the generalization capabilities in the face of statistical heterogeneity across clients.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-87
2023,Deep dynamic co-clustering of streams of count data: a new online Zip-dLBM,"Giulia Marchello, Marco Corneli, Charles Bouveyron","Co-clustering is a technique used to analyze complex and high-dimensional data in various fields. However, traditional co-clustering methods are usually limited to dense data sets and require massive amount of memory, which can be limiting in some applications. To address this issue, we propose an online co-clustering model that processes the data incrementally and introduces a novel latent block model for sparse data matrices. The proposed model employs a LSTM neural network and a time and block dependent mixture of zero-inflated distributions to model sparsity and aims to detect real-time changes in dynamics through Bayesian online change point detection. An original variational procedure is proposed for inference. Simulations demonstrate the effectiveness of the methodology for count data.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-86
2023,Exploring Strategies for Modeling Sign Language Phonology,"Lee Kezar, Tejas Srinivasan, Riley Carlin, Jesse Thomason, Zed Sevcikova Sehyr, Naomi Caselli","Like speech, signs are composed of discrete, recombinable features called phonemes. Prior work shows that models which can recognize phonemes are better at sign recognition, motivating deeper exploration into strategies for modeling sign language phonemes. In this work, we learn graph convolution networks to recognize the sixteen phoneme “types” found in ASL-LEX 2.0. Specifically, we explore how learning strategies like multi-task and curriculum learning can leverage mutually useful information between phoneme types to facilitate better modeling of sign language phonemes. Results on the Sem-Lex Benchmark show that curriculum learning yields an average accuracy of 87% across all phoneme types, outperforming fine-tuning and multi-task strategies for most phoneme types.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-83
2023,Exploring the Importance of Sign Language Phonology for a Deep Neural Network,"Javier Martinez Rodriguez, Martha Larson, Louis ten Bosch","We conduct an initial investigation to gain insight into whether a deep neural network learns phonological aspects of sign language when classifying video recordings of isolated signs from a continuous signing scenario. We train a series of neural networks to distinguish pairs of signs in Dutch Sign Language, controlling the phonological difference between the signs in each pair. Our results suggest that the intrinsic dimension of the final hidden layer of a network is surprisingly insensitive to the phonological difference between the signs in a pair. However, the ability of the network to discriminate two signs shows a clear trend towards increasing with increasing phonological distinctiveness.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-138
2023,Large-scale dataset and benchmarking for hand and face detection focused on sign language,"Alvaro Leandro Cavalcante Carneiro, Denis Henrique Pinheiro Salvadeo, Lucas Brito Silva","Object detection is an important preprocessing technique for sign language recognition, allowing focus on the most important parts of the image. This paper introduces a new large-scale dataset for hand and face detection in sign language context, mitigating the lack of data for this problem. We evaluated different object detection architectures to find the best trade-off between computational cost and mean Average Precision (mAP). The proposed dataset contains 477,480 annotated images. The most accurate detector (CenterNet) achieved an mAP of 96.7%. Furthermore, the optimizations made to the models reduced the inference time up to 74% in the best scenario.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-185
2023,Disambiguating Signs: Deep Learning-based Gloss-level Classification for German Sign Language by Utilizing Mouth Actions,"Dinh Nam Pham, Vera Czehmann, Eleftherios Avramidis","Despite the importance of mouth actions in Sign Languages, previous work on Automatic Sign Language Recognition (ASLR) has limited use of the mouth area. Disambiguation of homonyms is one of the functions of mouth actions, making them essential for tasks involving ambiguous hand signs. To measure their importance for ASLR, we trained a classifier to recognize ambiguous hand signs. We compared three models which use the upper body/hands area, the mouth, and both combined as input. We found that the addition of the mouth area in the model resulted in the best accuracy, giving an improvement of 7.2% and 4.7% on the validation and test set, while allowing disambiguation of the hand signs for most of the cases. In cases where the disambiguation failed, it was observed that the signers in the video samples occasionally didn’t perform mouthings. In a few cases, the mouthing was enough to achieve full disambiguation of the signs. We conclude that further investigation on the modelling of the mouth region can be beneficial of future ASLR systems.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-168
2023,Wind Power Prediction with ETSformer,"Oliver Kramer, Jill Baumann","With growing environmental awareness, power generation from wind and other renewable sources is becoming increasingly important. Accurate short-term predictions of wind turbine power are needed to keep the grid stable and secure. This paper investigates the use of ETSformer, a new deep learning method based on a time series transformer architecture, for wind power prediction. ETSformer incorporates exponential smoothing principles and introduces mechanisms such as exponential smoothing attention and frequency attention to improve accuracy, efficiency and interpretability. This study compares ETSformer and LSTM on a sample dataset of a wind farm and its surrounding sites within a three kilometer radius from the Wind Integration National Dataset Toolkit with five minute interval measurements. The investigation shows promising results and improvements of ETSformer in ultra-short and short-term wind power prediction.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-173
2023,Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?,"Romain Egele, Isabelle Guyon, Yixuan Sun, Prasanna Balaprakash","Hyperparameter optimization (HPO) is essential to adjust machine learning models. However, it can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) uses intermediate accuracy and discards low-performing models. Numerous methods have been proposed, but determining the most effective one remains unclear. In this study, we compared popular methods against a simple baseline of training for 1-Epoch using different benchmarks. Surprisingly, the baseline demonstrated unexpectedly good performance, achieving similar accuracy with approximately ten times fewer training epochs. Analysis of the learning curves from these benchmarks suggests the need to increase the diversity of MF-HPO benchmarks to include cases of ""short-term horizon bias"".","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-84
2023,Trends and Challenges for Sign Language Recognition with Machine Learning,"Jérôme Fink, Mathieu De Coster, Joni Dambre, Benoit Frénay","Research in natural language processing has led to the creation of powerful tools for individuals, companies... However, these successes for written languages have not yet affected signed languages (SLs) to the same extent. The creation of similar tools for signed languages would benefit deaf, hard of hearing, and hearing people by making SL content, learning, and communication more accessible for everyone. SL recognition and translation are related to AI, but require collaboration with linguists and stakeholders. This paper describes related challenges from an AI researcher's point of view and summarizes the state of the art in these domains.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-7
2023,Learning Vector Quantization in Context of Information Bottleneck Theory,"Mehrdad Mohannazadeh Bakhtiari, Daniel Staps, Thomas Villmann","This paper is an effort to parameterize Information Bottle-neck Theory to become a supervised classifier. We introduce a parametrization by means of Learning Vector Quantization. With this new approach, one can find suitable components that are necessary for an accurate, yet efficient, classification. A balance between compression and representation is made by means of a specially designed objective function.",Classification,https://doi.org/10.14428/esann/2023.ES2023-95
2023,SOM-based Classification and a Novel Stopping Criterion for Astroparticle Applications,"Luis Sanchez, Erzsébet Merényi, Christopher Tunnell","Classification of detector signals is vital in particle physics experiments. However, the intricate spatiotemporal nature of the data and instrumentation effects make accurate classification challenging. In this study, we apply a Conscious Self-Organizing Map to data from the XENONnT experiment to identify clusters in the data. We evaluate the resulting clusters for physics interpretation, label them, and demonstrate an improvement in signal classification compared to the current method using the cluster labels. We also introduce a stopping criterion based on map quality that can help shorten long SOM training sessions.",Classification,https://doi.org/10.14428/esann/2023.ES2023-177
2023,WiSARD-based Ensemble Learning,"Leopoldo Lusquino Filho, Felipe França, Priscila Lima","Weightless neural networks are recognized for their online learning capacity and competitive performance with the state-of-the-art in different scenarios. Despite this, the literature has not adequately explored the potential of classification ensembles based on these models and their unique characteristics. This study introduces three types of ensembles based on the WiSARD weightless model and evaluates their effectiveness. The results show that these ensembles significantly improve accuracy compared to the WiSARD model and its ClusWiSARD extension, with a reasonable increase in computational cost. Furthermore, using ensembles eliminates the need for time-consuming tie-break policies of traditional WiSARD models.",Classification,https://doi.org/10.14428/esann/2023.ES2023-76
2023,Entropy Based Regularization Improves Performance in the Forward-Forward Algorithm,"Matteo Pardi, Domenico Tortorella, Alessio Micheli","The forward-forward algorithm (FFA) is a recently proposed alternative to end-to-end backpropagation in deep neural networks. FFA builds networks greedily layer by layer, thus being of particular interest in applications where memory and computational constraints are important. In order to boost layers' ability to transfer useful information to subsequent layers, in this paper we propose a novel regularization term for the layer-wise loss function that is based on Renyi's quadratic entropy. Preliminary experiments show accuracy is generally significantly improved across all network architectures. In particular, smaller architectures become more effective in addressing our classification tasks compared to the original FFA.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-79
2023,On the number of latent representations in deep neural networks for tabular data,"Edouard Couplet, Pierre Lambert, Michel Verleysen, Lee John, Cyril de Bodt","Most recent deep neural network architectures for tabular data operate at the feature level and process multiple latent representations simultaneously. While the dimension of these representations is set through hyper-parameter tuning, their number is typically fixed and equal to the number of features in the original data. In this paper, we explore the impact of varying the number of latent representations on model performance. Our results suggest that increasing the number of representations beyond the number of features can help capture more complex interactions, whereas reducing their number can improve performance in cases where there are many uninformative features.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-156
2023,Efficient Learning in Spiking Models,"Alex Rast, Mario Antoine Aoun, Eleni Elia, Nigel Crook","Spiking neural networks (SNNs) form a large class of neural models distinct from ‘classical’ continuous-valued networks such as multi layer perceptrons (MLPs). With event-driven dynamics and a continuous-time model, in contrast to the discrete-time model of their classical counterparts, they offer interesting advantages in representational capacity and energy consumption. However, developing models of learning for SNNs has historically proven challenging: as continuous-time systems, their dynamics are much more complex and they cannot benefit from the strong theoretical developments in MLPs such as convergence proofs and optimal gradient descent. Nor do they gain automatically from algorithmic improvements that have produced efficient matrix inversion and batch training methods. Research has focussed largely on the most extensively studied learning mechanisms in SNNs: spike-timing-dependent plasticity (STDP). Although there has been progress here, there are also notable pathologies that have often been solved with a variety of ad-hoc techniques. A relatively recent interesting development is attempts to map classical convolutional neural networks to spiking implementations, but these may not leverage all the claimed advantages of spiking. This tutorial overview looks at existing techniques for learning in SNNs and offers some thoughts for future directions.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-1
2023,Spiking neural networks with Hebbian plasticity for unsupervised representation learning,"Naresh Balaji Ravichandran, Anders  Lansner,  Pawel Herman","We introduce a novel spiking neural network model for learning distributed internal representations from data in an unsupervised procedure. We achieved this by transforming the non-spiking feedforward Bayesian Confidence Propagation Neural Network (BCPNN) model, employing an online correlation-based Hebbian-Bayesian learning and rewiring mechanism, shown previously to perform representation learning, into a spiking neural network with Poisson statistics and low firing rate comparable to in vivo cortical pyramidal neurons. We evaluated the representations learned by our spiking model using a linear classifier and show performance close to the non-spiking BCPNN, and competitive with other Hebbian-based spiking networks when trained on MNIST and F-MNIST machine learning benchmarks.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-169
2023,Functional Resonant Synaptic Clusters for Decoding Time-Structured Spike Trains,"Nigel Crook, Alex Rast, Eleni Elia, Mario Antoine Aoun","Biological neurons communicate with each other using two broad categories of spike event coding: rate-based and temporal. Rate-based coding communicates analog information on a continuous scale through the intensity of bursts of spikes while temporal coding relies on the timing of spike events. It has been shown that temporal coding has higher information capacity than rate based coding, but is much more challenging to model due to difficulties estimating spike-time statistics. In this paper we demonstrate how historically dependent NMDA-modulated ‘resonant’ synapses organised in ‘functional synaptic clusters’ provide a robust mechanism for decoding temporally structured spike trains.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-142
2023,Pattern Recognition Spiking Neural Network for Classification of Chinese Characters,"Nicola Russo, Wan Yuzhong, Thomas Madsen, Konstantin Nikolic","The Spiking Neural Networks (SNNs) are biologically more realistic than other types of Artificial Neural Networks (ANNs), but they have been much less utilised in applications. When comparing the two types of NNs, the SNNs are considered to be of lower latency, more hardware-friendly and energy-efficient, and suitable for running on portable devices with weak computing performance. In this paper we aim to use an SNN for the task of classifying  Chinese character images, and test its performance. The network utilises inhibitory synapses for the purpose of using unsupervised learning. The learning algorithm is a derivative of the traditional Spike-timing-dependent Plasticity (STDP) learning rule. The input images are first pre-processed by traditional methods (OpenCV). Different hyperparameters configurations are tested reaching an optimal configuration and a classification accuracy rate of 93%.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-174
2023,"Multimodal Recognition of Valence, Arousal and Dominance via Late-Fusion of Text, Audio and Facial Expressions","Fabrizio Nunnari, Annette Rios, Uwe Reichel, Chirag Bhuvaneshwara, Panagiotis Filntisis, Petros Maragos, Felix Burkhardt, Florian Eyben, Björn Schuller, Sarah Ebling","We present an approach for the prediction of valence, arousal, and dominance of people communicating via text/audio/video streams for a translation from and to sign languages. The approach consists of the fusion of the output of three CNN-based models dedicated to the analysis of text, audio, and facial expressions. Our experiments show that any combination of two or three modalities increases prediction performance for valence and arousal.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-128
2023,Hybrid Deep Learning-Based Air and Water Quality Prediction Model,"Jungeun Yoon, Dasong Yu, youngjae lee","This paper analyzes the impact of surrounding data on predicting air and water pollution levels by incorporating relevant features and examining their influence. By doing so, we can confirm the relationship between air and water pollution. A hybrid deep learning-based model is trained and various datasets and models are compared and analyzed. The proposed GCN-GRU model achieved the best results not only for PM2.5 but also for Dissolved Oxygen. The hybrid model takes into account the spatial and temporal effects of data characteristics and provides more accurate environmental prediction information through correlation analysis.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-44
2023,An Empirical Study of Over-Parameterized Neural Models based on Graph Random Features,"Nicolò Navarin, Luca Pasa, Luca Oneto, Alessandro Sperduti","In this paper, we investigate neural models based on graph random features. In particular, we aim to understand when over-parameterization, namely generating more features than the ones necessary to interpolate, may be beneficial for the generalization of the resulting models. Exploiting the algorithmic stability framework and based on empirical evidences from several commonly adopted graph datasets, we will shed some light on this issue.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-145
2023,Richness of Node Embeddings in Graph Echo State Networks,"Domenico Tortorella, Alessio Micheli","Graph Echo State Networks (GESN) have recently proved effective in node classification tasks, showing particularly able to address the issue of heterophily. While previous literature has analyzed the design of reservoirs for sequence ESN and GESN for graph-level tasks, the factors that contribute to rich node embeddings are so far unexplored. In this paper we analyze the impact of different reservoir designs on node classification accuracy and on the quality of node embeddings computed by GESN using tools from the areas of information theory and numerical analysis. In particular, we propose an entropy measure for quantifying information in node embeddings.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-51
2023,Hidden Markov Models for Temporal Graph Representation Learning,"Federico Errica, Alessio Gravina, Davide Bacciu, Alessio Micheli","We propose the Hidden Markov Model for temporal Graphs, a deep and fully probabilistic model for learning in the domain of dynamic time-varying graphs. We extend hidden Markov models for sequences to the graph domain by stacking probabilistic layers that perform efficient message passing and learn representations for the individual nodes. We evaluate the goodness of the learned representations on temporal node prediction tasks, and we observe promising results compared to neural approaches.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-35
2023,Convolutional Transformer via Graph Embeddings for Few-shot Toxicity and Side Effect Prediction,"Luis Torres, Bernardete Ribeiro, Joel Arrais","The prediction of chemical toxicity and adverse side effects is a crucial task in drug discovery. Graph neural networks (GNNs) have accelerated the discovery of compounds with improved molecular profiles for effective drug development. Recently, Transformer networks have also managed to capture the long-range dependence in molecules to preserve the global aspects of molecular embeddings for molecular property prediction. In this paper, we propose a few-shot GNN-Transformer, FS-GNNCvTR to face the challenge of low-data toxicity and side effect prediction. Specifically, we introduce a convolutional Transformer to model the local spatial context of molecular graph embeddings while preserving the global information of deep representations. Furthermore, a two-module meta-learning framework is proposed to iteratively update model parameters across few-shot tasks with limited available data. Experiments on small-sized biological datasets for toxicity and side effect prediction, Tox21 and SIDER, demonstrate a superior performance of FS-GNNCvTR compared to standard graph-based methods. The code and data underlying this article are available in the repository, https://github.com/larngroup/FS-GNNCvTR.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-66
2023,Robust and Cheap Safety Measure for Exoskeletal Learning Control with Estimated Uniform PAC (EUPAC),"Felix Weiske, Jens Jäkel","Although safe reinforcement learning control for exoskeletons shows great potential, established real-world applications seem rare. There is a dilemma: the safe RL agent is either robustly safe and computationally demanding or not robustly safe but computationally cheap. We propose Estimated Uniform PAC (EUPAC) as a new safety heuristic. We show that our EUPAC algorithm differentiates safe from unsafe system behaviour with high significance ($p<0.001$) while having a linear worst time complexity.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-40
2023,FairBayRank: A Fair Personalized Bayesian Ranker,"Armielle Noulapeu Ngaffo, Julien Albert, Benoit Frénay, Gilles Perrouin","Recommender systems are data-driven models that successfully provide users with personalized rankings of items (movies, books...). Meanwhile, for user minority groups, those systems can be unfair in predicting users’ expectations due to biased data. Consequently, fairness remains an open challenge in the ranking prediction task. To address this issue, we propose in this paper FairBayRank, a fair Bayesian personalized ranking algorithm that deals with both fairness and ranking performance requirements. FairBayRank evaluation on real-world datasets shows that it efficiently alleviates unfairness issues while ensuring high prediction performances.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-81
2023,Sleep analysis in a CLIS patient using soft-clustering: a case study,"Sophie Adama, Martin Bogdan","The paper deals with the analysis of the sleep patterns of a patient with Completely Locked-In Syndrome (CLIS). The analysis was performed using an approach initially designed to detect consciousness in Disorders of Consciousness (DoC) and CLIS patients. The method extracts different features based on spectral, complexity and connectivity measures and performs soft-clustering analyses to determine the consciousness state. The results showed that it was able to discriminate between the (Non)-Rapid Eye Movement (NREM) and the Rapid Eye Movement (REM) sleep stages. Detecting normal SWS and REM phases indicates better communication abilities for the patient.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-52
2023,Knowledge Distillation for Anomaly Detection,"Adrian Alan Pol, Ekaterina Govorkova, Sonja Gronroos, Nadezda Chernyavskaya, Philip Harris, Maurizio Pierini, Isobel Ojalvo, Peter Elmer","Unsupervised deep learning techniques are widely used to identify anomalous behaviour. The performance of such methods is a product of the amount of training data and the model size. However, the size is often a limiting factor for the deployment on resource-constrained devices. We present a novel procedure based on knowledge distillation for compressing an unsupervised anomaly detection model into a supervised deployable one and we suggest a set of techniques to improve the detection sensitivity. Compressed models perform comparably to their larger counterparts while significantly reducing the size and memory footprint.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-159
2023,Variants of Neural Gas for Regression Learning,"Thomas Villmann, Ronny Schubert, Marika Kaden","Approximation problems, and thus regression problems, have been widely considered as machine learning problems. A popular model to tackle such tasks are radial-basis-function networks (RBFN) and variants thereof. However, due to the global approximation scheme, RBFN, when trained in a supervised manner without additional constraints, may lack local representation. To this end, we propose approaches that aim to preserve locality in terms of the regression problem by using the Neural Gas algorithm. The models are tested on different data sets and compared to the supervised RBFN approach.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-94
2023,Don't skip the skips: autoencoder skip connections improve latent representation discrepancy for anomaly detection,"Anne-Sophie Collin, Cyril de Bodt, Dounia Mulders, Christophe De Vleeschouwer","Reconstruction-based anomaly detection typically relies on the reconstruction of a defect-free output from an input image. Such reconstruction can be obtained by training an autoencoder to reconstruct clean images from inputs corrupted with a synthetic defect. Previous works have shown that adopting an autoencoder with skip connections improves reconstruction sharpness. However, it remains unclear how skip connections affect the latent representations learned during training. Here, we compare internal representations of autoencoders with and without skip connections. Experiments over the MVTec AD dataset reveal that skip connections enable the autoencoder latent representations to intrinsically discriminate between clean and defective images.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-139
2023,Comparative study of the synfire chain and ring attractor model for timing in the premotor nucleus in male Zebra Finches,"Fjola Hyseni, Nicolas Rougier, Arthur Leblois","Timing is crucial for the generation of a wide range of sensorimotor tasks. However, the underlying mechanisms remain unclear. In the order of milliseconds, premotor nucleus HVC in male zebra finches is an outstanding model in studying the sequential neuronal activity encoding action timing. Current computational models of HV C rely on the synfire chains, which are not robust to noise and function for a narrow range of weights. An alternative with robust functional properties are attractors. Here, we compare the two models and show that not only the ring attractor is more robust, but can also reproduce the brief activity bursts of HV C neurons.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-120
2023,Energy-efficient detection of a spike sequence,"Louis LE COEUR, Nick Riedman, Saarthak Sarup, Kwabena Boahen",We present a novel 3D spike sorting network (3DSS) that detects a spike sequence efficiently and memorizes it upon a single presentation without configuration. We analyze the wiring and switches of alternatives and show that 3DSS reduces energy per spike quadratically compared to existing 2D networks. Applications include large-scale document retrieval and self-configuring hardware.,Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-179
2023,Anomaly detection in irregular image sequences for concentrated solar power plants,"Sukanya Patra, Thi Khanh Hien Le, Souhaib Ben Taieb","Operations at extremely high temperatures can lead to various malfunctions in Concentrated Solar Power (CSP) plants, emphasizing the need for predictive maintenance (PdM). We study PdM as an anomaly detection (AD) problem from irregular image sequences, which represent the minute-by-minute solar receiver’s surface temperature from a CSP plant. Contrary to standard benchmark image datasets in AD research, our data shows distinct characteristics such as non-stationarity, temporal dependence, and irregular sampling, which are unaddressed by current image-based AD techniques. Therefore, we introduce a forecast-based AD method to address these characteristics, drawing inspiration from irregular sequence modelling. The results show that the proposed method outperforms classical image-based AD methods on our dataset.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-178
2024,Clarity: a Deep Ensemble for Visual Counterfactual Explanations,"Claire Theobald, Frédéric Pennerath, Brieuc Conan-Guez, Miguel Couceiro, Amedeo Napoli","Counterfactual visual explanations are aimed at identifying changes in an image that will modify the prediction of a classifier. Unlike adversarial images, counterfactuals are required to be realistic. For this reason generative models such as variational autoencoders (VAE) have been used to restrain the search of counterfactuals on the data manifold. However such gradient-based approaches remain limited even when they deal with simple datasets such as MNIST. Conjecturing that these limitations result from a plateau effect which makes the gradient noisy and less informative, we improve the gradient estimation by training an ensemble of classifiers directly in the latent space of VAEs. Several experiments show that the resulting method called Clarity delivers counterfactual images of high-quality, competitive with the state-of-the-art.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-188
2024,Leveraging endoscopic data with Contrastive Learning for Crohn’s disease detection,"Robin Ghyselinck, Jérôme Fink, Bruno Dumas, Benoit Frénay","This study contributes to the automatic detection of Crohn's Disease (CD), a gastrointestinal inflammatory condition. In particular, our approach deals with the challenge of data scarcity for CD by pre-training Vision Transformers (ViT) on Hyper-Kvasir and LDPolyp, two large colonscopic datasets that represent over one million images from a similar domain, using a Contrastive Loss (CL) mechanism. This approach significantly outperforms models pre-trained on ImageNet as well as models pre-trained with a Cross-Entropy Loss on the Crohn-IPI dataset.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-56
2024,Generation of Simulated Dataset of Computed Tomography Images of Eggs and Extraction of Measurements Using Deep Learning,"Jean Pierre Brik López Vargas, Davi Duarte de Paula, Denis Henrique Pinheiro Salvadeo, Emílio Bergamim Júnior","This paper extracts morphometric measurements of the different volumes of chicken egg components (shell, yolk, albumen and air chamber) by evaluating the segmentation algorithms, U-Net and Fully Convolutional Network (FCN). It also presents a new data set of 3D CT images of chicken eggs, simulating the different densities of a real one in the Digital Imaging and Communications in Medicine (DICOM) format and its labeled masks. The 3D models trained end-to-end showed high generalization even in the presence of variations in egg size and internal structures, achieving state-of-the-art segmentation performance with 99.4% accuracy.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-134
2024,From Three to Two Dimensions: 2D Quaternion Convolutions for 3D Images,"Valentin Delchevalerie, Benoit Frénay, Alexandre Mayer","In fields like biomedical imaging, it is common to manage 3D images instead of 2D ones (CT-scans, MRI, 3D-ultrasound, etc.). Although 3D-Convolutional Neural Networks (CNNs) are generally more powerful compared to their 2D counterparts for such applications, it also comes at the cost of an increase in computational resources (both in time and memory). In this work, we present a new way to build 2D representations of 3D images while minimizing the information loss by leveraging quaternions. Those quaternion CNNs are able to offer competitive performance while significantly reducing computational complexity.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-73
2024,Visualizing and Improving 3D Mesh Segmentation with DeepView,"Andreas Mazur, Isaac Roberts, David Leins, Alexander Schulz, Barbara Hammer","While 3D data is rich in information, it often comes with the drawback of being tedious to handle. Recent work in the Geometric Deep Learning community focused on developing high quality 3D datasets for tasks like mesh segmentation. However, the label quality can never be assured to be perfect. To improve label quality in 3D datasets, we propose an interactive algorithm combining DeepView, a method to visualize the classification the function of neural networks, with Intrinsic Mesh CNNs, which generalize the convolution to Riemannian manifolds, to smartly select adequate sets of vertices from triangle mesh data for label correction.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-135
2024,A Two-Stage Approach for Implicit Bias Detection in Generative Language Models,"Jeremy Edwards, Renjie Hu, Amaury Lendasse, Alexander Schlager, Peggy Lindner","Machine learning and AI are increasingly popular for their impressive task performance. Yet, Natural Language Processing (NLP) models often inadvertently learn harmful biases related to gender and race, leading to skewed predictions. Literature distinguishes between direct and indirect bias. Current research aims to detect and mitigate these biases in machine learning models. This study introduces a two-stage approach to identify both types of gender bias in generative large language models (LLMs), confirming that they can manifest both direct and indirect biases.",Language models,https://doi.org/10.14428/esann/2024.ES2024-206
2024,LLaMA Tunes CMA-ES,Oliver Kramer,"This paper introduces LLaMA-ES, an approach for tuning the hyperparameters of Evolution Strategies (ES), specifically the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), by leveraging a Large Language Model (LLM). The proposed method uses the LLM to iteratively suggest parameter adjustments based on the optimization history, enabling dynamic fine-tuning of the algorithm. We validate our approach through experiments on numerical benchmark optimization problems, employing the LLaMA3 model with 70 billion parameters. The results demonstrate that LLaMA-ES significantly enhances the performance of CMA-ES, achieving competitive results in parameter tuning and demonstrating the potential of LLMs in optimization tasks.",Language models,https://doi.org/10.14428/esann/2024.ES2024-136
2024,Geometric Deep Learning to Enhance Imbalanced Domain Adaptation in EEG,"Shanglin Li, Motoaki Kawanabe, Reinmar Kobler","Electroencephalography (EEG) based brain-computer interfaces face significant challenges in generalization across different domains (i.e., sessions and subjects) without costly supervised calibration. Assuming identical label distributions across domains, we recently proposed a geometric deep learning framework to align marginal statistics in latent representation space. Yet, label distribution shifts are frequently encountered in practice. To this end, we proposed a novel approach integrating data augmentation and clustering techniques to align feature distributions more effectively under label shifts.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-91
2024,ChatDT: Simplifying Constraint Integration in Decision Trees,"Abiola Paterne Chokki, Benoit Frénay","Decision trees help domain experts, such as doctors and bankers, rationalize system decisions. However, existing methods lack user-friendly ways to integrate multiple constraints and identify branches for pruning. This paper introduces ChatDT, a prototype developed with a new domain-specific language and an enhanced version of the CART algorithm to address these challenges. An evaluation involving 22 participants highlights ChatDT's effectiveness, confirming its role in facilitating decision tree creation tailored to domain-specific constraints and identifying branches for pruning.",Language models,https://doi.org/10.14428/esann/2024.ES2024-8
2024,Unveiling Dreams: Moving Towards Automatic Dream Decoding via PSD-Based EEG Analysis and Machine Learning,"André  Torvestad, Mithila Packiyanathan, Luis Alfredo Moctezuma Pascual, Marta Molinas","Equipping brain-computer interfaces with dream decoding capabilities could be vital in healthcare applications. We used high-density electroencephalogram data from non-rapid eye movement sleep to conduct qualitative analysis employing multivariate empirical mode decomposition and power spectral density (PSD) for preprocessing and machine learning algorithms to distinguish between a dream experience and no experience. Qualitative analysis shows differences between the two classes, especially in the theta and beta bands. We achieve a classification performance of 0.915 in accuracy, 0.851 in AUROC, and 0.715 in kappa with PSD features and extreme gradient boosting classifier.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-164
2024,From Data to Simulation: Capturing Aircraft Engine Degradation Dynamics,"Abdellah Madane, Florent Forest, Hanane Azzag, Mustapha Lebbah, Jérôme Lacaille","The analysis and simulation of aircraft engine behavior have garnered significant attention in the aeronautical industry, primarily due to its implications for performance, maintenance, safety, and sustainability. Our work successfully showcases the efficacy of utilizing time series data collected from our aircraft engines to construct a digital twin capable of dynamically emulating their real-time behavior. We then introduce a new methodology to model the physical engine's degradation and meticulously monitor its evolution over time. By continuously analyzing the simulated data against real-world performance measurements, our approach offers valuable insights into the engine's long-term behavior and health trajectory.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-51
2024,Towards Contrail Mitigation through Robust and Frugal AI-Driven Data Exploitation,"Davide Di Giusto, Grégoire  Boussu, Simon Alix, Céline Reverdy, Mathieu Riou, Teodora Petrisor","Condensation trails significantly contribute to aviation's impact on climate change. Their effective mitigation involves formulating accurate predictions of occurrence, introducing the relevant constraints in trajectory optimization and employing reliable verification strategies based on observations. Atmospheric data, expert knowledge and contrails observations can be leveraged for these purposes. However, several factors determine a limited prediction accuracy and high uncertainty bounds, including the difficulties in predicting contrails persistence, the complexity of trajectory optimization problems and the lack of labelled data for contrail verification. This paper gives an overview of our robust Artificial Intelligence methods aiming to tackle these challenges throughout the entire contrail mitigation chain.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-64
2024,A Kalman Filter and Neural Network Hybrid Approach for Health Monitoring of Aircraft Engines,"Solène Thépaut, Sebastien RAZAKARIVONY, Dong Quan Vu, Alfred Bauny","In aircraft engine monitoring, estimating performance indicators from observed measurement data has been an important and long standing subject, as these indicators provide highly beneficial information to assist maintenance activities. Besides the traditional gas path analysis method, the two main resolution approaches in tackling this problem are Bayesian inferences, which strike a balance between assumed statistical models and observations, and machine-learning methods, where (simulated) data are generated to train regression models. However, these methods have their own limitations: Bayesian inferences are not robust against model-reality gap and non-linearity, while current implementations of machine learning algorithms in this context do not take into account temporal information. In this work, we focus on a use case in estimating engine performance indicators from operational measurement (snapshot) data. We explore several hybrid approaches, aiming to simultaneously leverage the advantages of Bayesian inference and machine learning. We demonstrate that the estimation precision provided by several of our hybrid methods significantly improves upon that of state-of-the-art methods in the tested use case.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-69
2024,Exploring High- and Low-Density Electroencephalography for a Dream Decoding Brain-Computer Interface,"Mithila Packiyanathan, André  Torvestad, Marta Molinas, Luis Alfredo Moctezuma Pascual","A high-performance real-time brain-computer interface system capable of identifying dreams has potential for healthcare applications. To address this, we use electroencephalogram (EEG) data from non-rapid eye movement sleep to classify dream experience and no- experience. Using 58 EEG channels, we achieve an accuracy of 0.94, an AUROC of 0.91, and a kappa score of 0.84, accomplished by first filtering the data through multivariate empirical mode decomposition followed by a combination of principal component analysis and common spatial patterns for feature extraction and K-nearest neighbors classifier. Interestingly, comparable results are obtained using 29 or 10 EEG channels selected by permutation-based channel selection.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-115
2024,Deep Riemannian Neural Architectures for Domain Adaptation in Burst cVEP-based Brain Computer Interface,"Sébastien VELUT, Sylvain Chevallier, Marie-Constance Corsi, Frédéric Dehais","Code modulated Visually Evoked Potentials (cVEP) is an emerging paradigm for Brain-Computer Interfaces (BCIs) that offers reduced calibration times. However, cVEP-based BCIs still encounter challenges related to cross-session/subject variabilities. As Riemannian approaches have demonstrated good robustness to these variabilities, we propose the first study of deep Riemannian neural architectures, namely SPDNets, on cVEP-based BCIs. To evaluate their performance with respect to subject variabilities, we conduct classification tasks in a domain adaptation framework using a burst cVEP open dataset. This study demonstrates that SPDNet yields the best accuracy with single-subject calibration and promising results in domain adaptation.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-112
2024,EEG Source Imaging Enhances Motor Imagery Classification,"Andres Soler, Viktor Naas, Amita Giri, Marta Molinas","Brain-computer Interfaces (BCIs) have been developed towards enhancing communication and control in individuals with motor disabilities and assist in motor rehabilitation, where motor imagery (MI), the mental visualization of limb movement, has been broadly explored. Traditionally, MI-based BCIs utilize electroencephalographic (EEG) recordings to discriminate between limbs motor imagination. This involves applying feature extraction and classification, primarily analyzing signals recorded at the scalp. Despite the success of the traditional sensor space analysis, recent studies have demonstrated that incorporating EEG source imaging (ESI)has led to an improvement of the classification performance. This work studies pipelines on both sensor and source space for classifying upper limb MI. Here, we introduce the use of source average power for the integration of ESI into MI-based BCIs. Our results suggest a significant accuracy improvement of 10% when applying source space analysis with average power against traditional sensor space analysis. This demonstrates that a shift from sensor space analysis to source space analysis can be beneficial for MI classification.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-158
2024,"Machine Learning Methods for BCI: challenges, pitfalls and promises","Jaime A Riascos, Marta Molinas, Fabien Lotte","The development of Brain-Computer Interfaces (BCIs) has been constrained by a predominant focus on signal classification. This paper rather emphasizes the integration of neurophysiological principles, BCI paradigm selection, and rigorous experimental design. By addressing common pitfalls in Machine Learning implementation, we provide researchers with a tutorial and robust framework for BCI development, promoting reproducibility and rigor. Furthermore, by tackling challenges at the intersection of BCI and Machine Learning, this work contributes to the advancement of practical, real-time BCI applications.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-4
2024,Automatic Miscalibration Diagnosis: Interpreting Probability Integral Transform (PIT) Histograms,"Ondřej Podsztavek, Alexander I. Jordan, Pavel Tvrdík, Kai L. Polsterer","Quantifying the predictive uncertainty of a model is essential for risk assessment. We address the proper calibration of the predictive uncertainty in regression tasks by employing the probability integral transform (PIT) histogram to diagnose miscalibration. PIT histograms are often difficult to interpret, and therefore we present an approach to an automatic interpretation of PIT histograms based on an interpreter trained with a synthetic data set. Given a PIT histogram of a model and a data set, the interpreter can estimate the data-generating distribution of the data set with the main purpose of identifying the cause of miscalibration.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-15
2024,ADLER - An efficient Hessian-based strategy for adaptive learning rate,"Dario Balboni, Davide Bacciu","We derive a sound positive semi-definite approximation of the Hessian of deep models for which Hessian-vector products are easily computable. This enables us to provide an adaptive SGD learning rate strategy based on the minimization of the local quadratic approximation, which requires just twice the computation of a single SGD run, but performs comparably with grid search on SGD learning rates on different model architectures (CNN with and without residual connections) on classification tasks, which makes the algorithm a promising first step toward obtaining hyperparameter-free optimization of deep learning models, and also reduces the energy impact of training. We also compare the novel approximation with the Gauss-Newton approximation.",Optimization,https://doi.org/10.14428/esann/2024.ES2024-132
2024,Convergence analysis of an inexact gradient method on smooth convex functions,"Pierre Vernimmen, François Glineur","We consider the classical gradient method with constant stepsizes where some error is introduced in the computation of each gradient. More specifically, we assume relative inexactness, in the sense that the norm of the difference between the true gradient and its approximate value is bounded by a certain fraction of the gradient norm.  We establish a sublinear convergence rate for this inexact method when applied to smooth convex functions, and illustrate on a logistic regression example.",Optimization,https://doi.org/10.14428/esann/2024.ES2024-171
2024,Joint Entropy Search for Multi-objective Bayesian Optimization with Constraints and Multiple Fidelities,"Daniel Fernández-Sánchez, Daniel Hernández-Lobato","Bayesian optimization (BO) methods solve problems with several black-box objectives and constraints. Each black box is expensive to evaluate and lacks a closed form. They use a model of each black box to guide the search for the problem’s solution. Sometimes, however, the black boxes may be evaluated at different fidelity levels. A lower fidelity is simply a cheap proxy for the corresponding black box. Thus, lower fidelities that correlate with the actual black box can be used to reduce the optimization cost. We propose Joint Entropy Search for Multi-Fidelity and Multi-Objective Bayesian Optimization with Constraints (MF-JESMOC), a BO method for solving the aforementioned problems. It chooses the next point and fidelity level at which to evaluate the black boxes as the one that is expected to reduce the most the joint entropy of the Pareto set and the Pareto front, normalized by the fidelity’s cost. Deep Gaussian processes are used to model each black box and the dependencies between fidelities. In our experiments, MF-JESMOC outperforms other state-of-the-art methods for multi-objective BO with constraints and different fidelity levels.",Optimization,https://doi.org/10.14428/esann/2024.ES2024-24
2024,Enhancing Echo State Networks with Gradient-based Explainability Methods,"Francesco Spinnato, Andrea Cossu, Riccardo Guidotti, Andrea Ceni, Claudio Gallicchio, Davide Bacciu","Recurrent Neural Networks are effective for analyzing temporal data, such as time series, but they often require costly and time-intensive training. Echo State Networks simplify the training process by using a fixed recurrent layer, the reservoir, and a trainable output layer, the readout. In sequence classification problems, the readout typically receives only the final state of the reservoir. However, averaging all states can sometimes be beneficial. In this work, we assess whether a weighted average of hidden states can enhance the Echo State Network performance. To this end, we propose a gradient-based, explainable technique to guide the contribution of each hidden state towards the final prediction. We show that our approach outperforms the naive average, as well as other baselines, in time series classification, particularly on noisy data.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-78
2024,Generalizing Convolution to Point Clouds,"Davide Bacciu, Francesco Landolfi","Convolution, a fundamental operation in deep learning for structured grid data like images, cannot be directly applied to point clouds due to their irregular and unordered nature. Many approaches in literature that perform convolution on point clouds achieve this by designing a convolutional operator from scratch, often with little resemblance to the one used on images. We present two point cloud convolutions that naturally follow from the convolution in its standard definition popular with images. We do so by relaxing the indexing of the kernel weights with a ``soft'' dictionary that resembles the attention mechanism of the transformers. Finally, experimental results demonstrate the effectiveness of the proposed relaxations on two benchmark point cloud classification tasks.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-145
2024,Towards the application of Backpropagation-Free Graph Convolutional Networks on Huge Datasets,"Nicolò Navarin, Luca Pasa, Alessandro Sperduti","Backpropagation-Free Graph Convolutional Networks (BF-GCN) are backpropagation-free neural models dealing with graph data based on Gated Linear Networks. Each neuron in a BF-GCN is defined as a set of graph convolution filters (weight vectors) and a gating mechanism that, given a node's context, selects the weight vector to use for processing the node's attributes based on its distance from a set of prototypes. Given the higher expressivity BF-GNN's neurons compared to the standard graph convolutional neural networks ones, they show a bigger memory footprint. This makes it challenging to apply BF-GNN on huge datasets.  In this paper, we explore how reducing the size of node contexts through randomization can reduce the memory occupancy of the method, enabling its application to huge datasets. We empirically show how working with very low dimensional contexts does not impact the resulting predictive performances.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-179
2024,Continual Learning with Graph Reservoirs: Preliminary experiments in graph classification,"Domenico Tortorella, Alessio Micheli","Continual learning aims to address the challenge of catastrophic forgetting in training models where data patterns are non-stationary. Previous research has shown that fully-trained graph learning models are particularly affected by this issue. One approach to lifting part of the burden is to leverage the representations provided by a training-free reservoir computing model. In this work, we evaluate for the first time different continual learning strategies in conjunction with Graph Echo State Networks, which have already demonstrated their efficacy and efficiency in graph classification tasks.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-21
2024,Towards calibration-free online EEG motor imagery decoding using Deep Learning,"Martin Wimpff, Jan Zerfowski, Bin  Yang","The prevalence of stroke-induced disability drives research in motor imagery Brain-Computer Interfaces (BCIs) for rehabilitation. Closed-loop systems using traditional decoding models prevail but deep learning advances in single-trial offline decoding offer promises. However, transferring methods from offline to online decoding poses challenges. To address this, we propose a new approach to tune existing offline deep learning models towards online decoding, outperforming traditional pipelines without the need for subject-specific calibration data. Our proposed method is a step towards calibration-free BCIs that enable immediate feedback and user learning.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-26
2024,Investigating the Gestalt Principle of Closure in Deep Convolutional Neural Networks,"Yuyan Zhang, Derya Soydaner, Fatemeh Behrad, Lisa Koßmann, Johan Wagemans","Deep neural networks perform well in object recognition, but do they perceive objects like humans? This study investigates the Gestalt principle of closure in convolutional neural networks. We propose a protocol to identify closure and conduct experiments using simple visual stimuli with progressively removed edge sections. We evaluate well-known networks on their ability to classify incomplete polygons. Our findings reveal a performance degradation as the edge removal percentage increases, indicating that current models heavily rely on complete edge information for accurate classification. The data used in our study is available on Github.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-111
2024,Unpaired Image-to-Image Translation to Improve Log End Identification,"Dag Björnberg, Morgan Ericsson, Welf Löwe, Jonas Nordqvist","Visual re-identification tasks are often subject to large domain variations due to camera types, brightness conditions, or environmental differences. For identification models to generalize in such varying domains, a large amount of training data is necessary for capturing these variations. We explore the potential of using unpaired image-to-image translation to enhance the generalization capacity of a log end identification model in the absence or combined with a smaller amount of labeled training data.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-63
2024,An Efficient Neural Architecture Search Model for Medical Image Classification,"Lunchen Xie, Eugenio Lomurno, Matteo Gambella, Danilo Ardagna, Manuel Roveri, Matteo Matteucci, Qingjiang Shi","Accurate classification of medical images is essential for modern diagnostics. Deep learning advancements led clinicians to increasingly use sophisticated models to make faster and more accurate decisions, sometimes replacing human judgment. However, model development is costly and repetitive. Neural Architecture Search (NAS) provides solutions by automating the design of deep learning architectures. This paper presents ZO-DARTS+, a differentiable NAS algorithm that improves search efficiency through a novel method of generating sparse probabilities by bi-level optimization. Experiments on five public medical datasets show that ZO-DARTS+ matches the accuracy of state-of-the-art solutions while reducing search times by up to three times.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-119
2024,SDE U-Net: Disentangling Aleatoric and Epistemic Uncertainties in Medical Image Segmentation,"Chuxin Zhang, Ana Maria Barragan Montero, Lee John","Quantifying uncertainty is crucial in artifical intelligence (AI) applications, particularly in high-stakes healthcare settings. This paper introduces SDE U-Net, a novel architecture that integrates stochastic differential equations (SDEs) with the U-Net framework, effectively distinguishing between aleatoric and epistemic uncertainties. By incorporating a randomness component, SDE U-Net directly captures and quantifies aleatoric uncertainty, while epistemic uncertainty is assessed through multiple forward passes. Comparative results demonstrate that SDE U-Net not only matches the benchmark performance but also shows superior robustness. This approach enhances the reliability of AI in medical decision-making by providing a clear, comprehensive representation of uncertainty, marking a significant advancement in the field of medical image segmentation.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-133
2024,Influence of image encoders and image features transformations in emergent communication,"Bastien Vanderplaetse, Stéphane Dupont, Xavier Siebert","Emergent communication in multi-agent systems is a research field exploring how autonomous agents can develop unique communication protocols without human programming, showing adaptability in various contexts. This study investigates the influence of image encoders and spatial information within image features on agent performance and the compositionality of emergent languages in multi-agent systems. By exploring various image encoding strategies, including the application of different processing methods to image features, we assess their impact on agents' abilities in a structured communication task. Our findings indicate that while certain encoding processes enhance overall task performance, they do not necessarily improve language compositionality.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-127
2024,Informed Machine Learning for Complex Data,"Luca Oneto, Nicolò Navarin, Alessio Micheli, Luca Pasa, Claudio Gallicchio, Davide Bacciu, Davide Anguita","In the contemporary era of data-driven decision-making, the application of Machine Learning (ML) on complex data (e.g., images, text, sequences, trees, and graphs) has become increasingly pivotal (e.g., Large Language Models and Graph Neural Networks). In this context, there is a gap between purely data-driven models and domain-specific knowledge, requirements, and expertise. In particular, this domain specificity needs to be integrated into the ML models to improve learning generalization, sustainability, trustworthiness, reliability, security, and safety. This additional knowledge can assume different forms, e.g.: software developers require ML to comply with many technical requirements, companies require ML to comply with economic and environmental sustainability, domain experts require ML to be aligned with physical and logical laws, and society requires ML to be aligned with ethical principles. This special session gathers valuable contributions and early findings in the field of Informed ML for Complex Data. Our main objective is to showcase the potential and limitations of new ideas, improvements, or the blending of ML and other research areas in solving real-world problems.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-1
2024,Informed Machine Learning: Excess Risk and Generalization,"Luca Oneto, Davide Anguita, Sandro Ridella","Machine Learning (ML) based predictive models are currently impacting research, industry, and society at large thanks to their ability to model or surrogate real systems. Two of the main current limitations of ML are the need for large amounts of high quality data and low performance far away from the observed data. For this reason, in certain applications where prior knowledge is available, researchers have developed Informed ML (IML) to decrease ML high quality data voracity and increase ML extrapolation abilities. In this work we study the differences between ML and IML excess risk and generalization using also some examples to elucidate the theoretical discussions. Our findings shed some lights on the mechanisms and the conditions under which IML outperforms ML.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-20
2024,XAI and Bias of Deep Graph Networks,"Michele Fontanesi, Alessio Micheli, Marco Podda","Generalization in machine learning involves introducing inductive biases that restrict the solution space of the learning problem, allowing for the inductive leap. In this paper, we show the existence of different inductive biases between convolutional and recursive Deep Graph Networks (DGN) by applying Explainable AI (XAI) methods as model inspection techniques. We show that different architectures can perfectly solve the given tasks by learning different labelling policies. Our results promote the usage of different architectures to address a task and raise warnings on the assessment of XAI techniques as their benchmarks may contain more ground truths than those provided.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-85
2024,"Machine learning in distributed, federated and non-stationary environments - recent trends","Mirko Polato, Barbara Hammer, Frank-Michael Schleif","This tutorial provides an overview of machine learning methodologies applied in distributed, federated, and non-stationary environments. We focus on recent advancements and novel research contributions of the field. Key topics include data analysis and pattern recognition for non-stationary environments, model compression, federated learning algorithms, and privacy preservation. This tutorial aims to equip researchers and practitioners with insights into current challenges and innovative solutions in this dynamic field.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-3
2024,Sparse Uncertainty-Informed Sampling from Federated Streaming Data,"Manuel Röder, Frank-Michael Schleif","We present a numerically robust, computationally efficient approach for non-I.I.D. data stream sampling in federated client systems, where resources are limited and labeled data for local model adaptation is sparse and expensive. The proposed method identifies relevant stream observations to optimize the underlying client model, given a local labeling budget, and performs instantaneous labeling decisions without relying on any memory buffering strategies. Our experiments show enhanced training batch diversity and an improved numerical robustness of the proposal compared to existing strategies over large-scale data streams, making our approach an effective and convenient solution in FL environments.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-9
2024,On the Fine Structure of Drifting Features,"Fabian  Hinder, Valerie Vaquet, Barbara Hammer","Feature selection is one of the most relevant preprocessing and analysis techniques in machine learning, allowing for increases in model performance and knowledge discovery. In online setups, both can be affected by concept drift, i.e., changes of the underlying distribution. Recently, an adaption of classical feature relevance approaches to drift detection was introduced. While the method increases detection performance significantly, there is only little discussion on the explanatory aspects. In this work, we focus on understanding the structure of the ongoing drift by transferring the concept of strongly and weakly relevant features to it. We empirically evaluate our methodology using graphical models.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-89
2024,FedHP: Federated Learning with Hyperspherical Prototypical Regularization,"Samuele Fonio, Mirko Polato, Roberto Esposito","This paper presents FedHP, an algorithm that amalgamates federated learning, hyperspherical geometries, and prototype learning. Federated Learning (FL) has garnered attention as a privacy-preserving method for constructing robust models across distributed datasets. Traditionally, FL involves exchanging model parameters to uphold data privacy; however, in scenarios with costly data communication, exchanging large neural network models becomes impractical. In such instances, prototype learning provides a feasible solution by necessitating the exchange of a few class prototypes instead of entire deep learning models. Motivated by these considerations, our approach leverages recent advancements in prototype learning, particularly the benefits offered by non-Euclidean geometries. Alongside introducing FedHP, we provide empirical evidence demonstrating its comparable performance to other state-of-the-art approaches while significantly reducing communication costs.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-183
2024,Few-shot similarity learning for motion classification via electromyography,"Rui Liu, Benjamin Paassen","Accurate motion classification from surface electromyography signals is crucial for controlling bionic prostheses. Unfortunately, most state-of-the-art classifiers need to be re-trained with lots of data to recognize any new motion. Therefore, we propose a few-shot similarity learning approach that can be applied to new classes without any re-training, just using one to five reference points per new class. In experiments on two real-world data sets, we find that our proposed approach outperforms two state-of-the-art approaches for few-shot learning on sEMG signals, namely a transfer learning and a contrastive learning approach. Our experiments also reveal that the choice of loss function is crucial for performance whereas the choice of similarity function has less effect.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-43
2024,About Vector Quantization and its Privacy in Federated Learning,"Ronny Schubert, Thomas Villmann","In this work, we will consider how privacy for vector quantization models can be broken in a federated learning environment. We show how a potential attacker can expose data from the prototype updates without needing to know about the specific model used by exploiting the transparency of vector quantization. Finally, a 1-user environment example based on GLVQ will be shown.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-57
2024,Federated Time Series Classification with ROCKET features,"Bruno Casella, Matthias Jakobs, Marco Aldinucci, Sebastian Buschjäger","This paper proposes FROCKS, a federated time series classification method using ROCKET features. Our approach dynamically adapts the models’ features by selecting and exchanging the best-performing ROCKET kernels from a federation of clients. Specifically, the server gathers the best-performing kernels of the clients together with the associated model parameters, and it performs a weighted average if a kernel is best-performing for more than one client. We compare the proposed method with state-of-the-art approaches on the UCR archive binary classification datasets and show superior performance on most datasets.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-61
2024,Federated Learning in a Semi-Supervised Environment for Earth Observation Data,"Bruno Casella, Alessio Barbaro Chisari, Marco Aldinucci, Sebastiano Battiato, Mario Valerio Giuffrida","We propose FedRec, a federated learning workflow taking advantage of unlabelled data in a semi-supervised environment to assist in the training of a supervised aggregated model. In our proposed method, an encoder architecture extracting features from unlabelled data is aggregated with the feature extractor of a classification model via weight averaging. The fully connected layers of the supervised models are also averaged in a federated fashion. We show the effectiveness of our approach by comparing it with the state-of-the-art federated algorithm, an isolated and a centralised baseline, on novel cloud detection datasets. Our code is available here.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-214
2024,Continual Learning of Deep Neural Networks in The Age of Big Data,"Alexander Gepperth, Timothée Lesort","Many applications of deep learning are set in an environment with perpetual change or at least with an ever-growing amount of data. In practice, deep neural networks (DNNs) and large language models (LLMs) are continually trained and evaluated. They need to incorporate new data or new annotations, where one typical issue is the extensive availability of unannotated or low-quality data, coupled with a bottleneck concerning annotations and/or curated samples. In such setups, the scaling behavior of continual learning (CL) algorithms w.r.t. training time becomes critical, which is in contrast to the standard CL setting operating on small databases like MNIST, CIFAR or ImageNet. Annotations or curated samples become available progressively, e.g., because they are created by humans, or due to an ongoing exploration of the environment, and need to be progressively incorporated into models. This article explores how advancement in continual learning can improve the scalability and performance of DNNs and LLMs in such setups. One interesting aspect is to leverage dedicated (small-scale) CL techniques to achieve advantageous trade-offs between computational cost and accuracy, or how such CL methods can maintain advantageous scaling behavior w.r.t. continuous re-training on all data.",Continual Improvement of Deep Neural Networks in The Age of Big Data,https://doi.org/10.14428/esann/2024.ES2024-2
2024,Sequential Continual Pre-Training for Neural Machine Translation,"Niko Dalla Noce, Michele Resta, Davide Bacciu",We explore continual pre-training for Neural Machine Translation within a continual learning framework. We introduce a setting where new languages are gradually added to pre-trained models across multiple training experiences. These pre-trained models are subsequently fine-tuned on downstream translation tasks. We compare mBART and mT5 pre-training objectives using four European Languages. Our findings demonstrate that sequentially adding languages during pre-training effectively mitigates catastrophic forgetting and minimally impacts downstream task performance.,Continual Improvement of Deep Neural Networks in The Age of Big Data,https://doi.org/10.14428/esann/2024.ES2024-165
2024,Towards Deep Continual Workspace Monitoring: Performance Evaluation of CL Strategies for Object Detection in Working Sites,"ASLI CELIK, OGUZHAN URHAN, Andrea Cossu, Vincenzo Lomonaco","Object detection plays a crucial role in computer-based monitoring tasks, where the adaptability of object detection algorithms to complex and dynamic backgrounds is essential for achieving accurate and stable detection performance. Despite the effectiveness of state-of-the-art object detectors, continual object detection remains a significant challenge in real-world applications. In this study, we utilized a dataset tailored for continual object detection in diverse working environments.  Using this dataset, a task-incremental continual learning scenario was established in which each experience, corresponding to object detection sub-datasets collected from different work sites, served as a separate task. Common baseline continual learning (CL) strategies were employed throughout the continual training process to evaluate their efficacy. Our findings, consistent with the CL literature, underscore replay-based strategies as the top performers, assessed across both task-aware and task-agnostic settings. Additionally, zero-shot object detection demonstrates notably lower performance compared to the best-performing CL strategies, emphasizing the critical importance of CL strategies in maintaining consistent detection performance and adapting to new environments and work sites.",Continual Improvement of Deep Neural Networks in The Age of Big Data,https://doi.org/10.14428/esann/2024.ES2024-128
2024,AI-based algorithm for intrusion detection on a real dataset,"David Esteban Martínez, Bertha Guijarro-Berdiñas, Amparo Alonso Betanzos, Elena Hernández-Pereira, Alejandro Esteban Martínez","In the realm of cybersecurity, the detection of network intrusions stands as a paramount challenge, with ever-evolving threats demanding innovative solutions. This study delves into the application of diverse machine learning algorithms on a contemporary dataset (UGR'16) comprising real-world instances of intrusion in software systems. Specifically, several Machine Learning models (Outlier Detectors, Ensemble Methods, Deep Learning, and Conventional Classifiers) were tested and compared with previously reported results using a standard methodology. The obtained results reveal that the Ensemble Methods have been capable of improving the results from prior research. Particularly, the Extreme Gradient Boosting (XGBoost) algorithm offers better results than the original solution with Random Forest, with an AUC of 0.9218 as opposed to 0.8977, and more than four times as fast for the problem to solve.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-204
2024,Similarity-Based Zero-Shot Domain Adaptation for Wearables,"Markus Vieth, Nils Grimmelsmann, Axel Schneider, Barbara Hammer","Biosensors measure signals from the human body, and usually process them with a small ML model on simple hardware. When a new person starts using such a device, a domain adaptation problem arises. We consider the case where no labels are known for the new person, but data (including labels) from several other people are available (unsupervised, multi-source). As an application scenario, we look at a shoe insole with 3-8 pressure sensors that estimates how much weight/force is put on the foot (regression problem). We propose a distance measure between a source and target domain, and a combination of all source models. Experiments on real world data from 13 persons show that our method outperforms all other tested methods by a good margin.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-123
2024,Robustness and Regularization in Hierarchical Re-Basin,"Benedikt Franke, Florian Heinrich, Markus Lange, Arne Raulf","This paper takes a closer look at Git Re-Basin, an interesting new approach to merge trained models. We propose a hierarchical model merging scheme that significantly outperforms the standard MergeMany algorithm. With our new algorithm, we find that Re-Basin induces adversarial and perturbation robustness into the merged models, with the effect becoming stronger the more models participate in the hierarchical merging scheme. However, in our experiments Re-Basin induces a much bigger performance drop than reported by the original authors.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-22
2024,Lightweight Cross-Modal Representation Learning,"Bilal FAYE, Hanane Azzag, Mustapha Lebbah, Djamel BOUCHAFFRA","Low-cost cross-modal representation learning is crucial for deriving semantic representations across diverse modalities such as text, audio, images, and video. Traditional approaches typically depend on large specialized models trained from scratch, requiring extensive datasets and resulting in high resource and time costs. To overcome these challenges, we introduce a novel approach named Lightweight Cross-Modal Representation Learning (LightCRL). This method uses a single neural network titled Deep Fusion Encoder (DFE), which projects data from multiple modalities into a shared latent representation space. This reduces the overall parameter count while still delivering robust performance comparable to more complex systems.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-96
2024,Feature Learning using Multi-view Kernel Partial Least Squares,"Xinjie Zeng, Qinghua Tao, Johan Suykens","The multi-view learning deals with data of multiple views, aiming to explore the underlying relations between different views and use them for various tasks. In this paper, we derive a multi-view extension of  kernel partial least squares  for unsupervised feature learning. We establish the optimization objective in the primal as the pair-wise covariance between the projection scores and derive that this model can be trained in the dual form by solving an eigenvalue problem.  Experiments are also conducted to verify the effectiveness of the method with real-life multi-view datasets, where the proposed method is adopted as a feature extractor and then the clustering  task is conducted for performance comparisons.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-168
2024,Stable Diffusion Dataset Generation for Downstream Classification Tasks,"Eugenio Lomurno, Matteo D'Oria, Matteo Matteucci","Recent advances in generative artificial intelligence have enabled the creation of high-quality synthetic data that closely mimics real-world data. This paper explores the adaptation of the Stable Diffusion 2.0 model for generating synthetic datasets, using Transfer Learning, Fine-Tuning and generation parameter optimisation techniques to improve the utility of the dataset for downstream classification tasks. We present a class-conditional version of the model that exploits a Class-Encoder and optimisation of key generation parameters. Our methodology led to synthetic datasets that, in a third of cases, produced models that outperformed those trained on real datasets.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-100
2024,Extrapolating Venusian Atmospheric Profiles using MAGMA Gaussian Processes,"Simon Lejoly, Arianna Piccialli, Arnaud Mahieux, Ann Carine Vandaele, Benoit Frénay","In the field of spatial aeronomy, atmospheric profile datasets often contain partial data. Probabilistic models, particularly Gaussian processes (GPs), offer promising solutions for filling these data gaps. However, traditional GP algorithms encounter challenges when handling multiple sequences simultaneously, both in terms of performance and computational complexity. Recently, an algorithm named MAGMA was introduced to address these issues. This paper evaluates MAGMA’s performance using the SOIR Venus atmosphere dataset, marking the first application of MAGMA to atmospheric profiles. Results indicate that MAGMA represents a significant advancement towards the efficient application of GPs for extrapolating atmospheric profiles.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-142
2024,Antagonism between Classification and Reconstruction Processes in Deep Predictive Coding Networks,"Jan Rathjens, Laurenz Wiskott","Predictive coding-inspired deep networks for visual computing integrate classification and reconstruction processes in shared intermediate layers. Although synergy between these processes is commonly assumed, it has yet to be convincingly demonstrated. In this study, we utilize a purposefully designed family of autoencoder-like architectures with an added classification head to examine the consequences of combining classification- and reconstruction-driven information within the models' latent layers. Our findings underscore a significant challenge: Classification-driven information diminishes reconstruction-driven information in shared representations and vice versa. Our results challenge prevailing assumptions in predictive coding and offer guidance for future iterations of predictive coding concepts in deep networks.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-59
2024,Constraints as Alternative Learning Objective in Deep Learning,"Quinten Van Baelen, Peter Karsmakers","The success of deep learning has been based on smooth loss functions that can easily be optimized using gradient descent and an off-the-shelf optimizer. However, training a neural network for a new application is not trivial as it requires many hyperparameters to be tuned. Several issues exist such as overfitting and underfitting. Many applications allow for some errors to be made, although, traditional learning objectives will influence the training in all cases except the one perfect prediction is made. In this work, constraints are proposed to replace the cross-entropy or the mean squared error to allow the neural network to make some errors. These errors can be set in advance to reflect how accurate the predictions of the neural network need to be. For each loss function, it is shown on two different data sets that the proposed constraint based learning performs similarly or even outperforms the standard loss functions. Moreover, in the case of classification problems, the constraints can result in predictions with significantly higher probability on a test set.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-76
2024,CNNGen: A Generator and a Dataset for Energy-Aware Neural Architecture Search,"Antoine Gratia, Hong Liu, Shin'ichi Satoh, Paul Temple, Pierre-Yves Schobbens, Gilles Perrouin","Neural Architecture Search (NAS) methods seek optimal networks within a set architecture space. Cells define this space and bound the search based on a reference neural architecture. Yet, optimality is mostly related to prediction performance, overlooking the environmental impacts of training thousands of models. Thus, reference architectures, designed for performance only, may hamper the search for tradeoffs between performance and energy consumption. We contribute to energy-aware NAS with i) a grammar-based Convolutional Neural Network (CNN) generator not requiring a predefined architecture; ii) A dataset of 1,300 architectures generated by CNNGen with their full description and implementation, performance and resource consumption measures; iii) Three novel performance and energy prediction models not requiring trained models and outperforming the state of the art.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-77
2024,Adversarial Training without Hard Labels,"Ammar Al-Najjar, István Megyeri, Mark Jelasity","Adversarial training is widely used to enhance classifier robustness. Several improvements have been proposed including different forms of distillation and self-alignment. Here, we propose a novel loss function combining these two approaches, while not using the hard ground truth labels directly. Our new loss function is demonstrated to simultaneously improve both the robustness and the accuracy of some well-known competing solutions. This is a step towards combatting the robustness accuracy tradeoff, a crucial issue in adversarial training. Our method also reduces the variance of the accuracy over the classes in the experimental scenarios we examined, leading to a more balanced model.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-81
2024,Learning Kernel Parameters for Support Vector Classification Using Similarity Embeddings,"Antonio Padua Braga, Murilo Menezes, Luiz Torres","In order to solve non-linear problems, kernel-based classifiers rely on implicit mappings to very high-dimensional spaces. These target spaces, although mathematically robust, often lack the property of visual interpretation, limiting the intuition of the problem at hand. In this work, the notion of a similarity space is presented, to which one can map input samples and visualize how they  interact under a given kernel function. By exploring statistics in such space, a class separability measure is derived, which can be used to find optimal kernel parameters for binary classification. Experiments using support vector machines were conducted, showing the method's effectiveness when compared to grid-search approaches.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-90
2024,Causes of Rejects in Prototype-based Classification Aleatoric vs. Epistemic Uncertainty,"Johannes Brinkrolf, Valerie Vaquet, Fabian  Hinder, Barbara Hammer","Prototype-based methods constitute a robust and transparent family of machine-learning models. To increase robustness in real-world applications, they are frequently coupled with reject options. While the state-of-the-art method, relative similarity, couples the rejection of samples with high aleatoric and epistemic uncertainty, the technique lacks transparency, i.e., an explanation of why a sample has been rejected. In this work, we analyze the relative similarity analytically and derive an explanation scheme for reject options in prototype-based classification.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-156
2024,''Mental Images'' driven classification,"Gianluca Coda, Massimo De Gregorio, Antonio Sorgente, Paolo Vanacore","Common sense rules are a form of implicit knowledge acquired through experience and observation of the world around us, and used by both humans and machines to reason and to make decisions about the surrounding environment. Artificial Intelligence systems can extract these rules by mining data and apply them to many predictive tasks. Herein, we first present a new method for extracting rules from DRASiW ""Mental Images"" (MI) and then how to exploit them to improve the classification performance of the system. The latter is confirmed by the obtained results.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-169
2024,Transfer learning to minimize the predictive risk in clinical research,"Samuel Branders, Jérôme Paul, Arthur Ooghe, Alvaro Pereira","The volume of data collected from patients enrolled in clinical trials is constantly on the rise. Classical linear and generalized linear models used in this context are unable to keep pace with this trend. Conversely, machine learning models have the potential to deal with such data, but cannot provide guarantees in terms of bias and interoperability. This paper explores a transfer learning approach that seeks to harmonize the strengths of both paradigms: providing unbiased and interpretable estimators while minimizing the expected predictive risk in finite samples.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-25
2024,Leveraging performance-based metadata for designing multi-objective NAS strategies for efficient models in Earth Observation,"Emre Demir, Rene Traore, Andrés Camero","Earth Observational (EO) datasets present challenges that differ from tra- ditional Computer Vision benchmarks often examined by the AutoML community. To assist EO researchers in leveraging AutoML techniques, we offer a NAS benchmark with performance meta-data specifically for an EO context. This dataset not only focuses on resource-efficient mod- els crucial to EO but also includes hardware-based metrics. Moreover, we investigate performance prediction to build a data-centric approach for initializing multi-objective NAS search algorithms.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-94
2024,Tumor Grading via Decorrelated Sparse Survival Regression,"Benjamin Paassen, Nadine Gaisa, Michael Rose, Mark-Sebastian Bösherz","In medical pathology, tumor grading is concerned with estimating the risk posed by a tumor, based on its pathological features. One way to infer risk scores is survival regression, i.e.\ using machine learning to infer a score that predicts the remaining survival time of a patient. Unfortunately, if applied naively, such a score is a mix of the intrinsic risk posed by the tumor and other risk factors, like the progression of the tumor or patient gender and age. We provide the first survival regression model that disentangles tumor grading from undesired correlations, while retaining a high degree of model interpretability, thanks to convex optimization, non-negativity constraints, sparsity, and linearity. We evaluate the proposed approach both on simulated and real-world data from N=114 patients at the University Clinic Aachen.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-44
2024,Physics-Aware Normalizing Flows: Leveraging Electric Circuit Models in Adversarial Learning,"Benjamin Schindler, Thomas Schmid","We introduce Physics-Aware Normalizing Flows, a novel framework combining data-driven generative modeling with a physical layer based on an Electric Circuit Model, ensuring adherence to electricity laws, sample fidelity, and explainability. Four existing Normalizing Flow architectures, including Real-NVP and NSF, were adapted to our adversarial regime and evaluated with promising results for the ad hoc determination of value ranges of physical quantities and the generation of labeled measurements based on an unlabeled dataset. By extensive data generation according to our self-explainable approach, Random Forest regressions of underlying physical quantities could be improved significantly, compared to the original dataset including omitted ground truth labels.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-177
2024,Leveraging Physics-Informed Neural Networks as Solar Wind Forecasting Models,"Nuno Costa, Filipa S. Barros, João J. G. Lima, Rui F. Pinto, André Restivo","Space weather refers to the dynamic conditions in the solar system, particularly the interactions between the solar wind - a stream of charged particles emitted by the Sun - and the Earth's magnetic field and atmosphere. Accurate space weather forecasting is crucial for mitigating potential impacts on satellite operations, communication systems, power grids, and astronaut safety. However, existing solar wind coronal models like MULTI-VP require substantial computational resources. This paper proposes a Physics-Informed Neural Network (PiNN) as a faster yet accurate alternative that respects physical laws. PiNNs blend physics and data-driven techniques for rapid and reliable forecasts. Our studies show that PiNNs can reduce computation times and deliver forecasts comparable to MULTI-VP, offering an expedited and dependable solar wind forecasting approach.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-110
2024,Self-Supervised Learning from Incrementally Drifting Data Streams,"Valerie Vaquet, Jonas Vaquet, Fabian  Hinder, Kleanthis Malialis, Christos Panayiotou, Marios Polycarpou, Barbara Hammer","Supervised online learning relies on the assumption that ground truth information is available for model updates at each time step. As this is not realistic in every setting, alternatives such as active online learning, or online learning with verification latency have been proposed. In this work, we argue that provided we can characterize the expected concept drift as incremental drift, we can rely on a self-labeling strategy to keep updated models without having label information available. We derive a knn-based self-labeling online learner implementing the presented self-supervised scheme and experimentally show that this is an option for incrementally drifting data streams in the absence of label information.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-49
2024,Human Activity Recognition from Thigh and Wrist Accelerometry,"Alejandro Castellanos Alonso, Antonio López, Diego Garcia-Perez, Diego Álvarez, Juan Carlos Alvarez","The IMPaCT Cohort (ISCIII, Spain) is expected to collect biomechanical parameters from a wide population (~200,000) over seven consecutive days, using a triaxial accelerometer and a gyroscope positioned on both the wrist and thigh of participants. This will be one of the distinctive features of the Cohort, based on the hypothesis that simultaneous placement of two devices on the wrist and thigh will enable accurate classification of subjects' activity. In this study, we aim to explore this crucial aspect using Deep CNNs and data from publicly available datasets. Our experimental findings demonstrate an 85% accuracy achieved when utilizing data from both the thigh and wrist. The results support the hypothesis that incorporating accelerometry data from both limbs enhances classification, yielding over a 15% increase in accuracy compared to using data from a single limb alone.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-75
2024,On Fb-score and Cost-Consistency in Evaluation of Imbalanced Classification,Aleksi Avela,"Among many other difficulties of imbalanced classification, evaluation of classifiers is rarely trivial. Fb-score is often recommended as one of the go-to evaluation measures in imbalanced classification, but researchers have voiced their concerns on whether Fb-score in fact is an appropriate measure. In this paper, we introduce a framework of cost-consistency, i.e., whether an evaluation measure is consistent with total classification cost at least for some cost and class imbalance ratio, and show that, with a simple cost structure, Fb-score is not cost-consistent.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-186
2024,Decision fusion based multimodal hierarchical method for speech emotion recognition from audio and text,"Nawal Alqurashi, Yuhua  Li, Kirill  Sidorov , David marshall","Expressing emotions is essential in human interaction. Often, individuals convey emotions through neutral speech, while the underlying meaning carries emotional weight. Conversely, tone can also convey emotion despite neutral words. Most Speech Emotion Recognition research overlooks this. We address this gap with a multimodal emotion recognition system using hierarchical classifiers and a novel decision fusion method. Our approach analyses emotional cues from speech and text, measuring their impact on predicted classes, considering emotional or neutral contributions for each instance. Results on the IEMOCAP dataset show our method's effectiveness: 69.45% and 65.26% weighted accuracy in speaker-dependent and speaker-independent settings, respectively.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-219
2024,Trust in Artificial Intelligence: Beyond Interpretability,"Tassadit Bouadi, Benoit Frénay, Luis Galárraga, Pierre Geurts, Barbara Hammer, Gilles Perrouin","As artificial intelligence (AI) systems become increasingly integrated into everyday life, the need for trustworthiness in these systems has emerged as a critical challenge. This tutorial paper addresses the complexity of building trust in AI systems by exploring recent advances in explainable AI (XAI) and related areas that go beyond mere interpretability. After reviewing recent trends in XAI, we discuss how to control AI systems, align them with societal concerns, and address the robustness, reproducibility, and evaluation concerns inherent in these systems. This review highlights the multifaceted nature of the mechanisms for building trust in AI, and we hope it will pave the way for further research in this area.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-6
2024,Interpreting Hybrid AI through Autodecoded Latent Space Entities,"Roland Veen, Christodoulos Hadjichristodoulou, Michael Biehl","Explainable AI models and methods have seen a rise in interest in recent years as a reaction to the widespread use of neural networks and similar black-box models in machine learning. In this project, we combine explainable, prototype-based systems and neural networks in an effort to benefit from both approaches. Specifically, we employ Generalized Matrix Relevance Learning Vector Quantization in combination with autoencoder networks. This allows us to perform automated non-linear feature extraction from high-dimensional inputs before feeding them into LVQ for classification. Moreover, the approach enables the mapping of the low-dimensional representatives and relevances back to the original feature space for visual inspection and interpretation.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-170
2024,ProtoNCD: Prototypical Parts for  Interpretable Novel Class Discovery,"Tomasz Michalski, Dawid Rymarczyk, Daniel Barczyk, Bartosz Zieliński","In this work, we introduce ProtoNCD, a novel approach to novel class discovery (NCD) that leverages prototypical parts for enhanced interpretability. ProtoNCD extends the ProtoPool methodology to the NCD setting, employing techniques such as knowledge distillation and specialized prototypical parts initialization. Through comprehensive experiments on the CUB-200-2011 dataset, we demonstrate the efficacy of ProtoNCD and its pivotal role in explaining how the reasoning of known classes influences predictions for those newly discovered.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-70
2024,Evaluating the Quality of Saliency Maps for Distilled Convolutional Neural Networks,"Jasper Wilfling, Matias Valdenegro-Toro, Marco Zullich","Knowledge Distillation (KD) is a popular technique to compress Deep Neural Networks. Studies on KD often evaluate it on the basis of accuracy and time-complexity; however, there exist other facets of a model performance, like explainability and fairness. In the present work, we evaluate the quality of saliency maps in terms of faithfulness and coherence in the context of KD and compare the results obtained with the uncompressed model. Our findings indicate how KD is potentially decreasing the accuracy of the saliency maps, thus acting as a warning on the usage of KD when high-quality explanations are required.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-131
2024,Safety-Oriented Pruning and Interpretation of Reinforcement Learning Policies,"Dennis Gross, Helge Spieker","Pruning neural networks (NNs) can streamline them but risks removing vital parameters from safe reinforcement learning (RL) policies. We introduce an interpretable RL method called VERINTER, which combines NN pruning with model checking to ensure interpretable RL safety. VERINTER exactly quantifies the effects of pruning and the impact of neural connections on complex safety properties by analyzing changes in safety measurements. This method maintains safety in pruned RL policies and enhances understanding of their safety dynamics, which has proven effective in multiple RL settings.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-71
2024,Evaluation methodology for disentangled uncertainty quantification on regression models,"Kevin Pasini, Clément ARLOTTI, milad leyli abadi, Marc Nabhan, johanna baro","A practical way to enhance the confidence of the predictions made by Machine Learning (ML) models is to enrich them with trustworthiness add-ons such as Uncertainty Quantification (UQ). Existing UQ paradigms capture two intertwined components (epistemic and aleatoric), but few of them evaluate their disentanglement, even less on real data. We thus propose and implement a methodology to assess the effectiveness of uncertainty disentanglement despite the absence of ground truth in real datasets. To do so, we use a data withdrawal-based strategy to simulate Out-of-Distribution (OOD) data and evaluate four state-of-the-art UQ approaches.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-87
2024,Influence of Data Characteristics on Machine Learning Classification Performance and Stability of SHapley Additive exPlanations,"Anusha Ihalapathirana, Gunjan Chandra, Piia Lavikainen, Pekka Siirtola, Satu Tamminen, Nirzor Talukder, Janne Martikainen, Juha Röning","This study explores the effects of different data sizes and data imbalance on model performance and the stability of SHapley Additive exPlanations (SHAP). The study utilizes a Type 2 diabetes (T2D) dataset to train three machine learning (ML) models: linear discriminant analysis, XGBoost, and a neural network. It shows that adjusting the background dataset size leads to variations in the SHAP values, with decreased variance observed in larger and balanced datasets. Furthermore, the study highlights that the data characteristics leading to high model performance may not always produce reliable and stable SHAP explanations.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-107
2024,Insight-SNE: Understanding t-SNE Embeddings through Interactive Explanation,"Sacha Corbugy, Thibaut Septon, Bruno Dumas, Benoit Frénay","Non-linear dimensionality reduction techniques offer insights into complex datasets, yet interpreting them poses challenges. While some papers provide methods for explaining DR, and others focus on interactively exploring embeddings, there are currently no works that seamlessly combine both aspects. Our contributions, Insight-SNE, propose an interactive tool that allows exploring t-SNE embeddings and their related gradient-based explanations, as well as its evaluation with expert users.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-190
2024,Does a Reduced Fine-Tuning Surface Impact the Stability of the Explanations of LLMs?,"Jérémie Bogaert, François-Xavier Standaert","Explainability is an increasingly demanded feature for the deployment of LLMs. In this context, it has been shown that the explanations of models that are equivalent from the accuracy viewpoint can differ due to their training randomness, leading to a need to characterize the explanations' distribution and to understand the origin of this sensitivity. In this paper, we investigate whether the fine-tuning surface, defined as the number of bits that are fine-tuned in a LLM, can serve as a good proxy for the stability of its explanations. We answer negatively and show that two different approaches for reducing the fine-tuning surface, namely quantizing and freezing (a part of) the models, lead to very different outcomes.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-194
2024,Positive and Scale Invariant Gaussian Process Latent Variable Model for Astronomical Spectra,"Nikos Gianniotis, Kai L. Polsterer, Iliana Isabel  Cortés Pérez","We propose a probabilistic model that reduces the dimensionality of positive-valued data in a scale-invariant way, treating data items that differ only in scaling as identical. Extending the Gaussian Process Latent Variable Model, we ensure positive function values by applying a non-linear transformation to latent function values. To address the intractable marginal log-likelihood, we utilize a variational lower bound and amortized inference to reduce the number of variational parameters. We apply our model to reconstructing partially observed spectra and show how its scale-invariant property leads to better reconstructions.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-72
2024,Forget early exaggeration in t-SNE: early hierarchization preserves global structure,"Lee John, Edouard Couplet, Pierre Lambert, Ludovic Journaux, Dounia Mulders, Cyril de Bodt, Michel Verleysen","As a local method of dimensionality reduction, t-SNE requires careful initialization in order to preserve the data global structure to the best extent. In regular t-SNE, the low-dimensional embedding is initialized either randomly or with PCA coordinates; next, gradient descent refines the embedding coordinates in two phases. In the first one, called \emph{early exaggeration}, attractive forces between points are artificially strengthened to delay any detrimental effect of repulsive forces while points are still poorly organized. In this paper, a novel initialization of t-SNE is proposed. It works by hierarchizing the data points into a space-partitioning binary tree and successive runs of t-SNE with 4, 8, 16, ..., N points. Between two runs, the prototypical point in each tree branch is split into its two children prototypes, with some little random noise, and the embedding is rescaled to account for the increased population. Experimental results show the effectiveness of the method. The proposed method is compatible with any method of neighbor embedding (t-SNE, UMAP, etc.) provided early exaggeration can be disable and initial coordinates can be fed.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-146
2024,Estimated neighbour sets and smoothed sampled global interactions are sufficient for a fast approximate tSNE.,"Pierre Lambert, Edouard Couplet, Cyril de Bodt, Lee John","To minimise its loss function, the popular method of nonlinear dimensionality reduction t-SNE requires O(N 2 ) computations. As its applications often involve large datasets, fast approximations have been developed, such as Barnes-Hut t-SNE and FIt-SNE. Most fast approximations to t-SNE require the embedding dimensionality to be small, typically 2 or 3, limiting the use of t-SNE to data visualisation. Additionally, the effective computation time of the current accelerated t-SNE algorithms stays too high for a comfortable interactive visual exploration of data. This paper proposes an accelerated approximation  of t-SNE with iterations of complexity O(N K), which does not rely on the use of a model to capture information about the low-dimensional space, relieving the computational burden of high dimensionality of the embedding space. For this purpose, the proposed method approximates neighbour sets and keeps track of smoothed estimations of long-range interactions in O(N K) time. The method is qualitatively tested on a handful of datasets and shows comparable results to existing fast neighbour embedding methods in the context of data visualisation. Code is available at https://github.com/PierreLambert3/c_fast_hSNE.git.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-203
2024,Hyperbolic Metabolite-Disease Association Prediction,"Domonkos Pogány, Péter Antal","In biomarker research, there is a growing demand for computational methods to efficiently identify novel metabolite-disease associations (MDAs). Current approaches, however, do not take into account the underlying geometry of the MDA space. Here, we show that classifiers leveraging hyperbolic embeddings achieve comparable results to their Euclidean counterparts with significantly lower dimensionality, aligning better with the association network's scale-free nature. Finally, through a case study, we provide an interpretation of the model embeddings and investigate newly predicted associations. Our results demonstrate the intrinsic non-Euclidean geometry of the MDA space, providing direction for further research. A Pytorch-based implementation is available at https://github.com/PDomonkos/hyperbolic-MDA-prediction.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-29
2024,Aeronautic data analysis,"Jérôme Lacaille, Patrick Fabiani, Patricia Besson","The latest IPCC report shows that the aviation industry is responsible for around 2% of greenhouse gas emissions; this is lower than emissions from many other sectors, but still equivalent to the total emissions of a European country like Germany. Following the recommendations of the International Civil Aviation Organization (ICAO) and its long-term global aspirational goal (LTAG), the aeronautics industry has come together under the Air Transport Aviation Group (ATAG) to converge towards zero greenhouse gas emissions by 2050, such as CO2 emissions and other radiative effects such as those generated by condensation trails. To achieve this goal, we have a number of levers at our disposal: technical improvements to our engines and aircrafts, the use of new sustainable fuels, and the use of data now accessible thanks to new engineering 4.0 technologies. This document first presents the data we now have at our disposal. The second section briefly recalls the opportunities offered by new renewable fuels. Finally, we present some digital approaches and conclude with details of three central themes illustrated by the contributions to this special session.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-7
2024,Enhanced Deep Reinforcement Learning based Group Recommendation System with Multi-head Attention for Varied Group Sizes,"Saba Izadkhah, Banafsheh Rekabdar","This paper introduces EnGRMA, an Enhanced deep reinforcement learning-based Group Recommendation system with Multi-head Attention for varied group sizes. EnGRMA adapts its recommendation strategy according to group sizes, using individual member preferences in smaller groups through a weighted average method, and leveraging multihead attention to aggregate diverse opinions effectively in larger groups. This method helps model dynamic member-item interactions, enhancing the system’s ability to deliver personalized recommendations. Our evaluation of the MovieLens-Rand dataset shows that EnGRMA not only outperforms GRMA and DRGR in Recall, NDCG, Precision, and F1 scores but also demonstrates superior performance in NDCG against AGREE.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-138
2024,A Deep Double Q-Learning as a SDLS support in solving LABS problem,Dominik Żurek,"Low Autocorrelation Binary Sequence (LABS) remains an open complex optimization problem with multiple applications. Existing studies rely primarily on advanced solvers based on local search heuristics, such as the steepest-descent local search algorithm (SDLS), Tabu search, or xLostovka algorithms. These approaches require searching through a large solution space, which is a computationally heavy and time-consuming process, leading to slower convergence. To improve convergence speed and allow for finding better solutions within a limited time, we propose the Deep Double Q-learning reinforcement learning algorithm for the LABS problem to support heuristic methods. The model aims to narrow down the search space without causing a drop in the final efficiency. Our experimental study showcases that the proposed approach is a promising direction for developing a highly efficient method for the LABS problem.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-36
2024,Predicting the Closing Cross Auction Results at the NASDAQ Stock Exchange,"Sarel Cohen, Manuel Hettich, Philipp Bielefeld, Crispin Schomers, Tobias Friedrich","This paper aims to present the results and learnings from our work on the last year's \textit{Optiver - Trading at the Close} Kaggle 2023 challenge. It not only touches the two most widely used approaches in the competition, deep learning models and support vector regression models, but also describes the provided dataset drawn from the NASDAQ stock exchange with many detailed attributes, like the imbalance size and far and near prices, recorded in an interval of one second for the last ten minutes of each trading day. It also describes the constraints of the competition. The presented machine learning model based on the LightGBM engine stood out from the competition by feeding back the revealed target data given for the previous day and was one of the top 5\% of all models in the competition.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-159
2024,Interactive Machine Learning-Powered Dashboard for Energy Analytics in Residential Buildings,"Diego Garcia-Perez, Ignacio Diaz-Blanco, Jose M. Enguita-Gonzalez, Jorge Menéndez, Abel A. Cuadrado-Vega","Efforts to reduce energy consumption in buildings are crucial for climate change concerns. In this sense, energy monitoring increases energy awareness and mitigates energy wastes. This study integrates machine learning models, advanced visualisations, and interactive tools to create an insightful energy monitoring dashboard. Novel contributions include a 2D map of daily energy demand profiles combining spatial encodings based on t-SNE, fluid aggregation, and filter operations via a data-cube framework, as well as visual encoding powered by morphing projections. This approach facilitates the  decisions of end users regarding the optimisation of energy in residential facilities.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-130
2024,Exploring Self-Organizing Maps for Addressing Semantic Impairments,"Jorge Graneri, Sebastian Basterrech, Gerardo Rubino, Eduardo Mizraji","Since the 1990s, Self-Organizing Maps (SOMs) have been instrumental in reducing dimensionality and visualizing high-dimensional data. This study adapts SOMs to explore the neural representation of human concepts, their neural ‘word net’ mapping, and the deterioration of these mappings in certain neurological disorders. Our model draws inspiration from semantic dementia, a severe condition that degrades semantic knowledge in the brain. Although our exploration utilizes a low-dimensional model - a rough simplification with respect of our brains - it successfully replicates observed clinical patterns. These promising results inspire further research to enhance our understanding of language pathophysiology in neurological disorders.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-215
2024,HDBSCAN for 3-rd order tensor,"Dina Faneva Andriantsiory, Joseph Ben Geloun, Mustapha Lebbah","Several methods for tensor clustering require hyperparameters such as the cluster size or the number of clusters per mode. These methods present a challenge because, for real datasets, such inputs cannot be determined without incurring significant costs. Recently, Multi-Slice Clustering (MSC) has addressed this issue by utilizing a threshold parameter to perform data clustering. MSC identifies signal slices that reside in a lower-dimensional subspace within a 3rd-order rank-1 tensor dataset. However, determining the tensor rank remains a complex task. The current work introduces a new approach to tensor clustering that can extract clusters of similar slices and is also capable of finding co-clustering and triclustering in 3rd-order tensors of any rank. Our algorithm is based on the density of the data.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-198
2024,Large-Scale Continuous Structure Learning from Time-Series Data,"Filippo Michelis, Riccardo Massidda, Davide Bacciu","Structure learning is the problem of recovering from data a Directed Acyclic Graph (DAG) of the interactions among variables. By enforcing a differentiable acyclicity constraint on the adjacency matrix of the graph, existing methods solve this problem as an optimization problem and have been recently extended to time-series data. Due to the cubic computational complexity of existing acyclicity constraints, their application is limited to a few variables. In this paper, we introduce SVARCOSMO, an optimization-based structure learning method for time-series data that builds upon recent developments on unconstrained but provably acyclic models. We empirically show on both simulated and real data that SVARCOSMO correctly recovers the underlying DAG in significantly less time, enabling optimization-based structure learning on high-dimensional data.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-120
2024,Inductive lateral movement detection in enterprise computer networks,Corentin Larroche,"Lateral movement is a crucial phase of advanced cyberattacks, during which attackers propagate from host to host within the targeted network. State-of-the-art methods for detecting this behavior rely on graph-based learning algorithms, which typically rely on node embeddings to detect anomalous edges between hosts. Once trained, such models cannot easily generalize to new hosts joining the network or to a different network, which is impractical in real-world applications. We investigate the detection performance of an inductive link prediction model, which can generalize to graphs not seen during training, and find that it performs as well as state-of-the-art transductive methods in a zero-shot setting. This opens promising perspectives for practical lateral movement detection.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-19
2024,T-WinG: Windowing for Temporal Knowledge Graph Completion,"Ngoc-Trung Nguyen, Thanh Vu, Thanh Le","In the domain of Temporal Knowledge Graph Completion, existing models often struggle with efficiently capturing the intricate temporal dynamics and interactions within knowledge graphs. To address these challenges, this paper introduces T-WinG, a novel approach that incorporates the Swin Transformer architecture, renowned for its efficacy in hierarchical representation learning. By integrating SPLIME's preprocessing techniques and refining the Swin Transformer's token mixer, T-WinG substantially improves performance. Specifically, our model demonstrates a performance improvement of up to 20% in accuracy metrics such as Mean Reciprocal Rank (MRR) and Hits@K, across four benchmark datasets compared to the best-performing baseline models. These results not only underscore T-WinG's ability to handle dynamic temporal data but also highlight its potential to address the pressing needs of real-world applications requiring accurate and timely insights from knowledge graphs.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-166
2024,Exploring Temporal Knowledge Graphs with Compositional Interactions and Diachronic Mechanisms,"Loc Tran, Bac Le, Thanh Le","Temporal Knowledge Graphs (TKGs) organize dynamic real-world facts, adding a time dimension to the multi-relational graph structure of Knowledge Graphs (KGs). We leverage the expressive power of graph convolutional networks (GCNs) for modeling TKGs, recognizing similarities with handling graph-structured data and utilizing complex geometry. Our approach emphasizes compositional interactions between relations and entities, integrating a diachronic mechanism to enhance representation with both graph structure and temporal dynamics. Experimental results on benchmark datasets, employing various composition operators, showcase the effectiveness of our model in link prediction tasks.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-173
2024,Domain Knowledge Integration in Machine Learning Systems -  An Introduction,"Marika Kaden, Sascha Saralajew, Thomas Villmann","Knowledge integration into machine learning systems is a promising and successful strategy to achieve	more plausible and consistent results. The plausibility	is accompanied by better model interpretability due to the adjustment	of the machine learning system to the domain specific requirements	and restrictions. Further, informed machine learning can be seen as	a particular task specific regularization of the model leading to	better learning convergence and frequently also requiring a lower	amount of training data. This short introduction paper addresses some	recent aspects, how domain knowledge can be integrated into learning	systems on different levels ranging from informed feature extraction	to domain adjusted structure and model architecture.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-5
2024,Noise Robust One-Class Intrusion Detection on Dynamic Graphs,"Aleksei Liuliakov, Alexander Schulz, Luca Hermes, Barbara Hammer","In the domain of network intrusion detection, robustness against contaminated and noisy data inputs remains a critical challenge. This study introduces a probabilistic version of the Temporal Graph Network Support Vector Data Description (TGN-SVDD) model, designed to enhance detection accuracy in the presence of input noise. By predicting parameters of a Gaussian distribution for each network event, our model is able to naturally address noisy adversarials and improve robustness compared to a baseline model. Our experiments on a modified CIC-IDS2017 data set with synthetic noise demonstrate significant improvements in detection performance compared to the baseline TGN-SVDD model, especially as noise levels increase.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-124
2024,SAT Instances Generation Using Graph Variational Autoencoders,"Daniel Crowley, Marco Dalla, Barry O'Sullivan, Andrea Visentin","This paper presents a SAT instance generator using a Graph Variational Autoencoder (GVAE) architecture that outperforms existing generative deep learning models in speed and requires minimal post-processing. Our computational analyses benchmark this model against current deep learning techniques, introducing advanced metrics for more accurate evaluation. This new model is unique in its ability to maintain partial satisfiability of SAT instances while significantly reducing computational time. Although no method perfectly addresses all challenges in generating SAT instances, our approach marks a significant step forward in the efficiency and effectiveness of SAT instance generation.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-223
2024,Dual Stream Graph Transformer Fusion Networks for Enhanced Brain Decoding,"Lucas Goené, Siamak Mehrkanoon","This paper presents the novel Dual Stream Graph-Transformer Fusion (DS-GTF) architecture designed specifically for classifying task-based Magnetoencephalography (MEG) data. In the spatial stream, inputs are initially represented as graphs, which are then passed through graph attention networks (GAT) to extract spatial patterns. Two methods, TopK and Thresholded Adjacency are introduced for initializing the adjacency matrix used in the GAT. In the temporal stream, the Transformer Encoder receives concatenated windowed input MEG data and learns new temporal representations. The learned temporal and spatial representations from both streams are fused before reaching the output layer. Experimental results demonstrate an enhancement in classification performance and a reduction in standard deviation across multiple test subjects compared to other examined models.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-23
2024,Link prediction heuristics for temporal graph benchmark,"Manuel Dileo, Matteo Zignani","Link prediction is one of the most well-known and studied problems in graph machine learning, successfully applied in different settings, such as predicting network evolution in online social networks, protein-to-protein interactions, or completing links in knowledge graphs. In recent years, we have witnessed several solutions based on deep learning methods for solving this task in the context of temporal networks. However, despite their effectiveness on static graphs, traditional heuristic-based approaches from network science research have never been considered potential benchmarks' baselines. For this reason, in this work, we tested four of the most well-known and simple heuristics for link prediction on the most adopted temporal graph benchmark (TGB). Our results show that simple link prediction heuristics can reach comparable results with state-of-the-art deep learning techniques and, thanks to their interpretability, give insights into the network being studied. We believe considering heuristic-based baselines will push the temporal graph learning community toward better models for link prediction.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-141
2024,Large Language Models as Tuning Agents of Metaheuristics,"Alicja Martinek, Szymon Łukasik, Amir H. Gandomi","This study examines whether LLMs can be utilized in metaheuristic tuning through selection of appropriate parameters. Instances of two optimization problems, Travelling Salesman and Graph Coloring, were solved with GA, ACO, PSO, and SA. Experiment involved running these heuristic optimizers with parameter values advised by LLMs. A round of feedback was performed through feeding LLMs with prompts that included initial parameters, average performance, and population variance, where applicable. The results show LLMs exhibit the ability to comprehend the non-trivial task of tuning metaheuristics' parameters. Additionally, feedback runs often outperform results achieved by initial setups, yielding a new application of LLMs.",Language models,https://doi.org/10.14428/esann/2024.ES2024-209
2024,Embodying Language Models in Robot Action,"Connor Gäde, Ozan Özdemir, Cornelius Weber, Stefan Wermter","Large language models (LLMs) have achieved significant recent success in deep learning. The remaining challenges in robotics and human-robot interaction (HRI) still need to be tackled but off-the-shelf pre-trained LLMs with advanced language and reasoning capabilities can provide solutions to problems in the field. In this work, we realise an open-ended HRI scenario involving a humanoid robot communicating with a human while performing robotic object manipulation tasks at a table. To this end, we combine pre-trained general models of speech recognition, vision-language, text-to-speech and open-world object detection with robot-specific models of visuospatial coordinate transfer and inverse kinematics, as well as a task-specific motion model. Our experiments reveal robust performance by the language model in accurately selecting the task mode and by the whole model in correctly executing actions during open-ended dialogue. Our innovative architecture enables a seamless integration of open-ended dialogue, scene description, open-world object detection and action execution. It is promising as a modular solution for diverse robotic platforms and HRI scenarios.",Language models,https://doi.org/10.14428/esann/2024.ES2024-143
2024,Towards Explainable Evolution Strategies with Large Language Models,"Jill Baumann, Oliver Kramer","This paper introduces an approach that integrates self-adaptive Evolution Strategies (ES) with Large Language Models (LLMs) to enhance the explainability of complex optimization processes. By employing a self-adaptive ES equipped with a restart mechanism, we effectively navigate the challenging landscapes of benchmark functions, capturing detailed logs of the optimization journey. The logs include fitness evolution, step-size adjustments and restart events due to stagnation. An LLM is then utilized to process these logs, generating concise, user-friendly summaries that highlight key aspects such as convergence behavior, optimal fitness achievements, and encounters with local optima. Our case study on the Rastrigin function demonstrates how our approach makes the complexities of ES optimization transparent. Our findings highlight the potential of using LLMs to bridge the gap between advanced optimization algorithms and their interpretability.",Language models,https://doi.org/10.14428/esann/2024.ES2024-129
2024,Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts,"Thanh Thi Nguyen, Campbell Wilson, Janis Dalins","This paper proposes an approach to detection of online harmful content using the open-source pretrained Llama~2 model, recently released by Meta GenAI. We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages. Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods. Experimental results show a strong performance of the proposed approach, which is proficient and consistent across three distinct datasets with five sets of experiments. This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, and hate speech in online discussions and comments to maintain respectful digital communities.",Language models,https://doi.org/10.14428/esann/2024.ES2024-222
2024,On-line Learning Dynamics in Layered Neural Networks with Arbitrary Activation Functions,"Frederieke Richert, Otavio Citton, Michael Biehl","We revisit and extend the statistical physics based analysis of layered neural networks trained by online gradient descent. We focus on the infl uence of the hidden unit activation functions on the typical learning behavior in model scenarios. Expanding activation functions in terms of Hermite polynomials enables us to extend the formalism to the analysis of soft committee machines with arbitrary activation in student-teacher scenarios. The approach requires much lower computational eff ort than naive numerical integration, which is practically infeasible. Moreover, it now becomes possible to treat mismatched scenarios in which the student activation function diff ers from the one used in the target rule defi nition. This makes it possible to study realistic models of machine learning.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-116
2024,Online Adaptation of Compressed Models by Pre-Training and Task-Relevant Pruning,"Thomas Avé, Matthias Hutsebaut-Buysse, Wei Wei, Kevin Mets","Neural networks are increasingly deployed on edge devices, where they must adapt to new data in dynamic environments. Here, model compression techniques like pruning are essential. This involves removing redundant neurons, increasing efficiency at the cost of accuracy, and creating a conflict between efficiency and adaptability. We propose a novel method for training and compressing models that maintains and extends their ability to generalize to new data, improving online adaptation without reducing compression rates. By pre-training the model on additional knowledge and identifying the parts of the deep neural network that actually encode task-relevant knowledge, we can effectively prune the model by 80% and achieve 16% higher accuracies when adapting to new domains.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-50
2024,Deep Temporal Consensus Clustering for Patient Stratification in Amyotrophic Lateral Sclerosis,"Miguel Pego Roque, Andreia S. Martins, Marta Gromicho, Mamede de Carvalho, Sara C. Madeira, Pedro Tomás, Helena Aidos","Amyotrophic Lateral Sclerosis (ALS) is a fast-acting neurodegenerative disease, characterized by loss of muscle movement and heterogeneity in disease evolution. This poses a challenge in predicting the best time for therapy administration. Here, we propose Deep Temporal Consensus Clustering (DTCC), a stratification method to uncover patient groups with similar disease progression. Using only the initial 6-month follow-up period, DTCC uncovered five clusters that were evaluated in terms of disease evolution and time-to-event. For three critical events (non-invasive ventilation, gastrostomy and death) the attained groups show distinct 10-year progressions, validating the approach.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-195
2024,Trustworthiness Score for Echo State Networks by Analysis of the Reservoir Dynamics,"Jose M. Enguita-Gonzalez, Diego Garcia-Perez, Abel Alberto Cuadrado-Vega, Daniel García-Peña, José Ramón Rodríguez-Ossorio, Ignacio Diaz-Blanco","Epistemic uncertainty arises from input data areas where models lack exposure during training and may result in significant performance degradation in deployment. Echo State Networks are often used as virtual sensors or digital twins processing temporal input data, so their robustness against this degradation is crucial. This paper addresses this challenge by proposing a score comparing the similarity between the dynamic evolution of the reservoir in training and in inference. This research aims to enhance model confidence and adaptability in evolving circumstances.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-38
2024,Reservoir Memory Networks,"Claudio Gallicchio, Andrea Ceni","We introduce Reservoir Memory Networks (RMNs),  a novel class of  Reservoir Computing (RC) models that integrate a linear memory cell with a non-linear reservoir to enhance long-term information retention.  We explore various configurations of the memory cell using orthogonal circular shift matrices and Legendre polynomials, alongside non-linear reservoirs configured as in Echo State Networks and Euler State Networks. Experimental results demonstrate the substantial benefits of RMNs in time-series classification tasks, highlighting their potential for advancing RC applications in areas requiring robust temporal processing.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-117
2024,LSTM encoder-decoder model for contextualized time series forecasting applied to the simulation of a digital patient's physiological variables.,"Julien Paris, Christine Sinoquet, Fadoua Taia-Alaoui, Corinne Lejus-Bourdeau","This paper explores utilizing an encoder-decoder neural architecture for unsupervised representation learning of mixed asynchronous data, presenting the JMETTS (Joint Modelling of Event Traces and Time Series) model. Our goal is to forecast short-term multivariate time series within event contexts. As a proof of concept, we examine a real-world case in digitally assisted training for anaesthesiology. JMETTS demonstrates high predictive performance, with a maximum prediction error percentage of approximately 5.5%, comparable to that of its only competitor published to date. The source code can be found at https://github.com/jp3142/jmetts_models_and_pipeline.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-105
2024,Unsupervised Drift Detection Using Quadtree Spatial Mapping,"Bernardo A. Ramos, Cristiano Leite de Castro, Tiago A. Coelho, Plamen Angelov",This paper presents an unsupervised and model-independent concept drift detector based on quadtree spatial analysis (QTS). We used a d-dimensional quadtree to map the feature space and tracked a univariate curve that mimics the spatial behavior of the data stream. This curve serves as a helpful visual tool for analyzing concept drifts. Drifts are identified when there is a significant change in the current spatial mapping. Experimental results show that the proposed outperformed well-known drift detectors in terms of average precision and F1-score,Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-187
2024,Invariant Representation Learning for Generalizable Imitation,"Mohamed Jabri, Panagiotis Papadakis, Ehsan Abbasnejad,  Gilles Coppin, Javen Shi","We address the problem of learning imitation policies that generalize across environments sharing the same underlying causal structure between the system dynamics and the task. We introduce a novel loss for learning invariant state representations that draws inspiration from adversarial robustness. Our approach is algorithm-agnostic and does not require knowledge of domain labels. Yet, evaluation in visual and non-visual environments reveals improved zero-shot generalization in the presence of spurious features compared to previous works.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-18
2024,Vision Language Models as Policy Learners in Reinforcement Learning Environments,"Giovanni Bonetta, Davide Zago, Rossella Cancelliere, Mirko Polato, Bernardo Magnini","In various domains requiring general knowledge and agent reasoning, traditional reinforcement learning (RL) algorithms often start from scratch, lacking prior knowledge of the environment. This approach can lead to significant inefficiencies as agents sometimes undergo extensive exploration before optimizing their actions. Conversely, in this paper we assume that recent Vision Language Models (VLMs), integrating both visual  and textual information, possess inherent knowledge and basic reasoning capabilities, offering potential solutions to the sample inefficiency problem in RL. The paper explores the integration of VLMs into RL by employing a robust VLM model, Idefics-9B, as a policy updated via Proximal Policy Optimization (PPO). Experimental results on simulated environments demonstrate that utilizing VLMs in RL significantly accelerates PPO convergence and improves rewards compared to traditional  solutions. Additionally, we propose a streamlined modification to the model architecture for memory efficiency and lighter training, and we release a number of upgraded environments featuring both visual observations and textual descriptions, which, we hope, will facilitate research in VLM and RL applications. Code is available at: https://github.com/giobin/VlmPolicyEsann24","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-181
2024,Multidimensional CDTW-based features for Parkinson's Disease classification,"Ferhat Attal, Nicolas Khoury, Yacine Amirat","This paper presents an improvement of the Unidimensional Continuous Dynamic Time Warping (UCDTW) method for diagnosing Parkinson's Disease (PD) based on multidimensional time series data. These data include recordings of vertical Ground Reaction Forces (vGRFs) collected from eight force sensors per shoe sole during the walk. Leveraging gait cycle patterns, the proposed approach distinguishes between healthy and PD subjects by assessing gait cycle repetition through Multidimensional CDTW. Serval classification methods, including supervised (K-NN, DT, RF, SVM) and unsupervised (GMM, K-means), are used to classify the healthy and PD subjects, using MCDTW distances extracted from the gait cycles. The obtained results show a significant improvement in terms of classification performances.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-106
2024,Recurrent Neural Network based Counter Automata,"Sergio Leal, Luis Lago","This paper presents a neural network architecture that aims to merge RNNs and push-down automata in order to address the recognition of formal languages improving interpretability. The model manages to reproduce a behaviour equivalent to that of an automaton, making it more generalizable and interpretable. Validation has been carried out through several experiments, testing not only convergence but also adaptability and training speed, and comparing the results with similar existing models, as well as with an LSTM. The proposed model serves as a starting point with excellent results, and serves as a basis for future extensions to more sophisticated architectures.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-211
2024,Why long model-based rollouts are no reason for bad Q-value estimates,"Philipp Wissmann, Daniel Hein, Steffen Udluft, Volker Tresp","This paper explores the use of model-based offline reinforcement learning with long model rollouts. While some literature criticizes this approach due to compounding errors, many practitioners have found success in real-world applications. The paper aims to demonstrate that long rollouts do not necessarily result in exponentially growing errors and can actually produce better Q-value estimates compared to model-free methods. These findings can potentially enhance reinforcement learning techniques.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-80
2024,AI-based Collimation Optimization for X-Ray Imaging using Time-of-Flight Cameras,"Dominik Mairhöfer, Manuel  Laufer, Lennart Berkel, Arpad Bischof, Erhardt Barth, Jörg Barkhausen, Thomas Martinetz","Collimation during radiography, which is the process of defining the area to be radiated, is a crucial factor for the protection of the patient and for the diagnostic quality of a radiograph. Moreover, incorrect collimation is one of the main causes for a retake and the associated costs. In this paper we propose a novel collimation optimization approach using Time-of-Flight cameras and deep Neural Networks trained end-to-end to increase the diagnostic quality of a radiograph. For this we acquired a new dataset in a clinical environment consisting of depth images of the lower leg and the abdomen. Using this dataset we are able to segment depth images for the optimal collimation with an average IoU of 83%.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-147
2024,On the Stability of Neural Segmentation in Radiology,"moritz wolter, Lokesh Veeramacheneni, Bettina Baeßler, Ulrike I. Attenberger, Barbara D. Wichtmann","Neural networks promise automated prostate segmentation for the development of precise and quantifiable image-based biomarkers in modern personalized oncology. Before clinical translation, however, their stability must be ensured. In this study, we train three-dimensional U-shaped convolutional neural networks to segment prostate magnetic resonance imaging (MRI) scans and evaluate different loss formulations to improve their performance. To evaluate the generalizability and reproducibility of our networks, we compare their performance in a clinically acquired test/re-test MRI data set of 26 prostate cancer patients that was previously not seen by the networks. We find our networks to be generalizable with good reproducibility with a mean Intersection over Union of 0.88. While initial results are promising, anatomical accuracy remains to be evaluated in larger, multi-center data sets. To facilitate clinical applicability, we provide an easy-to-use toolbox online.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-172
2024,Analysis of DNA methylation patterns in cancer samples using SOM,"Ignacio Diaz-Blanco, Jose M. Enguita-Gonzalez, Diego Garcia-Perez, Abel A. Cuadrado-Vega, Nuria Valdes-Gallego, Maria Dolores Chiara-Romero","By leveraging the SOM algorithm and the extensive epigenomic data from TCGA, this work aims to suggest a valid approach to explore the relationships between epigenetic alterations and PCPG pathogenesis. Additionally, the methodological approach presented here lays the foundation for a potentially valuable analysis tool that can be applied to other cancer types and epigenetic research.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-42
2024,Graph-cut-assisted CNN training for pulmonary embolism segmentation,"Nana Yang, Robin Verschuren, Christophe De Vleeschouwer","We present a novel algorithm for pulmonary embolism segmentation, designed to alleviate the need for expert annotation. Our approach integrates deep learning with a conventional image segmentation techniques, operating in two distinct stages. Specifically, graph cut  is used for initial segmentation, followed by manual refinement, to define the labels required to train a CNN. This CNN is then employed to generate pseudo-labels on a large dataset, enabling the training of an improved CNN*. Our findings demonstrate enhanced performance of CNN* over CNN. Overall, the CNN* builds on a very limited amount of manual intervention. Moreover, the injection of expert knowledge in the graph-cut avoids the need for expert knowledge in this manual intervention.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-45
2024,Reconstruction of Mammography Projections using Image-to-Image Translation Techniques,"Joana Cristo Santos, Miriam Seoane Santos, Pedro Henriques Abreu","Mammography imaging is the gold standard for breast cancer detection and involves capturing two projections: mediolateral oblique and craniocaudal projections.  The implementation of an approach that allows the acquisition of only one projection and reconstructs the other could mitigate patient burden, minimize radiation exposure, and reduce costs. Image-to-image translation has showcased the ability to generate realistic synthetic images in different medical imaging modalities which make these techniques a great candidate for the novel application in mammography. This study aims to compare five image-to-image translation approaches to assess the feasibility of reconstructing a mammography projection from its counterpart.  The results indicate that ResViT shows the best overall performance in translating between both projections.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-62
