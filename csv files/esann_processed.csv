Title,Authors,Affiliations,Abstract,Keywords,PDF Link,Year,Match Score,Text_clean
TreeESN: a Preliminary Experimental Analysis,"Claudio Gallicchio, Alessio Micheli","1 - Department of Computer Science University of Pisa Largo B. Pontecorvo
2 - 56127 Italy","In this paper we introduce an efficient approach to Recursive Neural Networks (RecNNs) modeling, the Tree Echo State Network (TreeESN), extending the Echo State Network (ESN) model from sequential to tree structured domains processing. For structure-to-element transductions, the state mapping (i.e. the way in which the state values for the whole structure are selected/collected) turns out to have a relevant role and the importance of its choice is pointed out by experimental results.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-101.pdf,2010,100.0,"TreeESN: a Preliminary Experimental Analysis In this paper we introduce an efficient approach to Recursive Neural Networks (RecNNs) modeling, the Tree Echo State Network (TreeESN), extending the Echo State Network (ESN) model from sequential to tree structured domains processing. For structure-to-element transductions, the state mapping (i.e. the way in which the state values for the whole structure are selected/collected) turns out to have a relevant role and the importance of its choice is pointed out by experimental results."
Free-energy-based Reinforcement Learning in a Partially Observable Environment,"Makoto Otsuka, Junichiro Yoshimoto, Kenji Doya","1 - Initial Research Project Okinawa Institute of Science and Technology 12-22, 904-2234 Suzaki, Uruma Okinawa Japan
2 - Graduate School of Information Science Nara Institute of Science and Technology 8916-5, 630-0192 Takayama, Ikoma Nara Japan","Free-energy-based reinforcement learning (FERL) can handle Markov decision processes (MDPs) with high-dimensional state spaces by approximating the state-action value function with the negative equilibrium free energy of a restricted Boltzmann machine (RBM). In this study, we extend the FERL framework to handle partially observable MDPs (POMDPs) by incorporating a recurrent neural network that learns a memory representation sufficient for predicting future observations and rewards. We demonstrate that the proposed method successfully solves POMDPs with high-dimensional observations without any prior knowledge of the environmental hidden states and dynamics. After learning, task structures are implicitly represented in the distributed activation patterns of hidden nodes of the RBM.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-102.pdf,2010,73.07692307692308,"Free-energy-based Reinforcement Learning in a Partially Observable Environment Free-energy-based reinforcement learning (FERL) can handle Markov decision processes (MDPs) with high-dimensional state spaces by approximating the state-action value function with the negative equilibrium free energy of a restricted Boltzmann machine (RBM). In this study, we extend the FERL framework to handle partially observable MDPs (POMDPs) by incorporating a recurrent neural network that learns a memory representation sufficient for predicting future observations and rewards. We demonstrate that the proposed method successfully solves POMDPs with high-dimensional observations without any prior knowledge of the environmental hidden states and dynamics. After learning, task structures are implicitly represented in the distributed activation patterns of hidden nodes of the RBM."
Towards sub-quadratic learning of probability density models in the form of mixtures of trees,"François Schnitzler, Philippe Leray, Louis Wehenkel","1 - Université de Liège -Department of EECS & GIGA-Research Grande Traverse 10 -B-4000 Liège Belgium
2 - -Knowledge and Decision Team
3 - Laboratoire d'Informatique de Nantes Atlantique (LINA) UMR 6241 Ecole Polytechnique de l'Université de Nantes France","We consider randomization schemes of the Chow-Liu algorithm from weak (bagging, of quadratic complexity) to strong ones (full random sampling, of linear complexity), for learning probability density models in the form of mixtures of Markov trees. Our empirical study on high-dimensional synthetic problems shows that, while bagging is the most accurate scheme on average, some of the stronger randomizations remain very competitive in terms of accuracy, specially for small sample sizes.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-104.pdf,2010,100.0,"Towards sub-quadratic learning of probability density models in the form of mixtures of trees We consider randomization schemes of the Chow-Liu algorithm from weak (bagging, of quadratic complexity) to strong ones (full random sampling, of linear complexity), for learning probability density models in the form of mixtures of Markov trees. Our empirical study on high-dimensional synthetic problems shows that, while bagging is the most accurate scheme on average, some of the stronger randomizations remain very competitive in terms of accuracy, specially for small sample sizes."
Heuristics Miner for Time Intervals,"Andrea Burattin, Alessandro Sperduti",1 - Department of Pure and Applied Mathematics University of Padua Italy,"Process Mining attempts to reconstruct the workflow of a business process from logs of activities. This task is quite important in business scenarios where there is not a well understood and structured definition of the business process performed by workers. Activities logs are thus mined in the attempt to reconstruct the actual business process. In this paper, we propose the generalization of a popular process mining algorithm, named Heuristics Miner, to time intervals. We show that the possibility to use, when available, time interval information for the performed activities allows the algorithm to produce better workflow models.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-105.pdf,2010,100.0,"Heuristics Miner for Time Intervals Process Mining attempts to reconstruct the workflow of a business process from logs of activities. This task is quite important in business scenarios where there is not a well understood and structured definition of the business process performed by workers. Activities logs are thus mined in the attempt to reconstruct the actual business process. In this paper, we propose the generalization of a popular process mining algorithm, named Heuristics Miner, to time intervals. We show that the possibility to use, when available, time interval information for the performed activities allows the algorithm to produce better workflow models."
Learning vector quantization for heterogeneous structured data,"Dietlind Zühlke, Frank-Michael Schleif, Tina Geweniger, Sven Haase, Thomas Villmann","1 - -RWTH Aachen -Information Systems -Life Science Informatics Ahornstr. 55 D-52056 Aachen Germany
2 - University of Bielefeld -Working Group Computational Intelligence Universitätsstraße 25 D-33615 Bielefeld Germany
3 - University of Leipzig -Working Group Computational Intelligence Semmelweisstrasse 10 D-04103 Leipzig Germany
4 - University of Applied Sciences Mittweida -Computational Intelligence Technikumplatz 17 D-09648 Mittweida Germany",In this paper we introduce an approach to integrate heterogeneous structured data into a learning vector quantization. The total distance between two heterogeneous structured samples is defined as a weighted sum of the distances in the single structural components. The weights are adapted in every iteration of learning using gradient descend on the cost function inspired by Generalized Learning Vector Quantization. The new method was tested on a real world data set for pollen recognition using image analysis.,Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-106.pdf,2010,100.0,Learning vector quantization for heterogeneous structured data In this paper we introduce an approach to integrate heterogeneous structured data into a learning vector quantization. The total distance between two heterogeneous structured samples is defined as a weighted sum of the distances in the single structural components. The weights are adapted in every iteration of learning using gradient descend on the cost function inspired by Generalized Learning Vector Quantization. The new method was tested on a real world data set for pollen recognition using image analysis.
Curvilinear Components Analysis and Bregman Divergences,"Jigang Sun, Malcolm Crowe, Colin Fyfe",1 - Applied Computational Intelligence Research Unit The University of the West of Scotland,"Curvilinear Component Analysis (CCA) is an interesting flavour of multidimensional scaling. In this paper one version of CCA is proved to be related to the mapping found by a specific Bregman divergence and its stress function is redefined based on this insight, and its parameter (the neighbourhood radius) is explained.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-107.pdf,2010,55.04587155963303,"Curvilinear Components Analysis and Bregman Divergences Curvilinear Component Analysis (CCA) is an interesting flavour of multidimensional scaling. In this paper one version of CCA is proved to be related to the mapping found by a specific Bregman divergence and its stress function is redefined based on this insight, and its parameter (the neighbourhood radius) is explained."
Multiple Local Models for System Identification Using Vector Quantization Algorithms,"Gustavo Luís, Guilherme Souza, Barreto","1 - Department of Teleinformatics Engineering Av. Mister Hull S/N -Campus of Pici Federal University of Ceará 60455-760 Fortaleza, Ceará CEP Brazil","We introduce a novel method to build multiple local regression models based on the prototype vectors of the SOM network and other well-known vector quantization (VQ) algorithms. The resulting models are evaluated in the task of identifying the inverse dynamics of a heat exchanger data set. Additionally, we evaluate through statistical hypothesis testing the influence of the VQ algorithm on the performance of the local model. Simulation results demonstrate that the proposed method consistently outperforms previous MLP-and SOM-based approaches for system identification.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-113.pdf,2010,100.0,"Multiple Local Models for System Identification Using Vector Quantization Algorithms We introduce a novel method to build multiple local regression models based on the prototype vectors of the SOM network and other well-known vector quantization (VQ) algorithms. The resulting models are evaluated in the task of identifying the inverse dynamics of a heat exchanger data set. Additionally, we evaluate through statistical hypothesis testing the influence of the VQ algorithm on the performance of the local model. Simulation results demonstrate that the proposed method consistently outperforms previous MLP-and SOM-based approaches for system identification."
A Novel Interactive Biometric Passport Photograph Alignment System,"G Mcconnon, F Deravi, S Hoque, G Howells, K Sirlantzis","1 - School of Engineering and Digital Arts Jennison Building University of Kent UoK CT2 7NT Canterbury, Kent United Kingdom",A novel framework for interactively acquiring images is developed in which uses real-time visual and audio cues to assist in guiding the user into correct alignment for compliance with European biometric passport regulations. Users pose in front of a camera using visual feedback from a monitor to approximately position themselves prior to an iris detection scheme used to calculate their roll (zaxis) alignment. Audio instructions are then provided to refine the posture. Blink detection is also used to ascertain the user's readiness to having their passport image taken. * This work is part of the NOmad Biometric Authentication (NOBA) project funded by ERDF under the Interreg IVA program. Reference No. 4051.,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-114.pdf,2010,89.39393939393939,A Novel Interactive Biometric Passport Photograph Alignment System A novel framework for interactively acquiring images is developed in which uses real-time visual and audio cues to assist in guiding the user into correct alignment for compliance with European biometric passport regulations. Users pose in front of a camera using visual feedback from a monitor to approximately position themselves prior to an iris detection scheme used to calculate their roll (zaxis) alignment. Audio instructions are then provided to refine the posture. Blink detection is also used to ascertain the user's readiness to having their passport image taken. * This work is part of the NOmad Biometric Authentication (NOBA) project funded by ERDF under the Interreg IVA program. Reference No. 4051.
Least 1-Norm SVMs: a New SVM Variant between Standard and LS-SVMs,"Jorge López, José Dorronsoro","1 - Departamento de Ingeniería Informática Universidad Autónoma de Madrid
2 - Instituto de Ingeniería del Conocimiento C/ Francisco Tomás y Valiente 11 28049 Madrid Spain","Least Squares Support Vector Machines (LS-SVMs) were proposed by replacing the inequality constraints inherent to L1-SVMs with equality constraints. So far this idea has only been suggested for a least squares (L2) loss. We describe how this can also be done for the sumof-slacks (L1) loss, yielding a new classifier (Least 1-Norm SVMs) which gives similar models in terms of complexity and accuracy and that may also be more robust than LS-SVMs with respect to outliers.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-115.pdf,2010,69.23076923076923,"Least 1-Norm SVMs: a New SVM Variant between Standard and LS-SVMs Least Squares Support Vector Machines (LS-SVMs) were proposed by replacing the inequality constraints inherent to L1-SVMs with equality constraints. So far this idea has only been suggested for a least squares (L2) loss. We describe how this can also be done for the sumof-slacks (L1) loss, yielding a new classifier (Least 1-Norm SVMs) which gives similar models in terms of complexity and accuracy and that may also be more robust than LS-SVMs with respect to outliers."
The Markov Decision Process Extraction Network,"Siegmund Duell, Alexander Hans, Steffen Udluft","1 - Siemens AG, Corporate Research and Technologies Learning Systems, Otto-Hahn-Ring 6 D-81739 Munich Germany
2 - Berlin University of Technology Machine Learning Franklinstr. 28-29 D-10587 Berlin Germany
4 - Neuroinformatics and Cognitive Robotics Lab Ilmenau University of Technology P.O.Box 100565 D-98684 Ilmenau Germany","This paper presents the Markov decision process extraction network, which is a data-efficient, automatic state estimation approach for discrete-time reinforcement learning (RL) based on recurrent neural networks. The architecture is designed to model the minimal relevant dynamics of an environment, capable of condensing large sets of continuous observables to a compact state representation and excluding irrelevant information. To the best of our knowledge, it is the first approach published to automatically extract minimal relevant aspects of the dynamics from observations to model a Markov decision process, suitable for RL, without requiring special knowledge of the regarded environment. The capabilities of the neural state estimation approach are evaluated using the cart-pole problem and standard table-based policy iteration.",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-116.pdf,2010,100.0,"The Markov Decision Process Extraction Network This paper presents the Markov decision process extraction network, which is a data-efficient, automatic state estimation approach for discrete-time reinforcement learning (RL) based on recurrent neural networks. The architecture is designed to model the minimal relevant dynamics of an environment, capable of condensing large sets of continuous observables to a compact state representation and excluding irrelevant information. To the best of our knowledge, it is the first approach published to automatically extract minimal relevant aspects of the dynamics from observations to model a Markov decision process, suitable for RL, without requiring special knowledge of the regarded environment. The capabilities of the neural state estimation approach are evaluated using the cart-pole problem and standard table-based policy iteration."
Oriented Bounding Box Computation Using Particle Swarm Optimization *,"Pierre Borckmans, P.-A Absil",1 - Department of Mathematical Engineering Université catholique de Louvain B-1348 Louvain-la-Neuve Belgium (,"The problem of finding the optimal oriented bounding box (OBB) for a given set of points in R 3 , yet simple to state, is computationally challenging. Existing state-of-the-art methods dealing with this problem are either exact but slow, or fast but very approximative and unreliable. We propose a method based on Particle Swarm Optimization (PSO) to approximate solutions both effectively and accurately. The original PSO algorithm is modified so as to search for optimal solutions over the rotation group SO(3). Particles are defined as 3D rotation matrices and operations are expressed over SO(3) using matrix products, exponentials and logarithms. The symmetry of the problem is also exploited. Numerical experiments show that the proposed algorithm outperforms existing methods, often by far. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization, funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, Science Policy Office). The scientific responsibility rests with its authors. This work is supported by a FRIA (Fonds pour la formation à la Recherche dans l'Industrie et dans l'Agriculture) fellowship and by ""Communauté française de Belgique -Actions de Recherche Concertées"".",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-117.pdf,2010,98.52941176470588,"Oriented Bounding Box Computation Using Particle Swarm Optimization * The problem of finding the optimal oriented bounding box (OBB) for a given set of points in R 3 , yet simple to state, is computationally challenging. Existing state-of-the-art methods dealing with this problem are either exact but slow, or fast but very approximative and unreliable. We propose a method based on Particle Swarm Optimization (PSO) to approximate solutions both effectively and accurately. The original PSO algorithm is modified so as to search for optimal solutions over the rotation group SO(3). Particles are defined as 3D rotation matrices and operations are expressed over SO(3) using matrix products, exponentials and logarithms. The symmetry of the problem is also exploited. Numerical experiments show that the proposed algorithm outperforms existing methods, often by far. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization, funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, Science Policy Office). The scientific responsibility rests with its authors. This work is supported by a FRIA (Fonds pour la formation à la Recherche dans l'Industrie et dans l'Agriculture) fellowship and by ""Communauté française de Belgique -Actions de Recherche Concertées""."
Learning how to grasp objects,"Annalisa Barla, Luca Baldassarre, Nicoletta Noceti, Francesca Odone",1 - DIFI Università degli Studi di Genova via Dodecaneso 35 Genova Italy,"This paper deals with the problem of estimating an appropriate hand posture to grasp an object, from 2D object's visual cues in a many-to-many (objects,grasp) configuration. A statistical learning protocol implementing vector-valued regression is adopted for both classifying the most likely grasp type and estimating the hand posture. An extensive experimental evaluation on a publicly available dataset of visuo-motor data reports very promising results and encourages further investigations.",Physiology and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-118.pdf,2010,100.0,"Learning how to grasp objects This paper deals with the problem of estimating an appropriate hand posture to grasp an object, from 2D object's visual cues in a many-to-many (objects,grasp) configuration. A statistical learning protocol implementing vector-valued regression is adopted for both classifying the most likely grasp type and estimating the hand posture. An extensive experimental evaluation on a publicly available dataset of visuo-motor data reports very promising results and encourages further investigations."
Asymptotic properties of mixture-of-experts models,"M Olteanu, J Rynkiewicz","1 - Universite Paris 1
2 - SAMOS-CES 90 Rue de Tolbiac 75013 Paris France","The statistical properties of the likelihood ratio test statistic (LRTS) for mixture-of-expert models are addressed in this paper. This question is essential when estimating the number of experts in the model. Our purpose is to extend the existing results for mixtures  (Liu and Shao, 2003)  and mixtures of multilayer perceptrons  (Olteanu and Rynkiewicz, 2008) . In this paper we study a simple example which embodies all the difficulties arising in such models. We find that in some cases the LRTS diverges but, with additional assumptions, the behavior of such models can be totally explicated.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-120.pdf,2010,100.0,"Asymptotic properties of mixture-of-experts models The statistical properties of the likelihood ratio test statistic (LRTS) for mixture-of-expert models are addressed in this paper. This question is essential when estimating the number of experts in the model. Our purpose is to extend the existing results for mixtures  (Liu and Shao, 2003)  and mixtures of multilayer perceptrons  (Olteanu and Rynkiewicz, 2008) . In this paper we study a simple example which embodies all the difficulties arising in such models. We find that in some cases the LRTS diverges but, with additional assumptions, the behavior of such models can be totally explicated."
An Augmented Efficient Backpropagation Training Strategy for Deep Autoassociative Neural Networks,"Mark Embrechts, Blake Hargis, Jonathan Linton","1 - Department of Decision Sciences and Engineering Systems Rensselaer Polytechnic Institute Troy New York USA
3 - University of Ottawa Telfer School of Management","We introduce Augmented Efficient BackProp, a strategy for applying the backpropagation algorithm to deep autoencoders, i.e. autoassociators with many hidden layers, without relying on a weight initialization using restricted Boltzmann machines (RBMs). This training method, benchmarked on three different types of application datasets, is an extension of Efficient BackProp, first proposed by LeCun et al. [12].",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-122.pdf,2010,86.5979381443299,"An Augmented Efficient Backpropagation Training Strategy for Deep Autoassociative Neural Networks We introduce Augmented Efficient BackProp, a strategy for applying the backpropagation algorithm to deep autoencoders, i.e. autoassociators with many hidden layers, without relying on a weight initialization using restricted Boltzmann machines (RBMs). This training method, benchmarked on three different types of application datasets, is an extension of Efficient BackProp, first proposed by LeCun et al. [12]."
Extending FSNPC to handle data points with fuzzy class assignments,"Tina Geweniger, Thomas Villmann","1 - University of Leipzig -Working Group Computational Intelligence Semmelweisstrasse 10 04103 Leipzig Germany
2 - Department of Mathematics/Physics/Informatics University of Applied Sciences Mittweida Computational Intelligence Group Technikumplatz 17 09648 Mittweida Germany",In this paper we present an advanced Nearest Prototype Classification to handle data points with unsharp class assignments. Therefore we extend the Soft Nearest Prototype Classification as proposed by Seo et al. and its further enhancement working with fuzzy labeled prototypes as introduced by Villmann et al. We adapt the cost function and derive appropriate update rules for the prototypes. We assess the performance on a toy data set and a real-world problem and compare the classification result with the results obtained by Fuzzy Robust Soft LVQ by means of Fuzzy Cohen's Kappa.,Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-123.pdf,2010,100.0,Extending FSNPC to handle data points with fuzzy class assignments In this paper we present an advanced Nearest Prototype Classification to handle data points with unsharp class assignments. Therefore we extend the Soft Nearest Prototype Classification as proposed by Seo et al. and its further enhancement working with fuzzy labeled prototypes as introduced by Villmann et al. We adapt the cost function and derive appropriate update rules for the prototypes. We assess the performance on a toy data set and a real-world problem and compare the classification result with the results obtained by Fuzzy Robust Soft LVQ by means of Fuzzy Cohen's Kappa.
Exploiting Local Structure in Stacked Boltzmann Machines,"Hannes Schulz, Andreas Müller, Sven Behnke",1 - Autonomous Intelligent Systems Group Römerstraße 164 University of Bonn -Computer Science VI 53117 Bonn Germany,"Restricted Boltzmann Machines (RBM) are well-studied generative models. For image data, however, standard RBMs are suboptimal, since they do not exploit the local nature of image statistics. We modify RBMs to focus on local structure by restricting visible-hidden interactions. We model long-range interactions using direct or indirect lateral interaction between hidden variables. While learning in our model is much faster, it retains generative and discriminative properties of RBMs of similar complexity.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-126.pdf,2010,87.5,"Exploiting Local Structure in Stacked Boltzmann Machines Restricted Boltzmann Machines (RBM) are well-studied generative models. For image data, however, standard RBMs are suboptimal, since they do not exploit the local nature of image statistics. We modify RBMs to focus on local structure by restricting visible-hidden interactions. We model long-range interactions using direct or indirect lateral interaction between hidden variables. While learning in our model is much faster, it retains generative and discriminative properties of RBMs of similar complexity."
Principal Curve Tracing,"Erhan Bas, Deniz Erdogmus",1 - ECE Department Cognitive Systems Laboratory Northeastern University 02115 Boston MA USA,We propose a principal curve tracing algorithm that uses the gradient and the Hessian of a given density estimate. Curve definition requires the local smoothness of data density and is based on the concept of subspace local maxima. Tracing of the curve is handled through the leading eigenvector where fixed-step updates are used. We also propose an image segmentation algorithm based on the original idea and show the effectiveness of the proposed algorithm on a Brainbow dataset.,Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-127.pdf,2010,69.56521739130434,Principal Curve Tracing We propose a principal curve tracing algorithm that uses the gradient and the Hessian of a given density estimate. Curve definition requires the local smoothness of data density and is based on the concept of subspace local maxima. Tracing of the curve is handled through the leading eigenvector where fixed-step updates are used. We also propose an image segmentation algorithm based on the original idea and show the effectiveness of the proposed algorithm on a Brainbow dataset.
Image Registration by the Extended Evolutionary Self-Organizing Map,"José Everardo, B Maia, Guilherme Barreto, André Coelho","1 - Department of Statistics Computing State University of Ceará (UECE) Fortaleza, Ceará Brazil
2 - Department of Teleinformatics Engineering Federal University of Ceará (UFC) Fortaleza, Ceará Brazil
3 - Graduate Program in Applied Informatics University of Fortaleza (Unifor) Fortaleza, Ceará Brazil","The Evolutionary Self-Organizing Map (EvSOM) is a recently proposed robust approach for topographic map formation that is based on evolutionary algorithms. In this work, a variant of EvSOM is proposed in order to fully exploit the neighborhood preservation property of the topographic maps induced by it when dealing with the image registration (IR) problem. In particular, the novel EvSOM is adopted here with the assumption that the relationship between the reference image and the free image can be approximated by an affine transformation. Preliminary experiments with black & white retinal blood vessel images are discussed, comparing the performance of EvSOM with that of two well-known IR methods, namely, iterative closest point and template matching. Overall, the results confirm the potentials of the extended EvSOM in this new application scenario.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-128.pdf,2010,79.10447761194031,"Image Registration by the Extended Evolutionary Self-Organizing Map The Evolutionary Self-Organizing Map (EvSOM) is a recently proposed robust approach for topographic map formation that is based on evolutionary algorithms. In this work, a variant of EvSOM is proposed in order to fully exploit the neighborhood preservation property of the topographic maps induced by it when dealing with the image registration (IR) problem. In particular, the novel EvSOM is adopted here with the assumption that the relationship between the reference image and the free image can be approximated by an affine transformation. Preliminary experiments with black & white retinal blood vessel images are discussed, comparing the performance of EvSOM with that of two well-known IR methods, namely, iterative closest point and template matching. Overall, the results confirm the potentials of the extended EvSOM in this new application scenario."
Identifying informative features for ERP speller systems based on RSVP paradigm,"Tian Lan, Deniz Erdogmus, Lois Black, Jan Santen","1 - Oregon Health & Science University -Dept of Science and Engineering Beaverton Oregon USA
2 - Dept of Electrical and Computer Engineering Boston Northeastern University Massachusetts USA",This preliminary study focused on identifying informative features in the frequency and spatial domains for single-trial Event Related Potential (ERP) detection for ERP spelling systems. A predefined sequence of letters was presented to subjects in a Rapid Serial Visual Presentation (RSVP) paradigm. EEG data were collected and analyzed offline. A Linear Discriminant Analysis (LDA) classifier was selected as ERP detector for its simplicity and robustness. A range of features in different frequency bands and EEG channel subsets was extracted and detection accuracies were compared for different classes of features.,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-129.pdf,2010,100.0,Identifying informative features for ERP speller systems based on RSVP paradigm This preliminary study focused on identifying informative features in the frequency and spatial domains for single-trial Event Related Potential (ERP) detection for ERP spelling systems. A predefined sequence of letters was presented to subjects in a Rapid Serial Visual Presentation (RSVP) paradigm. EEG data were collected and analyzed offline. A Linear Discriminant Analysis (LDA) classifier was selected as ERP detector for its simplicity and robustness. A range of features in different frequency bands and EEG channel subsets was extracted and detection accuracies were compared for different classes of features.
Active Set Training of Support Vector Regressors,Shigeo Abe,1 - Kobe University -Graduate School of Engineering Kobe Japan,"In our previous work we have discussed the training method of a support vector classifier by active set training allowing the solution to be infeasible during training. In this paper, we extend this method to training a support vector regressor (SVR). We use the dual form of the SVR where variables take real values and in the objective function the weighted linear sum of absolute values of the variables is included. We allow the variables to change signs from one step to the next. This means changes of the active inequality constraints. Namely, we solve the quadratic programming problem for the initial working set of training data by Newton's method, delete from the working set the data within the epsilon tube, add to the working set training data outside of the epsilon tube, and repeat training the SVM until the working set does not change. We demonstrate the effectiveness of the proposed method using some benchmark data sets.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-13.pdf,2010,83.33333333333334,"Active Set Training of Support Vector Regressors In our previous work we have discussed the training method of a support vector classifier by active set training allowing the solution to be infeasible during training. In this paper, we extend this method to training a support vector regressor (SVR). We use the dual form of the SVR where variables take real values and in the objective function the weighted linear sum of absolute values of the variables is included. We allow the variables to change signs from one step to the next. This means changes of the active inequality constraints. Namely, we solve the quadratic programming problem for the initial working set of training data by Newton's method, delete from the working set the data within the epsilon tube, add to the working set training data outside of the epsilon tube, and repeat training the SVM until the working set does not change. We demonstrate the effectiveness of the proposed method using some benchmark data sets."
A Novel Two-Phase SOM Clustering Approach to Discover Visitor Interests in a Website,"Ahmad Ammari, Valentina Zharkova",1 - Informatics and Media {A.N.Ammari University of Bradford -School of Computing V.V.Zharkova} @Bradford.ac.uk -Bradford United Kingdom,"Mining content, structure and usage data in websites can uncover browsing patterns that different groups of Web visitors follow to access the subjects that are truly valuable to them. Many works in the literature focused on proposing new similarity measures to cluster Web logs and detect segments of browsing behaviors. However, this does not reveal which contents the visitors are interested in since a Web page may contain many different topics. In this paper, a novel two-phase clustering approach based on Self Organizing Maps (SOM) is proposed to address this problem. A systematic process to prepare Web content data for clustering is also described.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-132.pdf,2010,100.0,"A Novel Two-Phase SOM Clustering Approach to Discover Visitor Interests in a Website Mining content, structure and usage data in websites can uncover browsing patterns that different groups of Web visitors follow to access the subjects that are truly valuable to them. Many works in the literature focused on proposing new similarity measures to cluster Web logs and detect segments of browsing behaviors. However, this does not reveal which contents the visitors are interested in since a Web page may contain many different topics. In this paper, a novel two-phase clustering approach based on Self Organizing Maps (SOM) is proposed to address this problem. A systematic process to prepare Web content data for clustering is also described."
Solving Large Regression Problems using an Ensemble of GPU-accelerated ELMs,"Mark Van Heeswijk, Yoan Miche, Erkki Oja, Amaury Lendasse","1 - Dept. of Information and Computer Science Helsinki University of Technology Konemiehentie 2 02015 HUT Finland
2 - Lab Institut National Polytechnique de Grenoble -Gipsa 961 rue de la Houille Blanche F-38402 Grenoble Cedex France","This paper presents an approach that allows for performing regression on large data sets in reasonable time. The main component of the approach consists in speeding up the slowest operation of the used algorithm by running it on the Graphics Processing Unit (GPU) of the video card, instead of the processor (CPU). The experiments show a speedup of an order of magnitude by using the GPU, and competitive performance on the regression task. Furthermore, the presented approach lends itself for further parallelization, that has still to be investigated.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-133.pdf,2010,100.0,"Solving Large Regression Problems using an Ensemble of GPU-accelerated ELMs This paper presents an approach that allows for performing regression on large data sets in reasonable time. The main component of the approach consists in speeding up the slowest operation of the used algorithm by running it on the Graphics Processing Unit (GPU) of the video card, instead of the processor (CPU). The experiments show a speedup of an order of magnitude by using the GPU, and competitive performance on the regression task. Furthermore, the presented approach lends itself for further parallelization, that has still to be investigated."
Predicting spike-timing of a thalamic neuron using a stochastic synaptic model,"Karim El-Laithy, Martin Bogdan",1 - Faculty of Computer science and Mathematics Dept of Computer Engineering Johannisgasse 26 04103 Leipzig Germany,"A twofold spike-timing dependent stochastic synaptic model is used along with a leaky Integrate-and-Fire neuronal model to predict the spike timing of a single post-synaptic neuron in the lateral geniculate nucleus, knowing the spike train on the pre-synaptic side (i.e. in a retinal ganglion cell). In this synaptic model, spike-timing dependency is introduced for both the magnitude and relaxation of the dynamics representing the synaptic action. The results show that the used model is able to reliably predict the exact timing of spikes. These results and the model are the winner of a recent international competition.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-14.pdf,2010,100.0,"Predicting spike-timing of a thalamic neuron using a stochastic synaptic model A twofold spike-timing dependent stochastic synaptic model is used along with a leaky Integrate-and-Fire neuronal model to predict the spike timing of a single post-synaptic neuron in the lateral geniculate nucleus, knowing the spike train on the pre-synaptic side (i.e. in a retinal ganglion cell). In this synaptic model, spike-timing dependency is introduced for both the magnitude and relaxation of the dynamics representing the synaptic action. The results show that the used model is able to reliably predict the exact timing of spikes. These results and the model are the winner of a recent international competition."
Spectral Prototype Extraction for dimensionality reduction in brain tumour diagnosis,"Sandra Ortega-Martorell, Iván Olier, Alfredo Vellido, Margarida Julià-Sapé, Carles Arús","1 - Departament de Bioquímica
2 - Centro de Investigación Biomédica en Red en Bioingeniería Cerdanyola del Vallès (Barcelona) CIBER-BBN) 08193 Biomateriales y Nanomedicina Spain
3 - Institut de Neurociències -UAB Edifici M M3/206, 08193 Despatx
4 - Cerdanyola del Vallès (Barcelona) Spain
5 - -Dept. de Llenguatges i Sistemes Informàtics -UPC Edifici Omega Campus Nord 08034 Barcelona Spain
10 - Biología Molecular -Unitat de Biociències -UAB 08193 Cerdanyola del Vallès (Barcelona) Spain","Diagnosis in neuro-oncology can be assisted by non-invasive data acquisition techniques such as Magnetic Resonance Spectroscopy (MRS). From the viewpoint of computer-based brain tumour classification, the high dimensionality of MRS poses a difficulty, and the use of dimensionality reduction (DR) techniques is advisable. Despite some important limitations, Principal Component Analysis (PCA) is commonly used for DR in MRS data analysis. Here, we define a novel DR technique, namely Spectral Prototype Extraction, based on a manifold-constrained Hidden Markov Model (HMM). Its formulation within a variational Bayesian framework imbues it with regularization properties that minimize the negative effect of the presence of noise in the data. Its use for MRS pre-processing is illustrated in a difficult brain tumour classification problem.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-15.pdf,2010,100.0,"Spectral Prototype Extraction for dimensionality reduction in brain tumour diagnosis Diagnosis in neuro-oncology can be assisted by non-invasive data acquisition techniques such as Magnetic Resonance Spectroscopy (MRS). From the viewpoint of computer-based brain tumour classification, the high dimensionality of MRS poses a difficulty, and the use of dimensionality reduction (DR) techniques is advisable. Despite some important limitations, Principal Component Analysis (PCA) is commonly used for DR in MRS data analysis. Here, we define a novel DR technique, namely Spectral Prototype Extraction, based on a manifold-constrained Hidden Markov Model (HMM). Its formulation within a variational Bayesian framework imbues it with regularization properties that minimize the negative effect of the presence of noise in the data. Its use for MRS pre-processing is illustrated in a difficult brain tumour classification problem."
On the use of a clinical kernel in survival analysis,"V Van Belle, K Pelckmans, J Suykens, S Van Huffel","1 - Katholieke Universiteit Leuven ESAT-SCD Kasteelpark Arenberg 10 B-3001 Leuven Belgium
2 - Department of Information Technology University of Uppsala SE-751 05 Uppsala Sweden","Clinical datasets typically contain continuous, ordinal, categorical and binary variables. To model this type of datasets, linear kernel methods are generally used. However, the linear kernel has some disadvantages, which were tackled by the introduction of a clinical one. This work shows that the use of a clinical kernel can improve the performance of support vector machine survival models. In addition, the polynomial kernel is adapted in the same way to obtain a clinical polynomial kernel. A comparison is made with other non-linear additive kernels on six different survival data. Our results indicate that the use of a clinical kernel is a simple way to obtain non-linear models for survival analysis, without the need to tune an extra parameter.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-16.pdf,2010,100.0,"On the use of a clinical kernel in survival analysis Clinical datasets typically contain continuous, ordinal, categorical and binary variables. To model this type of datasets, linear kernel methods are generally used. However, the linear kernel has some disadvantages, which were tackled by the introduction of a clinical one. This work shows that the use of a clinical kernel can improve the performance of support vector machine survival models. In addition, the polynomial kernel is adapted in the same way to obtain a clinical polynomial kernel. A comparison is made with other non-linear additive kernels on six different survival data. Our results indicate that the use of a clinical kernel is a simple way to obtain non-linear models for survival analysis, without the need to tune an extra parameter."
Machine learning analysis and modeling of interest rate curves,"Mikhail Kanevski, Vadim Timonin","1 - University of Lausanne -Institute of Geomatics and Analysis of Risk IGAR 1015 Amphipole, Lausanne -Switzerland","The present research deals with the review of the analysis and modeling of Swiss franc interest rate curves (IRC) by using unsupervised (SOM, Gaussian Mixtures) and supervised machine (MLP) learning algorithms. IRC are considered as objects embedded into different feature spaces: maturities; maturity-date, parameters of Nelson-Siegel model (NSM). Analysis of NSM parameters and their temporal and clustering structures helps to understand the relevance of model and its potential use for the forecasting. Mapping of IRC in a maturity-date feature space is presented and analyzed for the visualization and forecasting purposes. * The research was partly supported by Swiss NSF grants N200021-126505 and N 200020-121835. We thank M. Maignan and A. Pozdnoukhov for some useful discussions.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-17.pdf,2010,100.0,"Machine learning analysis and modeling of interest rate curves The present research deals with the review of the analysis and modeling of Swiss franc interest rate curves (IRC) by using unsupervised (SOM, Gaussian Mixtures) and supervised machine (MLP) learning algorithms. IRC are considered as objects embedded into different feature spaces: maturities; maturity-date, parameters of Nelson-Siegel model (NSM). Analysis of NSM parameters and their temporal and clustering structures helps to understand the relevance of model and its potential use for the forecasting. Mapping of IRC in a maturity-date feature space is presented and analyzed for the visualization and forecasting purposes. * The research was partly supported by Swiss NSF grants N200021-126505 and N 200020-121835. We thank M. Maignan and A. Pozdnoukhov for some useful discussions."
Highly Sparse Kernel Spectral Clustering with Predictive Out-of-Sample Extensions,"Carlos Alzate, Johan Suykens",1 - K.U.Leuven -Dept. of Electrical Engineering ESAT -SCD Kasteelpark Arenberg 10 B-3001 Leuven Belgium,"Kernel spectral clustering has been formulated as a primal -dual optimization setting allowing natural extensions to out-of-sample data together with model selection in a learning framework which is important for obtaining a good generalization performance. In this paper, we propose a new sparse method for kernel spectral clustering. The approach exploits the structure of the eigenvectors and the corresponding projections of the data when the clusters are well formed. Experimental results with toy data and images show highly sparse clustering models with predictive capabilities. 
 Predictive Kernel Spectral Clustering 2.1 Primal -Dual Formulation Given training data D = {x i } N i=1 , x i ∈ R d and the number of desired clusters k, the following clustering model can be assumed: e (l) = Φw (l) + b l 1 N , l = 1, . . . , n e 235",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-18.pdf,2010,81.4814814814815,"Highly Sparse Kernel Spectral Clustering with Predictive Out-of-Sample Extensions Kernel spectral clustering has been formulated as a primal -dual optimization setting allowing natural extensions to out-of-sample data together with model selection in a learning framework which is important for obtaining a good generalization performance. In this paper, we propose a new sparse method for kernel spectral clustering. The approach exploits the structure of the eigenvectors and the corresponding projections of the data when the clusters are well formed. Experimental results with toy data and images show highly sparse clustering models with predictive capabilities. 
 Predictive Kernel Spectral Clustering 2.1 Primal -Dual Formulation Given training data D = {x i } N i=1 , x i ∈ R d and the number of desired clusters k, the following clustering model can be assumed: e (l) = Φw (l) + b l 1 N , l = 1, . . . , n e 235"
Distance Functions for Local PCA Methods,"Alexander Kaiser, Wolfram Schenck, Ralf Möller",1 - Computer Engineering Group -Faculty of Technology Bielefeld University POB 100131 D-33501 Bielefeld Germany,"The NGPCA method, a combination of the robust neural gas vector quantization method and a fast neural principal component analyzer, has proved to be a valuable tool for the generalized learning of high-dimensional data. At its core, the method uses a competitive ranking to adapt its units. The competition is guided by a specialized distance function -known as the normalized Mahalanobis distance -that assumes elliptic cluster shapes. Recently, an alternative distance function, the normalized Rayleigh quotient, has been suggested. This paper compares the performance of NGPCA on different distance functions. For the comparison a data set from a realistic robot arm experiment is used.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-19.pdf,2010,72.5,"Distance Functions for Local PCA Methods The NGPCA method, a combination of the robust neural gas vector quantization method and a fast neural principal component analyzer, has proved to be a valuable tool for the generalized learning of high-dimensional data. At its core, the method uses a competitive ranking to adapt its units. The competition is guided by a specialized distance function -known as the normalized Mahalanobis distance -that assumes elliptic cluster shapes. Recently, an alternative distance function, the normalized Rayleigh quotient, has been suggested. This paper compares the performance of NGPCA on different distance functions. For the comparison a data set from a realistic robot arm experiment is used."
Computational Intelligence in biomedicine: Some contributions,"Paulo Lisboa, Alfredo Vellido, José Martín","1 - Department of Mathematics and Statistics. Liverpool John Moores University Byrom St L3 3AF Liverpool United Kingdom
2 - Dept. de Llenguatges i Sistemes Informàtics -Universitat Politècnica de Catalunya Edifici Omega Campus Nord 08034 Barcelona Spain
3 - Departament d'Enginyeria Electrònica Universitat de València C. Dr. Moliner 50. 46100 Burjassot (València) Spain","The commodification of healthcare has led to an increasing demand for personalization of patients' treatments. Meeting this demand requires not only the commitment of abundant resources, but also a sophisticated management of information systems, leading to initiatives such as the standardization of electronic health records. As these become mainstream, the amount of medical data available for analysis and knowledge extraction will increase exponentially. This is coupled with a surge in novel techniques for the non-invasive measurement and acquisition of medicallyrelevant data, in various forms including signals and image. The resulting vast amount of information -notwithstanding issues of standardization and availability -is a valuable asset for the Computational Intelligence community. Tapping into this data source, biomedical applications of CI are already experimenting an extraordinary growth. At ESANN, the special session ""Computational Intelligence in Biomedicine"" reflects some of the main emerging themes in the field. This brief tutorial prefaces the session, summarizing some of the contributions, while also providing some pointers to opportunities and challenges for CI in biomedical research.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-2.pdf,2010,100.0,"Computational Intelligence in biomedicine: Some contributions The commodification of healthcare has led to an increasing demand for personalization of patients' treatments. Meeting this demand requires not only the commitment of abundant resources, but also a sophisticated management of information systems, leading to initiatives such as the standardization of electronic health records. As these become mainstream, the amount of medical data available for analysis and knowledge extraction will increase exponentially. This is coupled with a surge in novel techniques for the non-invasive measurement and acquisition of medicallyrelevant data, in various forms including signals and image. The resulting vast amount of information -notwithstanding issues of standardization and availability -is a valuable asset for the Computational Intelligence community. Tapping into this data source, biomedical applications of CI are already experimenting an extraordinary growth. At ESANN, the special session ""Computational Intelligence in Biomedicine"" reflects some of the main emerging themes in the field. This brief tutorial prefaces the session, summarizing some of the contributions, while also providing some pointers to opportunities and challenges for CI in biomedical research."
Finding Correlations in Multimodal Data Using Decomposition Approaches,"Daniel Dornbusch, Robert Haschke, Stefan Menzel, Heiko Wersing","1 - CoR-Lab Bielefeld University Universitätsstr. 25 D-33615 Bielefeld Germany
3 - Honda Research Institute Europe GmbH Carl-Legien-Str. 30 D-63073 Offenbach/Main Germany","In this paper, we propose the application of standard decomposition approaches to find local correlations in multimodal data. In a test scenario, we apply these methods to correlate the local shape of turbine blades with their associated aerodynamic flow fields. We compare several decomposition algorithms, i.e., k-Means, Principal Component Analysis, Non-negative Matrix Factorization and Non-Negative Sparse Coding, with regards to their efficiency at finding local correlations and their ability to predict one modality from another.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-24.pdf,2010,80.0,"Finding Correlations in Multimodal Data Using Decomposition Approaches In this paper, we propose the application of standard decomposition approaches to find local correlations in multimodal data. In a test scenario, we apply these methods to correlate the local shape of turbine blades with their associated aerodynamic flow fields. We compare several decomposition algorithms, i.e., k-Means, Principal Component Analysis, Non-negative Matrix Factorization and Non-Negative Sparse Coding, with regards to their efficiency at finding local correlations and their ability to predict one modality from another."
Reliability of dimension reduction visualizations of hierarchical structures,Elina Parviainen,1 - Helsinki Univ. of Technology -Dept. of Biomedical Engineering and Computational Science P.O.Box 2200 FI-02015 TKK Finland,"Dimension reduction can produce visualizations of hierarchical structures, like those produced by cluster analysis. So far, reliability of such visualizations has only been assessed with rudimentary means. Here, a method for assessing reliability of such visualizations is developed. It measures how accurately the location of a data point in high-dimensional hierarchy tree can be inferred from a tree based on the low-dimensional visualization. The criterion can be used in point-wise fashion, allowing visual assessment of results, or as average values, for comparing visualizations. Use of the criterion is demonstrated on handwritten digits data, comparing visualizations by three dimension reduction methods.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-26.pdf,2010,100.0,"Reliability of dimension reduction visualizations of hierarchical structures Dimension reduction can produce visualizations of hierarchical structures, like those produced by cluster analysis. So far, reliability of such visualizations has only been assessed with rudimentary means. Here, a method for assessing reliability of such visualizations is developed. It measures how accurately the location of a data point in high-dimensional hierarchy tree can be inferred from a tree based on the low-dimensional visualization. The criterion can be used in point-wise fashion, allowing visual assessment of results, or as average values, for comparing visualizations. Use of the criterion is demonstrated on handwritten digits data, comparing visualizations by three dimension reduction methods."
Time Series Input Selection using Multiple Kernel Learning,"Loris Foresti, Devis Tuia, Vadim Timonin, Mikhail Kanevski",1 - Institute of Geomatics and Analysis of Risk University of Lausanne Amphipôle University of Lausanne 1015 Lausanne Switzerland,"In this paper we study the relevance of multiple kernel learning (MKL) for the automatic selection of time series inputs. Recently, MKL has gained great attention in the machine learning community due to its flexibility in modelling complex patterns and performing feature selection. In general, MKL constructs the kernel as a weighted linear combination of basis kernels, exploiting different sources of information. An efficient algorithm wrapping a Support Vector Regression model for optimizing the MKL weights, named SimpleMKL, is used for the analysis. In this sense, MKL performs feature selection by discarding inputs/kernels with low or null weights. The approach proposed is tested with simulated linear and nonlinear time series (AutoRegressive, Henon and Lorenz series).",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-28.pdf,2010,81.03448275862068,"Time Series Input Selection using Multiple Kernel Learning In this paper we study the relevance of multiple kernel learning (MKL) for the automatic selection of time series inputs. Recently, MKL has gained great attention in the machine learning community due to its flexibility in modelling complex patterns and performing feature selection. In general, MKL constructs the kernel as a weighted linear combination of basis kernels, exploiting different sources of information. An efficient algorithm wrapping a Support Vector Regression model for optimizing the MKL weights, named SimpleMKL, is used for the analysis. In this sense, MKL performs feature selection by discarding inputs/kernels with low or null weights. The approach proposed is tested with simulated linear and nonlinear time series (AutoRegressive, Henon and Lorenz series)."
Self Organizing Star (SOS) for health monitoring,"E Côme, M Cottrell, M Verleysen, J Lacaille","1 - Université Paris I SAMOS-MATISSE UMR CNRS 90 rue de Tolbiac 8174, F-75634 Paris Cedex 13 France
3 - Machine Learning Group Place du levant 3 Université Catholique de Louvain 1348 Louvain-La-Neuve -Belgium 3-Snecma
4 - Rond-Point René Ravaud-Réau 77550 Moissy-Cramayel CEDEX France","Self Organizing Maps (SOM) have been successfully applied in a lot of real world hard problems since their apparition. In this paper we present new topologie for SOM based on a planar graph. The design of a specific graph to encode prior information on the dataset topology is the central question addressed in this paper. In this context, star-shaped graphs are advocated for health monitoring applications, leading to a new kind of SOM that we denote by Self Organizing Star (SOS). Experiments using aircraft engine measurements show that SOS lead to meaningful and natural dataset representation.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-29.pdf,2010,100.0,"Self Organizing Star (SOS) for health monitoring Self Organizing Maps (SOM) have been successfully applied in a lot of real world hard problems since their apparition. In this paper we present new topologie for SOM based on a planar graph. The design of a specific graph to encode prior information on the dataset topology is the central question addressed in this paper. In this context, star-shaped graphs are advocated for health monitoring applications, leading to a new kind of SOM that we denote by Self Organizing Star (SOS). Experiments using aircraft engine measurements show that SOS lead to meaningful and natural dataset representation."
Machine Learning Techniques based on Random Projections,"Yoan Miche, Benjamin Schrauwen, Amaury Lendasse","1 - Lab Institut National Polytechnique de Grenoble -Gipsa 961 rue de la Houille Blanche BP46, 38402 Grenoble France
2 - School of Science and Technology -Dept. of Information and Computer Science Aalto University P.O. Box 15400 FI-00076 Aalto Finland
3 - Ghent University -Electronics
4 - Sint Pietersnieuwstraat 41 9000 Ghent -Belgium","This paper presents a short introduction to the Reservoir Computing and Extreme Learning Machine main ideas and developments. While both methods make use of Neural Networks and Random Projections, Reservoir Computing allows the network to have a recurrent structure, while the Extreme Learning Machine is a Feedforward neural network only. Some state of the art techniques are briefly presented and this special session papers are finally briefly described, in the terms of this introductory paper.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-3.pdf,2010,100.0,"Machine Learning Techniques based on Random Projections This paper presents a short introduction to the Reservoir Computing and Extreme Learning Machine main ideas and developments. While both methods make use of Neural Networks and Random Projections, Reservoir Computing allows the network to have a recurrent structure, while the Extreme Learning Machine is a Feedforward neural network only. Some state of the art techniques are briefly presented and this special session papers are finally briefly described, in the terms of this introductory paper."
An automated SOM clustering based on data topology,"Kadim Taşdemir, Pavel Milenov","1 - European Commission Joint Research Centre
2 - Institute for the Protection and Security of the Citizen (IPSC) Monitoring Agricultural Resources (MARS) Unit Via E. Fermi 2749 TP266, 21027 Ispra, VA Italy","Self-organizing maps are powerful for cluster extraction due to their ability of obtaining a topologically ordered and adaptive vector quantization of data. Thanks to lower-dimensional representation of highdimensional data on SOM lattice, clustering is often done interactively from informative SOM visualizations. Yet large volumes of today's data sets necessitate to have automated methods that are as successful as interactive ones for fast and accurate knowledge discovery. An automated SOM clustering, based on hierarchical clustering of a topology representing graph, is proposed here. Applications on several data sets indicate that the proposed method can be successfully used for automated partitioning.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-31.pdf,2010,100.0,"An automated SOM clustering based on data topology Self-organizing maps are powerful for cluster extraction due to their ability of obtaining a topologically ordered and adaptive vector quantization of data. Thanks to lower-dimensional representation of highdimensional data on SOM lattice, clustering is often done interactively from informative SOM visualizations. Yet large volumes of today's data sets necessitate to have automated methods that are as successful as interactive ones for fast and accurate knowledge discovery. An automated SOM clustering, based on hierarchical clustering of a topology representing graph, is proposed here. Applications on several data sets indicate that the proposed method can be successfully used for automated partitioning."
A randomized algorithm for spectral clustering,"Nicola Rebagliati, Alessandro Verri",1 - Dipartimento di Informatica e Scienze dell'Informazione Università di Genova Via Dodecaneso 36 16146 Genoa Italy,"Spectral Clustering has reached a wide level of diffusion among unsupervised learning applications. Despite its practical success we believe that for a correct usage one has to face a difficult problem: given a target number of classes K the optimal K-dimensional subspace is not necessarily spanned by the first K eigenvectors of the graph Normalized Laplacian. The contribution of this paper is twofold. First, we show a bound for choosing a correct number of eigenvectors. Second, we propose a randomized spectral algorithm able to find a clustering solution. We show the efficacy of the algorithm with experiments on real world graphs. Our proposal is a scheme that naturally extends the current usage of Spectral Clustering.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-32.pdf,2010,100.0,"A randomized algorithm for spectral clustering Spectral Clustering has reached a wide level of diffusion among unsupervised learning applications. Despite its practical success we believe that for a correct usage one has to face a difficult problem: given a target number of classes K the optimal K-dimensional subspace is not necessarily spanned by the first K eigenvectors of the graph Normalized Laplacian. The contribution of this paper is twofold. First, we show a bound for choosing a correct number of eigenvectors. Second, we propose a randomized spectral algorithm able to find a clustering solution. We show the efficacy of the algorithm with experiments on real world graphs. Our proposal is a scheme that naturally extends the current usage of Spectral Clustering."
k-NN behavior with set-valued attributes,"Mabel González, Yanet Rodríguez","1 - Universidad Central de Las Villas -Computer Science Department Carretera a Camajuaní km 5 ½ Santa Clara, Villa Clara Cuba","This paper addresses the problem of dealing with set-valued attributes in the lazy learning context. This type of attribute is present in various domains, yet the instance-based learning tools do not provide a representation for them. To solve this problem, we present a proposal for the treatment of the sets in the context of the k-NN algorithm through an extension to HEOM distance. Experiments using various data sets show the feasibility of this option. * WEKA is a Java-written open source. It is available at http://www.cs.waikato.ac.nz/˜ml/weka/ under the GNU General Public License.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-33.pdf,2010,88.60759493670886,"k-NN behavior with set-valued attributes This paper addresses the problem of dealing with set-valued attributes in the lazy learning context. This type of attribute is present in various domains, yet the instance-based learning tools do not provide a representation for them. To solve this problem, we present a proposal for the treatment of the sets in the context of the k-NN algorithm through an extension to HEOM distance. Experiments using various data sets show the feasibility of this option. * WEKA is a Java-written open source. It is available at http://www.cs.waikato.ac.nz/˜ml/weka/ under the GNU General Public License."
"Adaptive learning rate control for ""neural gas principal component analysis""","Wolfram Schenck, Ralph Welsch, Alexander Kaiser, Ralf Möller",1 - Computer Engineering Group -Faculty of Technology Bielefeld University POB 100131 D-33501 Bielefeld Germany,"We propose a novel algorithm for adaptive learning rate control for Gaussian mixture models of the NGPCA type. The core idea is to introduce a unit-specific learning rate which is adjusted automatically depending on the match between the local principal component analysis of each unit (interpreted as Gaussian distribution) and the empirical distribution within the unit's data partition. In contrast to fixed annealing schemes for the learning rate, the novel algorithm is applicable to real online learning. Two experimental studies are presented which demonstrate this important property and the general performance of this algorithm.",Mixture and generative models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-34.pdf,2010,100.0,"Adaptive learning rate control for ""neural gas principal component analysis"" We propose a novel algorithm for adaptive learning rate control for Gaussian mixture models of the NGPCA type. The core idea is to introduce a unit-specific learning rate which is adjusted automatically depending on the match between the local principal component analysis of each unit (interpreted as Gaussian distribution) and the empirical distribution within the unit's data partition. In contrast to fixed annealing schemes for the learning rate, the novel algorithm is applicable to real online learning. Two experimental studies are presented which demonstrate this important property and the general performance of this algorithm."
The Application of Gaussian Processes in the Prediction of Percutaneous Absorption for Mammalian and synthetic Membranes,"Yi Sun, Gary Moss, Maria Prapopoulou, Rod Adams, Marc Brown, Neil Davey","1 - -Science and Technology Research Institute University of Hertfordshire UK
2 - School of Pharmacy University of Hertfordshire UK","Improving prediction of the skin permeability coefficient is a difficult problem, and an important issue with the increasing use of skin patches as a means of drug delivery. In this work, we apply Gaussian Processes (GPs) with five different covariance functions to predict the permeability coefficients of human, pig, rodent and silastic membranes. We obtain a considerable improvement over quantitative structure-activity relationship (QSARs) predictors. The GPs with Matérn and neural network covariance functions give the best performance in this work. We find that five compound features applied to human, pig and rodent membranes cannot represent the main characteristics of the silastic dataset. 
 PROBLEM DOMAIN Predicting percutaneous absorption accurately has proven to be a major challenge and one which has substantial implications for pharmaceutical and cos-457",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-35.pdf,2010,91.66666666666666,"The Application of Gaussian Processes in the Prediction of Percutaneous Absorption for Mammalian and synthetic Membranes Improving prediction of the skin permeability coefficient is a difficult problem, and an important issue with the increasing use of skin patches as a means of drug delivery. In this work, we apply Gaussian Processes (GPs) with five different covariance functions to predict the permeability coefficients of human, pig, rodent and silastic membranes. We obtain a considerable improvement over quantitative structure-activity relationship (QSARs) predictors. The GPs with Matérn and neural network covariance functions give the best performance in this work. We find that five compound features applied to human, pig and rodent membranes cannot represent the main characteristics of the silastic dataset. 
 PROBLEM DOMAIN Predicting percutaneous absorption accurately has proven to be a major challenge and one which has substantial implications for pharmaceutical and cos-457"
A Markovian Characterization of Redundancy in Echo State Networks by PCA,"Claudio Gallicchio, Alessio Micheli","1 - Department of Computer Science University of Pisa Largo B. Pontecorvo
2 - 56127 Italy","Richness of dynamics is a desirable feature of Echo State Networks (ESNs) limited by a known high redundancy of state units activations. We show how this feature is mainly influenced by the Markovian state space organization of ESNs through a Principal Component Analysis (PCA) of the reservoir space. Relevances of principal components are coherent with Markovianity, whose role is further enlightened by investigating the strong relation among the suffix elements of the input sequence and the most relevant directions of variability in the state space.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-36.pdf,2010,68.05555555555556,"A Markovian Characterization of Redundancy in Echo State Networks by PCA Richness of dynamics is a desirable feature of Echo State Networks (ESNs) limited by a known high redundancy of state units activations. We show how this feature is mainly influenced by the Markovian state space organization of ESNs through a Principal Component Analysis (PCA) of the reservoir space. Relevances of principal components are coherent with Markovianity, whose role is further enlightened by investigating the strong relation among the suffix elements of the input sequence and the most relevant directions of variability in the state space."
Neural competition for motion segmentation,"Jan Steffen, Michael Pardowitz, Jochen Steil, Helge Ritter","1 - Faculty of Technology Neuroinformatics Group Bielefeld University Germany
2 - Research Institute for Cognition and Robotics (CoR-Lab) Bielefeld Univ Germany","We present a system for sensory classification and segmentation of motion trajectories. It consists of a combination of manifolds from Unsupervised Kernel Regression (UKR) and the recurrent neural Competitive Layer Model (CLM). The UKR manifolds hold learned representations of a set of candidate motions and the CLM dynamics, working on features defined in the UKR domain, realises the segmentation of observed trajectory data according to the competing candidates. The evaluation on trajectories describing four different letters yields improved classification results compared to our previous, pure manifold approach.",Motion estimation and segmentation,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-39.pdf,2010,100.0,"Neural competition for motion segmentation We present a system for sensory classification and segmentation of motion trajectories. It consists of a combination of manifolds from Unsupervised Kernel Regression (UKR) and the recurrent neural Competitive Layer Model (CLM). The UKR manifolds hold learned representations of a set of candidate motions and the CLM dynamics, working on features defined in the UKR domain, realises the segmentation of observed trajectory data according to the competing candidates. The evaluation on trajectories describing four different letters yields improved classification results compared to our previous, pure manifold approach."
"Recent Advances in Nonlinear Dimensionality Reduction, Manifold and Topological Learning","Axel Wismüller, Michel Verleysen, Michael Aupetit, John Lee","1 - Depts. of Radiology and Biomedical Engineering University of Rochester 601 Elmwood Avenue 14642-8648 Rochester NY USA
2 - Machine Learning Group Université catholique de Louvain Place du Levant 3 B-1348 Louvain-la-Neuve Belgium
3 - Dept. of Molecular Imaging and Experimental Radiotherapy Université catholique de Louvain Avenue Hippocrate 55 B-1200 Bruxelles Belgium
4 - Département Analyse Surveillance Environnement BP 12 91680 Bruyères-le-Châtel France","The ever-growing amount of data stored in digital databases raises the question of how to organize and extract useful knowledge. This paper outlines some current developments in the domains of dimensionality reduction, manifold learning, and topological learning. Several aspects are dealt with, ranging from novel algorithmic approaches to their realworld applications. The issue of quality assessment is also considered and progress in quantitive as well as visual crieria is reported.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-4.pdf,2010,100.0,"Recent Advances in Nonlinear Dimensionality Reduction, Manifold and Topological Learning The ever-growing amount of data stored in digital databases raises the question of how to organize and extract useful knowledge. This paper outlines some current developments in the domains of dimensionality reduction, manifold learning, and topological learning. Several aspects are dealt with, ranging from novel algorithmic approaches to their realworld applications. The issue of quality assessment is also considered and progress in quantitive as well as visual crieria is reported."
Geometric Models with Co-occurrence Groups,"Joan Bruna, Stéphane Mallat","1 - Ecole Polytechnique -CMAP Route de Saclay 91128 Palaiseau France
3 - Paul Vaillant Couturier 1-Zoran France 8/16 92240 Malakoff France",A geometric model of sparse signal representations is introduced for classes of signals. It is computed by optimizing co-occurrence groups with a maximum likelihood estimate calculated with a Bernoulli mixture model. Applications to face image compression and MNIST digit classification illustrate the applicability of this model.,Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-43.pdf,2010,69.04761904761905,Geometric Models with Co-occurrence Groups A geometric model of sparse signal representations is introduced for classes of signals. It is computed by optimizing co-occurrence groups with a maximum likelihood estimate calculated with a Bernoulli mixture model. Applications to face image compression and MNIST digit classification illustrate the applicability of this model.
Kernel Generative Topographic Mapping,"Iván Olier, Alfredo Vellido, Jesús Giraldo","1 - Institut de Neurosciènces
2 - Departament de Llenguatges i Sistemes Informatics Universitat Politècnica de Catalunya C/. Jordi Girona 1-3 08034 Edifici Omega, Barcelona CP Spain
4 - Unitat de Bioestadística Universitat Autònoma de Barcelona Edifici M -CP Bellaterra (Barcelona) 08193 Spain","A kernel version of Generative Topographic Mapping, a model of the manifold learning family, is defined in this paper. Its ability to adequately model non-i.i.d. data is illustrated in a problem concerning the identification of protein subfamilies from protein sequences.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-94.pdf,2010,75.67567567567568,"Kernel Generative Topographic Mapping A kernel version of Generative Topographic Mapping, a model of the manifold learning family, is defined in this paper. Its ability to adequately model non-i.i.d. data is illustrated in a problem concerning the identification of protein subfamilies from protein sequences."
Segmentation of EMG time series using a variational Bayesian approach for the robust estimation of cortical silent periods,"Iván Olier, Julià Amengual, Alfredo Vellido","1 - Institut de Neurociències Universitat Autónoma de Barcelona Edifici M M3/206, 08193 Despatx
2 - Bellaterra (Barcelona) Spain
3 - Neurodynamics Laboratory -Dept. of Psychiatry and Clinical Psychobiology Universitat de Barcelona 08035 Barcelona Spain
4 - Dept. de Llenguatges i Sistemes Informàtics -Universitat Politècnica de Catalunya Edifici Omega Campus Nord 08034 Barcelona Spain",A variational Bayesian formulation for a manifold-constrained Hidden Markov Model is used in this paper to segment a set of multivariate time series of electromyographic recordings corresponding to stroke patients and control subjects. An index of variability associated to this model is defined and applied to the robust detection of the silent period interval of the signal. The accuracy in the estimation of the duration of this interval is paramount to assess the rehabilitation of stroke patients.,Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-45.pdf,2010,100.0,Segmentation of EMG time series using a variational Bayesian approach for the robust estimation of cortical silent periods A variational Bayesian formulation for a manifold-constrained Hidden Markov Model is used in this paper to segment a set of multivariate time series of electromyographic recordings corresponding to stroke patients and control subjects. An index of variability associated to this model is defined and applied to the robust detection of the silent period interval of the signal. The accuracy in the estimation of the duration of this interval is paramount to assess the rehabilitation of stroke patients.
Programmable Triangular Neighborhood Functions of Kohonen Self-Organizing Maps Realized in CMOS Technology,"Rafał Długosz, Marta Kolasa, Witold Pedrycz","1 - Institute of Microtechnology Swiss Federal Institute of Technology in Lausanne Rue A.-L. Breguet 2 CH-2000 Neuchâtel Switzerland
2 - Institute of Electrical Engineering University of Technology and Life Sciences ul. Kaliskiego 7 85-791 Bydgoszcz Poland
3 - Department of Electrical and Computer Engineering University of Alberta
4 - ECERF Building T6G 2V4 Edmonton Canada","The paper presents a programmable triangular neighborhood function for application in low power transistor level implemented Kohonen self-organized maps (SOMs). Detailed simulations carried out for the software model of such network show that the triangular function forms a good approximation of the Gaussian function, while being implemented in a much easier way in hardware. The proposed circuit is very flexible and allows for easy adjustments of the slope of the function. It enables the asynchronous and fully parallel operation of all neurons in the network thus making it very fast. The proposed mechanism can be used in custom designed networks either in their analog or digital implementation. Due to the simple structure, the energy consumption per a single input pattern is low (120 pJ in case of the map of 16 x 16 neurons).",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-48.pdf,2010,62.264150943396224,"Programmable Triangular Neighborhood Functions of Kohonen Self-Organizing Maps Realized in CMOS Technology The paper presents a programmable triangular neighborhood function for application in low power transistor level implemented Kohonen self-organized maps (SOMs). Detailed simulations carried out for the software model of such network show that the triangular function forms a good approximation of the Gaussian function, while being implemented in a much easier way in hardware. The proposed circuit is very flexible and allows for easy adjustments of the slope of the function. It enables the asynchronous and fully parallel operation of all neurons in the network thus making it very fast. The proposed mechanism can be used in custom designed networks either in their analog or digital implementation. Due to the simple structure, the energy consumption per a single input pattern is low (120 pJ in case of the map of 16 x 16 neurons)."
Online Speaker Diarization with a Size-Monitored Growing Neural Gas Algorithm,"Jean-Louis Gutzwiller, Hervé Frezza-Buet, Olivier Pietquin","1 - SUPELEC -Metz Campus -IMS Research group
2 - Edouard Belin 57070 Metz FRANCE","This paper proposes a method for segmenting and clustering an audio flow on the basis of speaker turns. This process, also known as speaker diarization, is of major importance in multimedia indexation. Here, we propose to realize this process online and without any prior knowledge on the number of speakers. This is done thanks to a statistical modelling of speakers based on a size-monitored growing neural gas algorithm.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-49.pdf,2010,77.92207792207793,"Online Speaker Diarization with a Size-Monitored Growing Neural Gas Algorithm This paper proposes a method for segmenting and clustering an audio flow on the basis of speaker turns. This process, also known as speaker diarization, is of major importance in multimedia indexation. Here, we propose to realize this process online and without any prior knowledge on the number of speakers. This is done thanks to a statistical modelling of speakers based on a size-monitored growing neural gas algorithm."
Introduction to Computational Intelligence Business Applications,"Thiago Turchetti, Antônio Pádua Braga","1 - Vetta Group -Innovation Unit Alameda da Serra 400
2 - 7th floor -Nova Lima -MG 34000-000 Brazil
3 - Federal University of Minas Gerais -Dept of Electronics Engineering Av. Antônio Carlos Belo Horizonte -MG 6627, 31270-901 Brazil","Computational intelligence business applications have been developed since the early days of computing and are now commonly found in many aspects of modern society. This paper briefly surveys historic applications of computational intelligence in different business contexts. In addition, it describes this type of application from a business point of view, where computational intelligence is used as a source of competitive advantage. It concludes with an analysis of how organizations may create the proper environment and effectively use computational intelligence to improve their business.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-5.pdf,2010,100.0,"Introduction to Computational Intelligence Business Applications Computational intelligence business applications have been developed since the early days of computing and are now commonly found in many aspects of modern society. This paper briefly surveys historic applications of computational intelligence in different business contexts. In addition, it describes this type of application from a business point of view, where computational intelligence is used as a source of competitive advantage. It concludes with an analysis of how organizations may create the proper environment and effectively use computational intelligence to improve their business."
Financial Time Series Forecasting with Machine Learning Techniques: A Survey,"Bjoern Krollner, Bruce Vanstone, Gavin Finnie",1 - School of Information Technology Bond University Gold Coast Queensland Australia,"Stock index forecasting is vital for making informed investment decisions. This paper surveys recent literature in the domain of machine learning techniques and artificial intelligence used to forecast stock market movements. The publications are categorised according to the machine learning technique used, the forecasting timeframe, the input variables used, and the evaluation techniques employed. It is found that there is a consensus between researchers stressing the importance of stock index forecasting. Artificial Neural Networks (ANNs) are identified to be the dominant machine learning technique in this area. We conclude with possible future research directions.",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-50.pdf,2010,88.1578947368421,"Financial Time Series Forecasting with Machine Learning Techniques: A Survey Stock index forecasting is vital for making informed investment decisions. This paper surveys recent literature in the domain of machine learning techniques and artificial intelligence used to forecast stock market movements. The publications are categorised according to the machine learning technique used, the forecasting timeframe, the input variables used, and the evaluation techniques employed. It is found that there is a consensus between researchers stressing the importance of stock index forecasting. Artificial Neural Networks (ANNs) are identified to be the dominant machine learning technique in this area. We conclude with possible future research directions."
Autoregressive Independent Process Analysis with Missing Observations,Zoltán Szabó,1 - Department of Software Technology and Methodology Eötvös Loránd University Pázmány P. sétány 1/C H-1117 Budapest Hungary,"The goal of this paper is to search for independent multidimensional processes subject to missing and mixed observations. The corresponding cocktail-party problem has a number of successful applications, however, the case of missing observations has been worked out only for the simplest Independent Component Analysis (ICA) task, where the hidden processes (i) are one-dimensional, and (ii) signal generation in time is independent and identically distributed (i.i.d.). Here, the missing observation situation is extended to processes with (i) autoregressive (AR) dynamics and (ii) multidimensional driving sources. Performance of the solution method is illustrated by numerical examples.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-52.pdf,2010,81.15942028985508,"Autoregressive Independent Process Analysis with Missing Observations The goal of this paper is to search for independent multidimensional processes subject to missing and mixed observations. The corresponding cocktail-party problem has a number of successful applications, however, the case of missing observations has been worked out only for the simplest Independent Component Analysis (ICA) task, where the hidden processes (i) are one-dimensional, and (ii) signal generation in time is independent and identically distributed (i.i.d.). Here, the missing observation situation is extended to processes with (i) autoregressive (AR) dynamics and (ii) multidimensional driving sources. Performance of the solution method is illustrated by numerical examples."
Mapping without visualizing local default is nonsense,"Sylvain Lespinats, Michael Aupetit",1 - Multisensor Intelligence and Machine Learning Laboratory CEA LIST F-91191 Gif-sur-Yvette France,"High-dimensional data sets are often embedded in two-dimensional spaces so as to visualize neighborhood relationships. When the map is effective (i.e. when short distances are preserved) it is a powerful way to help an analyst to understand the data set. But, mappings most often show defaults and the user is then led astray. According to this notion, a mapping should not be considered when its overall quality is not good enough. Many imperfect mappings can however be exploited by informing the user of the nature and level of defaults. In this work, we propose to visualize local indices trustworthiness and continuity for that purpose. 
 Mappings When dealing with high-dimensional data the capacity to visualize the ""spatial organization"" is a powerful way to help an analyst to understand the data set. Its use provides a critical benefit for extracting information or can (for example) lead the user to the most suitable analysis method. This point is the main purpose of dimensionality reduction methods (also called mapping methods). Especially, Multi Dimensional Scaling (MDS) is the set of methods (including  [2, 3, 7, 8, 10] ) designed to embed data in a low-dimensional Euclidean space (the so called ""output space"") while preserving ""maximally"" the distances observed between data in the original space with a special attention to short distances. A main difference between methods can be found in the mean used to quantify the level of interest of each distance (that is to say, how much a given distance can be considered as ""short""). Using dimensionality reduction on a given dataset involves an underlying hypothesis: it assumes that data lies on (or close to) a low-dimensional submanifold of the original space. Following this line, the dimensionality of such a manifold is named ""intrinsic dimension"" of the dataset and should be chosen as the dimension of the output space. To limit the distortions Multidimensional scaling method unfolds the submanifold and delivers it on the output space.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-54.pdf,2010,100.0,"Mapping without visualizing local default is nonsense High-dimensional data sets are often embedded in two-dimensional spaces so as to visualize neighborhood relationships. When the map is effective (i.e. when short distances are preserved) it is a powerful way to help an analyst to understand the data set. But, mappings most often show defaults and the user is then led astray. According to this notion, a mapping should not be considered when its overall quality is not good enough. Many imperfect mappings can however be exploited by informing the user of the nature and level of defaults. In this work, we propose to visualize local indices trustworthiness and continuity for that purpose. 
 Mappings When dealing with high-dimensional data the capacity to visualize the ""spatial organization"" is a powerful way to help an analyst to understand the data set. Its use provides a critical benefit for extracting information or can (for example) lead the user to the most suitable analysis method. This point is the main purpose of dimensionality reduction methods (also called mapping methods). Especially, Multi Dimensional Scaling (MDS) is the set of methods (including  [2, 3, 7, 8, 10] ) designed to embed data in a low-dimensional Euclidean space (the so called ""output space"") while preserving ""maximally"" the distances observed between data in the original space with a special attention to short distances. A main difference between methods can be found in the mean used to quantify the level of interest of each distance (that is to say, how much a given distance can be considered as ""short""). Using dimensionality reduction on a given dataset involves an underlying hypothesis: it assumes that data lies on (or close to) a low-dimensional submanifold of the original space. Following this line, the dimensionality of such a manifold is named ""intrinsic dimension"" of the dataset and should be chosen as the dimension of the output space. To limit the distortions Multidimensional scaling method unfolds the submanifold and delivers it on the output space."
Combining Back-Propagation and Genetic Algorithms to Train Neural Networks for Start-Up Time Modeling in Combined Cycle Power Plants,"I Bertini, M De Felice, S Pizzuti","1 - ENEA (Italian Energy New Technology and sustainable Economic development Agency Via Anguillarese 301 00123 Rome Italy
3 - Department of Informatics and Automation University of Rome ``Roma Tre'' Via della Vasca Navale 79 00146 Rome Italy","This paper presents a neural networks based approach in order to estimate the start-up time of turbine based power plants. Neural networks are trained with a hybrid approach, indeed we combine the Back-Propagation (BP) algorithm and the Simple Genetic Algorithm (GA) in order to effectively train neural networks in such a way that the BP algorithm initializes a few individuals of the GA's population. Experiments have been performed over a big amount of data and results have shown a remarkable improvement in accuracy compared to the single traditional methods.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-55.pdf,2010,70.45454545454545,"Combining Back-Propagation and Genetic Algorithms to Train Neural Networks for Start-Up Time Modeling in Combined Cycle Power Plants This paper presents a neural networks based approach in order to estimate the start-up time of turbine based power plants. Neural networks are trained with a hybrid approach, indeed we combine the Back-Propagation (BP) algorithm and the Simple Genetic Algorithm (GA) in order to effectively train neural networks in such a way that the BP algorithm initializes a few individuals of the GA's population. Experiments have been performed over a big amount of data and results have shown a remarkable improvement in accuracy compared to the single traditional methods."
Using SVMs with randomised feature spaces: an extreme learning approach,"Benoît Frénay, Michel Verleysen",1 - ELEC/DICE -Place du Levant Université catholique de Louvain -Machine Learning Group EPL 1348 Louvain-la-Neuve Belgium,"Extreme learning machines are fast models which almost compare to standard SVMs in terms of accuracy, but are much faster. However, they optimise a sum of squared errors whereas SVMs are maximum-margin classifiers. This paper proposes to merge both approaches by defining a new kernel. This kernel is computed by the first layer of an extreme learning machine and used to train a SVM. Experiments show that this new kernel compares to the standard RBF kernel in terms of accuracy and is faster. Indeed, experiments show that the number of neurons of the ELM behind the randomised kernel does not need to be tuned and can be set to a sufficient value without altering the accuracy significantly.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-56.pdf,2010,100.0,"Using SVMs with randomised feature spaces: an extreme learning approach Extreme learning machines are fast models which almost compare to standard SVMs in terms of accuracy, but are much faster. However, they optimise a sum of squared errors whereas SVMs are maximum-margin classifiers. This paper proposes to merge both approaches by defining a new kernel. This kernel is computed by the first layer of an extreme learning machine and used to train a SVM. Experiments show that this new kernel compares to the standard RBF kernel in terms of accuracy and is faster. Indeed, experiments show that the number of neurons of the ELM behind the randomised kernel does not need to be tuned and can be set to a sufficient value without altering the accuracy significantly."
Learning Sparse Codes for Image Reconstruction,"Kai Labusch, Thomas Martinetz",1 - University of Lübeck -Institute for Neuro-and Bioinformatics Ratzeburger Allee 160 23538 Lübeck Germany,"We propose a new algorithm for the design of overcomplete dictionaries for sparse coding that generalizes the Sparse Coding Neural Gas (SCNG) algorithm such that it is not bound to a particular approximation method for the coefficients of the dictionary elements. In an application to image reconstruction, a dictionary that has been learned using this algorithm outperforms a dictionary that has been obtained from the widely-used K-SVD algorithm, an overcomplete Haar-wavelet dictionary and an overcomplete discrete cosine transformation (DCT). 1 a 0 is equal to the number of non-zero entries of a.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-57.pdf,2010,65.21739130434783,"Learning Sparse Codes for Image Reconstruction We propose a new algorithm for the design of overcomplete dictionaries for sparse coding that generalizes the Sparse Coding Neural Gas (SCNG) algorithm such that it is not bound to a particular approximation method for the coefficients of the dictionary elements. In an application to image reconstruction, a dictionary that has been learned using this algorithm outperforms a dictionary that has been obtained from the widely-used K-SVD algorithm, an overcomplete Haar-wavelet dictionary and an overcomplete discrete cosine transformation (DCT). 1 a 0 is equal to the number of non-zero entries of a."
Approximation of chemical reaction rates in turbulent combustion simulation,"Lars Große, Franz Joos","1 - Helmut-Schmidt-University University of the Federal Armed Forces Hamburg -Laboratory of Turbo Machinery -Hamburg D-22043, 85 Holstenhofweg Germany","It is essential to increase the efficiency of the commercially available combustion engines because of the limitations in fossil energy resources and environmental pollution Also the emission standards are a challenging aspect. If one succeeds in designing the combustion process, in particular the chemical reactions, it would be feasible to partly replace complex experiments by computer simulations. The suggestion made in this paper, is the use of artificial neuronal networks for approximation of complex chemistry in turbulent combustion applications. The use of complex chemistry is computationally expensive and limited to simple geometry, therefore it is replaced by trained ANNs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-58.pdf,2010,100.0,"Approximation of chemical reaction rates in turbulent combustion simulation It is essential to increase the efficiency of the commercially available combustion engines because of the limitations in fossil energy resources and environmental pollution Also the emission standards are a challenging aspect. If one succeeds in designing the combustion process, in particular the chemical reactions, it would be feasible to partly replace complex experiments by computer simulations. The suggestion made in this paper, is the use of artificial neuronal networks for approximation of complex chemistry in turbulent combustion applications. The use of complex chemistry is computationally expensive and limited to simple geometry, therefore it is replaced by trained ANNs."
Validation of Unsupervised Clustering Methods for Leaf Phenotype Screening,"Andreas Backhaus, Asuka Kuwabara, Andrew Fleming, Udo Seiffert","1 - Department of Animal and Plant Science University of Sheffield Sheffield United Kingdom
3 - Fraunhofer Institute for Factory Operation and Automation (IFF) 1-Biosystems Engineering Magdeburg Germany","The assessment of visible differences in leaf shape between plant species or mutants (phenotyping) plays a significant role in plant research. This paper investigates the application of unsupervised data clustering techniques for phenotype screening to find hidden common shape categories. A set of two wildtypes and seven mutations of Arabidopsis acted as a test case. K-Means, NG, GNG, SOM and ART2a were evaluated by classical validity indices and one index derived from the task at hand. K-Means showed the best results and a low agreement between classical validity measures and task constraints was found.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-59.pdf,2010,67.56756756756756,"Validation of Unsupervised Clustering Methods for Leaf Phenotype Screening The assessment of visible differences in leaf shape between plant species or mutants (phenotyping) plays a significant role in plant research. This paper investigates the application of unsupervised data clustering techniques for phenotype screening to find hidden common shape categories. A set of two wildtypes and seven mutations of Arabidopsis acted as a test case. K-Means, NG, GNG, SOM and ART2a were evaluated by classical validity indices and one index derived from the task at hand. K-Means showed the best results and a low agreement between classical validity measures and task constraints was found."
A Pseudoregression Formulation of Emphasized Soft Target Procedures for Classification Problems,"Soufiane El, Abdelouahid Lyhyaoui, Aníbal Figueiras Vidal","1 - Univ. Carlos III de Madrid -Dept. of Signal Processing and Communications Av. de la Universidad 30 Leganés, Madrid Spain
2 - Abdelmalek Essaâdi-ENSA of Tangier -Dept. of Telecoms and Electronics -LTI Lab. B.P. 1818 Univ Tanger Principale Tangier Morocco","Replacing a hard decision by a soft targets version including an attentional mechanism provides performance advantage and flexibility to solve classification tasks. In this paper, we modify the standard emphasized soft target method by proposing two new ideas, to avoid unnecessary updating and inappropriate definition of soft targets, in order to increase designs performance. Experimental results using MLPs show the effectiveness of this approach compared with the standard ST and other methods.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-60.pdf,2010,84.21052631578947,"A Pseudoregression Formulation of Emphasized Soft Target Procedures for Classification Problems Replacing a hard decision by a soft targets version including an attentional mechanism provides performance advantage and flexibility to solve classification tasks. In this paper, we modify the standard emphasized soft target method by proposing two new ideas, to avoid unnecessary updating and inappropriate definition of soft targets, in order to increase designs performance. Experimental results using MLPs show the effectiveness of this approach compared with the standard ST and other methods."
Modelling the McGurk effect,"Ioana Sporea, Andre Gruning",1 - Department of Computing Department of Computing Faculty of Engineering and Physical Sciences University of Surrey University of Surrey GU2 7XH Guildford Surrey United Kingdom,"The current study investigates the McGurk effect by modelling it with neural networks. The simulations are designed to test the two main theories about the moment at which the auditory-visual integration happens. To further analyze the causes behind the McGurk illusion, the neural network that best models the effect is used to simulate the influence of language and the frequency of phonemes on auditory-visual speech perception, using two phonetic distribution from English and Japanese, with different empirical results in the McGurk effect.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-61.pdf,2010,100.0,"Modelling the McGurk effect The current study investigates the McGurk effect by modelling it with neural networks. The simulations are designed to test the two main theories about the moment at which the auditory-visual integration happens. To further analyze the causes behind the McGurk illusion, the neural network that best models the effect is used to simulate the influence of language and the frequency of phonemes on auditory-visual speech perception, using two phonetic distribution from English and Japanese, with different empirical results in the McGurk effect."
Neural Oscillations allow for Selective Inhibition -New Perspective on the Role of Cortical Gamma Oscillations,Thomas Burwick,"1 - Frankfurt Institute for Advanced Studies (FIAS) Johann Wolfgang Goethe-Universität Ruth Moufang-Str. 1, Thinking Networks AG Markt 45-47 60438, 52062 Frankfurt am Main, Aachen Germany, Germany","A pattern recognition mechanism is proposed that uses inhibitory oscillations as fundamental ingredient. The mechanism realizes selective inhibition that could not be reached without oscillations. It uses couplings that are motivated by physiology. Since inhibitory oscillations are key to the generation of cortical gamma oscillation, the proposed mechanism may also shed new light on the gamma oscillation functionality.",Physiology and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-63.pdf,2010,72.39819004524887,"Neural Oscillations allow for Selective Inhibition -New Perspective on the Role of Cortical Gamma Oscillations A pattern recognition mechanism is proposed that uses inhibitory oscillations as fundamental ingredient. The mechanism realizes selective inhibition that could not be reached without oscillations. It uses couplings that are motivated by physiology. Since inhibitory oscillations are key to the generation of cortical gamma oscillation, the proposed mechanism may also shed new light on the gamma oscillation functionality."
Fast and Good Initialization of RBF Networks,"D Bauer, J Sjöberg","1 - Department Mobility Austrian Institute of Technology Giengg.2 A1210 Vienna Austria
2 - Signals & Systems Department Chalmers University Gothenburg Sweden",In this paper a new method for fast initialization of radial basis function (RBF) networks is proposed. A grid of possible positions and widths for the basis functions is dened and new nodes to the RBF network are introduced one at the time. The denition of the grid points is done in a specic way which leads to algorithms which are computationally inexpensive due to the fact that intermediate results can be reused and do not need to be re-computed. If the grid is dense one obtains estimators close to estimators resulting from an exhaustive search for the initial parameters which leads to a lower risk to be caught in local minima in the minimization which follows. The usefulness of the approach is demonstrated in a simulation example.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-64.pdf,2010,75.0,Fast and Good Initialization of RBF Networks In this paper a new method for fast initialization of radial basis function (RBF) networks is proposed. A grid of possible positions and widths for the basis functions is dened and new nodes to the RBF network are introduced one at the time. The denition of the grid points is done in a specic way which leads to algorithms which are computationally inexpensive due to the fact that intermediate results can be reused and do not need to be re-computed. If the grid is dense one obtains estimators close to estimators resulting from an exhaustive search for the initial parameters which leads to a lower risk to be caught in local minima in the minimization which follows. The usefulness of the approach is demonstrated in a simulation example.
Model Learning from Weights by Adaptive Enhanced Probabilistic Convergent Network,"P Lorrentz, W Howells, K Mcdonald-Maier","1 - Department of Electronics University of Kent CT2 7NT Canterbury, Kent UK Tel
2 - Department of Electronics University of Kent CT2 7NT Canterbury, Kent UK
3 - Department of Computer Science University of Essex Wivenhoe Park CO4 3SQ Colchester UK","Current weightless classifiers require historical data to model a system and make prediction about a system successfully. Historical data either is not always available or does not take a recent system modification into consideration. For this reason an adaptive filter is designed, which when employed with a weightless classifier enables system model, difficult to characterise system model, and system output prediction, successfully.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-65.pdf,2010,100.0,"Model Learning from Weights by Adaptive Enhanced Probabilistic Convergent Network Current weightless classifiers require historical data to model a system and make prediction about a system successfully. Historical data either is not always available or does not take a recent system modification into consideration. For this reason an adaptive filter is designed, which when employed with a weightless classifier enables system model, difficult to characterise system model, and system output prediction, successfully."
Sparse representation of data,"Thomas Villmann, Frank-Michael Schleif, Barbara Hammer","1 - University of Applied Sciences Mittweida Germany
2 - Bielefeld University Germany","The amount of electronic data available today as well as its dimensionality and complexity increases rapidly in many scientific areas including biology, (bio-)chemistry, medicine, physics and its application fields like robotics, bioinformatics or multimedia technologies. Many of these data sets are very complex but have also a simple inherent structure which allows an appropriate sparse representation and modeling of such data with less or no information loss. Advanced methods are needed to extract these inherent but hidden information. Sparsity can be observed at different levels: sparse representation of data points using e.g. dimensionality reduction for efficient data storage, sparse representation of full data sets using e.g. prototypes to achieve compact models for lifelong learning and sparse models of the underlying data structure using sparse encoding techniques. One main goal is to achieve a human-interpretable representation of the essential information. Sparse representations account for the ubiquitous problem that humans have to deal with ever increasing and inherently unlimited information by means of limited resources such as limited time, memory, or perception abilities. Starting with the seminal paper of Olshausen&Field  [40]  researchers recognized that sparsity can be used as a fundamental principle to arrive at very efficient information processing models for huge and complex data such as observed e.g. in the visual cortex. Nowadays, sparse models include diverse methods such as relevance learning in prototype based representations, sparse coding neural gas, factor analysis methods, latent semantic indexing, sparse Bayesian networks, relevance vector machines and other. This tutorial paper reviews recent developments in the field.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-7.pdf,2010,100.0,"Sparse representation of data The amount of electronic data available today as well as its dimensionality and complexity increases rapidly in many scientific areas including biology, (bio-)chemistry, medicine, physics and its application fields like robotics, bioinformatics or multimedia technologies. Many of these data sets are very complex but have also a simple inherent structure which allows an appropriate sparse representation and modeling of such data with less or no information loss. Advanced methods are needed to extract these inherent but hidden information. Sparsity can be observed at different levels: sparse representation of data points using e.g. dimensionality reduction for efficient data storage, sparse representation of full data sets using e.g. prototypes to achieve compact models for lifelong learning and sparse models of the underlying data structure using sparse encoding techniques. One main goal is to achieve a human-interpretable representation of the essential information. Sparse representations account for the ubiquitous problem that humans have to deal with ever increasing and inherently unlimited information by means of limited resources such as limited time, memory, or perception abilities. Starting with the seminal paper of Olshausen&Field  [40]  researchers recognized that sparsity can be used as a fundamental principle to arrive at very efficient information processing models for huge and complex data such as observed e.g. in the visual cortex. Nowadays, sparse models include diverse methods such as relevance learning in prototype based representations, sparse coding neural gas, factor analysis methods, latent semantic indexing, sparse Bayesian networks, relevance vector machines and other. This tutorial paper reviews recent developments in the field."
Exploratory Observation Machine (XOM) with Kullback-Leibler Divergence for Dimensionality Reduction and Visualization,"Kerstin Bunte, Barbara Hammer, Thomas Villmann, Michael Biehl, Axel Wismüller","1 - Depts. of Radiology and Biomedical Engineering University of Rochester 601 Elmwood Avenue 14642-8648 Rochester NY U.S.A
2 - Institute for Mathematics and Computer Science University of Groningen -Johann Bernoulli 9700 AK Groningen The Netherlands
3 - Bielefeld University CITEC Universitätsstraße 23 33615 Bielefeld -Germany
4 - Department of MPI Technikumplatz 17 University of Applied Sciences Mittweida 09648 Mittweida Germany","We present an extension of the Exploratory Observation Machine (XOM) for structure-preserving dimensionality reduction. Based on minimizing the Kullback-Leibler divergence of neighborhood functions in data and image spaces, this Neighbor Embedding XOM (NE-XOM) creates a link between fast sequential online learning known from topologypreserving mappings and principled direct divergence optimization approaches. We quantitatively evaluate our method on real world data using multiple embedding quality measures. In this comparison, NE-XOM performs as a competitive trade-off between high embedding quality and low computational expense, which motivates its further use in real-world settings throughout science and engineering.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-71.pdf,2010,100.0,"Exploratory Observation Machine (XOM) with Kullback-Leibler Divergence for Dimensionality Reduction and Visualization We present an extension of the Exploratory Observation Machine (XOM) for structure-preserving dimensionality reduction. Based on minimizing the Kullback-Leibler divergence of neighborhood functions in data and image spaces, this Neighbor Embedding XOM (NE-XOM) creates a link between fast sequential online learning known from topologypreserving mappings and principled direct divergence optimization approaches. We quantitatively evaluate our method on real world data using multiple embedding quality measures. In this comparison, NE-XOM performs as a competitive trade-off between high embedding quality and low computational expense, which motivates its further use in real-world settings throughout science and engineering."
Relevance learning in generative topographic maps,"Andrej Gisbrecht, Barbara Hammer",1 - Department of Computer Science Clausthal University of Technology D-38678 Clausthal-Zellerfeld Germany,"The generative topographic map (GTM) provides a flexible statistical model for unsupervised data inspection and topographic mapping. However, it shares the property of most unsupervised tools that noise in the data cannot be recognized as such and, in consequence, is visualized in the map. The framework of relevance learning or learning metrics as introduced in [4, 6] offers an elegant way to shape the metric according to auxiliary information at hand such that only those aspects are displayed in distance-based approaches which are relevant for a given classification task. Here we introduce the concept of relevance learning into GTM such that the metric is shaped according to auxiliary class labels. Relying on the prototype-based nature of GTM, several efficient realizations of this paradigm are developed and compared on a couple of benchmarks.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-72.pdf,2010,100.0,"Relevance learning in generative topographic maps The generative topographic map (GTM) provides a flexible statistical model for unsupervised data inspection and topographic mapping. However, it shares the property of most unsupervised tools that noise in the data cannot be recognized as such and, in consequence, is visualized in the map. The framework of relevance learning or learning metrics as introduced in [4, 6] offers an elegant way to shape the metric according to auxiliary information at hand such that only those aspects are displayed in distance-based approaches which are relevant for a given classification task. Here we introduce the concept of relevance learning into GTM such that the metric is shaped according to auxiliary class labels. Relying on the prototype-based nature of GTM, several efficient realizations of this paradigm are developed and compared on a couple of benchmarks."
Efficient online learning of a non-negative sparse autoencoder,"Andre Lemme, R Reinhart, Jochen Steil",1 - Research Institute for Cognition and Robotics (CoR-Lab) Bielefeld University,We introduce an efficient online learning mechanism for nonnegative sparse coding in autoencoder neural networks. In this paper we compare the novel method to the batch algorithm non-negative matrix factorization with and without sparseness constraint. We show that the efficient autoencoder yields to better sparseness and lower reconstruction errors than the batch algorithms on the MNIST benchmark dataset.,Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-73.pdf,2010,100.0,Efficient online learning of a non-negative sparse autoencoder We introduce an efficient online learning mechanism for nonnegative sparse coding in autoencoder neural networks. In this paper we compare the novel method to the batch algorithm non-negative matrix factorization with and without sparseness constraint. We show that the efficient autoencoder yields to better sparseness and lower reconstruction errors than the batch algorithms on the MNIST benchmark dataset.
Maximal Discrepancy for Support Vector Machines,"Davide Anguita, Alessandro Ghio, Sandro Ridella",1 - University of Genova -Dept. of Biophysical and Electronic Engineering Via Opera Pia 11A -I-16145 Genova Italy,"Several theoretical methods have been developed in the past years to evaluate the generalization ability of a classifier: they provide extremely useful insights on the learning phenomena, but are not as effective in giving good generalization estimates in practice. We focus in this work on the application of the Maximal Discrepancy method to the Support Vector Machine for computing an upper bound of its generalization bias. 
 The Maximal Discrepancy of a Classifier Let D l = {(x 1 , y 1 ), ...., (x l , y l )} be a set of i.i.d. patterns, with x i ∈ R n and y i ∈ Y = {−1, +1}, where the data are obtained from the unknown distribution P (x, y). A prediction rule is a function f : R n → Y f ⊆ R, selected from a set F, which can be applied to D l to compute its empirical error rate ν(f ) = Usually, in classification tasks, we are interested in a hard loss function, which counts the number of misclassified samples: Unfortunately, the use of a hard loss function makes the problem of finding the optimal f computationally hard. Therefore, the conventional SVM algorithm",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-74.pdf,2010,100.0,"Maximal Discrepancy for Support Vector Machines Several theoretical methods have been developed in the past years to evaluate the generalization ability of a classifier: they provide extremely useful insights on the learning phenomena, but are not as effective in giving good generalization estimates in practice. We focus in this work on the application of the Maximal Discrepancy method to the Support Vector Machine for computing an upper bound of its generalization bias. 
 The Maximal Discrepancy of a Classifier Let D l = {(x 1 , y 1 ), ...., (x l , y l )} be a set of i.i.d. patterns, with x i ∈ R n and y i ∈ Y = {−1, +1}, where the data are obtained from the unknown distribution P (x, y). A prediction rule is a function f : R n → Y f ⊆ R, selected from a set F, which can be applied to D l to compute its empirical error rate ν(f ) = Usually, in classification tasks, we are interested in a hard loss function, which counts the number of misclassified samples: Unfortunately, the use of a hard loss function makes the problem of finding the optimal f computationally hard. Therefore, the conventional SVM algorithm"
Adaptive Velocity Tuning for Visual Motion Estimation,"Volker Willert, Julian Eggert","1 - Control Theory and Robotics Lab Landgraf Darmstadt University of Technology Institute of Automatic Control Georg-Str. 4 D-64283 Darmstadt Germany
2 - Honda Research Institute Europe GmbH Carl-Legien-Str. 30 D-63073 Offenbach Germany","In the brain, both neural processing dynamics as well as the perceptual interpretation of a stimulus can depend on sensory history. The underlying principle is a sensory adaptation to the statistics of the input collected over a certain amount of time, allowing the system to tune its detectors, e.g. by improving the sampling of the input space. Here we show how a generative formulation for the problem of visual motion estimation leads to an online adaptation of velocity tuning that is compatible with physiological sensory adaptation and observed perceptual effects.",Motion estimation and segmentation,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-76.pdf,2010,83.01886792452831,"Adaptive Velocity Tuning for Visual Motion Estimation In the brain, both neural processing dynamics as well as the perceptual interpretation of a stimulus can depend on sensory history. The underlying principle is a sensory adaptation to the statistics of the input collected over a certain amount of time, allowing the system to tune its detectors, e.g. by improving the sampling of the input space. Here we show how a generative formulation for the problem of visual motion estimation leads to an online adaptation of velocity tuning that is compatible with physiological sensory adaptation and observed perceptual effects."
Modeling contextualized textual knowledge as a Long-Term Working Memory,"Mauro Mazzieri, Sara Topi, Aldo Dragoni, Germano Vallesi",1 - Management and Automation Engineering via Brecce Bianche 22 Univiversità Politecnica delle Marche Dept. of Computer 60100 Ancona Italy,"A knowledge management system is more than an archive of textual documents; it provides context information, allowing to know which documents where used by people with a common goal. In the hypothesis that a set of textual documents with a common context can be assimilated to the long term memory of a human expert executor, we can use on them mining techniques inspired by the mechanic of human comprehension in expert domains. Text mining techniques for KM task can use a model of the long-term memory to extract meaningful keywords from the documents. The model acts as a dynamic and non-stationary dimensionality reduction strategy, allowing the clustering of context documents according to keyword presence, the classification of external documents according to local criteria, and a better understanding of document content and relatedness.",Computational Intelligence Business Applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-77.pdf,2010,100.0,"Modeling contextualized textual knowledge as a Long-Term Working Memory A knowledge management system is more than an archive of textual documents; it provides context information, allowing to know which documents where used by people with a common goal. In the hypothesis that a set of textual documents with a common context can be assimilated to the long term memory of a human expert executor, we can use on them mining techniques inspired by the mechanic of human comprehension in expert domains. Text mining techniques for KM task can use a model of the long-term memory to extract meaningful keywords from the documents. The model acts as a dynamic and non-stationary dimensionality reduction strategy, allowing the clustering of context documents according to keyword presence, the classification of external documents according to local criteria, and a better understanding of document content and relatedness."
Adaptive matrix distances aiming at optimum regression subspaces,"M Strickert, Axel Soto Bc, Gustavo Vazquez","1 - Institute for Vision and Graphics (IVG) University of Siegen Germany
2 - DCIC Laboratory for Research and Development in Scientific Computing Universidad Nacional del Sur Bahía Blanca Argentina
3 - Planta Piloto de Ingeniería Química CONICET-UNS Argentina","A new supervised adaptive metric approach is introduced for mapping an input vector space to a plottable low-dimensional subspace in which the pairwise distances are in maximum correlation with distances of the associated target space. The new formalism of multivariate subspace regression (MSR) is based on cost function optimization, and it allows assessing the relevance of input vector attributes. An application to molecular descriptors in a chemical compound database is presented for targeting octanol-water partitioning properties.","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-78.pdf,2010,100.0,"Adaptive matrix distances aiming at optimum regression subspaces A new supervised adaptive metric approach is introduced for mapping an input vector space to a plottable low-dimensional subspace in which the pairwise distances are in maximum correlation with distances of the associated target space. The new formalism of multivariate subspace regression (MSR) is based on cost function optimization, and it allows assessing the relevance of input vector attributes. An application to molecular descriptors in a chemical compound database is presented for targeting octanol-water partitioning properties."
Exploiting Hierarchical Prediction Structures for Mixed 2D-3D Tracking,"Chen Zhang, Julian Eggert","1 - Control Theory and Robotics Lab Landgraf Darmstadt University of Technology Institute of Automatic Control Georg-Str. 4 D-64283 Darmstadt Germany
2 - Honda Research Institute Europe GmbH Carl-Legien-Straße 30 D-63073 Offenbach Main, Germany","In this paper, we present a generic way to use a hierarchical representation of prediction models for adaptive tracking. Starting with a basic appearance-based tracker working in 2D retinal space, we show how to combine individual trackers for the left and right eye to a true 3D tracker that is built on top of the 2D trackers. We show how the trackers benefit from the hierarchical structure by dynamical model switching depending on the reliability of the tracking results.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-79.pdf,2010,84.28571428571429,"Exploiting Hierarchical Prediction Structures for Mixed 2D-3D Tracking In this paper, we present a generic way to use a hierarchical representation of prediction models for adaptive tracking. Starting with a basic appearance-based tracker working in 2D retinal space, we show how to combine individual trackers for the left and right eye to a true 3D tracker that is built on top of the 2D trackers. We show how the trackers benefit from the hierarchical structure by dynamical model switching depending on the reliability of the tracking results."
eural models for the analysis of kidney disease patients,"Emilio Soria, José Martín, Mónica Climente, Amparo Soldevila, Antonio Serrano","1 - Electronic Engineering Department ETSE Intelligent Data Analysis Laboratory (IDAL) University of Valencia C/ Dr. Moliner 50 46100 Burjassot, Valencia Spain
3 - Pharmacy Service University Hospital Dr. Peset Valencia Spain
4 - -Nephrology Service Hospital La Fe Valencia Spain","This work uses Machine Learning techniques and other classical approaches to analyze both physiological variables and treatment characteristics in patients undergoing chronic renal failure. Firstly, the use of Self-Organizing Maps is proposed in order to extract qualitative knowledge. Secondly, the Hemoglobin concentration is predicted one-month ahead by models based on the Multilayer Perceptron; the prediction uses information from two months (the current month and the previous one). Achieved results support the usefulness of these tools in daily clinical practice.",Computational Intelligence in Biomedicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-81.pdf,2010,88.49557522123894,"eural models for the analysis of kidney disease patients This work uses Machine Learning techniques and other classical approaches to analyze both physiological variables and treatment characteristics in patients undergoing chronic renal failure. Firstly, the use of Self-Organizing Maps is proposed in order to extract qualitative knowledge. Secondly, the Hemoglobin concentration is predicted one-month ahead by models based on the Multilayer Perceptron; the prediction uses information from two months (the current month and the previous one). Achieved results support the usefulness of these tools in daily clinical practice."
Directional predictions for 4-class BCI data,"Dieter Devlaminck, Willem Waegeman, Bruno Bauwens, Bart Wyns, Georges Otte, Luc Boullart, Patrick Santens","1 - Systems and Automation Technologiepark 913 Ghent University -Electrical Energy 9052 Zwijnaarde Belgium
2 - Dept of Applied Mathematics, Biometrics and Process Control Ghent University Coupure links 653, 4-P.C. Dr. Guislain Fr. Ferrerlaan 88A 9000, 9000 Gent, Gent -Belgium, Belgium
6 - Dept of Neurology De Pintelaan 185 Ghent University Hospital 9000 Gent -Belgium","Brain-computer interfaces (BCI)   can allow disabled people to drive a wheel chair, just by imagining movement. Therefore, present day BCIs use training data, recorded during four different conditions, to calibrate a classifier. This, however, causes jerky behavior while abruptly switching between discrete states. We propose a cost-sensitive support vector approach for estimating two-dimensional directions based on fourclass BCI data, that is recorded from three subjects. We found that our method reduces the number of severe errors compared to classical support vector machines and results in a smoother trajectory estimate for application in a wheel chair.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-82.pdf,2010,100.0,"Directional predictions for 4-class BCI data Brain-computer interfaces (BCI)   can allow disabled people to drive a wheel chair, just by imagining movement. Therefore, present day BCIs use training data, recorded during four different conditions, to calibrate a classifier. This, however, causes jerky behavior while abruptly switching between discrete states. We propose a cost-sensitive support vector approach for estimating two-dimensional directions based on fourclass BCI data, that is recorded from three subjects. We found that our method reduces the number of severe errors compared to classical support vector machines and results in a smoother trajectory estimate for application in a wheel chair."
Figure-ground Segmentation using Metrics Adaptation in Level Set Methods,"A Denecke, I Clemente, H Wersing, J Eggert, J Steil","1 - CoR-Lab -Bielefeld University P.O.-Box 10 01 31 D-33501 Bielefeld Germany
2 - Honda Research Institute Europe Carl-Legien-Str. 30 63073 Offenbach/Main Germany","We present an approach for hypothesis-based image segmentation basing on the integration of level set methods and discriminative feature clustering techniques. Building up on previous work, we investigate Localized Generalized Matrix Learning Vector Quantization (LGMLVQ) to train a classifier for fore-and background of an image. We extend this concept towards level set segmentation algorithms, where region descriptors are used to adapt the object contour according to the image features. The fusion of both methods outperforms their individual applications and improve the performance compared to other state of the art segmentation methods.",Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-83.pdf,2010,100.0,"Figure-ground Segmentation using Metrics Adaptation in Level Set Methods We present an approach for hypothesis-based image segmentation basing on the integration of level set methods and discriminative feature clustering techniques. Building up on previous work, we investigate Localized Generalized Matrix Learning Vector Quantization (LGMLVQ) to train a classifier for fore-and background of an image. We extend this concept towards level set segmentation algorithms, where region descriptors are used to adapt the object contour according to the image features. The fusion of both methods outperforms their individual applications and improve the performance compared to other state of the art segmentation methods."
Evolution of adaptive center-crossing continuous time recurrent neural networks for biped robot control,"Ángel Campo, José Santos",1 - Computing Science Department University of A Coruña (Spain),"We used simulated evolution to obtain continuous time recurrent neural networks to control the locomotion of simulated bipeds. We also used the definition of center-crossing networks, so that the recurrent networks nodes can reach their areas of maximum sensitivity of their activation functions. Moreover, we incorporated a run-time adaptation of the nodes' biases to obtain such condition. We tested the improvements and possibilities this adaptation adds, focusing in the use for biped robot control.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-84.pdf,2010,100.0,"Evolution of adaptive center-crossing continuous time recurrent neural networks for biped robot control We used simulated evolution to obtain continuous time recurrent neural networks to control the locomotion of simulated bipeds. We also used the definition of center-crossing networks, so that the recurrent networks nodes can reach their areas of maximum sensitivity of their activation functions. Moreover, we incorporated a run-time adaptation of the nodes' biases to obtain such condition. We tested the improvements and possibilities this adaptation adds, focusing in the use for biped robot control."
An ART-type network approach for video object detection,"R Luque, E Domínguez, E Palomo, J Muñoz",1 - Dept of Computer Science Universidad de Malaga Campus Teatinos s/n 29071 Malaga Spain,"This paper presents an ART-type network (adaptive resonant theory) to detect objects in a video sequence classifying the pixels as foreground or background. The proposed ART network (ART+) not only possesses the structure and learning ability of an ART-based network, but also uses a neural merging process to adapt the variability of the input data (pixels) in the scene along the time. Experimental results demonstrate the effectiveness and feasibility of the proposed ART+ approach for object detection. Standard datasets are used to compare the efficiency of the proposed approach against other traditional methods based on gaussian models.",Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-85.pdf,2010,100.0,"An ART-type network approach for video object detection This paper presents an ART-type network (adaptive resonant theory) to detect objects in a video sequence classifying the pixels as foreground or background. The proposed ART network (ART+) not only possesses the structure and learning ability of an ART-based network, but also uses a neural merging process to adapt the variability of the input data (pixels) in the scene along the time. Experimental results demonstrate the effectiveness and feasibility of the proposed ART+ approach for object detection. Standard datasets are used to compare the efficiency of the proposed approach against other traditional methods based on gaussian models."
On Finding Complementary Clusterings,"Timo Pröscholdt, Michel Crucianu","1 - CEDRIC -Conservatoire National des Arts et Métiers 292 rue St Martin 75141, Cedex 03 Paris France","In many cases, a dataset can be clustered following several criteria that complement each other: group membership following one criterion provides little or no information regarding group membership following the other criterion. When these criteria are not known a priori, they have to be determined from the data. We put forward a new method for jointly finding the complementary criteria and the clustering corresponding to each criterion.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-86.pdf,2010,100.0,"On Finding Complementary Clusterings In many cases, a dataset can be clustered following several criteria that complement each other: group membership following one criterion provides little or no information regarding group membership following the other criterion. When these criteria are not known a priori, they have to be determined from the data. We put forward a new method for jointly finding the complementary criteria and the clustering corresponding to each criterion."
Deep Learning of Visual Control Policies,"Sascha Lange, Martin Riedmiller",1 - Dept of Computer Science University of Freiburg Germany,"This paper discusses the effectiveness of deep auto-encoding neural nets in visual reinforcement learning (RL) tasks. We describe a new algorithm and give results on succesfully learning policies directly on synthesized and real images without a predefined image processing. Furthermore, we present a thorough evaluation of the learned feature spaces.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-87.pdf,2010,70.0,"Deep Learning of Visual Control Policies This paper discusses the effectiveness of deep auto-encoding neural nets in visual reinforcement learning (RL) tasks. We describe a new algorithm and give results on succesfully learning policies directly on synthesized and real images without a predefined image processing. Furthermore, we present a thorough evaluation of the learned feature spaces."
Random Search Enhancement of Error Minimized Extreme Learning Machine,"Yuan Lan, Yeng Soh, Guang-Bin Huang",1 - School of Electrical and Electronic Engineering Nanyang Technological University,"Error Minimized Extreme Learning Machine (EM-ELM) proposed by Feng et al.  [1]  can automatically determine the number of hidden nodes in generalized Single-hidden Layer Feedforward Networks (SLFNs). We recently found that some of the hidden nodes that are added into the network may play a very minor role in the network output, which increases the network complexity. Hence, this paper proposes an Enhancement of EM-ELM (referred to as EEM-ELM), which introduce a selection phase based on the random search method. The empirical study shows that EEM-ELM leads to a more compact network structure.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-88.pdf,2010,78.26086956521739,"Random Search Enhancement of Error Minimized Extreme Learning Machine Error Minimized Extreme Learning Machine (EM-ELM) proposed by Feng et al.  [1]  can automatically determine the number of hidden nodes in generalized Single-hidden Layer Feedforward Networks (SLFNs). We recently found that some of the hidden nodes that are added into the network may play a very minor role in the network output, which increases the network complexity. Hence, this paper proposes an Enhancement of EM-ELM (referred to as EEM-ELM), which introduce a selection phase based on the random search method. The empirical study shows that EEM-ELM leads to a more compact network structure."
Web Document Clustering based on a Hierarchical Self-Organizing Model,"E Palomo, E Domínguez, R Luque, J Muñoz",1 - E.T.S.I. Informatica Department of Computer Science University of Malaga Campus Teatinos s/n 29071 Malaga Spain,"In this work, a hierarchical self-organizing model based on the GHSOM is presented in order to cluster web contents. The GHSOM is an artificial neural network that has been widely used for data clustering. The hierarchical architecture of the GHSOM is more flexible than a single SOM since it is adapted to input data, mirroring inherent hierarchical relations among them. The adaptation process of the GHSOM architecture is controlled by two parameters. However, these parameters have to be established in advance and this task is not always easy. In this paper, a one parameter hierarchical self-organizing model is proposed. This model has been evaluated by using the 'BankSearch' benchmark dataset. Experimental results show the good performance of this approach.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-89.pdf,2010,100.0,"Web Document Clustering based on a Hierarchical Self-Organizing Model In this work, a hierarchical self-organizing model based on the GHSOM is presented in order to cluster web contents. The GHSOM is an artificial neural network that has been widely used for data clustering. The hierarchical architecture of the GHSOM is more flexible than a single SOM since it is adapted to input data, mirroring inherent hierarchical relations among them. The adaptation process of the GHSOM architecture is controlled by two parameters. However, these parameters have to be established in advance and this task is not always easy. In this paper, a one parameter hierarchical self-organizing model is proposed. This model has been evaluated by using the 'BankSearch' benchmark dataset. Experimental results show the good performance of this approach."
Mode Estimation in High-dimensional Spaces with Flat-top Kernels: Application to Image Denoising,"Arnaud De Decker, John Lee, Damien Franc ¸ois, Michel Verleysen","1 - Machine Learning Group Université catholique de Louvain Place du Levant 3 B-1348 Louvain-la-Neuve Belgium
2 - Université catholique de Louvain Imagerie Moléculaire et Radiothérapie Expérimentale Avenue Hippocrate 55 B-1200 Bruxelles Belgium","Data denoising can be achieved by approximating the data distribution and replacing each data item with an estimate of its closest mode. This idea has already been successfully applied to image denoising. The data then consists of pixel intensities or image patches, that is, vectorized groups of pixel intensities. The latter case raises the issue of mode estimation in a high-dimensional space, since patches can contain about 10 to more than 100 pixels. This paper shows that the widely used Gaussian kernel is outperformed by flat-top kernels that are specifically tailored in order to fight the curse of dimensionality.",Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-91.pdf,2010,83.33333333333334,"Mode Estimation in High-dimensional Spaces with Flat-top Kernels: Application to Image Denoising Data denoising can be achieved by approximating the data distribution and replacing each data item with an estimate of its closest mode. This idea has already been successfully applied to image denoising. The data then consists of pixel intensities or image patches, that is, vectorized groups of pixel intensities. The latter case raises the issue of mode estimation in a high-dimensional space, since patches can contain about 10 to more than 100 pixels. This paper shows that the widely used Gaussian kernel is outperformed by flat-top kernels that are specifically tailored in order to fight the curse of dimensionality."
Consensus clustering by graph based approach,"Haytham Elghazel, Khalid Benabdeslemi, Fatma Hamdi","1 - University of Lyon 1 LIESP EA4125, F-69622 Villeurbanne, Lyon France
3 - UMR CNRS 7030 University of Paris 13 LIPN 93430 Villetaneuse France","In this paper, we propose G-Cons, an extension of a graph minimal coloring paradigm for consensus clustering. Based on the coassociation values between data, our approach is a graph partitioning one which yields a combined partition by maximizing an objective function given by the average mutual information between the consensus partition and all initial combined clusterings. It exhibits more important consensus clustering features (quality and computational complexity) and enables to build a combined partition by improving the stability and accuracy of clustering solutions. The proposed approach is evaluated against benchmark databases and promising results are obtained compared to other consensus clustering techniques.",Learning III,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-92.pdf,2010,100.0,"Consensus clustering by graph based approach In this paper, we propose G-Cons, an extension of a graph minimal coloring paradigm for consensus clustering. Based on the coassociation values between data, our approach is a graph partitioning one which yields a combined partition by maximizing an objective function given by the average mutual information between the consensus partition and all initial combined clusterings. It exhibits more important consensus clustering features (quality and computational complexity) and enables to build a combined partition by improving the stability and accuracy of clustering solutions. The proposed approach is evaluated against benchmark databases and promising results are obtained compared to other consensus clustering techniques."
Ensemble Modeling with a Constrained Linear System of Leave-One-Out Outputs,"Yoan Miche, Emil Eirola, Patrick Bas, Olli Simula, Christian Jutten, Amaury Lendasse, Michel Verleysen","1 - Dept. of Information and Computer Science Helsinki University of Technology Konemiehentie 2 02015 TKK Finland
2 - Lab Institut National Polytechnique de Grenoble -Gipsa 961 rue de la Houille Blanche BP46, 38402 Grenoble France
8 - Université Catholique de Louvain -Machine Learning Group Place du Levant 3 B-1348 -Louvain-la-Neuve Belgium","This paper proposes a method for ensemble models using their Leave-One-Out output and solving a constrained linear system. By the use of the proposed method to create an ensemble of Locally Linear models, results on six different regression data sets are comparable to state-of-the-art methods such as Least-Squares Support Vector Machines and Gaussian Processes, while being orders of magnitude faster.",Supervised and recurrent models,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-93.pdf,2010,100.0,"Ensemble Modeling with a Constrained Linear System of Leave-One-Out Outputs This paper proposes a method for ensemble models using their Leave-One-Out output and solving a constrained linear system. By the use of the proposed method to create an ensemble of Locally Linear models, results on six different regression data sets are comparable to state-of-the-art methods such as Least-Squares Support Vector Machines and Gaussian Processes, while being orders of magnitude faster."
Relational Generative Topographic Mapping,"Andrej Gisbrecht, Bassam Mokbel, Barbara Hammer",1 - Department of Computer Science Clausthal Clausthal University of Technology Zellerfeld Germany,"The generative topographic mapping (GTM) has been proposed as a statistical model to represent high dimensional data by means of a sparse lattice of points in latent space, such that visualization, compression, and data inspection become possible. Original GTM is restricted to Euclidean data points in a vector space. Often, data are not explicitly embedded in a Euclidean vector space, rather pairwise dissimilarities of data can be computed, i.e. the relations between data points are given rather than the data vectors themselves. We propose a method which extends the GTM to relational data and which allows to achieve a sparse representation of data characterized by pairwise dissimilarities, in latent space. The method, relational GTM, is demonstrated on several benchmarks. 
 Introduction More and more electronic data become available in virtually all areas of life including, for example, biomedical domains, robotics, the web, or multimedia applications, such that powerful data mining tools are needed to support humans to inspect and interpret this information. Also, rapidly increasing technology such as improved sensor technology and advanced methods of data preprocessing and data storage make the data more and more complex, concerning data dimensionality and information content contained in the representation. Therefore, often, a simple comparison of data in terms of the Euclidean norm and a standard representation by means of Euclidean vectors is no longer appropriate to capture the relevant aspects of the data. Rather, dissimilarity measures which are adjusted to the data type and application area at hand should be used, including, for example, alignment distances for genomic sequence analysis in bioinformatics, the compression distance to compare texts, or structure kernels to compare complex graphs and tree structures. Classical data mining tools such as the self-organizing map (SOM) or its statistical counterpart, the generative topographic mapping (GTM) provide a sparse representation of high-dimensional data by means of latent points arranged in a low-dimensional neighborhood structure which is useful for visualization. However, they have been introduced for Euclidean vectors only  [9, 1] . Several extensions of SOM to the more general setting of data characterized by pairwise relations only, have been proposed, including median SOM which restricts prototype locations to data points [10], online and batch SOM using a kernelization of the classical approach [2, 13], and methods which rely on deterministic annealing techniques borrowed from statistical physics  [5] . For GTM, a complex noise model as proposed in  [12]  allows the extension of the method to discrete structures such as sequences. Recently, an intuitive extension of SOM to dissimilarity data has been proposed in [7]  which relies on techniques as introduced in [8]: assume that only a dissimilarity matrix characterizes the data and an explicit vectorial representation is unknown. If prototypes have the special form of convex combinations 277",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-94.pdf,2010,94.87179487179486,"Relational Generative Topographic Mapping The generative topographic mapping (GTM) has been proposed as a statistical model to represent high dimensional data by means of a sparse lattice of points in latent space, such that visualization, compression, and data inspection become possible. Original GTM is restricted to Euclidean data points in a vector space. Often, data are not explicitly embedded in a Euclidean vector space, rather pairwise dissimilarities of data can be computed, i.e. the relations between data points are given rather than the data vectors themselves. We propose a method which extends the GTM to relational data and which allows to achieve a sparse representation of data characterized by pairwise dissimilarities, in latent space. The method, relational GTM, is demonstrated on several benchmarks. 
 Introduction More and more electronic data become available in virtually all areas of life including, for example, biomedical domains, robotics, the web, or multimedia applications, such that powerful data mining tools are needed to support humans to inspect and interpret this information. Also, rapidly increasing technology such as improved sensor technology and advanced methods of data preprocessing and data storage make the data more and more complex, concerning data dimensionality and information content contained in the representation. Therefore, often, a simple comparison of data in terms of the Euclidean norm and a standard representation by means of Euclidean vectors is no longer appropriate to capture the relevant aspects of the data. Rather, dissimilarity measures which are adjusted to the data type and application area at hand should be used, including, for example, alignment distances for genomic sequence analysis in bioinformatics, the compression distance to compare texts, or structure kernels to compare complex graphs and tree structures. Classical data mining tools such as the self-organizing map (SOM) or its statistical counterpart, the generative topographic mapping (GTM) provide a sparse representation of high-dimensional data by means of latent points arranged in a low-dimensional neighborhood structure which is useful for visualization. However, they have been introduced for Euclidean vectors only  [9, 1] . Several extensions of SOM to the more general setting of data characterized by pairwise relations only, have been proposed, including median SOM which restricts prototype locations to data points [10], online and batch SOM using a kernelization of the classical approach [2, 13], and methods which rely on deterministic annealing techniques borrowed from statistical physics  [5] . For GTM, a complex noise model as proposed in  [12]  allows the extension of the method to discrete structures such as sequences. Recently, an intuitive extension of SOM to dissimilarity data has been proposed in [7]  which relies on techniques as introduced in [8]: assume that only a dissimilarity matrix characterizes the data and an explicit vectorial representation is unknown. If prototypes have the special form of convex combinations 277"
A critique of BCM behavior verification for STDP-type plasticity models,"Christian Mayr, Johannes Partzsch, Rene Schüffny",1 - Endowed Chair of Highly-Parallel VLSI-Systems and Neural Microelectronics University of Technology Dresden Dresden Germany,"Rate based (Bienenstock-Cooper-Munroe, BCM) and spike timing dependent plasticity (STDP) are the two principal learning behaviors found at cortical synapses. Some BCM induction protocols have been shown to be compatible with STDP rules, thus combining both forms of plasticity. However, we demonstrate that the majority of actual experimental BCM protocols cannot be reproduced by STDP. This sensitivity to spike protocol is inconsistent with the robust BCM behavior generally found in experiments. Moreover, we show that major recent spike timing rules, despite incorporating rate based effects, cannot replicate actual experimental BCM evidence. Thus, the purported convergence between these two important plasticity phenomena is called in question.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-95.pdf,2010,100.0,"A critique of BCM behavior verification for STDP-type plasticity models Rate based (Bienenstock-Cooper-Munroe, BCM) and spike timing dependent plasticity (STDP) are the two principal learning behaviors found at cortical synapses. Some BCM induction protocols have been shown to be compatible with STDP rules, thus combining both forms of plasticity. However, we demonstrate that the majority of actual experimental BCM protocols cannot be reproduced by STDP. This sensitivity to spike protocol is inconsistent with the robust BCM behavior generally found in experiments. Moreover, we show that major recent spike timing rules, despite incorporating rate based effects, cannot replicate actual experimental BCM evidence. Thus, the purported convergence between these two important plasticity phenomena is called in question."
Hybrid Soft Computing for PVT Properties Prediction,"Lahouari Ghouti, Saeed Al-Bukhitan","1 - Minerals -Department of Information and Computer Science KFUPM King Fahd University of Petroleum Box 1128. Dhahran 31261 Saudi Arabia First
3 - This research is funded by King Fahd University of Petroleum and Minerals","Pressure-Volume-Temperature (PVT) properties are very important in the reservoir engineering computations. There are many approaches for predicting various PVT properties based on empirical correlations and statistical regression models. Last decade, researchers utilized neural networks to develop more accurate PVT correlations. These achievements of neural networks open the door to data mining techniques to play a major role in oil and gas industry. Unfortunately, the developed neural networks correlations are often limited and global correlations are usually less accurate compared to local correlations. Recently, adaptive neurofuzzy inference systems have been proposed as a new intelligence framework for both prediction and classification based on fuzzy clustering optimization criterion and ranking. In this paper, a genetic-neuro-fuzzy inference system is proposed for estimating PVT properties of crude oil systems.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-96.pdf,2010,100.0,"Hybrid Soft Computing for PVT Properties Prediction Pressure-Volume-Temperature (PVT) properties are very important in the reservoir engineering computations. There are many approaches for predicting various PVT properties based on empirical correlations and statistical regression models. Last decade, researchers utilized neural networks to develop more accurate PVT correlations. These achievements of neural networks open the door to data mining techniques to play a major role in oil and gas industry. Unfortunately, the developed neural networks correlations are often limited and global correlations are usually less accurate compared to local correlations. Recently, adaptive neurofuzzy inference systems have been proposed as a new intelligence framework for both prediction and classification based on fuzzy clustering optimization criterion and ranking. In this paper, a genetic-neuro-fuzzy inference system is proposed for estimating PVT properties of crude oil systems."
Divergence based Learning Vector Quantization,"E Mwebaze, P Schneider, F.-M Schleif, S Haase, T Villmann, M Biehl","1 - Faculty of Computing & IT Makerere Univ P.O. Box 7062 Kampala Uganda
2 - Johann Bernoulli Inst. for Mathematics and Computer Science Univ. of Groningen P. O. Box 407 9700AK Groningen The Netherlands
4 - Computational Intelligence Group University of Leipzig Semmelweisstr. 10 04103 Leipzig Germany
5 - Department of MPI University of Applied Sciences Technikumplatz 17 09648 Mittweida Germany","We suggest the use of alternative distance measures for similarity based classification in Learning Vector Quantization. Divergences can be employed whenever the data consists of non-negative normalized features, which is the case for, e.g., spectral data or histograms. As examples, we derive gradient based training algorithms in the framework of Generalized Learning Vector Quantization based on the so-called Cauchy-Schwarz divergence and a non-symmetric Renyi divergence. As a first test we apply the methods to two different biomedical data sets and compare with the use of standard Euclidean distance.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-97.pdf,2010,100.0,"Divergence based Learning Vector Quantization We suggest the use of alternative distance measures for similarity based classification in Learning Vector Quantization. Divergences can be employed whenever the data consists of non-negative normalized features, which is the case for, e.g., spectral data or histograms. As examples, we derive gradient based training algorithms in the framework of Generalized Learning Vector Quantization based on the so-called Cauchy-Schwarz divergence and a non-symmetric Renyi divergence. As a first test we apply the methods to two different biomedical data sets and compare with the use of standard Euclidean distance."
Extending reservoir computing with random static projections: a hybrid between extreme learning and RC,"John Butcher, David Verstraeten, Benjamin Schrauwen, Charles Day, Peter Haycock","1 - Physical Sciences and Applied Mathematics (EPSAM) -Institute for the Environment Keele University ST5 5BG Staffordshire United Kingdom
2 - Department of Electronics and Information Systems Ghent University Sint-Pietersnieuwstraat 41 9000 Ghent Belgium
6 - The Department of Electronics and Information Systems Ghent University","Reservoir Computing is a relatively new paradigm in the field of neural networks that has shown promise in applications where traditional recurrent neural networks have performed poorly. The main advantage of using reservoirs is that only the output weights are trained, reducing computational requirements significantly. There is a trade-off, however, between the amount of memory a reservoir can possess and its capability of mapping data into a highly non-linear transformation space. A new, hybrid architecture, combining a reservoir with an extreme learning machine, is presented which overcomes this trade-off, whose performance is demonstrated on a 4 th order polynomial modelling task and an isolated spoken digit recognition task. * SciSite Ltd and the UK EPSRC are gratefully acknowledged for supporting this research.",Machine learning techniques based on random projections,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-99.pdf,2010,100.0,"Extending reservoir computing with random static projections: a hybrid between extreme learning and RC Reservoir Computing is a relatively new paradigm in the field of neural networks that has shown promise in applications where traditional recurrent neural networks have performed poorly. The main advantage of using reservoirs is that only the output weights are trained, reducing computational requirements significantly. There is a trade-off, however, between the amount of memory a reservoir can possess and its capability of mapping data into a highly non-linear transformation space. A new, hybrid architecture, combining a reservoir with an extreme learning machine, is presented which overcomes this trade-off, whose performance is demonstrated on a 4 th order polynomial modelling task and an isolated spoken digit recognition task. * SciSite Ltd and the UK EPSRC are gratefully acknowledged for supporting this research."
Using Very Deep Autoencoders for Content-Based Image Retrieval,"Alex Krizhevsky, Georey Hinton",1 - Department of Computer Science University of Toronto 6 King's College Road M5S 3H5 Toronto Canada,"We show how to learn many layers of features on color images and we use these features to initialize deep autoencoders. We then use the autoencoders to map images to short binary codes. Using semantic hashing [6], 28-bit codes can be used to retrieve images that are similar to a query image in a time that is independent of the size of the database. This extremely fast retrieval makes it possible to search using multiple dierent transformations of the query image. 256-bit binary codes allow much more accurate matching and can be used to prune the set of images found using the 28-bit codes.",Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-10.pdf,2011,72.58064516129032,"Using Very Deep Autoencoders for Content-Based Image Retrieval We show how to learn many layers of features on color images and we use these features to initialize deep autoencoders. We then use the autoencoders to map images to short binary codes. Using semantic hashing [6], 28-bit codes can be used to retrieve images that are similar to a query image in a time that is independent of the size of the database. This extremely fast retrieval makes it possible to search using multiple dierent transformations of the query image. 256-bit binary codes allow much more accurate matching and can be used to prune the set of images found using the 28-bit codes."
Optimization of Parametrized Divergences in Fuzzy c-Means,"T Geweniger, M Kästner, T Villmann","1 - Johann Bernoulli Institute for Mathematics and Computer Science University of Groningen The Netherlands
2 - Computational Intelligence Group Dep. of Mathematics, Natural and Computer Sciences University of Applied Sciences Mittweida Mittweida Germany",We propose the utilization of divergences as dissimilarity measure in the Fuzzy c-Means algorithm for the clustering of functional data. Further we adapt the relevance parameter to improve the data representation and therefore obtain more accurate clusterings in terms of separation and compactness. We show for two example applications that this method leads to improved performance.,Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-100.pdf,2011,100.0,Optimization of Parametrized Divergences in Fuzzy c-Means We propose the utilization of divergences as dissimilarity measure in the Fuzzy c-Means algorithm for the clustering of functional data. Further we adapt the relevance parameter to improve the data representation and therefore obtain more accurate clusterings in terms of separation and compactness. We show for two example applications that this method leads to improved performance.
Ensemble Usage for More Reliable Policy Identification in Reinforcement Learning,"Alexander Hans, Steffen Udluft","1 - Ilmenau University of Technology -Neuroinformatics & Cognitive Robotics Lab P.O. Box 100565 D-98684 Ilmenau Germany
2 - Siemens AG, Corporate Technology -Intelligent Systems & Control Otto-Hahn-Ring 6 D-81739 Munich Germany","Reinforcement learning (RL) methods employing powerful function approximators like neural networks have become an interesting approach for optimal control. Since they learn a policy from observations, they are also applicable when no analytical description of the system is available. Although impressive results have been reported, their handling in practice is still hard, as they can fail at reliably determining a good policy. In previous work, we used ensembles of policies from independent runs of neural fitted Q-iteration (NFQ) to produce successful policies more reliably. In this paper we evaluate the approach on more problems and propose to form ensembles from successive iterations of a single NFQ run as a computationally cheap alternative to completely independent runs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-101.pdf,2011,100.0,"Ensemble Usage for More Reliable Policy Identification in Reinforcement Learning Reinforcement learning (RL) methods employing powerful function approximators like neural networks have become an interesting approach for optimal control. Since they learn a policy from observations, they are also applicable when no analytical description of the system is available. Although impressive results have been reported, their handling in practice is still hard, as they can fail at reliably determining a good policy. In previous work, we used ensembles of policies from independent runs of neural fitted Q-iteration (NFQ) to produce successful policies more reliably. In this paper we evaluate the approach on more problems and propose to form ensembles from successive iterations of a single NFQ run as a computationally cheap alternative to completely independent runs."
Hybrid HMM and HCRF model for sequence classification,"Y Soullard, T Artières",1 - University Pierre and Marie Curie -LIP6 4 place Jussieu 75005 Paris France,"We propose a hybrid model combining a generative model and a discriminative model for signal labelling and classification tasks, aiming at taking the best from each world. The idea is to focus the learning of the discriminative model on most likely state sequences as output by the generative model. This allows taking advantage of the usual increased accuracy of generative models on small training datasets and of discriminative models on large training datasets. We instantiate this framework with Hidden Markov Models and Hidden Conditional Random Fields. We validate our model on financial time series and on handwriting data.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-102.pdf,2011,100.0,"Hybrid HMM and HCRF model for sequence classification We propose a hybrid model combining a generative model and a discriminative model for signal labelling and classification tasks, aiming at taking the best from each world. The idea is to focus the learning of the discriminative model on most likely state sequences as output by the generative model. This allows taking advantage of the usual increased accuracy of generative models on small training datasets and of discriminative models on large training datasets. We instantiate this framework with Hidden Markov Models and Hidden Conditional Random Fields. We validate our model on financial time series and on handwriting data."
New conditioning model for robots,Jean Salotti,1 - IMS laboratory ENSC-IPB Bordeaux University 146 Rue Léo Saignat 33076 Bordeaux Cedex France,"We present a neural network for the prediction of rewards in a conditioning model. It is based on two noisy-or and one noisy-and nodes and update rules inspired from BANNER technique. In specific cases, we show that the computation is similar to Rescorla-Wagner's equation, which inspired many computational models in the domain of conditioning.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-104.pdf,2011,100.0,"New conditioning model for robots We present a neural network for the prediction of rewards in a conditioning model. It is based on two noisy-or and one noisy-and nodes and update rules inspired from BANNER technique. In specific cases, we show that the computation is similar to Rescorla-Wagner's equation, which inspired many computational models in the domain of conditioning."
A Neural Filter for Electrolocation in Weakly Electric Fish,"Miyoung Sim, Daeeun Kim","1 - Biological Cybernetics Lab Yonsei University
2 - School of Electrical and Electronic Engineering 120-749 Seoul, Corea South Korea","The weakly electric fish have the electric organ to generate the electric field and electrosensory mechanism to read the change of electric field with their electroreceptors. The electric organ produce a waveform of electric field as their electric organ discharge (EOD). Their active electrolocation system can detect the distortion of the self-generated electric field, which is caused by a target object, and estimate the position of a target object. In this paper, we suggest a hypothesis that the periodic EOD signals are involved to extract localization features from noisy electrosensory signals and then provide a possible neural network to process the noise-filtering to obtain the accurate information of a target position. The neural network has sinusoidal weights to process a time series of sensor readings for each electroreceptor.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-105.pdf,2011,100.0,"A Neural Filter for Electrolocation in Weakly Electric Fish The weakly electric fish have the electric organ to generate the electric field and electrosensory mechanism to read the change of electric field with their electroreceptors. The electric organ produce a waveform of electric field as their electric organ discharge (EOD). Their active electrolocation system can detect the distortion of the self-generated electric field, which is caused by a target object, and estimate the position of a target object. In this paper, we suggest a hypothesis that the periodic EOD signals are involved to extract localization features from noisy electrosensory signals and then provide a possible neural network to process the noise-filtering to obtain the accurate information of a target position. The neural network has sinusoidal weights to process a time series of sensor readings for each electroreceptor."
A Unified Approach to Estimation and Control of the False Discovery Rate in Bayesian Network Skeleton Identification,"Angelos Armen, Ioannis Tsamardinos",1 - University of Crete -Computer Science Department Heraklion Crete -Greece Foundation of Research and Technology Hellas -Institute of Computer Science Heraklion Crete Greece,"Constraint-based Bayesian network (BN) structure learning algorithms typically control the False Positive Rate (FPR) of their skeleton identification phase. The False Discovery Rate (FDR), however, may be of greater interest and methods for its utilization by these algorithms have been recently devised. We present a unified approach to BN skeleton identification FDR estimation and control and experimentally evaluate the performance of FDR estimators in both tasks over several networks. We demonstrate that estimation is too conservative for most networks and strong control at common FDR thresholds is not achieved with some networks; finally, we identify the possible causes of this situation.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-106.pdf,2011,57.758620689655174,"A Unified Approach to Estimation and Control of the False Discovery Rate in Bayesian Network Skeleton Identification Constraint-based Bayesian network (BN) structure learning algorithms typically control the False Positive Rate (FPR) of their skeleton identification phase. The False Discovery Rate (FDR), however, may be of greater interest and methods for its utilization by these algorithms have been recently devised. We present a unified approach to BN skeleton identification FDR estimation and control and experimentally evaluate the performance of FDR estimators in both tasks over several networks. We demonstrate that estimation is too conservative for most networks and strong control at common FDR thresholds is not achieved with some networks; finally, we identify the possible causes of this situation."
A Spectral Based Clustering Algorithm for Categorical Data with Maximum Modularity,"Lazhar Labiod, Younès Bennani","1 - LIPN-UMR 7030 Université Paris 13 99, av. J-B Clément 93430 Villetaneuse France","In this paper we propose a spectral based clustering algorithm to maximize an extended Modularity measure for categorical data; first, we establish the connection with the Relational Analysis criterion. Second, the maximization of the extended modularity is shown as a trace maximization problem. A spectral based algorithm is then presented to search for the partitions maximizing the extended Modularity criterion. Experimental results indicate that the new algorithm is efficient and effective at finding a good clustering across a variety of real-world data sets 
 Definitions and Notations Let D be a dataset with a set I of N objects (O 1 , O 2 , ..., O N ) described by the set V of M categorical attributes (or variables)",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-107.pdf,2011,100.0,"A Spectral Based Clustering Algorithm for Categorical Data with Maximum Modularity In this paper we propose a spectral based clustering algorithm to maximize an extended Modularity measure for categorical data; first, we establish the connection with the Relational Analysis criterion. Second, the maximization of the extended modularity is shown as a trace maximization problem. A spectral based algorithm is then presented to search for the partitions maximizing the extended Modularity criterion. Experimental results indicate that the new algorithm is efficient and effective at finding a good clustering across a variety of real-world data sets 
 Definitions and Notations Let D be a dataset with a set I of N objects (O 1 , O 2 , ..., O N ) described by the set V of M categorical attributes (or variables)"
Statistical dependence measure for feature selection in microarray datasets,"Verónica Bolón-Canedo, Seth Sohan, Noelia Sánchez-Maroño, Amparo Alonso-Betanzos, José Príncipe","1 - Department of Computer Science University of A Coruña Spain
2 - Department of Electrical and Computer Engineering University of Florida Gainesville Florida USA","Feature selection is the domain of machine learning which studies data-driven methods to select, among a set of input variables, the ones that will lead to the most accurate predictive model. In this paper, a statistical dependence measure is presented for variable selection in the context of classification. Its performance is tested over DNA microarray data, a challenging dataset for machine learning researchers due to the high number of genes and relatively small number of measurements. This measure is compared against the so called mRMR approach, and is shown to obtain better or equal performance over the binary datasets.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-11.pdf,2011,100.0,"Statistical dependence measure for feature selection in microarray datasets Feature selection is the domain of machine learning which studies data-driven methods to select, among a set of input variables, the ones that will lead to the most accurate predictive model. In this paper, a statistical dependence measure is presented for variable selection in the context of classification. Its performance is tested over DNA microarray data, a challenging dataset for machine learning researchers due to the high number of genes and relatively small number of measurements. This measure is compared against the so called mRMR approach, and is shown to obtain better or equal performance over the binary datasets."
A brief tutorial on reinforcement learning: The game of Chung Toi,"Christopher Gatti, Jonathan Linton, Mark Embrechts","1 - Rensselaer Polytechnic Institute Department of Industrial and Systems Engineering Troy 12180 NY USA
2 - University of Ottawa Telfer School of Management Ottawa K1N 6N5 ON Canada","This work presents a simple implementation of reinforcement learning, using the temporal difference algorithm and a neural network, applied to the board game of Chung Toi, which is a challenging variation of Tic-Tac-Toe. The implementation of this learning algorithm is fully described and includes all parameter settings and various techniques to improve the ability of the network to learn the board game. With relatively little training, the network was able to win nearly 90% of games played against a 'smart' random opponent. The aim of this work is to develop a general software framework for reinforcement learning with an aim to allow for the implementation of game playing strategies for managers that can be applied to option and portfolio management.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-110.pdf,2011,100.0,"A brief tutorial on reinforcement learning: The game of Chung Toi This work presents a simple implementation of reinforcement learning, using the temporal difference algorithm and a neural network, applied to the board game of Chung Toi, which is a challenging variation of Tic-Tac-Toe. The implementation of this learning algorithm is fully described and includes all parameter settings and various techniques to improve the ability of the network to learn the board game. With relatively little training, the network was able to win nearly 90% of games played against a 'smart' random opponent. The aim of this work is to develop a general software framework for reinforcement learning with an aim to allow for the implementation of game playing strategies for managers that can be applied to option and portfolio management."
Abstract Category Learning,"Atsushi Hashimoto, Haruo Hosoya","1 - Department of Computer Science The University of Tokyo 7-3-1 Hongo, Bunkyo-ku Tokyo Japan","Motivated by a neurophysiological experiment on prefrontal cortex, we study a scheme for learning abstract categories. An abstract category represents a set of vectors that are identical to each other modulo substitution, e.g., 'ABAB', 'BABA', 'ACAC', etc. We employ a clusteringbased unsupervised learning method for such abstract categories, in which the recognition step is reduced to the problem of maximal perfect weight matching. Our simulations using artificial inputs confirm that the scheme learns abstract categories robustly even with a certain level of noise in the inputs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-12.pdf,2011,92.3076923076923,"Abstract Category Learning Motivated by a neurophysiological experiment on prefrontal cortex, we study a scheme for learning abstract categories. An abstract category represents a set of vectors that are identical to each other modulo substitution, e.g., 'ABAB', 'BABA', 'ACAC', etc. We employ a clusteringbased unsupervised learning method for such abstract categories, in which the recognition step is reduced to the problem of maximal perfect weight matching. Our simulations using artificial inputs confirm that the scheme learns abstract categories robustly even with a certain level of noise in the inputs."
A distributed learning algorithm based on two-layer artificial neural networks and genetic algorithms,"Diego Peteiro-Barral, Bertha Guijarro-Berdiñas, Beatriz Pérez-Sánchez, Óscar Fontenla-Romero",1 - Faculty of Informatics -Dept of Computer Science University of A Coruña Campus de Elviña s/n 15071 A Coruña Spain,"In many real-world applications of machine learning, the amount of data is now beyond the capability of learning algorithms because they cannot process all available data in a reasonable time. Moreover, most large datasets are naturally distributed or they are being stored in a distributed manner. A promising line of research in order to deal with large and/or distributed data is distributed learning. We propose a new distributed learning algorithm based on two-layer artificial neural networks and genetic algorithms. The results obtained show that our method performs better than other distributed learning algorithms.",Optimization and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-13.pdf,2011,100.0,"A distributed learning algorithm based on two-layer artificial neural networks and genetic algorithms In many real-world applications of machine learning, the amount of data is now beyond the capability of learning algorithms because they cannot process all available data in a reasonable time. Moreover, most large datasets are naturally distributed or they are being stored in a distributed manner. A promising line of research in order to deal with large and/or distributed data is distributed learning. We propose a new distributed learning algorithm based on two-layer artificial neural networks and genetic algorithms. The results obtained show that our method performs better than other distributed learning algorithms."
Increased robustness and intermittent dynamics in structured Reservoir Networks with feedback,"Sarah Jarvis, Stefan Rotter, Ulrich Egert","1 - Bernstein Center Freiburg Freiburg im Breisgau Germany
2 - Freiburg im Breisgau Biomicrotechnology -Department of Microsystems Engineering Albert-Ludwig University Germany
4 - -Computational Neuroscience -Faculty of Biology Albert Freiburg im Breisgau Ludwig University Germany","Recent studies using feedforward Echo State Networks (ESN) demonstrate that reservoir stability can be strongly affected by reservoir substructures, such as clusters. Here, we evaluate the impact of including feedback on clustered ESNs and assert that certain cluster configurations extend the permissible range of spectral radius values. We also report a new class of reservoir activity: intermittent dynamics, characterized by variable periods of chaotic activity before returning to quiescent behaviour. Using a non-linear benchmark data set, we establish clustered ESNs have comparable performance against conventional ESNs, but importantly display an increased tolerance and robustness to spectral radius and input choice.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-14.pdf,2011,100.0,"Increased robustness and intermittent dynamics in structured Reservoir Networks with feedback Recent studies using feedforward Echo State Networks (ESN) demonstrate that reservoir stability can be strongly affected by reservoir substructures, such as clusters. Here, we evaluate the impact of including feedback on clustered ESNs and assert that certain cluster configurations extend the permissible range of spectral radius values. We also report a new class of reservoir activity: intermittent dynamics, characterized by variable periods of chaotic activity before returning to quiescent behaviour. Using a non-linear benchmark data set, we establish clustered ESNs have comparable performance against conventional ESNs, but importantly display an increased tolerance and robustness to spectral radius and input choice."
General bound of overfitting for MLP regression models,J Rynkiewicz,1 - Universite Paris 1 -SAMM 90 Rue de Tolbiac 75013 Paris France,"Multilayer perceptrons (MLP) with one hidden layer have been used for a long time to deal with non-linear regression. However, in some task, MLP's are too powerful models and a small mean square error (MSE) may be more due to overfitting than to actual modelling. If the noise of the regression model is Gaussian, the overfitting of the model is totally determined by the behavior of the likelihood ratio test statistic (LRTS), however in numerous cases the assumption of normality of the noise is arbitrary if not false. In this paper, we present an universal bound for the overfitting of such model under smooth assumptions, this bound is valid without Gaussian or identifiability assumptions. The main application of this bound is to give a hint about determining the true architecture of the MLP model when the number of data goes to infinite.",Learning theory,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-15.pdf,2011,100.0,"General bound of overfitting for MLP regression models Multilayer perceptrons (MLP) with one hidden layer have been used for a long time to deal with non-linear regression. However, in some task, MLP's are too powerful models and a small mean square error (MSE) may be more due to overfitting than to actual modelling. If the noise of the regression model is Gaussian, the overfitting of the model is totally determined by the behavior of the likelihood ratio test statistic (LRTS), however in numerous cases the assumption of normality of the noise is arbitrary if not false. In this paper, we present an universal bound for the overfitting of such model under smooth assumptions, this bound is valid without Gaussian or identifiability assumptions. The main application of this bound is to give a hint about determining the true architecture of the MLP model when the number of data goes to infinite."
Fisherman learning algorithm of the SOM realized in the CMOS technology,"Rafa Lugosz, Marta Kolasa, Witold Pedrycz","1 - Faculty of Telecommunication and Electrical Engineering University of Technology and Life Sciences ul Kaliskiego 7 85-796 Bydgoszcz Poland
3 - Department of Electrical and Computer Engineering University of Alberta Edmonton T6G 2V4 AB Canada","This study presents an idea of transistor level realization of the fisherman learning algorithm of Self-Organizing Maps (SOMs) which is described in  [4] . The realization of this algorithm in hardware calls for a solution of several specific problems not present in software implementation. The main problem is related to an iterative nature of the adaptation process of the neighboring neurons positioned at particular rings surrounding the winning neuron. This makes the circuit structure of the SOM very complex. To come up with a feasible realization, we introduce some modifications to the original fisherman algorithm. Detailed simulations of the software model of the SOM show that these modifications do not have the negative impact on the learning process, and helps bring significant reduction of the circuit complexity. In consequence, a fully parallel adaptation of all neurons is possible, which makes the SOM very fast.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-16.pdf,2011,100.0,"Fisherman learning algorithm of the SOM realized in the CMOS technology This study presents an idea of transistor level realization of the fisherman learning algorithm of Self-Organizing Maps (SOMs) which is described in  [4] . The realization of this algorithm in hardware calls for a solution of several specific problems not present in software implementation. The main problem is related to an iterative nature of the adaptation process of the neighboring neurons positioned at particular rings surrounding the winning neuron. This makes the circuit structure of the SOM very complex. To come up with a feasible realization, we introduce some modifications to the original fisherman algorithm. Detailed simulations of the software model of the SOM show that these modifications do not have the negative impact on the learning process, and helps bring significant reduction of the circuit complexity. In consequence, a fully parallel adaptation of all neurons is possible, which makes the SOM very fast."
Generalized functional relevance learning vector quantization,"M Kästner, B Hammer, M Biehl, T Villmann","1 - Natural and Computer Sciences University of Applied Science -Dept. of Mathematics 09648 Mittweida Germany
2 - CITEC -Faculty of Technology Bielefeld University 33594 Bielefeld Germany
3 - Johann Bernoulli Institute for Mathematics and Computer Science University of Groningen The Netherlands","Generalized learning vector quantization (GRLVQ) is a prototype based classification algorithm with metric adaptation weighting each data dimensions according to their relevance for the classification task. We present in this paper an extension for functional data, which are usually very high dimensional. This approach supposes the data vectors have to be functional representations. Taking into account, these information the so-called relevance profile are modeled by superposition of simple basis functions depending on only a few parameters. As a consequence, the resulting functional GRLVQ has drastically reduced number of parameters to be adapted for relevance learning. We demonstrate the ability of the new algorithms for standard functional data sets using different basis functions, namely Gaussians and Lorentzians.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-18.pdf,2011,100.0,"Generalized functional relevance learning vector quantization Generalized learning vector quantization (GRLVQ) is a prototype based classification algorithm with metric adaptation weighting each data dimensions according to their relevance for the classification task. We present in this paper an extension for functional data, which are usually very high dimensional. This approach supposes the data vectors have to be functional representations. Taking into account, these information the so-called relevance profile are modeled by superposition of simple basis functions depending on only a few parameters. As a consequence, the resulting functional GRLVQ has drastically reduced number of parameters to be adapted for relevance learning. We demonstrate the ability of the new algorithms for standard functional data sets using different basis functions, namely Gaussians and Lorentzians."
Probabilistic Fisher Discriminant Analysis,"Charles Bouveyron, Camille Brunet","1 - University Paris 1 Panthéon-Sorbonne -Laboratoire SAMM, 90 rue de Tolbiac 4543, 75013 PARIS EA FRANCE
2 - University of Evry -IBISC TADIB FRE CNRS 3190 40 rue Pelvoux CE 1455 -91020 EVRY FRANCE","Fisher Discriminant Analysis (FDA) is a powerful and popular method for dimensionality reduction and classification which has unfortunately poor performances in the cases of label noise and sparse labeled data. To overcome these limitations, we propose a probabilistic framework for FDA and extend it to the semi-supervised case. Experiments on realworld datasets show that the proposed approach works as well as FDA in standard situations and outperforms it in the label noise and sparse label cases.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-27.pdf,2011,50.46728971962617,"Probabilistic Fisher Discriminant Analysis Fisher Discriminant Analysis (FDA) is a powerful and popular method for dimensionality reduction and classification which has unfortunately poor performances in the cases of label noise and sparse labeled data. To overcome these limitations, we propose a probabilistic framework for FDA and extend it to the semi-supervised case. Experiments on realworld datasets show that the proposed approach works as well as FDA in standard situations and outperforms it in the label noise and sparse label cases."
Learning of Causal Relations,"John Quinn, Joris Mooij, Tom Heskes, Michael Biehl","1 - Faculty of Computing & IT Makerere University P.O. Box 7062 Kampala Uganda
2 - Institute for Computing and Information Sciences Radboud University Nijmegen P.O. Box 9010 6500 GL Nijmegen The Netherlands
4 - Johann Bernoulli Institute for Mathematics and Computer Science University of Groningen P.O. Box 407 9700AK Groningen The Netherlands","To learn about causal relations between variables just by observing samples from them, particular assumptions must be made about those variables' distributions. This article gives a practical description of how such a learning task can be undertaken based on different possible assumptions. Two categories of assumptions lead to different methods, constraint-based and Bayesian learning, and in each case we review both the basic ideas and some recent extensions and alternatives to them.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-4,2011,63.1578947368421,"Learning of Causal Relations To learn about causal relations between variables just by observing samples from them, particular assumptions must be made about those variables' distributions. This article gives a practical description of how such a learning task can be undertaken based on different possible assumptions. Two categories of assumptions lead to different methods, constraint-based and Bayesian learning, and in each case we review both the basic ideas and some recent extensions and alternatives to them."
Multispectral image characterization by partial generalized covariance,"Marc Strickert, Björn Labitzke, Andreas Kolb, Thomas Villmann","1 - Institute for Vision and Graphics (IVG) University of Siegen Germany
4 - Department of Mathematics University of Applied Sciences Mittweida Germany","A general method is presented for the assessment of data attribute variability, which plays an important role in initial screening of multi-and high-dimensional data sets. Instead of the commonly used second centralized moment, known as variance, the proposed method allows a mathematically rigorous characterization of attribute sensitivity given not only Euclidean distances but partial data comparisons by general similarity measures. Depending on the choice of measure different spectral features get highlighted by attribute assessment, this way creating new image segmentation aspects, as shown in a comparison of Euclidean distance, Pearson correlation and γ-divergence applied to multi-spectral images.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-20.pdf,2011,100.0,"Multispectral image characterization by partial generalized covariance A general method is presented for the assessment of data attribute variability, which plays an important role in initial screening of multi-and high-dimensional data sets. Instead of the commonly used second centralized moment, known as variance, the proposed method allows a mathematically rigorous characterization of attribute sensitivity given not only Euclidean distances but partial data comparisons by general similarity measures. Depending on the choice of measure different spectral features get highlighted by attribute assessment, this way creating new image segmentation aspects, as shown in a comparison of Euclidean distance, Pearson correlation and γ-divergence applied to multi-spectral images."
A supervised strategy for deep kernel machine,"Florian Yger, Maxime Berar, Gilles Gasso, Alain Rakotomamonjy","1 - LITIS EA Université de Rouen / INSA de Rouen 4108, 76800 Saint Etienne du Rouvray France","This paper presents an alternative to the supervised KPCA based approach for learning a Multilayer Kernel Machine (MKM)  [1] . In our proposed procedure, the hidden layers are learnt in a supervised fashion based on kernel partial least squares regression. The main interest resides in a simplified learning scheme as the obtained hidden features are automatically ranked according to their correlation with the target outputs. The approach is illustrated on small scale real world applications and shows compelling evidences.",Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-21.pdf,2011,100.0,"A supervised strategy for deep kernel machine This paper presents an alternative to the supervised KPCA based approach for learning a Multilayer Kernel Machine (MKM)  [1] . In our proposed procedure, the hidden layers are learnt in a supervised fashion based on kernel partial least squares regression. The main interest resides in a simplified learning scheme as the obtained hidden features are automatically ranked according to their correlation with the target outputs. The approach is illustrated on small scale real world applications and shows compelling evidences."
Selecting from an infinite set of features in SVM,"Rémi Flamary, Florian Yger, Alain Rakotomamonjy","1 - LITIS EA Université de Rouen 4108, 76800 Saint Etienne du Rouvray France","Dealing with the continuous parameters of a feature extraction method has always been a difficult task that is usually solved by cross-validation. In this paper, we propose an active set algorithm for selecting automatically these parameters in a SVM classification context. Our experiments on texture recognition and BCI signal classification show that optimizing the feature parameters in a continuous space while learning the decision function yields to better performances than using fixed parameters obtained from a grid sampling.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-23.pdf,2011,100.0,"Selecting from an infinite set of features in SVM Dealing with the continuous parameters of a feature extraction method has always been a difficult task that is usually solved by cross-validation. In this paper, we propose an active set algorithm for selecting automatically these parameters in a SVM classification context. Our experiments on texture recognition and BCI signal classification show that optimizing the feature parameters in a continuous space while learning the decision function yields to better performances than using fixed parameters obtained from a grid sampling."
Hierarchical clustering for graph visualization,"Stéphan Clémençon, Hector De Arazoza, Fabrice Rossi, Viet-Chi Tran","1 - Institut Télécom Télécom ParisTech
2 - LTCI -UMR CNRS rue Barrault 5141 46, 75013 Paris France
3 - Facultad de Matemática y Computación Universidad de la Habana La Habana Cuba
6 - Laboratoire Paul Painlevé UMR CNRS No. 8524 Université Lille 1 59 655 Villeneuve d'Ascq Cedex France","This paper describes a graph visualization methodology based on hierarchical maximal modularity clustering, with interactive and significant coarsening and refining possibilities. An application of this method to HIV epidemic analysis in Cuba is outlined.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-24.pdf,2011,100.0,"Hierarchical clustering for graph visualization This paper describes a graph visualization methodology based on hierarchical maximal modularity clustering, with interactive and significant coarsening and refining possibilities. An application of this method to HIV epidemic analysis in Cuba is outlined."
Multi-Goal Path Planning Using Self-Organizing Map with Navigation Functions,"Jan Faigl, Jan Mačák",1 - Czech Technical University,"This paper presents a combination of Self-Organizing Map (SOM) approach and navigation functions in the Traveling Salesman Problem with segment goals where paths between goals have to respect obstacles. Hence, the problem is called multi-goal path planning. The problem arises from the inspection planning, where a path from which all points of the given polygonal environment have to be ""seen"". The proposed approach demonstrates applicability of SOM principles in such problems in which SOM has not yet been applied.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-26.pdf,2011,100.0,"Multi-Goal Path Planning Using Self-Organizing Map with Navigation Functions This paper presents a combination of Self-Organizing Map (SOM) approach and navigation functions in the Traveling Salesman Problem with segment goals where paths between goals have to respect obstacles. Hence, the problem is called multi-goal path planning. The problem arises from the inspection planning, where a path from which all points of the given polygonal environment have to be ""seen"". The proposed approach demonstrates applicability of SOM principles in such problems in which SOM has not yet been applied."
Effects of sparseness and randomness of pairwise distance matrix on t-SNE results,Eli Parviainen,"1 - BECS Aalto University Helsinki Finland
2 - MNIST and USPS
3 - Extended Yale Face Database B [12]
4 - 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3","We apply ideas from random graph theory to sparse pairwise distance matrices in dimension reduction. We use matrices with some short and some randomly chosen distances, and study effects of matrix sparseness and randomness on trustworthiness and continuity of t-SNE visualizations. The existing works have either concentrated on matrices with only short distances, or implemented heuristics with mixed distances without explaining the effects. We find that trustworthiness generally increases with randomness, but not without limit. Continuity is less affected, but drops if matrices become too random. Sparseness has little effect on continuity, but decreases trustworthiness. Decrease in quality appears sublinear, which suggests that sparse t-SNE could be made subquadratic in complexity without too much effect on quality.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-27.pdf,2011,100.0,"Effects of sparseness and randomness of pairwise distance matrix on t-SNE results We apply ideas from random graph theory to sparse pairwise distance matrices in dimension reduction. We use matrices with some short and some randomly chosen distances, and study effects of matrix sparseness and randomness on trustworthiness and continuity of t-SNE visualizations. The existing works have either concentrated on matrices with only short distances, or implemented heuristics with mixed distances without explaining the effects. We find that trustworthiness generally increases with randomness, but not without limit. Continuity is less affected, but drops if matrices become too random. Sparseness has little effect on continuity, but decreases trustworthiness. Decrease in quality appears sublinear, which suggests that sparse t-SNE could be made subquadratic in complexity without too much effect on quality."
Principal component analysis for unsupervised calibration of bio-inspired airow array sensors,"Michiel Dyck, Herbert Peremans",1 - Universiteit Antwerpen -Dept MTT-FTEW prinsstraat 13 2000 Antwerpen -Belgie,"This paper describes the automatic calibration of a set of air ow sensitive sensors on a robot exposed to unknown random air ow stimuli. This might support the idea that the cricket cercus neural system in the terminal abdominal ganglion is evolved by learning. The algorithm makes use of the singular value decomposition (SVD) and the known reduced model dimension of the system for learning the sensor array setup. The absolute orientation of the array can only be found in function of a reference ow or reference sensor which must be calibrated manually. When only a change in airow measure is needed, the reference sensor can be left uncalibrated.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-28.pdf,2011,98.93617021276596,"Principal component analysis for unsupervised calibration of bio-inspired airow array sensors This paper describes the automatic calibration of a set of air ow sensitive sensors on a robot exposed to unknown random air ow stimuli. This might support the idea that the cricket cercus neural system in the terminal abdominal ganglion is evolved by learning. The algorithm makes use of the singular value decomposition (SVD) and the known reduced model dimension of the system for learning the sensor array setup. The absolute orientation of the array can only be found in function of a reference ow or reference sensor which must be calibrated manually. When only a change in airow measure is needed, the reference sensor can be left uncalibrated."
A post-processing strategy for SVM learning from unbalanced data,"Haydemar Núñez, Luis Gonzalez-Abril, Cecilio Angulo","1 - Faculty of Sciences. Los Ilustres Artificial Intelligence Laboratory Central University of Venezuela Urb. Valle Abajo 1020-A Caracas Venezuela
2 - -Qualitative Methods Research Group University of Seville Avda Ramon y Cajal s/n 41018 Seville Spain
3 - Knowledge Engineering Research Group Technical University of Catalonia Avda Víctor Balaguer 1 08800 Vilanova i la Geltrú Spain
4 - Research Intensification Universitat Politécnica de Catalunya 2008-2011","Standard learning algorithms may perform poorly when learning from unbalanced datasets. Based on the Fisher's discriminant analysis, a post-processing strategy is introduced to deal datasets with significant imbalance in the data distribution. A new bias is defined, which reduces skew towards the minority class. Empirical results from experiments for a learned SVM model on twelve UCI datasets indicates that the proposed solution improves the original SVM, and they also improve those reported when using a z-SVM, in terms of g-mean and sensitivity.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-29.pdf,2011,100.0,"A post-processing strategy for SVM learning from unbalanced data Standard learning algorithms may perform poorly when learning from unbalanced datasets. Based on the Fisher's discriminant analysis, a post-processing strategy is introduced to deal datasets with significant imbalance in the data distribution. A new bias is defined, which reduces skew towards the minority class. Empirical results from experiments for a learned SVM model on twelve UCI datasets indicates that the proposed solution improves the original SVM, and they also improve those reported when using a z-SVM, in terms of g-mean and sensitivity."
Seeing is believing: The importance of visualization in real-world machine learning applications,"Alfredo Vellido, José Martín, Fabrice Rossi, Paulo Lisboa","1 - Departament de Llenguatges i Sistemes Informàtics Universitat Politècnica de Catalunya 08034 Barcelona Spain
2 - Departament d'Enginyeria Electrònica Escola Tècnica Superior d'Enginyeria University of Valencia 46100 Burjassot Valencia) Spain
3 - Computer Science & Networks Department Télécom ParisTech F-75634 Paris France
4 - Department of Mathematics and Statistics Liverpool John Moores University Byrom Street L3 3AF Liverpool UK","The increasing availability of data sets with a huge amount of information, coded in many different features, justifies the research on new methods of knowledge extraction: the great challenge is the translation of the raw data into useful information that can be used to improve decisionmaking processes, detect relevant profiles, find out relationships among features, etc. It is undoubtedly true that a picture is worth a thousand words, what makes visualization methods be likely the most appealing and one of the most relevant kinds of knowledge extration methods. At ESANN 2011, the special session ""Seeing is believing: The importance of visualization in real-world machine learning applications"" reflects some of the main emerging topics in the field. This tutorial prefaces the session, summarizing some of its contributions, while also providing some clues to the current state and the near future of visualization methods within the framework of Machine Learning.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-3.pdf,2011,100.0,"Seeing is believing: The importance of visualization in real-world machine learning applications The increasing availability of data sets with a huge amount of information, coded in many different features, justifies the research on new methods of knowledge extraction: the great challenge is the translation of the raw data into useful information that can be used to improve decisionmaking processes, detect relevant profiles, find out relationships among features, etc. It is undoubtedly true that a picture is worth a thousand words, what makes visualization methods be likely the most appealing and one of the most relevant kinds of knowledge extration methods. At ESANN 2011, the special session ""Seeing is believing: The importance of visualization in real-world machine learning applications"" reflects some of the main emerging topics in the field. This tutorial prefaces the session, summarizing some of its contributions, while also providing some clues to the current state and the near future of visualization methods within the framework of Machine Learning."
Approaches for Automatic Speaker Recognition in a Binaural Humanoid Context,"Karim Youssef, Bastien Breteau, Sylvain Argentieri, Jean-Luc Zarader, Zefeng Wang","1 - Institut des Systèmes Intelligents et de Robotique Université Pierre et Marie Curie Paris 6 4, Place Jussieu 75252, Cedex 05 Paris France","This paper presents two methods of Automatic Speaker Recognition (ASkR). ASkR has been largely studied in the last decades, but in most cases in mono-microphone or microphone array contexts. Our systems are placed in a binaural humanoid context where the signals captured by both ears of a humanoid robot will be exploited to perform the ASkR. Both methods use Mel-Frequency Cepstral Coding (MFCC), but one performs the classification with Predictive Neural Networks (PNN) and the other performs it with Gaussian Mixture Models (GMM). Tests are made on a database simulating the functioning of the human ears. They study the influence of noise, reverberations and speaker spatial position on the recognition rate.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-30.pdf,2011,100.0,"Approaches for Automatic Speaker Recognition in a Binaural Humanoid Context This paper presents two methods of Automatic Speaker Recognition (ASkR). ASkR has been largely studied in the last decades, but in most cases in mono-microphone or microphone array contexts. Our systems are placed in a binaural humanoid context where the signals captured by both ears of a humanoid robot will be exploited to perform the ASkR. Both methods use Mel-Frequency Cepstral Coding (MFCC), but one performs the classification with Predictive Neural Networks (PNN) and the other performs it with Gaussian Mixture Models (GMM). Tests are made on a database simulating the functioning of the human ears. They study the influence of noise, reverberations and speaker spatial position on the recognition rate."
Negatively Correlated Echo State Networks,"Ali Rodan, Peter Tiňo",1 - School of Computer Science The University of Birmingham B15 2TT Birmingham United Kingdom,"Echo State Network (ESN) is a special type of recurrent neural network with fixed random recurrent part (reservoir) and a trainable reservoir-to-output readout mapping (typically obtained by linear regression). In this work we utilise an ensemble of ESNs with diverse reservoirs whose collective read-out is obtained through Negative Correlation Learning (NCL) of ensemble of Multi-Layer Perceptrons (MLP), where each individual MPL realises the readout from a single ESN. Experimental results on three data sets confirm that, compared with both single ESN and flat ensembles of ESNs, NCL based ESN ensembles achieve better generalisation performance.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-31.pdf,2011,100.0,"Negatively Correlated Echo State Networks Echo State Network (ESN) is a special type of recurrent neural network with fixed random recurrent part (reservoir) and a trainable reservoir-to-output readout mapping (typically obtained by linear regression). In this work we utilise an ensemble of ESNs with diverse reservoirs whose collective read-out is obtained through Negative Correlation Learning (NCL) of ensemble of Multi-Layer Perceptrons (MLP), where each individual MPL realises the readout from a single ESN. Experimental results on three data sets confirm that, compared with both single ESN and flat ensembles of ESNs, NCL based ESN ensembles achieve better generalisation performance."
Classifying mental states with machine learning algorithms using alpha activity decline,"Carina Walter, Gabriele Cierniak, Peter Gerjets, Wolfgang Rosenstiel, Martin Bogdan","1 - Department of Computer Engineering Eberhard-Karls University Tuebingen Sand 13 72076 Tuebingen Germany
2 - Department of Computer Engineering University of Leipzig Johannisgasse 26 04103 Leipzig Germany
3 - Knowledge Media Research Center Konrad Adenauer-Str. 40 72072 Tuebingen -Germany","This publication aims at developing computer based learning environments adapting to learners' individual cognitive condition. The adaptive mechanism, based on Brain-Computer-Interface (BCI) methodology, relays on electroencephalogram (EEG)-data to diagnose learners' mental states. A first within-subjects study (10 students) was accomplished aiming at differentiating between states of learning and non-learning by means of EEG-data. Support-Vector-Machines classified characteristics in the EEG-signals for these two different stimuli on average as 74.55% correct. For individual students the percentage of correct classification reached 92.22%. The results indicate that continuous EEG-data combined with BCI methodology is a promising approach to measuring learners' mental states online.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-35.pdf,2011,100.0,"Classifying mental states with machine learning algorithms using alpha activity decline This publication aims at developing computer based learning environments adapting to learners' individual cognitive condition. The adaptive mechanism, based on Brain-Computer-Interface (BCI) methodology, relays on electroencephalogram (EEG)-data to diagnose learners' mental states. A first within-subjects study (10 students) was accomplished aiming at differentiating between states of learning and non-learning by means of EEG-data. Support-Vector-Machines classified characteristics in the EEG-signals for these two different stimuli on average as 74.55% correct. For individual students the percentage of correct classification reached 92.22%. The results indicate that continuous EEG-data combined with BCI methodology is a promising approach to measuring learners' mental states online."
Adaptive Kernel Smoothing Regression for Spatio-Temporal Environmental Datasets,"Federico Pouzols, Amaury Lendasse","1 - Dept. of Information and Computer Science Aalto University P.O. Box 15400 FI-00076 Aalto, Espoo Finland","This paper describes a method for performing kernel smoothing regression in an incremental, adaptive manner. A simple and fast combination of incremental vector quantization with kernel smoothing regression using adaptive bandwidth is shown to be effective for online modeling of environmental datasets. The method is illustrated on openly available datasets corresponding to the Tropical Atmosphere Ocean array and the Helsinki Commission hydrographic database for the Baltic Sea.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-36.pdf,2011,100.0,"Adaptive Kernel Smoothing Regression for Spatio-Temporal Environmental Datasets This paper describes a method for performing kernel smoothing regression in an incremental, adaptive manner. A simple and fast combination of incremental vector quantization with kernel smoothing regression using adaptive bandwidth is shown to be effective for online modeling of environmental datasets. The method is illustrated on openly available datasets corresponding to the Tropical Atmosphere Ocean array and the Helsinki Commission hydrographic database for the Baltic Sea."
Fast Data Mining with Sparse Chemical Graph Fingerprints by Estimating the Probability of Unique Patterns,"Georg Hinselmann, Lars Rosenbaum, Andreas Jahn, Andreas Zell",1 - Department for Computer Science University of Tübingen Tübingen Germany,The aim of this work is to introduce a modification of chemical graphs fingerprints for data mining. The algorithm reduces the number of features by taking the probability of producing an unique feature at a specific search depth into account. We observed the probability of generating a non-unique feature depending on a search parameter (which leads to a power-law growths of features) and modeled it by a sigmoid function. This function was integrated into a fingerprinting routine to reduce the features according to their probability. The predictive performance was convincing with a considerable speedup for the training of a linear support vector machine for sparse instances.,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-37.pdf,2011,100.0,Fast Data Mining with Sparse Chemical Graph Fingerprints by Estimating the Probability of Unique Patterns The aim of this work is to introduce a modification of chemical graphs fingerprints for data mining. The algorithm reduces the number of features by taking the probability of producing an unique feature at a specific search depth into account. We observed the probability of generating a non-unique feature depending on a search parameter (which leads to a power-law growths of features) and modeled it by a sigmoid function. This function was integrated into a fingerprinting routine to reduce the features according to their probability. The predictive performance was convincing with a considerable speedup for the training of a linear support vector machine for sparse instances.
Nearest neighbors and correlation dimension for dimensionality estimation. Application to factor analysis of real biological time series data,"J Lapuyade-Lahorgue, A Mohammad-Djafari","1 - Laboratoire des signaux et systèmes (L2S) -Supelec
2 - UMR 8506 CNRS-SUPELEC UNIV PARIS SUD plateau de Moulon 3 rue Joliot-Curie 91192 GIF-SUR-YVETTE Cedex France","Determining the number of components in dimensionality reduction techniques is still one of the open problems of research on data analysis. These methods are often used in knowledge extraction of multivariate great dimensional data, but very often the number of components is assumed to be known. One of the classical methods to estimate this dimensionality is based on the Principal Components Analysis (PCA) eigenvalues  [1, 2] . However, this method supposes that the model is linear and the signals are Gaussian. To be able to consider non-linear and non-Gaussian cases, we propose in this paper ""measure based methods"" as nearest neighbors dimension and correlation dimension. The comparaison between the three methods is evaluated both with simulated data and with real biological data, which are gene expression time series. The main goal of this study is to estimate the minimum number of factors. * This work is a part of ERASYSBIO-C5Sys European project ""circadian and cell cycle clock systems in cancer"" http://www.erasysbio.net/index.php?index=272",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-38.pdf,2011,99.64664310954063,"Nearest neighbors and correlation dimension for dimensionality estimation. Application to factor analysis of real biological time series data Determining the number of components in dimensionality reduction techniques is still one of the open problems of research on data analysis. These methods are often used in knowledge extraction of multivariate great dimensional data, but very often the number of components is assumed to be known. One of the classical methods to estimate this dimensionality is based on the Principal Components Analysis (PCA) eigenvalues  [1, 2] . However, this method supposes that the model is linear and the signals are Gaussian. To be able to consider non-linear and non-Gaussian cases, we propose in this paper ""measure based methods"" as nearest neighbors dimension and correlation dimension. The comparaison between the three methods is evaluated both with simulated data and with real biological data, which are gene expression time series. The main goal of this study is to estimate the minimum number of factors. * This work is a part of ERASYSBIO-C5Sys European project ""circadian and cell cycle clock systems in cancer"" http://www.erasysbio.net/index.php?index=272"
An Introduction to Deep Learning,"Ludovic Arnold, Sébastien Rebecchi, Sylvain Chevallier, Hélène Paugam-Moisy","1 - LIMSI UMR3251 F-91403 Orsay France
2 - Université Lyon 2 LIRIS UMR5205 F-69676 Bron France
3 - UMR8623 INRIA-Saclay, LRI 1-Tao
4 - Université Paris-Sud 11 F-91405 Orsay France",The deep learning paradigm tackles problems on which shallow architectures (e.g. SVM) are affected by the curse of dimensionality. As part of a two-stage learning scheme involving multiple layers of nonlinear processing a set of statistically robust features is automatically extracted from the data. The present tutorial introducing the ESANN deep learning special session details the state-of-the-art models and summarizes the current understanding of this learning approach which is a reference for many difficult classification tasks.,Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-4.pdf,2011,100.0,An Introduction to Deep Learning The deep learning paradigm tackles problems on which shallow architectures (e.g. SVM) are affected by the curse of dimensionality. As part of a two-stage learning scheme involving multiple layers of nonlinear processing a set of statistically robust features is automatically extracted from the data. The present tutorial introducing the ESANN deep learning special session details the state-of-the-art models and summarizes the current understanding of this learning approach which is a reference for many difficult classification tasks.
Statistical properties of the 'Hopfield estimator' of dynamical systems,"Miguel Atencia, Gonzalo Joya","1 - Dept of Applied Mathematics University of Málaga Campus de Teatinos 29071 Málaga Spain
2 - Dept of Electronics Technology University of Málaga","This paper analyses the statistical properties of a method for estimating the parameters of systems defined by ordinary differential equations. Previously, this estimator was defined as an adapted version of Hopfield neural networks, and its convergence and robustness with respect to signal disturbances were proved, even when parameters are time-varying. This contribution aims at analysing the estimation error by performing a set of simulations where a random noise with known probability distribution is added to signals. It is shown that, asymptotically, the estimator is unbiased and its variance vanishes. Further theoretical work is being undertaken in order to rigourously support these empirical findings.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-40.pdf,2011,85.91549295774648,"Statistical properties of the 'Hopfield estimator' of dynamical systems This paper analyses the statistical properties of a method for estimating the parameters of systems defined by ordinary differential equations. Previously, this estimator was defined as an adapted version of Hopfield neural networks, and its convergence and robustness with respect to signal disturbances were proved, even when parameters are time-varying. This contribution aims at analysing the estimation error by performing a set of simulations where a random noise with known probability distribution is added to signals. It is shown that, asymptotically, the estimator is unbiased and its variance vanishes. Further theoretical work is being undertaken in order to rigourously support these empirical findings."
Single-trial P300 detection with Kalman filtering and SVMs,"Lucie Daubigney, Olivier Pietquin",1 - SUPELEC / UMI 2958 (GeorgiaTech -CNRS 2 rue Edouard Belin 57070 Metz France,"Brain Computer Interfaces (BCI) are systems enabling humans to communicate with machines through signals generated by the brain. Several kinds of signals can be envisioned as well as means to measure them. In this paper we are particularly interested in even-related brain potentials (ERP) and especially visually-evoked potential signals (P300) measured with surface electroencephalograms (EEG). When the human is stimulated with visual inputs, the P300 signals arise about 300 ms after the visual stimulus has been received. Yet, the EEG signal is often very noisy which makes the P300 detection hard. It is customary to use an average of several trials to enhance the P300 signal and reduce the random noise but this results in a lower bit rate of the interface. In this contribution, we propose a novel approach to P300 detection using Kalman filtering and SVMs. Experiments show that this method is a promising step toward single-trial detection of P300.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-41.pdf,2011,100.0,"Single-trial P300 detection with Kalman filtering and SVMs Brain Computer Interfaces (BCI) are systems enabling humans to communicate with machines through signals generated by the brain. Several kinds of signals can be envisioned as well as means to measure them. In this paper we are particularly interested in even-related brain potentials (ERP) and especially visually-evoked potential signals (P300) measured with surface electroencephalograms (EEG). When the human is stimulated with visual inputs, the P300 signals arise about 300 ms after the visual stimulus has been received. Yet, the EEG signal is often very noisy which makes the P300 detection hard. It is customary to use an average of several trials to enhance the P300 signal and reduce the random noise but this results in a lower bit rate of the interface. In this contribution, we propose a novel approach to P300 detection using Kalman filtering and SVMs. Experiments show that this method is a promising step toward single-trial detection of P300."
Comparison of the Complex Valued and Real Valued Neural Networks Trained with Gradient Descent and Random Search Algorithms,"Hans Zimmermann, Alexey Minin, Victoria Kusherbaeva","1 - Siemens AG -Corporate Technology Muenchen Germany
2 - Technischen Universitat Muenchen -Robotics dept Muenchen Germany
3 - Siemens OOO-Corporate Technology St Petersburg Russia",Complex Valued Neural Network is one of the open topics in the machine learning society. In this paper we will try to go through the problems of the complex valued neural networks gradients computations by combining the global and local optimization algorithms. The outcome of the current research is the combined global-local algorithm for training the complex valued feed forward neural network which is appropriate for the considered chaotic problem.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-42.pdf,2011,100.0,Comparison of the Complex Valued and Real Valued Neural Networks Trained with Gradient Descent and Random Search Algorithms Complex Valued Neural Network is one of the open topics in the machine learning society. In this paper we will try to go through the problems of the complex valued neural networks gradients computations by combining the global and local optimization algorithms. The outcome of the current research is the combined global-local algorithm for training the complex valued feed forward neural network which is appropriate for the considered chaotic problem.
Sparse LS-SVMs with L 0 -norm minimization,"J López, K De Brabanter, J Dorronsoro, J Suykens, De Brabanter, Leuven Dorronsoro","1 - Departamento de Ingeniería Informática-IIC C/ Francisco Tomás y Valiente 11 Universidad Autónoma de Madrid (UAM) 28049 Madrid Spain
2 - Katholieke Universiteit Leuven (K.U. Leuven) Departement Electrotechniek (ESAT-SCD-SISTA Kasteelpark Arenberg 10 B-3001 Leuven (Heverlee) Belgium","Least-Squares Support Vector Machines (LS-SVMs) have been successfully applied in many classification and regression tasks. Their main drawback is the lack of sparseness of the final models. Thus, a procedure to sparsify LS-SVMs is a frequent desideratum. In this paper, we adapt to the LS-SVM case a recent work for sparsifying classical SVM classifiers, which is based on an iterative approximation to the L0-norm. Experiments on real-world classification and regression datasets illustrate that this adaptation achieves very sparse models, without significant loss of accuracy compared to standard LS-SVMs or SVMs.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-43.pdf,2011,90.2439024390244,"Sparse LS-SVMs with L 0 -norm minimization Least-Squares Support Vector Machines (LS-SVMs) have been successfully applied in many classification and regression tasks. Their main drawback is the lack of sparseness of the final models. Thus, a procedure to sparsify LS-SVMs is a frequent desideratum. In this paper, we adapt to the LS-SVM case a recent work for sparsifying classical SVM classifiers, which is based on an iterative approximation to the L0-norm. Experiments on real-world classification and regression datasets illustrate that this adaptation achieves very sparse models, without significant loss of accuracy compared to standard LS-SVMs or SVMs."
A probabilistic approach to the visual exploration of G Protein-Coupled Receptor sequences,"Alfredo Vellido, Martha Cárdenas, Iván Olier, Xavier Rovira, Jesús Giraldo","1 - Departament de Llenguatges i Sistemes Informàtics Universitat Politècnica de Catalunya 08034 Barcelona Spain
3 - School of Psychological Sciences Manchester -United Kingdom 3-Institut de Neurociències The University of Manchester Unitat de Bioestadística Universitat Autònoma de Barcelona M13 9PL, 08193 Bellaterra (Barcelona) Spain","The study of G protein-coupled receptors (GPCRs) is of great interest in pharmaceutical research, but only a few of their 3D structures are known at present. On the contrary, their amino acid sequences are known and accessible. Sequence analysis can provide new insight on GPCR function. Here, we use a kernel-based statistical machine learning model for the visual exploration of GPCR functional groups from their sequences. This is based on the rich information provided by the model regarding the probability of each sequence belonging to a certain receptor group.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-44.pdf,2011,100.0,"A probabilistic approach to the visual exploration of G Protein-Coupled Receptor sequences The study of G protein-coupled receptors (GPCRs) is of great interest in pharmaceutical research, but only a few of their 3D structures are known at present. On the contrary, their amino acid sequences are known and accessible. Sequence analysis can provide new insight on GPCR function. Here, we use a kernel-based statistical machine learning model for the visual exploration of GPCR functional groups from their sequences. This is based on the rich information provided by the model regarding the probability of each sequence belonging to a certain receptor group."
Visual place recognition using Bayesian Filtering with Markov Chains *,"Mathieu Dubois, Hervé Guillaume, Emmanuelle Frenoux, Philippe Tarroux","1 - Univ Paris-Sud -Dept of Computer Science Orsay F-91405 France
2 - LIMSI -CNRS B.P. 133 F-91403 France
8 - Ecole Normale Supérieure 45 rue d'Ulm F-75230 Paris France","We present a novel idea to use Bayesian filtering in the case of place recognition. More precisely, our system combines global image characterization, Learned Vector Quantization, Markov chains and Bayesian filtering. The goal is to integrate several images seen by a robot during exploration of the environment and the dependency between them. We present our system and the new Bayesian filtering algorithm. Our system has been evaluated on a standard database and shows promising results.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-45.pdf,2011,75.36231884057972,"Visual place recognition using Bayesian Filtering with Markov Chains * We present a novel idea to use Bayesian filtering in the case of place recognition. More precisely, our system combines global image characterization, Learned Vector Quantization, Markov chains and Bayesian filtering. The goal is to integrate several images seen by a robot during exploration of the environment and the dependency between them. We present our system and the new Bayesian filtering algorithm. Our system has been evaluated on a standard database and shows promising results."
Reservoir regularization stabilizes learning of Echo State Networks with output feedback,"René Reinhart, Jochen Steil",1 - Research Institute for Cognition and Robotics Bielefeld University Universitätsstr. 25 33615 Bielefed Germany,Output feedback is crucial for autonomous and parameterized pattern generation with reservoir networks. Read-out learning can lead to error amplification in these settings and therefore regularization is important for both generalization and reduction of error amplification. We show that regularization of the inner reservoir network mitigates parameter dependencies and boosts the task-specific performance.,Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-48.pdf,2011,100.0,Reservoir regularization stabilizes learning of Echo State Networks with output feedback Output feedback is crucial for autonomous and parameterized pattern generation with reservoir networks. Read-out learning can lead to error amplification in these settings and therefore regularization is important for both generalization and reduction of error amplification. We show that regularization of the inner reservoir network mitigates parameter dependencies and boosts the task-specific performance.
Locating Anomalies Using Bayesian Factorizations and Masks,"Li Yao, Amaury Lendasse, Francesco Corona",1 - Department of Information and Computer Science School of Science and Technology Aalto University Finland,"A plethora of methods have been developed to handle anomaly detection in various application domains. This work focuses on locating anomalies inside a categorical data set without assuming any specific domain knowledge. By exploiting the conditional dependence and independence relationships among data attributes, not only can data analysts recognize the anomaly, but also locate the potentially anomalous attributes inside an anomalous instance following its masks. Masks are geometrically generated based on the factorization of the joint probability from a Bayesian network automatically learnt from the given data set.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-49.pdf,2011,100.0,"Locating Anomalies Using Bayesian Factorizations and Masks A plethora of methods have been developed to handle anomaly detection in various application domains. This work focuses on locating anomalies inside a categorical data set without assuming any specific domain knowledge. By exploiting the conditional dependence and independence relationships among data attributes, not only can data analysts recognize the anomaly, but also locate the potentially anomalous attributes inside an anomalous instance following its masks. Masks are geometrically generated based on the factorization of the joint probability from a Bayesian network automatically learnt from the given data set."
Recent Trends in Computational Intelligence in Life Sciences,"Udo Seiffert, Frank-Michael Schleif, Dietlind Zühlke","1 - Fraunhofer IFF Magdeburg Dept. Biosystems Engineering Sandtorstrasse 22 39106 Magdeburg Germany
2 - Institute of Electronics University of Magdeburg Signal Processing and Communications P.O. Box 4120 39016 Magdeburg Germany
3 - AG Theoretical Computer Science -University of Bielefeld
4 - Universitätsstrasse 21-23 33615 Bielefeld Germany
5 - Dept. Information Systems Aachen University Ahornstrasse 55 52056 Aachen Germany
6 - Dept. Life Science Informatics Fraunhofer FIT Sankt Augustin Schloss Birlinghoven 53754 Sankt Augustin Germany","Computational intelligence generally comprises a rather large set of -in a wider sense -adaptive and human-like data analysis and modelling methods. Due to some superior features -such as generalisation, trainability, coping with incomplete and inconsistent data, etc.computational intelligence has found its way into numerous applications in almost all scientific disciplines. A very prominent field among them are life sciences that are characterised by some unique requirements in terms of data structure and analysis.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-5.pdf,2011,70.0,"Recent Trends in Computational Intelligence in Life Sciences Computational intelligence generally comprises a rather large set of -in a wider sense -adaptive and human-like data analysis and modelling methods. Due to some superior features -such as generalisation, trainability, coping with incomplete and inconsistent data, etc.computational intelligence has found its way into numerous applications in almost all scientific disciplines. A very prominent field among them are life sciences that are characterised by some unique requirements in terms of data structure and analysis."
Mutual information for feature selection with missing data,"Gauthier Doquire, Michel Verleysen",1 - ICTEAM/Machine Learning Group Place du Levant 3 Université catholique de Louvain 1348 Louvain-la-Neuve Belgium,"Feature selection is an important task for many machine learning applications; moreover missing data are encoutered very often in practice. This paper proposes to adapt a nearest neighbors based mutual information estimator to handle missing data and to use it to achieve feature selection. Results on artificial and real world datasets show that the method is able to select important features without the need for any imputation algorithm. Moreover, experiments also indicate that selecting the features before imputing the data generally increases the precision of the prediction models.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-50.pdf,2011,100.0,"Mutual information for feature selection with missing data Feature selection is an important task for many machine learning applications; moreover missing data are encoutered very often in practice. This paper proposes to adapt a nearest neighbors based mutual information estimator to handle missing data and to use it to achieve feature selection. Results on artificial and real world datasets show that the method is able to select important features without the need for any imputation algorithm. Moreover, experiments also indicate that selecting the features before imputing the data generally increases the precision of the prediction models."
Mutual information based feature selection for mixed data,"Gauthier Doquire, Michel Verleysen",1 - ICTEAM/Machine Learning Group Place du Levant 3 Université Catholique de Louvain 1348 Louvain-la-Neuve Belgium,"The problem of feature selection is crucial for many applications and has thus been studied extensively. However, most of the existing methods are designed to handle data consisting only in categorical or in real-valued features while a mix of both kinds of features is often encountered in practice. This paper proposes an approach based on mutual information and the maximal Relevance minimal Redundancy principle to handle the case of mixed data. It combines aspects of both wrapper and filter methods and is well suited for regression problems. Experiments on artificial and real-world datasets show the interest of the methodology.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-51.pdf,2011,100.0,"Mutual information based feature selection for mixed data The problem of feature selection is crucial for many applications and has thus been studied extensively. However, most of the existing methods are designed to handle data consisting only in categorical or in real-valued features while a mix of both kinds of features is often encountered in practice. This paper proposes an approach based on mutual information and the maximal Relevance minimal Redundancy principle to handle the case of mixed data. It combines aspects of both wrapper and filter methods and is well suited for regression problems. Experiments on artificial and real-world datasets show the interest of the methodology."
Iterative multi-task sequence labeling for predicting structural properties of proteins,"Francis Maes, Julien Becker, Louis Wehenkel","1 - Dept of Electrical Engineering and Computer Science Institut Montefiore University of Liege B28, B-4000 Liege Belgium","Developing computational tools for predicting protein structural information given their amino acid sequence is of primary importance in protein science. Problems, such as the prediction of secondary structures, of solvent accessibility, or of disordered regions, can be expressed as sequence labeling problems and could be solved independently by existing machine learning based sequence labeling approaches. But, since these problems are closely related, we propose to rather approach them jointly in a multi-task approach. To this end, we introduce a new generic framework for iterative multi-task sequence labeling. We apply this -conceptually simple but quite effective -strategy to jointly solve a set of five protein annotation tasks. Our empirical results with two protein datasets show that the proposed strategy significantly outperforms the single-task approaches. * This paper presents research results of the Belgian Network BIOMAGNET (Bioinformatics and Modelling: from Genomes to Networks), funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, and of the EU FP7 PASCAL2 network of excellence. Julien Becker is recipient of a F.R.I.A. fellowship.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-52.pdf,2011,100.0,"Iterative multi-task sequence labeling for predicting structural properties of proteins Developing computational tools for predicting protein structural information given their amino acid sequence is of primary importance in protein science. Problems, such as the prediction of secondary structures, of solvent accessibility, or of disordered regions, can be expressed as sequence labeling problems and could be solved independently by existing machine learning based sequence labeling approaches. But, since these problems are closely related, we propose to rather approach them jointly in a multi-task approach. To this end, we introduce a new generic framework for iterative multi-task sequence labeling. We apply this -conceptually simple but quite effective -strategy to jointly solve a set of five protein annotation tasks. Our empirical results with two protein datasets show that the proposed strategy significantly outperforms the single-task approaches. * This paper presents research results of the Belgian Network BIOMAGNET (Bioinformatics and Modelling: from Genomes to Networks), funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, and of the EU FP7 PASCAL2 network of excellence. Julien Becker is recipient of a F.R.I.A. fellowship."
Multi-class Classification in the Presence of Labelling Errors,"Jakramate Bootkrajang, Ata Kabán",1 - School of Computer Science The University of Birmingham Edgbaston B15 2TT Birmingham United Kingdom,"Learning a classifier from a training set that contains labelling errors is a difficult, yet not very well studied problem. Here we present a model-based approach that extends multi-class quadratic normal discriminant analysis with a model of the mislabelling process. We demonstrate the benefits of this approach in terms of parameter recovery as well as improved classification performance, on both synthetic and real-world multiclass problems. We also obtain enhanced accuracy in comparison with a previous model-free approach.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-53.pdf,2011,66.12903225806453,"Multi-class Classification in the Presence of Labelling Errors Learning a classifier from a training set that contains labelling errors is a difficult, yet not very well studied problem. Here we present a model-based approach that extends multi-class quadratic normal discriminant analysis with a model of the mislabelling process. We demonstrate the benefits of this approach in terms of parameter recovery as well as improved classification performance, on both synthetic and real-world multiclass problems. We also obtain enhanced accuracy in comparison with a previous model-free approach."
Identification of sparse spatio-temporal features in Evoked Response Potentials,"Nisrine Jrad, Marco Congedo",1 - GIPSA-lab CNRS Grenoble Univ. 961 rue de la Houille Blanche 38402 GRENOBLE Cedex France,"Electroencephalographic Evoked Response Potentials (ERP)s exhibit distinct and individualized spatial and temporal characteristics. Identification of spatio-temporal features improves single-trial classification performance and allows a better understanding of the underlying physiology. This paper presents a method for analyzing the spatio-temporal characteristics associated with Error related Potentials (ErrP)s. First, a resampling procedure based on Global Field Power (GFP) extracts temporal features. Second, a spatially weighted SVM (sw-SVM) is proposed to learn a spatial filter optimizing the classification performance for each temporal feature. Third, the so obtained ensemble of sw-SVM classifiers are combined using a weighted combination of all sw-SVM outputs. Results indicate that inclusion of temporal features provides useful insight regarding the spatio-temporal characteristics of error potentials.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-54.pdf,2011,100.0,"Identification of sparse spatio-temporal features in Evoked Response Potentials Electroencephalographic Evoked Response Potentials (ERP)s exhibit distinct and individualized spatial and temporal characteristics. Identification of spatio-temporal features improves single-trial classification performance and allows a better understanding of the underlying physiology. This paper presents a method for analyzing the spatio-temporal characteristics associated with Error related Potentials (ErrP)s. First, a resampling procedure based on Global Field Power (GFP) extracts temporal features. Second, a spatially weighted SVM (sw-SVM) is proposed to learn a spatial filter optimizing the classification performance for each temporal feature. Third, the so obtained ensemble of sw-SVM classifiers are combined using a weighted combination of all sw-SVM outputs. Results indicate that inclusion of temporal features provides useful insight regarding the spatio-temporal characteristics of error potentials."
Thresholds tuning of a neuro-symbolic net controlling a behavior-based robotic system,"M Staffa, S Rossi, M De Gregorio, E Burattini","1 - Dipartimento di Informatica e Sistemistica Università di Napoli ""Federico II"" Piazzale Tecchio Naples Italy
2 - Dipartimento di Scienze Fisiche Università di Napoli ""Federico II"" Via Cintia Naples Italy
3 - Istituto di Cibernetica ""E. Caianiello"" -CNR via Campi Flegrei Pozzuoli Italy",In this paper we present the results obtained by adopting an evolutionary approach to tune some critical neuron thresholds of a neuro-symbolic net that regulates the overall emergent behavior of a behavior-based robotic system.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-55.pdf,2011,100.0,Thresholds tuning of a neuro-symbolic net controlling a behavior-based robotic system In this paper we present the results obtained by adopting an evolutionary approach to tune some critical neuron thresholds of a neuro-symbolic net that regulates the overall emergent behavior of a behavior-based robotic system.
Analysis of a Reinforcement Learning algorithm using Self-Organizing Maps,"Vicente Buendía-Ramón, Emilio Soria-Olivas, José Martín-Guerrero, Pablo Escandell-Montero, José Martínez-Martínez","1 - Department of Electronic Engineering CL. Dr. Moliner University of Valencia 50 46100 Burjassot, Valencia Spain",The scenario of this work is defined by the need of many Machine Learning algorithms to tune a number of parameters that define its behavior; the resulting performance can be evaluated with different indices. The relationship between parameters and performance may be neither linear nor straightforward. This work proposes a qualitative approach to the afore-mentioned relationship by using Self-Organizing Maps due to their visual information processing. The approach is evaluated in the framework of Reinforcement Learning algorithms.,Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-56.pdf,2011,100.0,Analysis of a Reinforcement Learning algorithm using Self-Organizing Maps The scenario of this work is defined by the need of many Machine Learning algorithms to tune a number of parameters that define its behavior; the resulting performance can be evaluated with different indices. The relationship between parameters and performance may be neither linear nor straightforward. This work proposes a qualitative approach to the afore-mentioned relationship by using Self-Organizing Maps due to their visual information processing. The approach is evaluated in the framework of Reinforcement Learning algorithms.
A Multi-kernel Framework for Inductive Semi-supervised Learning,"Xilan Tian, Gilles Gasso, Stéphane Canu",1 - LITIS EA4108 -INSA de Rouen St Etienne du Rouvray France,We investigate the benefit of combining both cluster assumption and manifold assumption underlying most of the semi-supervised algorithms using the flexibility and the efficiency of multi-kernel learning. The multiple kernel version of Transductive SVM (a cluster assumption based approach) is proposed and it is solved based on DC (Difference of Convex functions) programming. Promising results on benchmark data sets suggesting the effectiveness of proposed work.,Semi-supervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-57.pdf,2011,100.0,A Multi-kernel Framework for Inductive Semi-supervised Learning We investigate the benefit of combining both cluster assumption and manifold assumption underlying most of the semi-supervised algorithms using the flexibility and the efficiency of multi-kernel learning. The multiple kernel version of Transductive SVM (a cluster assumption based approach) is proposed and it is solved based on DC (Difference of Convex functions) programming. Promising results on benchmark data sets suggesting the effectiveness of proposed work.
SO-VAT: Self-Organizing Visual Assessment of cluster Tendency for large data sets,"Enrique Pelayo, Carlos Orrite, David Buldain",1 - Aragon Institute for Engineering Research University of Zaragoza SPAIN,"A new method, Self-Organizing Visual Assessment of cluster Tendency (SO-VAT), is given for visually assessing the cluster tendency in large data sets. It is based on training a SOM with the input samples, and then calculating the VAT image from a selected group of the generated neurons, selection that is done according to a certain density of activation. Tests with synthetic and real examples demonstrate that the new SO-VAT algorithm results in clearer images and shorter computing time than applying directly the VAT procedure to the whole input-data set.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-58.pdf,2011,100.0,"SO-VAT: Self-Organizing Visual Assessment of cluster Tendency for large data sets A new method, Self-Organizing Visual Assessment of cluster Tendency (SO-VAT), is given for visually assessing the cluster tendency in large data sets. It is based on training a SOM with the input samples, and then calculating the VAT image from a selected group of the generated neurons, selection that is done according to a certain density of activation. Tests with synthetic and real examples demonstrate that the new SO-VAT algorithm results in clearer images and shorter computing time than applying directly the VAT procedure to the whole input-data set."
Application of stochastic recurrent reinforcement learning to index trading,Denise Gorse,1 - Dept of Computer Science University College London Gower Street WC1E 6BT London UK,"A novel stochastic adaptation of the recurrent reinforcement learning (RRL) methodology is applied to daily, weekly, and monthly stock index data, and compared to results obtained elsewhere using genetic programming (GP). The data sets used have been a considered a challenging test for algorithmic trading. It is demonstrated that RRL can reliably outperform buy-and-hold for the higher frequency data, in contrast to GP which performed best for monthly data.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-60.pdf,2011,100.0,"Application of stochastic recurrent reinforcement learning to index trading A novel stochastic adaptation of the recurrent reinforcement learning (RRL) methodology is applied to daily, weekly, and monthly stock index data, and compared to results obtained elsewhere using genetic programming (GP). The data sets used have been a considered a challenging test for algorithmic trading. It is demonstrated that RRL can reliably outperform buy-and-hold for the higher frequency data, in contrast to GP which performed best for monthly data."
A Similarity Function with Local Feature Weighting for Structured Data,"Rubén Suárez, Rocío García-Durán, Fernando Fernández","1 - Universidad Carlos III de Madrid -Computer Science Department Avenida de la Universidad 30 28911 Leganés, Madrid Spain","The application of learning approaches as Kernel or Instance Based methods to tree structured data requires the definition of similarity functions able to deal with such data. A new similarity function for nearest prototype classification in relational data that follows a tree structure is defined in this paper. Its main characteristic is its capability to weight the importance of the different data features in different areas of the feature space. This work is built over two previous ideas: a similarity function for Local Feature Weighting (LFW), and a Relational Nearest Prototype Classification algorithm (RNPC). 
 A Similarity Function for Local Feature Weighting in Nearest Prototype Classification A Nearest Prototype Classifier, C, is composed of a set of N relational prototypes C = {p 1 , . . . , p N }. Each prototype p i is an instance of the training set (or a",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-61.pdf,2011,100.0,"A Similarity Function with Local Feature Weighting for Structured Data The application of learning approaches as Kernel or Instance Based methods to tree structured data requires the definition of similarity functions able to deal with such data. A new similarity function for nearest prototype classification in relational data that follows a tree structure is defined in this paper. Its main characteristic is its capability to weight the importance of the different data features in different areas of the feature space. This work is built over two previous ideas: a similarity function for Local Feature Weighting (LFW), and a Relational Nearest Prototype Classification algorithm (RNPC). 
 A Similarity Function for Local Feature Weighting in Nearest Prototype Classification A Nearest Prototype Classifier, C, is composed of a set of N relational prototypes C = {p 1 , . . . , p N }. Each prototype p i is an instance of the training set (or a"
D-VisionDraughts: a Draughts Player Neural Network That Learns by Reinforcement in a High Performance Environment,"Ayres Roberto, Araújo Barcelos, Rita Silva, Rivalino Júnior",1 - Federal University of Uberlandia -Computer Science Department Av Joao Naves de Avila 2121 Uberlandia MG Brazil,"This paper describes D-VisionDraughts, a distributed player agent for draughts which is based on Neural Networks trained by Temporal Differences. D-VisionDraughs is trained in a high performance environment and achieves a high level of play without expert game analysis and with minimum human intervention. D-VisionDraughts corresponds to a distributed version of the efficient agent player VisionDraughts. In this way, the main contributions of this paper consist on substituting the distributed Young Brothers Wait Concept algorithm (YBWC) for the serial alpha-beta search algorithm used in VisionDraughts and on measuring the impact of a high performance environment into the non-supervised learning abilities of the player. Evaluative tests proved that even a modest distributed version counting just on ten processors is able to reduce from about 83% the search runtime and to increase from 15% its capacity of winning.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-62.pdf,2011,82.30088495575221,"D-VisionDraughts: a Draughts Player Neural Network That Learns by Reinforcement in a High Performance Environment This paper describes D-VisionDraughts, a distributed player agent for draughts which is based on Neural Networks trained by Temporal Differences. D-VisionDraughs is trained in a high performance environment and achieves a high level of play without expert game analysis and with minimum human intervention. D-VisionDraughts corresponds to a distributed version of the efficient agent player VisionDraughts. In this way, the main contributions of this paper consist on substituting the distributed Young Brothers Wait Concept algorithm (YBWC) for the serial alpha-beta search algorithm used in VisionDraughts and on measuring the impact of a high performance environment into the non-supervised learning abilities of the player. Evaluative tests proved that even a modest distributed version counting just on ten processors is able to reduce from about 83% the search runtime and to increase from 15% its capacity of winning."
Multivariate class labeling in Robust Soft LVQ,"Petra Schneider, Tina Geweniger, Frank-Michael Schleif, Michael Biehl, Thomas Villmann","1 - School of Clinical and Experimental Medicine University of Birmingham B15 2TT Birmingham United Kingdom
2 - Department MPI -University of Applied Sciences Mittweida Technikumplatz 17 -09648 Mittweida Germany
3 - CITEC -University of Bielefeld Universitätsstrasse 21-23 -33615 Bielefeld Germany
4 - Institute for Mathematics and Computer Science University of Groningen P.O. Box 407 -9700 AK Groningen The Netherlands","We introduce a generalization of Robust Soft Learning Vector Quantization (RSLVQ). This algorithm for nearest prototype classification is derived from an explicit cost function and follows the dynamics of a stochastic gradient ascent. We generalize the RSLVQ cost function with respect to vectorial class labels: Probabilistic LVQ (PLVQ) allows to realize multivariate class memberships for prototypes and training samples, and the prototype labels can be learned from the data during training. We present experiments to demonstrate the new algorithm in practice.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-66.pdf,2011,100.0,"Multivariate class labeling in Robust Soft LVQ We introduce a generalization of Robust Soft Learning Vector Quantization (RSLVQ). This algorithm for nearest prototype classification is derived from an explicit cost function and follows the dynamics of a stochastic gradient ascent. We generalize the RSLVQ cost function with respect to vectorial class labels: Probabilistic LVQ (PLVQ) allows to realize multivariate class memberships for prototypes and training samples, and the prototype labels can be learned from the data during training. We present experiments to demonstrate the new algorithm in practice."
Anticipating Rewards in Continuous Time and Space with Echo State Networks and Actor-Critic Design,"Mohamed Oubbati, Markus Kächele, Petia Koprinkova-Hristova, Günther Palm","1 - Institute of Neural Information Processing University of Ulm Germany
3 - Institute of Control and System Research Bulgarian Academy of Sciences Bulgaria",In this paper we implement an echo state network within the concept of actor-critic design to obtain optimal control policy for a mobile robot. The robot is asked to anticipate future rewards/punishments and react accordingly. Experimental results show that the proposed approach is simple and effective.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-69.pdf,2011,100.0,Anticipating Rewards in Continuous Time and Space with Echo State Networks and Actor-Critic Design In this paper we implement an echo state network within the concept of actor-critic design to obtain optimal control policy for a mobile robot. The robot is asked to anticipate future rewards/punishments and react accordingly. Experimental results show that the proposed approach is simple and effective.
Information Theory Related Learning,"T Villmann, A Cichocki, J Principe","1 - Dep. of Mathematics/Natural & Computer Sciences Computational Intelligence Group University of Applied Sciences Mittweida Technikumplatz 17 09648 Mittweida GERMANY
2 - Riken Brain Sience Institute Lab. for Advanced Brain Signal Processing 2-1 Hirosawa 351-0198 Wako City, Saitama JAPAN
3 - University of Florida Computational NeuroEngineering Laboratory Gainesville 32611 FL USA","This is the introduction paper to a special session held on ESANN conference 2011. It reviews and highlights recent developments and new direction in information related learning, which is a fastly developing research area. These algorithms are based on the fundamental principles of information theory and relate them implicitly or explicitly to learning algoithms and strategies.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-7.pdf,2011,91.42857142857143,"Information Theory Related Learning This is the introduction paper to a special session held on ESANN conference 2011. It reviews and highlights recent developments and new direction in information related learning, which is a fastly developing research area. These algorithms are based on the fundamental principles of information theory and relate them implicitly or explicitly to learning algoithms and strategies."
Time Experiencing by Robotic Agents,"Michail Maniadakis, Marc Wittmann, Panos Trahanias","1 - -Foundation for Research and Technology -Hellas ICS Greece
2 - Institute for Frontier Areas of Psychology and Mental Health EAP Germany","Biological organisms perceive and act in the world based on spatiotemporal experiences and interpretations. However, artificial agents consider mainly the spatial relationships that exist in the world, typically ignoring its temporal aspects. In an attempt to direct research interest towards the fundamental issue of time experiencing, the current work explores two temporally different versions of a robotic rule switching task. An evolutionary process is employed to design a neural network controller capable of accomplishing both versions of the task. The systematic exploration of neural network dynamics revealed a self-organized time perception capacity in the agent's cognitive system that significantly facilitates the accomplishment of tasks, through modulation of the supplementary behavioural and cognitive processes.",Sequence and time processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-70.pdf,2011,100.0,"Time Experiencing by Robotic Agents Biological organisms perceive and act in the world based on spatiotemporal experiences and interpretations. However, artificial agents consider mainly the spatial relationships that exist in the world, typically ignoring its temporal aspects. In an attempt to direct research interest towards the fundamental issue of time experiencing, the current work explores two temporally different versions of a robotic rule switching task. An evolutionary process is employed to design a neural network controller capable of accomplishing both versions of the task. The systematic exploration of neural network dynamics revealed a self-organized time perception capacity in the agent's cognitive system that significantly facilitates the accomplishment of tasks, through modulation of the supplementary behavioural and cognitive processes."
Sparsity Issues in Self-Organizing-Maps for Structures,"Markus Hagenbuchner, Giovanni Da San Martino, Ah Tsoi, Alessandro Sperduti","1 - School of Computer Science and Software Engineering University of Wollongong Australia
2 - Department of Pure and Applied Mathematics University of Padova Italy
3 - Faculty of Information Technology Macau University of Science and Technology
5 - Macau SAR China","Recent developments with Self-Organizing Maps (SOMs) produced methods capable of clustering graph structured data onto a fixed dimensional display space. These methods have been applied successfully to a number of benchmark problems and produced state-of-the-art results. This paper discusses a limitation of the most powerful version of these SOMs, known as probability measure graph SOMs (PMGraphSOMs), viz., the sparsity induced by processing a large number of small graphs, which prevents a successful application of PMGraphSOM to such problems. An approach using the idea of compactifying the generated state space to address this sparsity problem is proposed. An application to an established benchmark problem, viz., the Mutag dataset in toxicology will show that the proposed method is effective when dealing with a large number of small graphs. Hence, this work fills a gap between the processing of a number of small graphs, and the processing of densely connected graphs using PMGraphSOMs.",Self-organizing maps and recurrent networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-71.pdf,2011,100.0,"Sparsity Issues in Self-Organizing-Maps for Structures Recent developments with Self-Organizing Maps (SOMs) produced methods capable of clustering graph structured data onto a fixed dimensional display space. These methods have been applied successfully to a number of benchmark problems and produced state-of-the-art results. This paper discusses a limitation of the most powerful version of these SOMs, known as probability measure graph SOMs (PMGraphSOMs), viz., the sparsity induced by processing a large number of small graphs, which prevents a successful application of PMGraphSOM to such problems. An approach using the idea of compactifying the generated state space to address this sparsity problem is proposed. An application to an established benchmark problem, viz., the Mutag dataset in toxicology will show that the proposed method is effective when dealing with a large number of small graphs. Hence, this work fills a gap between the processing of a number of small graphs, and the processing of densely connected graphs using PMGraphSOMs."
Mathematical Foundations of the Self Organized Neighbor Embedding (SONE) for Dimension Reduction and Visualization,"Kerstin Bunte, Frank-Michael Schleif, Sven Haase, Thomas Villmann, Ace Ach, Ach Ach, Ach Ach, Achach Ach, Ach Ach, Ach Ach, et al.","1 - Institute for Mathematics and Computer Science University of Groningen -Johann Bernoulli Nijenborgh 9 Groningen The Netherlands
2 - University of Bielefeld -CITEC Center of Excellence Bielefeld Germany
3 - -University of Apllied Sciences Mittweida Mittweida Germany
5 - Cam Cam Cam Cam Cam Cam Cam Cam Cam Cam Cam Cam Cam Cam Cam Cam Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Can Cas Cas Cas Cas Cas Ced Ced Ced Cel Cel Cel Cel Cel Cel Cel Cel Chr Chr Chr Chr Chr Chr
6 - Coh Col Com Com Com Com Com Com
7 - Cry Cry Cry Cup Cup Cup Cur Cur Cur Deb","In this paper we propose the generalization of the recently introduced Neighbor Embedding Exploratory Observation Machine (NE-XOM) for dimension reduction and visualization. We provide a general mathematical framework called Self Organized Neighbor Embedding (SONE). It treats the components, like data similarity measures and neighborhood functions, independently and easily changeable. And it enables the utilization of different divergences, based on the theory of Fréchet derivatives. In this way we propose a new dimension reduction and visualization algorithm, which can be easily adapted to the user specific request and the actual problem.",Information theory related learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-72.pdf,2011,100.0,"Mathematical Foundations of the Self Organized Neighbor Embedding (SONE) for Dimension Reduction and Visualization In this paper we propose the generalization of the recently introduced Neighbor Embedding Exploratory Observation Machine (NE-XOM) for dimension reduction and visualization. We provide a general mathematical framework called Self Organized Neighbor Embedding (SONE). It treats the components, like data similarity measures and neighborhood functions, independently and easily changeable. And it enables the utilization of different divergences, based on the theory of Fréchet derivatives. In this way we propose a new dimension reduction and visualization algorithm, which can be easily adapted to the user specific request and the actual problem."
Supervised dimension reduction mappings,"Kerstin Bunte, Michael Biehl, Barbara Hammer","1 - Institute for Mathematics and Computer Science University of Groningen -Johann Bernoulli Nijenborgh 9 Groningen The Netherlands
3 - University of Bielefeld -CITEC Center of Excellence Bielefeld Germany",We propose a general principle to extend dimension reduction tools to explicit dimension reduction mappings and we show that this can serve as an interface to incorporate prior knowledge in the form of class labels. We explicitly demonstrate this technique by combining locally linear mappings which result from matrix learning vector quantization schemes with the t-distributed stochastic neighbor embedding cost function. The technique is tested on several benchmark data sets.,Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-73.pdf,2011,100.0,Supervised dimension reduction mappings We propose a general principle to extend dimension reduction tools to explicit dimension reduction mappings and we show that this can serve as an interface to incorporate prior knowledge in the form of class labels. We explicitly demonstrate this technique by combining locally linear mappings which result from matrix learning vector quantization schemes with the t-distributed stochastic neighbor embedding cost function. The technique is tested on several benchmark data sets.
Growing Hierarchical Sectors on Sectors,"José Martínez-Martínez, Pablo Escandell-Montero, Emilio Soria-Olivas, José Martín-Guerrero, Juan Gómez-Sanchis, Joan Vila-Francés",1 - University of Valencia -Electronic Engineering Department st/ Dr Moliner 50 46100 Burjassot Valencia Spain,"Self-organizing maps are widely used in visual data mining. This paper proposes a new visualization approach for GHSOM algorithm, a hierarchical variant of SOM. The method is based on pie charts. That improves the visualization in hierarchical data structures making possible to extract all the existing relationships among the attributes of the neurons at any hierarchy level. The methodology is tested in one synthetic data set and one real data set. Achieved results show the suitability and usefulness of the proposed approach.",Seeing is believing: The importance of visualization in real-world machine learning applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-74.pdf,2011,100.0,"Growing Hierarchical Sectors on Sectors Self-organizing maps are widely used in visual data mining. This paper proposes a new visualization approach for GHSOM algorithm, a hierarchical variant of SOM. The method is based on pie charts. That improves the visualization in hierarchical data structures making possible to extract all the existing relationships among the attributes of the neurons at any hierarchy level. The methodology is tested in one synthetic data set and one real data set. Achieved results show the suitability and usefulness of the proposed approach."
Non-linearly increasing resampling in racing algorithms,"Verena Heidrich-Meisner, Christian Igel","1 - Institut für Neuroinformatik Bochum Ruhr-Universität Bochum Germany
2 - Department of Computer Science University of Copenhagen Copenhagen Denmark",Racing algorithms are iterative methods for identifying the best among several options with high probability. The quality of each option is a random variable. It is estimated by its empirical mean and concentration bounds obtained from repeated sampling. In each iteration of a standard racing algorithm each promising option is reevaluated once before being statistically compared with its competitors. We argue that Hoeffding and empirical Bernstein races benefit from generalizing the functional dependence of the racing iteration and the number of samples per option and illustrate this on an artificial benchmark problem.,Optimization and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-75.pdf,2011,100.0,Non-linearly increasing resampling in racing algorithms Racing algorithms are iterative methods for identifying the best among several options with high probability. The quality of each option is a random variable. It is estimated by its empirical mean and concentration bounds obtained from repeated sampling. In each iteration of a standard racing algorithm each promising option is reevaluated once before being statistically compared with its competitors. We argue that Hoeffding and empirical Bernstein races benefit from generalizing the functional dependence of the racing iteration and the number of samples per option and illustrate this on an artificial benchmark problem.
A constraint-based approach to incorporate prior knowledge in causal models,"G Borboudakis, S Triantafillou, V Lagani, I Tsamardinos","1 - Computer Science Department University of Crete
2 - Institute of Computer Science FORTH Hellas","In this paper we address the problem of incorporating prior knowledge, in the form of causal relations, in causal models. Prior approaches mostly consider knowledge about the presence or absence of edges in the model. We use the formalism of Maximal Ancestral Graphs (MAGs) and adapt cSAT+ to solve this problem, an algorithm for reasoning with datasets defined over different variable sets.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-76.pdf,2011,100.0,"A constraint-based approach to incorporate prior knowledge in causal models In this paper we address the problem of incorporating prior knowledge, in the form of causal relations, in causal models. Prior approaches mostly consider knowledge about the presence or absence of edges in the model. We use the formalism of Maximal Ancestral Graphs (MAGs) and adapt cSAT+ to solve this problem, an algorithm for reasoning with datasets defined over different variable sets."
Maximal Discrepancy Vs. Rademacher Complexity for Error Estimation,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella",1 - Department of Biophysical and Electronic Engineering University of Genova Via Opera Pia 11A I-16145 Genova Italy,"The Maximal Discrepancy and the Rademacher Complexity are powerful statistical tools that can be exploited to obtain reliable, albeit not tight, upper bounds of the generalization error of a classifier. We study the different behavior of the two methods when applied to linear classifiers and suggest a practical procedure to tighten the bounds. The resulting generalization estimation can be succesfully used for classifier model selection.",Learning theory,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-78.pdf,2011,71.21212121212122,"Maximal Discrepancy Vs. Rademacher Complexity for Error Estimation The Maximal Discrepancy and the Rademacher Complexity are powerful statistical tools that can be exploited to obtain reliable, albeit not tight, upper bounds of the generalization error of a classifier. We study the different behavior of the two methods when applied to linear classifiers and suggest a practical procedure to tighten the bounds. The resulting generalization estimation can be succesfully used for classifier model selection."
Training RBMs Based on the Signs of the CD Approximation of the Log-likelihood Derivatives,"Asja Fischer, Christian Igel","1 - Institut für Neuroinformatik Ruhr-Universität Bochum Germany
2 - Department of Computer Science University of Copenhagen Denmark","Contrastive Divergence (CD) learning is frequently applied to Restricted Boltzmann Machines (RBMs), the building blocks of deep believe networks. It relies on biased approximations of the log-likelihood gradient. This bias can deteriorate the learning process. It was claimed that the signs of most components of the CD update are equal to the corresponding signs of the log-likelihood gradient. This suggests using optimization techniques only depending on the signs. Resilient backpropagation is such a method and we combine it with CD learning. However, it does not prevent divergence caused by the approximation bias.",Deep Learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-79.pdf,2011,70.0,"Training RBMs Based on the Signs of the CD Approximation of the Log-likelihood Derivatives Contrastive Divergence (CD) learning is frequently applied to Restricted Boltzmann Machines (RBMs), the building blocks of deep believe networks. It relies on biased approximations of the log-likelihood gradient. This bias can deteriorate the learning process. It was claimed that the signs of most components of the CD update are equal to the corresponding signs of the log-likelihood gradient. This suggests using optimization techniques only depending on the signs. Resilient backpropagation is such a method and we combine it with CD learning. However, it does not prevent divergence caused by the approximation bias."
Class-Specific Feature Selection for One-Against-All Multiclass SVMs,"Gaël De Lannoy, Damien François, Michel Verleysen",1 - Electronics and Applied Mathematics Machine Learning Group Place du Levant Université catholique de Louvain Institute of Information and Communication Technologies 3 Louvain-la-Neuve Belgium,"This paper proposes a method to perform class-specific feature selection in multiclass support vector machines addressed with the one-against-all strategy. The main issue arises at the final step of the classification process, where binary classifier outputs must be compared one against another to elect the winning class. This comparison may be biased towards one specific class when the binary classifiers are built on distinct feature subsets. This paper proposes a normalization of the binary classifiers outputs that allows fair comparisons in such cases.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-8.pdf,2011,100.0,"Class-Specific Feature Selection for One-Against-All Multiclass SVMs This paper proposes a method to perform class-specific feature selection in multiclass support vector machines addressed with the one-against-all strategy. The main issue arises at the final step of the classification process, where binary classifier outputs must be compared one against another to elect the winning class. This comparison may be biased towards one specific class when the binary classifiers are built on distinct feature subsets. This paper proposes a normalization of the binary classifiers outputs that allows fair comparisons in such cases."
Training of multiple classifier systems utilizing partially labelled sequences,"Martin Schels, Patrick Schillinger, Friedhelm Schwenker",1 - Department of Neural Information Processing Ulm University 89069 Ulm Germany,"Making use of unlabeled data samples in a classification or training of a classifier is a desirable aim for many real world applications in pattern recognition. In this study, a multiple classifier system is utilized to investigate this matter. Further, cluster analysis is used in order to group the available data while neglecting the actual labels. Then, by implementing an information fusion architecture based on these clusters, a classification architecture is constructed. This kind of an architecture is investigated by means of a facial expression data collection with focusing on one-against-one class decisions to produce locally ""unlabeled"", i.e. not assigned to one of the considered classes, data.",Semi-supervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-80.pdf,2011,91.56626506024097,"Training of multiple classifier systems utilizing partially labelled sequences Making use of unlabeled data samples in a classification or training of a classifier is a desirable aim for many real world applications in pattern recognition. In this study, a multiple classifier system is utilized to investigate this matter. Further, cluster analysis is used in order to group the available data while neglecting the actual labels. Then, by implementing an information fusion architecture based on these clusters, a classification architecture is constructed. This kind of an architecture is investigated by means of a facial expression data collection with focusing on one-against-one class decisions to produce locally ""unlabeled"", i.e. not assigned to one of the considered classes, data."
A structure independent algorithm for causal discovery,"Tom Claassen, Tom Heskes",1 - Radboud University Nijmegen -Intelligent Systems Heyendaalseweg 135 6525 AJ Nijmegen The Netherlands,"We present two inference rules, based on so called minimal conditional independencies, that are sufficient to find all invariant arrowheads in a single causal DAG, even when selection bias may be present. It turns out that the set of seven graphical orientation rules that are usually employed to identify these arrowheads are, in fact, just different instances/manifestations of these two rules. The resulting algorithm to obtain the definite causal information is elegant and fast, once the (often surprisingly small) set of minimal independencies is found.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-82.pdf,2011,100.0,"A structure independent algorithm for causal discovery We present two inference rules, based on so called minimal conditional independencies, that are sufficient to find all invariant arrowheads in a single causal DAG, even when selection bias may be present. It turns out that the set of seven graphical orientation rules that are usually employed to identify these arrowheads are, in fact, just different instances/manifestations of these two rules. The resulting algorithm to obtain the definite causal information is elegant and fast, once the (often surprisingly small) set of minimal independencies is found."
Exploiting Vertices States in GraphESN by Weighted Nearest Neighbor,"Claudio Gallicchio, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 -56127 Pisa Italy,"Graph Echo State Networks (GraphESN) extend the Reservoir Computing approach to directly process graph structures. The reservoir is applied to every vertex of an input graph, realizing a contractive encoding process and resulting in a structured state isomorphic to the input. Whenever an unstructured output is required, a state mapping function maps the structured state into a fixed-size feature representation that feeds the linear readout. In this paper we propose an alternative approach, based on distance-weighted nearest neighbor, to realize a more flexible readout exploiting the state information computed for every vertex according to its individual relevance.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-83.pdf,2011,83.5820895522388,"Exploiting Vertices States in GraphESN by Weighted Nearest Neighbor Graph Echo State Networks (GraphESN) extend the Reservoir Computing approach to directly process graph structures. The reservoir is applied to every vertex of an input graph, realizing a contractive encoding process and resulting in a structured state isomorphic to the input. Whenever an unstructured output is required, a state mapping function maps the structured state into a fixed-size feature representation that feeds the linear readout. In this paper we propose an alternative approach, based on distance-weighted nearest neighbor, to realize a more flexible readout exploiting the state information computed for every vertex according to its individual relevance."
Causal Relevance Learning for Robust Classification under Interventions,"Ernest Mwebaze, Michael Biehl, John Quinn","1 - Faculty of Computing & IT Makerere University P.O. Box 7062 Kampala Uganda
2 - Johann Bernoulli Institute for Mathematics and Computer Science Univ. of Groningen P.O. Box 407 9700AK Groningen The Netherlands","In some classification problems the distribution of the test data is different from that of the training data because of external manipulations to the variables we observe. We propose a classification scheme which is robust to outside interventions by identifying causes in the training data, given that causes of a target variable remain predictive even when the data is manipulated. We do this by extending Relevance Learning Vector Quantization (RLVQ), a classification scheme that learns a relevance profile for the classification task presented. Our proposed algorithm, Causal-RLVQ, learns a relevance profile that weights causally relevant features more strongly. The algorithm can determine a tradeoff between robustness to intervention and accuracy on non-manipulated data, yielding RLVQ as a special case.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-84.pdf,2011,87.32394366197182,"Causal Relevance Learning for Robust Classification under Interventions In some classification problems the distribution of the test data is different from that of the training data because of external manipulations to the variables we observe. We propose a classification scheme which is robust to outside interventions by identifying causes in the training data, given that causes of a target variable remain predictive even when the data is manipulated. We do this by extending Relevance Learning Vector Quantization (RLVQ), a classification scheme that learns a relevance profile for the classification task presented. Our proposed algorithm, Causal-RLVQ, learns a relevance profile that weights causally relevant features more strongly. The algorithm can determine a tradeoff between robustness to intervention and accuracy on non-manipulated data, yielding RLVQ as a special case."
Automatic Enhancement of Correspondence Detection in an Object Tracking System,"Denis Schulze, Sven Wachsmuth, Katharina Rohlfing","1 - University of Bielefeld -Applied Informatics Universitätsstr. 25 33615 Bielefeld Germany
3 - University of Bielefeld -Emergentist Semantics Universitätsstr. 25 33615 Bielefeld Germany",This paper proposes a strategy to automatically detect the correspondence between measurements of different sensors using object tracking. In addition the strategy includes the ability to learn new features to facilitate the correspondence computation for future measurements. Therefore first a correlation between objects of different modalities is computed using time synchronous changes of attribute values. Using statistical methods to determine the dependencies between changes of different attributes it is shown how a multi layer perceptron (MLP) can be used to enhance the correspondence detection in ambiguous situations. 1,Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-85.pdf,2011,100.0,Automatic Enhancement of Correspondence Detection in an Object Tracking System This paper proposes a strategy to automatically detect the correspondence between measurements of different sensors using object tracking. In addition the strategy includes the ability to learn new features to facilitate the correspondence computation for future measurements. Therefore first a correlation between objects of different modalities is computed using time synchronous changes of attribute values. Using statistical methods to determine the dependencies between changes of different attributes it is shown how a multi layer perceptron (MLP) can be used to enhance the correspondence detection in ambiguous situations. 1
The role of Fisher information in primary data space for neighbourhood mapping,"H Ruiz, I Jarman, J Martín, P Lisboa","1 - School of Computing and Mathematical Sciences -Department of Mathematics and Statistics -LJMU L3 3AF Liverpool UK
2 - Centre for Public Health -LJMU L3 2ET Liverpool UK
3 - Escuela Técnica Superior de Ingeniería -Departamento de Ingeniería Electrónica Universidad de Valencia Burjassot Valencia) Spain","Clustering methods and nearest neighbour classifiers typically compute distances between data points as a measure of similarity, with nearby pairs of points considered more like each other than remote pairs. The distance measure of choice is often Euclidean, implicitly treating all directions in space as equally relevant. This paper reviews the application of Fisher information to derive a metric in primary data space. The aim is to provide a natural coordinate space to represent pairwise distances with respect to a probability distribution p(c|x), defined by an external label c, and use it to compute more informative distances.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-86.pdf,2011,100.0,"The role of Fisher information in primary data space for neighbourhood mapping Clustering methods and nearest neighbour classifiers typically compute distances between data points as a measure of similarity, with nearby pairs of points considered more like each other than remote pairs. The distance measure of choice is often Euclidean, implicitly treating all directions in space as equally relevant. This paper reviews the application of Fisher information to derive a metric in primary data space. The aim is to provide a natural coordinate space to represent pairwise distances with respect to a probability distribution p(c|x), defined by an external label c, and use it to compute more informative distances."
Clustering data streams with weightless neural networks,"Douglas Cardoso, Priscila Lima, Massimo De Gregorio, João Gama, Felipe França","1 - PESC/COPPE Universidade Federal do Rio de Janeiro Brazil
2 - DEMAT/ICE Universidade Federal Rural do Rio de Janeiro Brazil
3 - Istituto di Cibernetica ""Eduardo Caianiello"" CNR -Italy 4-LIAAD-INESC Universidade do Porto Portugal
4 - Thanks to the Project Knowledge Discovery from Ubiquitous Data Streams","Producing good quality clustering of data streams in real time is a difficult problem, since it is necessary to perform the analysis of data points arriving in a continuous style, with the support of quite limited computational resources. The incremental and evolving nature of the resulting clustering structures must reflect the dynamics of the target data stream. The WiSARD weightless perceptron, and its associated DRASiW extension, are intrinsically capable of, respectively, performing one-shot learning and producing prototypes of the learnt categories. This work introduces a simple generalization of RAM-based neurons in order to explore both weightless neural models in the data stream clustering problem.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-87.pdf,2011,100.0,"Clustering data streams with weightless neural networks Producing good quality clustering of data streams in real time is a difficult problem, since it is necessary to perform the analysis of data points arriving in a continuous style, with the support of quite limited computational resources. The incremental and evolving nature of the resulting clustering structures must reflect the dynamics of the target data stream. The WiSARD weightless perceptron, and its associated DRASiW extension, are intrinsically capable of, respectively, performing one-shot learning and producing prototypes of the learnt categories. This work introduces a simple generalization of RAM-based neurons in order to explore both weightless neural models in the data stream clustering problem."
Patch Affinity Propagation,"Xibin Zhu, Barbara Hammer",1 - Bielefeld University -CITEC Centre of Excellence D-33594 Bielefeld Germany,"Affinity propagation constitutes an exemplar based clustering technique which reliably optimizes the quantization error given a matrix of pairwise data dissimilarities by means of the max-sum algorithm for factor graphs. Albeit very efficient for sparse matrices, it displays squared complexity in the worst case, hence it is not suited as high throughput method due to time and memory constraints. We propose an extension of affinity propagation to patch clustering such that data are treated in chunks of fixed size with limited memory requirements and linear time. We test the suitability of the approach for two biomedical applications.",Computational Intelligence in Life Sciences,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-89.pdf,2011,100.0,"Patch Affinity Propagation Affinity propagation constitutes an exemplar based clustering technique which reliably optimizes the quantization error given a matrix of pairwise data dissimilarities by means of the max-sum algorithm for factor graphs. Albeit very efficient for sparse matrices, it displays squared complexity in the worst case, hence it is not suited as high throughput method due to time and memory constraints. We propose an extension of affinity propagation to patch clustering such that data are treated in chunks of fixed size with limited memory requirements and linear time. We test the suitability of the approach for two biomedical applications."
Unsupervised Feature Selection for Sparse Data,"Artur Ferreira, Mário Figueiredo","1 - Instituto Superior de Engenharia de Lisboa Lisboa PORTUGAL
2 - Instituto de Telecomunicações Lisboa PORTUGAL
3 - Instituto Superior Técnico Lisboa PORTUGAL","Feature selection is a well-known problem in machine learning and pattern recognition. Many high-dimensional datasets are sparse, that is, many features have zero value. In some cases, we do not known the class label for some (or even all) patterns in the dataset, leading us to semi-supervised or unsupervised learning problems. For instance, in text classification with the bag-of-words (BoW) representations, there is usually a large number of features, many of which may be irrelevant (or even detrimental) for categorization tasks. In this paper, we propose one efficient unsupervised feature selection technique for sparse data, suitable for both standard floating point and binary features. The experimental results on standard datasets show that the proposed method yields efficient feature selection, reducing the number of features while simultaneously improving the classification accuracy.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-134.pdf,2011,66.66666666666667,"Unsupervised Feature Selection for Sparse Data Feature selection is a well-known problem in machine learning and pattern recognition. Many high-dimensional datasets are sparse, that is, many features have zero value. In some cases, we do not known the class label for some (or even all) patterns in the dataset, leading us to semi-supervised or unsupervised learning problems. For instance, in text classification with the bag-of-words (BoW) representations, there is usually a large number of features, many of which may be irrelevant (or even detrimental) for categorization tasks. In this paper, we propose one efficient unsupervised feature selection technique for sparse data, suitable for both standard floating point and binary features. The experimental results on standard datasets show that the proposed method yields efficient feature selection, reducing the number of features while simultaneously improving the classification accuracy."
Inferring the Causal Decomposition under the Presence of Deterministic Relations,"Jan Lemeire, Stijn Meganck, Francesco Cartella, Tingting Liu, Alexander Statnikov","1 - -ETRO Department Vrije Universiteit Brussel Pleinlaan 2 Brussels Belgium
2 - Interdisciplinary Institute for Broadband Technology (IBBT) Belgium
7 - Center for Health Informatics and Bioinformatics New York University Medical Center USA","The presence of deterministic relations pose problems for current algorithms that learn the causal structure of a system based on the observed conditional independencies. Deterministic variables lead to information equivalences; two sets of variables have the same information about a third variable. Based on information content, one cannot decide on the direct causes. Several edges model equally well the dependencies. We call them equivalent edges. We propose to select among the equivalent edges the one with the simplest descriptive complexity. This approach assumes that the descriptive complexity increases along a causal path. As confirmed by our experimental results, the accuracy of the method depends on the chance of accidental matches of complexities. 1 With an undirected edge we denote that we have not yet identified the orientation.",Learning of causal relations,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-93.pdf,2011,80.0,"Inferring the Causal Decomposition under the Presence of Deterministic Relations The presence of deterministic relations pose problems for current algorithms that learn the causal structure of a system based on the observed conditional independencies. Deterministic variables lead to information equivalences; two sets of variables have the same information about a third variable. Based on information content, one cannot decide on the direct causes. Several edges model equally well the dependencies. We call them equivalent edges. We propose to select among the equivalent edges the one with the simplest descriptive complexity. This approach assumes that the descriptive complexity increases along a causal path. As confirmed by our experimental results, the accuracy of the method depends on the chance of accidental matches of complexities. 1 With an undirected edge we denote that we have not yet identified the orientation."
Communication Challenges in Cloud K-means,"Matthieu Durut, Fabrice Rossi","1 - BILab LTCI -UMR CNRS Télécom ParisTech, rue Barrault 5141 46, 75013 Paris France
2 - 1-Lokad, 70, rue Lemercier 75018 Paris France","This paper studies how parallel machine learning algorithms can be implemented on top of Microsoft Windows Azure cloud computing platform. More specifically, we design efficient storage based communication mechanisms that lead to a scalable implementation of the K-means.",Learning II,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-95.pdf,2011,100.0,"Communication Challenges in Cloud K-means This paper studies how parallel machine learning algorithms can be implemented on top of Microsoft Windows Azure cloud computing platform. More specifically, we design efficient storage based communication mechanisms that lead to a scalable implementation of the K-means."
Symbolic computing of LS-SVM based models,"S Mehrkanoon, L Jiang, Carlos Alzate, J Suykens",1 - Department of Electrical Engineering K.U. Leuven ESAT-SCD Kasteelpark Arenberg 10 B-3001 Leuven (Heverlee) Belgium,"This paper introduces a software tool SYM-LS-SVM-SOLVER written in Maple to derive the dual system and the dual model representation of LS-SVM based models, symbolically. SYM-LS-SVM-SOLVER constructs the Lagrangian from the given objective function and list of constraints. Afterwards it obtains the KKT (Karush-Kuhn-Tucker) optimality conditions and finally formulates a linear system in terms of the dual variables. The effectiveness of the developed solver is illustrated by applying it to a variety of problems involving LS-SVM based models.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-97.pdf,2011,100.0,"Symbolic computing of LS-SVM based models This paper introduces a software tool SYM-LS-SVM-SOLVER written in Maple to derive the dual system and the dual model representation of LS-SVM based models, symbolically. SYM-LS-SVM-SOLVER constructs the Lagrangian from the given objective function and list of constraints. Afterwards it obtains the KKT (Karush-Kuhn-Tucker) optimality conditions and finally formulates a linear system in terms of the dual variables. The effectiveness of the developed solver is illustrated by applying it to a variety of problems involving LS-SVM based models."
Deconvolution in Nonparametric Statistics,"Kris De Brabanter, Bart De Moor","1 - Department of Electrical Engineering (ESAT-SCD) Katholieke Universiteit Leuven Kasteelpark Arenberg 10 B-3001 Leuven Belgium
2 - Katholieke Universiteit Leuven -IBBT-KU Leuven Future Health Department Kasteelpark Arenberg 10 B-3001 Leuven Belgium
5 - Katholieke Universiteit Leuven Belgium","In this tutorial paper we give an overview of deconvolution problems in nonparametric statistics. First, we consider the problem of density estimation given a contaminated sample. We illustrate that the classical Rosenblatt-Parzen kernel density estimator is unable to capture the full shape of the density while the presented method experiences almost no problems. Second, we use the previous estimator in a nonparametric regression framework with errors-in-variables.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-10.pdf,2012,87.8048780487805,"Deconvolution in Nonparametric Statistics In this tutorial paper we give an overview of deconvolution problems in nonparametric statistics. First, we consider the problem of density estimation given a contaminated sample. We illustrate that the classical Rosenblatt-Parzen kernel density estimator is unable to capture the full shape of the density while the presented method experiences almost no problems. Second, we use the previous estimator in a nonparametric regression framework with errors-in-variables."
Fast calibration of hand movement-based interface for arm exoskeleton control,"Hugo Martin, Sylvain Chevallier, Eric Monacelli",1 - Université Versailles Saint-Quentin Laboratoire d'Ingénierie des Systèmes de Versailles 78140 Velizy France,"Several muscular degenerative diseases alter motor abilities of large muscles but spare smaller muscles, e.g. keeping hand motor skills relatively unaffected while upper limbs ones are altered. Thus, hand movements could be be used to control an arm exoskeleton for rehabilitation and assistive purpose. Using an infra-red sensors (IR) based interface for the exoskeleton control, this paper describes the learning part of the system, endowing the system with a fast online calibration and adaptation abilities. This learning component shows good results and have been successfully implemented on the real system.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-102.pdf,2012,99.35483870967742,"Fast calibration of hand movement-based interface for arm exoskeleton control Several muscular degenerative diseases alter motor abilities of large muscles but spare smaller muscles, e.g. keeping hand motor skills relatively unaffected while upper limbs ones are altered. Thus, hand movements could be be used to control an arm exoskeleton for rehabilitation and assistive purpose. Using an infra-red sensors (IR) based interface for the exoskeleton control, this paper describes the learning part of the system, endowing the system with a fast online calibration and adaptation abilities. This learning component shows good results and have been successfully implemented on the real system."
Modularity-Based Clustering for Network-Constrained Trajectories,"Mohamed El Mahrsi, Fabrice Rossi","1 - Université Paris I -Département SAMM 90 75634 Tolbiac, Paris CEDEX 13 France
2 - 1-Télécom ParisTech -Département Informatique et Réseaux 46 75013 Barrault, Paris France",We present a novel clustering approach for moving object trajectories that are constrained by an underlying road network. The approach builds a similarity graph based on these trajectories then uses modularity-optimization hiearchical graph clustering to regroup trajectories with similar profiles. Our experimental study shows the superiority of the proposed approach over classic hierarchical clustering and gives a brief insight to visualization of the clustering results.,Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-107.pdf,2012,84.375,Modularity-Based Clustering for Network-Constrained Trajectories We present a novel clustering approach for moving object trajectories that are constrained by an underlying road network. The approach builds a similarity graph based on these trajectories then uses modularity-optimization hiearchical graph clustering to regroup trajectories with similar profiles. Our experimental study shows the superiority of the proposed approach over classic hierarchical clustering and gives a brief insight to visualization of the clustering results.
Hardware accelerated real time classification of hyperspectral imaging data for coffee sorting,"Andreas Backhaus, Jan Lachmair, Ulrich Rückert, Udo Seiffert","1 - -Cognitronics & Sensor Systems University Bielefeld Bielefeld Germany
3 - Fraunhofer Institute for Factory Operation and Automation (IFF) 1-Biosystems Engineering Magdeburg Germany","Hyperspectral imaging has been proven to be a viable tool for automated food inspection that is non-invasive and on-line capable. In this contribution a hardware implemented Self-Organizing Feature Map with Conscience (CSOM) is presented that is capable of on-line adaptation and recall in order to learn to classify green coffee varieties as well as coffee of different roast stages. The CSOM showed favourable results in some datasets compared to a number of classical supervised neural network classifiers. The massive parallel neural hardware architecture allows for constant processing times at different map sizes. 
 Data Acquisition Coffee beans of each class were recorded separately. Beans and a standard optical PTFE (polytetrafluoroethylene) calibration pad were positioned on a translation",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-110.pdf,2012,100.0,"Hardware accelerated real time classification of hyperspectral imaging data for coffee sorting Hyperspectral imaging has been proven to be a viable tool for automated food inspection that is non-invasive and on-line capable. In this contribution a hardware implemented Self-Organizing Feature Map with Conscience (CSOM) is presented that is capable of on-line adaptation and recall in order to learn to classify green coffee varieties as well as coffee of different roast stages. The CSOM showed favourable results in some datasets compared to a number of classical supervised neural network classifiers. The massive parallel neural hardware architecture allows for constant processing times at different map sizes. 
 Data Acquisition Coffee beans of each class were recorded separately. Beans and a standard optical PTFE (polytetrafluoroethylene) calibration pad were positioned on a translation"
Automatic Group-Outlier Detection,"Amine Chaibi, Mustapha Lebbah, Hanane Azzag","1 - LIPN-UMR 7030 Université Paris 13 -CNRS 99, av. J-B Clément F-93430 Villetaneuse",We propose in this paper a new measure called GOF (Group Outlier Factor) to detect groups outliers. To validate this measure we integrated it in a clustering process using Self-organizing Map. The proposed approach is based on relative density of each group of data and simultaneously provides a partitioning of data and a quantitative indicator (GOF). The obtained results are very encouraging to continue in this direction.,Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-111.pdf,2012,100.0,Automatic Group-Outlier Detection We propose in this paper a new measure called GOF (Group Outlier Factor) to detect groups outliers. To validate this measure we integrated it in a clustering process using Self-organizing Map. The proposed approach is based on relative density of each group of data and simultaneously provides a partitioning of data and a quantitative indicator (GOF). The obtained results are very encouraging to continue in this direction.
How regular is neuronal activity?,"Lubomir Kostal, Petr Lansky, Ondrej Pokora","1 - Institute of Physiology AS CR, v.v.i Dept. of Computational Neuroscience 1083 Videnska, Praha 4 Czech Republic","We propose and investigate two information-based measures of statistical dispersion of neuronal firing: the entropy-based dispersion and Fisher information-based dispersion. The measures are compared with the standard deviation. Although the standard deviation is used routinely, we show, that it is not well suited to quantify some aspects of dispersion that are often expected intuitively, such as the degree of randomness. The proposed dispersion measures are not entirely independent, although each describes the firing regularity from a different point of view.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-12.pdf,2012,100.0,"How regular is neuronal activity? We propose and investigate two information-based measures of statistical dispersion of neuronal firing: the entropy-based dispersion and Fisher information-based dispersion. The measures are compared with the standard deviation. Although the standard deviation is used routinely, we show, that it is not well suited to quantify some aspects of dispersion that are often expected intuitively, such as the degree of randomness. The proposed dispersion measures are not entirely independent, although each describes the firing regularity from a different point of view."
On the Potential Inadequacy of Mutual Information for Feature Selection,"Benoît Frénay, Gauthier Doquire, Michel Verleysen",1 - ICTEAM/ELEN -Machine Learning Group Place du Levant 3 Université catholique de Louvain 1348 Louvain-la-Neuve Belgium,"Despite its popularity as a relevance criterion for feature selection, the mutual information can sometimes be inadequate for this task. Indeed, it is commonly accepted that a set of features maximising the mutual information with the target vector leads to a lower probability of misclassification. However, this assumption is in general not true. Justifications and illustrations of this fact are given in this paper.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-120.pdf,2012,100.0,"On the Potential Inadequacy of Mutual Information for Feature Selection Despite its popularity as a relevance criterion for feature selection, the mutual information can sometimes be inadequate for this task. Indeed, it is commonly accepted that a set of features maximising the mutual information with the target vector leads to a lower probability of misclassification. However, this assumption is in general not true. Justifications and illustrations of this fact are given in this paper."
Introducing diversity among the models of multi-label classification ensemble,"Lena Chekina, Lior Rokach, Bracha Shapira",1 - Ben-Gurion University of the Negev -Dept. of Information Systems Engineering and Telekom Innovation Laboratories Beer-Sheva 84105 Israel,"A number of ensemble algorithms for solving multi-label classification problems have been proposed in recent years. Diversity among the base learners is known to be important for constructing a good ensemble. In this paper we define a method for introducing diversity among the base learners of one of the previously presented multi-label ensemble classifiers. An empirical comparison on 10 datasets demonstrates that model diversity leads to an improvement in prediction accuracy in 80% of the evaluated cases. Additionally, in most cases the proposed ""diverse"" ensemble method outperforms other multi-label ensembles as well.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-121.pdf,2012,100.0,"Introducing diversity among the models of multi-label classification ensemble A number of ensemble algorithms for solving multi-label classification problems have been proposed in recent years. Diversity among the base learners is known to be important for constructing a good ensemble. In this paper we define a method for introducing diversity among the base learners of one of the previously presented multi-label ensemble classifiers. An empirical comparison on 10 datasets demonstrates that model diversity leads to an improvement in prediction accuracy in 80% of the evaluated cases. Additionally, in most cases the proposed ""diverse"" ensemble method outperforms other multi-label ensembles as well."
Process Mining in Non-Stationary Environments,"Phil Weber, Peter Tiňo, Behzad Bordbar","1 - School of Computer Science University of Birmingham UK
2 - School of Computer Science University of Birmingham","Process Mining uses event logs to discover and analyse business processes, typically assumed to be static. However as businesses adapt to change, processes can be expected to change. Since one application of process mining is ensuring conformance to prescribed processes or rules, timely detection of change is important. We consider process mining in such non-stationary environments and show that using a probabilistic view of processes, timely and confident detection of change is possible.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-123.pdf,2012,100.0,"Process Mining in Non-Stationary Environments Process Mining uses event logs to discover and analyse business processes, typically assumed to be static. However as businesses adapt to change, processes can be expected to change. Since one application of process mining is ensuring conformance to prescribed processes or rules, timely detection of change is important. We consider process mining in such non-stationary environments and show that using a probabilistic view of processes, timely and confident detection of change is possible."
Texture Classification Based on Symbolic Data Analysis,"Carlos De Almeida, Renata De Souza, Ana Lúcia, B Candeias","1 - Center of Informatics (CIn) Recife Federal University of Pernambuco Brazil
3 - Department of Cartographic Engineering Recife Federal University of Pernambuco Brazil","This article presents a hybrid approach for texture-based image classification using the gray-level co-occurrence matrices (GLCM) and a new Fuzzy Kohonen Clustering Network for Symbolic Interval Data (IFKCN). The GLCM matrices extracted from an image database are processed to create the training data set using IFKCN algorithm. The IFKCN organizes and extracts prototypes from processed GLCM matrices. The experimental results demonstrate that the proposed method is encouraging with an average successful rate of 97.39%. 
 The Proposed Approach for Texture Classification Four main modules are the building blocks of the proposed method: (i) Texture Descriptor, (ii) Symbolic Data Analysis, (iii) Clustering, and (iv) Classification. Our ap-145",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-124.pdf,2012,83.33333333333334,"Texture Classification Based on Symbolic Data Analysis This article presents a hybrid approach for texture-based image classification using the gray-level co-occurrence matrices (GLCM) and a new Fuzzy Kohonen Clustering Network for Symbolic Interval Data (IFKCN). The GLCM matrices extracted from an image database are processed to create the training data set using IFKCN algorithm. The IFKCN organizes and extracts prototypes from processed GLCM matrices. The experimental results demonstrate that the proposed method is encouraging with an average successful rate of 97.39%. 
 The Proposed Approach for Texture Classification Four main modules are the building blocks of the proposed method: (i) Texture Descriptor, (ii) Symbolic Data Analysis, (iii) Clustering, and (iv) Classification. Our ap-145"
A Discussion on Parallelization Schemes for Stochastic Vector Quantization Algorithms,"Matthieu Durut, Benoit Patra, Fabrice Rossi","1 - Telecom ParisTech -INFRES 46 rue Barrault -Paris France
2 - Université Pierre et Marie Curie -LSTA 4 place Jussieu -Paris -France 3-Lokad, 10 rue Philippe de Champaigne -Paris -France 4-SAMM
3 - Université Paris I Panthéon-Sorbonne -90 rue de Tolbiac -Paris France","This paper studies parallelization schemes for stochastic Vector Quantization algorithms in order to obtain time speed-ups using distributed resources. We show that the most intuitive parallelization scheme does not lead to better performances than the sequential algorithm. Another distributed scheme is therefore introduced which obtains the expected speedups. Then, it is improved to fit implementation on distributed architectures where communications are slow and inter-machines synchronization too costly. The schemes are tested with simulated distributed architectures and, for the last one, with Microsoft Windows Azure platform obtaining speed-ups up to 32 Virtual Machines.",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-127.pdf,2012,100.0,"A Discussion on Parallelization Schemes for Stochastic Vector Quantization Algorithms This paper studies parallelization schemes for stochastic Vector Quantization algorithms in order to obtain time speed-ups using distributed resources. We show that the most intuitive parallelization scheme does not lead to better performances than the sequential algorithm. Another distributed scheme is therefore introduced which obtains the expected speedups. Then, it is improved to fit implementation on distributed architectures where communications are slow and inter-machines synchronization too costly. The schemes are tested with simulated distributed architectures and, for the last one, with Microsoft Windows Azure platform obtaining speed-ups up to 32 Virtual Machines."
One-class classifier based on extreme value statistics,"David Martinez-Rego, Evan Kriminger, Jose Principe, Oscar Fontenla-Romero, Amparo Alonso-Betanzos","1 - Dept. of Computer Science -LIDIA Group Campus de Elvina, s/n 15071 A Coruna Spain
2 - Computational NeuroEgineering Lab University of Florida 32611 Gainesville FL","In recent years, interest in one-class classification methods has soared due to its wide applicability in many practical problems in which classification in the absence of counterexamples is needed. In this paper, a new one class classification rule based on order statistics is presented. It only relies on embedding the classification problem into a metric space, so it is suitable for Euclidean or other structured mappings. The suitability of the proposed method is assessed through a comparison both for artificial and real life data sets. The good results obtained pave the road for its application on practical novelty detection problems.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-13.pdf,2012,91.22807017543859,"One-class classifier based on extreme value statistics In recent years, interest in one-class classification methods has soared due to its wide applicability in many practical problems in which classification in the absence of counterexamples is needed. In this paper, a new one class classification rule based on order statistics is presented. It only relies on embedding the classification problem into a metric space, so it is suitable for Euclidean or other structured mappings. The suitability of the proposed method is assessed through a comparison both for artificial and real life data sets. The good results obtained pave the road for its application on practical novelty detection problems."
BCI Signal Classification using a Riemannian-based kernel,"Alexandre Barachant, Stéphane Bonnet, Marco Congedo, Christian Jutten","1 - DTBS/STD/LE2S CEA, LETI 17 rue des Martyrs F-38054 Grenoble France
3 - Team ViBS (Vision and Brain Signal Processing) GIPSA-lab CNRS Grenoble Universities. Domaine Universitaire F-38402 Saint Martin d'Hères France","The use of spatial covariance matrix as feature is investigated for motor imagery EEG-based classification. A new kernel is derived by establishing a connection with the Riemannian geometry of symmetric positive definite matrices. Different kernels are tested, in combination with support vector machines, on a past BCI competition dataset. We demonstrate that this new approach outperforms significantly state of the art results without the need for spatial filtering.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-130.pdf,2012,100.0,"BCI Signal Classification using a Riemannian-based kernel The use of spatial covariance matrix as feature is investigated for motor imagery EEG-based classification. A new kernel is derived by establishing a connection with the Riemannian geometry of symmetric positive definite matrices. Different kernels are tested, in combination with support vector machines, on a past BCI competition dataset. We demonstrate that this new approach outperforms significantly state of the art results without the need for spatial filtering."
Dissimilarity Clustering by Hierarchical Multi-Level Refinement,"Brieuc Conan-Guez, Fabrice Rossi","1 - LITA EA Université Paul Verlaine-Metz Île du Saulcy 3097, 57045 Metz cedex 1 France
2 - SAMM EA Université Paris 1 Panthéon-Sorbonne 90, rue de Tolbiac 4543, 75634 Paris cedex 13 France","We introduce in this paper a new way of optimizing the natural extension of the quantization error using in k-means clustering to dissimilarity data. The proposed method is based on hierarchical clustering analysis combined with multi-level heuristic refinement. The method is computationally efficient and achieves better quantization errors than the relational k-means. 
 Hierarchical Clustering Analysis 
 Dissimilarity matrix and error measure We consider the general case of a set Ω equipped with a dissimilarity measure. This is a map from Ω × Ω → R + , which is reflexive and symmetric, i.e.,",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-132.pdf,2012,100.0,"Dissimilarity Clustering by Hierarchical Multi-Level Refinement We introduce in this paper a new way of optimizing the natural extension of the quantization error using in k-means clustering to dissimilarity data. The proposed method is based on hierarchical clustering analysis combined with multi-level heuristic refinement. The method is computationally efficient and achieves better quantization errors than the relational k-means. 
 Hierarchical Clustering Analysis 
 Dissimilarity matrix and error measure We consider the general case of a set Ω equipped with a dissimilarity measure. This is a map from Ω × Ω → R + , which is reflexive and symmetric, i.e.,"
Enhanced emotion recognition by feature selection to animate a talking head,"Hela Daassi-Gnaba, Yacine Oussar","1 - Université Paris 8 -Laboratoire d'Informatique Avancée de Saint-Denis (LIASD 2 rue de la Liberté 4383, 93526 Saint-Denis Cedex EA France
2 - Laboratoire de Physique et d' Étude des Matériaux (LPEM) ESPCI-ParisTech 10 rue Vauquelin 75231 Paris Cedex France","It is known that deaf and hard of hearing people can substantially improve their skill to lip reading if they have access to speaker emotion. Moreover, it has been shown that animating an artificial talking head can provide this modality. In this paper, we assume that emotion recognition to animate such talking head can be performed using a small set of relevant features extracted from the speech signal. More precisely, we show that the implementation of linear classifiers using Support Vector Machines (SVM) with the involvement of a feature selection method leads to a promising performance which confirms our assumption.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-133.pdf,2012,88.0,"Enhanced emotion recognition by feature selection to animate a talking head It is known that deaf and hard of hearing people can substantially improve their skill to lip reading if they have access to speaker emotion. Moreover, it has been shown that animating an artificial talking head can provide this modality. In this paper, we assume that emotion recognition to animate such talking head can be performed using a small set of relevant features extracted from the speech signal. More precisely, we show that the implementation of linear classifiers using Support Vector Machines (SVM) with the involvement of a feature selection method leads to a promising performance which confirms our assumption."
Implementation Issues of Kohonen Self-Organizing Map Realized on FPGA,"Marta Kolasa, Micha Szulc, Witold Pedrycz, Pierre-André Farine","1 - Faculty of Telecommunication and Electrical Engineering University of Technology and Life Sciences ul Kaliskiego 7 85-796 Bydgoszcz Poland
2 - -Institute of Microtechnology Swiss Federal Institute of Technology in Lausanne Rue A.-L Breguet 2 CH-2000 Neuchâtel Switzerland
4 - Chair of Computer Engineering Poznań University of Technology ul. Polanka 3A 60-965 Poznań Poland
5 - Department of Electrical and Computer Engineering University of Alberta T6G 2V4 Edmonton AB Canada","Presented are the investigations showing an impact of the length of data signals in hardware implemented Kohonen Self-Organizing Maps (SOM) on the quality of the learning process. The aim of this work was to determine the allowable reduction of the number of bits in particular signals that does not deteriorate the network behavior. The efficiency of the learning process has been quantified by using the quantization error. The results obtained for the SOM realized on Field Programmable Gate Array (FPGA), as well as by means of the software model of the SOM show that the smallest allowable resolution (expressed in bits) of the weight signals equals seven, while the minimal bit length of the neighborhood signal ranges from 3 to 6 (depending on the map topology). For such values and properly selected values of other parameters the learning process remains undisturbed. Reducing the number of bits has an influence on the number of neurons that can be synthesized on a single FPGA device.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-137.pdf,2012,100.0,"Implementation Issues of Kohonen Self-Organizing Map Realized on FPGA Presented are the investigations showing an impact of the length of data signals in hardware implemented Kohonen Self-Organizing Maps (SOM) on the quality of the learning process. The aim of this work was to determine the allowable reduction of the number of bits in particular signals that does not deteriorate the network behavior. The efficiency of the learning process has been quantified by using the quantization error. The results obtained for the SOM realized on Field Programmable Gate Array (FPGA), as well as by means of the software model of the SOM show that the smallest allowable resolution (expressed in bits) of the weight signals equals seven, while the minimal bit length of the neighborhood signal ranges from 3 to 6 (depending on the map topology). For such values and properly selected values of other parameters the learning process remains undisturbed. Reducing the number of bits has an influence on the number of neurons that can be synthesized on a single FPGA device."
Highly efficient Localisation utilising Weightless neural systems,"Ben Mcelroy, Michael Gillham, Gareth Howells, Sarah Spurgeon, Stephen Kelly, John Batchelor, Matthew Pepper","1 - School of Engineering and Digital Arts University of Kent
2 - East Kent Hospitals University Foundation Trust","Efficient localisation is a highly desirable property for an autonomous navigation system. Weightless neural networks offer a real-time approach to robotics applications by reducing hardware and software requirements for pattern recognition techniques. Such networks offer the potential for objects, structures, routes and locations to be easily identified and maps constructed from fused limited sensor data as information becomes available. We show that in the absence of concise and complex information, localisation can be obtained using simple algorithms from data with inherent uncertainties using a combination of Genetic Algorithm techniques applied to a Weightless Neural Architecture.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-138.pdf,2012,66.15384615384615,"Highly efficient Localisation utilising Weightless neural systems Efficient localisation is a highly desirable property for an autonomous navigation system. Weightless neural networks offer a real-time approach to robotics applications by reducing hardware and software requirements for pattern recognition techniques. Such networks offer the potential for objects, structures, routes and locations to be easily identified and maps constructed from fused limited sensor data as information becomes available. We show that in the absence of concise and complex information, localisation can be obtained using simple algorithms from data with inherent uncertainties using a combination of Genetic Algorithm techniques applied to a Weightless Neural Architecture."
Classifying Scotch Whisky from near-infrared Raman spectra with a Radial Basis Function Network with Relevance Learning,"Andreas Backhaus, Praveen Ashok, Bavishna Praveen, Kishan Dholakia, Udo Seiffert","1 - SUPA School of Physics and Astronomy University of St. Andrews North Haugh Fife Scotland, UK
4 - Fraunhofer Institute for Factory Operation and Automation (IFF) 1-Biosystems Engineering Magdeburg Germany",The instantaneous assessment of high-priced liquor products with minimal sample volume and no special preparation is an important task for quality monitoring and fraud detection. In this contribution the automated classification of Raman spectra acquired with a special optofluidic chip is performed with the use of a number of Artificial Neural Networks. A standard Radial Basis Function Network is adopted to incorporate relevance learning and showed robust classification performance across classification tasks. The acquired relevance weighting per feature dimension can be used to reduce the number of features while retaining a high level of accuracy.,Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-139.pdf,2012,100.0,Classifying Scotch Whisky from near-infrared Raman spectra with a Radial Basis Function Network with Relevance Learning The instantaneous assessment of high-priced liquor products with minimal sample volume and no special preparation is an important task for quality monitoring and fraud detection. In this contribution the automated classification of Raman spectra acquired with a special optofluidic chip is performed with the use of a number of Artificial Neural Networks. A standard Radial Basis Function Network is adopted to incorporate relevance learning and showed robust classification performance across classification tasks. The acquired relevance weighting per feature dimension can be used to reduce the number of features while retaining a high level of accuracy.
Semi-Supervised Neural Gas for Adaptive Brain-Computer Interfaces,"Hannes Riechmann, Andrea Finke",1 - Bielefeld University -CITEC Universitaetsstrasse 21 33615 Bielefeld Germany,"Non-stationarity is inherent in EEG data. We propose a concept for an adaptive brain computer interface (BCI) that adapts a classifier to the changes in EEG data. It combines labeled and unlabeled data acquired during normal operation of the system. The classifier is based on Fuzzy Neural Gas (FNG), a prototype-based classifier. Based on four data sets we show that retraining the classifier significantly increases classification accuracy. Our approach smoothly adapts to the session-tosession variations in the data.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-140.pdf,2012,100.0,"Semi-Supervised Neural Gas for Adaptive Brain-Computer Interfaces Non-stationarity is inherent in EEG data. We propose a concept for an adaptive brain computer interface (BCI) that adapts a classifier to the changes in EEG data. It combines labeled and unlabeled data acquired during normal operation of the system. The classifier is based on Fuzzy Neural Gas (FNG), a prototype-based classifier. Based on four data sets we show that retraining the classifier significantly increases classification accuracy. Our approach smoothly adapts to the session-tosession variations in the data."
Distributed Learning via Diffusion Adaptation with Application to Ensemble Learning,"Zaid Towfic, Jianshu Chen, Ali Sayed",1 - Electrical Engineering Department University of California Los Angeles,"We examine the problem of learning a set of parameters from a distributed dataset. We assume the datasets are collected by agents over a distributed ad-hoc network, and that the communication of the actual raw data is prohibitive due to either privacy constraints or communication constraints. We propose a distributed algorithm for online learning that is proved to guarantee a bounded excess risk and the bound can be made arbitrary small for sufficiently small step-sizes. We apply our framework to the expert advice problem where nodes learn the weights for the trained experts distributively.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-141.pdf,2012,68.67469879518072,"Distributed Learning via Diffusion Adaptation with Application to Ensemble Learning We examine the problem of learning a set of parameters from a distributed dataset. We assume the datasets are collected by agents over a distributed ad-hoc network, and that the communication of the actual raw data is prohibitive due to either privacy constraints or communication constraints. We propose a distributed algorithm for online learning that is proved to guarantee a bounded excess risk and the bound can be made arbitrary small for sufficiently small step-sizes. We apply our framework to the expert advice problem where nodes learn the weights for the trained experts distributively."
Simple Reservoirs with Chain Topology Based on a Single Time-Delay Nonlinear Node,"J Gutiérrez, D San-Martín, S Ortín, L Pesquera, L Cdtuc, Santander -Spain",1 - Instituto de Física de Cantabria (IFCA) CSIC-Univ. Cantabria Avda. de los Castros. Santander Spain,A physical scheme based on a single nonlinear dynamical system with delayed feedback has been recently proposed for Reservoir Computing (RC)  [1] . In this paper we present a computational implementation of this idea using a simple chain topology with properties derived from its physical counterpart (e.g. the reservoir is defined by two tunable parameters related to feedback-and input-strength terms). An application to time series prediction is described and a comparison with other standard reservoir computing methods is given.,Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-142.pdf,2012,74.07407407407408,Simple Reservoirs with Chain Topology Based on a Single Time-Delay Nonlinear Node A physical scheme based on a single nonlinear dynamical system with delayed feedback has been recently proposed for Reservoir Computing (RC)  [1] . In this paper we present a computational implementation of this idea using a simple chain topology with properties derived from its physical counterpart (e.g. the reservoir is defined by two tunable parameters related to feedback-and input-strength terms). An application to time series prediction is described and a comparison with other standard reservoir computing methods is given.
A Hybrid CMOS/Memristive Nanoelectronic Circuit for Programming Synaptic Weights,"Arne Heittmann, Tobias Noll",1 - Chair of Electrical Engineering and Computer Systems RWTH Aachen University D-52062 Aachen Germany,"In this paper a hybrid circuit is presented which comprises nanoelectronic resistive switches based on the electrochemical memory effect (ECM) as well as devices from a standard 40nm-CMOS process. A closed ECM device model, which is based on device physics, was used for simulations allowing for a precise prediction of the expected I-V characteristics. The device is used as a non-volatile and/or programmable synapse in a neuromorphic architecture. Expected performance figures are derived such as write time as well as robustness with regard to variations of supply voltage and timing errors. The results show that ECM cells are prospective devices for hybrid neuromorphic systems.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-146.pdf,2012,86.25,"A Hybrid CMOS/Memristive Nanoelectronic Circuit for Programming Synaptic Weights In this paper a hybrid circuit is presented which comprises nanoelectronic resistive switches based on the electrochemical memory effect (ECM) as well as devices from a standard 40nm-CMOS process. A closed ECM device model, which is based on device physics, was used for simulations allowing for a precise prediction of the expected I-V characteristics. The device is used as a non-volatile and/or programmable synapse in a neuromorphic architecture. Expected performance figures are derived such as write time as well as robustness with regard to variations of supply voltage and timing errors. The results show that ECM cells are prospective devices for hybrid neuromorphic systems."
Similarity networks for heterogeneous data,"Lluís Belanche, Jerónimo Hernández","1 - Faculty of Computer Science -Dept. of Software Technical University of Catalonia Barcelona Spain
2 - Intelligent Systems Group -Dept. of Computer Science Artificial Intelligence University of the Basque Country Donostia Spain","A two-layer neural network is developed in which the neuron model computes a user-defined similarity function between inputs and weights. The neuron model is formed by the composition of an adapted logistic function with the mean of the partial input-weight similarities. The model is capable of dealing directly with variables of potentially different nature (continuous, ordinal, categorical); there is also provision for missing values. The network is trained using a fast two-stage procedure and involves the setting of only one parameter. In our experiments, the network achieves slightly superior performance on a set of challenging problems with respect to both RBF nets and RBF-kernel SVMs.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-148.pdf,2012,100.0,"Similarity networks for heterogeneous data A two-layer neural network is developed in which the neuron model computes a user-defined similarity function between inputs and weights. The neuron model is formed by the composition of an adapted logistic function with the mean of the partial input-weight similarities. The model is capable of dealing directly with variables of potentially different nature (continuous, ordinal, categorical); there is also provision for missing values. The network is trained using a fast two-stage procedure and involves the setting of only one parameter. In our experiments, the network achieves slightly superior performance on a set of challenging problems with respect to both RBF nets and RBF-kernel SVMs."
Joint Regression and Linear Combination of Time Series for Optimal Prediction,"Dries Geebelen, Kim Batselier, Philippe Dreesen, Marco Signoretto, Johan Suykens, Bart De Moor, Joos Vandewalle","1 - Department of Electrical Engineering-ESAT SCD-SISTA 1-KULeuven
2 - IBBT Future Health Department Kasteelpark Arenberg 10 B-3001 Leuven Belgium",In most machine learning applications the time series to predict is fixed and one has to learn a prediction model that causes the smallest error. In this paper choosing the time series to predict is part of the optimization problem. This time series has to be a linear combination of a priori given time series. The optimization problem that we have to solve can be formulated as choosing the linear combination of a priori known matrices such that the smallest singular vector is minimized. This problem has many local minima and can be formulated as a polynomial system which we will solve using a polynomial system solver. The proposed prediction algorithm has applications in algorithmic trading in which a linear combination of stocks will be bought.,Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-149.pdf,2012,100.0,Joint Regression and Linear Combination of Time Series for Optimal Prediction In most machine learning applications the time series to predict is fixed and one has to learn a prediction model that causes the smallest error. In this paper choosing the time series to predict is part of the optimization problem. This time series has to be a linear combination of a priori given time series. The optimization problem that we have to solve can be formulated as choosing the linear combination of a priori known matrices such that the smallest singular vector is minimized. This problem has many local minima and can be formulated as a polynomial system which we will solve using a polynomial system solver. The proposed prediction algorithm has applications in algorithmic trading in which a linear combination of stocks will be bought.
Intrinsic Plasticity via Natural Gradient Descent,"Klaus Neumann, Jochen Steil",1 - Research Institute for Cognition and Robotics (CoR-Lab Bielefeld University Germany,"This paper introduces the natural gradient for intrinsic plasticity, which tunes a neuron's activation function such that its output distribution becomes exponentially distributed. The information-geometric properties of the intrinsic plasticity potential are analyzed and the improved learning dynamics when using the natural gradient are evaluated for a variety of input distributions. The applied measure for evaluation is the relative geodesic length of the respective path in parameter space.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-15.pdf,2012,89.79591836734694,"Intrinsic Plasticity via Natural Gradient Descent This paper introduces the natural gradient for intrinsic plasticity, which tunes a neuron's activation function such that its output distribution becomes exponentially distributed. The information-geometric properties of the intrinsic plasticity potential are analyzed and the improved learning dynamics when using the natural gradient are evaluated for a variety of input distributions. The applied measure for evaluation is the relative geodesic length of the respective path in parameter space."
ÖÓÑ Ò ÙÖÓÒ Ð Ó×Ø¹ × Ñ ØÖ × ØÓÛ Ö × ×Ô Ö× Ó × Ò Ð× Ð ×× Ø ÓÒ,"Ò Óòý Åóùö Ù, ¸éù Òø Ò Öø Ð Ñý, ¸ Ùö Ð Ò Å Ýóù, ¸ Óùý¹è Ðð Ö 1 ¸ Ò Ø Óòý Ä Öù, ¸à Ð Ò È Ù Ñ¹åó ×ý",Unknown,"Stocks of the German Prime standard have to publish financial reports every three months which were not used fully for fundamental analysis so far. Through web scrapping, an up-to-date high-dimensional dataset of 45 features of 269 companies was extracted, but finding meaningful cluster structures in a high-dimensional dataset with a low number of cases is still a challenge in data science. A hybrid of a swarm with a SOM called Databionic swarm (DBS) found meaningful structures in the financial reports. Using the Chord distance the DBS algorithm results in a topographic map of high-dimensional structures and a clustering. Knowledge from the clustering is acquired using CART. The cluster structures can be explained by simple rules that allow predicting which future stock courses will fall with a 70% probability.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-34.pdf,2012,22.3463687150838,"ÖÓÑ Ò ÙÖÓÒ Ð Ó×Ø¹ × Ñ ØÖ × ØÓÛ Ö × ×Ô Ö× Ó × Ò Ð× Ð ×× Ø ÓÒ Stocks of the German Prime standard have to publish financial reports every three months which were not used fully for fundamental analysis so far. Through web scrapping, an up-to-date high-dimensional dataset of 45 features of 269 companies was extracted, but finding meaningful cluster structures in a high-dimensional dataset with a low number of cases is still a challenge in data science. A hybrid of a swarm with a SOM called Databionic swarm (DBS) found meaningful structures in the financial reports. Using the Chord distance the DBS algorithm results in a topographic map of high-dimensional structures and a clustering. Knowledge from the clustering is acquired using CART. The cluster structures can be explained by simple rules that allow predicting which future stock courses will fall with a 70% probability."
Recognition of HIV-1 subtypes and antiretroviral drug resistance using weightless neural networks,"Caio Souza, Flavio Nobre, Priscila Lima, Robson Silva, Rodrigo Brindeiro, Felipe França","1 - COPPE Universidade Federal do Rio de Janeiro Brazil
3 - DEMAT/ICE Universidade Federal Rural do Rio de Janeiro Brazil
5 - Laboratory of Molecular Virology Universidade Federal do Rio de Janeiro Brazil","This work presents an application of an improved version of the WiSARD weightless neural network in the recognition of different mutation types of HIV-1 and in the determination of antiretroviral drugs resistence. The data set used consists of 1205 gene sequence of the HIV-1 protease of subtypes B, C and F from patients under treatment failure. Experiments performed with the bleaching technique over the WiSARD model under different data representation strategies have shown promising results, both in terms of accuracy and standard deviation. 
 Materials and Methods 
 Database The data set were provided by Molecular Virology Laboratory at the Federal University of Rio de Janeiro (UFRJ / Brazil). This database consists of 1205 gene sequence of the HIV-1 protease from patients with HIV-1. The samples are distributed in 6 classes according to their subtype and drug resistance: B resistance (62%), B naïve (8%), C resistance (12%), C naïve (4%), F resistance (11,5%), F naive (1,5). This is distribution is similar to the Brazilian reality [4]. 
 WiSARD The WiSARD (Wilkie, Stonham and Aleksander's Recognition Device) is a weightless neural network based on the set of answers from RAM's memories. It was",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-154.pdf,2012,100.0,"Recognition of HIV-1 subtypes and antiretroviral drug resistance using weightless neural networks This work presents an application of an improved version of the WiSARD weightless neural network in the recognition of different mutation types of HIV-1 and in the determination of antiretroviral drugs resistence. The data set used consists of 1205 gene sequence of the HIV-1 protease of subtypes B, C and F from patients under treatment failure. Experiments performed with the bleaching technique over the WiSARD model under different data representation strategies have shown promising results, both in terms of accuracy and standard deviation. 
 Materials and Methods 
 Database The data set were provided by Molecular Virology Laboratory at the Federal University of Rio de Janeiro (UFRJ / Brazil). This database consists of 1205 gene sequence of the HIV-1 protease from patients with HIV-1. The samples are distributed in 6 classes according to their subtype and drug resistance: B resistance (62%), B naïve (8%), C resistance (12%), C naïve (4%), F resistance (11,5%), F naive (1,5). This is distribution is similar to the Brazilian reality [4]. 
 WiSARD The WiSARD (Wilkie, Stonham and Aleksander's Recognition Device) is a weightless neural network based on the set of answers from RAM's memories. It was"
Linear kernel combination using boosting,"Alexis Lechervy, Philippe-Henri Gosselin, Frédéric Precioso","1 - ETIS -CNRS ENSEA Université de Cergy-Pontoise 6 avenue du Ponceau F-95000 Cergy-Pontoise France
3 - route des Lucioles I3S -UMR7271 -UNS CNRS 2000, 06903 Sophia Antipolis France","In this paper, we propose a novel algorithm to design multiclass kernels based on an iterative combination of weak kernels in a schema inspired from the boosting framework. Our solution has a complexity linear with the training set size. We evaluate our method for classification on a toy example by integrating our multi-class kernel into a kNN classifier and comparing our results with a reference iterative kernel design method. We also evaluate our method for image categorization by considering a classic image database and comparing our boosted linear kernel combination with the direct linear combination of all features in a linear SVM.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-156.pdf,2012,100.0,"Linear kernel combination using boosting In this paper, we propose a novel algorithm to design multiclass kernels based on an iterative combination of weak kernels in a schema inspired from the boosting framework. Our solution has a complexity linear with the training set size. We evaluate our method for classification on a toy example by integrating our multi-class kernel into a kNN classifier and comparing our results with a reference iterative kernel design method. We also evaluate our method for image categorization by considering a classic image database and comparing our boosted linear kernel combination with the direct linear combination of all features in a linear SVM."
Extraction of Betti numbers based on a generative model,"Maxime Maillot, Michaël Aupetit, Gerard Govaert","1 - -CEA, LIST, Information, Models and Machine Learning Laboratory (LIMA) F-91191 Gif-sur-Yvette France
3 - University of Technology of Compiegne -Heudiasyc BP 20529 F 60205 Compiègne France","Analysis of multidimensional data is challenging. Topological invariants can be used to summarize essential features of such data sets. In this work, we propose to compute the Betti numbers from a generative model based on a simplicial complex learnt from the data. We compare it to the Witness Complex, a geometric technique based on nearest neighbors. Our results on different data distributions with known topology show that Betti numbers are well recovered with our method.",Nonlinear dimensionality reduction and topological learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-157.pdf,2012,64.34782608695653,"Extraction of Betti numbers based on a generative model Analysis of multidimensional data is challenging. Topological invariants can be used to summarize essential features of such data sets. In this work, we propose to compute the Betti numbers from a generative model based on a simplicial complex learnt from the data. We compare it to the Witness Complex, a geometric technique based on nearest neighbors. Our results on different data distributions with known topology show that Betti numbers are well recovered with our method."
The stability of feature selection and class prediction from ensemble tree classifiers,"Jérôme Paul, Michel Verleysen, Pierre Dupont",1 - ICTEAM/Machine Learning Group Université catholique de Louvain Place Sainte Barbe 2 1348 Louvain-la-Neuve Belgium,"The bootstrap aggregating procedure at the core of ensemble tree classifiers reduces, in most cases, the variance of such models while offering good generalization capabilities. The average predictive performance of those ensembles is known to improve up to a certain point while increasing the ensemble size. The present work studies this convergence in contrast to the stability of the class prediction and the variable selection performed while and after growing the ensemble. Experiments on several biomedical datasets, using random forests or bagging of decision trees, show that class prediction and, most notably, variable selection typically require orders of magnitude more trees to get stable. 
 Ensemble of tree classifiers Bagging of decision trees is arguably among the simplest approaches to overcome the strong tendency of a single decision tree to over-fit the learning data.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-158.pdf,2012,100.0,"The stability of feature selection and class prediction from ensemble tree classifiers The bootstrap aggregating procedure at the core of ensemble tree classifiers reduces, in most cases, the variance of such models while offering good generalization capabilities. The average predictive performance of those ensembles is known to improve up to a certain point while increasing the ensemble size. The present work studies this convergence in contrast to the stability of the class prediction and the variable selection performed while and after growing the ensemble. Experiments on several biomedical datasets, using random forests or bagging of decision trees, show that class prediction and, most notably, variable selection typically require orders of magnitude more trees to get stable. 
 Ensemble of tree classifiers Bagging of decision trees is arguably among the simplest approaches to overcome the strong tendency of a single decision tree to over-fit the learning data."
Quantile regression with multilayer perceptrons,"S.-F Dimby, J Rynkiewicz",1 - Universite Paris 1 -SAMM 90 Rue de Tolbiac 75013 Paris France,"We consider nonlinear quantile regression involving multilayer perceptrons (MLP). In this paper we investigate the asymptotic behavior of quantile regression in a general framework. First by allowing possibly non-identifiable regression models like MLP's with redundant hidden units, then by relaxing the conditions on the density of the noise. In this paper, we present an universal bound for the overfitting of such model under weak assumptions. The main application of this bound is to give a hint about determining the true architecture of the MLP quantile regression model. As an illustration, we use this theoretical result to propose and compare effective criteria to find the true architecture of such regression model.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-159.pdf,2012,98.94736842105263,"Quantile regression with multilayer perceptrons We consider nonlinear quantile regression involving multilayer perceptrons (MLP). In this paper we investigate the asymptotic behavior of quantile regression in a general framework. First by allowing possibly non-identifiable regression models like MLP's with redundant hidden units, then by relaxing the conditions on the density of the noise. In this paper, we present an universal bound for the overfitting of such model under weak assumptions. The main application of this bound is to give a hint about determining the true architecture of the MLP quantile regression model. As an illustration, we use this theoretical result to propose and compare effective criteria to find the true architecture of such regression model."
Learning Object-Class Segmentation with Convolutional Neural Networks,"Hannes Schulz, Sven Behnke",1 - University Bonn -Computer Science VI Autonomous Intelligent Systems Friedrich-Ebert-Allee 144 53113 Bonn Germany,"After successes at image classification, segmentation is the next step towards image understanding for neural networks. We propose a convolutional network architecture that includes innovative elements, such as multiple output maps, suitable loss functions, supervised pretraining, multiscale inputs, reused outputs, and pairwise class location filters. Experiments on three data sets show that our method performs on par with current in computer vision methods with regards to accuracy and exceeds them in speed.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-160.pdf,2012,100.0,"Learning Object-Class Segmentation with Convolutional Neural Networks After successes at image classification, segmentation is the next step towards image understanding for neural networks. We propose a convolutional network architecture that includes innovative elements, such as multiple output maps, suitable loss functions, supervised pretraining, multiscale inputs, reused outputs, and pairwise class location filters. Experiments on three data sets show that our method performs on par with current in computer vision methods with regards to accuracy and exceeds them in speed."
gNBXe -a Reconfigurable Neuroprocessor for Various Types of Self-Organizing Maps,"Jan Lachmair, Erzsébet Merényi, Mario Porrmann, Ulrich Rückert","1 - University of Bielefeld -Cognitronics and Sensor Systems Bielefeld Germany
2 - Rice University -Department of Statistics Houston Texas U.S.A
5 - Center of Excellence Cognitive Interaction Technology (CITEC)","In this paper we present the FPGA-based hardware accelerator gNBXe for emulation of classical Self-Organizing Maps (SOMs) and Conscience SOM (CSOM) in a multi-FPGA environment. After discussing how the CSOM is mapped to a resource-efficient digital hardware implementation, we present how the modular system architecture can be flexibly adapted to various application datasets. The hardware costs and scalability of a multi-FPGA based accelerator using Xilinx Virtex2 and Virtex4 FPGAs are discussed. Compared to a state-of-the-art multi-core PC, a speedup of 9.1 is achieved for a CSOM with 4, 840 neurons and 196 synaptic weights.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-161.pdf,2012,97.53086419753086,"gNBXe -a Reconfigurable Neuroprocessor for Various Types of Self-Organizing Maps In this paper we present the FPGA-based hardware accelerator gNBXe for emulation of classical Self-Organizing Maps (SOMs) and Conscience SOM (CSOM) in a multi-FPGA environment. After discussing how the CSOM is mapped to a resource-efficient digital hardware implementation, we present how the modular system architecture can be flexibly adapted to various application datasets. The hardware costs and scalability of a multi-FPGA based accelerator using Xilinx Virtex2 and Virtex4 FPGAs are discussed. Compared to a state-of-the-art multi-core PC, a speedup of 9.1 is achieved for a CSOM with 4, 840 neurons and 196 synaptic weights."
Unmixing Hyperspectral Images with Fuzzy Supervised Self-Organizing Maps,"T Villmann, E Merényi, W Farrand","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Germany
2 - Rice University Houston -Dept. of Statistics Houston TX USA
3 - Space Science Institute Boulder CO USA","We propose a powerful alternative to customary linear spectral unmixing, with a new neural model, which achieves locally linear but globally non-linear unmixing. This enables unmixing with respect to a large number of endmembers, while traditional linear unmixing is limited to a handful of endmembers.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-162.pdf,2012,100.0,"Unmixing Hyperspectral Images with Fuzzy Supervised Self-Organizing Maps We propose a powerful alternative to customary linear spectral unmixing, with a new neural model, which achieves locally linear but globally non-linear unmixing. This enables unmixing with respect to a large number of endmembers, while traditional linear unmixing is limited to a handful of endmembers."
Hybrid Hierarchical Clustering: Cluster Assessment via Cluster Validation Indices,"Mark Embrechts, Jonathan Linton, Christopher Gatti","1 - Rensselaer Polytechnic Institute -Industrial and Systems Engineering Troy 12180 NY USA
2 - University of Ottawa Telfer School of Management Ottawa K1N 6N5 ON Canada","This paper introduces a hybrid hierarchical clustering method, which is a novel method for speeding up agglomerative hierarchical clustering by seeding the algorithm with clusters obtained from K-means clustering. This work describes a benchmark study comparing the performance of hybrid hierarchical clustering to that of conventional hierarchical clustering. The two clustering methods are compared for 16 benchmark data sets based on the cluster validation index signature, an aggregation of several cluster indices. In most cases, the cluster signatures indicate similar clusterings for unseeded and seeded hierarchical clustering.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-163.pdf,2012,83.9506172839506,"Hybrid Hierarchical Clustering: Cluster Assessment via Cluster Validation Indices This paper introduces a hybrid hierarchical clustering method, which is a novel method for speeding up agglomerative hierarchical clustering by seeding the algorithm with clusters obtained from K-means clustering. This work describes a benchmark study comparing the performance of hybrid hierarchical clustering to that of conventional hierarchical clustering. The two clustering methods are compared for 16 benchmark data sets based on the cluster validation index signature, an aggregation of several cluster indices. In most cases, the cluster signatures indicate similar clusterings for unseeded and seeded hierarchical clustering."
Functional Mixture Discriminant Analysis with hidden process regression for curve classification,"Faicel Chamroukhi, Hervé Glotin, Céline Rabouy","1 - -Information Sciences and Systems Laboratory (LSIS) UMR CNRS 7296 University of the South Toulon-Var 83957 La Garde Cedex France
3 - Institut Universitaire de France",We present a new mixture model-based discriminant analysis approach for functional data using a specific hidden process regression model. The approach allows for fitting flexible curve-models to each class of complex-shaped curves presenting regime changes. The model parameters are learned by maximizing the observed-data log-likelihood for each class by using a dedicated expectation-maximization (EM) algorithm. Comparisons on simulated data with alternative approaches show that the proposed approach provides better results.,"Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-165.pdf,2012,100.0,Functional Mixture Discriminant Analysis with hidden process regression for curve classification We present a new mixture model-based discriminant analysis approach for functional data using a specific hidden process regression model. The approach allows for fitting flexible curve-models to each class of complex-shaped curves presenting regime changes. The model parameters are learned by maximizing the observed-data log-likelihood for each class by using a dedicated expectation-maximization (EM) algorithm. Comparisons on simulated data with alternative approaches show that the proposed approach provides better results.
Discriminant functional gene groups identification with machine learning and prior knowledge,"Grzegorz Zycinski, Margherita Squillario, Annalisa Barla, Tiziana Sanavia, Alessandro Verri, Barbara Camillo","1 - Department of Computer and Information Science University of Genoa via Dodecaneso 35 I-16146 Genova Italy
4 - Information Engineering Department University of Padova via Gradenigo 6A I-35131 Padova Italy","In computational biology, the analysis of high-throughput data poses several issues on the reliability, reproducibility and interpretability of the results. It has been suggested that one reason for these inconsistencies may be that in complex diseases, such as cancer, multiple genes belonging to one or more physiological pathways are associated with the outcomes. Thus, a possible approach to improve list interpretability is to integrate biological information from genomic databases in the learning process. Here we propose KDVS, a machine learning based pipeline that incorporates domain biological knowledge a priori to structure the data matrix before the feature selection and classification phases. The pipeline is completed by a final step of semantic clustering and visualization. The clustering phase provides further interpretability of the results, allowing the identification of their biological meaning. To prove the efficacy of this procedure we analyzed a public dataset on prostate cancer.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-167.pdf,2012,100.0,"Discriminant functional gene groups identification with machine learning and prior knowledge In computational biology, the analysis of high-throughput data poses several issues on the reliability, reproducibility and interpretability of the results. It has been suggested that one reason for these inconsistencies may be that in complex diseases, such as cancer, multiple genes belonging to one or more physiological pathways are associated with the outcomes. Thus, a possible approach to improve list interpretability is to integrate biological information from genomic databases in the learning process. Here we propose KDVS, a machine learning based pipeline that incorporates domain biological knowledge a priori to structure the data matrix before the feature selection and classification phases. The pipeline is completed by a final step of semantic clustering and visualization. The clustering phase provides further interpretability of the results, allowing the identification of their biological meaning. To prove the efficacy of this procedure we analyzed a public dataset on prostate cancer."
Constructing similarity networks using the Fisher information metric,"H Ruiz, S Ortega-Martorell, I Jarman, J Martín, P Lisboa","1 - School of Computing and Mathematical Sciences -Department of Mathematics and Statistics -LJMU L3 3AF Liverpool UK
2 - Departament de Bioquímica
4 - Escuela Técnica Superior de Ingeniería -Departamento de Ingeniería Electrónica Universidad de Valencia Burjassot Valencia) Spain
6 - Biología Molecular -Universitat Autònoma de Barcelona Cerdanyola del Vallés (Barcelona) Spain","The Fisher information metric defines a Riemannian space where distances reflect similarity with respect to a given probability distribution. This metric can be used during the process of building a relational network, resulting in a structure that is informed about the similarity criterion. Furthermore, the relational nature of this network allows for an intuitive interpretation of the data through their location within the network and the way it relates to the most representative cases or prototypes.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-169.pdf,2012,100.0,"Constructing similarity networks using the Fisher information metric The Fisher information metric defines a Riemannian space where distances reflect similarity with respect to a given probability distribution. This metric can be used during the process of building a relational network, resulting in a structure that is informed about the similarity criterion. Furthermore, the relational nature of this network allows for an intuitive interpretation of the data through their location within the network and the way it relates to the most representative cases or prototypes."
Weighted/Structured Total Least Squares Problems and Polynomial System Solving,"Philippe Dreesen, Kim Batselier, Bart De Moor",1 - Dept. Electrical Engineering KU Leuven ESAT/SCD-SISTA ‡ KU Leuven IBBT Future Health Department,"Weighted and Structured Total Least Squares (W/STLS) problems are generalizations of Total Least Squares with additional weighting and/or structure constraints. W/STLS are found at the heart of several mathematical engineering techniques, such as statistics and systems theory, and are typically solved by local optimization methods, having the drawback that one cannot guarantee global optimality of the retrieved solution. This paper employs the Riemannian SVD formulation to write the W/STLS problem as a system of polynomial equations. Using a novel matrix technique for solving systems of polynomial equations, the globally optimal solution of the W/STLS problem is retrieved. * PD is a research assistant with the KU Leuven and is supported by the Institute for the Promotion of Innovation through Science and Technology in Flanders (IWT-Vlaanderen). KB is a research assistant with the KU Leuven. BDM is a full professor with the KU Leuven.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-170.pdf,2012,55.12820512820513,"Weighted/Structured Total Least Squares Problems and Polynomial System Solving Weighted and Structured Total Least Squares (W/STLS) problems are generalizations of Total Least Squares with additional weighting and/or structure constraints. W/STLS are found at the heart of several mathematical engineering techniques, such as statistics and systems theory, and are typically solved by local optimization methods, having the drawback that one cannot guarantee global optimality of the retrieved solution. This paper employs the Riemannian SVD formulation to write the W/STLS problem as a system of polynomial equations. Using a novel matrix technique for solving systems of polynomial equations, the globally optimal solution of the W/STLS problem is retrieved. * PD is a research assistant with the KU Leuven and is supported by the Institute for the Promotion of Innovation through Science and Technology in Flanders (IWT-Vlaanderen). KB is a research assistant with the KU Leuven. BDM is a full professor with the KU Leuven."
Application of Dynamic Time Warping on Kalman Filtering Framework for Abnormal ECG Filtering,"Mohammad Niknazar, Bertrand Rivet, Christian Jutten",1 - CNRS University of Grenoble Grenoble 5216 France,"Existing nonlinear Bayesian filtering frameworks serve as an effective tool for the model-based filtering of noisy ECG recordings. However, since these methods are based on linear phase assumption, for some heart defects where abnormal waves only appear in certain cycles of the ECG, they are unable to simultaneously filter the normal and abnormal ECG segments. In this paper, a new method based on Dynamic Time Warping (DTW), which benefits information of all channels for nonlinear phase state calculation is presented. Results on real and synthetic data show that the new method can be successfully applied for filtering normal and abnormal ECG segments simultaneously.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-171.pdf,2012,100.0,"Application of Dynamic Time Warping on Kalman Filtering Framework for Abnormal ECG Filtering Existing nonlinear Bayesian filtering frameworks serve as an effective tool for the model-based filtering of noisy ECG recordings. However, since these methods are based on linear phase assumption, for some heart defects where abnormal waves only appear in certain cycles of the ECG, they are unable to simultaneously filter the normal and abnormal ECG segments. In this paper, a new method based on Dynamic Time Warping (DTW), which benefits information of all channels for nonlinear phase state calculation is presented. Results on real and synthetic data show that the new method can be successfully applied for filtering normal and abnormal ECG segments simultaneously."
The Exploration vs Exploitation Trade-Off in Bandit Problems: An Empirical Study,"Saba Yahyaa, Bernard Manderick",1 - Vrije Universiteit Brussel -Computational Modeling Lab Pleinlaan 2 B-1050 Brussels Belgium,We compare well-known action selection policies used in reinforcement learning like ǫ-greedy and softmax with lesser known ones like the Gittins index and the knowledge gradient on bandit problems. The latter two are in comparison very performant. Moreover the knowledge gradient can be generalized to other than bandit problems.,"Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-172.pdf,2012,100.0,The Exploration vs Exploitation Trade-Off in Bandit Problems: An Empirical Study We compare well-known action selection policies used in reinforcement learning like ǫ-greedy and softmax with lesser known ones like the Gittins index and the knowledge gradient on bandit problems. The latter two are in comparison very performant. Moreover the knowledge gradient can be generalized to other than bandit problems.
Learning visuo-motor coordination for pointing without depth calculation,"Ananda Freire, Andre Lemme, Jochen Steil, Guilherme Barreto, Av N -Bloco, Fortaleza -Brazil","1 - Federal University of Ceará -Dept.of Engineering of Teleinformatics
2 - Faculty of Technology Institute for Cognition and Robotics (CoR-Lab) Bielefeld University 33615 Bielefeld Germany","Pointing refers to orienting a hand, arm, head or body towards an object and is possible without calculating the object's depth and 3D position. We show that pointing can be learned as holistic direct mapping from an object's pixel coordinates in the visual field to joint angles, which define pose and orientation of a human or robot. To this aim, we record real world and noisy training images together with corresponding robot pointing postures for the humanoid robot iCub. We then learn and comparatively evaluate pointing with an multi-layer perceptron, an extreme learning machine and a reservoir network, but also demonstrate that learning fails at reconstructing the depth of trained objects.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-173.pdf,2012,100.0,"Learning visuo-motor coordination for pointing without depth calculation Pointing refers to orienting a hand, arm, head or body towards an object and is possible without calculating the object's depth and 3D position. We show that pointing can be learned as holistic direct mapping from an object's pixel coordinates in the visual field to joint angles, which define pose and orientation of a human or robot. To this aim, we record real world and noisy training images together with corresponding robot pointing postures for the humanoid robot iCub. We then learn and comparatively evaluate pointing with an multi-layer perceptron, an extreme learning machine and a reservoir network, but also demonstrate that learning fails at reconstructing the depth of trained objects."
Recurrent Neural State Estimation in Domains with Long-Term Dependencies,"Siegmund Duell, Lina Weichbrodt, Alexander Hans, Steffen Udluft","1 - Siemens AG, Corporate Technology Intelligent Systems & Control Otto-Hahn-Ring 6 81739 Munich Germany
2 - Berlin University of Technology Machine Learning Franklinstr. 28-29 10587 Berlin Germany
4 - Otto-von-Guericke-University Magdeburg P.O.Box 4120 39016 Magdeburg Germany
6 - Neuroinformatics and Cognitive Robotics Lab Ilmenau University of Technology P.O.Box 100565 98684 Ilmenau Germany","This paper presents a state estimation approach for reinforcement learning (RL) of a partially observable Markov decision process. It is based on a special recurrent neural network architecture, the Markov decision process extraction network with shortcuts (MPEN-S). In contrast to previous work regarding this topic, we address the problem of long-term dependencies, which cause major problems in many real-world applications. The architecture is designed to model the reward-relevant dynamics of an environment and is capable to condense large sets of continuous observables to a compact Markovian state representation. The resulting estimate can be used as input for RL methods that assume the underlying system to be a Markov decision process. Although the approach was developed with RL in mind, it is also useful for general prediction tasks. * This work has been supported by the German Ministry for Education and Science (BMBF) under grand ""ALICE"" (Autonomous Learning in Complex Environments).","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-174.pdf,2012,100.0,"Recurrent Neural State Estimation in Domains with Long-Term Dependencies This paper presents a state estimation approach for reinforcement learning (RL) of a partially observable Markov decision process. It is based on a special recurrent neural network architecture, the Markov decision process extraction network with shortcuts (MPEN-S). In contrast to previous work regarding this topic, we address the problem of long-term dependencies, which cause major problems in many real-world applications. The architecture is designed to model the reward-relevant dynamics of an environment and is capable to condense large sets of continuous observables to a compact Markovian state representation. The resulting estimate can be used as input for RL methods that assume the underlying system to be a Markov decision process. Although the approach was developed with RL in mind, it is also useful for general prediction tasks. * This work has been supported by the German Ministry for Education and Science (BMBF) under grand ""ALICE"" (Autonomous Learning in Complex Environments)."
Balancing of Neural Contributions for Multi-modal Hidden State Association,"Christian Emmerich, R Reinhart, Jochen Steil",1 - Research Institute for Cognition and Robotics Bielefeld University Universitätsstr. 25 33615 Bielefed Germany,We generalize the formulation of associative reservoir computing networks to multiple input modalities and demonstrate applications in image and audio processing scenarios. Robust association with reservoir networks requires to cope with potential error amplification of output feedback dynamics and to handle differently sized input and output modalities. We propose a dendritic neuron model in combination with a modified reservoir regularization technique to address both issues.,Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-175.pdf,2012,70.27027027027026,Balancing of Neural Contributions for Multi-modal Hidden State Association We generalize the formulation of associative reservoir computing networks to multiple input modalities and demonstrate applications in image and audio processing scenarios. Robust association with reservoir networks requires to cope with potential error amplification of output feedback dynamics and to handle differently sized input and output modalities. We propose a dendritic neuron model in combination with a modified reservoir regularization technique to address both issues.
A CUSUM approach for online change-point detection on curve sequences,"Nicolas Cheifetz, Allou Samé, Patrice Aknin, Emmanuel De Verdalle","1 - Université Paris-Est IFSTTAR GRETTIA
2 - Veolia Environnement Recherche & Innovation (VERI)","Anomaly detection on sequential data is common in many domains such as fraud detection for credit cards, intrusion detection for cyber-security or military surveillance. This paper addresses a new CUSUMlike method for change point detection on curves sequences in a context of preventive maintenance of transit buses door systems. The proposed approach is derived from a specific generative modeling of curves. The system is considered out of control when the parameters of the curves density change. Experimental studies performed on realistic world data demonstrate the promising behavior of the proposed method. 
 Review of CUSUM-like algorithms for multivariate data Let us suppose that data are multivariate observations x 1 , . . . , x t , . . . sequentially received. The classical CUSUM algorithm  [2]  consists in deciding about which",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-176.pdf,2012,100.0,"A CUSUM approach for online change-point detection on curve sequences Anomaly detection on sequential data is common in many domains such as fraud detection for credit cards, intrusion detection for cyber-security or military surveillance. This paper addresses a new CUSUMlike method for change point detection on curves sequences in a context of preventive maintenance of transit buses door systems. The proposed approach is derived from a specific generative modeling of curves. The system is considered out of control when the parameters of the curves density change. Experimental studies performed on realistic world data demonstrate the promising behavior of the proposed method. 
 Review of CUSUM-like algorithms for multivariate data Let us suppose that data are multivariate observations x 1 , . . . , x t , . . . sequentially received. The classical CUSUM algorithm  [2]  consists in deciding about which"
Real Time Drunkenness Analysis in a Realistic Car Simulation,"Robinel Audrey, Puzenat Didier",1 - Laboratoire LAMIA Université Antilles Guyane Campus de Fouillole -Guadeloupe France,"This paper describes a blood alcohol content estimation method for car driver, based on a comportment analysis performed within a realistic simulation. An artificial neural network learns how to estimate the subject's blood alcohol content. Low-level recording of user actions on the steering wheel and pedals are used to feed a multilayer perceptron, and a breathalyzer is used to build the learning examples set (desired output). Results are compared with a successful previous work based on a simple video game and demonstrate the ""complexity scalability"" of the approach. * This work has been funded by ApportMédia (www.apportmedia.fr), la Région Guadeloupe (www.cr-guadeloupe.fr), and the European Social Fund (ec.europa.eu/esf).",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-177.pdf,2012,75.0,"Real Time Drunkenness Analysis in a Realistic Car Simulation This paper describes a blood alcohol content estimation method for car driver, based on a comportment analysis performed within a realistic simulation. An artificial neural network learns how to estimate the subject's blood alcohol content. Low-level recording of user actions on the steering wheel and pedals are used to feed a multilayer perceptron, and a breathalyzer is used to build the learning examples set (desired output). Results are compared with a successful previous work based on a simple video game and demonstrate the ""complexity scalability"" of the approach. * This work has been funded by ApportMédia (www.apportmedia.fr), la Région Guadeloupe (www.cr-guadeloupe.fr), and the European Social Fund (ec.europa.eu/esf)."
Manifold-based non-parametric learning of action-value functions,"Hunor Jakab, Lehel Csató",1 - Faculty of Mathematics and Informatics Babeş-Bolyai University 1 Kogâlniceanu str RO-400084 Cluj-Napoca Romania,"Finding good approximations to state-action value functions is a central problem in model-free on-line reinforcement learning. The use of non-parametric function approximators enables us to simultaneously represent model and confidence. Since Q functions are usually discontinuous, we present a novel Gaussian process (GP) kernel function to cope with discontinuity. We use a manifold-based distance measure in our kernels, the manifold being induced by the graph structure extracted from data. Using on-line learning, the graph formation is parallel with the estimation algorithm. This results in a compact and efficient graph structure, eliminates the need for predefined function class and improves the accuracy of the estimated value functions, as tested on simulated robotic control tasks.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-179.pdf,2012,100.0,"Manifold-based non-parametric learning of action-value functions Finding good approximations to state-action value functions is a central problem in model-free on-line reinforcement learning. The use of non-parametric function approximators enables us to simultaneously represent model and confidence. Since Q functions are usually discontinuous, we present a novel Gaussian process (GP) kernel function to cope with discontinuity. We use a manifold-based distance measure in our kernels, the manifold being induced by the graph structure extracted from data. Using on-line learning, the graph formation is parallel with the estimation algorithm. This results in a compact and efficient graph structure, eliminates the need for predefined function class and improves the accuracy of the estimated value functions, as tested on simulated robotic control tasks."
One Class SVM and Canonical Correlation Analysis increase performance in a c-VEP based Brain-Computer Interface (BCI),"Martin Spüler, Wolfgang Rosenstiel, Martin Bogdan","1 - Wilhelm-Schickard-Institute for Computer Science -University of Tübingen Sand 13 72076 Tübingen Germany
4 - -Computer Engineering University of Leipzig Postfach 10 09 20 04103 Leipzig Germany","The goal of a Brain-Computer Interface (BCI) is to enable communication by pure brain activity without the need for muscle control. Recently BCIs based on code-modulated visual evoked potentials (c-VEPs) have shown great potential to establish high-performance communication. In this paper we present two new methods to improve classification in a c-VEP BCI. Canonical correlation analysis can be used to build an optimal spatial filter for detection of c-VEPs, while the use of a one class support vector machine (OCSVM) makes the BCI more robust in terms of artefacts and thus increases performance. We show both methods to increase performance in an offline analysis on data from 8 subjects. As a proof of concept both methods are tested online with one subject, who achieved an average performance of 133 bit/min, which is higher than any other bitrate reported so far for a non-invasive BCI.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-18.pdf,2012,100.0,"One Class SVM and Canonical Correlation Analysis increase performance in a c-VEP based Brain-Computer Interface (BCI) The goal of a Brain-Computer Interface (BCI) is to enable communication by pure brain activity without the need for muscle control. Recently BCIs based on code-modulated visual evoked potentials (c-VEPs) have shown great potential to establish high-performance communication. In this paper we present two new methods to improve classification in a c-VEP BCI. Canonical correlation analysis can be used to build an optimal spatial filter for detection of c-VEPs, while the use of a one class support vector machine (OCSVM) makes the BCI more robust in terms of artefacts and thus increases performance. We show both methods to increase performance in an offline analysis on data from 8 subjects. As a proof of concept both methods are tested online with one subject, who achieved an average performance of 133 bit/min, which is higher than any other bitrate reported so far for a non-invasive BCI."
Sparse Nonparametric Topic Model for Transfer Learning,"Ali Faisal, Jussi Gillberg, Jaakko Peltonen, Gayle Leen, Samuel Kaski","1 - Department of Information and Computer Science Helsinki Institute for Information Technology HIIT Aalto University
5 - Department of Computer Science Helsinki Institute for Information Technology HIIT University of Helsinki","Count data arises for example in bioinformatics or analysis of text documents represented as word count vectors. With several data sets available from related sources, exploiting their similarities by transfer learning can improve models compared to modeling sources independently. We introduce a Bayesian generative transfer learning model which represents similarity across document collections by sparse sharing of latent topics controlled by an Indian Buffet Process. Unlike Hierarchical Dirichlet Process based multi-task learning, our model decouples topic sharing probability from topic strength, making sharing of low-strength topics easier, and outperforms the HDP approach in experiments.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-183.pdf,2012,100.0,"Sparse Nonparametric Topic Model for Transfer Learning Count data arises for example in bioinformatics or analysis of text documents represented as word count vectors. With several data sets available from related sources, exploiting their similarities by transfer learning can improve models compared to modeling sources independently. We introduce a Bayesian generative transfer learning model which represents similarity across document collections by sparse sharing of latent topics controlled by an Indian Buffet Process. Unlike Hierarchical Dirichlet Process based multi-task learning, our model decouples topic sharing probability from topic strength, making sharing of low-strength topics easier, and outperforms the HDP approach in experiments."
Incremental feature computation and classification for image segmentation,"Guillaume Bernard, Michel Verleysen, John Lee","1 - Molecular Imaging, Radiotherapy, and Oncology -IREC Université catholique de Louvain Belgium
2 - -Machine Learning Group -ICTEAM Université catholique de Louvain Belgium","Image segmentation problems can be solved with classification algorithms. However, their use is limited to features derived from intensities of pixels or patches. Features such as contiguity of two regions cannot be considered without prior knowledge of one of the two class labels. Instead of stacking various classification algorithms, we describe an incremental classifier that works in a space where features are progressively evaluated. Experiments on artificial images demonstrate the capabilities of this incremental scheme.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-185.pdf,2012,85.3146853146853,"Incremental feature computation and classification for image segmentation Image segmentation problems can be solved with classification algorithms. However, their use is limited to features derived from intensities of pixels or patches. Features such as contiguity of two regions cannot be considered without prior knowledge of one of the two class labels. Instead of stacking various classification algorithms, we describe an incremental classifier that works in a space where features are progressively evaluated. Experiments on artificial images demonstrate the capabilities of this incremental scheme."
Hidden Markov models for time series of counts with excess zeros,"Madalina Olteanu, James Ridgway","1 - University Paris 1 Pantheon-Sorbonne -SAMM, EA4543 90 Rue de Tolbiac 75013 Paris France","Integer-valued time series are often modeled with Markov models or hidden Markov models (HMM). However, when the series represents count data it is often subject to excess zeros. In this case, usual distributions such as binomial or Poisson are unable to estimate the zero mass correctly. In order to overcome this issue, we introduce zero-inflated distributions in the hidden Markov model. The empirical results on simulated and real data show good convergence properties, while excess zeros are better estimated than with classical HMM. * James Ridgway is currently 3rd year ENSAE student. His internship at SAMM was funded by the University Paris 1 through the ""Analyse"" project (http://analyseshs.hypotheses.org/). The authors are acknowledging Julien Alerini for his useful comments and support.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-187.pdf,2012,100.0,"Hidden Markov models for time series of counts with excess zeros Integer-valued time series are often modeled with Markov models or hidden Markov models (HMM). However, when the series represents count data it is often subject to excess zeros. In this case, usual distributions such as binomial or Poisson are unable to estimate the zero mass correctly. In order to overcome this issue, we introduce zero-inflated distributions in the hidden Markov model. The empirical results on simulated and real data show good convergence properties, while excess zeros are better estimated than with classical HMM. * James Ridgway is currently 3rd year ENSAE student. His internship at SAMM was funded by the University Paris 1 through the ""Analyse"" project (http://analyseshs.hypotheses.org/). The authors are acknowledging Julien Alerini for his useful comments and support."
Relevance learning for time series inspection,"Andrej Gisbrecht, Dusan Sovilj, Barbara Hammer, Amaury Lendasse","1 - University of Bielefeld -CITEC Centre of Excellence Germany
2 - Department of Information and Computer Science Aalto University -School of Science Finland
5 - IKERBASQUE Basque Foundation for Science Spain","By means of local neighborhood regression and time windows, the generative topographic mapping (GTM) allows to predict and visually inspect time series data. GTM itself, however, is fully unsupervised. In this contribution, we propose an extension of relevance learning to time series regression with GTM. This way, the metric automatically adapts according to the relevant time lags resulting in a sparser representation, improved accuracy, and smoother visualization of the data.",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-188.pdf,2012,100.0,"Relevance learning for time series inspection By means of local neighborhood regression and time windows, the generative topographic mapping (GTM) allows to predict and visually inspect time series data. GTM itself, however, is fully unsupervised. In this contribution, we propose an extension of relevance learning to time series regression with GTM. This way, the metric automatically adapts according to the relevant time lags resulting in a sparser representation, improved accuracy, and smoother visualization of the data."
Short Term Memory Quantifications in Input-Driven Linear Dynamical Systems,"Peter Tiňo, Ali Rodan",1 - School of Computer Science The University of Birmingham B15 2TT Birmingham United Kingdom,"We investigate the relation between two quantitative measures characterizing short term memory in input driven dynamical systems, namely the short term memory capacity (MC) [2] and the Fisher memory curve (FMC)  [1] . We show that under some assumptions, the two quantities can be interpreted as squared 'Mahalanobis' norms of images of the input vector under the system's dynamics and that even though MC and FMC map the memory structure of the system from two quite different perspectives, they can be linked by a close relation.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-189.pdf,2012,100.0,"Short Term Memory Quantifications in Input-Driven Linear Dynamical Systems We investigate the relation between two quantitative measures characterizing short term memory in input driven dynamical systems, namely the short term memory capacity (MC) [2] and the Fisher memory curve (FMC)  [1] . We show that under some assumptions, the two quantities can be interpreted as squared 'Mahalanobis' norms of images of the input vector under the system's dynamics and that even though MC and FMC map the memory structure of the system from two quite different perspectives, they can be linked by a close relation."
On the Independence of the Individual Predictions in Parallel Randomized Ensembles,"Daniel Hernández-Lobato, Gonzalo Martínez-Muñoz, Alberto Suárez","1 - Escuela Politécnica Superior Universidad Autónoma de Madrid
2 - C/ Francisco Tomás y Valiente 11 28049 Madrid Spain","In randomized parallel ensembles the class label predictions for a particular instance by different ensemble classifiers are independent random variables. Taking advantage of this independence we design a statistical test to identify instances near the decision borders, which are difficult to classify because of their proximity to these borders. For these instances, the performance of the ensemble is poor and approaches random guessing. The validity of this analysis and the usefulness of the proposed statistical test are illustrated in several real-world classification problems. * The authors acknowledge financial support from the Spanish Dirección General de Investigación, project TIN2010-21575-C02-02.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-19.pdf,2012,100.0,"On the Independence of the Individual Predictions in Parallel Randomized Ensembles In randomized parallel ensembles the class label predictions for a particular instance by different ensemble classifiers are independent random variables. Taking advantage of this independence we design a statistical test to identify instances near the decision borders, which are difficult to classify because of their proximity to these borders. For these instances, the performance of the ensemble is poor and approaches random guessing. The validity of this analysis and the usefulness of the proposed statistical test are illustrated in several real-world classification problems. * The authors acknowledge financial support from the Spanish Dirección General de Investigación, project TIN2010-21575-C02-02."
Modified Conn-Index for the evaluation of fuzzy clusterings,"Tina Geweniger, Marika Kästner, Mandy Lange, Thomas Villmann","1 - Johann Bernoulli Institute for Mathematics and Computer Science University of Groningen The Netherlands
2 - Computational Intelligence Group University of Applied Sciences Mittweida Technikumplatz 17 09648 Mittweida Germany","We propose an extension of the Conn-Index to evaluate fuzzy cluster solutions obtained from fuzzy prototype vector quantization, whereas the original Conn-Index was designed for crisp vector quantization models. The fuzzy index explicitly takes the fuzzy assignments resulting from fuzzy vector quantization into account. This avoids the information loss which would occur if the original crisp index is applied to fuzzy solutions.",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-22.pdf,2012,100.0,"Modified Conn-Index for the evaluation of fuzzy clusterings We propose an extension of the Conn-Index to evaluate fuzzy cluster solutions obtained from fuzzy prototype vector quantization, whereas the original Conn-Index was designed for crisp vector quantization models. The fuzzy index explicitly takes the fuzzy assignments resulting from fuzzy vector quantization into account. This avoids the information loss which would occur if the original crisp index is applied to fuzzy solutions."
Complex Valued Artificial Recurrent Neural Network as a Novel Approach to Model the Perceptual Binding Problem,"Alexey Minin, Alois Knoll, Hans-Georg Zimmermann","1 - Technische Universitaet Muenchen -Robotics and Embedded Systems Garching bei Muenchen Boltzmannstraße 3 85748 Germany
2 - Siemens LLC -Corporate Technology Volynskiy lane 3 of. 905 191186 St. Petersburg Russia
4 - Siemens AG -Corporate Technology Otto-Hahn Ring 6 81730 Muenchen Germany","In this paper we suggest a new model for solving the binding problem by introducing complex-valued recurrent networks. These networks can represent sinusoidal oscillations and their phase, i.e., they can model the binding problem of neuronal assemblies by adjusting the relative phase of the oscillations of different feature detectors. As feature examples, we use color and shape -but the network would also function with any combination of other features. The suggested network architecture performs image generalization but can also be used as an image memory. The information about object color is represented in the phase of the network weights, while the spatial distribution of the neurons codes represent the object's shape. We will show that the architecture can generalize object shapes and recognize object color with very low computational overhead. 
 The Binding Problem Brains are permanently confronted with the problem of classifying objects into meaningful groups, e.g., the object class of ""cars"", even though the objects can be of different size, color, shape. The binding hypothesis is as follows: there are groups of neurons that are sensitive to a certain colors and other groups that react to certain shapes (e.g., typical shapes that are associated with cars). When a human sees a green car, both the neurons responsible for the color green, and those neurons reacting to the car-specific shapes start oscillating. After some time both align their oscillation phase, which means that they react to the same object. Thus, in the perception of the human, the car is associated with the color green. More details are presented in works  [1] [2] [3] [4] . 
 The Complex Valued Recurrent Neural Network The basis of our work is the ""recurrent open network"" -a system that is driven not only by its internal processes but also by external inputs. The Complex-Valued Recurrent Neural Network (CVRNN) is an extension of the Real Valued Recurrent Neural Network (RVRNN)  [5] . In the sequel we use CVRNNs that comply with the following general state space model:","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-24.pdf,2012,100.0,"Complex Valued Artificial Recurrent Neural Network as a Novel Approach to Model the Perceptual Binding Problem In this paper we suggest a new model for solving the binding problem by introducing complex-valued recurrent networks. These networks can represent sinusoidal oscillations and their phase, i.e., they can model the binding problem of neuronal assemblies by adjusting the relative phase of the oscillations of different feature detectors. As feature examples, we use color and shape -but the network would also function with any combination of other features. The suggested network architecture performs image generalization but can also be used as an image memory. The information about object color is represented in the phase of the network weights, while the spatial distribution of the neurons codes represent the object's shape. We will show that the architecture can generalize object shapes and recognize object color with very low computational overhead. 
 The Binding Problem Brains are permanently confronted with the problem of classifying objects into meaningful groups, e.g., the object class of ""cars"", even though the objects can be of different size, color, shape. The binding hypothesis is as follows: there are groups of neurons that are sensitive to a certain colors and other groups that react to certain shapes (e.g., typical shapes that are associated with cars). When a human sees a green car, both the neurons responsible for the color green, and those neurons reacting to the car-specific shapes start oscillating. After some time both align their oscillation phase, which means that they react to the same object. Thus, in the perception of the human, the car is associated with the color green. More details are presented in works  [1] [2] [3] [4] . 
 The Complex Valued Recurrent Neural Network The basis of our work is the ""recurrent open network"" -a system that is driven not only by its internal processes but also by external inputs. The Complex-Valued Recurrent Neural Network (CVRNN) is an extension of the Real Valued Recurrent Neural Network (RVRNN)  [5] . In the sequel we use CVRNNs that comply with the following general state space model:"
Out-of-Sample Kernel Extensions for Nonparametric Dimensionality Reduction,"Andrej Gisbrecht, Wouter Lueks, Bassam Mokbel, Barbara Hammer","1 - University of Bielefeld -CITEC centre of excellence Germany
2 - Faculty of Science University of Nijmegen The Netherlands","Nonparametric dimensionality reduction (DR) techniques such as locally linear embedding or t-distributed stochastic neighbor (t-SNE) embedding constitute standard tools to visualize high dimensional and complex data in the Euclidean plane. With increasing data volumes and streaming applications, it is often no longer possible to project all data points at once. Rather, out-of-sample extensions (OOS) derived from a small subset of all data points are used. In this contribution, we propose a kernel mapping for OOS in contrast to direct techniques based on the DR method. This can be trained based on a given example set, or it can be trained indirectly based on the cost function of the DR technique. Considering t-SNE as an example and several benchmarks, we show that a kernel mapping outperforms direct OOS as provided by t-SNE.",Nonlinear dimensionality reduction and topological learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-25.pdf,2012,68.91891891891892,"Out-of-Sample Kernel Extensions for Nonparametric Dimensionality Reduction Nonparametric dimensionality reduction (DR) techniques such as locally linear embedding or t-distributed stochastic neighbor (t-SNE) embedding constitute standard tools to visualize high dimensional and complex data in the Euclidean plane. With increasing data volumes and streaming applications, it is often no longer possible to project all data points at once. Rather, out-of-sample extensions (OOS) derived from a small subset of all data points are used. In this contribution, we propose a kernel mapping for OOS in contrast to direct techniques based on the DR method. This can be trained based on a given example set, or it can be trained indirectly based on the cost function of the DR technique. Considering t-SNE as an example and several benchmarks, we show that a kernel mapping outperforms direct OOS as provided by t-SNE."
Regularized Committee of Extreme Learning Machine for Regression Problems,"Pablo Escandell-Montero, José Martínez-Martínez, Emilio Soria-Olivas, Josep Guimerá-Tomás, Marcelino Martínez-Sober, Antonio Serrano-López","1 - Intelligent Data Analysis Laboratory IDAL
2 - University of Valencia -Electronic Engineering Department Av. de la Universidad, s/n 46100 Burjassot Valencia Spain",Extreme learning machine (ELM) is an efficient learning algorithm for single-hidden layer feedforward networks (SLFN). This paper proposes the combination of ELM networks using a regularized committee. Simulations on many real-world regression data sets have demonstrated that this algorithm generally outperforms the original ELM algorithm.,Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-26.pdf,2012,100.0,Regularized Committee of Extreme Learning Machine for Regression Problems Extreme learning machine (ELM) is an efficient learning algorithm for single-hidden layer feedforward networks (SLFN). This paper proposes the combination of ELM networks using a regularized committee. Simulations on many real-world regression data sets have demonstrated that this algorithm generally outperforms the original ELM algorithm.
Learning Task Relatedness via Dirichlet Process Priors for Linear Regression Models,"Marcel Hermkes, Nicolas Kuehn, Carsten Riggelsen",1 - University of Potsdam -Institute of Earth and Environmental Science Karl-Liebknecht Str. 24/25 14476 Golm-Potsdam Germany,"In this paper we present a hierarchical model of linear regression functions in the context of multi-task learning. The parameters of the linear model are coupled by a Dirichlet Process (DP) prior, which implies a clustering of related functions for different tasks. To make approximate Bayesian inference under this model we apply the Bayesian Hierarchical Clustering (BHC) algorithm. The experiments are conducted on two real world problems: (i) school exam score prediction and (ii) prediction of ground-motion parameters. In comparison to baseline methods with no shared prior the results show an improved prediction performance when using the hierarchical model.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-27.pdf,2012,84.33734939759037,"Learning Task Relatedness via Dirichlet Process Priors for Linear Regression Models In this paper we present a hierarchical model of linear regression functions in the context of multi-task learning. The parameters of the linear model are coupled by a Dirichlet Process (DP) prior, which implies a clustering of related functions for different tasks. To make approximate Bayesian inference under this model we apply the Bayesian Hierarchical Clustering (BHC) algorithm. The experiments are conducted on two real world problems: (i) school exam score prediction and (ii) prediction of ground-motion parameters. In comparison to baseline methods with no shared prior the results show an improved prediction performance when using the hierarchical model."
Extended visualization method for classification trees,"José Martínez-Martínez, Pablo Escandell-Montero, Emilio Soria-Olivas, José Martín-Guerrero, Juan Gómez-Sanchis, Joan Vila-Francés","1 - Intelligent Data Analysis Laboratory IDAL
2 - University of Valencia -Electronic Engineering Department Av de la Universidad, s/n 46100 Burjassot Valencia Spain","Classification tree analysis is one of the main techniques used in Data Mining, and nowadays there is a lack of a visualization method that support this tool. Therefore, graphical procedures can be developed in order to help simplify interpretation and to obtain a better understanding. This paper proposes a method for representing the input data for each class presented in each terminal node. For this purpose, the new visualization method Sectors on Sectors (SonS) is used. The methodology is tested in two real data sets.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-28.pdf,2012,83.33333333333334,"Extended visualization method for classification trees Classification tree analysis is one of the main techniques used in Data Mining, and nowadays there is a lack of a visualization method that support this tool. Therefore, graphical procedures can be developed in order to help simplify interpretation and to obtain a better understanding. This paper proposes a method for representing the input data for each class presented in each terminal node. For this purpose, the new visualization method Sectors on Sectors (SonS) is used. The methodology is tested in two real data sets."
Cartogram representation of the batch-SOM magnification factor,"Alessandra Tosi, Alfredo Vellido","1 - Dept de Llenguatges i Sistemes Informàtics -Universitat Politècnica de Catalunya C. Jordi Girona 1-3, Campus Nord 08034 Edifici Omega, Barcelona Spain","Model interpretability is a problem of knowledge extraction from the patterns found in raw data. One key source of knowledge is information visualization, which can help us to gain insights into a problem through graphical representations and metaphors. Nonlinear dimensionality reduction techniques can provide flexible visual insight, but the locally varying representation distortion they produce makes interpretation far from intuitive. In this paper, we define a cartogram method, based on techniques of geographic representation, that allows reintroducing this distortion, measured as a magnification factor, in the visual maps of the batch-SOM model. It does so while preserving the topological continuity of the representation.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-29.pdf,2012,100.0,"Cartogram representation of the batch-SOM magnification factor Model interpretability is a problem of knowledge extraction from the patterns found in raw data. One key source of knowledge is information visualization, which can help us to gain insights into a problem through graphical representations and metaphors. Nonlinear dimensionality reduction techniques can provide flexible visual insight, but the locally varying representation distortion they produce makes interpretation far from intuitive. In this paper, we define a cartogram method, based on techniques of geographic representation, that allows reintroducing this distortion, measured as a magnification factor, in the visual maps of the batch-SOM model. It does so while preserving the topological continuity of the representation."
Type 1 and 2 mixtures of divergences for stochastic neighbor embedding,John Lee,"1 - Pole of Molecular Imaging Université catholique de Louvain and Oncology Avenue Hippocrate 55 B-1200 Radiotherapy, Bruxelles Belgium","Stochastic neighbor embedding (SNE) is a method of dimensionality reduction (DR) that involves softmax similarities measured between all pairs of data points. In order to build a low-dimensional embedding, SNE tries to reproduce the similarities observed in the highdimensional data space. The capability of softmax similarities to fight the phenomenon of norm concentration has been studied in previous work. This paper investigates a complementary aspect, namely, the cost function that quantifies the mismatch between the high-and low-dimensional similarities. We show experimentally that switching from a simple Kullback-Leibler divergences to mixtures of dual divergences increases the quality of DR. This modification brings SNE to the performance level of its Student t-distributed variant, without the need to resort to non-identical similarity definitions in the high-and low-dimensional spaces. These results allow us to conclude that future improvements in similarity-based DR will likely emerge from better definitions of the cost function.",Nonlinear dimensionality reduction and topological learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-3.pdf,2012,84.05797101449275,"Type 1 and 2 mixtures of divergences for stochastic neighbor embedding Stochastic neighbor embedding (SNE) is a method of dimensionality reduction (DR) that involves softmax similarities measured between all pairs of data points. In order to build a low-dimensional embedding, SNE tries to reproduce the similarities observed in the highdimensional data space. The capability of softmax similarities to fight the phenomenon of norm concentration has been studied in previous work. This paper investigates a complementary aspect, namely, the cost function that quantifies the mismatch between the high-and low-dimensional similarities. We show experimentally that switching from a simple Kullback-Leibler divergences to mixtures of dual divergences increases the quality of DR. This modification brings SNE to the performance level of its Student t-distributed variant, without the need to resort to non-identical similarity definitions in the high-and low-dimensional spaces. These results allow us to conclude that future improvements in similarity-based DR will likely emerge from better definitions of the cost function."
Curves clustering with approximation of the density of functional random variables,"Julien Jacques, Cristian Preda","1 - Laboratoire Paul Painlevé UMR CNRS 8524 University Lille I Lille France
2 - INRIA Lille-Nord Europe and Polytech'Lille",ponents is proposed by approximating the density of functional random variables. An EM-like algorithm is used for parameter estimation and the maximum a posteriori rule provides the clusters. Real data applications illustrate the interest of the proposed methodology.,Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-30.pdf,2012,100.0,Curves clustering with approximation of the density of functional random variables ponents is proposed by approximating the density of functional random variables. An EM-like algorithm is used for parameter estimation and the maximum a posteriori rule provides the clusters. Real data applications illustrate the interest of the proposed methodology.
Magnitude Sensitive Competitive Learning,"Enrique Pelayo, David Buldain, Carlos Orrite",1 - Aragon Institute for Engineering Research University of Zaragoza SPAIN,"This paper presents a new algorithm, Magnitude Sensitive Competitive Learning (MSCL), which has the ability of distributing the unit weights following any magnitude calculated from the unit parameters or the input data inside the Voronoi region of the unit. This controlled behavior permits to surpass other standard Competitive Learning algorithms that only tend to concentrate neurons accordingly to the input data density. Some application examples applying different magnitude functions show the MSCL possibilities.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-31.pdf,2012,90.0,"Magnitude Sensitive Competitive Learning This paper presents a new algorithm, Magnitude Sensitive Competitive Learning (MSCL), which has the ability of distributing the unit weights following any magnitude calculated from the unit parameters or the input data inside the Voronoi region of the unit. This controlled behavior permits to surpass other standard Competitive Learning algorithms that only tend to concentrate neurons accordingly to the input data density. Some application examples applying different magnitude functions show the MSCL possibilities."
Adaptive Optimization for Cross Validation,"Alessandro Rudi, Gabriele Chiusano, Alessandro Verri","1 - Robotics, Brain and Cognitive Sciences Department -Istituto Italiano di Tecnologia Via Morego 30 16163 Genova Italy
2 - Dipartimento di Informatica e Scienza dell'Informazione University of Genoa Via Dodecaneso 35 16146 Genova Italy","The process of model selection and assessment aims at finding a subset of parameters that minimize the expected test error for a model related to a learning algorithm. Given a subset of tuning parameters, an exhaustive grid search is typically performed. In this paper an automatic algorithm for model selection and assessment is proposed. It adaptively learns the error function in the parameters space, making use of the Scale Space theory and the Statistical Learning theory in order to estimate a reduced number of models and, at the same time, to make them more reliable. Extensive experiments are performed on the MNIST dataset.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-32.pdf,2012,100.0,"Adaptive Optimization for Cross Validation The process of model selection and assessment aims at finding a subset of parameters that minimize the expected test error for a model related to a learning algorithm. Given a subset of tuning parameters, an exhaustive grid search is typically performed. In this paper an automatic algorithm for model selection and assessment is proposed. It adaptively learns the error function in the parameters space, making use of the Scale Space theory and the Statistical Learning theory in order to estimate a reduced number of models and, at the same time, to make them more reliable. Extensive experiments are performed on the MNIST dataset."
EMFit based Ultrasonic Phased Arrays with evolved Weights for Biomimetic Target Localization,"Jan Steckel, Andre Boen, Dieter Vanderelst, Herbert Peremans",1 - University of Antwerp -FTEW MTT Prinsstraat 13 B-2000 Antwerp Belgium,"Bats use the spatial filtering performed by their pinnae in localization tasks. We propose a similar localization scheme based on the spatial filtering of the received echoes by using a phased array. By evolving the weights of a linear phased array using a genetic algorithm, a very efficient spatial filter can be implemented. The localization performance of the evolved array in combination with the biomimetic localization algorithm is compared to a standard phased array localization scheme.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-33.pdf,2012,100.0,"EMFit based Ultrasonic Phased Arrays with evolved Weights for Biomimetic Target Localization Bats use the spatial filtering performed by their pinnae in localization tasks. We propose a similar localization scheme based on the spatial filtering of the received echoes by using a phased array. By evolving the weights of a linear phased array using a genetic algorithm, a very efficient spatial filter can be implemented. The localization performance of the evolved array in combination with the biomimetic localization algorithm is compared to a standard phased array localization scheme."
A GPU-Accelerated Algorithm for Self-Organizing Maps in a Distributed Environment,"Peter Wittek, Sándor Darányi",1 - Swedish School of Library and Information Science University of Borås Borås Sweden,"In this paper we introduce a MapReduce-based implementation of self-organizing maps that performs compute-bound operations on distributed GPUs. The kernels are optimized to ensure coalesced memory access and effective use of shared memory. We have performed extensive tests of our algorithms on a cluster of eight nodes with two NVidia Tesla M2050 attached to each, and we achieve a 10x speedup for self-organizing maps over a distributed CPU algorithm.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-35.pdf,2012,64.19753086419753,"A GPU-Accelerated Algorithm for Self-Organizing Maps in a Distributed Environment In this paper we introduce a MapReduce-based implementation of self-organizing maps that performs compute-bound operations on distributed GPUs. The kernels are optimized to ensure coalesced memory access and effective use of shared memory. We have performed extensive tests of our algorithms on a cluster of eight nodes with two NVidia Tesla M2050 attached to each, and we achieve a 10x speedup for self-organizing maps over a distributed CPU algorithm."
Interval coded scoring systems for survival analysis,"V Van Belle, S Van Huffel, J Suykens, S Boyd","1 - Department of Electrical Engineering Stanford Stanford University 94305-9510 CA USA
2 - Department of Electrical Engineering (ESAT-SCD) Katholieke Universiteit Leuven Kasteelpark Arenberg 10/2446 3001 Leuven Belgium
3 - IBBT-K.U.Leuven Future Health Department Kasteelpark Arenberg 10/2446 3001 Leuven -Belgium","Black-box mathematical models are powerful tools in classification and regression problems. Thanks to the use of (unknown) transformations of the inputs, the outcome can be estimated, improving performance in comparison to standard statistical models. A disadvantage of these complex models however, is their lack of interpretability. This work illustrates how advanced methods can be made interpretable. Using constant B-spline kernel functions and sparsity constraints, interval coded scoring models for survival analysis are presented.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-36.pdf,2012,100.0,"Interval coded scoring systems for survival analysis Black-box mathematical models are powerful tools in classification and regression problems. Thanks to the use of (unknown) transformations of the inputs, the outcome can be estimated, improving performance in comparison to standard statistical models. A disadvantage of these complex models however, is their lack of interpretability. This work illustrates how advanced methods can be made interpretable. Using constant B-spline kernel functions and sparsity constraints, interval coded scoring models for survival analysis are presented."
Maximum Likelihood Estimation and Polynomial System Solving,"Kim Batselier, Philippe Dreesen, Bart De Moor","1 - Department of Electrical Engineering (ESAT) SCD Katholieke Universiteit Leuven IBBT-K.U.Leuven Future Health Department 3001 Leuven Belgium
2 - Katholieke Universiteit Leuven Belgium","This article presents an alternative method to find the global maximum likelihood estimates of the mixing probabilities of a mixture of multinomial distributions. For these mixture models it is shown that the maximum likelihood estimates of the mixing probabilities correspond with the roots of a multivariate polynomial system. A new algorithm, set in a linear algebra framework, is presented which allows to find all these roots by solving a generalized eigenvalue problem.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-37.pdf,2012,83.05084745762711,"Maximum Likelihood Estimation and Polynomial System Solving This article presents an alternative method to find the global maximum likelihood estimates of the mixing probabilities of a mixture of multinomial distributions. For these mixture models it is shown that the maximum likelihood estimates of the mixing probabilities correspond with the roots of a multivariate polynomial system. A new algorithm, set in a linear algebra framework, is presented which allows to find all these roots by solving a generalized eigenvalue problem."
Posterior regularization and attribute assessment of under-determined linear mappings,"Marc Strickert, Michael Seifert","1 - Knowledge Engineering and Bioinformatics University of Marburg DE
2 - Leibniz Institute of Plant Genetics and Crop Plant Research Gatersleben DE","Linear mappings are omnipresent in data processing analysis ranging from regression to distance metric learning. The interpretation of coefficients from under-determined mappings raises an unexpected challenge when the original modeling goal does not impose regularization. Therefore, a general posterior regularization strategy is presented for inducing unique results, and additional sensitivity analysis enables attribute assessment for facilitating model interpretation. An application to infrared spectra reflects data smoothness and indicates improved generalization.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-4.pdf,2012,100.0,"Posterior regularization and attribute assessment of under-determined linear mappings Linear mappings are omnipresent in data processing analysis ranging from regression to distance metric learning. The interpretation of coefficients from under-determined mappings raises an unexpected challenge when the original modeling goal does not impose regularization. Therefore, a general posterior regularization strategy is presented for inducing unique results, and additional sensitivity analysis enables attribute assessment for facilitating model interpretation. An application to infrared spectra reflects data smoothness and indicates improved generalization."
Automatic selection of the number of spatial filters for motor-imagery BCI,"Y Yang, S Chevallier, J Wiart, I Bloch","1 - Department 46 rue Barrault Télécom ParisTech CNRS LTCI -Signal and Image Processing 75013 Paris France
2 - -Whist Lab -Institut Télécom 46 rue Barrault 75013 Paris France
5 - -Orange Labs R&D -SAFE/Wave Group 40 rue du Général Leclerc 92794 Issy les Moulineaux France","Common spatial pattern (CSP) is widely used for constructing spatial filters to extract features for motor-imagery-based BCI. One main parameter in CSP-based classification is the number of spatial filters used. An automatic method relying on Rayleigh quotient is presented to estimate its optimal value for each subject. Based on an existing dataset, we validate the contribution of the proposed method through a study of the effect of this parameter on the classification performance. The evaluation on testing data shows that the estimated subject-specific optimal values yield better performances than the recommended value in the literature.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-40.pdf,2012,100.0,"Automatic selection of the number of spatial filters for motor-imagery BCI Common spatial pattern (CSP) is widely used for constructing spatial filters to extract features for motor-imagery-based BCI. One main parameter in CSP-based classification is the number of spatial filters used. An automatic method relying on Rayleigh quotient is presented to estimate its optimal value for each subject. Based on an existing dataset, we validate the contribution of the proposed method through a study of the effect of this parameter on the classification performance. The evaluation on testing data shows that the estimated subject-specific optimal values yield better performances than the recommended value in the literature."
L 1 -based compression of random forest models,"Arnaud Joly, François Schnitzler, Pierre Geurts, Louis Wehenkel","1 - University of Liège -Department of EE and CS & GIGA-research Liège Sart-Tilman, B-28 B-4000 Belgium","Random forests are effective supervised learning methods applicable to large-scale datasets. However, the space complexity of tree ensembles, in terms of their total number of nodes, is often prohibitive, specially in the context of problems with very high-dimensional input spaces. We propose to study their compressibility by applying a L1-based regularization to the set of indicator functions defined by all their nodes. We show experimentally that preserving or even improving the model accuracy while significantly reducing its space complexity is indeed possible.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-43.pdf,2012,93.33333333333333,"L 1 -based compression of random forest models Random forests are effective supervised learning methods applicable to large-scale datasets. However, the space complexity of tree ensembles, in terms of their total number of nodes, is often prohibitive, specially in the context of problems with very high-dimensional input spaces. We propose to study their compressibility by applying a L1-based regularization to the set of indicator functions defined by all their nodes. We show experimentally that preserving or even improving the model accuracy while significantly reducing its space complexity is indeed possible."
Towards biologically realistic multi-compartment neuron model emulation in analog VLSI,"Sebastian Millner, Andreas Hartel, Johannes Schemmel, Karlheinz Meier","1 - Universität Heidelberg -Kirchhoff-Institut für Physik Im Neuenheimer Feld 227 69120 Heidelberg Germany
2 - Very large scale integration","We present a new concept for multi-compartment emulation on neuromorphic hardware based on the BrainScaleS wafer-scale system. The implementation features complex dendrite routing capabilities, realistic scaling of compartmental parameters and active spike propagation. Simulations proof the circuit's capability of reproducing passive dendritic properties of a model from literature.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-44.pdf,2012,100.0,"Towards biologically realistic multi-compartment neuron model emulation in analog VLSI We present a new concept for multi-compartment emulation on neuromorphic hardware based on the BrainScaleS wafer-scale system. The implementation features complex dendrite routing capabilities, realistic scaling of compartmental parameters and active spike propagation. Simulations proof the circuit's capability of reproducing passive dendritic properties of a model from literature."
Input-Output Hidden Markov Models for Trees,"Davide Bacciu, Alessio Micheli, Alessandro Sperduti","1 - Dipartimento di Informatica Università di Pisa Italy
3 - Dipartimento di Matematica Pura e Applicata Università di Padova Italy",The paper introduces an input-driven generative model for tree-structured data that extends the bottom-up hidden tree Markov model with non-homogenous transition and emission probabilities. The advantage of introducing an input-driven dynamics in structured-data processing is experimentally investigated. The results of this preliminary analysis suggest that input-driven models can capture more discriminative structural information than non-input-driven approaches.,Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-45.pdf,2012,88.37209302325581,Input-Output Hidden Markov Models for Trees The paper introduces an input-driven generative model for tree-structured data that extends the bottom-up hidden tree Markov model with non-homogenous transition and emission probabilities. The advantage of introducing an input-driven dynamics in structured-data processing is experimentally investigated. The results of this preliminary analysis suggest that input-driven models can capture more discriminative structural information than non-input-driven approaches.
The error-related potential and BCIs,"Sandra Rousseau, Christian Jutten, Marco Congedo",1 - Gipsa-lab -DIS 11 rue des Mathématiques BP 46 38402 Saint Martin d'Héres Cedex France,"The error-related potential is an event-related potential triggered by errors. Recently it has been the subject of many attentions notably for its possible use in BCI systems. Since it is linked to error occurrence, it could be used in the design of control loop to build more robust systems. In this paper we studied the characteristics of the error potential and present how it could be used for BCI systems improvement.",Brain-computer interfaces,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-46.pdf,2012,100.0,"The error-related potential and BCIs The error-related potential is an event-related potential triggered by errors. Recently it has been the subject of many attentions notably for its possible use in BCI systems. Since it is linked to error occurrence, it could be used in the design of control loop to build more robust systems. In this paper we studied the characteristics of the error potential and present how it could be used for BCI systems improvement."
Combined scattering for rotation invariant texture analysis,"Laurent Sifre, Stéphane Mallat","1 - Ecole Polytechnique -Centre de Mathématiques Appliquées Palaiseau France
3 - Institut des Hautes Etudes Scientifiques Bures-sur-Yvette France","This paper introduces a combined scattering representation for texture classification, which is invariant to rotations and stable to deformations. A combined scattering is computed with two nested cascades of wavelet transforms and complex modulus, along spatial and rotation variables. Results are compared with state-of-the-art algorithms, with a nearest neighbor classifier.",Image and time series analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-47.pdf,2012,100.0,"Combined scattering for rotation invariant texture analysis This paper introduces a combined scattering representation for texture classification, which is invariant to rotations and stable to deformations. A combined scattering is computed with two nested cascades of wavelet transforms and complex modulus, along spatial and rotation variables. Results are compared with state-of-the-art algorithms, with a nearest neighbor classifier."
Unsupervised Learning of Motion Patterns,"Thomas Guthier, Julian Eggert, Volker Willert","1 - -TU Darmstadt -Control theory and robotics lab Landgraf-Georg-Str. 4 64283 Darmstadt -Germany
2 - Honda Research Institute Europe Carl-Legien-Str. 30 63073 Offenbach Germany","Neurophysiological findings suggest that the visual cortex of mammals contains neural populations that are sensitive to specific motion patterns. In this paper, we present a new method to learn such patterns in an unsupervised way. To represent motion, dense optical flow fields of videos containing humans performing several actions like walking and running are estimated. We introduce VNMF, an extension of the translation invariant NMF that works on flow fields, along with a new energy term that enforces parts-basedness. VNMF incorporates three principles found in neural motion processing: Sparsity, non-negativity and direction selectivity. We find that the extracted motion patterns are shaped like body parts, which supports the idea that the representation of biological motion is directly linked to the shape of an object.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-134.pdf,2012,64.64646464646464,"Unsupervised Learning of Motion Patterns Neurophysiological findings suggest that the visual cortex of mammals contains neural populations that are sensitive to specific motion patterns. In this paper, we present a new method to learn such patterns in an unsupervised way. To represent motion, dense optical flow fields of videos containing humans performing several actions like walking and running are estimated. We introduce VNMF, an extension of the translation invariant NMF that works on flow fields, along with a new energy term that enforces parts-basedness. VNMF incorporates three principles found in neural motion processing: Sparsity, non-negativity and direction selectivity. We find that the extracted motion patterns are shaped like body parts, which supports the idea that the representation of biological motion is directly linked to the shape of an object."
Recent developments in clustering algorithms,"C Bouveyron, B Hammer, T Villmann","1 - University of Paris
2 - SAMM Laboratory France
3 - University of Bielefeld -CITEC centre of excellence Germany
4 - -University of Applied Sciences -CI Group Mittweida","In this paper, we give a short review of recent developments in clustering. We shortly summarize important clustering paradigms before addressing important topics including metric adaptation in clustering, dealing with non-Euclidean data or large data sets, clustering evaluation, and learning theoretical foundations.",Recent developments in clustering algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-5.pdf,2012,100.0,"Recent developments in clustering algorithms In this paper, we give a short review of recent developments in clustering. We shortly summarize important clustering paradigms before addressing important topics including metric adaptation in clustering, dealing with non-Euclidean data or large data sets, clustering evaluation, and learning theoretical foundations."
Supervised learning to tune simulated annealing for in silico protein structure prediction,"Alejandro Alvarez, Francis Maes, Louis Wehenkel",1 - Department of Electrical Engineering and Computer Science University of Liège Sart-Tilman B28 B-4000 Liège Belgium,Simulated annealing is a widely used stochastic optimization algorithm whose efficiency essentially depends on the proposal distribution used to generate the next search state at each step. We propose to adapt this distribution to a family of parametric optimization problems by using supervised machine learning on a sample of search states derived from a set of typical runs of the algorithm over this family. We apply this idea in the context of in silico protein structure prediction. * This work was funded by the Biomagnet IUAP network of the Belgian Science Policy Office and the Pascal2 network of excellence of the EC. The scientific responsibility rests with the authors. 1 The search space is R 3n where n is the number of atoms of the protein.,Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-51.pdf,2012,100.0,Supervised learning to tune simulated annealing for in silico protein structure prediction Simulated annealing is a widely used stochastic optimization algorithm whose efficiency essentially depends on the proposal distribution used to generate the next search state at each step. We propose to adapt this distribution to a family of parametric optimization problems by using supervised machine learning on a sample of search states derived from a set of typical runs of the algorithm over this family. We apply this idea in the context of in silico protein structure prediction. * This work was funded by the Biomagnet IUAP network of the Belgian Science Policy Office and the Pascal2 network of excellence of the EC. The scientific responsibility rests with the authors. 1 The search space is R 3n where n is the number of atoms of the protein.
Robust Clustering of High-Dimensional Data,"Anastasios Bellas, Charles Bouveyron, Marie Cottrell, Jérôme Lacaille","1 - SAMM Université Paris 1 90, rue de Tolbiac 4543), 75634 Paris Cedex 13 EA France
4 - 77550 Snecma, Groupe Safran, Moissy Cramayel France","We address the problem of robust clustering of high -dimensional data, which is recurrent in real-world applications. Existing robust clustering methods are unfortunately sensitive in high dimension, while existing approaches for high-dimensional data are in general not robust. We propose a hybrid iterative EM-based algorithm that combines an efficient high-dimensional clustering algorithm and the trimming technique. We test our algorithm on synthetic and real-world data from the domain of aircraft engine health monitoring and show its efficiency for high-dimensional noisy datasets.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-52.pdf,2012,73.80952380952381,"Robust Clustering of High-Dimensional Data We address the problem of robust clustering of high -dimensional data, which is recurrent in real-world applications. Existing robust clustering methods are unfortunately sensitive in high dimension, while existing approaches for high-dimensional data are in general not robust. We propose a hybrid iterative EM-based algorithm that combines an efficient high-dimensional clustering algorithm and the trimming technique. We test our algorithm on synthetic and real-world data from the domain of aircraft engine health monitoring and show its efficiency for high-dimensional noisy datasets."
Low-Power Manhattan Distance Calculation Circuit for Self-Organizing Neural Networks Implemented in the CMOS Technology,"Tomasz Talaśka, Witold Pedrycz, Pierre-André Farine","1 - Faculty of Telecommunication and Electrical Engineering University of Technology and Life Sciences ul Kaliskiego 7 85-796 Bydgoszcz Poland
2 - -Institute of Microtechnology Swiss Federal Institute of Technology in Lausanne (EPFL) Rue A.-L Breguet 2 CH-2000 Neuchâtel Switzerland
4 - Department of Electrical and Computer Engineering University of Alberta Edmonton T6G 2V4 AB Canada","The paper presents an analog, current-mode circuit that calculates a distance between the neuron weights vectors W and the input learning patterns X. The circuit can be used as a component of different self-organizing neural networks (NN) implemented in the CMOS technology. In Self-Organizing Maps (SOM) as well as in NNs using the Neural Gas or the Winner Takes All (WTA) learning algorithms, to calculate the distance between X and W , the same circuit can be used that makes it a universal structure. Detailed system level simulations of the WTA NN and the Kohonen SOM showed that using both the Euclidean (L2) and the Manhattan (L1) distance measures leads to similar learning results. For this reason, the L1 measure has been implemented, as in this case the circuit is much simpler than the one using the L2 distance, resulting in very low chip area and low power dissipation. This enables including even large NNs in miniaturized portable devices, such as sensors in Wireless Sensor Networks (WSN) or Wireless Body Area Networks (WBAN).",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-54.pdf,2012,100.0,"Low-Power Manhattan Distance Calculation Circuit for Self-Organizing Neural Networks Implemented in the CMOS Technology The paper presents an analog, current-mode circuit that calculates a distance between the neuron weights vectors W and the input learning patterns X. The circuit can be used as a component of different self-organizing neural networks (NN) implemented in the CMOS technology. In Self-Organizing Maps (SOM) as well as in NNs using the Neural Gas or the Winner Takes All (WTA) learning algorithms, to calculate the distance between X and W , the same circuit can be used that makes it a universal structure. Detailed system level simulations of the WTA NN and the Kohonen SOM showed that using both the Euclidean (L2) and the Manhattan (L1) distance measures leads to similar learning results. For this reason, the L1 measure has been implemented, as in this case the circuit is much simpler than the one using the L2 distance, resulting in very low chip area and low power dissipation. This enables including even large NNs in miniaturized portable devices, such as sensors in Wireless Sensor Networks (WSN) or Wireless Body Area Networks (WBAN)."
Integration of Structural Expert Knowledge about Classes for Classication Using the Fuzzy Supervised Neural Gas,"M Kästner, W Hermann, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
2 - Paracelsus-Hospital Zwickau -Dept. of Neurology Zwickau Saxonia Germany","In this paper we describe an approach to integrate structural expert knowledge about class relations into classication schemes under the assumption of unary class coding. Exemplary, we show in a medical application such an integration for incorporation of prior medical knowledge about uncertainty for distinguishing patient classes. This knowlegde is integrated here in a class dissimilarity measure used for training the classication model.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-57.pdf,2012,99.10714285714286,"Integration of Structural Expert Knowledge about Classes for Classication Using the Fuzzy Supervised Neural Gas In this paper we describe an approach to integrate structural expert knowledge about class relations into classication schemes under the assumption of unary class coding. Exemplary, we show in a medical application such an integration for incorporation of prior medical knowledge about uncertainty for distinguishing patient classes. This knowlegde is integrated here in a class dissimilarity measure used for training the classication model."
Theory of Input Driven Dynamical Systems,"G Manjunath, P Tiňo, H Jaeger","1 - School of Engineering and Science 3-Jacobs University Bremen 28759 Bremen Germany
2 - School of computer Science The University of Birmingham B15 2TT Birmingham United Kingdom","Most dynamic models of interest in machine learning, robotics, AI or cognitive science are nonautonomous and input-driven. In the last few years number of important innovations have occurred in mathematical research on nonautonomous systems. In understanding the long term behavior of nonautonomous systems, the notion of an attractor is fundamental. With a time varying input, it turns out that for a notion of an attractor to be useful, the attractor cannot a single subset, but must be conceived as a sequence of sets varying with time as well. The aim of this tutorial is to illuminate useful notions of attractors of nonautonomous systems, and also introduce some newly emerging concepts of dynamical systems theory which are particularly relevant for input driven systems. * The research leading to this paper was funded by the FP7 European project ORGANIC, organic.elis.ugent.be/organic. 1 Note that this usage of autonomous/nonautonomous is entirely unrelated to the notion of autonomy as understood in robotics and the agent sciences.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-6.pdf,2012,100.0,"Theory of Input Driven Dynamical Systems Most dynamic models of interest in machine learning, robotics, AI or cognitive science are nonautonomous and input-driven. In the last few years number of important innovations have occurred in mathematical research on nonautonomous systems. In understanding the long term behavior of nonautonomous systems, the notion of an attractor is fundamental. With a time varying input, it turns out that for a notion of an attractor to be useful, the attractor cannot a single subset, but must be conceived as a sequence of sets varying with time as well. The aim of this tutorial is to illuminate useful notions of attractors of nonautonomous systems, and also introduce some newly emerging concepts of dynamical systems theory which are particularly relevant for input driven systems. * The research leading to this paper was funded by the FP7 European project ORGANIC, organic.elis.ugent.be/organic. 1 Note that this usage of autonomous/nonautonomous is entirely unrelated to the notion of autonomy as understood in robotics and the agent sciences."
Averaging of kernel functions,"Lluís Belanche, Alessandra Tosi",1 - Faculty of Computer Science -Dept. of Software Technical University of Catalonia Barcelona Spain,"In kernel-based machines, the integration of several kernels to build more flexible learning methods is a promising avenue for research. In particular, in Multiple Kernel Learning a compound kernel is build by learning a kernel that is the weighted mean of several sources. We show in this paper that the only feasible average for kernel learning is precisely the arithmetic average. We also show that three familiar means (the geometric, inverse root mean square and harmonic means) for positive real values actually generate valid kernels. 
 Definition 1 In the real case, the symmetric matrix Theorem 1 The function K : H×H → R is a kernel in H if and only if for any positive p ∈ N and choice of finite subsets {x 1 , x 2 , ..., x p } ⊂ H, the associated matrix K p×p = (k ij ), where k ij = K(x i , x j ) is a symmetric PSD matrix.",Statistical methods and kernel-based algorithms,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-60.pdf,2012,100.0,"Averaging of kernel functions In kernel-based machines, the integration of several kernels to build more flexible learning methods is a promising avenue for research. In particular, in Multiple Kernel Learning a compound kernel is build by learning a kernel that is the weighted mean of several sources. We show in this paper that the only feasible average for kernel learning is precisely the arithmetic average. We also show that three familiar means (the geometric, inverse root mean square and harmonic means) for positive real values actually generate valid kernels. 
 Definition 1 In the real case, the symmetric matrix Theorem 1 The function K : H×H → R is a kernel in H if and only if for any positive p ∈ N and choice of finite subsets {x 1 , x 2 , ..., x p } ⊂ H, the associated matrix K p×p = (k ij ), where k ij = K(x i , x j ) is a symmetric PSD matrix."
Structural Risk Minimization and Rademacher Complexity for Regression,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella",1 - Department of Biophysical and Electronic Engineering University of Genova Via Opera Pia 11A I-16145 Genova Italy,"The Structural Risk Minimization principle allows estimating the generalization ability of a learned hypothesis by measuring the complexity of the entire hypothesis class. Two of the most recent and effective complexity measures are the Rademacher Complexity and the Maximal Discrepancy, which have been applied to the derivation of generalization bounds for kernel classifiers. In this work, we extend their application to the regression framework. 
 Complexity and Structural Risk Minimization Let us consider the usual regression framework, consisting of an input set X ⊆ R d and an output set Y ⊆ R, which are related by a fixed but unknown probability distribution μ on X × Y. A series of IID samples (x 1 , y 1 ), . . . , (x n , y n ), where x i ∈ X and y i ∈ Y, is originated from μ and our goal is to find a regression function h : X → R, chosen in a fixed class H, along with a reliable estimate of its performance. For this purpose, a loss function (h(x), y) : R × Y → R is defined, which measures the quality of the regressor. Typical loss functions in the regression framework are the Mean Square Error (MSE), the Mean Absolute Error (MAE) or more sophisticated ones like the Huber's loss. Unfortunately, all the mentioned losses are unbounded, and this represents an issue for several statistical approaches, including both MD and RC  [1, 2] . In particular, it is well-known that additional constraints on μ (e.g. on its high-order moments) must be introduced in this case, otherwise the convergence of the regressor to",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-61.pdf,2012,100.0,"Structural Risk Minimization and Rademacher Complexity for Regression The Structural Risk Minimization principle allows estimating the generalization ability of a learned hypothesis by measuring the complexity of the entire hypothesis class. Two of the most recent and effective complexity measures are the Rademacher Complexity and the Maximal Discrepancy, which have been applied to the derivation of generalization bounds for kernel classifiers. In this work, we extend their application to the regression framework. 
 Complexity and Structural Risk Minimization Let us consider the usual regression framework, consisting of an input set X ⊆ R d and an output set Y ⊆ R, which are related by a fixed but unknown probability distribution μ on X × Y. A series of IID samples (x 1 , y 1 ), . . . , (x n , y n ), where x i ∈ X and y i ∈ Y, is originated from μ and our goal is to find a regression function h : X → R, chosen in a fixed class H, along with a reliable estimate of its performance. For this purpose, a loss function (h(x), y) : R × Y → R is defined, which measures the quality of the regressor. Typical loss functions in the regression framework are the Mean Square Error (MSE), the Mean Absolute Error (MAE) or more sophisticated ones like the Huber's loss. Unfortunately, all the mentioned losses are unbounded, and this represents an issue for several statistical approaches, including both MD and RC  [1, 2] . In particular, it is well-known that additional constraints on μ (e.g. on its high-order moments) must be introduced in this case, otherwise the convergence of the regressor to"
The 'K' in K-fold Cross Validation,"Davide Anguita, Luca Ghelardoni, Alessandro Ghio, Luca Oneto, Sandro Ridella",1 - Department of Biophysical and Electronic Engineering University of Genova Via Opera Pia 11A I-16145 Genova Italy,"The K-fold Cross Validation (KCV) technique is one of the most used approaches by practitioners for model selection and error estimation of classifiers. The KCV consists in splitting a dataset into k subsets; then, iteratively, some of them are used to learn the model, while the others are exploited to assess its performance. However, in spite of the KCV success, only practical rule-of-thumb methods exist to choose the number and the cardinality of the subsets. We propose here an approach, which allows to tune the number of the subsets of the KCV in a data-dependent way, so to obtain a reliable, tight and rigorous estimation of the probability of misclassification of the chosen model.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-62.pdf,2012,88.23529411764706,"The 'K' in K-fold Cross Validation The K-fold Cross Validation (KCV) technique is one of the most used approaches by practitioners for model selection and error estimation of classifiers. The KCV consists in splitting a dataset into k subsets; then, iteratively, some of them are used to learn the model, while the others are exploited to assess its performance. However, in spite of the KCV success, only practical rule-of-thumb methods exist to choose the number and the cardinality of the subsets. We propose here an approach, which allows to tune the number of the subsets of the KCV in a data-dependent way, so to obtain a reliable, tight and rigorous estimation of the probability of misclassification of the chosen model."
Effects of Noise-Reduction on Neural Function Approximation,"Frank-Florian Steege, Volker Stephan, Horst-Michael Groß","1 - Neuroinformatics and Cognitive Robotics Lab Ilmenau University of Technology P.O.Box 100565 D-98684 Ilmenau Germany
2 - Powitec Intelligent Technologies GmbH 45219 Essen-Kettwig Germany",Noise disturbance in training data prevents a good approximation of a function by neural networks. To achieve better approximation results we combine neural networks with noise reduction algorithms. We compare different methods to distinguish between samples with high noise level (outliers) in a dataset and samples with low noise level. Drawbacks of common outlier detection approaches are analysed and a new approach is defined which increases the quality of network function approximation. We demonstrate the effects of noise reduction on artificial datasets and on real data from the process control domain.,Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-65.pdf,2012,79.66101694915254,Effects of Noise-Reduction on Neural Function Approximation Noise disturbance in training data prevents a good approximation of a function by neural networks. To achieve better approximation results we combine neural networks with noise reduction algorithms. We compare different methods to distinguish between samples with high noise level (outliers) in a dataset and samples with low noise level. Drawbacks of common outlier detection approaches are analysed and a new approach is defined which increases the quality of network function approximation. We demonstrate the effects of noise reduction on artificial datasets and on real data from the process control domain.
Cluster homogeneity as a semi-supervised principle for feature selection using mutual information,"Frederico Coelho, Antonio Padua Braga, Michel Verleysen","1 - Universidade Federal de Minas Gerais Brazil
3 - Université Catholique de Louvain Belgium","In this work the principle of homogeneity between labels and data clusters is exploited in order to develop a semi-supervised Feature Selection method. This principle permits the use of cluster information to improve the estimation of feature relevance in order to increase selection performance. Mutual Information is used in a Forward-Backward search process in order to evaluate the relevance of each feature to the data distribution and the existent labels, in a context of few labeled and many unlabeled instances.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-68.pdf,2012,100.0,"Cluster homogeneity as a semi-supervised principle for feature selection using mutual information In this work the principle of homogeneity between labels and data clusters is exploited in order to develop a semi-supervised Feature Selection method. This principle permits the use of cluster information to improve the estimation of feature relevance in order to increase selection performance. Mutual Information is used in a Forward-Backward search process in order to evaluate the relevance of each feature to the data distribution and the existent labels, in a context of few labeled and many unlabeled instances."
Making machine learning models interpretable,"Alfredo Vellido, José Martín-Guerrero, Paulo Lisboa","1 - Dept. de Llenguatges i Sistemes Informàtics -Univ. Politècnica de Catalunya C. Jordi Girona 1-3 08034 Barcelona Spain
2 - Dept. d'Enginyeria Electrònica Universitat de València Av. de la Universitat 46100 Burjassot (València) -Spain
3 - Dept. of Mathematics and Statistics -Liverpool John Moores University Byrom St L3 3AF Liverpool United Kingdom","Data of different levels of complexity and of ever growing diversity of characteristics are the raw materials that machine learning practitioners try to model using their wide palette of methods and tools. The obtained models are meant to be a synthetic representation of the available, observed data that captures some of their intrinsic regularities or patterns. Therefore, the use of machine learning techniques for data analysis can be understood as a problem of pattern recognition or, more informally, of knowledge discovery and data mining. There exists a gap, though, between data modeling and knowledge extraction. Models, depending on the machine learning techniques employed, can be described in diverse ways but, in order to consider that some knowledge has been achieved from their description, we must take into account the human cognitive factor that any knowledge extraction process entails. These models as such can be rendered powerless unless they can be interpreted, and the process of human interpretation follows rules that go well beyond technical prowess. For this reason, interpretability is a paramount quality that machine learning methods should aim to achieve if they are to be applied in practice. This paper is a brief introduction to the special session on interpretable models in machine learning, organized as part of the 20 th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. It includes a discussion on the several works accepted for the session, with an overview of the context of wider research on interpretability of machine learning models.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-7.pdf,2012,100.0,"Making machine learning models interpretable Data of different levels of complexity and of ever growing diversity of characteristics are the raw materials that machine learning practitioners try to model using their wide palette of methods and tools. The obtained models are meant to be a synthetic representation of the available, observed data that captures some of their intrinsic regularities or patterns. Therefore, the use of machine learning techniques for data analysis can be understood as a problem of pattern recognition or, more informally, of knowledge discovery and data mining. There exists a gap, though, between data modeling and knowledge extraction. Models, depending on the machine learning techniques employed, can be described in diverse ways but, in order to consider that some knowledge has been achieved from their description, we must take into account the human cognitive factor that any knowledge extraction process entails. These models as such can be rendered powerless unless they can be interpreted, and the process of human interpretation follows rules that go well beyond technical prowess. For this reason, interpretability is a paramount quality that machine learning methods should aim to achieve if they are to be applied in practice. This paper is a brief introduction to the special session on interpretable models in machine learning, organized as part of the 20 th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. It includes a discussion on the several works accepted for the session, with an overview of the context of wider research on interpretability of machine learning models."
Parallelization of Deep Networks,"Michele De, Filippo De Grazia, Ivilin Stoianov, Marco Zorzi","1 - Dipartimento di Psicologia Generale and Center for Cognitive Science -via Venezia University of Padova
2 - Padova Italy","Learning multiple levels of feature detectors in Deep Belief Networks is a promising approach both for neuro-cognitive modeling and for practical applications, but it comes at the cost of high computational requirements. Here we propose a method for the parallelization of unsupervised generative learning in deep networks based on distributing training data among multiple computational nodes in a cluster. We show that this approach significantly reduces the training time with very limited cost on performance. We also show that a layerwise convergence stopping criterion yields faster training.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-71.pdf,2012,100.0,"Parallelization of Deep Networks Learning multiple levels of feature detectors in Deep Belief Networks is a promising approach both for neuro-cognitive modeling and for practical applications, but it comes at the cost of high computational requirements. Here we propose a method for the parallelization of unsupervised generative learning in deep networks based on distributing training data among multiple computational nodes in a cluster. We show that this approach significantly reduces the training time with very limited cost on performance. We also show that a layerwise convergence stopping criterion yields faster training."
Images Reconstruction using an iterative SOM based algorithm,"M Jouini, S Thiria, M Crépon","1 - LOCEAN, MMSA team CNAM University Paris France
2 - LOCEAN MMSA team UVSQ University Paris France
3 - LOCEAN MMSA team CNRS Paris France","The frequent presence of clouds in optical remotely sensed imagery prevents space and time continuity and limits its exploitation. The aim of this study is to propose a new statistical processing approach for the reconstruction of areas covered by clouds in a time sequence of optical satellite images. The approach is an iterative SOM based algorithm and is applied here to reconstruct ocean color images. It used the information contained in ocean color images and a set of satellite-derived dynamic ocean products (sea surface temperature: SST, altimetry: SSH) to reproduce the local spatio-temporal relationships of the cloudy images. The reconstruction method is general and can be extended to similar problems.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-78.pdf,2012,73.94957983193278,"Images Reconstruction using an iterative SOM based algorithm The frequent presence of clouds in optical remotely sensed imagery prevents space and time continuity and limits its exploitation. The aim of this study is to propose a new statistical processing approach for the reconstruction of areas covered by clouds in a time sequence of optical satellite images. The approach is an iterative SOM based algorithm and is applied here to reconstruct ocean color images. It used the information contained in ocean color images and a set of satellite-derived dynamic ocean products (sea surface temperature: SST, altimetry: SSH) to reproduce the local spatio-temporal relationships of the cloudy images. The reconstruction method is general and can be extended to similar problems."
Parallel Neural Hardware: The Time is Right,"Ulrich Rückert, Erzsébet Merényi","1 - Cognitive Interaction Technology -Center of Excellence Bielefeld Bielefeld University Germany
2 - -Rice University -Department of Statistics Houston Texas U.S.A","It seems obvious that the massively parallel computations inherent in artificial neural networks (ANNs) can only be realized by massively parallel hardware. However, the vast majority of the many ANN applications simulate their ANNs on sequential computers which, in turn, are not resource-efficient. The increasing availability of parallel standard hardware such as FPGAs, graphics processors, and multi-core processors offers new scopes and challenges in respect to resource-efficiency and real-time applications of ANNs. Within this paper we will discuss some key issues for parallel ANN implementation on these standard devices compared to special purpose ANN implementations.",Parallel hardware architectures for acceleration of neural network computation,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-8.pdf,2012,62.7906976744186,"Parallel Neural Hardware: The Time is Right It seems obvious that the massively parallel computations inherent in artificial neural networks (ANNs) can only be realized by massively parallel hardware. However, the vast majority of the many ANN applications simulate their ANNs on sequential computers which, in turn, are not resource-efficient. The increasing availability of parallel standard hardware such as FPGAs, graphics processors, and multi-core processors offers new scopes and challenges in respect to resource-efficiency and real-time applications of ANNs. Within this paper we will discuss some key issues for parallel ANN implementation on these standard devices compared to special purpose ANN implementations."
Learning geometric combinations of Gaussian kernels with alternating Quasi-Newton algorithm,"David Picard, Nicolas Thome, Matthieu Cord, Alain Rakotomamonjy","1 - ETIS -ENSEA CNRS Université de Cergy Pontoise 6 avenue du Ponceau F-95000 Cergy Pontoise
2 - UPMC Univ Paris 6 4 place Jussieu LIP6 -, 75005 Paris France
4 - LITIS EA4108 INSA-Université de Rouen Avenue de l'université 76800 Saint Etienne du Rouvray","We propose a novel algorithm for learning a geometric combination of Gaussian kernel jointly with a SVM classifier. This problem is the product counterpart of MKL, with restriction to Gaussian kernels. Our algorithm finds a local solution by alternating a Quasi-Newton gradient descent over the kernels and a classical SVM solver over the instances. We show promising results on well known data sets which suggest the soundness of the approach.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-80.pdf,2012,100.0,"Learning geometric combinations of Gaussian kernels with alternating Quasi-Newton algorithm We propose a novel algorithm for learning a geometric combination of Gaussian kernel jointly with a SVM classifier. This problem is the product counterpart of MKL, with restriction to Gaussian kernels. Our algorithm finds a local solution by alternating a Quasi-Newton gradient descent over the kernels and a classical SVM solver over the instances. We show promising results on well known data sets which suggest the soundness of the approach."
Supervised and unsupervised classification approaches for human activity recognition using body-mounted sensors,"D Trabelsi, S Mohammed, F Chamroukhi, L Oukhellou, Y Amirat","1 - −University Paris-Est Créteil (UPEC) LISSI 120-122 rue Paul Armangot 94400 Vitry-Sur-Seine France
3 - University Sud Toulon-Var, LSIS R BP 132 -83957 Batiment, La Garde Cedex France
4 - −University Paris-Est IFSTTAR F-93166 Noisy-le-Grand GRETTIA France","In this paper, the activity recognition problem from 3-d acceleration data measured with body-worn accelerometers is formulated as a problem of multidimensional time series segmentation and classification. More specifically, the proposed approach uses a statistical model based on Multiple Hidden Markov Model Regression (MHMMR) to automatically analyze the human activity. The method takes into account the sequential appearance and temporal evolution of the data to easily detect activities and transitions. Classification results obtained by the proposed approach and compared to those of the standard supervised classification approaches as well as the standard hidden Markov model show that the proposed approach is promising.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-81.pdf,2012,100.0,"Supervised and unsupervised classification approaches for human activity recognition using body-mounted sensors In this paper, the activity recognition problem from 3-d acceleration data measured with body-worn accelerometers is formulated as a problem of multidimensional time series segmentation and classification. More specifically, the proposed approach uses a statistical model based on Multiple Hidden Markov Model Regression (MHMMR) to automatically analyze the human activity. The method takes into account the sequential appearance and temporal evolution of the data to easily detect activities and transitions. Classification results obtained by the proposed approach and compared to those of the standard supervised classification approaches as well as the standard hidden Markov model show that the proposed approach is promising."
Using event-based metric for event-based neural network weight adjustment,"Bruno Cessac, Rodrigo Salas, Thierry Viéville","1 - Departamento de Ingenieria Biomedica Universidad de Valparaiso Chile
2 - http://cortex.loria.fr (2) Inria Neuromathcomp Inria Cortex France, France (","The problem of adjusting the parameters of an event-based network model is addressed here at the programmatic level. Considering temporal processing, the goal is to adjust the network units weights so that the outcoming events correspond to what is desired. The present work proposes, in the deterministic and discrete case, a way to adapt usual alignment metrics in order to derive suitable adjustment rules. At the numerical level, the stability and unbiasness of the method is verified. * Partially supported by the ANR KEOpS project and CORTINA associated team.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-82.pdf,2012,100.0,"Using event-based metric for event-based neural network weight adjustment The problem of adjusting the parameters of an event-based network model is addressed here at the programmatic level. Considering temporal processing, the goal is to adjust the network units weights so that the outcoming events correspond to what is desired. The present work proposes, in the deterministic and discrete case, a way to adapt usual alignment metrics in order to derive suitable adjustment rules. At the numerical level, the stability and unbiasness of the method is verified. * Partially supported by the ANR KEOpS project and CORTINA associated team."
Adaptive learning for complex-valued data,"Kerstin Bunte, Frank-Michael Schleif, Michael Biehl","1 - University of Bielefeld -CITEC Center of Excellence D-33501 Bielefeld Germany
3 - Institute for Mathematics and Computer Science University of Groningen -Johann Bernoulli P.O. Box 407 9700 AK Groningen The Netherlands","In this paper we propose a variant of the Generalized Matrix Learning Vector Quantization (GMLVQ) for dissimilarity learning on complex-valued data. Complex features can be encountered in various data domains, e.g. Fourier transformed mass spectrometry or image analysis data. Current approaches deal with complex inputs by ignoring the imaginary parts or concatenating real and imaginary parts in one real valued vector. In this contribution we propose a prototype based classification method, which allows to deal with complex-valued data directly. The algorithm is tested on a benchmark data set and for leaf recognition using Zernike moments. We observe that the complex version converges much faster than the original GMLVQ evaluated on the real parts only. The complex version has fewer free parameters than using a concatenated vector and is thus computationally more efficient than original GMLVQ.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-85.pdf,2012,100.0,"Adaptive learning for complex-valued data In this paper we propose a variant of the Generalized Matrix Learning Vector Quantization (GMLVQ) for dissimilarity learning on complex-valued data. Complex features can be encountered in various data domains, e.g. Fourier transformed mass spectrometry or image analysis data. Current approaches deal with complex inputs by ignoring the imaginary parts or concatenating real and imaginary parts in one real valued vector. In this contribution we propose a prototype based classification method, which allows to deal with complex-valued data directly. The algorithm is tested on a benchmark data set and for leaf recognition using Zernike moments. We observe that the complex version converges much faster than the original GMLVQ evaluated on the real parts only. The complex version has fewer free parameters than using a concatenated vector and is thus computationally more efficient than original GMLVQ."
Matrix Relevance LVQ in Steroid Metabolomics Based Classification of Adrenal Tumors,"M Biehl, P Schneider, D Smith, H Stiekema, A Taylor, B Hughes, C Shackleton, P Stewart, W Arlt","1 - Inst. for Math. and Computer Science Univ. of Groningen -Johann Bernoulli P.O. Box 407 9700 AK Groningen The Netherlands
2 - Centre for Endocrinology, Diabetes, and Metabolism University of Birmingham B15 2TT Birmingham United Kingdom","We present a machine learning system for the differential diagnosis of benign adrenocortical adenoma (ACA) vs. malignant adrenocortical carcinoma (ACC). The data employed for the classification are urinary excretion values of 32 steroid metabolites. We apply prototypebased classification techniques to discriminate the classes, in particular, we use modifications of Generalized Learning Vector Quantization including matrix relevance learning. The obtained system achieves high sensitivity and specificity and outperforms previously used approaches for the detection of adrenal malignancy. Moreover, the method identifies a subset of most discriminative markers which facilitates its future use as a noninvasive high-throughput diagnostic tool.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-86.pdf,2012,73.49397590361446,"Matrix Relevance LVQ in Steroid Metabolomics Based Classification of Adrenal Tumors We present a machine learning system for the differential diagnosis of benign adrenocortical adenoma (ACA) vs. malignant adrenocortical carcinoma (ACC). The data employed for the classification are urinary excretion values of 32 steroid metabolites. We apply prototypebased classification techniques to discriminate the classes, in particular, we use modifications of Generalized Learning Vector Quantization including matrix relevance learning. The obtained system achieves high sensitivity and specificity and outperforms previously used approaches for the detection of adrenal malignancy. Moreover, the method identifies a subset of most discriminative markers which facilitates its future use as a noninvasive high-throughput diagnostic tool."
RNN based Batch Mode Active Learning Framework,"Gaurav Maheshwari, Vikram Pudi",1 - Centre for Data Engineering IIIT Hyderabad India,"Active Learning has been applied in many real world classification tasks to reduce the amount of labeled data required for training a classifier. However most of the existing active learning strategies select only a single sample for labeling by the oracle in every iteration. This results in retraining the classifier after each sample is added which is quite computationally expensive. Also many of the existing sample selection strategies are not suitable for the multi-class classification tasks. To overcome these issues, we propose an efficient batch mode framework for active learning using the notion of influence sets based on Reverse Nearest Neighbor, which is applicable for multi-class classification as well. To demonstrate the effectiveness of our technique, we compare its performance against existing active learning techniques on real life datasets. Experimental results show that our technique outperforms existing active learning methods significantly especially on multi-class datasets.",Classification and model selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-88.pdf,2012,86.95652173913044,"RNN based Batch Mode Active Learning Framework Active Learning has been applied in many real world classification tasks to reduce the amount of labeled data required for training a classifier. However most of the existing active learning strategies select only a single sample for labeling by the oracle in every iteration. This results in retraining the classifier after each sample is added which is quite computationally expensive. Also many of the existing sample selection strategies are not suitable for the multi-class classification tasks. To overcome these issues, we propose an efficient batch mode framework for active learning using the notion of influence sets based on Reverse Nearest Neighbor, which is applicable for multi-class classification as well. To demonstrate the effectiveness of our technique, we compare its performance against existing active learning techniques on real life datasets. Experimental results show that our technique outperforms existing active learning methods significantly especially on multi-class datasets."
Constructive Reservoir Computation with Output Feedbacks for Structured Domains,"Claudio Gallicchio, Alessio Micheli, Giulio Visco",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 -56127 Pisa Italy,"We introduce a novel constructive algorithm which progressively builds the architecture of GraphESN, which generalizes Reservoir Computing to learning in graph domains. Exploiting output feedback signals in a forward fashion in such construction, allows us to introduce supervision in the reservoir encoding process. The potentiality of the proposed approach is experimentally assessed on real-world tasks from Toxicology.",Theory and practice of adaptive input driven dynamical dystems,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-89.pdf,2012,100.0,"Constructive Reservoir Computation with Output Feedbacks for Structured Domains We introduce a novel constructive algorithm which progressively builds the architecture of GraphESN, which generalizes Reservoir Computing to learning in graph domains. Exploiting output feedback signals in a forward fashion in such construction, allows us to introduce supervision in the reservoir encoding process. The potentiality of the proposed approach is experimentally assessed on real-world tasks from Toxicology."
An Exploration of Research Directions in Machine Ensemble Theory and Applications,"A Figueiras-Vidal, L Rokach","1 - Dept. of Signal Theory and Communications Universidad Carlos III de Madrid
2 - Avda. de la Universidad 30 28911 Leganés, Madrid Spain
3 - Dept. of Information Systems Engineering Ben-Gurion University of the Negev 84105 Beer-Sheva Israel","A concise overview of the fundamentals and the main types of machine ensembles serves to propose a structured perspective for the papers that are included in this special session. The subsequent brief discussion of the works, emphasizing their principal contributions, permits an extraction of a series of suggestions for further research in the fruitful area of ensemble learning.",Machine ensembles: theory and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-9.pdf,2012,100.0,"An Exploration of Research Directions in Machine Ensemble Theory and Applications A concise overview of the fundamentals and the main types of machine ensembles serves to propose a structured perspective for the papers that are included in this special session. The subsequent brief discussion of the works, emphasizing their principal contributions, permits an extraction of a series of suggestions for further research in the fruitful area of ensemble learning."
A Discrete/Rhythmic Pattern Generating RNN,"Tim Waegeman, Francis Wyffels, Benjamin Schrauwen",1 - Department of Electronics and Information Systems Ghent University Sint Pietersnieuwstraat 41 B9000 Ghent Belgium,"Biological research supports the concept that advanced motion emerges from modular building blocks, which generate both rhythmical and discrete patterns. Inspired by these ideas, roboticists try to implement such building blocks using different techniques. In this paper, we show how to build such module by using a recurrent neural network (RNN) to encapsulate both discrete and rhythmical motion patterns into a single network. We evaluate the proposed system on a planar robotic manipulator. For training, we record several handwriting motions by back driving the robot manipulator. Finally, we demonstrate the ability to learn multiple motions (even discrete and rhythmic) and evaluate the pattern generation robustness in the presence of perturbations.","Recurrent and neural networks, reinforcement learning, control",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-90.pdf,2012,80.95238095238095,"A Discrete/Rhythmic Pattern Generating RNN Biological research supports the concept that advanced motion emerges from modular building blocks, which generate both rhythmical and discrete patterns. Inspired by these ideas, roboticists try to implement such building blocks using different techniques. In this paper, we show how to build such module by using a recurrent neural network (RNN) to encapsulate both discrete and rhythmical motion patterns into a single network. We evaluate the proposed system on a planar robotic manipulator. For training, we record several handwriting motions by back driving the robot manipulator. Finally, we demonstrate the ability to learn multiple motions (even discrete and rhythmic) and evaluate the pattern generation robustness in the presence of perturbations."
Assessment of Sequential Boltzmann Machines on a Lexical Processing Task,"Alberto Testolin, Alessandro Sperduti, Ivilin Stoianov, Marco Zorzi","1 - Department of Pure and Applied Mathematics
2 - Department of General Psychology and Center for Cognitive Sciences University of Padova Italy","The Recurrent Temporal Restricted Boltzmann Machine is a promising probabilistic model for processing temporal data. It has been shown to learn physical dynamics from videos (e.g. bouncing balls), but its ability to process sequential data has not been tested on symbolic tasks. Here we assess its capabilities on learning sequences of letters corresponding to English words. It emerged that the model is able to extract local transition rules between items of a sequence (i.e. English graphotactic rules), but it does not seem to be suited to encode a whole word.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-94.pdf,2012,81.11888111888112,"Assessment of Sequential Boltzmann Machines on a Lexical Processing Task The Recurrent Temporal Restricted Boltzmann Machine is a promising probabilistic model for processing temporal data. It has been shown to learn physical dynamics from videos (e.g. bouncing balls), but its ability to process sequential data has not been tested on symbolic tasks. Here we assess its capabilities on learning sequences of letters corresponding to English words. It emerged that the model is able to extract local transition rules between items of a sequence (i.e. English graphotactic rules), but it does not seem to be suited to encode a whole word."
An Analysis of Gaussian-Binary Restricted Boltzmann Machines for Natural Images,"Nan Wang, Jan Melchior, Laurenz Wiskott","1 - Institut für Neuroinformatik Ruhr-Universität Bochum 44780 Bochum Germany
2 - International Graduate School of Neuroscience Ruhr-Universität Bochum 44780 Bochum Germany","A Gaussian-binary restricted Boltzmann machine is a widely used energy-based model for continuous data distributions, although many authors reported difficulties in training on natural images. To clarify the model's capabilities and limitations we derive a rewritten formula of the probability density function as a linear superposition of Gaussians. Based on this formula we show how Gaussian-binary RBMs learn natural image statistics. However the probability density function of the model is not a good representation of the data distribution.","Bayesian and graphical models, optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2012-95.pdf,2012,73.41772151898735,"An Analysis of Gaussian-Binary Restricted Boltzmann Machines for Natural Images A Gaussian-binary restricted Boltzmann machine is a widely used energy-based model for continuous data distributions, although many authors reported difficulties in training on natural images. To clarify the model's capabilities and limitations we derive a rewritten formula of the probability density function as a linear superposition of Gaussians. Based on this formula we show how Gaussian-binary RBMs learn natural image statistics. However the probability density function of the model is not a good representation of the data distribution."
Range-based non-orthogonal ICA using cross-entropy method,"S Selvan, A Chattopadhyay, U Amato, P.-A Absil","1 - Université catholique de Louvain -ICTEAM Institute 1348 Louvain-la-Neuve Belgium
2 - Université catholique de Louvain -iMMC 3-Consiglio Nazionale delle Ricerche -Istituto per le Applicazioni del Calcolo Napoli 80131 Italy","A derivative-free framework for optimizing a non-smooth range-based contrast function in order to estimate independent components is presented. The proposed algorithm employs the von-Mises Fisher (vMF) distribution to draw random samples in the cross-entropy (CE) method, thereby intrinsically maintaining the unit-norm constraint that removes the scaling indeterminacy in independent component analysis (ICA) problem. Empirical studies involving natural images show how this approach outperforms popular schemes  [1]  in terms of the separation performance. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, Science Policy Office. The scientific responsibility rests with its authors.",Feature selection and information-based learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-97.pdf,2012,100.0,"Range-based non-orthogonal ICA using cross-entropy method A derivative-free framework for optimizing a non-smooth range-based contrast function in order to estimate independent components is presented. The proposed algorithm employs the von-Mises Fisher (vMF) distribution to draw random samples in the cross-entropy (CE) method, thereby intrinsically maintaining the unit-norm constraint that removes the scaling indeterminacy in independent component analysis (ICA) problem. Empirical studies involving natural images show how this approach outperforms popular schemes  [1]  in terms of the separation performance. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, Science Policy Office. The scientific responsibility rests with its authors."
Visualizing the quality of dimensionality reduction,"Bassam Mokbel, Wouter Lueks, Andrej Gisbrecht, Michael Biehl, Barbara Hammer","1 - Bielefeld University -CITEC Centre of Excellence Germany
2 - Faculty of Mathematics and Natural Sciences University of Groningen Netherlands
6 - Faculty of Science University of Nijmegen The Netherlands","Many different evaluation measures for dimensionality reduction can be summarized based on the co-ranking framework  [6] . Here, we extend this framework in two ways: (i) we show that the current parameterization of the quality shows unpredictable behavior, even in simple settings, and we propose a different parameterization which yields more intuitive results; (ii) we propose how to link the quality to point-wise quality measures which can directly be integrated into the visualization.",Interpretable models in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-99.pdf,2012,100.0,"Visualizing the quality of dimensionality reduction Many different evaluation measures for dimensionality reduction can be summarized based on the co-ranking framework  [6] . Here, we extend this framework in two ways: (i) we show that the current parameterization of the quality shows unpredictable behavior, even in simple settings, and we propose a different parameterization which yields more intuitive results; (ii) we propose how to link the quality to point-wise quality measures which can directly be integrated into the visualization."
Developments in kernel design,Lluís Belanche,1 - Computer Science School -Dept. of Software Technical University of Catalonia Jordi Girona 1-3 08034 Barcelona SPAIN,"The aim of this paper is to give a concise overview of kernels, with a special attention to non-standard or heterogeneous data sources (e.g. non-numerical or structured data). A second goal is to discuss the world of possibilities that kernel design opens for the principled analysis of special or new application domains. The reader is referred to some of the excellent survey publications -as [1, 2, 3]-for an in-depth coverage. * Financial support from the Spanish CICYT project TIN2012-31377 is greatly appreciated.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-10.pdf,2013,100.0,"Developments in kernel design The aim of this paper is to give a concise overview of kernels, with a special attention to non-standard or heterogeneous data sources (e.g. non-numerical or structured data). A second goal is to discuss the world of possibilities that kernel design opens for the principled analysis of special or new application domains. The reader is referred to some of the excellent survey publications -as [1, 2, 3]-for an in-depth coverage. * Financial support from the Spanish CICYT project TIN2012-31377 is greatly appreciated."
WIPS: the WiSARD Indoor Positioning System,"D Cardoso, J Gama, M De Gregorio, F França, M Giordano, P Lima","1 - Universidade Federal do Rio de Janeiro PESC-COPPE Rio de Janeiro Brazil
2 - University of Porto LIAAD-INESC Porto Portugal
3 - Istituto di Cibernetica ""E. Caianiello"" -CNR Pozzuoli (NA) Italy
6 - DEMAT-ICE Seropédica Universidade Federal Rural do Rio de Janeiro Brazil","In this paper, we present a WiSARD-based system facing the problem of Indoor Positioning (IP) by taking advantage of pervasively available infrastructures (WiFi Access Points -AP). The goal is to develop a system to be used to position users in indoor environments, such as: museums, malls, factories, offshore platforms etc. Based on the fingerprint approach, we show how the proposed weightless neural system provides very good results in terms of performance and positioning resolution. Both the approach to the problem and the system will be presented through two correlated experiments.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-101.pdf,2013,100.0,"WIPS: the WiSARD Indoor Positioning System In this paper, we present a WiSARD-based system facing the problem of Indoor Positioning (IP) by taking advantage of pervasively available infrastructures (WiFi Access Points -AP). The goal is to develop a system to be used to position users in indoor environments, such as: museums, malls, factories, offshore platforms etc. Based on the fingerprint approach, we show how the proposed weightless neural system provides very good results in terms of performance and positioning resolution. Both the approach to the problem and the system will be presented through two correlated experiments."
Synthetic over-sampling in the empirical feature space,"M Pérez-Ortiz, P Gutiérrez, C Hervás-Martínez",1 - Dept. of Computer Science University of Córdoba Numerical Analysis Rabanales Campus Albert Einstein building 14071 Córdoba Spain,"The imbalanced nature of some real-world data is one of the current challenges for machine learning, giving rise to different approaches to handling it. However, preprocessing methods operate in the original input space, presenting distortions when combined with the kernel classifiers, which make use of the feature space. This paper explores the notion of empirical feature space (a Euclidean space which is isomorphic to the feature space) to develop a kernel-based synthetic over-sampling technique, which maintains the main properties of the kernel mapping. The proposal achieves better results than the same oversampling method applied to the original input space.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-103.pdf,2013,100.0,"Synthetic over-sampling in the empirical feature space The imbalanced nature of some real-world data is one of the current challenges for machine learning, giving rise to different approaches to handling it. However, preprocessing methods operate in the original input space, presenting distortions when combined with the kernel classifiers, which make use of the feature space. This paper explores the notion of empirical feature space (a Euclidean space which is isomorphic to the feature space) to develop a kernel-based synthetic over-sampling technique, which maintains the main properties of the kernel mapping. The proposal achieves better results than the same oversampling method applied to the original input space."
A dictionary learning based method for aCGH segmentation,"Salvatore Masecchia, Saverio Salzo, Annalisa Barla, Alessandro Verri",1 - DIBRIS via Dodecaneso 35 Genova Italy,"The starting point of our work is to devise a model for segmentation of aCGH data. We propose an optimization method based on dictionary learning and regularization and we compare it with a stateof-the-art approach, presenting our experimental results on synthetic data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-104.pdf,2013,100.0,"A dictionary learning based method for aCGH segmentation The starting point of our work is to devise a model for segmentation of aCGH data. We propose an optimization method based on dictionary learning and regularization and we compare it with a stateof-the-art approach, presenting our experimental results on synthetic data."
Handling missing values in kernel methods with application to microbiology data,"Vladimer Kobayashi, Tomàs Aluja, Lluís Belanche","1 - Laboratoire Hubert Curien -UMR CNRS 5516 Bâtiment F 18 Rue du Professeur Benoît Lauras 42000 Saint-Etienne FRANCE
2 - Computer Science School -Dept. of Statistics & Operations Research Technical University of Catalonia Jordi Girona 1-3 08034 Barcelona SPAIN
3 - Computer Science School -Dept. of Software Technical University of Catalonia Jordi Girona 1-3 08034 Barcelona SPAIN","We discuss several approaches that make possible for kernel methods to deal with missing values. The first two are extended kernels able to handle missing values without data preprocessing methods. Another two methods are derived from a sophisticated multiple imputation technique involving logistic regression as local model learner. The performance of these approaches is compared using a binary data set that arises typically in microbiology (the microbial source tracking problem). Our results show that the kernel extensions demonstrate competitive performance in comparison with multiple imputation in terms of predictive accuracy. However, these results are achieved with a simpler and deterministic methodology and entail a much lower computational effort.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-105.pdf,2013,100.0,"Handling missing values in kernel methods with application to microbiology data We discuss several approaches that make possible for kernel methods to deal with missing values. The first two are extended kernels able to handle missing values without data preprocessing methods. Another two methods are derived from a sophisticated multiple imputation technique involving logistic regression as local model learner. The performance of these approaches is compared using a binary data set that arises typically in microbiology (the microbial source tracking problem). Our results show that the kernel extensions demonstrate competitive performance in comparison with multiple imputation in terms of predictive accuracy. However, these results are achieved with a simpler and deterministic methodology and entail a much lower computational effort."
Using Wikipedia with associative networks for document classification,"N Bloom, M Theune, F De Jong","1 - University of Twente Enschede The Netherlands
4 - 1-Perrit B.V Hengelo The Netherlands","We demonstrate a new technique for building associative networks based on Wikipedia, comparing them to WordNet-based associative networks that we used previously, finding the Wikipedia-based networks to perform better at document classification. Additionally, we compare the performance of associative networks to various other text classification techniques using the Reuters-21578 dataset, establishing that associative networks can achieve comparable results.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-106.pdf,2013,100.0,"Using Wikipedia with associative networks for document classification We demonstrate a new technique for building associative networks based on Wikipedia, comparing them to WordNet-based associative networks that we used previously, finding the Wikipedia-based networks to perform better at document classification. Additionally, we compare the performance of associative networks to various other text classification techniques using the Reuters-21578 dataset, establishing that associative networks can achieve comparable results."
A new metric for dissimilarity data classification based on Support Vector Machines optimization,"Agata Manolova, Anne Guerin-Dugue","1 - Technical University Sofia Faculty of Telecommunications 8 ave Kliment Ohridski 1000 Sofia Bulgaria
2 - GIPSA-Lab Department of Images and Signal Grenoble INP-CNRS France","Dissimilarities are extremely useful in many real-world pattern classification problems, where the data resides in a complicated, complex space, and it can be very difficult, if not impossible, to find useful feature vector representations. In these cases a dissimilarity representation may be easier to come by. The goal of this work is to provide a new technique based on Support Vector Machines (SVM) optimization that can be a good alternative in terms of accuracy compared to known methods using dissimilarities such as k nearest neighbor classifier (kNN), prototype-based dissimilarity classifiers and distance kernel based SVM classifiers.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-107.pdf,2013,100.0,"A new metric for dissimilarity data classification based on Support Vector Machines optimization Dissimilarities are extremely useful in many real-world pattern classification problems, where the data resides in a complicated, complex space, and it can be very difficult, if not impossible, to find useful feature vector representations. In these cases a dissimilarity representation may be easier to come by. The goal of this work is to provide a new technique based on Support Vector Machines (SVM) optimization that can be a good alternative in terms of accuracy compared to known methods using dissimilarities such as k nearest neighbor classifier (kNN), prototype-based dissimilarity classifiers and distance kernel based SVM classifiers."
Learning Associative Spatiotemporal Features with Non-negative Sparse Coding,"Thomas Guthier, Steve Gerges, Volker Willert, Julian Eggert","1 - -TU Darmstadt -Control theory and robotics lab Landgraf-Georg-Str. 4 64283 Darmstadt -Germany
4 - Honda Research Institute Europe Carl-Legien-Str. 30 63073 Offenbach Germany","Motion features based on optical flow are very powerful in tasks such as the recognition of human actions or gestures. Usually, they are combined with gradient information to form a set of spatiotemporal features. However, humans can recognize gestures and actions and thus derive the implied motion out of static images alone. We model this associative recognition within a learned hierarchy of non-negative sparse coding layers. In the first stages, topology preserving gradient and motion features are processed separately. Afterwards, they are projected onto a combined inner representation, that is learned during the training phase. We show, that during recognition the learned, combined representation improves the recognition of human actions, even in the absence of explicit motion information.",Machine Learning for multimedia applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-109.pdf,2013,81.57894736842105,"Learning Associative Spatiotemporal Features with Non-negative Sparse Coding Motion features based on optical flow are very powerful in tasks such as the recognition of human actions or gestures. Usually, they are combined with gradient information to form a set of spatiotemporal features. However, humans can recognize gestures and actions and thus derive the implied motion out of static images alone. We model this associative recognition within a learned hierarchy of non-negative sparse coding layers. In the first stages, topology preserving gradient and motion features are processed separately. Afterwards, they are projected onto a combined inner representation, that is learned during the training phase. We show, that during recognition the learned, combined representation improves the recognition of human actions, even in the absence of explicit motion information."
Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments,"Jorge Reyes-Ortiz, Alessandro Ghio, Davide Anguita, Xavier Parra, Joan Cabestany, Andreu Català","1 - Università degli Studi di Genova -DITEN Via Opera Pia 11A I-16145 Genoa Italy
2 - Universitat Politècnica de Catalunya -CETpD Rambla de l'Exposició 59-69 08800 Vilanova i la Geltrú Spain","The rise of ubiquitous computing systems in our environment is engendering a strong need for novel approaches of human-computer interaction. Either for extending the existing range of possibilities and services available to people or for providing assistance the ones with limited conditions. Human Activity Recognition (HAR) is playing a central role in this task by offering the input for the development of more interactive and cognitive environments. This has motivated the organization of the ESANN 2013 Special Session in Human Activity and Motion Disorder Recognition and the execution of a competition in HAR. Here, a compilation of the most recent proposals in the area are exposed accompanied by the results of the contest calling for innovative approaches to recognize activities of daily living (ADL) from a recently published data set.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-11.pdf,2013,93.87755102040816,"Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments The rise of ubiquitous computing systems in our environment is engendering a strong need for novel approaches of human-computer interaction. Either for extending the existing range of possibilities and services available to people or for providing assistance the ones with limited conditions. Human Activity Recognition (HAR) is playing a central role in this task by offering the input for the development of more interactive and cognitive environments. This has motivated the organization of the ESANN 2013 Special Session in Human Activity and Motion Disorder Recognition and the execution of a competition in HAR. Here, a compilation of the most recent proposals in the area are exposed accompanied by the results of the contest calling for innovative approaches to recognize activities of daily living (ADL) from a recently published data set."
Content-based image retrieval with hierarchical Gaussian Process bandits with self-organizing maps,"Ksenia Konyushkova, Dorota Lowacka",1 - Department of Computer Science Helsinki Institute for Information Technology University of Helsinki Finland,A content-based image retrieval system based on relevance feedback is proposed. The system relies on an interactive search paradigm where at each round a user is presented with k images and selects the one closest to her target. The approach based on hierarchical Gaussian Process (GP) bandits is used to trade exploration and exploitation in presenting the images in each round. Experimental results show that the new approach compares favorably with previous work.,Machine Learning for multimedia applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-111.pdf,2013,100.0,Content-based image retrieval with hierarchical Gaussian Process bandits with self-organizing maps A content-based image retrieval system based on relevance feedback is proposed. The system relies on an interactive search paradigm where at each round a user is presented with k images and selects the one closest to her target. The approach based on hierarchical Gaussian Process (GP) bandits is used to trade exploration and exploitation in presenting the images in each round. Experimental results show that the new approach compares favorably with previous work.
ÒÙ Ð Ö¹ÒÓÖÑ × ÓÒÚ Ü ÓÖÑÙÐ Ø ÓÒ ÓÖ Ò ÓÖÑ ×ÓÙÖ × Ô Ö Ø ÓÒ,Ù Ù×ø Ò Ä Úö ½ ¸ Ö Ò Ó × Ð Ò Ùö ½ ¾ Ò Èº¹,Unknown,"We designed and implemented a decision support system for small tomatoes producers that investigates ways to recognize the late blight disease from the analysis of digital images of tomatoes, using a pair of multilayer perceptron neural network. The networks outputs are used to calculate the damage level at each plant and to construct a situation map of a farm where a cellular automata simulates the outbreak evolution over the fields. The simulator can test different pesticides actions, helping in the decision on when to start the spraying and in the analysis of losses and gains of each choice of action.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-39.pdf,2013,21.118012422360245,"ÒÙ Ð Ö¹ÒÓÖÑ × ÓÒÚ Ü ÓÖÑÙÐ Ø ÓÒ ÓÖ Ò ÓÖÑ ×ÓÙÖ × Ô Ö Ø ÓÒ We designed and implemented a decision support system for small tomatoes producers that investigates ways to recognize the late blight disease from the analysis of digital images of tomatoes, using a pair of multilayer perceptron neural network. The networks outputs are used to calculate the damage level at each plant and to construct a situation map of a farm where a cellular automata simulates the outbreak evolution over the fields. The simulator can test different pesticides actions, helping in the decision on when to start the spraying and in the analysis of losses and gains of each choice of action."
Linear Spectral Hashing,"Zalán Bodó, Lehel Csató",1 - Faculty of Mathematics and Computer Science Babeş-Bolyai University Kogȃlniceanu 1 400084 Cluj-Napoca Romania,"Spectral hashing assigns binary hash keys to data points. This is accomplished via thresholding the eigenvectors of the graph Laplacian and obtaining binary codewords. While calculation for inputs in the training set is straightforward, an intriguing and difficult problem is how to compute the hash codewords for unseen data. A second problem we address is the computational difficulties when using the Gaussian similarity measure in spectral hashing: for specific problems -mainly the processing of large text databases -we propose linear scalar products as similarity measures and analyze the performance of the algorithm. We implement the linear algorithm and provide an inductive -generative -formula that leads to a prediction method similar to locality-sensitive hashing for a new data point. Experiments on document retrieval show promising results.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-113.pdf,2013,60.86956521739131,"Linear Spectral Hashing Spectral hashing assigns binary hash keys to data points. This is accomplished via thresholding the eigenvectors of the graph Laplacian and obtaining binary codewords. While calculation for inputs in the training set is straightforward, an intriguing and difficult problem is how to compute the hash codewords for unseen data. A second problem we address is the computational difficulties when using the Gaussian similarity measure in spectral hashing: for specific problems -mainly the processing of large text databases -we propose linear scalar products as similarity measures and analyze the performance of the algorithm. We implement the linear algorithm and provide an inductive -generative -formula that leads to a prediction method similar to locality-sensitive hashing for a new data point. Experiments on document retrieval show promising results."
Read Classification for Next Generation Sequencing,"James Hogan, Peter Holland, Alexander Holloway, Robert Petit, Timothy Read","1 - School of EECS -Faculty of Science and Engineering QUT GPO Box 2434 4001 Brisbane QLD Australia
4 - Department of Human Genetics Emory University School of Medicine Whitehead Biomedical Research Building 615 Michael Street, Suite 301 30322 Atlanta GA United States of America","Next Generation Sequencing (NGS) has revolutionised molecular biology, allowing routine clinical sequencing. NGS data consists of short sequence reads, given context through downstream assembly and annotation, a process requiring reads consistent with the assumed species or species group. The common bacterium Staphylococcus aureus may cause severe and life-threatening infections in humans, with some strains exhibiting antibiotic resistance. Here we apply an SVM classifier to the important problem of distinguishing S. aureus sequencing projects from other pathogens, including closely related Staphylococci. Using a sequence k-mer representation, we achieve precision and recall above 95%, implicating features with important functional associations.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-115.pdf,2013,74.0,"Read Classification for Next Generation Sequencing Next Generation Sequencing (NGS) has revolutionised molecular biology, allowing routine clinical sequencing. NGS data consists of short sequence reads, given context through downstream assembly and annotation, a process requiring reads consistent with the assumed species or species group. The common bacterium Staphylococcus aureus may cause severe and life-threatening infections in humans, with some strains exhibiting antibiotic resistance. Here we apply an SVM classifier to the important problem of distinguishing S. aureus sequencing projects from other pathogens, including closely related Staphylococci. Using a sequence k-mer representation, we achieve precision and recall above 95%, implicating features with important functional associations."
Efficient prediction of x-axis intercepts of discrete impedance spectra,"Thomas Schmid, Dorothee Günzel, Martin Bogdan","1 - Department of Computer Engineering Universität Leipzig Augustusplatz 10 04109 Leipzig Germany
2 - Charité -Institute of Clinical Physiology Campus Benjamin Franklin 12200 Berlin Germany","In impedance spectroscopy of epithelial cell layers, it is a common task to extrapolate discrete two-dimensional plots in order to determine electrical properties associated with axis intercepts. Here, we investigate how implicit properties of such curves can be used to predict the x-axis intercept where explicitly determined properties fail to do so. We perform feature extraction, algorithmic feature ranking and dimension reduction on model impedance spectra derived from a tissue-equivalent electric circuit. Selected feature subsets are assessed by training artificial neural networks to predict the intercept. Results show that subsets of three or less implicit features provide a reasonable basis for predictions.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-116.pdf,2013,100.0,"Efficient prediction of x-axis intercepts of discrete impedance spectra In impedance spectroscopy of epithelial cell layers, it is a common task to extrapolate discrete two-dimensional plots in order to determine electrical properties associated with axis intercepts. Here, we investigate how implicit properties of such curves can be used to predict the x-axis intercept where explicitly determined properties fail to do so. We perform feature extraction, algorithmic feature ranking and dimension reduction on model impedance spectra derived from a tissue-equivalent electric circuit. Selected feature subsets are assessed by training artificial neural networks to predict the intercept. Results show that subsets of three or less implicit features provide a reasonable basis for predictions."
GA-KDE-Bayes: An Evolutionary Wrapper Method Based on Non-Parametric Density Estimation Applied to Bioinformatics Problems,"Maria Wanderley, Vincent Gardeux, René Natowicz, Antônio Braga","1 - Graduate Program in Electrical Engineering -Federal University of Minas Gerais Av 6627, 31270-901 Belo Horizonte Antônio Carlos, MG Brazil
2 - ESIEE-Paris -University of Paris-Est Noisy-le-Grand France
4 - Avenue du Parc Cergy France","This paper presents an evolutionary wrapper method for feature selection that uses a non-parametric density estimation method and a Bayesian Classifier. Non-parametric methods are a good alternative for scarce and sparse data, as in Bioinformatics problems, since they do not make any assumptions about its structure and all the information come from data itself. Results show that local modeling provides small and relevant subsets of features when comparing to results available on literature.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-117.pdf,2013,74.59016393442623,"GA-KDE-Bayes: An Evolutionary Wrapper Method Based on Non-Parametric Density Estimation Applied to Bioinformatics Problems This paper presents an evolutionary wrapper method for feature selection that uses a non-parametric density estimation method and a Bayesian Classifier. Non-parametric methods are a good alternative for scarce and sparse data, as in Bioinformatics problems, since they do not make any assumptions about its structure and all the information come from data itself. Results show that local modeling provides small and relevant subsets of features when comparing to results available on literature."
Support Vector Machine-based approach for multi-labelers problems,"S Murillo, D Peluffo, G Castellanos",1 - Departamento de Ingeniería Eléctrica Universidad Nacional de Colombia Electrónica y Computación Manizales Colombia,"We propose a first approach to quantify the panelist's labeling generalizing a soft-margin support vector machine classifier to multi-labeler analysis. Our approach consists of formulating a quadratic optimization problem instead of using a heuristic search algorithm. We determine penalty factors for each panelist by incorporating a linear combination in the primal formulation. Solution is obtained on a dual formulation using quadratic programming. For experiments, the well-known Iris with multiple simulated artificial labels and a multi-label speech database are employed. Obtained penalty factors are compared with both standard supervised and non-supervised measurements. Promising results show that proposed method is able to asses the concordance among panelists considering the structure of data. * This work is supported by the ""Aprendizaje de máquina a partir de múltiples expertos en clasificación multiclase de señales de voz"" project associated with ""Jóvenes Investigadores"" program by COLCIENCIAS",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-150.pdf,2013,55.94405594405594,"Support Vector Machine-based approach for multi-labelers problems We propose a first approach to quantify the panelist's labeling generalizing a soft-margin support vector machine classifier to multi-labeler analysis. Our approach consists of formulating a quadratic optimization problem instead of using a heuristic search algorithm. We determine penalty factors for each panelist by incorporating a linear combination in the primal formulation. Solution is obtained on a dual formulation using quadratic programming. For experiments, the well-known Iris with multiple simulated artificial labels and a multi-label speech database are employed. Obtained penalty factors are compared with both standard supervised and non-supervised measurements. Promising results show that proposed method is able to asses the concordance among panelists considering the structure of data. * This work is supported by the ""Aprendizaje de máquina a partir de múltiples expertos en clasificación multiclase de señales de voz"" project associated with ""Jóvenes Investigadores"" program by COLCIENCIAS"
Forecasting Financial Markets with Classified Tactical Signals,"Patrick Kouontchou, Amaury Lendasse, Yoan Miche, Bertrand Maillet","1 - -Variances and University de Lorraine (CEREFIGE). Ile du Saulcy 57045 Metz cedex 01 France
2 - ICS Department Aalto University School of Science Konemiehentie 2 FI-00076 Finland
3 - France
6 - LEO/CNRS Rue de Blois F-45067 Orléans Cedex","The financial market dynamics can be characterized by macro-economic, micro-financial and market risk indicators, used as leading indicators by market professionals. In this article, we propose a method to identify market states integrating two classification algorithms: a Robust Kohonen Self-Organising Maps one and a CART one. After studying the market's states separation using the former, we use the latter to characterize the economic conditions over time and to compute the conditional probabilities of related market states.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-121.pdf,2013,100.0,"Forecasting Financial Markets with Classified Tactical Signals The financial market dynamics can be characterized by macro-economic, micro-financial and market risk indicators, used as leading indicators by market professionals. In this article, we propose a method to identify market states integrating two classification algorithms: a Robust Kohonen Self-Organising Maps one and a CART one. After studying the market's states separation using the former, we use the latter to characterize the economic conditions over time and to compute the conditional probabilities of related market states."
A Competitive Approach for Human Activity Recognition on Smartphones,"Attila Reiss, Gustaf Hendeby, Didier Stricker","1 - German Research Center for Artificial Intelligence (DFKI) Trippstadter Str. 122 67663 Kaiserslautern Germany
2 - Division of Sensor and E/W Systems Swedish Defence Research Agency (FOI) -Competence Group Sensor Informatics 581 11 Linköping Sweden
3 - Dept. of Electrical Engineering Linköping University 581 83 Linköping Sweden","This paper describes a competitive approach developed for an activity recognition challenge. The competition was defined on a new and publicly available dataset of human activities, recorded with smartphone sensors. This work investigates different feature sets for the activity recognition task of the competition. Moreover, the focus is also on the introduction of a new, confidence-based boosting algorithm called ConfAda-Boost.M1. Results show that the new classification method outperforms commonly used classifiers, such as decision trees or AdaBoost.M1.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-122.pdf,2013,80.88235294117648,"A Competitive Approach for Human Activity Recognition on Smartphones This paper describes a competitive approach developed for an activity recognition challenge. The competition was defined on a new and publicly available dataset of human activities, recorded with smartphone sensors. This work investigates different feature sets for the activity recognition task of the competition. Moreover, the focus is also on the introduction of a new, confidence-based boosting algorithm called ConfAda-Boost.M1. Results show that the new classification method outperforms commonly used classifiers, such as decision trees or AdaBoost.M1."
A Sparse Kernelized Matrix Learning Vector Quantization Model for Human Activity Recognition,"M Kästner, M Strickert, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
2 - Fac. of Mathematics and Computer Sciences -University Marburg
3 - Knowledge Engineering & Bioinformatics Group Germany","The contribution describes our application to the ESANN'2013 Competition on Human Activity Recognition (HAR) using Android-OS smartphone sensor signals. We applied a kernel variant of learning vector quantization with metric adaptation using only one prototype vector per class. This sparse model obtains very good accuracies and additionally provides class correlation information. Further, the model allows an optimized class visualization.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-123.pdf,2013,84.78260869565217,"A Sparse Kernelized Matrix Learning Vector Quantization Model for Human Activity Recognition The contribution describes our application to the ESANN'2013 Competition on Human Activity Recognition (HAR) using Android-OS smartphone sensor signals. We applied a kernel variant of learning vector quantization with metric adaptation using only one prototype vector per class. This sparse model obtains very good accuracies and additionally provides class correlation information. Further, the model allows an optimized class visualization."
Machine Learning and Content-Based Multimedia Retrieval,"Philippe-Henri Gosselin, David Picard","1 - INRIA Rennes Bretagne Atlantique Rennes France
2 - ETIS ENSEA Université de Cergy-Pontoise -CNRS Cergy-Pontoise France","This paper presents an overview of popular retrieval techniques based on machine learning for content based multimedia retrieval. Furthermore, we also propose to highlight current gaps and required improvement in this context. We first introduce common retrieval problems, and the usual models and assumptions made on multimedia data. Thanks to these assumptions, techniques based on machine learning can be used in many application cases. In this scope, we present popular methods for indexing multimedia data, like the ones based on the training of visual dictionaries. Then, we present supervised techniques that use labeled data to train and design retrieval components. We show how this last topic could benefit from many improvement from the machine learning community. Finally, this paper presents interesting perspective and new paradigms for multimedia retrieval based on machine learning.",Machine Learning for multimedia applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-13.pdf,2013,100.0,"Machine Learning and Content-Based Multimedia Retrieval This paper presents an overview of popular retrieval techniques based on machine learning for content based multimedia retrieval. Furthermore, we also propose to highlight current gaps and required improvement in this context. We first introduce common retrieval problems, and the usual models and assumptions made on multimedia data. Thanks to these assumptions, techniques based on machine learning can be used in many application cases. In this scope, we present popular methods for indexing multimedia data, like the ones based on the training of visual dictionaries. Then, we present supervised techniques that use labeled data to train and design retrieval components. We show how this last topic could benefit from many improvement from the machine learning community. Finally, this paper presents interesting perspective and new paradigms for multimedia retrieval based on machine learning."
Research directions in interpretable machine learning models,"Vanya Van Belle, Paulo Lisboa","1 - Department of Electrical Engineering (ESAT-SCD) KU Leuven/iMinds Future Health Department Kasteelpark Arenberg 10/2446 3001 Leuven Belgium
2 - School of Computing and Mathematical Sciences Dept of Mathematics and Statistics Liverpool John Moores University Byrom Street L3 3AF Liverpol UK","The theoretical novelty of many machine learning methods leading to high performing algorithms has been substantial. However, the black-box nature of much of this body of work has meant that the models are difficult to interpret, with the consequence that the significant developments in machine learning theory are not matched by their practical impact. This tutorial stresses the need for interpretation and outlines the current status and future directions of interpretability in machine learning models.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-14.pdf,2013,100.0,"Research directions in interpretable machine learning models The theoretical novelty of many machine learning methods leading to high performing algorithms has been substantial. However, the black-box nature of much of this body of work has meant that the models are difficult to interpret, with the consequence that the significant developments in machine learning theory are not matched by their practical impact. This tutorial stresses the need for interpretation and outlines the current status and future directions of interpretability in machine learning models."
Prior knowledge in an end-user trainable machine vision framework,"Klaas Dijkstra, Walter Jansen, Jaap Van De Loosdrecht",1 - Center of Expertise Computer Vision NHL University of Applied Sciences P.O. Box 1080 8900 CB Leeuwarden Netherlands,"The increasing popularity of machine vision based solutions in common applications calls for a structured approach for incorporating the end user's domain knowledge and limiting the solution's dependency on expert knowledge. We propose a framework facilitating optimized classification results and will show several approaches in which prior knowledge of the solution is captured in a neural network or in a geometric pattern matcher. The methodology is applied to disc print reading for antibiotic susceptibility testing by disc diffusion. Results show that increased prior knowledge produces better classifiers, and that more thorough optimization is required to increase the accuracy of classifiers which use less prior knowledge. * This research is part of a project for BD Kiestra. Experiments were performed using the vision operators, MLP, GA and BM from the software package VisionLab of Van de Loosdrecht Machine Vision BV.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-15.pdf,2013,100.0,"Prior knowledge in an end-user trainable machine vision framework The increasing popularity of machine vision based solutions in common applications calls for a structured approach for incorporating the end user's domain knowledge and limiting the solution's dependency on expert knowledge. We propose a framework facilitating optimized classification results and will show several approaches in which prior knowledge of the solution is captured in a neural network or in a geometric pattern matcher. The methodology is applied to disc print reading for antibiotic susceptibility testing by disc diffusion. Results show that increased prior knowledge produces better classifiers, and that more thorough optimization is required to increase the accuracy of classifiers which use less prior knowledge. * This research is part of a project for BD Kiestra. Experiments were performed using the vision operators, MLP, GA and BM from the software package VisionLab of Van de Loosdrecht Machine Vision BV."
Hierarchical Reinforcement Learning for Robot Navigation,"B Bischoff, D Nguyen-Tuong, I-H Lee, F Streichert, A Knoll","1 - Robert Bosch GmbH -Corporate Research Robert Bosch-Str. 2 71701 Schwieberdingen Germany
5 - -TU Munich -Robotics and Embedded Systems Boltzmannstr. 3 Garching at Munich 85748 Germany","For complex tasks, such as manipulation and robot navigation, reinforcement learning (RL) is well-known to be difficult due to the curse of dimensionality. To overcome this complexity and making RL feasible, hierarchical RL (HRL) has been suggested. The basic idea of HRL is to divide the original task into elementary subtasks, which can be learned using RL. In this paper, we propose a HRL architecture for learning robot's movements, e.g. robot navigation. The proposed HRL consists of two layers: (i) movement planning and (ii) movement execution. In the planning layer, e.g. generating navigation trajectories, discrete RL is employed while using movement primitives. Given the movement planning and corresponding primitives, the policy for the movement execution can be learned in the second layer using continuous RL. The proposed approach is implemented and evaluated on a mobile robot platform for a navigation task.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-19.pdf,2013,100.0,"Hierarchical Reinforcement Learning for Robot Navigation For complex tasks, such as manipulation and robot navigation, reinforcement learning (RL) is well-known to be difficult due to the curse of dimensionality. To overcome this complexity and making RL feasible, hierarchical RL (HRL) has been suggested. The basic idea of HRL is to divide the original task into elementary subtasks, which can be learned using RL. In this paper, we propose a HRL architecture for learning robot's movements, e.g. robot navigation. The proposed HRL consists of two layers: (i) movement planning and (ii) movement execution. In the planning layer, e.g. generating navigation trajectories, discrete RL is employed while using movement primitives. Given the movement planning and corresponding primitives, the policy for the movement execution can be learned in the second layer using continuous RL. The proposed approach is implemented and evaluated on a mobile robot platform for a navigation task."
Least-Squares Temporal Difference Learning based on Extreme Learning Machine,"Pablo Escandell-Montero, José Martínez-Martínez, José Martín-Guerrero, Emilio Soria-Olivas, Juan Gómez-Sanchis","1 - Intelligent Data Analysis Laboratory IDAL University of Valencia Av. de la Universidad, s/n 46100 Burjassot Valencia Spain
2 - Un Sistema Inteligente Adaptativo para la Gestión Eficiente de Energía en","This paper proposes a least-squares temporal difference (LSTD) algorithm based on extreme learning machine that uses a singlehidden layer feedforward network to approximate the value function. While LSTD is typically combined with local function approximators, the proposed approach uses a global approximator that allows better scalability properties. The results of the experiments carried out on four Markov decision processes show the usefulness of the proposed approach.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-73.pdf,2013,66.66666666666667,"Least-Squares Temporal Difference Learning based on Extreme Learning Machine This paper proposes a least-squares temporal difference (LSTD) algorithm based on extreme learning machine that uses a singlehidden layer feedforward network to approximate the value function. While LSTD is typically combined with local function approximators, the proposed approach uses a global approximator that allows better scalability properties. The results of the experiments carried out on four Markov decision processes show the usefulness of the proposed approach."
ONP-MF: An Orthogonal Nonnegative Matrix Factorization Algorithm with Application to Clustering,"Filippo Pompili, Nicolas Gillis, P.-A Absil, François Glineur","1 - Department of Electronic and Information Engineering University of Perugia Via G. Duranti 93 I-06125 Perugia Italy
2 - Université catholique de Louvain ICTEAM Institute B-1348 Louvain-la-Neuve Belgium
5 - Université catholique de Louvain CORE Voie du Roman Pays 34 B-1348 Louvain-la-Neuve Belgium","Given a nonnegative matrix M , the orthogonal nonnegative matrix factorization (ONMF) problem consists in finding a nonnegative matrix U and an orthogonal nonnegative matrix V such that the product UV is as close as possible to M . The importance of ONMF comes from its tight connection with data clustering. In this paper, we propose a new ONMF method, called ONP-MF, and we show that it performs in average better than other ONMF algorithms in terms of accuracy on several datasets in text clustering and hyperspectral unmixing.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-20.pdf,2013,100.0,"ONP-MF: An Orthogonal Nonnegative Matrix Factorization Algorithm with Application to Clustering Given a nonnegative matrix M , the orthogonal nonnegative matrix factorization (ONMF) problem consists in finding a nonnegative matrix U and an orthogonal nonnegative matrix V such that the product UV is as close as possible to M . The importance of ONMF comes from its tight connection with data clustering. In this paper, we propose a new ONMF method, called ONP-MF, and we show that it performs in average better than other ONMF algorithms in terms of accuracy on several datasets in text clustering and hyperspectral unmixing."
Multi-scale Support Vector Machine Optimization by Kernel Target-Alignment,"M Pérez-Ortiz, P Gutiérrez, J Sánchez-Monedero, C Hervás-Martínez",1 - Dept. of Computer Science University of Córdoba Numerical Analysis Rabanales Campus Albert Einstein building 14071 Córdoba Spain,"The problem considered is the optimization of a multi-scale kernel, where a different width is chosen for each feature. This idea has been barely studied in the literature, and through the use of evolutionary or gradient descent approaches, which explicitly train the learning machine and thereby incur high computacional cost. To cope with this limitation, the problem is explored by making use of an analytical methodology known as kernel-target alignment, where the kernel is optimized by aligning it to the so-called ideal kernel matrix. The results show that the proposal leads to better performance and simpler models at limited computational cost when applying the binary Support Vector Machine (SVM) paradigm.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-21.pdf,2013,100.0,"Multi-scale Support Vector Machine Optimization by Kernel Target-Alignment The problem considered is the optimization of a multi-scale kernel, where a different width is chosen for each feature. This idea has been barely studied in the literature, and through the use of evolutionary or gradient descent approaches, which explicitly train the learning machine and thereby incur high computacional cost. To cope with this limitation, the problem is explored by making use of an analytical methodology known as kernel-target alignment, where the kernel is optimized by aligning it to the so-called ideal kernel matrix. The results show that the proposal leads to better performance and simpler models at limited computational cost when applying the binary Support Vector Machine (SVM) paradigm."
B-bleaching : Agile Overtraining Avoidance in the WiSARD Weightless Neural Classifier,"Danilo Carvalho, Hugo Carneiro, Felipe França, Priscila Lima","1 - Universidade Federal do Rio de Janeiro -PESC/COPPE Rio de Janeiro Brazil
4 - Universidade Federal Rural do Rio de Janeiro -PPGMMC/DEMAT Seropédica Brazil","Weightless neural networks constitute a still not fully explored Machine Learning paradigm, even if its first model, WiSARD, is considered. Bleaching, an improvement on WiSARD's learning mechanism was recently proposed in order to avoid overtraining. Although presenting very good results in different application domains, the original sequential bleaching and its confidence modulation mechanisms still offer room for improvement. This paper presents a new variation of the bleaching mechanism and compares the three strategies performance on a complex domain, that of multilingual grammatical categorization. Experiments considered both number of iterations and accuracy. Results show that binary bleaching allows for a considerable improvement to number of iterations whilst not introducing loss of accuracy.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-22.pdf,2013,98.22485207100591,"B-bleaching : Agile Overtraining Avoidance in the WiSARD Weightless Neural Classifier Weightless neural networks constitute a still not fully explored Machine Learning paradigm, even if its first model, WiSARD, is considered. Bleaching, an improvement on WiSARD's learning mechanism was recently proposed in order to avoid overtraining. Although presenting very good results in different application domains, the original sequential bleaching and its confidence modulation mechanisms still offer room for improvement. This paper presents a new variation of the bleaching mechanism and compares the three strategies performance on a complex domain, that of multilingual grammatical categorization. Experiments considered both number of iterations and accuracy. Results show that binary bleaching allows for a considerable improvement to number of iterations whilst not introducing loss of accuracy."
Percolation model of axon guidance,"Gaetano Aiello, Valentino Romano",1 - Dipartimento di Fisica Viale delle Scienze Universita' di Palermo Ed. 18 90128 Palermo Italy,"In the developing brain neurons interconnect via the action of molecules that guide the axon to its targets, thus allowing the proper wiring scheme to emerge. It is not fully understood whether the underlying mechanism is wholly deterministic or not. The existence of ""choice-points"" and ""decision-regions"" suggests that options are available to the growth cone. The guidance mechanism is here simulated by equating the axonal trajectory to that of a trickle of ground water sipping through a bed of sand. Decision regions are implemented by assigning each site of the percolation lattice a set of probabilities ruling the possible moves.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-23.pdf,2013,100.0,"Percolation model of axon guidance In the developing brain neurons interconnect via the action of molecules that guide the axon to its targets, thus allowing the proper wiring scheme to emerge. It is not fully understood whether the underlying mechanism is wholly deterministic or not. The existence of ""choice-points"" and ""decision-regions"" suggests that options are available to the growth cone. The guidance mechanism is here simulated by equating the axonal trajectory to that of a trickle of ground water sipping through a bed of sand. Decision regions are implemented by assigning each site of the percolation lattice a set of probabilities ruling the possible moves."
Learning Control Under Uncertainty: A Probabilistic Value-Iteration Approach,"B Bischoff, D Nguyen-Tuong, H Markert, A Knoll","1 - Robert Bosch GmbH -Corporate Research Robert Bosch-Str. 2 71701 Schwieberdingen Germany
4 - -TU Munich -Robotics and Embedded Systems Boltzmannstr. 3 Garching at Munich 85748 Germany","In this paper, we introduce a probabilistic version of the wellstudied Value-Iteration approach, i.e. Probabilistic Value-Iteration (PVI). The PVI approach can handle continuous states and actions in an episodic Reinforcement Learning (RL) setting, while using Gaussian Processes to model the state uncertainties. We further show, how the approach can be efficiently realized making it suitable for learning with large data. The proposed PVI is evaluated on a benchmark problem, as well as on a real robot for learning a control task. A comparison of PVI with two state-ofthe-art RL algorithms shows that the proposed approach is competitive in performance while being efficient in learning.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-26.pdf,2013,60.526315789473685,"Learning Control Under Uncertainty: A Probabilistic Value-Iteration Approach In this paper, we introduce a probabilistic version of the wellstudied Value-Iteration approach, i.e. Probabilistic Value-Iteration (PVI). The PVI approach can handle continuous states and actions in an episodic Reinforcement Learning (RL) setting, while using Gaussian Processes to model the state uncertainties. We further show, how the approach can be efficiently realized making it suitable for learning with large data. The proposed PVI is evaluated on a benchmark problem, as well as on a real robot for learning a control task. A comparison of PVI with two state-ofthe-art RL algorithms shows that the proposed approach is competitive in performance while being efficient in learning."
Analysis of Synaptic Weight Distribution in an Izhikevich Network,"Li Guo, Zhijun Yang, Qingbao Zhu",1 - School of Computer Science Nanjing Normal University 210023 Nanjing China,"Izhikevich network is a relatively new neuronal network, which consists of cortical spiking model neurons with axonal conduction delays and spike-timingdependent plasticity (STDP) with hard bound adaptation. In this work, we use uniform and Gaussian distributions respectively to initialize the weights of all excitatory neurons. After the network undergoes a few minutes of STDP adaptation, we can see that the weights of all synapses in the network, for both initial weight distributions, form a bimodal distribution, and numerically the established distribution presents dynamic stability.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-27.pdf,2013,100.0,"Analysis of Synaptic Weight Distribution in an Izhikevich Network Izhikevich network is a relatively new neuronal network, which consists of cortical spiking model neurons with axonal conduction delays and spike-timingdependent plasticity (STDP) with hard bound adaptation. In this work, we use uniform and Gaussian distributions respectively to initialize the weights of all excitatory neurons. After the network undergoes a few minutes of STDP adaptation, we can see that the weights of all synapses in the network, for both initial weight distributions, form a bimodal distribution, and numerically the established distribution presents dynamic stability."
A Quotient Basis Kernel for the prediction of mortality in severe sepsis patients,"Vicent Ripoll, Enrique Romero, Juan Carlos Ruiz-Rodríguez, Alfredo Vellido","1 - -Llenguatges i Sistemes Informàtics Universitat Politècnica de Catalunya Edifici Omega, Campus Nord 08034 Barcelona Spain
3 - Critical Care Department Vall d'Hebron University Hospital
4 - Vall d'Hebron Research Institute UAB Barcelona Spain","In this paper, we describe a novel kernel for multinomial distributions, namely the Quotient Basis Kernel (QBK), which is based on a suitable reparametrization of the input space through algebraic geometry and statistics. The QBK is used here for data transformation prior to classification in a medical problem concerning the prediction of mortality in patients suffering severe sepsis. This is a common clinical syndrome, often treated at the Intensive Care Unit (ICU) in a time-critical context. Mortality prediction results with Support Vector Machines using QBK compare favorably with those obtained using alternative kernels and standard clinical procedures.",Developments in kernel design,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-29.pdf,2013,80.24691358024691,"A Quotient Basis Kernel for the prediction of mortality in severe sepsis patients In this paper, we describe a novel kernel for multinomial distributions, namely the Quotient Basis Kernel (QBK), which is based on a suitable reparametrization of the input space through algebraic geometry and statistics. The QBK is used here for data transformation prior to classification in a medical problem concerning the prediction of mortality in patients suffering severe sepsis. This is a common clinical syndrome, often treated at the Intensive Care Unit (ICU) in a time-critical context. Mortality prediction results with Support Vector Machines using QBK compare favorably with those obtained using alternative kernels and standard clinical procedures."
Learning Regression Models with Guaranteed Error Bounds,Clemens Otte,"1 - Siemens AG, Corporate Technology Otto-Hahn-Ring 6 81739 Munich Germany
2 - Work partially funded by German Federal Research Ministry BMBF grant ALICE 01 IB10003 A-C","The combination of a symbolic regression model with a residual Gaussian Process is proposed for providing an interpretable model with improved accuracy. While the learned symbolic model is highly interpretable the residual model usually is not. However, by limiting the output of the residual model to a defined range a worst-case guarantee can be given in the sense that the maximal deviation from the symbolic model is always below a defined limit. When ranking the accuracy and interpretability of several different approaches on the SARCOS data benchmark the proposed combination yields the best result.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-3.pdf,2013,74.54545454545455,"Learning Regression Models with Guaranteed Error Bounds The combination of a symbolic regression model with a residual Gaussian Process is proposed for providing an interpretable model with improved accuracy. While the learned symbolic model is highly interpretable the residual model usually is not. However, by limiting the output of the residual model to a defined range a worst-case guarantee can be given in the sense that the maximal deviation from the symbolic model is always below a defined limit. When ranking the accuracy and interpretability of several different approaches on the SARCOS data benchmark the proposed combination yields the best result."
Network community detection with edge classifiers trained on LFR graphs,"Twan Van Laarhoven, Elena Marchiori",1 - Department of Computer Science Radboud University Nijmegen The Netherlands,"Graphs generated using the Lancichinetti-Fortunato-Radicchi (LFR) model are widely used for assessing the performance of network community detection algorithms. This paper investigates an laternative use of LFR graphs: as training data for learning classifiers that discriminate between edges that are 'within' a community and 'between' network communities. The LFR generator has a parameter that controls the extent to which communities are mixed, and hence harder to detect. We show experimentally that a linear edge-wise weighted support vector machine classifier trained on a graph with more mixed communities also works well when tested on easier graph instances, while it achieves mixed performance on real-life networks, with a tendency towards finding many communities. * This work has been partially funded by the Netherlands Organization for Scientific Research (NWO) within the NWO project 612.066.927.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-33.pdf,2013,100.0,"Network community detection with edge classifiers trained on LFR graphs Graphs generated using the Lancichinetti-Fortunato-Radicchi (LFR) model are widely used for assessing the performance of network community detection algorithms. This paper investigates an laternative use of LFR graphs: as training data for learning classifiers that discriminate between edges that are 'within' a community and 'between' network communities. The LFR generator has a parameter that controls the extent to which communities are mixed, and hence harder to detect. We show experimentally that a linear edge-wise weighted support vector machine classifier trained on a graph with more mixed communities also works well when tested on easier graph instances, while it achieves mixed performance on real-life networks, with a tendency towards finding many communities. * This work has been partially funded by the Netherlands Organization for Scientific Research (NWO) within the NWO project 612.066.927."
Multi-view feature extraction for hyperspectral image classification,"Michele Volpi, Giona Matasci, Mikhail Kanevski, Devis Tuia","1 - Université de Lausanne -Centre de Recherche en Environnmenent Terrestre UNIL-Mouline 1015 Lausanne Switzerland
4 - Laboratoire des Systèmes d'Information Géographique -EPFL Ecole Polytechnique Fédérale de Lausanne 1015 Lausanne Switzerland","We study the multi-view feature extraction (MV-FE) framework for the classification of hyperspectral images acquired from airborne and spaceborne sensors. This type of data is naturally composed by distinct blocks of spectral channels, forming the hypercube. To reduce the dimensionality of the data by taking advantage of this particular structure, an unsupervised multi-view feature extraction method is applied prior to classification. First, a technique to automatically obtain the blocks, based on the global spectral correlation matrix, is applied. Then, the kernel canonical correlation analysis is performed in a multi-view setting (MV-kCCA) to find projections of the data blocks in a correlated subspace, gaining thus discriminant power. Experiments using the linear discriminant classifier (LDA) show the appropriateness of adopting a MV-FE approach.",Machine Learning Methods for Processing and Analysis of Hyperspectral Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-34.pdf,2013,100.0,"Multi-view feature extraction for hyperspectral image classification We study the multi-view feature extraction (MV-FE) framework for the classification of hyperspectral images acquired from airborne and spaceborne sensors. This type of data is naturally composed by distinct blocks of spectral channels, forming the hypercube. To reduce the dimensionality of the data by taking advantage of this particular structure, an unsupervised multi-view feature extraction method is applied prior to classification. First, a technique to automatically obtain the blocks, based on the global spectral correlation matrix, is applied. Then, the kernel canonical correlation analysis is performed in a multi-view setting (MV-kCCA) to find projections of the data blocks in a correlated subspace, gaining thus discriminant power. Experiments using the linear discriminant classifier (LDA) show the appropriateness of adopting a MV-FE approach."
Are Rosenblatt multilayer perceptrons more powerfull than sigmoidal multilayer perceptrons? From a counter example to a general result,J Barahona Da Fonseca,1 - Department of Electrical Engineering Faculty of Sciences and Technology New University of Lisbon 2829-516 Monte de Caparica Portugal,"In the eighties the problem of the lack of an efficient algorithm to train multilayer Rosenblatt perceptrons was solved by sigmoidal neural networks and backpropagation. But should we still try to find an efficient algorithm to train multilayer hardlimit neuronal networks, a task known as a NP-Complete problem? In this work we show that this would not be a waste of time by means of a counter example where a two layer Rosenblatt perceptron with 21 neurons showed much more computational power than a sigmoidal feedforward two layer neural network with 300 neurons trained by backpropagation for the same classification problem. We show why the synthesis of logical functions with threshold gates or hardlimit perceptrons is an active research area in VLSI design and nanotechnology and we review some of the methods to synthesize logical functions with a multilayer hardlimit perceptron and we propose the search for an efficient method to synthesize any classification problem with analogical inputs with a two layer hardlimit perceptron as a near future objective. Nevertheless we recognize that with hardlimit multilayer perceptrons we cannot approximate continuous functions as we can easily do with multilayer sigmoidal neural networks, with multilayer hardlimit perceptrons we can only solve any classification problem, as we plan to demonstrate in a near future.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-35.pdf,2013,100.0,"Are Rosenblatt multilayer perceptrons more powerfull than sigmoidal multilayer perceptrons? From a counter example to a general result In the eighties the problem of the lack of an efficient algorithm to train multilayer Rosenblatt perceptrons was solved by sigmoidal neural networks and backpropagation. But should we still try to find an efficient algorithm to train multilayer hardlimit neuronal networks, a task known as a NP-Complete problem? In this work we show that this would not be a waste of time by means of a counter example where a two layer Rosenblatt perceptron with 21 neurons showed much more computational power than a sigmoidal feedforward two layer neural network with 300 neurons trained by backpropagation for the same classification problem. We show why the synthesis of logical functions with threshold gates or hardlimit perceptrons is an active research area in VLSI design and nanotechnology and we review some of the methods to synthesize logical functions with a multilayer hardlimit perceptron and we propose the search for an efficient method to synthesize any classification problem with analogical inputs with a two layer hardlimit perceptron as a near future objective. Nevertheless we recognize that with hardlimit multilayer perceptrons we cannot approximate continuous functions as we can easily do with multilayer sigmoidal neural networks, with multilayer hardlimit perceptrons we can only solve any classification problem, as we plan to demonstrate in a near future."
Robust cartogram visualization of outliers in manifold learning,"Alessandra Tosi, Alfredo Vellido","1 - -Llenguatges i Sistemes Informàtics Universitat Politècnica de Catalunya Edifici Omega, Campus Nord 08034 Barcelona Spain","Most real data sets contain atypical observations, often referred to as outliers. Their presence may have a negative impact in data modeling using machine learning. This is particularly the case in data density estimation approaches. Manifold learning techniques provide low-dimensional data representations, often oriented towards visualization. The visualization provided by density estimation manifold learning methods can be compromised by the presence of outliers. Recently, a cartogram-based representation of model-generated distortion was presented for nonlinear dimensionality reduction. Here, we investigate the impact of outliers on this visualization when using manifold learning techniques that behave robustly in their presence.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-36.pdf,2013,100.0,"Robust cartogram visualization of outliers in manifold learning Most real data sets contain atypical observations, often referred to as outliers. Their presence may have a negative impact in data modeling using machine learning. This is particularly the case in data density estimation approaches. Manifold learning techniques provide low-dimensional data representations, often oriented towards visualization. The visualization provided by density estimation manifold learning methods can be compromised by the presence of outliers. Recently, a cartogram-based representation of model-generated distortion was presented for nonlinear dimensionality reduction. Here, we investigate the impact of outliers on this visualization when using manifold learning techniques that behave robustly in their presence."
Semi-Supervised Vector Quantization for proximity data,"Xibin Zhu, Frank-Michael Schleif, Barbara Hammer",1 - CITEC -Centre of Excellence Bielefeld University 33615 Bielefeld Germany,"Semi-supervised learning (SSL) is focused on learning from labeled and unlabeled data by incorporating structural and statistical information of the available unlabeled data. The amount of data is dramatically increasing, but few of them are fully labeled, due to cost and time constraints. This is even more challenging for non-vectorial, proximity data, given by pairwise proximity values. Only few methods provide SSL for this data, limited to positive-semi-definite (psd) data. They also lack interpretable models, which is a relevant aspect in life-sciences where most of these data are found. This paper provides a prototype based SSL approach for proximity data.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-38.pdf,2013,100.0,"Semi-Supervised Vector Quantization for proximity data Semi-supervised learning (SSL) is focused on learning from labeled and unlabeled data by incorporating structural and statistical information of the available unlabeled data. The amount of data is dramatically increasing, but few of them are fully labeled, due to cost and time constraints. This is even more challenging for non-vectorial, proximity data, given by pairwise proximity values. Only few methods provide SSL for this data, limited to positive-semi-definite (psd) data. They also lack interpretable models, which is a relevant aspect in life-sciences where most of these data are found. This paper provides a prototype based SSL approach for proximity data."
"Mixed Order Associative Networks for Function Approximation, Optimisation and Sampling","Kevin Swingler, Leslie Smith",1 - University of Stirling -Computing Science and Mathematics Stirling FK9 4LA Scotland,"A mixed order associative neural network with n neurons and a modified Hebbian learning rule can learn any function f : {−1, 1} n → R and reproduce its output as the network's energy function. The network weights are equal to Walsh coefficients, the fixed point attractors are local maxima in the function, and partial sums across the weights of the network calculate averages for hyperplanes through the function. If the network is trained on data sampled from a distribution, then marginal and conditional probability calculations may be made and samples from the distribution generated from the network. These qualities make the network ideal for optimisation fitness function modelling and make the relationships amongst variables explicit in a way that architectures such as the MLP do not.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-4.pdf,2013,75.5813953488372,"Mixed Order Associative Networks for Function Approximation, Optimisation and Sampling A mixed order associative neural network with n neurons and a modified Hebbian learning rule can learn any function f : {−1, 1} n → R and reproduce its output as the network's energy function. The network weights are equal to Walsh coefficients, the fixed point attractors are local maxima in the function, and partial sums across the weights of the network calculate averages for hyperplanes through the function. If the network is trained on data sampled from a distribution, then marginal and conditional probability calculations may be made and samples from the distribution generated from the network. These qualities make the network ideal for optimisation fitness function modelling and make the relationships amongst variables explicit in a way that architectures such as the MLP do not."
A Distributed Wrapper Approach for Feature Selection,"Verónica Bolón-Canedo, Noelia Sánchez-Maroño, Amparo Alonso-Betanzos",1 - Department of Computer Science University of A Coruña Campus de Elviña s/n 15071 -A Coruña Spain,"In recent years, distributed learning has been the focus of much attention due to the proliferation of big databases, usually distributed. In this context, machine learning can take advantage of feature selection methods to deal with these datasets of high dimensionality. However, the great majority of current feature selection algorithms are designed for centralized learning. To confront the problem of distributed feature selection, in this paper we propose a distributed wrapper approach. In this manner, the learning accuracy can be improved, as well as obtaining a reduction in the memory requirements and execution time. Four representative datasets were selected to test the approach, paving the way to its application over extremely-high data which prevented previously the use of wrapper approaches. * This research has been economically supported in part by the Secretaría de Estado de Investigación of the Spanish Government through the research projects TIN2009-10748 and TIN 2012-37954; and by the Consellería de Industria of the Xunta de Galicia through the research projects CN2011/007 and CN2012/211; all of them partially funded by FEDER funds of the European Union. V. Bolón-Canedo acknowledges the support of Xunta de Galicia under Plan I2C Grant Program.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-41.pdf,2013,82.6923076923077,"A Distributed Wrapper Approach for Feature Selection In recent years, distributed learning has been the focus of much attention due to the proliferation of big databases, usually distributed. In this context, machine learning can take advantage of feature selection methods to deal with these datasets of high dimensionality. However, the great majority of current feature selection algorithms are designed for centralized learning. To confront the problem of distributed feature selection, in this paper we propose a distributed wrapper approach. In this manner, the learning accuracy can be improved, as well as obtaining a reduction in the memory requirements and execution time. Four representative datasets were selected to test the approach, paving the way to its application over extremely-high data which prevented previously the use of wrapper approaches. * This research has been economically supported in part by the Secretaría de Estado de Investigación of the Spanish Government through the research projects TIN2009-10748 and TIN 2012-37954; and by the Consellería de Industria of the Xunta de Galicia through the research projects CN2011/007 and CN2012/211; all of them partially funded by FEDER funds of the European Union. V. Bolón-Canedo acknowledges the support of Xunta de Galicia under Plan I2C Grant Program."
Non-Euclidean Independent Component Analysis and Oja's Learning,"M Lange, M Biehl, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
2 - -University Groningen -J.-Bernoulli-Inst. of Mathematics and Computer Sciences Groningen The Netherlands","In the present contribution we tackle the problem of nonlinear independent component analysis by non-Euclidean Hebbian-like learning. Independent component analysis (ICA) and blind source separation originally were introduced as tools for the linear unmixing of the signals to detect the underlying sources. Hebbian methods became very popular and succesfully in this context. Many nonlinear ICA extensions are known. A promising strategy is the application of kernel mapping. Kernel mapping realizes an usually nonlinear but implicite data mapping of the data into a reproducing kernel Hilbert space. After that a linear demixing can be carried out there. However, explicit handling in this non-Euclidean kernel mapping space is impossible. We show in this paper an alternative using an isomorphic mapping space. In particular, we show that the idea of Hebbian-like learning of kernel ICA can be transferred to this non-Euclidean space realizing an non-Euclidean ICA.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-49,2013,62.295081967213115,"Non-Euclidean Independent Component Analysis and Oja's Learning In the present contribution we tackle the problem of nonlinear independent component analysis by non-Euclidean Hebbian-like learning. Independent component analysis (ICA) and blind source separation originally were introduced as tools for the linear unmixing of the signals to detect the underlying sources. Hebbian methods became very popular and succesfully in this context. Many nonlinear ICA extensions are known. A promising strategy is the application of kernel mapping. Kernel mapping realizes an usually nonlinear but implicite data mapping of the data into a reproducing kernel Hilbert space. After that a linear demixing can be carried out there. However, explicit handling in this non-Euclidean kernel mapping space is impossible. We show in this paper an alternative using an isomorphic mapping space. In particular, we show that the idea of Hebbian-like learning of kernel ICA can be transferred to this non-Euclidean space realizing an non-Euclidean ICA."
Temperature Forecast in Buildings Using Machine Learning Techniques,"Fernando Mateo, Juan Carrasco, Mónica Millán-Giraldo, Abderrahim Sellami, Pablo Escandell-Montero, José Martínez-Martínez, Emilio Soria-Olivas","1 - University of Valencia -Intelligent Data Analysis Laboratory Avda Universitat S/N 46100 Burjassot -Valencia Spain
4 - University Jaume I -Institute of New Imaging Technologies Av. Sos Baynat S/N 12071 -Castelló de la Plana Spain
9 - Spanish Ministerio de Economía y Competitividad
10 - Un Sistema Inteligente Adaptativo para la Gestión Eficiente de la Energía en Grandes Edificios","Energy efficiency in buildings requires having good prediction of the variables that define the power consumption in the building. Temperature is the most relevant of these variables because it affects the operation of the cooling systems in summer and the heating systems in winter, while being also the main variable that defines comfort. This paper presents the application of classical methods of time series forecasting, such as Autoregressive (AR), Multiple Linear Regression (MLR) and Robust MLR (RMLR) models, along with others derived from more complex machine learning techniques, including Multilayer Perceptron with Non-linear Autoregressive Exogenous (MLP-NARX) and Extreme Learning Machine (ELM), to forecast temperature in buildings. The results obtained in the temperature prediction of several rooms of a building show the goodness of machine learning methods as compared to traditional approaches.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-43.pdf,2013,100.0,"Temperature Forecast in Buildings Using Machine Learning Techniques Energy efficiency in buildings requires having good prediction of the variables that define the power consumption in the building. Temperature is the most relevant of these variables because it affects the operation of the cooling systems in summer and the heating systems in winter, while being also the main variable that defines comfort. This paper presents the application of classical methods of time series forecasting, such as Autoregressive (AR), Multiple Linear Regression (MLR) and Robust MLR (RMLR) models, along with others derived from more complex machine learning techniques, including Multilayer Perceptron with Non-linear Autoregressive Exogenous (MLP-NARX) and Extreme Learning Machine (ELM), to forecast temperature in buildings. The results obtained in the temperature prediction of several rooms of a building show the goodness of machine learning methods as compared to traditional approaches."
ManiSonS: A New Visualization Tool for Manifold Clustering,"José Martínez-Martínez, Pablo Escandell-Montero, José Martín-Guerrero, Joan Vila-Francés, Emilio Soria-Olivas","1 - Intelligent Data Analysis Laboratory IDAL
2 - University of Valencia -Electronic Engineering Department Av de la Universidad, s/n 46100 Burjassot Valencia Spain
3 - Spanish Ministerio de Economía y Competitividad
4 - with reference IPT Un Sistema Inteligente Adaptativo para la Gestión Eficiente de la Energía en Grandes Edificios 2011-0962-920000","Manifold learning is an important theme in machine learning. This paper proposes a new visualization approach to manifold clustering. The method is based on pie charts in order to obtain meaningful visualizations of the clustering results when applying a manifold technique. In addition to this, the proposed approach extracts all the existing relationships among the attributes of the different clusters and find the most important variables of the manifold in order to distinguish among the different clusters. The methodology is tested in one synthetic data set and one real data set. Achieved results show the suitability and usefulness of the proposed approach.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-44.pdf,2013,100.0,"ManiSonS: A New Visualization Tool for Manifold Clustering Manifold learning is an important theme in machine learning. This paper proposes a new visualization approach to manifold clustering. The method is based on pie charts in order to obtain meaningful visualizations of the clustering results when applying a manifold technique. In addition to this, the proposed approach extracts all the existing relationships among the attributes of the different clusters and find the most important variables of the manifold in order to distinguish among the different clusters. The methodology is tested in one synthetic data set and one real data set. Achieved results show the suitability and usefulness of the proposed approach."
Machine Learning Techniques for Short-Term Electric Power Demand Prediction,"Fernando Mateo, Juan Carrasco, Mónica Millán-Giraldo, Abderrahim Sellami, Pablo Escandell-Montero, José Martínez-Martínez, Emilio Soria-Olivas","1 - University of Valencia -Intelligent Data Analysis Laboratory Av. Universitat S/N 46100 Burjassot -Valencia Spain
4 - University Jaume I -Institute of New Imaging Technologies Av. Sos Baynat S/N 12071 -Castelló de la Plana Spain
9 - Spanish Ministerio de Economía y Competitividad
10 - Un Sistema Inteligente Adaptativo para la Gestión Eficiente de la Energía en Grandes Edificios","Since several years ago, power consumption forecast has attracted considerable attention from the scientific community. Although there exist several works that deal with this issue, it remains open. The good management of energy consumption in HVAC (Heating, Ventilation and Air Conditioning) systems for large households and public buildings may benefit from a sustainable development in terms of economy and environmental preservation. In this paper, several Machine Learning techniques are evaluated and compared with a linear technique (Robust Multiple Linear Regression) and a naïve method. All methods have been applied to five buildings of the University of León (Spain), the results indicate nonlinear techniques outperform the linear one in most scenarios.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-45.pdf,2013,100.0,"Machine Learning Techniques for Short-Term Electric Power Demand Prediction Since several years ago, power consumption forecast has attracted considerable attention from the scientific community. Although there exist several works that deal with this issue, it remains open. The good management of energy consumption in HVAC (Heating, Ventilation and Air Conditioning) systems for large households and public buildings may benefit from a sustainable development in terms of economy and environmental preservation. In this paper, several Machine Learning techniques are evaluated and compared with a linear technique (Robust Multiple Linear Regression) and a naïve method. All methods have been applied to five buildings of the University of León (Spain), the results indicate nonlinear techniques outperform the linear one in most scenarios."
Soft Rank Neighbor Embeddings,"Marc Strickert, Kerstin Bunte","1 - Philipps Universität Marburg -Computational Intelligence Group DE
2 - University of Bielefeld -CITEC Center of Excellence
3 - Department of Information and Computer Science Aalto University FI","Correlation-based multidimensional scaling is proposed for reconstructing pairwise dissimilarity or score relationships in a Euclidean space. Pearson correlation between pairs of objects in source and target space can be directly maximized by gradient methods, while gradient optimization of Spearman rank correlation profits from a numerically soft formulation introduced in this work. Scale and shift invariance properties of correlation help circumventing typical distance concentration problems.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-46.pdf,2013,72.41379310344827,"Soft Rank Neighbor Embeddings Correlation-based multidimensional scaling is proposed for reconstructing pairwise dissimilarity or score relationships in a Euclidean space. Pearson correlation between pairs of objects in source and target space can be directly maximized by gradient methods, while gradient optimization of Spearman rank correlation profits from a numerically soft formulation introduced in this work. Scale and shift invariance properties of correlation help circumventing typical distance concentration problems."
Error Entropy Criterion in Echo State Network Training,"Levy Boccato, Daniel Silva, Denis Fantinato, Kenji Filho, Rafael Ferrari, Romis Attux, Aline Neves, Jugurta Montalvão, João Marcos, Travassos Romano","1 - School of Electrical and Computer Engineering University of Campinas Av. Albert Einstein 400 13083-852 Campinas, São Paulo Brazil
7 - CECS -Federal University of ABC Av. dos Estados 5001, 09210-170 Santo André, São Paulo Brazil
8 - Department of Electrical Engineering Federal University of Sergipe Av. Marechal Rondon 49100-000 São Cristóvão, Sergipe Brazil","Echo state networks offer a promising possibility for an effective use of recurrent structures as the presence of feedback is accompanied with a relatively simple training process. However, such simplicity, which is obtained through the use of an adaptive linear readout that minimizes the mean-squared error, limits the capability of exploring the statistical information of the involved signals. In this work, we apply an informationtheoretic learning framework, based on the error entropy criterion, to the ESN training, in order to improve the performance of the neural model, whose advantages are analyzed in the context of supervised channel equalization problem.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-47.pdf,2013,74.07407407407408,"Error Entropy Criterion in Echo State Network Training Echo state networks offer a promising possibility for an effective use of recurrent structures as the presence of feedback is accompanied with a relatively simple training process. However, such simplicity, which is obtained through the use of an adaptive linear readout that minimizes the mean-squared error, limits the capability of exploring the statistical information of the involved signals. In this work, we apply an informationtheoretic learning framework, based on the error entropy criterion, to the ESN training, in order to improve the performance of the neural model, whose advantages are analyzed in the context of supervised channel equalization problem."
Automatic Singular Spectrum Analysis for Time-Series Decomposition,"A Álvarez-Meza, C Acosta-Medina, G Castellanos-Domínguez","1 - Signal Processing and Recognition Group Universidad Nacional de Colombia Campus La Nubia, km 7 vía al Magdalena Manizales Colombia","An automatic Singular Spectrum Analysis based methodology is proposed to decompose and reconstruct time-series. We suggest a clustering based procedure to identify the main dynamics of the input signal, by computing a subset of orthogonal basis using a power spectrum criterion. The subset of basis are represented by the Discrete Fourier Transform to infer basis vectors encoding similar data structures. Thus, it is possible to highlight hidden components into the signal. Our approach is tested over some synthetic and real-world datasets, showing that our algorithm is a good tool to decompose time-series. * Research carried out under grants provided by a PhD scholarship and by the project 111045426008 funded by Colciencias.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-48.pdf,2013,100.0,"Automatic Singular Spectrum Analysis for Time-Series Decomposition An automatic Singular Spectrum Analysis based methodology is proposed to decompose and reconstruct time-series. We suggest a clustering based procedure to identify the main dynamics of the input signal, by computing a subset of orthogonal basis using a power spectrum criterion. The subset of basis are represented by the Discrete Fourier Transform to infer basis vectors encoding similar data structures. Thus, it is possible to highlight hidden components into the signal. Our approach is tested over some synthetic and real-world datasets, showing that our algorithm is a good tool to decompose time-series. * Research carried out under grants provided by a PhD scholarship and by the project 111045426008 funded by Colciencias."
Efficient VLSI Architecture for Spike Sorting Based on Generalized Hebbian Algorithm,"Wen-Jyi Hwang, Hao Chen",1 - Department of Computer Science and Information Engineering National Taiwan Normal University 117 Taipei Taiwan,A novel hardware architecture for fast spike sorting is presented in this paper. The architecture is able to perform feature extraction based on the Generalized Hebbian Algorithm (GHA). The employment of GHA allows efficient computation of principal components for subsequent clustering and classification operations. The hardware implementations of GHA features high throughput and low area costs. The proposed architecture is implemented by Field Programmable Gate Array (FPGA). It is embedded in a System-On-Programmable-Chip(SOPC) platform for performance measurement. Experimental results show that the proposed architecture is an efficient spike sorting design for attaining low hardware resource utilization and high speed computation.,Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-5.pdf,2013,100.0,Efficient VLSI Architecture for Spike Sorting Based on Generalized Hebbian Algorithm A novel hardware architecture for fast spike sorting is presented in this paper. The architecture is able to perform feature extraction based on the Generalized Hebbian Algorithm (GHA). The employment of GHA allows efficient computation of principal components for subsequent clustering and classification operations. The hardware implementations of GHA features high throughput and low area costs. The proposed architecture is implemented by Field Programmable Gate Array (FPGA). It is embedded in a System-On-Programmable-Chip(SOPC) platform for performance measurement. Experimental results show that the proposed architecture is an efficient spike sorting design for attaining low hardware resource utilization and high speed computation.
Auto-Encoder Pre-Training of Segmented-Memory Recurrent Neural Networks,"Stefan Glüge, Ronald Böck, Andreas Wendemuth",1 - Faculty of Electrical Engineering and Information Technology Cognitive Systems Group Otto von Guericke University Magdeburg and Center for Behavioral Brain Science Universitätsplatz 2 39106 Magdeburg Germany,"The extended Backpropagation Through Time (eBPTT) learning algorithm for Segmented-Memory Recurrent Neural Networks (SMRNNs) yet lacks the ability to reliably learn long-term dependencies. The alternative learning algorithm, extended Real-Time Recurrent Learning (eRTRL), does not suffer this problem but is computational very intensive, such that it is impractical for the training of large networks. The positive results reported with the pre-training of deep neural networks give rise to the hope that SMRNNs could also benefit of a pre-training procedure. In this paper we introduce a layer-local pre-training procedure for SMRNNs. Using the information latching problem as benchmark task, the comparison of random initialised and pre-trained networks shows the beneficial effect of the unsupervised pre-training. It significantly improves the learning of long-term dependencies in the supervised eBPTT training.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-50.pdf,2013,84.50704225352112,"Auto-Encoder Pre-Training of Segmented-Memory Recurrent Neural Networks The extended Backpropagation Through Time (eBPTT) learning algorithm for Segmented-Memory Recurrent Neural Networks (SMRNNs) yet lacks the ability to reliably learn long-term dependencies. The alternative learning algorithm, extended Real-Time Recurrent Learning (eRTRL), does not suffer this problem but is computational very intensive, such that it is impractical for the training of large networks. The positive results reported with the pre-training of deep neural networks give rise to the hope that SMRNNs could also benefit of a pre-training procedure. In this paper we introduce a layer-local pre-training procedure for SMRNNs. Using the information latching problem as benchmark task, the comparison of random initialised and pre-trained networks shows the beneficial effect of the unsupervised pre-training. It significantly improves the learning of long-term dependencies in the supervised eBPTT training."
Optimization of Gaussian Process Hyperparameters using Rprop,"Manuel Blum, Martin Riedmiller",1 - Department of Computer Science University of Freiburg Freiburg Germany,"Gaussian processes are a powerful tool for non-parametric regression. Training can be realized by maximizing the likelihood of the data given the model. We show that Rprop, a fast and accurate gradient-based optimization technique originally designed for neural network learning, can outperform more elaborate unconstrained optimization methods on real world data sets, where it is able to converge more quickly and reliably to the optimal solution.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-51.pdf,2013,63.33333333333333,"Optimization of Gaussian Process Hyperparameters using Rprop Gaussian processes are a powerful tool for non-parametric regression. Training can be realized by maximizing the likelihood of the data given the model. We show that Rprop, a fast and accurate gradient-based optimization technique originally designed for neural network learning, can outperform more elaborate unconstrained optimization methods on real world data sets, where it is able to converge more quickly and reliably to the optimal solution."
Feature Selection for Footwear Shape Estimation,"Fernando Mateo, Mónica Millán-Giraldo, Juan Carrasco, Enrique Montiel, José Bernabeu, José Martín-Guerrero","1 - University of Valencia -Intelligent Data Analysis Laboratory Avda Universitat S/N 46100 Burjassot -Valencia Spain
4 - Instituto Tecnológico del Calzado y Conexas (INESCOP) Polígono Industrial Campo Alto 03600 Elda Spain","This study proposes feature selection techniques to obtain a set of significant foot anthropometric measurements that can assist custumers in the choice of footwear size and width. The results given by a number of methods are averaged to provide a reliable set of features. Several machine learning methods are used to evaluate the classification (for the width) and regression (for the size) accuracies before and after feature selection. The results prove the benefits of carrying out feature selection, especially for the shoe width.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-52.pdf,2013,100.0,"Feature Selection for Footwear Shape Estimation This study proposes feature selection techniques to obtain a set of significant foot anthropometric measurements that can assist custumers in the choice of footwear size and width. The results given by a number of methods are averaged to provide a reliable set of features. Several machine learning methods are used to evaluate the classification (for the width) and regression (for the size) accuracies before and after feature selection. The results prove the benefits of carrying out feature selection, especially for the shoe width."
Regularization in Relevance Learning Vector Quantization Using l 1 -Norms,"M Riedel, F Rossi, M Kästner, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
2 - University Paris Sorbonne Pantheon France
5 - Saxony Germany","We propose in this contribution a method for l1-regularization in prototype based relevance learning vector quantization (LVQ) for sparse relevance proles. Sparse relevance proles in hyperspectral data analysis fade down those spectral bands which are not necessary for classication. In particular, we consider the sparsity in the relevance prole enforced by LASSO optimization. The latter one is obtained by a gradient learning scheme using a dierentiable parametrized approximation of the l1-norm, which has an upper error bound. We extend this regularization idea also to the matrix learning variant of LVQ as the natural generalization of relevance learning. * M.R. and M.K. are supported by a grant of the ESF,",Machine Learning Methods for Processing and Analysis of Hyperspectral Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-54.pdf,2013,63.888888888888886,"Regularization in Relevance Learning Vector Quantization Using l 1 -Norms We propose in this contribution a method for l1-regularization in prototype based relevance learning vector quantization (LVQ) for sparse relevance proles. Sparse relevance proles in hyperspectral data analysis fade down those spectral bands which are not necessary for classication. In particular, we consider the sparsity in the relevance prole enforced by LASSO optimization. The latter one is obtained by a gradient learning scheme using a dierentiable parametrized approximation of the l1-norm, which has an upper error bound. We extend this regularization idea also to the matrix learning variant of LVQ as the natural generalization of relevance learning. * M.R. and M.K. are supported by a grant of the ESF,"
Frequency-Dependent Peak-Over-Threshold algorithm for fault detection in the spectral domain,"Aurélien Hazan, Kurosh Madani",1 - LISSI-Université Paris-Est Créteil IUT de Sénart-Fontainebleau 77567 Lieusaint France,"An original novelty detection algorithm in the Fourier domain, using extreme value theory (EVT) is considered in this article. Periodograms may be considered as frequency-dependent random variables, and this can be taken into account when designing statistical tests. Frequency-Dependent Peak-Over-Threshold (FDPOT) puts special emphasis on the frequency dependence of extreme value statistics, thanks to Vector Generalized Additive Models (VGAM) estimation. An application is discussed in the field of mechanical vibrations. It is first shown that performance increases compared to POT detection. Then FDPOT is compared to state-of-the-art algorithms such as KPCA.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-56.pdf,2013,100.0,"Frequency-Dependent Peak-Over-Threshold algorithm for fault detection in the spectral domain An original novelty detection algorithm in the Fourier domain, using extreme value theory (EVT) is considered in this article. Periodograms may be considered as frequency-dependent random variables, and this can be taken into account when designing statistical tests. Frequency-Dependent Peak-Over-Threshold (FDPOT) puts special emphasis on the frequency dependence of extreme value statistics, thanks to Vector Generalized Additive Models (VGAM) estimation. An application is discussed in the field of mechanical vibrations. It is first shown that performance increases compared to POT detection. Then FDPOT is compared to state-of-the-art algorithms such as KPCA."
A Heterogeneous Database for Movement Knowledge Extraction in Parkinson's Disease,"Albert Samà, Carlos Pérez, Daniel Rodríguez-Martin, Joan Cabestany, Juan Manuel, Moreno Aróstegui, Alejandro Rodríguez-Molinero","1 - Technical Research Centre for Dependency Care and Autonomous Living (CETpD) Rambla de l'Exposició 59-69 08800 Vilanova i la Geltrú Spain
6 - Electrical & Electronic Engineering Department NUI Galway (NUIG) Ireland","This paper presents the design and methodology used to create a heterogeneous database for knowledge movement extraction in Parkinson's Disease. This database is being constructed as part of REM-PARK project and is composed of movement measurements acquired from inertial sensors, standard medical scales as Unified Parkinson's Disease Rating Scale, and other information obtained from 90 Parkinson's Disease patients. The signals obtained will be used to create movement disorder detection algorithms using supervised learning techniques. The different sources of information and the need of labelled data pose many challenges which the methodology described in this paper addresses. Some preliminary data obtained are presented. * This work has been performed in the framework of the FP7 project REMPARK ICT-287677, which is funded by the European Community. The author(s) would like to acknowledge the contributions of their colleagues from REMPARK Consortium (http://www.rempark.eu) 413",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-57.pdf,2013,69.1358024691358,"A Heterogeneous Database for Movement Knowledge Extraction in Parkinson's Disease This paper presents the design and methodology used to create a heterogeneous database for knowledge movement extraction in Parkinson's Disease. This database is being constructed as part of REM-PARK project and is composed of movement measurements acquired from inertial sensors, standard medical scales as Unified Parkinson's Disease Rating Scale, and other information obtained from 90 Parkinson's Disease patients. The signals obtained will be used to create movement disorder detection algorithms using supervised learning techniques. The different sources of information and the need of labelled data pose many challenges which the methodology described in this paper addresses. Some preliminary data obtained are presented. * This work has been performed in the framework of the FP7 project REMPARK ICT-287677, which is funded by the European Community. The author(s) would like to acknowledge the contributions of their colleagues from REMPARK Consortium (http://www.rempark.eu) 413"
Evolutionary Computation based System Decomposition with Neural Networks,"Robert Kaltenhäuser, Erik Schaffernicht, Frank-Florian Steege, Horst-Michael Gross","1 - Neuroinformatics and Cognitive Robotics Lab -Ilmenau University of Technology
2 - Center of Applied Autonomous Sensor Systems Örebro University Sweden
4 - STEAG Powitec GmbH 45219 Essen-Kettwig Germany
6 - Helmholtzplatz 5 98693 Ilmenau Germany","We present an evolutionary approach to divide a complex control system into smaller sub-systems with the help of neural networks. Thereto, measured channels are partitioned into several disjunct sets, representing possible sub-problems, while the networks are used to assess the quality of the resulting decomposition. We show that this approach is well suited to calculate correct decompositions of complex control systems. Furthermore, the obtained neural networks are used to predict important process factors with considerable better approximation quality than monolithic approaches that have to deal with all input channels in parallel.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-58.pdf,2013,68.05555555555556,"Evolutionary Computation based System Decomposition with Neural Networks We present an evolutionary approach to divide a complex control system into smaller sub-systems with the help of neural networks. Thereto, measured channels are partitioned into several disjunct sets, representing possible sub-problems, while the networks are used to assess the quality of the resulting decomposition. We show that this approach is well suited to calculate correct decompositions of complex control systems. Furthermore, the obtained neural networks are used to predict important process factors with considerable better approximation quality than monolithic approaches that have to deal with all input channels in parallel."
Border Sensitive Fuzzy Vector Quantization in Semi-Supervised Learning,"Tina Geweniger, Marika Kästner, Thomas Villmann",1 - Computational Intelligence Group University of Applied Sciences Mittweida Technikumplatz 17 09648 Mittweida Germany,"We propose a semi-supervised fuzzy vector quantization method for the classification of incompletely labeled data. Since information contained within the structure of the data set should not be neglected, our method considers the whole data set during the learning process. In difference to known methods our approach uses neighborhood cooperativeness for stable prototype learning known from Neural Gas. Further improvement of the classification accuracy is achieved by including class border sensitivity inspired by Support Vector Machines again improved by neighborhood learning. 
 Motivation Supervised classification based on labeled data and unsupervised clustering based on unlabeled data are common tasks in the field of machine learning. There exist a variety of algorithms for either paradigm. Some famous clustering methods are c-Means, Self Organizing Maps (SOM), Neural Gas (NG), Affinity Propagation, and variants thereof to improve the performance, consider overlapping data (fuzziness), incorporate neighborhood relations or to attend to sparsity to name just a few. On the other hand there are classifiers like Learning Vector Quantizers (LVQ, GLVQ, RSLVQ etc.) or Nearest Prototype Classifiers (NPC, SNPC, FSNPC etc.) to solve classification problems. Obtaining labeled data sets often is a difficult and costly procedure requiring expert knowledge and -especially if the labelling has to be done manually -a considerable amount of time. Therefore, sometimes only a fraction of a data set is labeled impeding complete classification learning. To utilize the above mentioned methods for this kind of data, either the labels are neglected to do unsupervised clustering or the data set itself is reduced considering only labeled data samples for the classification. In either case, information is lost. For this reason several semi-supervised classification methods namely FLSOM and FLNG  [1]  have been developed for crisp data. These methods closely follow the standard SOM and NG procedures yet also take labeled data into consideration. Pedrycz proposed an alternative semi-supervised vector quantization scheme based on Fuzzy c-Means (FCM)  [2] , but also pays attention to the labeled data samples. For this partially supervised clustering the original FCM cost function is extended by an additional term expressing a level of coincidence between the FCM membership degrees and the expert provided class information  [3, 4] . This way the class information as well as the structure of the data inherent in the whole data set is taken into consideration. Further, special interest frequently is given to the knowledge about decision borders between classes. This problem is explicitly addressed in Support Vector Machine (SVM) learning, which determines so-called support vectors approximating and indicating the borders between the classes  [5, 6] . Recently, the idea",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-59.pdf,2013,85.71428571428572,"Border Sensitive Fuzzy Vector Quantization in Semi-Supervised Learning We propose a semi-supervised fuzzy vector quantization method for the classification of incompletely labeled data. Since information contained within the structure of the data set should not be neglected, our method considers the whole data set during the learning process. In difference to known methods our approach uses neighborhood cooperativeness for stable prototype learning known from Neural Gas. Further improvement of the classification accuracy is achieved by including class border sensitivity inspired by Support Vector Machines again improved by neighborhood learning. 
 Motivation Supervised classification based on labeled data and unsupervised clustering based on unlabeled data are common tasks in the field of machine learning. There exist a variety of algorithms for either paradigm. Some famous clustering methods are c-Means, Self Organizing Maps (SOM), Neural Gas (NG), Affinity Propagation, and variants thereof to improve the performance, consider overlapping data (fuzziness), incorporate neighborhood relations or to attend to sparsity to name just a few. On the other hand there are classifiers like Learning Vector Quantizers (LVQ, GLVQ, RSLVQ etc.) or Nearest Prototype Classifiers (NPC, SNPC, FSNPC etc.) to solve classification problems. Obtaining labeled data sets often is a difficult and costly procedure requiring expert knowledge and -especially if the labelling has to be done manually -a considerable amount of time. Therefore, sometimes only a fraction of a data set is labeled impeding complete classification learning. To utilize the above mentioned methods for this kind of data, either the labels are neglected to do unsupervised clustering or the data set itself is reduced considering only labeled data samples for the classification. In either case, information is lost. For this reason several semi-supervised classification methods namely FLSOM and FLNG  [1]  have been developed for crisp data. These methods closely follow the standard SOM and NG procedures yet also take labeled data into consideration. Pedrycz proposed an alternative semi-supervised vector quantization scheme based on Fuzzy c-Means (FCM)  [2] , but also pays attention to the labeled data samples. For this partially supervised clustering the original FCM cost function is extended by an additional term expressing a level of coincidence between the FCM membership degrees and the expert provided class information  [3, 4] . This way the class information as well as the structure of the data inherent in the whole data set is taken into consideration. Further, special interest frequently is given to the knowledge about decision borders between classes. This problem is explicitly addressed in Support Vector Machine (SVM) learning, which determines so-called support vectors approximating and indicating the borders between the classes  [5, 6] . Recently, the idea"
Unsupervised Non-Linear Neural Networks Capture Aspects of Floral Choice Behaviour,"Levente Orbán, Sylvain Chartier",1 - School of Psychology 136 University of Ottawa Jean-Jacques Lussier Pvt Ottawa Ont K1N 5N6 CANADA,"Two unsupervised neural networks were tested to understand the extent to which they capture elements of bumblebees' unlearned preferences towards flower-like visual properties. The networks, which are based on Independent Component Analysis and Feature-Extracting Bidirectional Associative Memory use images of test-patterns that are identical to ones used in behavioural studies. While both models show consistency with behavioural results, the ICA model matches behavioural results substantially better in terms of image reconstruction quality of radial and concentric patterns, and foliage background. Both models generated a novel prediction of an interaction between spatial frequency and symmetry. These results are interpreted to support the hypothesis that flower displays are adapted to pollinators' information processing constraints.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-6.pdf,2013,73.17073170731707,"Unsupervised Non-Linear Neural Networks Capture Aspects of Floral Choice Behaviour Two unsupervised neural networks were tested to understand the extent to which they capture elements of bumblebees' unlearned preferences towards flower-like visual properties. The networks, which are based on Independent Component Analysis and Feature-Extracting Bidirectional Associative Memory use images of test-patterns that are identical to ones used in behavioural studies. While both models show consistency with behavioural results, the ICA model matches behavioural results substantially better in terms of image reconstruction quality of radial and concentric patterns, and foliage background. Both models generated a novel prediction of an interaction between spatial frequency and symmetry. These results are interpreted to support the hypothesis that flower displays are adapted to pollinators' information processing constraints."
Novelty Detection in image recognition using IRF Neural Networks properties,"Philippe Smagghe, Jean-Luc Buessler, Jean-Philippe Urban",1 - Université de Haute-Alsace -MIPS 4 Frères Lumière 68093 Mulhouse France,"Image Receptive Fields Neural Network (IRF-NN) is a variant of feedforward multi-layer perceptrons adapted to image recognition. It shows very fast training as well as robust and accurate results on supervised classification tasks. This paper presents another property of IRF-NN: responses of trained networks can be analysed to detect unknown images. Several discriminative and efficient novelty criteria are introduced and tested successfully on the ALOI image dataset. A combination of novelty detection and object recognition is illustrated with a robust, pose invariant application of multi-object localization in various backgrounds.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-60.pdf,2013,86.66666666666667,"Novelty Detection in image recognition using IRF Neural Networks properties Image Receptive Fields Neural Network (IRF-NN) is a variant of feedforward multi-layer perceptrons adapted to image recognition. It shows very fast training as well as robust and accurate results on supervised classification tasks. This paper presents another property of IRF-NN: responses of trained networks can be analysed to detect unknown images. Several discriminative and efficient novelty criteria are introduced and tested successfully on the ALOI image dataset. A combination of novelty detection and object recognition is illustrated with a robust, pose invariant application of multi-object localization in various backgrounds."
DYNG: Dynamic Online Growing Neural Gas for Stream Data Classification,"Oliver Beyer, Philipp Cimiano",1 - Semantic Computing Group CITEC Bielefeld University,"In this paper we introduce Dynamic Online Growing Neural Gas (DYNG), a novel online stream data classification approach based on Online Growing Neural Gas (OGNG). DYNG exploits labelled data during processing to adapt the network structure as well as the speed of growth of the network to the requirements of the classification task. It thus speeds up learning for new classes/labels and dampens growth of the subnetwork representing the class once the class error converges. We show that this strategy is beneficial in life-long learning settings involving non-stationary data, giving DYNG an increased performance in highly non-stationary phases compared to OGNG.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-61.pdf,2013,65.71428571428571,"DYNG: Dynamic Online Growing Neural Gas for Stream Data Classification In this paper we introduce Dynamic Online Growing Neural Gas (DYNG), a novel online stream data classification approach based on Online Growing Neural Gas (OGNG). DYNG exploits labelled data during processing to adapt the network structure as well as the speed of growth of the network to the requirements of the classification task. It thus speeds up learning for new classes/labels and dampens growth of the subnetwork representing the class once the class error converges. We show that this strategy is beneficial in life-long learning settings involving non-stationary data, giving DYNG an increased performance in highly non-stationary phases compared to OGNG."
Dynamic Placement with Connectivity for RSNs based on a Primal-Dual Neural Network,"Rafael Carvalho, Lunlong Zhong, Felipe França, Felix Mora-Camino","1 - ENAC MAIAA Univ. de Toulouse F-31055 Toulouse France
2 - PESC COPPE Universidade Federal do Rio de Janeiro Rio de Janeiro Brazil","The present work deals with the dynamic placement of a set of pursuers and a set of relay devices so that the mean distance to a set of moving targets is minimized along a given period of time. The relay devices are here in charge of maintaining the communication between the pursuers. Moving targets, relay devices and pursuers are limited in their movements from one period to the next. The periodic problem is formulated as a linear quadratic programming model and a primal-dual neural network is proposed to solve from one stage to the next the current optimization problem. Moreover, the feasibility of the proposed approach is displayed through a numerical example.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-62.pdf,2013,100.0,"Dynamic Placement with Connectivity for RSNs based on a Primal-Dual Neural Network The present work deals with the dynamic placement of a set of pursuers and a set of relay devices so that the mean distance to a set of moving targets is minimized along a given period of time. The relay devices are here in charge of maintaining the communication between the pursuers. Moving targets, relay devices and pursuers are limited in their movements from one period to the next. The periodic problem is formulated as a linear quadratic programming model and a primal-dual neural network is proposed to solve from one stage to the next the current optimization problem. Moreover, the feasibility of the proposed approach is displayed through a numerical example."
Sparse approximations for kernel learning vector quantization,"Daniela Hofmann, Barbara Hammer",1 - CITEC center of excellence Bielefeld University Germany,"Various prototype based learning techniques have recently been extended to similarity data by means of kernelization. While stateof-the-art classification results can be achieved this way, kernelization loses one important property of prototype-based techniques: a representation of the solution in terms of few characteristic prototypes which can directly be inspected by experts. In this contribution, we introduce several different ways to obtain sparse representations for kernel learning vector quantization and compare its efficiency and performance in connection to the underlying data characteristics in diverse benchmark scenarios.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-63.pdf,2013,100.0,"Sparse approximations for kernel learning vector quantization Various prototype based learning techniques have recently been extended to similarity data by means of kernelization. While stateof-the-art classification results can be achieved this way, kernelization loses one important property of prototype-based techniques: a representation of the solution in terms of few characteristic prototypes which can directly be inspected by experts. In this contribution, we introduce several different ways to obtain sparse representations for kernel learning vector quantization and compare its efficiency and performance in connection to the underlying data characteristics in diverse benchmark scenarios."
Dimension Reduction for Individual ICA to Decompose FMRI during Real-World Experiences: Principal Component Analysis vs. Canonical Correlation Analysis,"Valeri Tsatsishvili, Fengyu Cong, Tuomas Puoliväli, Vinoo Alluri, Petri Toiviainen, Asoke Nandi, Elvira Brattico, Tapani Ristaniemi",1 - This work,"was financially supported by TEKES (Finland) under grant40334/10 ""Machine Learning for Future Music and Learning Technologies"". A.K. Nandi would like to thank TEKES for their award of the Finland Distinguished Professorship.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-64.pdf,2013,75.49668874172185,"Dimension Reduction for Individual ICA to Decompose FMRI during Real-World Experiences: Principal Component Analysis vs. Canonical Correlation Analysis was financially supported by TEKES (Finland) under grant40334/10 ""Machine Learning for Future Music and Learning Technologies"". A.K. Nandi would like to thank TEKES for their award of the Finland Distinguished Professorship."
Optimization by Variational Bounding,"Joe Staines, David Barber",1 - University College London -Computer Science Gower Street WC1E 6BT London United Kingdom,We discuss a general technique that forms a differentiable bound on non-differentiable objective functions by bounding the function optimum by its expectation with respect to a parametric variational distribution. We describe sufficient conditions for the bound to be convex with respect to the variational parameters. As example applications we consider variants of sparse linear regression and SVM training.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-65.pdf,2013,100.0,Optimization by Variational Bounding We discuss a general technique that forms a differentiable bound on non-differentiable objective functions by bounding the function optimum by its expectation with respect to a parametric variational distribution. We describe sufficient conditions for the bound to be convex with respect to the variational parameters. As example applications we consider variants of sparse linear regression and SVM training.
Sensitivity to parameter and data variations in dimensionality reduction techniques,"Francisco García-Fernández, Michel Verleysen, John Lee, Ignacio Díaz","1 - Department of Electrical Engineering Univ. of Oviedo Campus Viesques 33204 Gijón Spain
2 - Univ. Catholique de Louvain -Machine Learning Group ICTEAM ELEN -Place du Levant 3 1348 Louvain-la-Neuve Belgium
4 - Radiotherapy and Oncology Univ. Catholique de Louvain-Molecular Imaging IREC -Avenue Hippocrate 55 1200 Bruxelles Belgium","Dimensionality reduction techniques aim at representing highdimensional data in a meaningful and lower-dimensional space, improving the human comprehension and interpretation of data. In recent years, newer nonlinear techniques have been proposed in order to address the limitation of linear techniques. This paper presents a study of the stability of some of these dimensionality reduction techniques, analyzing their behavior under changes in the parameters and the data. The performances of these techniques are investigated on artificial datasets. The paper presents these results by identifying the weaknesses of each technique, and suggests some data-processing tasks to improve the stability.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-66.pdf,2013,100.0,"Sensitivity to parameter and data variations in dimensionality reduction techniques Dimensionality reduction techniques aim at representing highdimensional data in a meaningful and lower-dimensional space, improving the human comprehension and interpretation of data. In recent years, newer nonlinear techniques have been proposed in order to address the limitation of linear techniques. This paper presents a study of the stability of some of these dimensionality reduction techniques, analyzing their behavior under changes in the parameters and the data. The performances of these techniques are investigated on artificial datasets. The paper presents these results by identifying the weaknesses of each technique, and suggests some data-processing tasks to improve the stability."
Random Brains: An ensemble method for feature selection with neural networks,"Mark Embrechts, Jorge Santos, Jonathan Linton","1 - Rensselaer Polytechnic Institute -Dept. of Industrial and Systems Engineering Troy NY USA
2 - School of Engineering Polytechnic of Porto -Dept. of Mathematics, and Biomedical Engineering Institute Porto Portugal
3 - University of Ottawa Telfer School of Management","The purpose of this paper is to introduce and validate Random Brains, a novel artificial neural network based feature selection technique. Feature selection is widely used in high-dimensional data and it aims on removing irrelevant or redundant data, providing faster predictors without a significant decrease in model performance. Random Brains, inspired by Breiman's Random Forests, are bagged ensembles of predictive neural network models that use randomly selected subsets of features. This paper validates Random Brains on several classification and regression benchmark data sets by comparing its performance to similar models with features selected based on sensitivity analysis.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-67.pdf,2013,100.0,"Random Brains: An ensemble method for feature selection with neural networks The purpose of this paper is to introduce and validate Random Brains, a novel artificial neural network based feature selection technique. Feature selection is widely used in high-dimensional data and it aims on removing irrelevant or redundant data, providing faster predictors without a significant decrease in model performance. Random Brains, inspired by Breiman's Random Forests, are bagged ensembles of predictive neural network models that use randomly selected subsets of features. This paper validates Random Brains on several classification and regression benchmark data sets by comparing its performance to similar models with features selected based on sensitivity analysis."
An empirical analysis of reinforcement learning using design of experiments,"Christopher Gatti, Mark Embrechts, Jonathan Linton","1 - Rensselaer Polytechnic Institute -Dept. of Industrial and Systems Engineering Troy NY USA
3 - University of Ottawa Telfer School of Management","This study uses a design of experiments approach to understand the behavior of a neural network to learn the mountain car domain using the TD(λ) algorithm. A large experiment is first performed to characterize the probability of empirical convergence based on three parameters of the TD(λ) algorithm (λ, γ, ), and a logistic regression model is fitted to this data. A detailed analysis of the parameter subspace finds that, upon convergence, these parameters significant affect convergence speed and mean performance, though performance differences are minimal.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-68.pdf,2013,100.0,"An empirical analysis of reinforcement learning using design of experiments This study uses a design of experiments approach to understand the behavior of a neural network to learn the mountain car domain using the TD(λ) algorithm. A large experiment is first performed to characterize the probability of empirical convergence based on three parameters of the TD(λ) algorithm (λ, γ, ), and a logistic regression model is fitted to this data. A detailed analysis of the parameter subspace finds that, upon convergence, these parameters significant affect convergence speed and mean performance, though performance differences are minimal."
Hierarchical and multiscale Mean Shift segmentation of population grid,"Johanna Baro, Etienne Come, Patrice Aknin, Olivier Bonin","1 - Université Paris-Est IFSTTAR F-77447 Marne-la-Vallée GRETTIA France
2 - Université Paris-Est IFSTTAR F-77447 Marne-la-Vallée LVMT France",The Mean Shift (MS) algorithm allows to identify clusters that are catchment areas of modes of a probability density function (pdf). We propose to use a multiscale and hierarchical implementation of the algorithm to process grid data of population and identify automatically urban centers and their dependant sub-centers through scales. The multiscale structure is obtained by increasing iteratively the bandwidth of the kernel used to define the pdf on which the MS algorithm works. This will induce a hierarchical structure over clusters since modes will merge together when the bandwidth parameter increases.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-69.pdf,2013,99.29078014184397,Hierarchical and multiscale Mean Shift segmentation of population grid The Mean Shift (MS) algorithm allows to identify clusters that are catchment areas of modes of a probability density function (pdf). We propose to use a multiscale and hierarchical implementation of the algorithm to process grid data of population and identify automatically urban centers and their dependant sub-centers through scales. The multiscale structure is obtained by increasing iteratively the bandwidth of the kernel used to define the pdf on which the MS algorithm works. This will induce a hierarchical structure over clusters since modes will merge together when the bandwidth parameter increases.
Automated operational states detection for drilling systems control in critical conditions 53,"Galina Veres, Zoheir Sabeur",1 - IT Innovation Center -Faculty of Physical and Applied Sciences Gamma House University of Southampton Enterprise Road Southampton UK,"Critical events in industrial drilling should be overcome by engineers while they maintain safety and achieve their targeted operational drilling plans. Geophysical drilling requires maximum awareness of critical situations such as ""Kicks"", ""Fluid loss"" and ""Stuck pipe"". These may compromise safety and potentially halt operations with the need of staff rapid evacuations from rigs. In this paper, a robust method for the detection of operational states is proposed. Specifically, Echo State Networks (ESNs) were benchmarked and tested rigorously despite the challenging unbalanced datasets used for training. Nevertheless, these challenges were overcome and led to acceptable ESNs performances.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-7.pdf,2013,98.36065573770492,"Automated operational states detection for drilling systems control in critical conditions 53 Critical events in industrial drilling should be overcome by engineers while they maintain safety and achieve their targeted operational drilling plans. Geophysical drilling requires maximum awareness of critical situations such as ""Kicks"", ""Fluid loss"" and ""Stuck pipe"". These may compromise safety and potentially halt operations with the need of staff rapid evacuations from rigs. In this paper, a robust method for the detection of operational states is proposed. Specifically, Echo State Networks (ESNs) were benchmarked and tested rigorously despite the challenging unbalanced datasets used for training. Nevertheless, these challenges were overcome and led to acceptable ESNs performances."
Long term analysis of daily activities in a smart home,"Labiba Gillani Fahad, Arshad Ali, Muttukrishnan Rajarajan","1 - School of Engineering and Mathematical Sciences City University London United Kingdom
2 - School of Electrical Engineering and Computer Sciences National University of Science and Technology Pakistan","In this paper, we propose an approach to monitor the change in the daily routine of a person living in a smart home using the long term analysis of the activities performed, where daily routine is the group of activities that can be performed in a single day and are repeated over a period of time. In the proposed approach, first the activity recognition is performed, in which the newly detected activity instances are labeled using the probabilistic neural network learning model. Next, the daily routine of the occupant is analyzed by exploiting the group of activities of a day performed over a period of time. We apply K-means clustering to separate the normal routine from unusual and suspected routines. The proposed approach is validated on a publicly available Kasteren dataset.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-71.pdf,2013,98.11320754716981,"Long term analysis of daily activities in a smart home In this paper, we propose an approach to monitor the change in the daily routine of a person living in a smart home using the long term analysis of the activities performed, where daily routine is the group of activities that can be performed in a single day and are repeated over a period of time. In the proposed approach, first the activity recognition is performed, in which the newly detected activity instances are labeled using the probabilistic neural network learning model. Next, the daily routine of the occupant is analyzed by exploiting the group of activities of a day performed over a period of time. We apply K-means clustering to separate the normal routine from unusual and suspected routines. The proposed approach is validated on a publicly available Kasteren dataset."
Cost-Sensitive Cascade Graph Neural Networks,"Nguyen Van Tuc, Ah Tsoi, Markus Hagenbuchner","1 - University of Wollongong NSW 2500 Australia
2 - Macau University of Science and Technology Macau China","This paper introduces a novel cost sensitive weighted samples approach to a cascade of Graph Neural Networks for learning from imbalanced data in the graph structured input domain. This is shown to be very effective in addressing the effects of imbalanced data distribution on learning systems. The proposed idea is based on a weighting mechanism which forces the network to encode misclassified graphs (or nodes) more strongly. We evaluate the approach through an application to the well known Web spam detection problem, and demonstrate that the generalization performance is improved as a result. Indeed the results obtained reported in this paper are the best reported so far for both datasets.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-72.pdf,2013,72.72727272727273,"Cost-Sensitive Cascade Graph Neural Networks This paper introduces a novel cost sensitive weighted samples approach to a cascade of Graph Neural Networks for learning from imbalanced data in the graph structured input domain. This is shown to be very effective in addressing the effects of imbalanced data distribution on learning systems. The proposed idea is based on a weighting mechanism which forces the network to encode misclassified graphs (or nodes) more strongly. We evaluate the approach through an application to the well known Web spam detection problem, and demonstrate that the generalization performance is improved as a result. Indeed the results obtained reported in this paper are the best reported so far for both datasets."
Locally Weighted Least Squares Temporal Difference Learning,"Matthew Howard, Yoshihiko Nakamura",1 - Dept. Mechano-informatics University of Tokyo Japan,"This paper introduces locally weighted temporal difference learning for evaluation of a class of policies whose value function is nonlinear in the state. Least squares temporal difference learning is used for training local models according to a distance metric in state-space. Empirical evaluations are reported demonstrating learning performance on a number of strongly non-linear value functions, without the need for prior knowledge of features or a specific functional form.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-73.pdf,2013,100.0,"Locally Weighted Least Squares Temporal Difference Learning This paper introduces locally weighted temporal difference learning for evaluation of a class of policies whose value function is nonlinear in the state. Least squares temporal difference learning is used for training local models according to a distance metric in state-space. Empirical evaluations are reported demonstrating learning performance on a number of strongly non-linear value functions, without the need for prior knowledge of features or a specific functional form."
A Learning Machine with a Bit-Based Hypothesis Space,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella",1 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy,"We propose in this paper a bit-based classifier, picked from an hypothesis space described accordingly to sparsity and locality principles: the complexity of the corresponding space of functions is controlled through the number of bits needed to represent it, so that it will include the classifiers that will be most likely chosen by the learning procedure. Through an introductory example, we show how the number of bits, the sparsity of the representation and the local definition approach affect the complexity of the space of functions, where the final classifier is selected from.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-75.pdf,2013,100.0,"A Learning Machine with a Bit-Based Hypothesis Space We propose in this paper a bit-based classifier, picked from an hypothesis space described accordingly to sparsity and locality principles: the complexity of the corresponding space of functions is controlled through the number of bits needed to represent it, so that it will include the classifiers that will be most likely chosen by the learning procedure. Through an introductory example, we show how the number of bits, the sparsity of the representation and the local definition approach affect the complexity of the space of functions, where the final classifier is selected from."
Sensor Positioning for Activity Recognition Using Multiple Accelerometer-Based Sensors,"Lei Gao, Alan Bourke, John Nelson","1 - Ecole Polytechnique Fé dé rale de Lausanne-School of Engineering EPFL 2015 Lausanne Switzerland
2 - Department of Electronic and Computer Engineering Engineering Research Building University of Limerick University of Limerick Limerick Ireland","Physical activity has a positive impact on people's well-being and it can decrease the occurrence of chronic disease. To date, there has been a substantial amount of research studies, which focus on activity recognition using accelerometer and gyroscope-based sensors. However, the sensor position and the sensor combination, which have the best recognition performance with minimum sensor number, have not been investigated enough. This study proposes a method to adopt multiple accelerometer-based sensors on different body locations to investigate this problem. The dataset was collected in a study conducted by the eCAALYX project. Eight subjects were recruited to perform eight normal scripted activities in different life scenarios, and each repeated three times. Thus a total of 192 activities were recorded. The collected dataset was used to find the most suitable sensor-subset for recognizing Activities of Daily Living (ADLs).",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-76.pdf,2013,100.0,"Sensor Positioning for Activity Recognition Using Multiple Accelerometer-Based Sensors Physical activity has a positive impact on people's well-being and it can decrease the occurrence of chronic disease. To date, there has been a substantial amount of research studies, which focus on activity recognition using accelerometer and gyroscope-based sensors. However, the sensor position and the sensor combination, which have the best recognition performance with minimum sensor number, have not been investigated enough. This study proposes a method to adopt multiple accelerometer-based sensors on different body locations to investigate this problem. The dataset was collected in a study conducted by the eCAALYX project. Eight subjects were recruited to perform eight normal scripted activities in different life scenarios, and each repeated three times. Thus a total of 192 activities were recorded. The collected dataset was used to find the most suitable sensor-subset for recognizing Activities of Daily Living (ADLs)."
Risk Estimation and Feature Selection,"Gauthier Doquire, Benoît Frénay, Michel Verleysen",1 - ICTEAM/ELEN -Machine Learning Group Place du Levant 3 Université catholique de Louvain 1348 Louvain-la-Neuve Belgium,"For classification problems, the risk is often the criterion to be eventually minimised. It can thus naturally be used to assess the quality of feature subsets in feature selection. However, in practice, the probability of error is often unknown and must be estimated. Also, mutual information is often used as a criterion to assess the quality of feature subsets, since it can be seen as an imperfect proxy for the risk and can be reliably estimated. In this paper, two different ways to estimate the risk using the Kozachenko-Leonenko probability density estimator are proposed. The resulting estimators are compared on feature selection problems with a mutual information estimator based on the same density estimator. Along the line of our previous works, experiments show that using an estimator of either the risk or the mutual information give similar results.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-77.pdf,2013,100.0,"Risk Estimation and Feature Selection For classification problems, the risk is often the criterion to be eventually minimised. It can thus naturally be used to assess the quality of feature subsets in feature selection. However, in practice, the probability of error is often unknown and must be estimated. Also, mutual information is often used as a criterion to assess the quality of feature subsets, since it can be seen as an imperfect proxy for the risk and can be reliably estimated. In this paper, two different ways to estimate the risk using the Kozachenko-Leonenko probability density estimator are proposed. The resulting estimators are compared on feature selection problems with a mutual information estimator based on the same density estimator. Along the line of our previous works, experiments show that using an estimator of either the risk or the mutual information give similar results."
Ensembles of genetically trained artificial neural networks for survival analysis,"Jonas Kalderstam, Mattias Ohlsson",1 - Computational Biology and Biological Physics Department of Astronomy and Theoretical Physics Lund University Sweden,"We have developed a prognostic index model for survival data based on an ensemble of artificial neural networks that optimizes directly on the concordance index. Approximations of the c-index are avoided with the use of a genetic algorithm, which does not require gradient information. The model is compared with Cox proportional hazards (COX) and three support vector machine (SVM) models by Van Belle et al. [10]  on two clinical data sets, and only with COX on one artificial data set. Results indicate comparable performance to COX and SVM models on clinical data and superior performance compared to COX on non-linear data. 
 Methods To compare the performance of our model with existing results, we used clinical data sets from the study of Van Belle et al. [10]. A non-linear artificial data set was also used to illustrate the capabilities of the model and to compare with Cox proportional hazards (COX).",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-79.pdf,2013,100.0,"Ensembles of genetically trained artificial neural networks for survival analysis We have developed a prognostic index model for survival data based on an ensemble of artificial neural networks that optimizes directly on the concordance index. Approximations of the c-index are avoided with the use of a genetic algorithm, which does not require gradient information. The model is compared with Cox proportional hazards (COX) and three support vector machine (SVM) models by Van Belle et al. [10]  on two clinical data sets, and only with COX on one artificial data set. Results indicate comparable performance to COX and SVM models on clinical data and superior performance compared to COX on non-linear data. 
 Methods To compare the performance of our model with existing results, we used clinical data sets from the study of Van Belle et al. [10]. A non-linear artificial data set was also used to illustrate the capabilities of the model and to compare with Cox proportional hazards (COX)."
Decoding stimulation intensity from evoked ECoG activity using support vector regression,"Armin Walter, Georgios Naros, Martin Spüler, Alireza Gharabaghi, Wolfgang Rosenstiel, Martin Bogdan","1 - Department of Computer Engineering University of Tübingen Sand 13 72076 Tübingen Germany
2 - Werner Reichardt Centre for Integrative Neuroscience Department of Neurosurgery University Hospital Tübingen Otfried-Müller-Str. 45 72076 Tübingen -Germany
7 - Department of Computer Engineering University of Leipzig Augustusplatz 10 04109 Leipzig Germany","One of the unsolved problems of the application of cortical stimulation for therapeutic means is the selection of optimal stimulation parameters. Using support vector regression, we demonstrate that the intensity of single pulse electrical stimulation can be decoded from the waveform of the evoked electrocorticographic (ECoG) activity, even if intensities used for training and testing of the regression model are disjoint. This was most effective when stimulation was applied directly over the motor cortex, less so for premotor and sensory cortex. Thus, if the optimal shape of the evoked neural response to stimulation is known, a regression model trained on the responses to a small set of stimulation intensities could be sufficient to determine the optimal stimulation intensity.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-81.pdf,2013,100.0,"Decoding stimulation intensity from evoked ECoG activity using support vector regression One of the unsolved problems of the application of cortical stimulation for therapeutic means is the selection of optimal stimulation parameters. Using support vector regression, we demonstrate that the intensity of single pulse electrical stimulation can be decoded from the waveform of the evoked electrocorticographic (ECoG) activity, even if intensities used for training and testing of the regression model are disjoint. This was most effective when stimulation was applied directly over the motor cortex, less so for premotor and sensory cortex. Thus, if the optimal shape of the evoked neural response to stimulation is known, a regression model trained on the responses to a small set of stimulation intensities could be sufficient to determine the optimal stimulation intensity."
Activity Date Estimation in Timestamped Interaction Networks,"Fabrice Rossi, Pierre Latouche","1 - SAMM EA Université Paris 1 Panthéon-Sorbonne 90, rue de Tolbiac 4543, 75634 Paris cedex 13 France",We propose in this paper a new generative model for graphs that uses a latent space approach to explain timestamped interactions. The model is designed to provide global estimates of activity dates in historical networks where only the interaction dates between agents are known with reasonable precision. Experimental results show that the model provides better results than local averages in dense enough networks.,"Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-82.pdf,2013,100.0,Activity Date Estimation in Timestamped Interaction Networks We propose in this paper a new generative model for graphs that uses a latent space approach to explain timestamped interactions. The model is designed to provide global estimates of activity dates in historical networks where only the interaction dates between agents are known with reasonable precision. Experimental results show that the model provides better results than local averages in dense enough networks.
Visualizing pay-per-view television customers churn using cartograms and flow maps,"David García, Àngela Nebot, Alfredo Vellido",1 - Dept. de Llenguatges i Sistemes Informàtics Universitat Politècnica de Catalunya. Barcelona TECH Spain,"Media companies aggressively compete for their share of the pay-per-view television market. Such share can only be kept or improved by avoiding customer defection, or churn. The analysis of customers' data should provide insight into customers' behavior over time and help preventing churn. Data visualization can be part of this analysis. Here, a database of pay-per-view television customers is visualized using a nonlinear manifold learning model. This visualization is enhanced through, first, the reintroduction of the local nonlinear distortion using a cartogram technique and, second, the visualization of customer migrations using flow maps. Both techniques are inspired by geographical representation.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-83.pdf,2013,100.0,"Visualizing pay-per-view television customers churn using cartograms and flow maps Media companies aggressively compete for their share of the pay-per-view television market. Such share can only be kept or improved by avoiding customer defection, or churn. The analysis of customers' data should provide insight into customers' behavior over time and help preventing churn. Data visualization can be part of this analysis. Here, a database of pay-per-view television customers is visualized using a nonlinear manifold learning model. This visualization is enhanced through, first, the reintroduction of the local nonlinear distortion using a cartogram technique and, second, the visualization of customer migrations using flow maps. Both techniques are inspired by geographical representation."
A Public Domain Dataset for Human Activity Recognition Using Smartphones,"Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge Reyes-Ortiz","1 - University of Genova -DITEN Via Opera Pia 11A I-16145 Genova Italy
4 - Universitat Politècnica de Catalunya -CETpD Rambla de l'Exposició 59-69 08800 Vilanova i la Geltrú Spain","Human-centered computing is an emerging research field that aims to understand human behavior and integrate users and their social context with computer systems. One of the most recent, challenging and appealing applications in this framework consists in sensing human body motion using smartphones to gather context information about people actions. In this context, we describe in this work an Activity Recognition database, built from the recordings of 30 subjects doing Activities of Daily Living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors, which is released to public domain on a well-known on-line repository. Results, obtained on the dataset by exploiting a multiclass Support Vector Machine (SVM), are also acknowledged.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-84.pdf,2013,93.05555555555556,"A Public Domain Dataset for Human Activity Recognition Using Smartphones Human-centered computing is an emerging research field that aims to understand human behavior and integrate users and their social context with computer systems. One of the most recent, challenging and appealing applications in this framework consists in sensing human body motion using smartphones to gather context information about people actions. In this context, we describe in this work an Activity Recognition database, built from the recordings of 30 subjects doing Activities of Daily Living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors, which is released to public domain on a well-known on-line repository. Results, obtained on the dataset by exploiting a multiclass Support Vector Machine (SVM), are also acknowledged."
Visualizing Dependencies of Spectral Features using Mutual Information,"Andrej Gisbrecht, Yoan Miche, Barbara Hammer, Amaury Lendasse","1 - University of Bielefeld -CITEC Centre of Excellence Germany
2 - Department of Information and Computer Science Aalto University -School of Science Finland
5 - IKERBASQUE Basque Foundation for Science Spain","The curse of dimensionality leads to problems in machine learning when dealing with high dimensionality. This aspect is particularly pronounced if intrinsically infinite dimensionality is faced such as present for spectral or functional data. Feature selection constitutes one possibility to deal with this problem. Often, it relies on mutual information as an evaluation tool for the feature importance, however, it might be overlaid by intrinsic biases such as a high correlation of neighbored function values for functional data. In this paper we propose to assess feature correlations of spectral data by an overlay of prior dependencies due to the functional nature and its similarity as measured by mutual information, enabling a quick overall assessment of the relationships between features. By integrating the Nyström approximation technique, the usually time consuming step to compute all pairwise mutual informations can be reduced to only linear complexity in the number of features.",Sparsity for interpretation and visualization in inference models,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-86.pdf,2013,71.42857142857143,"Visualizing Dependencies of Spectral Features using Mutual Information The curse of dimensionality leads to problems in machine learning when dealing with high dimensionality. This aspect is particularly pronounced if intrinsically infinite dimensionality is faced such as present for spectral or functional data. Feature selection constitutes one possibility to deal with this problem. Often, it relies on mutual information as an evaluation tool for the feature importance, however, it might be overlaid by intrinsic biases such as a high correlation of neighbored function values for functional data. In this paper we propose to assess feature correlations of spectral data by an overlay of prior dependencies due to the functional nature and its similarity as measured by mutual information, enabling a quick overall assessment of the relationships between features. By integrating the Nyström approximation technique, the usually time consuming step to compute all pairwise mutual informations can be reduced to only linear complexity in the number of features."
Bayesian non Parametric Inference of Discrete Valued Networks,"Laetitia Nouedoui, Pierre Latouche","1 - SAMM EA Université Paris 1 Panthéon-Sorbonne 90 rue de Tolbiac 4543, 75634 Paris Cedex 13 France","We present a non parametric bayesian inference strategy to automatically infer the number of classes during the clustering process of a discrete valued random network. Our methodology is related to the Dirichlet process mixture models and inference is performed using a Blocked Gibbs sampling procedure. Using simulated data, we show that our approach improves over competitive variational inference clustering methods. Recently, [12]  proposed the Infinite Relational Model (IRM) as well as a Gibbs sampling procedure. Their approach for relation data is non parametric and allows the number of clusters to be estimated automatically while clustering",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-87.pdf,2013,80.32786885245902,"Bayesian non Parametric Inference of Discrete Valued Networks We present a non parametric bayesian inference strategy to automatically infer the number of classes during the clustering process of a discrete valued random network. Our methodology is related to the Dirichlet process mixture models and inference is performed using a Blocked Gibbs sampling procedure. Using simulated data, we show that our approach improves over competitive variational inference clustering methods. Recently, [12]  proposed the Infinite Relational Model (IRM) as well as a Gibbs sampling procedure. Their approach for relation data is non parametric and allows the number of clusters to be estimated automatically while clustering"
Multi-User Blood Alcohol Content Estimation in a Realistic Simulator using Artificial Neural Networks and Support Vector Machines,"Robinel Audrey, Puzenat Didier",1 - Laboratoire LAMIA Université Antilles Guyane Campus de Fouillole -Guadeloupe France,"We instrumented a realistic car simulator to extract low level data related to the driver's use of the vehicle controls. After proceeding these data, we generated features that were fed to a Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM). Our goal was determine if the driver's Blood Alcohol Content (BAC) was over 0.4g.l −1 or not, and even estimate the BAC value. Our device process the vehicle's controls data and then outputs the user BAC. We discuss the results of the prototype using the MLP and SVM algorithms in both single-user and multi-user context for detection of drunk drivers and estimation of the BAC value. The prototype performed better with single user base than with multi-user, and provided comparable results with MLP and SVM. This paper corrects a small error in our previous publication in ESANN '12 [3]. * This work has been funded by ApportMédia (www.apportmedia.fr), la Région Guadeloupe (www.cr-guadeloupe.fr), and the European Social Fund (ec.europa.eu/esf).",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-88.pdf,2013,75.1937984496124,"Multi-User Blood Alcohol Content Estimation in a Realistic Simulator using Artificial Neural Networks and Support Vector Machines We instrumented a realistic car simulator to extract low level data related to the driver's use of the vehicle controls. After proceeding these data, we generated features that were fed to a Multi-Layer Perceptron (MLP) and Support Vector Machines (SVM). Our goal was determine if the driver's Blood Alcohol Content (BAC) was over 0.4g.l −1 or not, and even estimate the BAC value. Our device process the vehicle's controls data and then outputs the user BAC. We discuss the results of the prototype using the MLP and SVM algorithms in both single-user and multi-user context for detection of drunk drivers and estimation of the BAC value. The prototype performed better with single user base than with multi-user, and provided comparable results with MLP and SVM. This paper corrects a small error in our previous publication in ESANN '12 [3]. * This work has been funded by ApportMédia (www.apportmedia.fr), la Région Guadeloupe (www.cr-guadeloupe.fr), and the European Social Fund (ec.europa.eu/esf)."
Delaunay simplices pruning based clustering,"Octavio Razafindramanana, Gilles Venturini","1 - Université François Rabelais de Tours -Laboratoire d'Informatique 64, avenue Jean Portalis -37200 Tours France","In this paper, we introduce a new clustering method using the Delaunay triangulation of a set of points as an input. The proposed method is based on pruning extra simplices of a triangulation according to a local heterogeneity measure, which we introduce here. This measure produces good clustering results as it yields to better inter-cluster simplices detection. The efficiency of the measure is evaluated on 2-D shape data set.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-89.pdf,2013,100.0,"Delaunay simplices pruning based clustering In this paper, we introduce a new clustering method using the Delaunay triangulation of a set of points as an input. The proposed method is based on pruning extra simplices of a triangulation according to a local heterogeneity measure, which we introduce here. This measure produces good clustering results as it yields to better inter-cluster simplices detection. The efficiency of the measure is evaluated on 2-D shape data set."
Processing Hyperspectral Data in Machine Learning,"T Villmann, M Kästner, A Backhaus, U Seiert","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
3 - Fraunhofer IFF Magdeburg -Dept. Biosystems Engineering Magdeburg Germany
5 - ESF Saxony Germany","The adaptive and automated analysis of hyperspectral data is mandatory in many areas of research such as physics, astronomy and geophysics, chemistry, bioinformatics, medicine, biochemistry, engineering, and others. Hyperspectra dier from other spectral data that a large frequency range is uniformly sampled. The resulting discretized spectra have a huge number of spectral bands and can be seen as good approximations of the underlying continuous spectra. The large dimensionality causes numerical diculties in ecient data analysis. Another aspect to deal with is that the amount of data may range from several billion samples in geophysics to only a few in medical applications. In consequence, dedicated machine learning algorithms and approaches are required for precise while ecient processing of hyperspectral data, which should include also expert knowledge of the application domain as well as mathematical properties of the hyperspectral data.",Machine Learning Methods for Processing and Analysis of Hyperspectral Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-9.pdf,2013,100.0,"Processing Hyperspectral Data in Machine Learning The adaptive and automated analysis of hyperspectral data is mandatory in many areas of research such as physics, astronomy and geophysics, chemistry, bioinformatics, medicine, biochemistry, engineering, and others. Hyperspectra dier from other spectral data that a large frequency range is uniformly sampled. The resulting discretized spectra have a huge number of spectral bands and can be seen as good approximations of the underlying continuous spectra. The large dimensionality causes numerical diculties in ecient data analysis. Another aspect to deal with is that the amount of data may range from several billion samples in geophysics to only a few in medical applications. In consequence, dedicated machine learning algorithms and approaches are required for precise while ecient processing of hyperspectral data, which should include also expert knowledge of the application domain as well as mathematical properties of the hyperspectral data."
Normalized Cuts Clustering with Prior Knowledge and a Pre-clustering Stage,"D Peluffo-Ordoñez, A Castro-Ospina, D Chavez-Chamorro, C Acosta-Medina, G Castellanos-Dominguez",1 - Signal Processing and Recognition Group Universidad Nacional de Colombia Manizales Colombia,"Clustering is of interest in cases when data are not labeled enough and a prior training stage is unfeasible. In particular, spectral clustering based on graph partitioning is of interest to solve problems with highly non-linearly separable classes. However, spectral methods, such as the well-known normalized cuts, involve the computation of eigenvectors that is a highly time-consuming task in case of large data. In this work, we propose an alternative to solve the normalized cuts problem for clustering, achieving same results as conventional spectral methods but spending less processing time. Our method consists of a heuristic search to find the best cluster binary indicator matrix, in such a way that each pair of nodes with greater similarity value are first grouped and the remaining nodes are clustered following a heuristic algorithm to search into the similarity-based representation space. The proposed method is tested over a public domain image data set. Results show that our method reaches comparable results with a lower computational cost.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-90.pdf,2013,68.91891891891892,"Normalized Cuts Clustering with Prior Knowledge and a Pre-clustering Stage Clustering is of interest in cases when data are not labeled enough and a prior training stage is unfeasible. In particular, spectral clustering based on graph partitioning is of interest to solve problems with highly non-linearly separable classes. However, spectral methods, such as the well-known normalized cuts, involve the computation of eigenvectors that is a highly time-consuming task in case of large data. In this work, we propose an alternative to solve the normalized cuts problem for clustering, achieving same results as conventional spectral methods but spending less processing time. Our method consists of a heuristic search to find the best cluster binary indicator matrix, in such a way that each pair of nodes with greater similarity value are first grouped and the remaining nodes are clustered following a heuristic algorithm to search into the similarity-based representation space. The proposed method is tested over a public domain image data set. Results show that our method reaches comparable results with a lower computational cost."
Binary Particle Swarm Optimisation With Improved Scaling Behaviour,Denise Gorse,1 - Dept of Computer Science University College London Gower Street WC1E 6BT London UK,A boolean particle swarm optimisation (PSO) algorithm is presented that builds on the strengths of earlier proposals but which by introducing a wholly random element into the search process shows greatly improved performance in higher dimensional search spaces in comparison also to the binary PSO algorithm of Kennedy and Eberhart.,"Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-91.pdf,2013,81.81818181818181,Binary Particle Swarm Optimisation With Improved Scaling Behaviour A boolean particle swarm optimisation (PSO) algorithm is presented that builds on the strengths of earlier proposals but which by introducing a wholly random element into the search process shows greatly improved performance in higher dimensional search spaces in comparison also to the binary PSO algorithm of Kennedy and Eberhart.
Detection and quantification in real-time polymerase chain reaction,"Abou Keita, Romain Hérault, Colas Calbrix, Stéphane Canu","1 - Normandie Univ France
2 - INSARouen, LITIS F-76801 Saint Etienne du Rouvray France
6 - Université de Rouen PRIMACEN F-76821 Mont Saint-Aignan France","The estimation of the concentration of an infectious agent in the environment is a key step to trigger an alert when there is a biological threat. This concentration can be obtained trough a quantitative polymerase chain reaction (qPCR). Nevertheless, standard real-time procedure do not address detection delay which is a main concern in alert triggering. Therefore, we propose a method based on Lasso regression and CUSUM change detection to accurately estimate the concentration while minimizing the detection delay. The trade-off between accuracy and delay can be managed through a parameter. We compare our results with those found by a standard method (threshold method) and promising results are obtained.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-92.pdf,2013,100.0,"Detection and quantification in real-time polymerase chain reaction The estimation of the concentration of an infectious agent in the environment is a key step to trigger an alert when there is a biological threat. This concentration can be obtained trough a quantitative polymerase chain reaction (qPCR). Nevertheless, standard real-time procedure do not address detection delay which is a main concern in alert triggering. Therefore, we propose a method based on Lasso regression and CUSUM change detection to accurately estimate the concentration while minimizing the detection delay. The trade-off between accuracy and delay can be managed through a parameter. We compare our results with those found by a standard method (threshold method) and promising results are obtained."
Ensembles for Continuous Actions in Reinforcement Learning,"Siegmund Duell, Steffen Udluft","1 - Siemens AG, Corporate Technology Learning Systems, Otto-Hahn-Ring 6 D-81739 Munich Germany
2 - Berlin University of Technology Machine Learning Marchstr. 23 D-10587 Berlin Germany","Data efficient reinforcement learning methods allow to optimize controllers (policies) for complex technical systems in a data-driven manner. Still, there is the risk that, when running such a policy on the real system, it performs considerably worse than expected. For policies with discrete actions it has been shown that this risk can be reduced considerably, when, instead of just using a single policy, that by chance might be inferior, a whole ensemble of policies is used to select the final policy by an aggregation like, e.g., majority voting. In this paper we extend the applicability of the ensemble approach to vector-valued, continuous actions.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-93.pdf,2013,100.0,"Ensembles for Continuous Actions in Reinforcement Learning Data efficient reinforcement learning methods allow to optimize controllers (policies) for complex technical systems in a data-driven manner. Still, there is the risk that, when running such a policy on the real system, it performs considerably worse than expected. For policies with discrete actions it has been shown that this risk can be reduced considerably, when, instead of just using a single policy, that by chance might be inferior, a whole ensemble of policies is used to select the final policy by an aggregation like, e.g., majority voting. In this paper we extend the applicability of the ensemble approach to vector-valued, continuous actions."
Perceptual Grouping through Competition in Coupled Oscillator Networks,"Martin Meier, Robert Haschke, Helge Ritter","1 - Bielefeld University 33615 Neuroinformatics Group, Bielefeld Germany","In this paper we present a novel approach to model perceptual grouping based on phase and frequency synchronization in a network of coupled Kuramoto oscillators. Transferring the grouping concept from the Competitive Layer Model (CLM) to a network of Kuramoto oscillators, we preserve the excellent grouping capabilities of the CLM, while dramatically improving the convergence rate, robustness to noise, and computational performance, which is verified in a series of artificial grouping experiments.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-94.pdf,2013,72.85714285714286,"Perceptual Grouping through Competition in Coupled Oscillator Networks In this paper we present a novel approach to model perceptual grouping based on phase and frequency synchronization in a network of coupled Kuramoto oscillators. Transferring the grouping concept from the Competitive Layer Model (CLM) to a network of Kuramoto oscillators, we preserve the excellent grouping capabilities of the CLM, while dramatically improving the convergence rate, robustness to noise, and computational performance, which is verified in a series of artificial grouping experiments."
Clustering the Vélib' origin-destinations flows by means of Poisson mixture models,"Andry Randriamanamihaga, Etienne Côme, Latifa Oukhellou, Gérard Govaert","1 - Université Paris-Est IFSTTAR F-93166 Noisy-Le-Grand GRETTIA France
4 - UMR CNRS 6599 Heudiasyc Université de Technologie de Compiègne
5 - Centre de Recherches de Royallieu F-60205 Compiègne Cedex France","Studies based on human mobility, including Bicycle Sharing System analysis, has expanded over the past few years. They aim to give insight of the underlying urban phenomena linked to city dynamics. This paper presents a generative count-series model using adapted Poisson mixtures to automatically analyse and find temporal-based clusters over the Vélib' origin-destination flow-data. Such an approach may provide latent factors that reveal how regions of different usage interact over the time. More generally, the proposed methodology can be used to cluster edges of temporal valued-graph with respect to their temporal profiles.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-95.pdf,2013,98.78048780487805,"Clustering the Vélib' origin-destinations flows by means of Poisson mixture models Studies based on human mobility, including Bicycle Sharing System analysis, has expanded over the past few years. They aim to give insight of the underlying urban phenomena linked to city dynamics. This paper presents a generative count-series model using adapted Poisson mixtures to automatically analyse and find temporal-based clusters over the Vélib' origin-destination flow-data. Such an approach may provide latent factors that reveal how regions of different usage interact over the time. More generally, the proposed methodology can be used to cluster edges of temporal valued-graph with respect to their temporal profiles."
Neurally Imprinted Stable Vector Fields,"Andre Lemme, Klaus Neumann, Felix Reinhart, Jochen Steil",1 - Faculty of Technology Institute for Cognition and Robotics (CoR-Lab) Bielefeld University Universitätsstr. 25 33615 Bielefeld Germany,"We present a novel learning scheme to imprint stable vector fields into Extreme Learning Machines (ELMs). The networks represent movements, where asymptotic stability is incorporated through constraints derived from Lyapunov stability theory. We show that our approach successfully performs stable and smooth point-to-point movements learned from human handwriting movements.",Regression and forecasting,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-98.pdf,2013,66.66666666666667,"Neurally Imprinted Stable Vector Fields We present a novel learning scheme to imprint stable vector fields into Extreme Learning Machines (ELMs). The networks represent movements, where asymptotic stability is incorporated through constraints derived from Lyapunov stability theory. We show that our approach successfully performs stable and smooth point-to-point movements learned from human handwriting movements."
Multiple Kernel Self-Organizing Maps,"Madalina Olteanu, Nathalie Villa-Vialaneix, Christine Cierco-Ayrolles","1 - SAMM Université Paris 1 Paris France
2 - Unité BIA INRA de Toulouse Auzeville France","In a number of real-life applications, the user is interested in analyzing several sources of information together: a graph combined with the additional information known on its nodes, numerical variables measured on individuals and factors describing these individuals... The combination of all sources of information can help him to understand the dataset in its whole better. The present article focuses on such an issue, by using self-organizing maps. The use a kernel version of the algorithm allows us to combine various types of information and automatically tune the data combination. This approach is illustrated on a simulated example.",Dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-99.pdf,2013,100.0,"Multiple Kernel Self-Organizing Maps In a number of real-life applications, the user is interested in analyzing several sources of information together: a graph combined with the additional information known on its nodes, numerical variables measured on individuals and factors describing these individuals... The combination of all sources of information can help him to understand the dataset in its whole better. The present article focuses on such an issue, by using self-organizing maps. The use a kernel version of the algorithm allows us to combine various types of information and automatically tune the data combination. This approach is illustrated on a simulated example."
A Comprehensive Introduction to Label Noise,"Benoît Frénay, Ata Kabán","1 - ICTEAM/ELEN -Machine Learning Group Place du Levant 3 Université catholique de Louvain 1348 Louvain-la-Neuve Belgium
2 - School of Computer Science University of Birmingham Edgbaston Birmingham B15 2TT United Kingdom","In classification, it is often difficult or expensive to obtain completely accurate and reliable labels. Indeed, labels may be polluted by label noise, due to e.g. insufficient information, expert mistakes, and encoding errors. The problem is that errors in training labels that are not properly handled may deteriorate the accuracy of subsequent predictions, among other effects. Many works have been devoted to label noise and this paper provides a concise and comprehensive introduction to this research topic. In particular, it reviews the types of label noise, their consequences and a number of state of the art approaches to deal with label noise. 
 Consequences of Label Noise Label noise is ubiquitous in real-word datasets, and has several consequences.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-10.pdf,2014,90.69767441860466,"A Comprehensive Introduction to Label Noise In classification, it is often difficult or expensive to obtain completely accurate and reliable labels. Indeed, labels may be polluted by label noise, due to e.g. insufficient information, expert mistakes, and encoding errors. The problem is that errors in training labels that are not properly handled may deteriorate the accuracy of subsequent predictions, among other effects. Many works have been devoted to label noise and this paper provides a concise and comprehensive introduction to this research topic. In particular, it reviews the types of label noise, their consequences and a number of state of the art approaches to deal with label noise. 
 Consequences of Label Noise Label noise is ubiquitous in real-word datasets, and has several consequences."
Modeling consumption of contents and advertising in online newspapers,"Iago Porto-Díaz, David Martínez-Rego, Oscar Fontenla-Romero, Amparo Alonso-Betanzos",1 - Department of Computer Science University of A Coruña Campus de Elviña s/n 15071 Coruña Spain,"This paper presents the design of a system for personalization of contents and advertising for readers of online newspapers. This software is conceived to work in a context of high network traffic with millions of URLs served each day. The model is divided into two subsystems. The first one takes care of the recommendation of news items. The mathematical model is based on the PageRank algorithm and considers several practical day-to-day scenarios. The second one, which is the subsystem of personalization of advertising, uses a Multinomial Logistic Regression model in order to predict categories of advertising for banners within the news content. The system has obtained practical satisfactory results using real data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-100.pdf,2014,100.0,"Modeling consumption of contents and advertising in online newspapers This paper presents the design of a system for personalization of contents and advertising for readers of online newspapers. This software is conceived to work in a context of high network traffic with millions of URLs served each day. The model is divided into two subsystems. The first one takes care of the recommendation of news items. The mathematical model is based on the PageRank algorithm and considers several practical day-to-day scenarios. The second one, which is the subsystem of personalization of advertising, uses a Multinomial Logistic Regression model in order to predict categories of advertising for banners within the news content. The system has obtained practical satisfactory results using real data."
The Sum-over-Forests Clustering,"Mathieu Senelle, Marco Saerens, François Fouss","1 - Université catholique de Louvain (UCL) Belgium
2 - LSM & ICTEAM","This work introduces a novel way to identify dense regions in a graph based on a mode-seeking clustering technique, relying on the Sum-Over-Forests (SoF) density index  [1]  (which can easily be computed in closed form through a simple matrix inversion) as a local density estimator. We rst identify the modes of the SoF density in the graph. Then, the nodes of the graph are assigned to the cluster corresponding to the nearest mode, according to a new kernel, also based on the SoF framework. Experiments on articial and real datasets show that the proposed index performs well in nodes clustering.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-104.pdf,2014,64.51612903225806,"The Sum-over-Forests Clustering This work introduces a novel way to identify dense regions in a graph based on a mode-seeking clustering technique, relying on the Sum-Over-Forests (SoF) density index  [1]  (which can easily be computed in closed form through a simple matrix inversion) as a local density estimator. We rst identify the modes of the SoF density in the graph. Then, the nodes of the graph are assigned to the cluster corresponding to the nearest mode, according to a new kernel, also based on the SoF framework. Experiments on articial and real datasets show that the proposed index performs well in nodes clustering."
Improved Cat Swarm Optimization Approach Applied to Reliability-Redundancy Problem,"Carlos Klein, ; Leandro, S Coelho, M Sant'anna, Roberto Freire, Viviana Mariani²","1 - Pontifical Catholic University of Parana (PUCPR) -Polytechnic School Industrial and Systems Engineering Graduate Program (PPGEPS) Rua Imaculada Conceição 1555. Postal Code 80215-901 Brazil
3 - Electrical Engineering Department Federal University of Parana (UFPR)","System reliability-redundancy optimization plays a vital role in realworld applications. Recently, a new meta-heuristic based on swarm intelligence called cat swarm optimization (CSO) algorithm has emerged. CSO is a stochastic optimization paradigm inspired from the natural behavior of cats. To enhance the performance of the CSO algorithm, an improved adaptive CSO (ICSO) algorithm is presented. Both CSO and ICSO approaches were applied to an overspeed protection system for a gas turbine, a benchmark in the reliability-redundancy mixed-integer optimization field. Better results obtained by the ICSO show that the algorithm can be an efficient alternative for solving reliability problems.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-106.pdf,2014,68.29268292682926,"Improved Cat Swarm Optimization Approach Applied to Reliability-Redundancy Problem System reliability-redundancy optimization plays a vital role in realworld applications. Recently, a new meta-heuristic based on swarm intelligence called cat swarm optimization (CSO) algorithm has emerged. CSO is a stochastic optimization paradigm inspired from the natural behavior of cats. To enhance the performance of the CSO algorithm, an improved adaptive CSO (ICSO) algorithm is presented. Both CSO and ICSO approaches were applied to an overspeed protection system for a gas turbine, a benchmark in the reliability-redundancy mixed-integer optimization field. Better results obtained by the ICSO show that the algorithm can be an efficient alternative for solving reliability problems."
Credit analysis with a clustering RAM-based neural classifier,"Douglas Cardoso, Danilo Carvalho, Daniel Alves, Diego Souza, Hugo Carneiro, Carlos Pedreira, Priscila Lima, Felipe França",1 - COPPE Universidade Federal do Rio de Janeiro 2 -iNCE BRAZIL,"Datasets with a large amount of noisy data are quite common in real-world classification problems. Robustness is an important characteristic of state-of-the-art classifiers that use error minimization techniques, thus requiring a long time to converge. This paper presents ClusWiSARD, a clustering customization of the WiSARD weightless neural network model, applied to credit analysis, a non-trivial real-world problem. Experimental evidence show that ClusWiSARD is very competitive with Support Vector Machine (SVM) w.r.t. accuracy, with the difference of being capable of online learning. Nonetheless, it outperforms SVM in both training time, being two orders of magnitude faster, and test time, being slightly faster.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-107.pdf,2014,100.0,"Credit analysis with a clustering RAM-based neural classifier Datasets with a large amount of noisy data are quite common in real-world classification problems. Robustness is an important characteristic of state-of-the-art classifiers that use error minimization techniques, thus requiring a long time to converge. This paper presents ClusWiSARD, a clustering customization of the WiSARD weightless neural network model, applied to credit analysis, a non-trivial real-world problem. Experimental evidence show that ClusWiSARD is very competitive with Support Vector Machine (SVM) w.r.t. accuracy, with the difference of being capable of online learning. Nonetheless, it outperforms SVM in both training time, being two orders of magnitude faster, and test time, being slightly faster."
An application of the temporal difference algorithm to the truck backer-upper problem,"Christopher Gatti, Mark Embrechts",1 - Rensselaer Polytechnic Institute Dept. of Industrial and Systems Engineering Troy NY USA,"We use a reinforcement learning approach to learn a real world control problem, the truck backer-upper problem. In this problem, a tractor trailer truck must be backed into a loading dock from an arbitrary location and orientation. Our approach uses the temporal difference algorithm using a neural network as the value function approximator. The novelty of this work is the simplicity of our implementation, yet it is able to successfully back the truck into the loading dock from random initial locations and orientations. 
 Truck-backer upper problem The goal of the truck backer-upper problem is to learn a control system that is capable of backing up a tractor trailer truck from an arbitrary location and",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-108.pdf,2014,100.0,"An application of the temporal difference algorithm to the truck backer-upper problem We use a reinforcement learning approach to learn a real world control problem, the truck backer-upper problem. In this problem, a tractor trailer truck must be backed into a loading dock from an arbitrary location and orientation. Our approach uses the temporal difference algorithm using a neural network as the value function approximator. The novelty of this work is the simplicity of our implementation, yet it is able to successfully back the truck into the loading dock from random initial locations and orientations. 
 Truck-backer upper problem The goal of the truck backer-upper problem is to learn a control system that is capable of backing up a tractor trailer truck from an arbitrary location and"
Recent Trends in Learning of structured and non-standard data,"Frank-Michael Schleif, Peter Tino, Thomas Villmann","1 - School of Computer Science University of Birmingham B15 2TT Edgbaston, Birmingham United Kingdom
3 - Department of Mathematics University of Applied Sciences Mittweida Germany","In many application domains data are not given in a classical vector space but occur in form of structural, sequential, relational characteristics or other non-standard formats. These data are often represented as graphs or by means of proximity matrices. Often these data sets are also huge and mathematically complicated to treat requesting for new efficient analysis algorithms which are the focus of this tutorial.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-11.pdf,2014,73.77049180327869,"Recent Trends in Learning of structured and non-standard data In many application domains data are not given in a classical vector space but occur in form of structural, sequential, relational characteristics or other non-standard formats. These data are often represented as graphs or by means of proximity matrices. Often these data sets are also huge and mathematically complicated to treat requesting for new efficient analysis algorithms which are the focus of this tutorial."
Spiking AGREL,"Davide Zambrano, Jaldert Rombouts, Cecilia Laschi, Sander Bohte","1 - The BioRobotics Institute Scuola Superiore Sant'Anna Italy
2 - CWI Amsterdam The Netherlands","Spiking neural networks are characterised by the spiking neuron models they use and how these spiking neurons process information communicated through spikes -the neural code. We demonstrate a plausible spiking neural network based on Spike Response Models and predictive spike-coding. When combined with a plausible reinforcement learning strategy -Attention Gated REinforcement Learning (AGREL), we show that such predictive spiking neural networks can compute non-linear mappings, including XOR. Our spiking AGREL achieves similar performance as standard AGREL, with much more efficient neural coding.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-112.pdf,2014,100.0,"Spiking AGREL Spiking neural networks are characterised by the spiking neuron models they use and how these spiking neurons process information communicated through spikes -the neural code. We demonstrate a plausible spiking neural network based on Spike Response Models and predictive spike-coding. When combined with a plausible reinforcement learning strategy -Attention Gated REinforcement Learning (AGREL), we show that such predictive spiking neural networks can compute non-linear mappings, including XOR. Our spiking AGREL achieves similar performance as standard AGREL, with much more efficient neural coding."
Improving the firefly algorithm through the Barnes-Hut tree code,Kiril Ralinovski,"1 - Institute of Technology -Machine Learning Group Marchstr. 23 Berlin, Berlin Germany","The firefly algorithm is a nature-inspired meta-heuristic algorithm that has a variety of applications such as multimodal optimization, clustering and finding good solutions for NP-hard problems. The original algorithm and modifications thereof have so far always calculated interactions between all fireflies individually which leads to a complexity of O(n 2 ). In this paper we present a novel approach to reduce the complexity to O(n • log(n)) in lower dimensions by using the Barnes-Hut tree code, which is used for n-body simulations in physics. This is possible due to the similar nature of both problems and requires only small modifications.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-114.pdf,2014,100.0,"Improving the firefly algorithm through the Barnes-Hut tree code The firefly algorithm is a nature-inspired meta-heuristic algorithm that has a variety of applications such as multimodal optimization, clustering and finding good solutions for NP-hard problems. The original algorithm and modifications thereof have so far always calculated interactions between all fireflies individually which leads to a complexity of O(n 2 ). In this paper we present a novel approach to reduce the complexity to O(n • log(n)) in lower dimensions by using the Barnes-Hut tree code, which is used for n-body simulations in physics. This is possible due to the similar nature of both problems and requires only small modifications."
Enhanced NMF initialization using a physical model for pollution source apportionment,"Marc Plouvin, Abdelhakim Limem, Matthieu Puigt, Gilles Delmaire, Gilles Roussel, Dominique Courcot","1 - LISIC ULCO Université Lille Nord de France FR-62228 Calais France
6 - UCEIV ULCO Université Lille Nord de France FR-59140 Dunkerque France","In a previous work, we proposed an informed Non-negative Matrix Factorization (NMF) with a specific parametrization which involves constraints about some known components of the factorization. In this paper we extend the above work by adding some information provided by a physical dispersion model. In particular, we derive a special structure of one of the factorizing matrices, which provides a better initialization of the NMF procedure. Experiments on simulated mixtures of particulate matter sources show that our new approach outperforms both our previous one and the state-of-the-art NMF methods.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-115.pdf,2014,100.0,"Enhanced NMF initialization using a physical model for pollution source apportionment In a previous work, we proposed an informed Non-negative Matrix Factorization (NMF) with a specific parametrization which involves constraints about some known components of the factorization. In this paper we extend the above work by adding some information provided by a physical dispersion model. In particular, we derive a special structure of one of the factorizing matrices, which provides a better initialization of the NMF procedure. Experiments on simulated mixtures of particulate matter sources show that our new approach outperforms both our previous one and the state-of-the-art NMF methods."
Self-organizing map for determination of goal candidates in mobile robot exploration,"Jan Faigl, Petr Vaněk, Miroslav Kulich","1 - Czech Technical University
2 - Department of Computer Science and Engineering Technická 2 166 27 Prague Czech Republic",This paper addresses a problem of determining goal candidates in the frontier-based mobile robot exploration. The proposed solution is based on self-organizing map for the traveling salesman problem with neighborhoods and it allows to study the exploration formulated as a problem of repeated coverage of the current frontiers where the minimal number of goal candidates is determined simultaneously together with the expected cost to visit the candidates. The early results enabled by the proposed self-organizing map-based solution indicate exploration improvement for the proposed problem formulation. The presented work demonstrates how neural network approach can provide interesting insights and ground for studying optimizations problems arising in robotics.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-116.pdf,2014,100.0,Self-organizing map for determination of goal candidates in mobile robot exploration This paper addresses a problem of determining goal candidates in the frontier-based mobile robot exploration. The proposed solution is based on self-organizing map for the traveling salesman problem with neighborhoods and it allows to study the exploration formulated as a problem of repeated coverage of the current frontiers where the minimal number of goal candidates is determined simultaneously together with the expected cost to visit the candidates. The early results enabled by the proposed self-organizing map-based solution indicate exploration improvement for the proposed problem formulation. The presented work demonstrates how neural network approach can provide interesting insights and ground for studying optimizations problems arising in robotics.
Misclassification of class C G-protein-coupled receptors as a label noise problem,"Caroline König, Alfredo Vellido, René Alquezar, Jesús Giraldo","1 - Dept. de Llenguatges i Sistemes Informàtics Univ. Politècnica de Catalunya C. Jordi Girona 1-3 08034 Barcelona Spain
4 - Institut de Robòtica i Informàtica Industrial CSIC-UPC Barcelona Spain
5 - Institut de Neurociències -Unitat de Bioestadística Univ. Autònoma de Barcelona Cerdanyola del Vallès (Barcelona) 08193 Spain","G-Protein-Coupled Receptors (GPCRs) are cell membrane proteins of relevance to biology and pharmacology. Their supervised classification in subtypes is hampered by label noise, which stems from a combination of expert knowledge limitations and lack of clear correspondence between labels and different representations of the protein primary sequences. In this brief study, we describe a systematic approach to the analysis of GPCR misclassifications using Support Vector Machines and use it to assist the discovery of database labeling quality problems and investigate the extent to which GPCR sequence physicochemical transformations reflect GPCR subtype labeling. The proposed approach could enable a filtering approach to the label noise problem.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-118.pdf,2014,100.0,"Misclassification of class C G-protein-coupled receptors as a label noise problem G-Protein-Coupled Receptors (GPCRs) are cell membrane proteins of relevance to biology and pharmacology. Their supervised classification in subtypes is hampered by label noise, which stems from a combination of expert knowledge limitations and lack of clear correspondence between labels and different representations of the protein primary sequences. In this brief study, we describe a systematic approach to the analysis of GPCR misclassifications using Support Vector Machines and use it to assist the discovery of database labeling quality problems and investigate the extent to which GPCR sequence physicochemical transformations reflect GPCR subtype labeling. The proposed approach could enable a filtering approach to the label noise problem."
Supporting GNG-based Clustering with Local Input Space Histograms,"Jochen Kerdels, Gabriele Peters",1 - University of Hagen -Chair of Human-Computer Interaction Universitätsstrasse 1 58097 Hagen Germany,This paper presents an extension to the growing neural gas (GNG) algorithm that allows to capture local characteristics of the input space. Using these characteristics clustering schemes based on the GNG network can be improved by discarding uncertain edges of the network and identifying edges that span discontinuous regions of input space. We applied the described approach to different two-dimensional data sets found in the literature and obtained comparable results.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-119.pdf,2014,60.0,Supporting GNG-based Clustering with Local Input Space Histograms This paper presents an extension to the growing neural gas (GNG) algorithm that allows to capture local characteristics of the input space. Using these characteristics clustering schemes based on the GNG network can be improved by discarding uncertain edges of the network and identifying edges that span discontinuous regions of input space. We applied the described approach to different two-dimensional data sets found in the literature and obtained comparable results.
Byte The Bullet: Learning on Real-World Computing Architectures,"Alessandro Ghio, Luca Oneto",1 - DITEN -University of Genoa Via Opera Pia 11A I-16145 Genoa Italy,"Fast, effective, and reliable models: these are the desiderata of every theorist and practitioner. Machine Learning (ML) algorithms, proposed in the last decades, proved to be effective and reliable in solving complex real-world problems, but they are usually designed without taking into account the underlying computing architecture. On the contrary, the effort of contemplating the exploited computing device is often motivated by application-specific and real-world requirements, such as the need to accelerate the learning process with dedicated/distributed hardware, or to foster energy-sparing requirements of applications based on mobile standalone devices. The ESANN 2014 Byte The Bullet: Learning on Real-World Computing Architectures special session has pooled a compilation of the most recent proposals in this area, by encouraging submissions related to the development and the application of fast, effective, reliable techniques, which consider possibilities, potentialities and constraints of real-world computing architectures as basic cornerstones and motivations.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-12.pdf,2014,100.0,"Byte The Bullet: Learning on Real-World Computing Architectures Fast, effective, and reliable models: these are the desiderata of every theorist and practitioner. Machine Learning (ML) algorithms, proposed in the last decades, proved to be effective and reliable in solving complex real-world problems, but they are usually designed without taking into account the underlying computing architecture. On the contrary, the effort of contemplating the exploited computing device is often motivated by application-specific and real-world requirements, such as the need to accelerate the learning process with dedicated/distributed hardware, or to foster energy-sparing requirements of applications based on mobile standalone devices. The ESANN 2014 Byte The Bullet: Learning on Real-World Computing Architectures special session has pooled a compilation of the most recent proposals in this area, by encouraging submissions related to the development and the application of fast, effective, reliable techniques, which consider possibilities, potentialities and constraints of real-world computing architectures as basic cornerstones and motivations."
Using Shannon Entropy as EEG Signal Feature for Fast Person Identification,"Dinh Phung, Dat Tran, Wanli Ma, Phuoc Nguyen, Tien Pham",1 - Faculty of ESTeM University of Canberra Australia,"Identification accuracy and speed are important factors in automatic person identification systems. In this paper, we propose a feature extraction method to extract brain wave features from different brain rhythms of electroencephalography (EEG) signal for the purpose of fast, yet accurate person identification. The proposed feature extraction method is based on the fact that EEG signal is complex, non-stationary, and non-linear. With this fact, non-linear analysis like entropy would be more appropriate. Shannon entropy (SE) based EEG features from alpha, beta, and gamma wave bands are extracted and evaluated for person identification. Experimental results show that SE features provide high person identification rates yet with a low feature dimension, thus better performance.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-121.pdf,2014,100.0,"Using Shannon Entropy as EEG Signal Feature for Fast Person Identification Identification accuracy and speed are important factors in automatic person identification systems. In this paper, we propose a feature extraction method to extract brain wave features from different brain rhythms of electroencephalography (EEG) signal for the purpose of fast, yet accurate person identification. The proposed feature extraction method is based on the fact that EEG signal is complex, non-stationary, and non-linear. With this fact, non-linear analysis like entropy would be more appropriate. Shannon entropy (SE) based EEG features from alpha, beta, and gamma wave bands are extracted and evaluated for person identification. Experimental results show that SE features provide high person identification rates yet with a low feature dimension, thus better performance."
Capturing confounding sources of variation in DNA methylation data by spatiotemporal independent component analysis,"Emilie Renard, Andrew Teschendorff, Pierre-Antoine Absil","1 - Université catholique de Louvain -ICTEAM Institute Avenue Georges Lemaître 4 B-1348 Louvain-la-Neuve Belgium
2 - University College London -Cancer Institute 72 Huntley Street WC1E 6BT London United Kingdom","Confounding sources of variation, which are often either unknown or known with error, are widespread in genomic datasets, and failing to adjust for them may adversely impact statistical inference. In this context, we propose a ""spatiotemporal"" independent component analysis method that possesses a novel invariance property, and we show that that spatiotemporal aspect may increase the ability of the method to model confounding sources of variation. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-123.pdf,2014,100.0,"Capturing confounding sources of variation in DNA methylation data by spatiotemporal independent component analysis Confounding sources of variation, which are often either unknown or known with error, are widespread in genomic datasets, and failing to adjust for them may adversely impact statistical inference. In this context, we propose a ""spatiotemporal"" independent component analysis method that possesses a novel invariance property, and we show that that spatiotemporal aspect may increase the ability of the method to model confounding sources of variation. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office."
An Optimized Learning Algorithm Based on Linear Filters Suitable for Hardware implemented Self-Organizing Maps,"Marta Kolasa, Rafal Dlugosz, Tomasz Talaska, Witold Pedrycz","1 - Faculty of Telecommunication and Electrical Engineering University of Technology and Life Sciences ul Kaliskiego 7 85-796 Bydgoszcz Poland
3 - -Institute of Microengineering Swiss Federal Institute of Technology in Lausanne Rue de la Maladière 71B CH-2002 Neuchâtel Switzerland
5 - Department of Electrical and Computer Engineering University of Alberta ECERF 9107 -116, T6G 2V4 Street, Edmonton AB Canada","In this study, we present a fast and energy efficient learning algorithm suitable for Self-Organizing Maps (SOMs) realized in hardware. The proposed algorithm is an extension of the classical algorithm used in Kohonen SOM. It is based on the observation that the quantization error that is a typical quality measure of the learning process, does not decrease linearly along the learning process. One can observe the phases of the increased 'activity', during which the quantization error rapidly decreases, followed by 'stagnation' phases, during which its values are almost the same. The activity phases occur just after decreasing the neighborhood radius, R. A set of finite impulse response (FIR) filters is used to detect both phases. This enables an automatic switching the radius R to a smaller value that shorts a given stagnation phase and starts a new activity phase. Comprehensive investigations carried out by means of the software model of the SOM show that the learning process can be shorten even by 80-95% that allows for reduction of energy consumption even by 70-90%.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-125.pdf,2014,100.0,"An Optimized Learning Algorithm Based on Linear Filters Suitable for Hardware implemented Self-Organizing Maps In this study, we present a fast and energy efficient learning algorithm suitable for Self-Organizing Maps (SOMs) realized in hardware. The proposed algorithm is an extension of the classical algorithm used in Kohonen SOM. It is based on the observation that the quantization error that is a typical quality measure of the learning process, does not decrease linearly along the learning process. One can observe the phases of the increased 'activity', during which the quantization error rapidly decreases, followed by 'stagnation' phases, during which its values are almost the same. The activity phases occur just after decreasing the neighborhood radius, R. A set of finite impulse response (FIR) filters is used to detect both phases. This enables an automatic switching the radius R to a smaller value that shorts a given stagnation phase and starts a new activity phase. Comprehensive investigations carried out by means of the software model of the SOM show that the learning process can be shorten even by 80-95% that allows for reduction of energy consumption even by 70-90%."
Towards an effective multi-map self organizing recurrent neural network,"Denis Baheux, Jérémy Fix, Hervé Frezza-Buet","1 - Supelec -MaLIS team UMI 2958 Georgia Tech CNRS
2 - Edouard Belin 57070 METZ France",This paper presents a multi-map joint self-organizing architecture able to represent non-markovian temporal sequences. The proposed architecture is inspired by previous works based on dynamic neural fields. It provides a faster and easier to handle architecture making it easier to scale to higher dimensional machine learning problems.,Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-126.pdf,2014,98.61111111111111,Towards an effective multi-map self organizing recurrent neural network This paper presents a multi-map joint self-organizing architecture able to represent non-markovian temporal sequences. The proposed architecture is inspired by previous works based on dynamic neural fields. It provides a faster and easier to handle architecture making it easier to scale to higher dimensional machine learning problems.
Ensembles of Extreme Learning Machine Networks for Value Prediction,"Pablo Escandell-Montero, José Martínez-Martínez, Emilio Soria-Olivas, Joan Vila-Francés, José Martín-Guerrero","1 - Intelligent Data Analysis Laboratory IDAL University of Valencia Av. de la Universidad, s/n 46100 Burjassot Valencia Spain","Value prediction is an important subproblem of several reinforcement learning (RL) algorithms. In a previous work, it has been shown that the combination of least-squares temporal-difference learning with ELM (extreme learning machine) networks is a powerful method for value prediction in continuous-state problems. This work proposes the use of ensembles to improve the approximation capabilities of ELM networks in the context of RL.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-127.pdf,2014,80.59701492537313,"Ensembles of Extreme Learning Machine Networks for Value Prediction Value prediction is an important subproblem of several reinforcement learning (RL) algorithms. In a previous work, it has been shown that the combination of least-squares temporal-difference learning with ELM (extreme learning machine) networks is a powerful method for value prediction in continuous-state problems. This work proposes the use of ensembles to improve the approximation capabilities of ELM networks in the context of RL."
Selective Neural Network Ensembles in Reinforcement Learning,"Stefan Faußer, Friedhelm Schwenker",1 - University of Ulm -Institute of Neural Information Processing 89069 Ulm Germany,"Ensemble models can achieve more accurate predictions than single learners. Selective ensembles further improve the predictions by selecting an informative subset of the full ensemble. We consider reinforcement learning ensembles, where the members are neural networks. In this context we study a new algorithm for ensemble subset selection in reinforcement learning scenarios. The aim of the proposed learning strategy is to minimize the Bellman errors of the collected states. In the empirical evaluation, two benchmark applications with large state spaces have been considered, namely SZ-Tetris and generalized maze. Here, our selective ensemble algorithm significantly outperforms other approaches.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-128.pdf,2014,100.0,"Selective Neural Network Ensembles in Reinforcement Learning Ensemble models can achieve more accurate predictions than single learners. Selective ensembles further improve the predictions by selecting an informative subset of the full ensemble. We consider reinforcement learning ensembles, where the members are neural networks. In this context we study a new algorithm for ensemble subset selection in reinforcement learning scenarios. The aim of the proposed learning strategy is to minimize the Bellman errors of the collected states. In the empirical evaluation, two benchmark applications with large state spaces have been considered, namely SZ-Tetris and generalized maze. Here, our selective ensemble algorithm significantly outperforms other approaches."
Easy multiple kernel learning,"Fabio Aiolli, Michele Donini",1 - Department of Mathematics Via Trieste University of Padova 63 35121 Padova Italy,"The goal of Multiple Kernel Learning (MKL) is to combine kernels derived from multiple sources in a data-driven way with the aim to enhance the accuracy of a kernel based machine. In this paper, we propose a time and space efficient MKL algorithm that can easily cope with hundreds of thousands of kernels and more. We compared our algorithm with other baselines plus three state-of-the-art MKL methods showing that our approach is often superior.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-129.pdf,2014,100.0,"Easy multiple kernel learning The goal of Multiple Kernel Learning (MKL) is to combine kernels derived from multiple sources in a data-driven way with the aim to enhance the accuracy of a kernel based machine. In this paper, we propose a time and space efficient MKL algorithm that can easily cope with hundreds of thousands of kernels and more. We compared our algorithm with other baselines plus three state-of-the-art MKL methods showing that our approach is often superior."
Spiking Neural Networks: Principles and Challenges,"André Grüning, Sander Bohte","1 - University of Surrey United Kingdom
2 - CWI Amsterdam The Netherlands","Over the last decade, various spiking neural network models have been proposed, along with a similarly increasing interest in spiking models of computation in computational neuroscience. The aim of this tutorial paper is to outline some of the common ground in state-of-the-art spiking neural networks as well as open challenges.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-13.pdf,2014,100.0,"Spiking Neural Networks: Principles and Challenges Over the last decade, various spiking neural network models have been proposed, along with a similarly increasing interest in spiking models of computation in computational neuroscience. The aim of this tutorial paper is to outline some of the common ground in state-of-the-art spiking neural networks as well as open challenges."
Learning Resets of Neural Working Memory,"J Rombouts, P Roelfsema, S Bohte","1 - Institute for Neuroscience -Vision and Cognition Centrum Wiskunde & Informatica -Life Sciences Science Park 123 -The Netherlands 2-Netherlands, Meibergdreef 47 The Netherlands","Working memory is a key component of intelligence that the brain implements as persistent neural activations. How do persistent neurons learn to store information, and how can they be made to forget this information once it is no longer relevant? When animals learn episodic tasks, neurons in prefrontal cortex learn to represent task ends. We show that a biologically plausible neural network model equipped with persistent memory and a 'reset' action can learn to store and forget information at task ends by reinforcement learning. The new model has competitive performance compared to a variety of (biologically implausible) models.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-130.pdf,2014,82.5,"Learning Resets of Neural Working Memory Working memory is a key component of intelligence that the brain implements as persistent neural activations. How do persistent neurons learn to store information, and how can they be made to forget this information once it is no longer relevant? When animals learn episodic tasks, neurons in prefrontal cortex learn to represent task ends. We show that a biologically plausible neural network model equipped with persistent memory and a 'reset' action can learn to store and forget information at task ends by reinforcement learning. The new model has competitive performance compared to a variety of (biologically implausible) models."
Rejection Strategies for Learning Vector Quantization,"Lydia Fischer, Barbara Hammer, Heiko Wersing","1 - HONDA Research Institute Europe GmbH Carl-Legien-Str. 30 63065 Offenbach Germany
2 - Bielefeld University Universitätsstr. 25 33615 Bielefeld Germany
5 - CoR-Lab Research Institute for Cognition and Robotics and gratefully acknowledges the financial support from Honda Research Institute Europe","We present prototype-based classification schemes, e. g. learning vector quantization, with cost-function-based and geometrically motivated reject options. We evaluate the reject schemes in experiments on artificial and benchmark data sets. We demonstrate that reject options improve the accuracy of the models in most cases, and that the performance of the proposed schemes is comparable to the optimal reject option of the Bayes classifier in cases where the latter is available.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-90,2014,70.70707070707071,"Rejection Strategies for Learning Vector Quantization We present prototype-based classification schemes, e. g. learning vector quantization, with cost-function-based and geometrically motivated reject options. We evaluate the reject schemes in experiments on artificial and benchmark data sets. We demonstrate that reject options improve the accuracy of the models in most cases, and that the performance of the proposed schemes is comparable to the optimal reject option of the Bayes classifier in cases where the latter is available."
Direct model predictive control,"Jean-Joseph Christophe, Jérémie Decock, Olivier Teytaud","1 - LRI UMR 8623 TAO (Inria) CNRS -Univ. Paris-Sud) bat 490
2 - Univ. Paris-Sud 91405 Orsay France","Due to simplicity and convenience, Model Predictive Control, which consists in optimizing future decisions based on a pessimistic deterministic forecast of the random processes, is one of the main tools for stochastic control. Yet, it suffers from a large computation time, unless the tactical horizon (i.e. the number of future time steps included in the optimization) is strongly reduced, and lack of real stochasticity handling. We here propose a combination between Model Predictive Control and Direct Policy Search. 
 Methods Framework. We assume that a strategic horizon T ∈ N, a state space S, an action space A, a random process p 0 , . . . , p T −1 with values p i ∈ P , a transition function f : S × A × P → S, a reward function r : S × A → R and an initial state s 0 are given. Equipped with a policy π : (N, S, P ) → A, they define actions a t = π(t, s t , p t ), states s t+1 = f (s t , a t , p t ) and the total reward R(π) = E T −1 t=0 r(s t , a t ) for time steps t ∈ {0, . . . , T −1}. The goal of stochastic dynamic programming is to find (approximately) the optimum arg max π ER(π). Bellman's decomposition[1] are classical tools for doing so when (p t ) t∈{1,...,T −1} is Markovian. Model Predictive Control (MPC[4, 5] ) consists in replacing the random process by a deterministic approximation (which is usually more or",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-132.pdf,2014,64.51612903225806,"Direct model predictive control Due to simplicity and convenience, Model Predictive Control, which consists in optimizing future decisions based on a pessimistic deterministic forecast of the random processes, is one of the main tools for stochastic control. Yet, it suffers from a large computation time, unless the tactical horizon (i.e. the number of future time steps included in the optimization) is strongly reduced, and lack of real stochasticity handling. We here propose a combination between Model Predictive Control and Direct Policy Search. 
 Methods Framework. We assume that a strategic horizon T ∈ N, a state space S, an action space A, a random process p 0 , . . . , p T −1 with values p i ∈ P , a transition function f : S × A × P → S, a reward function r : S × A → R and an initial state s 0 are given. Equipped with a policy π : (N, S, P ) → A, they define actions a t = π(t, s t , p t ), states s t+1 = f (s t , a t , p t ) and the total reward R(π) = E T −1 t=0 r(s t , a t ) for time steps t ∈ {0, . . . , T −1}. The goal of stochastic dynamic programming is to find (approximately) the optimum arg max π ER(π). Bellman's decomposition[1] are classical tools for doing so when (p t ) t∈{1,...,T −1} is Markovian. Model Predictive Control (MPC[4, 5] ) consists in replacing the random process by a deterministic approximation (which is usually more or"
Swim Velocity Profile Identification through a Dynamic Self-adaptive Multiobjective Harmonic Search and RBF Neural Networks,"Helon Ayala, Luciano Da Cruz, Leandro Coelho, Roberto Freire","1 - Pontifical Catholic University of Parana -PUCPR, Industrial and Systems Engineering Graduate Program -PPGEPS. Imaculada Conceição 1155 Curitiba Parana -Brazil
4 - Department of Electrical Engineering DEE/PPGEE Federal University of Parana -UFPR
5 - Polytechnic School of UFPR Curitiba, Parana Brazil","Technology has been successfully applied in sports, where biomechanical analysis is one of the most important areas used to raise the performance of athletes. In this context, this paper focuses on swim velocity profile identification using Radial Basis Functions Neural Networks (RBF-NN) trained by the Gustafson-Kessel clustering combined with a novel Dynamic Self-adaptive Multiobjective Harmony Search (DS-MOHS). One study case is analyzed, from real data acquired of an elite female athlete, swimming breaststroke style. Better results are obtained by DS-MOHS when compared with standard multiobjective harmony search in terms of accuracy and generalization of the model.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-133.pdf,2014,62.601626016260155,"Swim Velocity Profile Identification through a Dynamic Self-adaptive Multiobjective Harmonic Search and RBF Neural Networks Technology has been successfully applied in sports, where biomechanical analysis is one of the most important areas used to raise the performance of athletes. In this context, this paper focuses on swim velocity profile identification using Radial Basis Functions Neural Networks (RBF-NN) trained by the Gustafson-Kessel clustering combined with a novel Dynamic Self-adaptive Multiobjective Harmony Search (DS-MOHS). One study case is analyzed, from real data acquired of an elite female athlete, swimming breaststroke style. Better results are obtained by DS-MOHS when compared with standard multiobjective harmony search in terms of accuracy and generalization of the model."
Naive Augmenting Q-Learning to Process Feature-Based Representations of States,Janis Zuters,"1 - Faculty of Computing 19 Raina blvd University of Latvia LV-1586 Riga Latvia
2 - Artificial Intelligence Foundation Latvia University of Latvia""","Temporal difference algorithms perform well on discrete and small problems. This paper proposes a modification of the Q-learning algorithm towards natural ability to receive a feature list instead of an already identified state in the input. Complete observability is still assumed. The algorithm, Naive Augmenting Q-Learning, has been designed through building a hierarchical structure of input features (a kind of feature-state mapping) to avoid a direct state identification, thus potentially optimizing the required resources for storing and processing action values.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-136.pdf,2014,100.0,"Naive Augmenting Q-Learning to Process Feature-Based Representations of States Temporal difference algorithms perform well on discrete and small problems. This paper proposes a modification of the Q-learning algorithm towards natural ability to receive a feature list instead of an already identified state in the input. Complete observability is still assumed. The algorithm, Naive Augmenting Q-Learning, has been designed through building a hierarchical structure of input features (a kind of feature-state mapping) to avoid a direct state identification, thus potentially optimizing the required resources for storing and processing action values."
FINGeR: Framework for Interactive Neural-based Gesture Recognition,"German Parisi, Pablo Barros, Stefan Wermter",1 - Department of Computer Science University of Hamburg Vogt-Koelln-Strasse 30 D-22527 Hamburg Germany,"For operating in real world scenarios, the recognition of human gestures must be adaptive, robust and fast. Despite the prominent use of Kinect-like range sensors for demanding visual tasks involving motion, it still remains unclear how to process depth information for efficiently extrapolating the dynamics of hand gestures. We propose a learning framework based on neural evidence for processing visual information. We first segment and extract spatiotemporal hand properties from RGB-D videos. Shape and motion features are then processed by two parallel streams of hierarchical self-organizing maps and subsequently combined for a more robust representation. We provide experimental results to show how multicue integration increases recognition rates over a single-cue approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-138.pdf,2014,87.87878787878788,"FINGeR: Framework for Interactive Neural-based Gesture Recognition For operating in real world scenarios, the recognition of human gestures must be adaptive, robust and fast. Despite the prominent use of Kinect-like range sensors for demanding visual tasks involving motion, it still remains unclear how to process depth information for efficiently extrapolating the dynamics of hand gestures. We propose a learning framework based on neural evidence for processing visual information. We first segment and extract spatiotemporal hand properties from RGB-D videos. Shape and motion features are then processed by two parallel streams of hierarchical self-organizing maps and subsequently combined for a more robust representation. We provide experimental results to show how multicue integration increases recognition rates over a single-cue approach."
Meta online learning: experiments on a unit commitment problem,"Jialin Liu, Olivier Teytaud","1 - LRI UMR 8623 TAO (Inria) CNRS -Univ. Paris-Sud) bat 490
2 - Univ. Paris-Sud 91405 Orsay France","Online learning is machine learning, in real time from successive data samples. Meta online learning consists in combining several online learning algorithms from a given set (termed portfolio) of algorithms. The goal can be (i) mitigating the effect of a bad choice of online learning algorithms (ii) parallelization (iii) combining the strengths of different algorithms. Basically, meta online learning boils down to combining noisy optimization algorithms. Whereas many tools exist for combining combinatorial optimization tools, little is known about combining noisy optimization algorithms. Recently, a methodology termed lag has been proposed for that. We test experimentally the lag methodology for online learning, for a stock management problem and a cartpole problem.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-139.pdf,2014,75.80645161290323,"Meta online learning: experiments on a unit commitment problem Online learning is machine learning, in real time from successive data samples. Meta online learning consists in combining several online learning algorithms from a given set (termed portfolio) of algorithms. The goal can be (i) mitigating the effect of a bad choice of online learning algorithms (ii) parallelization (iii) combining the strengths of different algorithms. Basically, meta online learning boils down to combining noisy optimization algorithms. Whereas many tools exist for combining combinatorial optimization tools, little is known about combining noisy optimization algorithms. Recently, a methodology termed lag has been proposed for that. We test experimentally the lag methodology for online learning, for a stock management problem and a cartpole problem."
A New Error-Correcting Syndrome Decoder with Retransmit Signal Implemented with an Hardlimit Neural Network,José Barahona Da Fonseca,1 - Department of Electrical Engineering and Computer Science Faculty of Sciences and Technology New University of Lisbon Monte de Caparica 2829-516 Caparica Portugal,"Still today the problem of counting the errors of a noisy received word is an open problem in literature. This means that when we use an error correcting code we cannot control if the number of errors of the received noisy word is greater than the error correction capability of the code of k errors, k=(d-1)/2, where d is the minimum Hamming distance of the code. The main advantage of our proposal results from the introduction of the Retransmit signal when the syndrome decoder detects an ambiguity situation and cannot correct the noisy word. These ambiguity situations occur when happens one more error than the error correction capability of the error correcting code. This property of the error correcting syndrome scheme allows increasing the error correction capability of an error correcting code by one error at a little increment of bandwidth or delay in the transmission. Although there are some proposals of implementation of errorcorrecting decoders with neural networks in literature our work is completely different in what concerns three main aspects. First we propose the implementation of the retransmit signal based on the detection of ambiguity of the minimum Hamming distance between the received word and each of the codewords, i.e. when there are more than one codeword at the minimum Hamming distance to the too noisy received word. Second we use a constructive approach that does not need training. And finally we use hardlimit neurons that can be implemented in hardware by a single transistor in a high gain setup. We begin with two exhaustive simulation experiments where we introduced all manners of occurrence of two errors in all codewords of two codes with minimum Hamming distances 3 and 4, respectively, which only guarantee all possible one error good corrections, to show how the ambiguities arise in the decoding process. Next we present the building blocks of the error correcting decoder based in hardlimit multilayered perceptrons and then we assembled all them out and show an example for an error correcting decoder for a four codewords error correcting code. Finally we discuss the advantages of our proposal and the consequences of the introduction of the Retransmit signal and define possible ways of evolution of our work.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-14.pdf,2014,100.0,"A New Error-Correcting Syndrome Decoder with Retransmit Signal Implemented with an Hardlimit Neural Network Still today the problem of counting the errors of a noisy received word is an open problem in literature. This means that when we use an error correcting code we cannot control if the number of errors of the received noisy word is greater than the error correction capability of the code of k errors, k=(d-1)/2, where d is the minimum Hamming distance of the code. The main advantage of our proposal results from the introduction of the Retransmit signal when the syndrome decoder detects an ambiguity situation and cannot correct the noisy word. These ambiguity situations occur when happens one more error than the error correction capability of the error correcting code. This property of the error correcting syndrome scheme allows increasing the error correction capability of an error correcting code by one error at a little increment of bandwidth or delay in the transmission. Although there are some proposals of implementation of errorcorrecting decoders with neural networks in literature our work is completely different in what concerns three main aspects. First we propose the implementation of the retransmit signal based on the detection of ambiguity of the minimum Hamming distance between the received word and each of the codewords, i.e. when there are more than one codeword at the minimum Hamming distance to the too noisy received word. Second we use a constructive approach that does not need training. And finally we use hardlimit neurons that can be implemented in hardware by a single transistor in a high gain setup. We begin with two exhaustive simulation experiments where we introduced all manners of occurrence of two errors in all codewords of two codes with minimum Hamming distances 3 and 4, respectively, which only guarantee all possible one error good corrections, to show how the ambiguities arise in the decoding process. Next we present the building blocks of the error correcting decoder based in hardlimit multilayered perceptrons and then we assembled all them out and show an example for an error correcting decoder for a four codewords error correcting code. Finally we discuss the advantages of our proposal and the consequences of the introduction of the Retransmit signal and define possible ways of evolution of our work."
Lightning Fast Asynchronous Distributed K-Means Clustering *,"Árpád Berta, István Hegedűs, Róbert Ormándi",1 - University of Szeged Szeged Hungary,"One of the most fundamental data processing approach is the clustering. This is even true in distributed architectures. Here, we focus on the problem of designing efficient and fast K-Means approaches which work in fully distributed, asynchronous networks without any central control. We assume that the network has a huge number of computational units (even orders of magnitude more than the number of computational units in a general cloud). Our approaches apply online learning clustering models which take different random walks in the network, while they update themselves using the data points stored by the computational units, and various ensemble techniques combine them to get a faster convergence. We define different instantiations of the general framework that apply various ensemble techniques. We evaluate them empirically against several state-of-the-art distributed baseline algorithms in different computational scenarios. The experiments show that our methods are not only robust against network failure, but they also provide accurate clustering and converge extremely fast.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-140.pdf,2014,72.88135593220339,"Lightning Fast Asynchronous Distributed K-Means Clustering * One of the most fundamental data processing approach is the clustering. This is even true in distributed architectures. Here, we focus on the problem of designing efficient and fast K-Means approaches which work in fully distributed, asynchronous networks without any central control. We assume that the network has a huge number of computational units (even orders of magnitude more than the number of computational units in a general cloud). Our approaches apply online learning clustering models which take different random walks in the network, while they update themselves using the data points stored by the computational units, and various ensemble techniques combine them to get a faster convergence. We define different instantiations of the general framework that apply various ensemble techniques. We evaluate them empirically against several state-of-the-art distributed baseline algorithms in different computational scenarios. The experiments show that our methods are not only robust against network failure, but they also provide accurate clustering and converge extremely fast."
Analysis of the Weighted Fuzzy C-means in the Problem of Source Location,"Everton Nadalin, Rodrigo Silva, Romis Attux, João Romano","1 - School of Electrical and Computer Engineering DSPCom Laboratory University of Campinas (UNICAMP) Av. Albert Einstein, 400 13083-970 Campinas SP Brazil","This paper proposes the use of the clustering method called Weighted Fuzzy C-means to solve the problem of mixing matrix estimation in underdetermined source separation based on sparse component analysis. The performed comparative analysis shows that the approach has a significant application potential, especially if the distributions of the columns of the mixing matrix has a non-uniform character.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-142.pdf,2014,70.83333333333333,"Analysis of the Weighted Fuzzy C-means in the Problem of Source Location This paper proposes the use of the clustering method called Weighted Fuzzy C-means to solve the problem of mixing matrix estimation in underdetermined source separation based on sparse component analysis. The performed comparative analysis shows that the approach has a significant application potential, especially if the distributions of the columns of the mixing matrix has a non-uniform character."
A Random Forest proximity matrix as a new measure for gene annotation *,"Jose Seoane, Ian Day, Juan Casas, Colin Campbell, Tom Gaunt, Humancvd Beadchip","1 - Bristol Genetic Epidemiology Labs. School of Social and Community Medicine Oakfield House Oakfield Grove. University of Bristol BS8 2BN Bristol UK
3 - Department of Non-communicable Disease Epidemiology London School of Hygiene and Tropical Medicine UK
4 - Intelligent Systems Laboratory. Merchant Venturers Building University of Bristol BS8 2BN Bristol UK
6 - MRC Integrative Epidemiology Unit. School of Social and Community Medicine Oakfield House Oakfield Grove. University of Bristol BS8 2BN Bristol UK
7 - Department of Health Policy Research Programme The BWHHS Illumina UK","In this paper we present a new score for gene annotation. This new score is based on the proximity matrix obtained from a trained Random Forest (RF) model. As an example application, we built this model using the association pvalues of genotype with blood phenotype as input and the association of genotype data with coronary heart disease as output. This new score has been validated by comparing the Gene Ontology (GO) annotation using this score versus the score obtained from the gene annotation ""String"" tool. Using the new proximity based measure results in more accurate annotation, especially in the GO categories Molecular Function and Biological Process.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-144.pdf,2014,98.57142857142858,"A Random Forest proximity matrix as a new measure for gene annotation * In this paper we present a new score for gene annotation. This new score is based on the proximity matrix obtained from a trained Random Forest (RF) model. As an example application, we built this model using the association pvalues of genotype with blood phenotype as input and the association of genotype data with coronary heart disease as output. This new score has been validated by comparing the Gene Ontology (GO) annotation using this score versus the score obtained from the gene annotation ""String"" tool. Using the new proximity based measure results in more accurate annotation, especially in the GO categories Molecular Function and Biological Process."
The one-sided mean kernel: a positive definite kernel for time series,"Nicolas Chrysanthos, Pierre Beauseroy, Hichem Snoussi, Edith Grall, Fabrice Ferrand","1 - Institut Charles Delaunay UMR CNRS 6279 STMR) Université de Technologie de Troyes 10010 Troyes LM2S, France
2 - Sagem Défense Sécurité 18-20 Quai du Point du Jour 92100 Boulogne-Bilancourt France","We propose in this paper a new kernel for time series on structured data in the dynamic time warping family. We demonstrate using the theory of infinitely divisible kernels that this kernel is positive definite, that it is a radial basis kernel and that it reduces to a product kernel when comparing two sequences of the same length. Finally we compare this kernel with the global alignment kernel in a classification task using support vector machines.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-147.pdf,2014,100.0,"The one-sided mean kernel: a positive definite kernel for time series We propose in this paper a new kernel for time series on structured data in the dynamic time warping family. We demonstrate using the theory of infinitely divisible kernels that this kernel is positive definite, that it is a radial basis kernel and that it reduces to a product kernel when comparing two sequences of the same length. Finally we compare this kernel with the global alignment kernel in a classification task using support vector machines."
Discrimination of visual pedestrians data by combining projection and prediction learning,"Mathieu Lefort, Alexander Gepperth",1 - ENSTA ParisTech -UIIS division 858 Boulevard des Maréchaux 91762 Palaiseau France,"PROPRE is a generic and semi-supervised neural learning paradigm that extracts meaningful concepts of multimodal data flows based on predictability across modalities. It consists on the combination of two computational paradigms. First, a topological projection of each data flow on a self-organizing map (SOM) to reduce input dimension. Second, each SOM activity is used to predict activities in all other SOMs. Predictability measure, that compares predicted and real activities, is used to modulate the SOM learning to favor mutually predictable stimuli. In this article, we study PROPRE applied to a classical visual pedestrian data classification task. The SOM learning modulation introduced in PROPRE improves significantly classification performance.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-148.pdf,2014,100.0,"Discrimination of visual pedestrians data by combining projection and prediction learning PROPRE is a generic and semi-supervised neural learning paradigm that extracts meaningful concepts of multimodal data flows based on predictability across modalities. It consists on the combination of two computational paradigms. First, a topological projection of each data flow on a self-organizing map (SOM) to reduce input dimension. Second, each SOM activity is used to predict activities in all other SOMs. Predictability measure, that compares predicted and real activities, is used to modulate the SOM learning to favor mutually predictable stimuli. In this article, we study PROPRE applied to a classical visual pedestrian data classification task. The SOM learning modulation introduced in PROPRE improves significantly classification performance."
Neural network based 2D/3D fusion for robotic object recognition,"Louis-Charles Caron, Yang Song, David Filliat, Alexander Gepperth",1 - Lab 828 Blvd des Maréchaux ENSTA ParisTech -UIIS 91762 Palaiseau France,"We present a neural network based fusion approach for realtime robotic object recognition which integrates 2D and 3D descriptors in a flexible way. The presented recognition architecture is coupled to a real-time segmentation step based on 3D data, since a focus of our investigations is real-world operation on a mobile robot. As recognition must operate on imperfect segmentation results, we conduct tests of recognition performance using complex everyday objects in order to quantify the overall gain of performing 2D/3D fusion, and to discover where it is particularly useful. We find that the fusion approach is most powerful when generalization is required, for example to significant viewpoint changes and a large number of object categories, and that a perfect segmentation is apparently not a necessary prerequisite for successful discrimination.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-149.pdf,2014,100.0,"Neural network based 2D/3D fusion for robotic object recognition We present a neural network based fusion approach for realtime robotic object recognition which integrates 2D and 3D descriptors in a flexible way. The presented recognition architecture is coupled to a real-time segmentation step based on 3D data, since a focus of our investigations is real-world operation on a mobile robot. As recognition must operate on imperfect segmentation results, we conduct tests of recognition performance using complex everyday objects in order to quantify the overall gain of performing 2D/3D fusion, and to discover where it is particularly useful. We find that the fusion approach is most powerful when generalization is required, for example to significant viewpoint changes and a large number of object categories, and that a perfect segmentation is apparently not a necessary prerequisite for successful discrimination."
A robust regularization path for the Doubly Regularized Support Vector Machine,"Antoine Lachaud, David Mercier, Stephane Canu, Frederic Suard","1 - CEA,LIST 91191 Gif sur Yvette France
3 - INSA de Rouen -LITIS Avenue de l'Universite -Saint-Etienne-du-Rouvray 76800 France","The Doubly Regularized SVM (DrSVM) is an extension of SVM using a mixture of L2 and L1 norm penalties. This kind of penalty, sometimes referred as the elastic net, allows to perform variable selection while taking into account correlations between variables. Introduced by Wang [1], an ecient algorithm to compute the whole DrSVM solution path has been proposed. Unfortunately, in some cases, this path is discontinuous, and thus not piecewise linear. To solve this problem, we propose here a new sub gradient formulation of the DrSVM problem. This led us to propose an alternative L1 regularization path algorithm. This reformulation eciently addresses the aforementioned problem and makes the initialization step more generic. The results show the validity of our sub-gradient formulation and the eciency compared to the initial formulation.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-150.pdf,2014,100.0,"A robust regularization path for the Doubly Regularized Support Vector Machine The Doubly Regularized SVM (DrSVM) is an extension of SVM using a mixture of L2 and L1 norm penalties. This kind of penalty, sometimes referred as the elastic net, allows to perform variable selection while taking into account correlations between variables. Introduced by Wang [1], an ecient algorithm to compute the whole DrSVM solution path has been proposed. Unfortunately, in some cases, this path is discontinuous, and thus not piecewise linear. To solve this problem, we propose here a new sub gradient formulation of the DrSVM problem. This led us to propose an alternative L1 regularization path algorithm. This reformulation eciently addresses the aforementioned problem and makes the initialization step more generic. The results show the validity of our sub-gradient formulation and the eciency compared to the initial formulation."
NMF-Density: NMF-Based Breast Density Classifier,"Lahouari Ghouti, Abdullah Owaidh",1 - Minerals -Department of Information and Computer Science King Fahd University of Petroleum KFUPM Box 1128. Dhahran 31261 Saudi Arabia,"The amount of tissue available in the breast, commonly characterized by the breast density, is highly correlated with breast cancer. In fact, dense breasts have higher risk of developing breast cancer. On the other hand, breast density influences the mammographic interpretation since it decreases the sensitivity of breast cancer detection. This sensitivity decrease is due to the fact that both cancerous regions and tissue appear as white areas in breast mammograms. This paper introduces new features to improve the classification of breast density in digital mammograms according to the commonly used radiological lexicon (BI-RADS). These features are extracted from non-negative matrix factorization (NMF) of mammograms and classified using machine learning classifiers. Using ground truth mammographic data, the classification performance of the proposed features is assessed. Simulation results show that the latter significantly outperforms existing density features based on principal component analysis (PCA) by achieving higher classification accuracy.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-151.pdf,2014,100.0,"NMF-Density: NMF-Based Breast Density Classifier The amount of tissue available in the breast, commonly characterized by the breast density, is highly correlated with breast cancer. In fact, dense breasts have higher risk of developing breast cancer. On the other hand, breast density influences the mammographic interpretation since it decreases the sensitivity of breast cancer detection. This sensitivity decrease is due to the fact that both cancerous regions and tissue appear as white areas in breast mammograms. This paper introduces new features to improve the classification of breast density in digital mammograms according to the commonly used radiological lexicon (BI-RADS). These features are extracted from non-negative matrix factorization (NMF) of mammograms and classified using machine learning classifiers. Using ground truth mammographic data, the classification performance of the proposed features is assessed. Simulation results show that the latter significantly outperforms existing density features based on principal component analysis (PCA) by achieving higher classification accuracy."
Applications of l p -Norms and their Smooth Approximations for Gradient Based Learning Vector Quantization,"M Lange, D Zühlke, O Holz, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
2 - Fraunhofer-IAIS -Dep. of Organized Knowledge Sankt Augustin Germany
3 - Fraunhofer-ITEM -Hannover Germany","Learning vector quantization applying non-standard metrics became quite popular for classification performance improvement compared to standard approaches using the Euclidean distance. Kernel metrics and quadratic forms belong to the most promising approaches. In this paper we consider Minkowski distances (lp-norms). In particular, l1-norms are known to be robust against noise in data, such that, if this structural knowledge is available in advance about the data, this norm should be utilized. However, application in gradient based learning algorithms based on distance evaluations need to calculate the respective derivatives. Because lp-distance formulas contain the absolute approximations thereof are required. We consider in this paper several approaches for smooth consistent approximations for numerical evaluations and demonstrate the applicability for exemplary real world applications.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-153.pdf,2014,92.38095238095238,"Applications of l p -Norms and their Smooth Approximations for Gradient Based Learning Vector Quantization Learning vector quantization applying non-standard metrics became quite popular for classification performance improvement compared to standard approaches using the Euclidean distance. Kernel metrics and quadratic forms belong to the most promising approaches. In this paper we consider Minkowski distances (lp-norms). In particular, l1-norms are known to be robust against noise in data, such that, if this structural knowledge is available in advance about the data, this norm should be utilized. However, application in gradient based learning algorithms based on distance evaluations need to calculate the respective derivatives. Because lp-distance formulas contain the absolute approximations thereof are required. We consider in this paper several approaches for smooth consistent approximations for numerical evaluations and demonstrate the applicability for exemplary real world applications."
Utilization of Chemical Structure Information for Analysis of Spectra Composites,"Kristin Domaschke, André Rossberg, Thomas Villmann","1 - -University of Appl. Science Mittweida -Dept. of Mathematics Technikumplatz 17 09648 Mittweida Germany
2 - Institute of Resource Ecology 1-Helmholtz-Zentrum Dresden-Rossendorf P.O. Box 51 01 01314 Dresden Germany
3 - Life Science Inkubator Sachsen GmbH & Co. KG, project team NanoscopiX Tatzberg 47 01307 Dresden Germany","In this paper, we propose the utilization of structural information of spectral data during the preprocessing to extend the ability of subsequent analysis methods. Specifically, we expect a dataset of measured spectra containing mixtures of only a few spectral components. Using the concentration ratios for a small subset of mixtures and the chemical structural knowledge, theoretical spectral components are generated. Then a set, which combines measured and theoretical spectra, is analyzed using a self-organizing map to predict the unknown mixture ratios of the remaining subset by an associative learning. At this time, the initial study on simulated data reached very good results.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-155.pdf,2014,100.0,"Utilization of Chemical Structure Information for Analysis of Spectra Composites In this paper, we propose the utilization of structural information of spectral data during the preprocessing to extend the ability of subsequent analysis methods. Specifically, we expect a dataset of measured spectra containing mixtures of only a few spectral components. Using the concentration ratios for a small subset of mixtures and the chemical structural knowledge, theoretical spectral components are generated. Then a set, which combines measured and theoretical spectra, is analyzed using a self-organizing map to predict the unknown mixture ratios of the remaining subset by an associative learning. At this time, the initial study on simulated data reached very good results."
The Choquet Kernel for Monotone Data,"Ali Fallah Tehrani, Marc Strickert, Eyke Hüllermeier",1 - Computational Intelligence Group Philipps Universität Marburg D-35032 Marburg Germany,"In this paper, we introduce a kernel for monotone data derived from the Choquet integral with its underlying fuzzy measure. While a naïve computation of this kernel has a complexity that is exponential in the number of data attributes, we propose a more efficient approach with quadratic time complexity. Kernel PCA and SVM classification are employed to illustrate characteristics and benefits of the new Choquet kernel in two experiments related to decision-making and pricing.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-156.pdf,2014,69.44444444444444,"The Choquet Kernel for Monotone Data In this paper, we introduce a kernel for monotone data derived from the Choquet integral with its underlying fuzzy measure. While a naïve computation of this kernel has a complexity that is exponential in the number of data attributes, we propose a more efficient approach with quadratic time complexity. Kernel PCA and SVM classification are employed to illustrate characteristics and benefits of the new Choquet kernel in two experiments related to decision-making and pricing."
Machine learning techniques to assess the performance of a gait analysis system,"Sébastien Piérard, Rémy Phan-Ba, Marc Van Droogenbroeck",1 - Montefiore Institute INTELSIG Laboratory University of Liège Belgium,"This paper presents a methodology based on machine learning techniques to assess the performance of a system measuring the trajectories of the lower limbs extremities for the follow-up of patients with multiple sclerosis. We show how we have established, with the help of machine learning, four important properties about this system: (1) an automated analysis of gait characteristics provides an improved analysis with respect to that of a human expert, (2) after learning, the gait characteristics provided by this system are valuable compared to measures taken by stopwatches, as used in the standardized tests, (3) the motion of the lower limbs extremities contains a lot of useful information about the gait, even if it is only a small part of the body motion, (4) a measurement system combined with a machine learning tool is sensitive to intra-subject modifications of the walking pattern.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-159.pdf,2014,100.0,"Machine learning techniques to assess the performance of a gait analysis system This paper presents a methodology based on machine learning techniques to assess the performance of a system measuring the trajectories of the lower limbs extremities for the follow-up of patients with multiple sclerosis. We show how we have established, with the help of machine learning, four important properties about this system: (1) an automated analysis of gait characteristics provides an improved analysis with respect to that of a human expert, (2) after learning, the gait characteristics provided by this system are valuable compared to measures taken by stopwatches, as used in the standardized tests, (3) the motion of the lower limbs extremities contains a lot of useful information about the gait, even if it is only a small part of the body motion, (4) a measurement system combined with a machine learning tool is sensitive to intra-subject modifications of the walking pattern."
Choosing the Metric in High-Dimensional Spaces Based on Hub Analysis,"Dominik Schnitzer, Arthur Flexer",1 - Austrian Research Institute for Artificial Intelligence (OFAI) Freyung 6/6 1010 Wien Austria,"To avoid the undesired effects of distance concentration in high-dimensional spaces, previous work has already advocated the use of fractional p norms instead of the ubiquitous Euclidean norm. Closely related to concentration is the emergence of hub and anti-hub objects. Hub objects have a small distance to an exceptionally large number of data points while anti-hubs lie far from all other data points. The contribution of this work is an empirical examination of concentration and hubness, resulting in an unsupervised approach for choosing an p norm by minimizing hubs while simultaneously maximizing nearest neighbor classification.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-16.pdf,2014,100.0,"Choosing the Metric in High-Dimensional Spaces Based on Hub Analysis To avoid the undesired effects of distance concentration in high-dimensional spaces, previous work has already advocated the use of fractional p norms instead of the ubiquitous Euclidean norm. Closely related to concentration is the emergence of hub and anti-hub objects. Hub objects have a small distance to an exceptionally large number of data points while anti-hubs lie far from all other data points. The contribution of this work is an empirical examination of concentration and hubness, resulting in an unsupervised approach for choosing an p norm by minimizing hubs while simultaneously maximizing nearest neighbor classification."
Can you follow that guy?,"Mariacarla Staffa, Massimo De Gregorio, Maurizio Giordano, Silvia Rossi","1 - Dipartimento di Ingegneria Elettrica e Tecnologie dell'Informazione -DIETI Via Claudio 27 -Naples Italy
2 - Istituto di Cibernetica ""Eduardo Caianiello"" -CNR Via Campi Flegrei 34 Pozzuoli Italy
3 - Istituto di Calcolo e Reti ad Alte Prestazioni -CNR Via Pietro Castellino 111 Naples Italy","The problem of tracking moving objects or human beings is a challenging problem in mobile robotics. Knowledge about the position of moving subjects can be used both to improve the behavior of the robotic system, and to perform tasks of monitoring or following. Different methodologies have been applied in literature, using different sensors and techniques for addressing this problem. In this paper we propose a WiSARD-based system approach for tracking either moving robots or human beings.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-160.pdf,2014,100.0,"Can you follow that guy? The problem of tracking moving objects or human beings is a challenging problem in mobile robotics. Knowledge about the position of moving subjects can be used both to improve the behavior of the robotic system, and to perform tasks of monitoring or following. Different methodologies have been applied in literature, using different sensors and techniques for addressing this problem. In this paper we propose a WiSARD-based system approach for tracking either moving robots or human beings."
Exploiting Similarity in System Identification Tasks with Recurrent Neural Networks,"Sigurd Spieckermann, Siegmund Düll, Steffen Udluft, Alexander Hentschel, Thomas Runkler","1 - Siemens Corporate Technology -Learning Systems Otto-Hahn-Ring 6 -81739 Munich Germany
2 - Department of Informatics Boltzmannstr Technical University of Munich 3 -85748 Garching Germany
4 - Berlin University of Technology -Machine Learning Franklinstr 28-29 -10587 Berlin Germany","A new dual-task learning approach based on recurrent neural networks with factored tensor components for system identification tasks is presented. The overall goal is to identify the underlying dynamics of a system given few observations which are augmented by auxiliary data from similar systems. The resulting system identification is motivated by various real-world industrial use cases, e.g. gas or wind turbine modeling for optimization and monitoring. The problem is formalized and the effectiveness of the proposed method is assessed on the cart-pole benchmark.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-162.pdf,2014,87.95180722891567,"Exploiting Similarity in System Identification Tasks with Recurrent Neural Networks A new dual-task learning approach based on recurrent neural networks with factored tensor components for system identification tasks is presented. The overall goal is to identify the underlying dynamics of a system given few observations which are augmented by auxiliary data from similar systems. The resulting system identification is motivated by various real-world industrial use cases, e.g. gas or wind turbine modeling for optimization and monitoring. The problem is formalized and the effectiveness of the proposed method is assessed on the cart-pole benchmark."
Optimal Data Projection for Kernel Spectral Clustering,"D Peluffo, C Alzate, J Suykens, G Castellanos-Dominguez","1 - Machine Learning Group -ICTEAM Université catholique de Louvain
2 - IBM Research Ireland
3 - Katholieke Universiteit Leuven ESAT-STADIUS
4 - Johan Suykens acknowledges support by Research Council KUL ERC AdG A-DATADRIVE-B GOA/10/09MaNet
5 - CoE EF 05/006 FWO G.0588.09, G.0377.12
6 - IUAP P6/04 DYSCO SBO POM
7 - Universidad Nacional de Colombia","Spectral clustering has taken an important place in the context of pattern recognition, being a good alternative to solve problems with non-linearly separable groups. Because of its unsupervised nature, clustering methods are often parametric, requiring then some initial parameters. Thus, clustering performance is greatly dependent on the selection of those initial parameters. Furthermore, tuning such parameters is not an easy task when the initial data representation is not adequate. Here, we propose a new projection for input data to improve the cluster identification within a kernel spectral clustering framework. The proposed projection is done from a feature extraction formulation, in which a generalized distance involving the kernel matrix is used. Data projection shows to be useful for improving the performance of kernel spectral clustering.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-163.pdf,2014,100.0,"Optimal Data Projection for Kernel Spectral Clustering Spectral clustering has taken an important place in the context of pattern recognition, being a good alternative to solve problems with non-linearly separable groups. Because of its unsupervised nature, clustering methods are often parametric, requiring then some initial parameters. Thus, clustering performance is greatly dependent on the selection of those initial parameters. Furthermore, tuning such parameters is not an easy task when the initial data representation is not adequate. Here, we propose a new projection for input data to improve the cluster identification within a kernel spectral clustering framework. The proposed projection is done from a feature extraction formulation, in which a generalized distance involving the kernel matrix is used. Data projection shows to be useful for improving the performance of kernel spectral clustering."
An adjustable p-exponential clustering algorithm,"Valmir Macario, Francisco De Carvalho",1 - Universidade Federal Rural de Pernambuco -Deinfo Rua Dom Manoel de Medeiros,This paper proposes a new exponential clustering algorithm (XPFCM) by reformulating the clustering objective function with an additional parameter p to adjust the exponential behavior for membership assignment. The clustering experiments show that the proposed method assign data to the clusters better than other fuzzy C-means (FCM) variants.,Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-164.pdf,2014,100.0,An adjustable p-exponential clustering algorithm This paper proposes a new exponential clustering algorithm (XPFCM) by reformulating the clustering objective function with an additional parameter p to adjust the exponential behavior for membership assignment. The clustering experiments show that the proposed method assign data to the clusters better than other fuzzy C-means (FCM) variants.
Relevance Learning for Dimensionality Reduction,"Alexander Schulz, Andrej Gisbrecht, Barbara Hammer",1 - CITEC center of excellence Bielefeld University Germany,"Nonlinear dimensionality reduction (NLDR) techniques offer powerful data visualization schemes capturing nonlinear effects of the data at the costs of a decreased interpretability of the projection: Unlike for linear counterparts such as principal component analysis, the relevance of the original feature dimensions for the NLDR projection is not clear. In this contribution we propose relevance learning schemes for NLDR which enable to judge the relevance of a feature dimension for the projection. This technique can be extended to a metric learning scheme which opens a way to imprint the information as provided by a given visualization on the data representation in the original feature space.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-165.pdf,2014,100.0,"Relevance Learning for Dimensionality Reduction Nonlinear dimensionality reduction (NLDR) techniques offer powerful data visualization schemes capturing nonlinear effects of the data at the costs of a decreased interpretability of the projection: Unlike for linear counterparts such as principal component analysis, the relevance of the original feature dimensions for the NLDR projection is not clear. In this contribution we propose relevance learning schemes for NLDR which enable to judge the relevance of a feature dimension for the projection. This technique can be extended to a metric learning scheme which opens a way to imprint the information as provided by a given visualization on the data representation in the original feature space."
A HMM-based Pre-training Approach for Sequential Data,"Luca Pasa, Alberto Testolin, Alessandro Sperduti","1 - Department of Mathematics
2 - Department of Developmental Psychology Socialisation University of Padova Italy","Much recent research highlighted the critical role of unsupervised pre-training to improve the performance of neural network models. However, extensions of those architectures to the temporal domain introduce additional issues, which often prevent to obtain good performance in a reasonable time. We propose a novel approach to pre-train sequential neural networks in which a simpler, approximate distribution generated by a linear model is first used to drive the weights in a better region of the parameter space. After this smooth distribution has been learned, the network is fine-tuned on the more complex real dataset. The benefits of the proposed method are demonstrated on a prediction task using two datasets of polyphonic music, and the general validity of this strategy is shown by applying it to two different recurrent neural network architectures.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-166.pdf,2014,67.9245283018868,"A HMM-based Pre-training Approach for Sequential Data Much recent research highlighted the critical role of unsupervised pre-training to improve the performance of neural network models. However, extensions of those architectures to the temporal domain introduce additional issues, which often prevent to obtain good performance in a reasonable time. We propose a novel approach to pre-train sequential neural networks in which a simpler, approximate distribution generated by a linear model is first used to drive the weights in a better region of the parameter space. After this smooth distribution has been learned, the network is fine-tuned on the more complex real dataset. The benefits of the proposed method are demonstrated on a prediction task using two datasets of polyphonic music, and the general validity of this strategy is shown by applying it to two different recurrent neural network architectures."
"Extracting rules from DRASiW's ""mental images""","Paulo Coutinho, Hugo Carneiro, Danilo Carvalho, Felipe França","1 - Universidade Federal do Rio de Janeiro -PESC Rio de Janeiro COPPE, Brazil","DRASiW is an extension of the WiSARD weightless neural model that provides the ability of producing examples/prototypes, called ""mental images"", from learnt categories. This work introduces a novel way of performing rule extraction by applying the WiSARD/DRASiW RAMbased neural model upon a well-known machine learning benchmark. A functional exploration is offered in order to demonstrate how the new rule extraction mechanism behaves under different system configurations. Experimental results suggest that the rules conformance to data increases proportionally to the corresponding classifier accuracy. Furthermore, comparison with C4.5 decision tree algorithm shows that the DRASiW-based technique produces more compact sets of rules.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-167.pdf,2014,97.82608695652173,"Extracting rules from DRASiW's ""mental images"" DRASiW is an extension of the WiSARD weightless neural model that provides the ability of producing examples/prototypes, called ""mental images"", from learnt categories. This work introduces a novel way of performing rule extraction by applying the WiSARD/DRASiW RAMbased neural model upon a well-known machine learning benchmark. A functional exploration is offered in order to demonstrate how the new rule extraction mechanism behaves under different system configurations. Experimental results suggest that the rules conformance to data increases proportionally to the corresponding classifier accuracy. Furthermore, comparison with C4.5 decision tree algorithm shows that the DRASiW-based technique produces more compact sets of rules."
Beyond Histograms: Why Learned Structure-Preserving Descriptors Outperform HOG,"Thomas Guthier, Volker Willert, Julian Eggert","1 - -TU Darmstadt -Control theory and robotics lab Landgraf-Georg-Str. 4 64283 Darmstadt -Germany
3 - Honda Research Institute Europe Carl-Legien-Str. 30 63073 Offenbach Germany","Statistical image descriptors based on histograms (e.g. SIFT [1], HOG  [2] ) are widely used in image processing, because they are fast and simple methods with high classification performance. However, they discard the local spatial topology and thus lose discriminative information contained in the image. We discuss the relations between HOG and VNMF descriptors, i.e. structure free histograms versus learned structure-preserving patterns. VNMF is a shift-invariant, sparse, nonnegative unsupervised learning algorithm  [8, 9, 5] , that provides a distinct decomposition of the input into its parts. The VNMF descriptor outperforms the statistical HOG descriptor, because it preserves spatial topology leading to better classification results on real-world human action recognition benchmarks  [11, 12] .",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-168.pdf,2014,85.8974358974359,"Beyond Histograms: Why Learned Structure-Preserving Descriptors Outperform HOG Statistical image descriptors based on histograms (e.g. SIFT [1], HOG  [2] ) are widely used in image processing, because they are fast and simple methods with high classification performance. However, they discard the local spatial topology and thus lose discriminative information contained in the image. We discuss the relations between HOG and VNMF descriptors, i.e. structure free histograms versus learned structure-preserving patterns. VNMF is a shift-invariant, sparse, nonnegative unsupervised learning algorithm  [8, 9, 5] , that provides a distinct decomposition of the input into its parts. The VNMF descriptor outperforms the statistical HOG descriptor, because it preserves spatial topology leading to better classification results on real-world human action recognition benchmarks  [11, 12] ."
A multi-class extension for multi-labeler support vector machines,"D Peluffo-Ordóñez, S Murillo-Rendón, J Arias-Londoño, G Castellanos-Domínguez","1 - Machine Learning Group -ICTEAM Université catholique de Louvain
2 - Grupo de Ingenierı ´a de Software Universidad Autónoma de Manizales
3 - Department of Systems Engineering Signal Processing and Recognition Group Universidad de Antioquia Universidad Nacional de Colombia
5 - Universidad Nacional de Colombia Grupo","In recent years, there has been an increasing interest in the design of pattern recognition systems able to deal with labels coming from multiple sources. To avoid bias during the learning process, in some applications it is strongly recommended to learn from a set of panelists or experts instead of only one. In particular, two aspects are of interest, namely: discriminating between confident and unconfident labelers, and determining the suitable ground truth. This work presents an extension of a previous work, which consists of a generalization of the two class case via a modified one-against-all approach. This approach uses modified classifiers able to learn from multi-labeler settings. This is done within a soft-margin support vector machine framework. Proposed method provides ranking values for panelist as well as an estimate of the ground truth.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-169.pdf,2014,100.0,"A multi-class extension for multi-labeler support vector machines In recent years, there has been an increasing interest in the design of pattern recognition systems able to deal with labels coming from multiple sources. To avoid bias during the learning process, in some applications it is strongly recommended to learn from a set of panelists or experts instead of only one. In particular, two aspects are of interest, namely: discriminating between confident and unconfident labelers, and determining the suitable ground truth. This work presents an extension of a previous work, which consists of a generalization of the two class case via a modified one-against-all approach. This approach uses modified classifiers able to learn from multi-labeler settings. This is done within a soft-margin support vector machine framework. Proposed method provides ranking values for panelist as well as an estimate of the ground truth."
Recent methods for dimensionality reduction: A brief comparative analysis,"Diego Peluffo, John Lee, Michel Verleysen","1 - Machine Learning Group -ICTEAM Université catholique de Louvain
3 - Molecular Imaging Radiotherapy and Oncology -IREC Université catholique de Louvain","Dimensionality reduction is a key stage for both the design of a pattern recognition system or data visualization. Recently, there has been a increasing interest in those methods aimed at preserving the data topology. Among them, Laplacian eigenmaps (LE) and stochastic neighbour embedding (SNE) are the most representative. In this work, we present a brief comparative among very recent methods being alternatives to LE and SNE. Comparisons are done mainly on two aspects: algorithm implementation, and complexity. Also, relations between methods are depicted. The goal of this work is providing researches on this field with some discussion as well as criteria decision to choose a method according to the user's needs and/or keeping a good trade-off between performance and required processing time.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-170.pdf,2014,100.0,"Recent methods for dimensionality reduction: A brief comparative analysis Dimensionality reduction is a key stage for both the design of a pattern recognition system or data visualization. Recently, there has been a increasing interest in those methods aimed at preserving the data topology. Among them, Laplacian eigenmaps (LE) and stochastic neighbour embedding (SNE) are the most representative. In this work, we present a brief comparative among very recent methods being alternatives to LE and SNE. Comparisons are done mainly on two aspects: algorithm implementation, and complexity. Also, relations between methods are depicted. The goal of this work is providing researches on this field with some discussion as well as criteria decision to choose a method according to the user's needs and/or keeping a good trade-off between performance and required processing time."
Speedy Greedy Feature Selection: Better Redshift Estimation via Massive Parallelism,"Fabian Gieseke, Kai Polsterer, Cosmin Oancea, Christian Igel","1 - Department of Computer Science University of Copenhagen Universitetsparken 5 2100 Copenhagen Denmark
2 - Heidelberg Institute for Theoretical Studies gGmbH -Astroinformatics Schloß Wolfsbrunnenweg 35 69118 Heidelberg Germany","Nearest neighbor models are among the most basic tools in machine learning, and recent work has demonstrated their effectiveness in the field of astronomy. The performance of these models crucially depends on the underlying metric, and in particular on the selection of a meaningful subset of informative features. The feature selection is task-dependent and usually very time-consuming. In this work, we propose an efficient parallel implementation of incremental feature selection for nearest neighbor models utilizing nowadays graphics processing units. Our framework provides significant computational speed-ups over its sequential single-core competitor of up to two orders of magnitude. We demonstrate the applicability of the overall scheme on one of the most challenging tasks in astronomy: redshift estimation for distant galaxies.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-171.pdf,2014,83.13253012048193,"Speedy Greedy Feature Selection: Better Redshift Estimation via Massive Parallelism Nearest neighbor models are among the most basic tools in machine learning, and recent work has demonstrated their effectiveness in the field of astronomy. The performance of these models crucially depends on the underlying metric, and in particular on the selection of a meaningful subset of informative features. The feature selection is task-dependent and usually very time-consuming. In this work, we propose an efficient parallel implementation of incremental feature selection for nearest neighbor models utilizing nowadays graphics processing units. Our framework provides significant computational speed-ups over its sequential single-core competitor of up to two orders of magnitude. We demonstrate the applicability of the overall scheme on one of the most challenging tasks in astronomy: redshift estimation for distant galaxies."
Classifying Patterns in a Spiking Neural Network,"Brian Gardner, André Grüning",1 - Department of Computing University of Surrey GU2 7XH Guildford Surrey United Kingdom,"Learning rules for spiking neural networks have emerged that can classify spatio-temporal spiking patterns as precise target spike trains, although there remains uncertainty in which rule to select that offers the greatest performance. Here, we quantify the performance of a stochastic neuron model in learning to classify input patterns by precise target responses as outputs, and compare its performance against other learning rules. We achieve a level of performance that is comparable with that found previously for alternative neuron models, and demonstrate the advantages of classifying inputs by multiple-spike timings: both by increasing the performance and the reliability of classifications.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-172.pdf,2014,100.0,"Classifying Patterns in a Spiking Neural Network Learning rules for spiking neural networks have emerged that can classify spatio-temporal spiking patterns as precise target spike trains, although there remains uncertainty in which rule to select that offers the greatest performance. Here, we quantify the performance of a stochastic neuron model in learning to classify input patterns by precise target responses as outputs, and compare its performance against other learning rules. We achieve a level of performance that is comparable with that found previously for alternative neuron models, and demonstrate the advantages of classifying inputs by multiple-spike timings: both by increasing the performance and the reliability of classifications."
Dynamic Ensemble Selection and Instantaneous Pruning for Regression,"Kaushala Dias, Terry Windeatt",1 - Centre for Vision Speech and Signal Processing Faculty of Engineering and Physical Sciences University of Surrey GU2 7XH Guildford Surrey United Kingdom,"A novel dynamic method of selecting pruned ensembles of predictors for regression problems is presented. The proposed method, known henceforth as DESIP, enhances the prediction accuracy and generalization ability of pruning methods. Pruning heuristics attempt to combine accurate yet complementary members, therefore DESIP enhances the performance by modifying the pruned aggregation through distributing the ensemble member selection over the entire dataset. Four static ensemble pruning approaches used in regression are compared to highlight the performance improvement yielded by the dynamic method. Experimental comparison is made using Multiple Layer Perceptron predictors on benchmark datasets.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-173.pdf,2014,80.59701492537313,"Dynamic Ensemble Selection and Instantaneous Pruning for Regression A novel dynamic method of selecting pruned ensembles of predictors for regression problems is presented. The proposed method, known henceforth as DESIP, enhances the prediction accuracy and generalization ability of pruning methods. Pruning heuristics attempt to combine accurate yet complementary members, therefore DESIP enhances the performance by modifying the pruned aggregation through distributing the ensemble member selection over the entire dataset. Four static ensemble pruning approaches used in regression are compared to highlight the performance improvement yielded by the dynamic method. Experimental comparison is made using Multiple Layer Perceptron predictors on benchmark datasets."
A New Approach for Multiple Instance Learning based on a Homogeneity Bag Operator,"A Faria, D Menotti, A Lemos, A Braga","1 - Graduate Program in Electrical Engineering -Federal University of Minas Gerais Av 31270-901 -Belo Horizonte 6627 Antônio Carlos, MG Brazil
2 - Computing Department Federal University of Ouro Preto Campus Universitário 35400-000 -Ouro Preto MG Brazil","Multiple Instance Learning (MIL) proposes a new paradigm when instance labeling, in the learning step, is not possible or infeasible, by assigning a single label (positive or negative) to a set of instances called bag. In this paper, an operator based on homogeneity of positive bags for MIL is introduced. Our method consists in removing instances from the positives bags according to their similarity with the ones from the negative bags. The experimental results show that our operator always increases the accuracy of the Citation kNN algorithm achieving the best results in 2 out of 4 datasets when compared with other classic methods in the literature.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-174.pdf,2014,71.60493827160495,"A New Approach for Multiple Instance Learning based on a Homogeneity Bag Operator Multiple Instance Learning (MIL) proposes a new paradigm when instance labeling, in the learning step, is not possible or infeasible, by assigning a single label (positive or negative) to a set of instances called bag. In this paper, an operator based on homogeneity of positive bags for MIL is introduced. Our method consists in removing instances from the positives bags according to their similarity with the ones from the negative bags. The experimental results show that our operator always increases the accuracy of the Citation kNN algorithm achieving the best results in 2 out of 4 datasets when compared with other classic methods in the literature."
Application of Newton's Method to Action Selection in Continuous State-and Action-Space Reinforcement Learning,"Barry Nichols, Dimitris Dracopoulos",1 - School of Science and Technology University of Westminster 115 New Cavendish St W1W 6XH London England,"An algorithm based on Newton's Method is proposed for action selection in continuous state-and action-space reinforcement learning without a policy network or discretization. The proposed method is validated on two benchmark problems: Cart-Pole and double Cart-Pole on which the proposed method achieves comparable or improved performance with less parameters to tune and in less training episodes than CACLA, which has previously been shown to outperform many other continuous state-and action-space reinforcement learning algorithms.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-175.pdf,2014,64.25339366515837,"Application of Newton's Method to Action Selection in Continuous State-and Action-Space Reinforcement Learning An algorithm based on Newton's Method is proposed for action selection in continuous state-and action-space reinforcement learning without a policy network or discretization. The proposed method is validated on two benchmark problems: Cart-Pole and double Cart-Pole on which the proposed method achieves comparable or improved performance with less parameters to tune and in less training episodes than CACLA, which has previously been shown to outperform many other continuous state-and action-space reinforcement learning algorithms."
Vector space weightless neural networks,"Wilson De Oliveira, Adenilton Da Silva, Teresa Ludermir","1 - Departamento de Estatíca e Informática Dois Irmãos-CEP Universidade Federal Rural de Pernambuco 52171-900 Recife PE, Brazil
2 - Universidade Federal de Pernambuco Centro de Informática Cidade Universitária","By embedding the boolean space Z2 as an orthonormal basis in a vector space we can treat the RAM based neuron as a matrix (operator) acting on the vector space. We show how this model (inspired by our research on quantum neural networks) is of sufficient generality as to have classical weighted (perceptronlike), classical weightless (RAM-based, PLN, etc), quantum weighted and quantum weightless neural models as particular cases. It is also indicated how one could use it to polynomially solve 3-SAT and briefly mention how could one train this novel model.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-176.pdf,2014,100.0,"Vector space weightless neural networks By embedding the boolean space Z2 as an orthonormal basis in a vector space we can treat the RAM based neuron as a matrix (operator) acting on the vector space. We show how this model (inspired by our research on quantum neural networks) is of sufficient generality as to have classical weighted (perceptronlike), classical weightless (RAM-based, PLN, etc), quantum weighted and quantum weightless neural models as particular cases. It is also indicated how one could use it to polynomially solve 3-SAT and briefly mention how could one train this novel model."
Data normalization and supervised learning to assess the condition of patients with multiple sclerosis based on gait analysis,"Samir Azrour, Sébastien Piérard, Pierre Geurts, Marc Van Droogenbroeck",1 - Department of Electrical Engineering and Computer Science University of Liège Sart-Tilman B28 4000 Liège Belgium,"Gait impairment is considered as an important feature of disability in multiple sclerosis but its evaluation in the clinical routine remains limited. In this paper, we assess, by means of supervised learning, the condition of patients with multiple sclerosis based on their gait descriptors obtained with a gait analysis system. As the morphological characteristics of individuals influence their gait while being in first approximation independent of the disease level, an original strategy of data normalization with respect to these characteristics is described and applied beforehand in order to obtain more reliable predictions. In addition, we explain how we address the problem of missing data which is a common issue in the field of clinical evaluation. Results show that, based on machine learning combined to the proposed data handling techniques, we can predict a score highly correlated with the condition of patients.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-178.pdf,2014,100.0,"Data normalization and supervised learning to assess the condition of patients with multiple sclerosis based on gait analysis Gait impairment is considered as an important feature of disability in multiple sclerosis but its evaluation in the clinical routine remains limited. In this paper, we assess, by means of supervised learning, the condition of patients with multiple sclerosis based on their gait descriptors obtained with a gait analysis system. As the morphological characteristics of individuals influence their gait while being in first approximation independent of the disease level, an original strategy of data normalization with respect to these characteristics is described and applied beforehand in order to obtain more reliable predictions. In addition, we explain how we address the problem of missing data which is a common issue in the field of clinical evaluation. Results show that, based on machine learning combined to the proposed data handling techniques, we can predict a score highly correlated with the condition of patients."
Context-and cost-aware feature selection in ultra-low-power sensor interfaces,"Steven Lauwereins, Komail Badami, Wannes Meert, Marian Verhelst","1 - -KU Leuven -ESAT-MICAS Kasteelpark Arenberg 10 B-3001 Heverlee Belgium
3 - KU Leuven -CS-DTAI Celestijnenlaan 200A B-3001 Heverlee Belgium","This paper introduces the use of machine learning to improve efficiency of ultra-low-power sensor interfaces. Adaptive feature extraction circuits are assisted by hardware embedded learning to dynamically activate only most relevant features. This selection is done in a context and power cost-aware way, through modification of the C4.5 algorithm. Furthermore, context dependence of different feature sets is explained. As proof-of-principle, a Voice Activity Detector is expanded with the proposed context-and cost-dependent voice/noise classifier, resulting in an average circuit power savings of 75%, with negligible accuracy loss.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-179.pdf,2014,99.35483870967742,"Context-and cost-aware feature selection in ultra-low-power sensor interfaces This paper introduces the use of machine learning to improve efficiency of ultra-low-power sensor interfaces. Adaptive feature extraction circuits are assisted by hardware embedded learning to dynamically activate only most relevant features. This selection is done in a context and power cost-aware way, through modification of the C4.5 algorithm. Furthermore, context dependence of different feature sets is explained. As proof-of-principle, a Voice Activity Detector is expanded with the proposed context-and cost-dependent voice/noise classifier, resulting in an average circuit power savings of 75%, with negligible accuracy loss."
Finding Originally Mislabels with MD-ELM,"Anton Akusok, David Veganzones, Yoan Miche, Eric Severin, Amaury Lendasse","1 - Dept. of Information and Computer Science Aalto University School of Science FI-00076 Finland
2 - Dept. of Computer Science & Artificial Intelligence Univ. del Pais Vasco Donostia/San Sebastian Spain
4 - University of Lille 1 IAE 104 avenue du peuple Belge 59043 Lille France
7 - Basque Foundation for Science IKERBASQUE 48011 Bilbao Spain
8 - Arcada Univ. of Applied Science Helsinki Finland","This paper presents a methodology which aims at detecting mislabeled samples, with a practical example in the field of bankruptcy prediction. Mislabeled samples are found in many classification problems and can bias the training of the desired classifier. This paper proposes a new method based on Extreme Learning Machine (ELM) which allows for identification of the most probable mislabeled samples. Two datasets are used in order to validate and test the proposed methodology: a toy example (XOR problem) and a real dataset from corporate finance (bankruptcy prediction).",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-18.pdf,2014,100.0,"Finding Originally Mislabels with MD-ELM This paper presents a methodology which aims at detecting mislabeled samples, with a practical example in the field of bankruptcy prediction. Mislabeled samples are found in many classification problems and can bias the training of the desired classifier. This paper proposes a new method based on Extreme Learning Machine (ELM) which allows for identification of the most probable mislabeled samples. Two datasets are used in order to validate and test the proposed methodology: a toy example (XOR problem) and a real dataset from corporate finance (bankruptcy prediction)."
A new model selection approach for the ELM network using metaheuristic optimization,"Ananda Freire, Guilherme Barreto","1 - Department of Teleinformatics Engineering (DETI) Av. Mister Hull S/N -Center of Technology Federal University of Ceará (UFC) Campus of Pici Fortaleza, Ceará Brazil","We propose a novel approach for architecture selection and hidden neurons excitability improvement for the Extreme Learning Machine (ELM). Named Adaptive Number of Hidden Neurons Approach (ANHNA), the proposed approach relies on a new general encoding scheme of the solution vector that automatically estimates the number of hidden neurons and adjust their activation function parameters (slopes and biases). Due to its general nature, ANHNA's encoding scheme can be used by any metaheuristic algorithm for continuous optimization. Computer experiments were carried out using Differential Evolution (DE) and Particle Swarm Optimization (PSO) metaheuristics, with promising results being achieved by the proposed method in benchmarking regression problems.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-180.pdf,2014,100.0,"A new model selection approach for the ELM network using metaheuristic optimization We propose a novel approach for architecture selection and hidden neurons excitability improvement for the Extreme Learning Machine (ELM). Named Adaptive Number of Hidden Neurons Approach (ANHNA), the proposed approach relies on a new general encoding scheme of the solution vector that automatically estimates the number of hidden neurons and adjust their activation function parameters (slopes and biases). Due to its general nature, ANHNA's encoding scheme can be used by any metaheuristic algorithm for continuous optimization. Computer experiments were carried out using Differential Evolution (DE) and Particle Swarm Optimization (PSO) metaheuristics, with promising results being achieved by the proposed method in benchmarking regression problems."
Training a classical weightless neural network in a quantum computer,"Adenilton Da Silva, Wilson De Oliveira, Teresa Ludermir","1 - Universidade Federal de Pernambuco -Centro de Informática Cidade Universitária 50740-560 Recife PE, Brazil
2 - Departamento de Estatística e Informática Dois Irmãos -CEP Universidade Federal Rural de Pernambuco 52171-900 Recife PE",The purpose of this paper is to investigate a new quantum learning algorithm for classical weightless neural networks. The learning algorithm creates a superposition of all possible neural network configurations for a given architecture. The performance of the network over the training set is stored entangled with neural configuration and quantum search is performed to amplify the probability amplitude of the network with desired performance.,Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-182.pdf,2014,100.0,Training a classical weightless neural network in a quantum computer The purpose of this paper is to investigate a new quantum learning algorithm for classical weightless neural networks. The learning algorithm creates a superposition of all possible neural network configurations for a given architecture. The performance of the network over the training set is stored entangled with neural configuration and quantum search is performed to amplify the probability amplitude of the network with desired performance.
An Extreme Learning Approach to Active Learning,"Euler Guimarães Horta, Antônio Pádua Braga","1 - Instituto de Ciência e Tecnologia Universidade Federal dos Vales do Jequitinhonha e Mucuri Diamantina MG Brazil
2 - Programa de Pós-Graduação em Engenharia Elétrica Universidade Federal de Minas Gerais Av 6627, 31270-901 Belo Horizonte Antônio Carlos, MG Brasil",We propose in this paper a new active learning method that makes no considerations about the data distribution and does not need to adjust any free parameter. The proposed algorithm is based on extreme learning machines (ELM) and a perceptron with analytical calculation of weights. We show that the proposed model have good results using a reduced set of patterns.,"Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-184.pdf,2014,100.0,An Extreme Learning Approach to Active Learning We propose in this paper a new active learning method that makes no considerations about the data distribution and does not need to adjust any free parameter. The proposed algorithm is based on extreme learning machines (ELM) and a perceptron with analytical calculation of weights. We show that the proposed model have good results using a reduced set of patterns.
Improving the Robustness of Bagging with Reduced Sampling Size,"Maryam Sabzevari, Gonzalo Martínez-Muñoz, Alberto Suárez","1 - Escuela Politécnica Superior Francisco Tomás y Valiente 11
2 - Universidad Autónoma de Madrid 28049) Madrid Spain","Bagging is a simple and robust classification algorithm in the presence of class label noise. This algorithm builds an ensemble of classifiers by bootstrapping samples with replacement of size equal to the original training set. However, several studies have shown that this choice of sampling size is arbitrary in terms of generalization performance of the ensemble. In this study we discuss how small sampling ratios can contribute to the robustness of bagging in the presence of class label noise. An empirical analysis on two datasets is carried out using different noise rates and bootstrap sampling sizes. The results show that, for the studied datasets, sampling rates of 20% clearly improve the performance of the bagging ensembles in the presence of class label noise. * The authors acknowledge financial support from the Spanish Dirección General de Investigación, project TIN2010-21575-C02-02",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-185.pdf,2014,100.0,"Improving the Robustness of Bagging with Reduced Sampling Size Bagging is a simple and robust classification algorithm in the presence of class label noise. This algorithm builds an ensemble of classifiers by bootstrapping samples with replacement of size equal to the original training set. However, several studies have shown that this choice of sampling size is arbitrary in terms of generalization performance of the ensemble. In this study we discuss how small sampling ratios can contribute to the robustness of bagging in the presence of class label noise. An empirical analysis on two datasets is carried out using different noise rates and bootstrap sampling sizes. The results show that, for the studied datasets, sampling rates of 20% clearly improve the performance of the bagging ensembles in the presence of class label noise. * The authors acknowledge financial support from the Spanish Dirección General de Investigación, project TIN2010-21575-C02-02"
Toward STDP-based population action in large networks of spiking neurons,Emmanuel Daucé,"1 - INSERM UMR 1106 -Institut de Neuroscience des Systèmes Faculté de Médecine de la Timone -Aix-Marseille University France
2 - Centrale Marseille France","We present simulation results that clarify the role of Spike-Timing Dependent Plasticity (STDP) in brain processing as a putative mechanism to transfer spatio-temporal regularities, as observed in sensory signals, toward action, expressed as a global increase of the target population activity, followed by a reset. The repetition of this activation-reset mechanism gives rise to a series of synchronous waves of activity when the same stimulus is repeated over and over. Our simulation results are obtained in recurrent networks of conductance-based neurons under realistic coupling contraints.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-186.pdf,2014,100.0,"Toward STDP-based population action in large networks of spiking neurons We present simulation results that clarify the role of Spike-Timing Dependent Plasticity (STDP) in brain processing as a putative mechanism to transfer spatio-temporal regularities, as observed in sensory signals, toward action, expressed as a global increase of the target population activity, followed by a reset. The repetition of this activation-reset mechanism gives rise to a series of synchronous waves of activity when the same stimulus is repeated over and over. Our simulation results are obtained in recurrent networks of conductance-based neurons under realistic coupling contraints."
Evidence build-up facilitates on-line adaptivity in dynamic environments: example of the BCI P300-speller,"Emmanuel Daucé, Eoin Thomas","1 - INSERM UMR 1106 -Institut de Neuroscience des Systèmes Faculté de Médecine de la Timone -Aix-Marseille Université France
2 - Centrale Marseille France
3 - INRIA Lille Nord Europe France",We consider a P300 BCI application where the subjects can write figures and letters in an unsupervised fashion. We (i) show that a generic speller can attain the state-of-the-art accuracy without any training phase or calibration and (ii) present an adaptive setup that consistently increases the bit rate for most of the subjects.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-188.pdf,2014,100.0,Evidence build-up facilitates on-line adaptivity in dynamic environments: example of the BCI P300-speller We consider a P300 BCI application where the subjects can write figures and letters in an unsupervised fashion. We (i) show that a generic speller can attain the state-of-the-art accuracy without any training phase or calibration and (ii) present an adaptive setup that consistently increases the bit rate for most of the subjects.
DELA: A Dynamic Online Ensemble Learning Algorithm,"Abdelhamid Bouchachia, Emili Balaguer-Ballester",1 - Faculty of Science and Technology Bournemouth University UK,"The present paper investigates the problem of prediction in the context of dynamically changing environment, where data arrive over time. A Dynamic online Ensemble Learning Algorithm (DELA) is introduced. The adaptivity concerns three levels: structural adaptivity, combination adaptivity and model adaptivity. In particular, the structure of the ensemble is sought to evolve in order to be able to deal with the problem of data drift. The proposed online ensemble is evaluated on the stagger data set to show its predictive power in presence of data drift.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-189.pdf,2014,100.0,"DELA: A Dynamic Online Ensemble Learning Algorithm The present paper investigates the problem of prediction in the context of dynamically changing environment, where data arrive over time. A Dynamic online Ensemble Learning Algorithm (DELA) is introduced. The adaptivity concerns three levels: structural adaptivity, combination adaptivity and model adaptivity. In particular, the structure of the ensemble is sought to evolve in order to be able to deal with the problem of data drift. The proposed online ensemble is evaluated on the stagger data set to show its predictive power in presence of data drift."
Weighted Tree Kernels for Sequence Analysis,"Christopher Bowles, James Hogan",1 - School of Electrical Engineering and Computer Science Queensland University of Technology 2 George St 4000 Brisbane QLD AUSTRALIA,"Genomic sequences are fundamentally text documents, admitting various representations according to need and tokenization. Gene expression depends crucially on binding of enzymes to the DNA sequence at small, poorly conserved binding sites, limiting the utility of standard pattern search. However, one may exploit the regular syntactic structure of the enzyme's component proteins and the corresponding binding sites, framing the problem as one of detecting grammatically correct genomic phrases. In this paper we propose new kernels based on weighted tree structures, traversing the paths within them to capture the features which underpin the task. Experimentally, we find that these kernels provide performance comparable with state of the art approaches for this problem, while offering significant computational advantages over earlier methods. The methods proposed may be applied to a broad range of sequence or tree-structured data in molecular biology and other domains.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-190.pdf,2014,60.46511627906976,"Weighted Tree Kernels for Sequence Analysis Genomic sequences are fundamentally text documents, admitting various representations according to need and tokenization. Gene expression depends crucially on binding of enzymes to the DNA sequence at small, poorly conserved binding sites, limiting the utility of standard pattern search. However, one may exploit the regular syntactic structure of the enzyme's component proteins and the corresponding binding sites, framing the problem as one of detecting grammatically correct genomic phrases. In this paper we propose new kernels based on weighted tree structures, traversing the paths within them to capture the features which underpin the task. Experimentally, we find that these kernels provide performance comparable with state of the art approaches for this problem, while offering significant computational advantages over earlier methods. The methods proposed may be applied to a broad range of sequence or tree-structured data in molecular biology and other domains."
Electric Load Forecasting Using Wavelet Transform and Extreme Learning Machine,"Song Li, Peng Wang, Lalit Goel","1 - School of Electrical and Electronic Engineering Nanyang Technological University 50 Nanyang Avenue 639798 Singapore, Singapore","This paper proposes a novel method for load forecast, which integrates wavelet transform and extreme learning machine. In order to capture more internal features, wavelet transform is used to decompose the load series into a set of subcomponents, which are more predictable. Then all the components are separately processed by extreme learning machine. Numerical testing shows that the proposed method is able to improve the forecast performance with much less computational cost compared with other benchmarking methods. 
 Proposed Hybrid Method 
 Wavelet transform A family of wavelet and scaling functions can be derived from the mother wavelet ψ(t) and the scaling function φ(t)","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-23.pdf,2014,84.61538461538461,"Electric Load Forecasting Using Wavelet Transform and Extreme Learning Machine This paper proposes a novel method for load forecast, which integrates wavelet transform and extreme learning machine. In order to capture more internal features, wavelet transform is used to decompose the load series into a set of subcomponents, which are more predictable. Then all the components are separately processed by extreme learning machine. Numerical testing shows that the proposed method is able to improve the forecast performance with much less computational cost compared with other benchmarking methods. 
 Proposed Hybrid Method 
 Wavelet transform A family of wavelet and scaling functions can be derived from the mother wavelet ψ(t) and the scaling function φ(t)"
Learning with Few Bits on Small-Scale Devices: from Regularization to Energy Efficiency,"Davide Anguita, Alessandro Ghio, Luca Oneto, Sandro Ridella",1 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy,"The implementation of Machine Learning (ML) algorithms on stand-alone small-scale devices allows the incorporation of new services and advanced functionalities without the need of resorting to remote computing systems. Despite having undeniable advantages with respect to conventional general-purpose devices, e.g. in terms of cost/performance ratios, small-scale systems suffer of issues related to their resource-limited nature, like limited battery capacity and processing power. In order to deal with such limitations, we propose to merge local Rademacher Complexities and bit-based hypothesis spaces to build thrifty models, which can be effectively implemented on small-scale resource-limited devices. Experiments, carried out on a smartphone in a Human Activity Recognition application, show the benefits of the proposed approach in terms of model accuracy and battery duration.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-27.pdf,2014,73.5632183908046,"Learning with Few Bits on Small-Scale Devices: from Regularization to Energy Efficiency The implementation of Machine Learning (ML) algorithms on stand-alone small-scale devices allows the incorporation of new services and advanced functionalities without the need of resorting to remote computing systems. Despite having undeniable advantages with respect to conventional general-purpose devices, e.g. in terms of cost/performance ratios, small-scale systems suffer of issues related to their resource-limited nature, like limited battery capacity and processing power. In order to deal with such limitations, we propose to merge local Rademacher Complexities and bit-based hypothesis spaces to build thrifty models, which can be effectively implemented on small-scale resource-limited devices. Experiments, carried out on a smartphone in a Human Activity Recognition application, show the benefits of the proposed approach in terms of model accuracy and battery duration."
Fine-Tuning of Support Vector Machine Parameters using Racing Algorithms,"Péricles Miranda, Ricardo Silva, Ricardo Prudêncio",1 - Centro de Informática Universidade Federal de Pernambuco Brazil,"This paper investigates the iterative racing approach, I/F-Race, for selecting parameters of SVMs. As a racing algorithm, I/F-Race eliminates candidate models as soon as there is sufficient statistical evidence of their inferiority relative to other models with respect to the objective. The results revealed that the I/F-Race algorithm was able to achieve better parameter values in comparison to default parameters used in literature and parameters suggested by particle swarm optimization techniques.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-28.pdf,2014,63.888888888888886,"Fine-Tuning of Support Vector Machine Parameters using Racing Algorithms This paper investigates the iterative racing approach, I/F-Race, for selecting parameters of SVMs. As a racing algorithm, I/F-Race eliminates candidate models as soon as there is sufficient statistical evidence of their inferiority relative to other models with respect to the objective. The results revealed that the I/F-Race algorithm was able to achieve better parameter values in comparison to default parameters used in literature and parameters suggested by particle swarm optimization techniques."
Extreme Learning Machines for Internet Traffic Classification,"Joseph Ghafari, Emmanuel Herbert, Stephane Senecal, Daniel Migault, Stanislas Francfort, Ting Liu","1 - Ecole des Mines de Nantes -GIPAD Dept 4 rue Alfred Kastler 44300 Nantes France
2 - 1-Orange Labs 38-40 rue du General Leclerc 92130 Issy-les-Moulineaux France",Network packet transport services (namely the Internet) are subject to significant security issues. This paper aims to apply Machine Learning methods based on Neural Networks (Extreme Learning Machines or ELM) to analyze the Internet traffic in order to detect specific malicious activities. This is performed by classifying traffic for a key service run over the internet: the Domain Name System (DNS). The ELM models and algorithms are run on DNS traffic data extracted from operating networks for botnet detection.,Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-155.pdf,2014,64.74820143884892,Extreme Learning Machines for Internet Traffic Classification Network packet transport services (namely the Internet) are subject to significant security issues. This paper aims to apply Machine Learning methods based on Neural Networks (Extreme Learning Machines or ELM) to analyze the Internet traffic in order to detect specific malicious activities. This is performed by classifying traffic for a key service run over the internet: the Domain Name System (DNS). The ELM models and algorithms are run on DNS traffic data extracted from operating networks for botnet detection.
Proximity learning for non-standard big data,Frank-Michael Schleif,1 - School of Computer Science The University of Birmingham Edgbaston Birmingham B15 2TT United Kingdom,"Huge and heterogeneous data sets, e.g. in the life science domain, are challenging for most data analysis algorithms. State of the art approaches do often not scale to larger problems or are inaccessible due to the variety of the data formats. A flexible and effective method to analyze a large variety of data formats is given by proximity learning methods, currently limited to medium size, metric data. Here we discuss novel strategies to open relational methods for non-standard data at large scale, applied to a very large protein sequence database.",Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-33.pdf,2014,100.0,"Proximity learning for non-standard big data Huge and heterogeneous data sets, e.g. in the life science domain, are challenging for most data analysis algorithms. State of the art approaches do often not scale to larger problems or are inaccessible due to the variety of the data formats. A flexible and effective method to analyze a large variety of data formats is given by proximity learning methods, currently limited to medium size, metric data. Here we discuss novel strategies to open relational methods for non-standard data at large scale, applied to a very large protein sequence database."
Tensor Decomposition of Dense SIFT Descriptors in Object Recognition,"Tan Vo, Dat Tran, Wanli Ma","1 - Faculty of Education, Science, Technology and Mathematics University of Canberra Australia","In machine vision, Scale-invariant feature transform (SIFT) and its variants have been widely used in image classification task. However, the high dimensionality nature of SIFT features, usually in the order of multiple thousands per image, would require careful consideration in place to achieve accurate and timely categorization of objects within images. This paper explores the possibility of processing SIFT features as tensors and uses tensor decomposition techniques on high-order SIFT tensors for dimensionality reduction. The method focuses on both accuracy and efficiency aspects and the validation result with the Caltech 101 dataset confirms the improvement with notable margins.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-34.pdf,2014,66.17647058823529,"Tensor Decomposition of Dense SIFT Descriptors in Object Recognition In machine vision, Scale-invariant feature transform (SIFT) and its variants have been widely used in image classification task. However, the high dimensionality nature of SIFT features, usually in the order of multiple thousands per image, would require careful consideration in place to achieve accurate and timely categorization of objects within images. This paper explores the possibility of processing SIFT features as tensors and uses tensor decomposition techniques on high-order SIFT tensors for dimensionality reduction. The method focuses on both accuracy and efficiency aspects and the validation result with the Caltech 101 dataset confirms the improvement with notable margins."
Joint SVM for Accurate and Fast Image Tagging,"Hanchen Xiong, Sandor Szedmak, Justus Piater",1 - Institute of Computer Science University of Innsbruck Technikerstr A-6020 Innsbruck Austria,"This paper studies how joint training of multiple support vector machines (SVMs) can improve the effectiveness and efficiency of automatic image annotation. We cast image annotation as an output-related multi-task learning framework, with the prediction of each tag's presence as one individual task. Evidently, these tasks are related via correlations between tags. The proposed joint learning framework, which we call joint SVM, can encode the correlation between tags by defining appropriate kernel functions on the outputs. Another practical merit of the joint SVM is that it shares the same computational complexity as one single conventional SVM, although multiple tasks are solved simultaneously. According to our empirical results on an image-annotation benchmark database, our joint training strategy of SVMs can yield substantial improvements, in terms of both accuracy and efficiency, over training them independently. In particular, it outperforms many other state-of-the-art algorithms.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-35.pdf,2014,100.0,"Joint SVM for Accurate and Fast Image Tagging This paper studies how joint training of multiple support vector machines (SVMs) can improve the effectiveness and efficiency of automatic image annotation. We cast image annotation as an output-related multi-task learning framework, with the prediction of each tag's presence as one individual task. Evidently, these tasks are related via correlations between tags. The proposed joint learning framework, which we call joint SVM, can encode the correlation between tags by defining appropriate kernel functions on the outputs. Another practical merit of the joint SVM is that it shares the same computational complexity as one single conventional SVM, although multiple tasks are solved simultaneously. According to our empirical results on an image-annotation benchmark database, our joint training strategy of SVMs can yield substantial improvements, in terms of both accuracy and efficiency, over training them independently. In particular, it outperforms many other state-of-the-art algorithms."
Predicting Grain Protein Content of Winter Wheat,"Mansouri Majdi, Dumont Benjamin","1 - Département des Sciences et Technologies de l'Environnement, GxABT Université de Liège
2 - Passage des Déportés 5030 Gembloux Belgium","The objective of this paper is to propose to use a new Improved Particle Filtering (IPF) based on minimizing Kullback-Leibler divergence for crop models' predictions. The performances of the method are compared with those of the conventional Particle Filtering (PF) at a complex crop model (AZODYN) to predict an important winter-wheat quality criterion, namely the grain protein content. Furthermore, the effect of measurement noise (e.g., different signal-to-noise ratios) on the performances of PF and IPF is investigated. The results of the comparative studies show that the IPF provides a significant improvement over the PF because, unlike the PF which depends on the choice of sampling distribution used to estimate the posterior distribution, the IPF yields an optimum choice of the sampling distribution, which also accounts for the observed data. The efficiency of IPF is expressed in terms of estimation accuracy (root mean square error).",Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-36.pdf,2014,100.0,"Predicting Grain Protein Content of Winter Wheat The objective of this paper is to propose to use a new Improved Particle Filtering (IPF) based on minimizing Kullback-Leibler divergence for crop models' predictions. The performances of the method are compared with those of the conventional Particle Filtering (PF) at a complex crop model (AZODYN) to predict an important winter-wheat quality criterion, namely the grain protein content. Furthermore, the effect of measurement noise (e.g., different signal-to-noise ratios) on the performances of PF and IPF is investigated. The results of the comparative studies show that the IPF provides a significant improvement over the PF because, unlike the PF which depends on the choice of sampling distribution used to estimate the posterior distribution, the IPF yields an optimum choice of the sampling distribution, which also accounts for the observed data. The efficiency of IPF is expressed in terms of estimation accuracy (root mean square error)."
Multi-Step Ahead Forecasting of Road Condition Using Least Squares Support Vector Regression,Konsta Sirvio,1 - Department of Information and Computer Science Aalto University School of Science P.O.Box 15400 FI-00076 Aalto Finland,"Network-level multi-step road condition forecasting is an important step in accurate road maintenance planning, where correct maintenance activities are defined in place and time of road networks. Forecasting methods have developed from engineering models to non-linear machine learning methods that make use of the collected condition and traffic data of the road network. Least Squares Support Vector Regression gives significantly the best results compared to Radial Basis Function networks or multiple linear regression.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-37.pdf,2014,100.0,"Multi-Step Ahead Forecasting of Road Condition Using Least Squares Support Vector Regression Network-level multi-step road condition forecasting is an important step in accurate road maintenance planning, where correct maintenance activities are defined in place and time of road networks. Forecasting methods have developed from engineering models to non-linear machine learning methods that make use of the collected condition and traffic data of the road network. Least Squares Support Vector Regression gives significantly the best results compared to Radial Basis Function networks or multiple linear regression."
Linear Scalarized Knowledge Gradient in the Multi-Objective Multi-Armed Bandits Problem,"Saba Yahyaa, Madalina Drugan, Bernard Manderick","1 - Computational Modeling group Computer Science Department Artificial Intelligence Lab Vrije Universiteit Brussel Pleinlaan 2 1050 Brussels, syahyaa, mdrugan Belgium","The multi-objective, multi-armed bandits (MOMABs) problem is a Markov decision process with stochastic rewards. Each arm generates a vector of rewards instead of a single reward and these multiple rewards might be conflicting. The agent has a set of optimal arms and the agent's goal is not only finding the optimal arms, but also playing them fairly. To find the optimal arm set, the agent uses a linear scalarized (LS) function which converts the multi-objective arms into one-objective arms. LS function is simple, however it can not find all the optimal arm set. As a result, we extend knowledge gradient (KG) policy to LS function. We propose two variants of linear scalarized-KG, LS-KG across arms and dimensions. We experimentally compare the two variant, LS-KG across arms finds the optimal arm set, while LS-KG across dimensions plays fairly the optimal arms.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-39.pdf,2014,100.0,"Linear Scalarized Knowledge Gradient in the Multi-Objective Multi-Armed Bandits Problem The multi-objective, multi-armed bandits (MOMABs) problem is a Markov decision process with stochastic rewards. Each arm generates a vector of rewards instead of a single reward and these multiple rewards might be conflicting. The agent has a set of optimal arms and the agent's goal is not only finding the optimal arms, but also playing them fairly. To find the optimal arm set, the agent uses a linear scalarized (LS) function which converts the multi-objective arms into one-objective arms. LS function is simple, however it can not find all the optimal arm set. As a result, we extend knowledge gradient (KG) policy to LS function. We propose two variants of linear scalarized-KG, LS-KG across arms and dimensions. We experimentally compare the two variant, LS-KG across arms finds the optimal arm set, while LS-KG across dimensions plays fairly the optimal arms."
Reject Option Paradigm for the Reduction of Support Vectors,"Ricardo Sousa, Ajalmar Da Rocha Neto, Guilherme Barreto, Jaime Cardoso, Miguel Coimbra","1 - Instituto de Telecomunicações Faculdade de Ciências da Universidade do Porto
2 - Federal Institute of Ceará
3 - Departamento Engenharia de Teleinformática Universidade Federal do Ceará 4-INESC TEC and Faculdade de Engenharia da Universidade do Porto",In this paper we introduce a new conceptualization for the reduction of the number of support vectors (SVs) for an efficient design of support vector machines. The techniques here presented provide a good balance between SVs reduction and generalization capability. Our proposal explores concepts from classification with reject option. These methods output a third class (the rejected instances) for a binary problem when a prediction cannot be given with sufficient confidence. Rejected instances along with misclassified ones are discarded from the original data to give rise to a classification problem that can be linearly solved. Our experimental study on two benchmark datasets show significant gains in terms of SVs reduction with competitive performances.,Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-4.pdf,2014,71.1864406779661,Reject Option Paradigm for the Reduction of Support Vectors In this paper we introduce a new conceptualization for the reduction of the number of support vectors (SVs) for an efficient design of support vector machines. The techniques here presented provide a good balance between SVs reduction and generalization capability. Our proposal explores concepts from classification with reject option. These methods output a third class (the rejected instances) for a binary problem when a prediction cannot be given with sufficient confidence. Rejected instances along with misclassified ones are discarded from the original data to give rise to a classification problem that can be linearly solved. Our experimental study on two benchmark datasets show significant gains in terms of SVs reduction with competitive performances.
On the complexity of shallow and deep neural network classifiers,"Monica Bianchini, Franco Scarselli",1 - Department of Information Engineering and Mathematics University of Siena Via Roma 56 I-53100 Siena ITALY,"Recently, deep networks were proved to be more effective than shallow architectures to face complex real-world applications. However, theoretical results supporting this claim are still few and incomplete. In this paper, we propose a new topological measure to study how the depth of feedforward networks impacts on their ability of implementing high complexity functions. Upper and lower bounds on network complexity are established, based on the number of hidden units and on their activation functions, showing that deep architectures are able, with the same number of resources, to address more difficult classification problems.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-44.pdf,2014,100.0,"On the complexity of shallow and deep neural network classifiers Recently, deep networks were proved to be more effective than shallow architectures to face complex real-world applications. However, theoretical results supporting this claim are still few and incomplete. In this paper, we propose a new topological measure to study how the depth of feedforward networks impacts on their ability of implementing high complexity functions. Upper and lower bounds on network complexity are established, based on the number of hidden units and on their activation functions, showing that deep architectures are able, with the same number of resources, to address more difficult classification problems."
Toward parallel feature selection from vertically partitioned data,"Verónica Bolón-Canedo, Noelia Sánchez-Maroño, Joana Cerviño-Rabuñal",1 - Department of Computer Science University of A Coruña Campus de Elviña s/n 15071 -A Coruña Spain,"Feature selection is often required as a preliminary step for many pattern recognition problems. In recent years, parallel learning has been the focus of much attention due to the advent of high dimensionality. Still, most of the existing algorithms only work in a centralized manner, i.e. using the whole dataset at once. This paper proposes a parallel filter approach for vertically partitioned data. The idea is to split the data by features and then apply a filter at each partition performing several rounds to obtain a stable set of features. Later, a merging procedure is carried out to combine the results into a single subset of relevant features. Experiments on three representative datasets show that the execution time is considerably shortened whereas the performance is maintained or even improved compared to the standard algorithms applied to the non-partitioned datasets. The proposed approach can be used with any filter algorithm, so it could be seen as a general framework for parallel feature selection.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-45.pdf,2014,100.0,"Toward parallel feature selection from vertically partitioned data Feature selection is often required as a preliminary step for many pattern recognition problems. In recent years, parallel learning has been the focus of much attention due to the advent of high dimensionality. Still, most of the existing algorithms only work in a centralized manner, i.e. using the whole dataset at once. This paper proposes a parallel filter approach for vertically partitioned data. The idea is to split the data by features and then apply a filter at each partition performing several rounds to obtain a stable set of features. Later, a merging procedure is carried out to combine the results into a single subset of relevant features. Experiments on three representative datasets show that the execution time is considerably shortened whereas the performance is maintained or even improved compared to the standard algorithms applied to the non-partitioned datasets. The proposed approach can be used with any filter algorithm, so it could be seen as a general framework for parallel feature selection."
Bayesian Non-Parametric Parsimonious Clustering,"Faicel Chamroukhi, Marius Bartcus, Hervé Glotin","1 - UMR 7296 Aix Marseille Université CNRS ENSAM, LSIS 13397 Marseille France
2 - UMR 7296 Université de Toulon CNRS LSIS 83957 La Garde France
7 - Institut Universitaire de France","This paper proposes a new Bayesian non-parametric approach for clustering. It relies on an infinite Gaussian mixture model with a Chinese Restaurant Process (CRP) prior, and an eigenvalue decomposition of the covariance matrix of each cluster. The CRP prior allows to control the model complexity in a principled way and to automatically learn the number of clusters. The covariance matrix decomposition allows to fit various parsimonious models going from simplest spherical ones to the more complex general one. We develop an MCMC Gibbs sampler to learn the models. First results obtained on both simulated and real data highlight the interest of the proposed infinite parsimonious mixture model.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-46.pdf,2014,91.48936170212765,"Bayesian Non-Parametric Parsimonious Clustering This paper proposes a new Bayesian non-parametric approach for clustering. It relies on an infinite Gaussian mixture model with a Chinese Restaurant Process (CRP) prior, and an eigenvalue decomposition of the covariance matrix of each cluster. The CRP prior allows to control the model complexity in a principled way and to automatically learn the number of clusters. The covariance matrix decomposition allows to fit various parsimonious models going from simplest spherical ones to the more complex general one. We develop an MCMC Gibbs sampler to learn the models. First results obtained on both simulated and real data highlight the interest of the proposed infinite parsimonious mixture model."
Implicitly and Explicitly Constrained Optimization Problems for Training of Recurrent Neural Networks,Carl-Johan Thore,1 - Division of Mechanics Linköping University 581 83 Linköping Sweden,"Training of recurrent neural networks is typically formulated as unconstrained optimization problems. There is, however, an implicit constraint stating that the equations of state must be satisfied at every iteration in the optimization process. Such constraints can make a problem highly non-linear and thus difficult to solve. A potential remedy is to reformulate the problem into one in which the parameters and state are treated as independent variables and all constraints appear explicitly. In this paper we compare an implicitly and an explicitly constrained formulation of the same problem. Reported numerical results suggest that the latter is in some respects superior.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-49.pdf,2014,71.28712871287128,"Implicitly and Explicitly Constrained Optimization Problems for Training of Recurrent Neural Networks Training of recurrent neural networks is typically formulated as unconstrained optimization problems. There is, however, an implicit constraint stating that the equations of state must be satisfied at every iteration in the optimization process. Such constraints can make a problem highly non-linear and thus difficult to solve. A potential remedy is to reformulate the problem into one in which the parameters and state are treated as independent variables and all constraints appear explicitly. In this paper we compare an implicitly and an explicitly constrained formulation of the same problem. Reported numerical results suggest that the latter is in some respects superior."
A new biologically plausible supervised learning method for spiking neurons,"Aboozar Taherkhani, Ammar Belatreche, Yuhua Li, Liam Maguire",1 - Intelligent Systems Research Centre University of Ulster U.K,"STDP is believed to play an important role in learning and memory. Additionally, experimental evidence shows that a few strong neural inputs can drive a neuron response and subsequently affect the learning of other inputs. Furthermore, recent studies have shown that local dendritic depolarization can impact STDP induction. This paper integrates these three biological concepts to devise a new biologically plausible supervised learning method for spiking neurons. Experimental results show that the proposed method can effectively map a random spatiotemporal input pattern to a random target output spike train with a much faster learning speed than ReSuMe.",Advances in Spiking Neural Information Processing Systems (SNIPS),https://www.esann.org/sites/default/files/proceedings/legacy/es2014-50.pdf,2014,100.0,"A new biologically plausible supervised learning method for spiking neurons STDP is believed to play an important role in learning and memory. Additionally, experimental evidence shows that a few strong neural inputs can drive a neuron response and subsequently affect the learning of other inputs. Furthermore, recent studies have shown that local dendritic depolarization can impact STDP induction. This paper integrates these three biological concepts to devise a new biologically plausible supervised learning method for spiking neurons. Experimental results show that the proposed method can effectively map a random spatiotemporal input pattern to a random target output spike train with a much faster learning speed than ReSuMe."
Learning State Prediction Using a Weightless Neural Explorer,"Igor Aleksander, Helen Morton","1 - Imperial College -Department of Electrical and Electronic Engineering SW7 2BT London UK
3 - School of Social Sciences (Psychology) Brunel University UB8 3PH Uxbridge Middlesex UK","A weightless neural state machine acting as an exploratory automaton changes its position in a simulated toy world by its own actions. A popular question is asked: how might the automaton 'become conscious of' the effect of its own actions? Here we develop previously defined iconic learning in such weightless machines so that this knowledge can be achieved. Weightlessness, iconic learning are expressed in terms of state equations. Experimental results that show the conditions under which correct predictions can be obtained on a neural simulator are presented. Issues of information integration and memory implication are briefly considered at the end of the paper.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-51.pdf,2014,73.33333333333334,"Learning State Prediction Using a Weightless Neural Explorer A weightless neural state machine acting as an exploratory automaton changes its position in a simulated toy world by its own actions. A popular question is asked: how might the automaton 'become conscious of' the effect of its own actions? Here we develop previously defined iconic learning in such weightless machines so that this knowledge can be achieved. Weightlessness, iconic learning are expressed in terms of state equations. Experimental results that show the conditions under which correct predictions can be obtained on a neural simulator are presented. Issues of information integration and memory implication are briefly considered at the end of the paper."
Support Vector Ordinal Regression using Privileged Information,"Fengzhen Tang, Peter Tiňo, Pedro Gutiérrez, Huanhuan Chen","1 - Department of Computer Science and Numerical Analysis University of Córdoba 14071 Córdoba Spain
2 - School of Computer Science The University of Birmingham B15 2TT Birmingham United Kingdom","We introduce a new methodology, called SVORIM+, for utilizing privileged information of the training examples, unavailable in the test regime, to improve generalization performance in ordinal regression. The privileged information is incorporated during the training by modelling the slacks through correcting functions for each of the parallel hyperplanes separating the ordered classes. The experimental results on several benchmark and time series datasets show that inclusion of the privileged information during training can boost the generalization performance significantly.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-58.pdf,2014,100.0,"Support Vector Ordinal Regression using Privileged Information We introduce a new methodology, called SVORIM+, for utilizing privileged information of the training examples, unavailable in the test regime, to improve generalization performance in ordinal regression. The privileged information is incorporated during the training by modelling the slacks through correcting functions for each of the parallel hyperplanes separating the ordered classes. The experimental results on several benchmark and time series datasets show that inclusion of the privileged information during training can boost the generalization performance significantly."
Kernel methods for mixed feature selection,"Jérôme Paul, Pierre Dupont",1 - ICTEAM/Machine Learning Group Université catholique de Louvain Place Sainte Barbe 2 1348 Louvain-la-Neuve Belgium,This paper introduces two feature selection methods to deal with heterogeneous data that include continuous and categorical variables. We propose to plug a dedicated kernel that handles both kind of variables into a Recursive Feature Elimination procedure using either a non-linear SVM or Multiple Kernel Learning. These methods are shown to offer significantly better predictive results than state-of-the-art alternatives on a variety of high-dimensional classification tasks.,Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-59.pdf,2014,100.0,Kernel methods for mixed feature selection This paper introduces two feature selection methods to deal with heterogeneous data that include continuous and categorical variables. We propose to plug a dedicated kernel that handles both kind of variables into a Recursive Feature Elimination procedure using either a non-linear SVM or Multiple Kernel Learning. These methods are shown to offer significantly better predictive results than state-of-the-art alternatives on a variety of high-dimensional classification tasks.
Comparison Of Local And Global Undirected Graphical Models *,"Zhemin Zhu, Djoerd Hiemstra, Peter Apers, Andreas Wombacher","1 - Electrical Engineering, Mathematics and Computer Science (EEMCS) University of Twente Enschede The Netherlands","CRFs are discriminative undirected models which are globally normalized. Global normalization preserves CRFs from the label bias problem which most local models suffer from. Recently proposed co-occurrence rate networks (CRNs) are also discriminative undirected models. In contrast to CRFs, CRNs are locally normalized. It was established that CRNs are immune to the label bias problem even they are local models. In this paper, we further compare ECRNs (using fully empirical relative frequencies, not by support vector regression 1 ) and CRFs. The connection between Co-occurrence Rate, which is the exponential function of pointwise mutual information, and Copulas is built in continuous case. Also they are further evaluated statistically by experiments. * We thank the three reviewers for their very helpful comments. This work has been supported by the Dutch national program COMMIT/. 1 This is different from our another later paper, in which we use support vector regression.",Dynamical systems and online learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-60.pdf,2014,81.35593220338984,"Comparison Of Local And Global Undirected Graphical Models * CRFs are discriminative undirected models which are globally normalized. Global normalization preserves CRFs from the label bias problem which most local models suffer from. Recently proposed co-occurrence rate networks (CRNs) are also discriminative undirected models. In contrast to CRFs, CRNs are locally normalized. It was established that CRNs are immune to the label bias problem even they are local models. In this paper, we further compare ECRNs (using fully empirical relative frequencies, not by support vector regression 1 ) and CRFs. The connection between Co-occurrence Rate, which is the exponential function of pointwise mutual information, and Copulas is built in continuous case. Also they are further evaluated statistically by experiments. * We thank the three reviewers for their very helpful comments. This work has been supported by the Dutch national program COMMIT/. 1 This is different from our another later paper, in which we use support vector regression."
Agglomerative Hierarchical Kernel Spectral Clustering for Large Scale Networks,"Raghvendra Mall, Rocco Langone, Johan Suykens","1 - KU Leuven ESAT/STADIUS Kasteelpark Arenberg 10, bus 2446 B-3001 Leuven Belgium",We propose an agglomerative hierarchical kernel spectral clustering (AH-KSC) model for large scale complex networks. The kernel spectral clustering (KSC) method uses a primal-dual framework to build a model on a subgraph of the network. We exploit the structure of the projections in the eigenspace to automatically identify a set of distance thresholds. These thresholds lead to the different levels of hierarchy in the network. We use these distance thresholds on the eigen-projections of the entire network to obtain a hierarchical clustering in an agglomerative fashion. The proposed approach locates several levels of hierarchy which have clusters with high modularity (Q) and high adjusted rand index (ARI) w.r.t. the groundtruth communities. We compare AH-KSC with 2 stateof-the-art large scale hierarchical community detection techniques.,Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-61.pdf,2014,85.8974358974359,Agglomerative Hierarchical Kernel Spectral Clustering for Large Scale Networks We propose an agglomerative hierarchical kernel spectral clustering (AH-KSC) model for large scale complex networks. The kernel spectral clustering (KSC) method uses a primal-dual framework to build a model on a subgraph of the network. We exploit the structure of the projections in the eigenspace to automatically identify a set of distance thresholds. These thresholds lead to the different levels of hierarchy in the network. We use these distance thresholds on the eigen-projections of the entire network to obtain a hierarchical clustering in an agglomerative fashion. The proposed approach locates several levels of hierarchy which have clusters with high modularity (Q) and high adjusted rand index (ARI) w.r.t. the groundtruth communities. We compare AH-KSC with 2 stateof-the-art large scale hierarchical community detection techniques.
Robust outlier detection with L 0 -SVDD,"Meriem Azami, Carole Lartizien, Stéphane Canu","1 - UMR5220; Inserm U1044 Université de Lyon CREATIS CNRS
2 - INSA-Lyon Univ. Lyon
3 - France
7 - LITIS INSA de Rouen Normandie Université, Saint-Etienne-du-Rouvray 76801 France","The problem of outlier detection consists in finding data that is not representative of the population from which it was ostensibly derived. Recently, to solve this problem, Liu et al.  [1]  proposed a two steps hypersphere-based approach, taking into account a confidence score pre-calculated for each input data. Defining these scores in a first step, independently from the second one, makes this approach not well-suited for large stream data. To solve these difficulties, we propose a global reformulation of the support vector data description (SVDD) problem based on the L0 norm, well suited for outlier detection. We demonstrate that this L0-SVDD problem can be solved using an iterative procedure providing data specific weighting terms. We show that our approach outperforms state of the art outlier detection techniques using both synthetic and clinical data. * This work was performed within the framework of the LABEX PRIMES (ANR-11-LABX-0063) of Université de Lyon, within the program ""Investissements d'Avenir"" (ANR-11-IDEX-0007) operated by the French National Research Agency (ANR). We thank Alexander Hammers from the Neurodis Foundation and Nicolas Costes from the CERMEP for providing the MRI data and for useful discussions.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-62.pdf,2014,92.10526315789474,"Robust outlier detection with L 0 -SVDD The problem of outlier detection consists in finding data that is not representative of the population from which it was ostensibly derived. Recently, to solve this problem, Liu et al.  [1]  proposed a two steps hypersphere-based approach, taking into account a confidence score pre-calculated for each input data. Defining these scores in a first step, independently from the second one, makes this approach not well-suited for large stream data. To solve these difficulties, we propose a global reformulation of the support vector data description (SVDD) problem based on the L0 norm, well suited for outlier detection. We demonstrate that this L0-SVDD problem can be solved using an iterative procedure providing data specific weighting terms. We show that our approach outperforms state of the art outlier detection techniques using both synthetic and clinical data. * This work was performed within the framework of the LABEX PRIMES (ANR-11-LABX-0063) of Université de Lyon, within the program ""Investissements d'Avenir"" (ANR-11-IDEX-0007) operated by the French National Research Agency (ANR). We thank Alexander Hammers from the Neurodis Foundation and Nicolas Costes from the CERMEP for providing the MRI data and for useful discussions."
Multiscale stochastic neighbor embedding: Towards parameter-free dimensionality reduction,"John Lee, Diego Peluffo-Ordóñez, Michel Verleysen","1 - SST/ICTM/ELEN -Machine Learning Group Université catholique de Louvain Belgium
4 - Oncology -SSS/IREC 1 -Molecular Imaging Radiotherapy MIRO
5 - Université catholique de Louvain Belgium","Stochastic neighbor embedding (SNE) is a method of dimensionality reduction that involves softmax similarities measured between all pairs of data points. To build a suitable embedding, SNE tries to reproduce in a low-dimensional space the similarities that are observed in the high-dimensional data space. Previous work has investigated the immunity of such similarities to norm concentration, as well as enhanced cost functions. This paper proposes an additional refinement, in the form of multiscale similarities, namely averages of softmax ratios with decreasing bandwidths. The objective is to maximize the embedding quality at all scales, with a better preservation of both local and global neighborhoods, and also to exempt the user from having to fix a scale arbitrarily. Experiments on several data sets show that this multiscale version of SNE, combined with an appropriate cost function (sum of Jensen-Shannon divergences), outperforms all previous variants of SNE.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-64.pdf,2014,100.0,"Multiscale stochastic neighbor embedding: Towards parameter-free dimensionality reduction Stochastic neighbor embedding (SNE) is a method of dimensionality reduction that involves softmax similarities measured between all pairs of data points. To build a suitable embedding, SNE tries to reproduce in a low-dimensional space the similarities that are observed in the high-dimensional data space. Previous work has investigated the immunity of such similarities to norm concentration, as well as enhanced cost functions. This paper proposes an additional refinement, in the form of multiscale similarities, namely averages of softmax ratios with decreasing bandwidths. The objective is to maximize the embedding quality at all scales, with a better preservation of both local and global neighborhoods, and also to exempt the user from having to fix a scale arbitrarily. Experiments on several data sets show that this multiscale version of SNE, combined with an appropriate cost function (sum of Jensen-Shannon divergences), outperforms all previous variants of SNE."
Parameter-Free Regularization in Extreme Learning Machines with Affinity Matrices,"Leonardo Silvestre, André Lemos, João Braga, Antônio Braga","1 - Graduate Program in Electrical Engineering -Federal University of Minas Gerais Av 6627, 31270-901 Belo Horizonte Antônio Carlos, MG Brazil
2 - Dept. of Computing and Electronics Federal University of Espírito Santo
3 - Dept. of Electronics Engineering Federal University of Minas Gerais 4 -Dept. of Chemistry -Federal University of Minas Gerais","This paper proposes a novel regularization approach for Extreme Learning Machines. Regularization is performed using a priori spacial information expressed by an affinity matrix. We show that the use of this type of a priori information is similar to perform Tikhonov regularization. Furthermore, if a parameter free affinity matrix is used, like the cosine similarity matrix, regularization is performed without any need for parameter tunning. Experiments are performed using classification problems to validate the proposed approach.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-66.pdf,2014,71.60493827160495,"Parameter-Free Regularization in Extreme Learning Machines with Affinity Matrices This paper proposes a novel regularization approach for Extreme Learning Machines. Regularization is performed using a priori spacial information expressed by an affinity matrix. We show that the use of this type of a priori information is similar to perform Tikhonov regularization. Furthermore, if a parameter free affinity matrix is used, like the cosine similarity matrix, regularization is performed without any need for parameter tunning. Experiments are performed using classification problems to validate the proposed approach."
Region of interest detection using MLP,"Tommi Kärkkäinen, Alexandr Maslov, Pekka Wartiainen",1 - Department of Mathematical Information Technology University of Jyväskylä P.O. Box 35 40014 Finland,A novel technique to detect regions of interest in a time series as deviation from the characteristic behavior is proposed. The deterministic form of a signal is obtained using a reliably trained MLP neural network with detailed complexity management and cross-validation based generalization assurance. The proposed technique is demonstrated with simulated and real data. * The authors gratefully acknowledge the support from Jenny and Antti Wihuri Foundation (TK) and from the OSER project (AM and PW).,Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-69.pdf,2014,100.0,Region of interest detection using MLP A novel technique to detect regions of interest in a time series as deviation from the characteristic behavior is proposed. The deterministic form of a signal is obtained using a reliably trained MLP neural network with detailed complexity management and cross-validation based generalization assurance. The proposed technique is demonstrated with simulated and real data. * The authors gratefully acknowledge the support from Jenny and Antti Wihuri Foundation (TK) and from the OSER project (AM and PW).
Advances in Weightless Neural Systems,"F França, M De Gregorio, P Lima, W De Oliveira","1 - COPPE Universidade Federal do Rio de Janeiro 2 -iNCE BRAZIL
2 - Istituto di Cibernetica ""E. Caianiello"" -CNR Pozzuoli ITALY
3 - Universidade Federal Rural de Pernambuco BRAZIL","Random Access Memory (RAM) nodes can play the role of artificial neurons that are addressed by Boolean inputs and produce Boolean outputs. The weightless neural network (WNN) approach has an implicit inspiration in the decoding process observed in the dendritic trees of biological neurons. An overview on recent advances in weightless neural systems is presented here. Theoretical aspects, such as the VC dimension of WNNs, architectural extensions, such as the Bleaching mechanism, and novel quantum WNN models, are discussed. A set of recent successful applications and cognitive explorations are also summarized here.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-7.pdf,2014,97.2972972972973,"Advances in Weightless Neural Systems Random Access Memory (RAM) nodes can play the role of artificial neurons that are addressed by Boolean inputs and produce Boolean outputs. The weightless neural network (WNN) approach has an implicit inspiration in the decoding process observed in the dendritic trees of biological neurons. An overview on recent advances in weightless neural systems is presented here. Theoretical aspects, such as the VC dimension of WNNs, architectural extensions, such as the Bleaching mechanism, and novel quantum WNN models, are discussed. A set of recent successful applications and cognitive explorations are also summarized here."
Segmented Shape-Symbolic Time Series Representation,"Herbert Kruitbosch, Ioannis Giotis, Michael Biehl","1 - University of Groningen -Johann Bernoulli Institute Nijenborgh 9 9747 AG Groningen The Netherlands
2 - Target Holding B.V Nettelbosje 1 9747 AJ Groningen The Netherlands",This paper introduces a symbolic time series representation using monotonic sub-sequences and bottom up segmentation. The representation minimizes the square error between the segments and their monotonic approximations. The representation can robustly classify the direction of a segment and is scale invariant with respect to the time and value dimensions. This paper describes two experiments. The first shows how accurately the monotonic functions are able to discriminate between different segments. The second tests how well the segmentation technique recognizes segments and classifies them with correct symbols. Finally this paper illustrates the new representation on real-world data.,Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-70.pdf,2014,70.58823529411764,Segmented Shape-Symbolic Time Series Representation This paper introduces a symbolic time series representation using monotonic sub-sequences and bottom up segmentation. The representation minimizes the square error between the segments and their monotonic approximations. The representation can robustly classify the direction of a segment and is scale invariant with respect to the time and value dimensions. This paper describes two experiments. The first shows how accurately the monotonic functions are able to discriminate between different segments. The second tests how well the segmentation technique recognizes segments and classifies them with correct symbols. Finally this paper illustrates the new representation on real-world data.
Credal decision trees in noisy domains,"Carlos Mantas, Joaquín Abellán",1 - Department of Computer Science Artificial Intelligence University of Granada Granada Spain,"Credal Decision Trees (CDTs) are algorithms to design classifiers based on imprecise probabilities and uncertainty measures. In this paper, the C4.5 and CDT procedures are combined in a new one. This depends on a parameter s. Several experiments are carried out with different values for s. The new procedure obtains better performance than C4.5 on data sets with different noise levels.",Label noise in classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-72.pdf,2014,100.0,"Credal decision trees in noisy domains Credal Decision Trees (CDTs) are algorithms to design classifiers based on imprecise probabilities and uncertainty measures. In this paper, the C4.5 and CDT procedures are combined in a new one. This depends on a parameter s. Several experiments are carried out with different values for s. The new procedure obtains better performance than C4.5 on data sets with different noise levels."
Interactive Dimensionality Reduction for Visual Analytics,"Ignacio Díaz, Abel Cuadrado, Daniel Pérez, Francisco García, Michel Verleysen","1 - Electrical Engineering Dept Dept. 2 University of Oviedo Edif campus de Viesques s/n 33204 Gijón SPAIN
5 - Univ. Catholique de Louvain -Machine Learning Group ICTEAM ELEN -Place du Levant 1348 Louvain-la-Neuve Belgium","In this work, we present a novel approach for data visualization based on interactive dimensionality reduction (iDR). The main idea of the paper relies on considering for visualization the intermediate results of non-convex DR algorithms under changes on the metric of the input data space driven by the user. With an appropriate visualization interface, our approach allows the user to focus on the relationships among dynamically selected groups of variables, as well as to assess the impact of a single variable or groups of variables in the structure of the data. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO) and FEDER funds from the EU.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-75.pdf,2014,68.42105263157895,"Interactive Dimensionality Reduction for Visual Analytics In this work, we present a novel approach for data visualization based on interactive dimensionality reduction (iDR). The main idea of the paper relies on considering for visualization the intermediate results of non-convex DR algorithms under changes on the metric of the input data space driven by the user. With an appropriate visualization interface, our approach allows the user to focus on the relationships among dynamically selected groups of variables, as well as to assess the impact of a single variable or groups of variables in the structure of the data. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO) and FEDER funds from the EU."
Dimensionality reduction in decentralized networks by Gossip aggregation of principal components analyzers,"Jerome Fellus, David Picard, Philippe-Henri Gosselin","1 - ETIS -UMR CNRS 8051 ENSEA -Universite de Cergy-Pontoise 2-Inria, Texmex project, Campus de Beaulieu Rennes France","This paper considers dimensionality reduction in large decentralized networks with limited node-local computing and memory resources and unreliable point-to-point connectivity (e.g peer-to-peer, sensors or ad-hoc mobile networks). We propose an asynchronous decentralized algorithm built on a Gossip consensus protocol that perform Principal Components Analysis (PCA) of data spread over such networks. All nodes obtain the same local basis that span the global principal subspace. Reported experiments show that obtained bases both reach a consensus and accurately estimate the global PCA solution.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-76.pdf,2014,100.0,"Dimensionality reduction in decentralized networks by Gossip aggregation of principal components analyzers This paper considers dimensionality reduction in large decentralized networks with limited node-local computing and memory resources and unreliable point-to-point connectivity (e.g peer-to-peer, sensors or ad-hoc mobile networks). We propose an asynchronous decentralized algorithm built on a Gossip consensus protocol that perform Principal Components Analysis (PCA) of data spread over such networks. All nodes obtain the same local basis that span the global principal subspace. Reported experiments show that obtained bases both reach a consensus and accurately estimate the global PCA solution."
Mobility Prediction Using Fully-Complex Extreme Learning Machines,Lahouari Ghouti,"1 - Department of Information and Computer Science King Fahd University of Petroleum and Minerals. KFUPM Box 1128. Dhahran 31261 Saudi Arabia
2 - Research supported by King Fahd University of Petroleum and Minerals","Efficient planning and improved quality of service (QoS) in wireless networks call for the use of mobility prediction schemes. Such schemes ensure accurate mobility prediction of wireless users and units which plays a major role in optimized planning and management of the available bandwidth and power resources. In this paper, fully-complex extreme learning machines (CELMs) model and predict the mobility patterns of arbitrary nodes in a mobile ad hoc network (MANET). Unlike their real-valued counterparts, CELMs properly capture the existing interaction/correlation between the nodes' location coordinates leading to more realistic and accurate prediction. Simulation results using standard mobility models and real-world mobility data clearly show that the proposed complex-valued prediction algorithm outperforms many existing real-valued learning machines in terms of prediction accuracy.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-79.pdf,2014,100.0,"Mobility Prediction Using Fully-Complex Extreme Learning Machines Efficient planning and improved quality of service (QoS) in wireless networks call for the use of mobility prediction schemes. Such schemes ensure accurate mobility prediction of wireless users and units which plays a major role in optimized planning and management of the available bandwidth and power resources. In this paper, fully-complex extreme learning machines (CELMs) model and predict the mobility patterns of arbitrary nodes in a mobile ad hoc network (MANET). Unlike their real-valued counterparts, CELMs properly capture the existing interaction/correlation between the nodes' location coordinates leading to more realistic and accurate prediction. Simulation results using standard mobility models and real-world mobility data clearly show that the proposed complex-valued prediction algorithm outperforms many existing real-valued learning machines in terms of prediction accuracy."
Learning and modelling big data,"Barbara Hammer, Haibo He, Thomas Martinetz","1 - CITEC centre of excellence Bielefeld University Germany
2 - -CISA Lab University of Rhode Island USA
3 - Institute for Neuro-and Bioinformatics University of Luebeck Germany","Caused by powerful sensors, advanced digitalisation techniques, and dramatically increased storage capabilities, big data in the sense of large or streaming data sets, very high dimensionality, or complex data formats constitute one of the major challenges faced by machine learning today. In this realm, a couple of typical assumptions of machine learning can no longer be met, such as e.g. the possibility to deal with all data in batch mode or data being identically distributed; this causes the need for novel algorithmic developments and paradigm shifts, or for the adaptation of existing ones to cope with such situations. The goal of this tutorial is to give an overview about recent machine learning approaches for big data, with a focus on principled algorithmic ideas in the field.",Learning and Modeling Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-8.pdf,2014,98.36065573770492,"Learning and modelling big data Caused by powerful sensors, advanced digitalisation techniques, and dramatically increased storage capabilities, big data in the sense of large or streaming data sets, very high dimensionality, or complex data formats constitute one of the major challenges faced by machine learning today. In this realm, a couple of typical assumptions of machine learning can no longer be met, such as e.g. the possibility to deal with all data in batch mode or data being identically distributed; this causes the need for novel algorithmic developments and paradigm shifts, or for the adaptation of existing ones to cope with such situations. The goal of this tutorial is to give an overview about recent machine learning approaches for big data, with a focus on principled algorithmic ideas in the field."
Adaptive distance measures for sequential data,"Bassam Mokbel, Benjamin Paassen, Barbara Hammer",1 - CITEC centre of excellence Bielefeld University Germany,"Recent extensions of learning vector quantization (LVQ) to general (dis-)similarity data have paved the way towards LVQ classifiers for possibly discrete, structured objects such as sequences addressed by classical alignment. In this contribution, we propose a metric learning scheme based on this framework which allows for autonomous learning of the underlying scoring matrix according to a given discriminative task. Besides facilitating the often crucial and problematic choice of the scoring matrix in applications, this extension offers an increased interpretability of the results by pointing out structural invariances for the given task. * Funding by the DFG under grant number HA 2719/6-1 and by the CITEC centre of excellence is gratefully acknowledged.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-82.pdf,2014,100.0,"Adaptive distance measures for sequential data Recent extensions of learning vector quantization (LVQ) to general (dis-)similarity data have paved the way towards LVQ classifiers for possibly discrete, structured objects such as sequences addressed by classical alignment. In this contribution, we propose a metric learning scheme based on this framework which allows for autonomous learning of the underlying scoring matrix according to a given discriminative task. Besides facilitating the often crucial and problematic choice of the scoring matrix in applications, this extension offers an increased interpretability of the results by pointing out structural invariances for the given task. * Funding by the DFG under grant number HA 2719/6-1 and by the CITEC centre of excellence is gratefully acknowledged."
Probabilistic automata simulation with single layer weightless neural networks,"Adenilton Da Silva, Wilson De Oliveira, Teresa Ludermir","1 - Universidade Federal de Pernambuco -Centro de Informática Cidade Universitária 50740-560 Recife PE, Brazil
2 - Departamento de Estatística e Informática Dois Irmãos -CEP Universidade Federal Rural de Pernambuco 52171-900 Recife PE, Brazil","Computability of weightless neural networks is the major topic of this paper. In previous works it has been shown that, one can simulate a Turing machine with a weightless neural network (WNN) with an infinite tape. And it has also been shown that one can simulate probabilistic automata with a WNN with two queues. In this paper, we will show that is possible to simulate a probabilistic automata with a single layer WNN with no auxiliary data structures.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-83.pdf,2014,100.0,"Probabilistic automata simulation with single layer weightless neural networks Computability of weightless neural networks is the major topic of this paper. In previous works it has been shown that, one can simulate a Turing machine with a weightless neural network (WNN) with an infinite tape. And it has also been shown that one can simulate probabilistic automata with a WNN with two queues. In this paper, we will show that is possible to simulate a probabilistic automata with a single layer WNN with no auxiliary data structures."
Online tracking of multiple objects using WiSARD,"Rafael Lima De Carvalho, Danilo Carvalho, Félix Mora-Camino, Priscila Lima, Felipe França","1 - COPPE Universidade Federal do Rio de Janeiro 2 -iNCE BRAZIL
2 - Universidade Federal do Tocantins UFT BRAZIL
4 - Ecole Nationale de l'Aviation Civile -Laboratoire d'Automatique FRANCE","This paper evaluates the WiSARD weightless model as a classification system on the problem of tracking multiple objects in realtime. Exploring the structure of this model, the proposed solution applies a re-learning stage in order to avoid interferences caused by background noise or variations in the target shape. Once the tracker finds a target at the first time, it applies only local searches around the neighbourhood in order to have fast response. This approach is evaluated through some experiments on real-world video data.",Advances on Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-89.pdf,2014,100.0,"Online tracking of multiple objects using WiSARD This paper evaluates the WiSARD weightless model as a classification system on the problem of tracking multiple objects in realtime. Exploring the structure of this model, the proposed solution applies a re-learning stage in order to avoid interferences caused by background noise or variations in the target shape. Once the tracker finds a target at the first time, it applies only local searches around the neighbourhood in order to have fast response. This approach is evaluated through some experiments on real-world video data."
Feature selection in environmental data mining combining Simulated Annealing and Extreme Learning Machine,"Michael Leuenberger, Mikhail Kanevski","1 - Surface Dynamics (IDYST) University of Lausanne -Institute of Earth
2 - UNIL-Mouline 1015 Lausanne Switzerland","Due to the large amount and complexity of data available in geosciences, machine learning nowadays plays an important role in environmental data mining. In many real data cases, we face the need to design input space with the most relevant features. Because the main goal is to understand and find relationships between phenomena and features, feature selection is preferred to feature transformation or extraction. To deal with the high-dimensional space of environmental data, a wrapper method based on Extreme Learning Machine and global optimization algorithm (Simulated Annealing) is proposed. This paper investigates the whole methodology and shows promising results for environmental data feature selection and modelling.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-90.pdf,2014,100.0,"Feature selection in environmental data mining combining Simulated Annealing and Extreme Learning Machine Due to the large amount and complexity of data available in geosciences, machine learning nowadays plays an important role in environmental data mining. In many real data cases, we face the need to design input space with the most relevant features. Because the main goal is to understand and find relationships between phenomena and features, feature selection is preferred to feature transformation or extraction. To deal with the high-dimensional space of environmental data, a wrapper method based on Extreme Learning Machine and global optimization algorithm (Simulated Annealing) is proposed. This paper investigates the whole methodology and shows promising results for environmental data feature selection and modelling."
Supervised Generative Models for Learning Dissimilarity Data,"D Nebel, B Hammer, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
2 - Theoretical Computer Science Group CITEC Centre of Excellence
3 - Bielefeld University Germany","Exemplar based techniques such as affinity propagation  [1]  represent data in terms of typical exemplars. This has two benefits: (i) the resulting models are directly interpretable by humans since representative exemplars can be inspected in the same way as data points, (ii) the model can be applied to any dissimilarity measure including non-Euclidean or non-metric settings. Most exemplar based techniques have been proposed in the unsupervised setting only, such that their performance in supervised learning tasks can be weak depending on the given data. Here, we address the problem of learning exemplar-based models for general dissimilarity data in a discriminative framework. For this purpose, we extend a generative model proposed in  [2]  to an exemplar based scenario using a generalized EM framework for its optimization. The resulting classifiers represent data in terms of sparse models while keeping high performance in state-of-the art benchmarks.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-91.pdf,2014,100.0,"Supervised Generative Models for Learning Dissimilarity Data Exemplar based techniques such as affinity propagation  [1]  represent data in terms of typical exemplars. This has two benefits: (i) the resulting models are directly interpretable by humans since representative exemplars can be inspected in the same way as data points, (ii) the model can be applied to any dissimilarity measure including non-Euclidean or non-metric settings. Most exemplar based techniques have been proposed in the unsupervised setting only, such that their performance in supervised learning tasks can be weak depending on the given data. Here, we address the problem of learning exemplar-based models for general dissimilarity data in a discriminative framework. For this purpose, we extend a generative model proposed in  [2]  to an exemplar based scenario using a generalized EM framework for its optimization. The resulting classifiers represent data in terms of sparse models while keeping high performance in state-of-the art benchmarks."
Optimization of General Statistical Accuracy Measures for Classification Based on Learning Vector Quantization,"M Kaden, W Hermann, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia -Germany
2 - Paracelsus Hospital Zwickau -Dep. of Neurology Zwickau Germany","We propose a framework for classification learning based on generalized learning vector quantization using statistical quality measures as cost function. Statistical measures like the F -measure or the Matthews correlation coefficient reflect better the performance for two-class classification problems than the simple accuracy, in particular if the data classes are imbalanced. For this purpose, we introduce soft approximations of those quantities contained in the confusion matrix, which are the basis for the calculation of the quality measures.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-93.pdf,2014,100.0,"Optimization of General Statistical Accuracy Measures for Classification Based on Learning Vector Quantization We propose a framework for classification learning based on generalized learning vector quantization using statistical quality measures as cost function. Statistical measures like the F -measure or the Matthews correlation coefficient reflect better the performance for two-class classification problems than the simple accuracy, in particular if the data classes are imbalanced. For this purpose, we introduce soft approximations of those quantities contained in the confusion matrix, which are the basis for the calculation of the quality measures."
Iterative ARIMA-Multiple Support Vector Regression models for long term time series prediction,"João Fausto, Lorenzato De Oliveira, Teresa Ludermir","1 - Federal University of Pernambuco -Center of informatics Av. Jornalista Anibal Fernandes, s/n 50.740-560 Recife PE Brazil","Support Vector Regression (SVR) has been widely applied in time series forecasting. Considering long term predictions, iterative predictions perform many one-step-ahead predictions until the desired horizon is achieved. This process accumulates the error from previous predictions and may affect the quality of forecasts. In order to improve long term iterative predictions a hybrid multiple Autoregressive Integrated Moving Average(ARIMA)-SVR model is applied to perform predictions considering linear and non-linear components from the time series. The results show that the proposed method produces more accurate predictions in the long term context.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-94.pdf,2014,71.27659574468085,"Iterative ARIMA-Multiple Support Vector Regression models for long term time series prediction Support Vector Regression (SVR) has been widely applied in time series forecasting. Considering long term predictions, iterative predictions perform many one-step-ahead predictions until the desired horizon is achieved. This process accumulates the error from previous predictions and may affect the quality of forecasts. In order to improve long term iterative predictions a hybrid multiple Autoregressive Integrated Moving Average(ARIMA)-SVR model is applied to perform predictions considering linear and non-linear components from the time series. The results show that the proposed method produces more accurate predictions in the long term context."
Sparse One Hidden Layer MLPs,"Alberto Torres, David Díaz, José Dorronsoro",1 - Departamento de Ingeniería Informática Tomás y Valiente 11 Universidad Autónoma de Madrid 28049 Madrid Spain,"We discuss how to build sparse one hidden layer MLP replacing the standard l2 weight decay penalty on all weights by an l1 penalty on the linear output weights. We will propose an iterative two step training procedure where the output weights are found using FISTA proximal optimization algorithm to solve a Lasso-like problem and the hidden weights are computed by unconstrained minimization. As we shall discuss, the procedure has a complexity equivalent to that of standard MLP training, yields MLPs with similar performance and, as a by product, automatically selects the number of hidden units.","Regression, Forceasting and Extreme Learning Machines",https://www.esann.org/sites/default/files/proceedings/legacy/es2014-95.pdf,2014,46.42857142857143,"Sparse One Hidden Layer MLPs We discuss how to build sparse one hidden layer MLP replacing the standard l2 weight decay penalty on all weights by an l1 penalty on the linear output weights. We will propose an iterative two step training procedure where the output weights are found using FISTA proximal optimization algorithm to solve a Lasso-like problem and the hidden weights are computed by unconstrained minimization. As we shall discuss, the procedure has a complexity equivalent to that of standard MLP training, yields MLPs with similar performance and, as a by product, automatically selects the number of hidden units."
Augmented Hashing for Semi-Supervised Scenarios,"Zalán Bodó, Lehel Csató",1 - Faculty of Mathematics and Computer Science Babeş-Bolyai University Kogȃlniceanu 1 400084 Cluj-Napoca Romania,"Hashing methods for fast approximate nearest-neighbor search are getting more and more attention with the excessive growth of the available data today. Embedding the points into the Hamming space is an important question of the hashing process. Analogously to machine learning there exist unsupervised, supervised and semi-supervised hashing methods. In this paper we propose a generic procedure to extend unsupervised codeword generators using error correcting codes and semisupervised classifiers. To show the effectiveness of the method we combine linear spectral hashing and two semi-supervised algorithms in the experiments.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-96.pdf,2014,82.97872340425532,"Augmented Hashing for Semi-Supervised Scenarios Hashing methods for fast approximate nearest-neighbor search are getting more and more attention with the excessive growth of the available data today. Embedding the points into the Hamming space is an important question of the hashing process. Analogously to machine learning there exist unsupervised, supervised and semi-supervised hashing methods. In this paper we propose a generic procedure to extend unsupervised codeword generators using error correcting codes and semisupervised classifiers. To show the effectiveness of the method we combine linear spectral hashing and two semi-supervised algorithms in the experiments."
Learning predictive partitions for continuous feature spaces,"Björn Weghenkel, Laurenz Wiskott",1 - Ruhr-Universität Bochum -Institut für Neuroinformatik 44780 Bochum Germany,"Any non-trivial agent (biological or algorithmical) that interacts with its environment needs some representation about its current state. Such a state should enable it to make informed decisions that lead to some desired outcome in the future. In practice, many learning algorithms assume states to come from a discrete set while real-world learning problems often are continuous in nature. We propose an unsupervised learning algorithm that finds discrete partitions of a continuous feature space that are predictive with respect to the future. More precisely, the learned partitions induce a Markov chain on the data with high mutual information between the current state and the next state. Such predictive partitions can serve as an alternative to classical discretization algorithms in cases where the predictable time-structure of the data is of importance.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-98.pdf,2014,100.0,"Learning predictive partitions for continuous feature spaces Any non-trivial agent (biological or algorithmical) that interacts with its environment needs some representation about its current state. Such a state should enable it to make informed decisions that lead to some desired outcome in the future. In practice, many learning algorithms assume states to come from a discrete set while real-world learning problems often are continuous in nature. We propose an unsupervised learning algorithm that finds discrete partitions of a continuous feature space that are predictive with respect to the future. More precisely, the learned partitions induce a Markov chain on the data with high mutual information between the current state and the next state. Such predictive partitions can serve as an alternative to classical discretization algorithms in cases where the predictable time-structure of the data is of importance."
Reweighted l 1 Dual Averaging Approach for Sparse Stochastic Learning,"Vilen Jumutc, Johan Suykens, K Leuven",1 - Department of Electrical Engineering ESAT-STADIUS Kasteelpark Arenberg 10 B-3001 Leuven Belgium,Recent advances in stochastic optimization and regularized dual averaging approaches revealed a substantial interest for a simple and scalable stochastic method which is tailored to some more specific needs. Among the latest one can find sparse signal recovery and l0-based sparsity inducing approaches. These methods in particular can force many components of the solution shrink to zero thus clarifying the importance of the features and simplifying the evaluation. In this paper we concentrate on enhancing sparsity of the recently proposed l1 Regularized Dual Averaging (RDA) method with a simple reweighting iterative procedure which in a limit applies the l0-norm penalty. We present some theoretical justifications of a bounded regret for a sequence of convex repeated games where every game stands for a separate reweighted l1-RDA problem. Numerical results show an enhanced sparsity of the proposed approach and some improvements over the l1-RDA method in generalization error.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-99.pdf,2014,97.8102189781022,Reweighted l 1 Dual Averaging Approach for Sparse Stochastic Learning Recent advances in stochastic optimization and regularized dual averaging approaches revealed a substantial interest for a simple and scalable stochastic method which is tailored to some more specific needs. Among the latest one can find sparse signal recovery and l0-based sparsity inducing approaches. These methods in particular can force many components of the solution shrink to zero thus clarifying the importance of the features and simplifying the evaluation. In this paper we concentrate on enhancing sparsity of the recently proposed l1 Regularized Dual Averaging (RDA) method with a simple reweighting iterative procedure which in a limit applies the l0-norm penalty. We present some theoretical justifications of a bounded regret for a sequence of convex repeated games where every game stands for a separate reweighted l1-RDA problem. Numerical results show an enhanced sparsity of the proposed approach and some improvements over the l1-RDA method in generalization error.
Assessment of Feature Saliency of MLP using Analytic Sensitivity,Tommi Kärkkäinen,1 - Department of Mathematical Information Technology University of Jyväskylä P.O. Box 35 40014 Finland,"A novel technique to determine the saliency of features for the multilayer perceptron (MLP) neural network is presented. It is based on the analytic derivative of the feedforward mapping with respect to inputs, which is then integrated over the training data using the mean of the absolute values. Experiments demonstrating the viability of the approach are given with small benchmark data sets. The cross-validation based framework for reliable determination of MLP that has been used in the experiments was introduced in [1, 2].","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-10.pdf,2015,67.1875,"Assessment of Feature Saliency of MLP using Analytic Sensitivity A novel technique to determine the saliency of features for the multilayer perceptron (MLP) neural network is presented. It is based on the analytic derivative of the feedforward mapping with respect to inputs, which is then integrated over the training data using the mean of the absolute values. Experiments demonstrating the viability of the approach are given with small benchmark data sets. The cross-validation based framework for reliable determination of MLP that has been used in the experiments was introduced in [1, 2]."
Memory Transfer in DRASiW-like Systems,"Massimo De Gregorio, Maurizio Giordano","1 - Istituto di Cibernetica ""Eduardo Caianiello"" (ICIB -CNR) Via Campi Flegrei 34 -80078 Pozzuoli NA) ITALY
2 - Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR -CNR) Via P. Castellino 111 -80131 Naples ITALY","DRASiW is an extension of the WiSARD Weightless NN model with the capability of storing the frequencies of seen patterns during the training stage in an internal data structure called ""mental image"" (MI). Due to these capability, in previous work it was demonstrated how to reversely process MIs in order to generate synthetic prototypes from training samples. In this paper we show how DRASiW-like systems are able to transfer memory between different architectures while preserving the same functionalities.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-100.pdf,2015,97.36842105263158,"Memory Transfer in DRASiW-like Systems DRASiW is an extension of the WiSARD Weightless NN model with the capability of storing the frequencies of seen patterns during the training stage in an internal data structure called ""mental image"" (MI). Due to these capability, in previous work it was demonstrated how to reversely process MIs in order to generate synthetic prototypes from training samples. In this paper we show how DRASiW-like systems are able to transfer memory between different architectures while preserving the same functionalities."
Depth and Height Aware Semantic RGB-D Perception with Convolutional Neural Networks,"Hannes Schulz, Nico Höft, Sven Behnke",1 - University Bonn -Computer Science VI Autonomous Intelligent Systems Friedrich-Ebert-Allee 144 53113 Bonn Germany,"Convolutional neural networks are popular for image labeling tasks, because of built-in translation invariance. They do not adopt well to scale changes, however, and cannot easily adjust to classes which regularly appear in certain scene regions. This is especially true when the network is applied in a sliding window. When depth data is available, we can address both problems. We propose to adjust the size of processed windows to the depth and to supply inferred height above ground to the network, which significantly improves object-class segmentation results on the NYU depth dataset.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-101.pdf,2015,73.49397590361446,"Depth and Height Aware Semantic RGB-D Perception with Convolutional Neural Networks Convolutional neural networks are popular for image labeling tasks, because of built-in translation invariance. They do not adopt well to scale changes, however, and cannot easily adjust to classes which regularly appear in certain scene regions. This is especially true when the network is applied in a sliding window. When depth data is available, we can address both problems. We propose to adjust the size of processed windows to the depth and to supply inferred height above ground to the network, which significantly improves object-class segmentation results on the NYU depth dataset."
Search Strategies for Binary Feature Selection for a Naive Bayes Classifier,"Tsirizo Rabenoro, Jérôme Lacaille, Marie Cottrell, Fabrice Rossi","1 - SAMM EA Université Paris 1 Panthéon-Sorbonne 90, rue de Tolbiac 4543, 75634 Paris cedex 13 France
2 - 77550 Snecma, Groupe Safran, Moissy Cramayel France","We compare in this paper several feature selection methods for the Naive Bayes Classifier (NBC) when the data under study are described by a large number of redundant binary indicators. Wrapper approaches guided by the NBC estimation of the classification error probability outperform filter approaches while retaining a reasonable computational cost. * T. Rabenoro is supported by a grant from Snecma, Safran Group.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-102.pdf,2015,100.0,"Search Strategies for Binary Feature Selection for a Naive Bayes Classifier We compare in this paper several feature selection methods for the Naive Bayes Classifier (NBC) when the data under study are described by a large number of redundant binary indicators. Wrapper approaches guided by the NBC estimation of the classification error probability outperform filter approaches while retaining a reasonable computational cost. * T. Rabenoro is supported by a grant from Snecma, Safran Group."
ESNigma: Efficient feature selection for Echo State Networks,"Davide Bacciu, Filippo Benedetti, Alessio Micheli",1 - Dipartimento di Informatica Università di Pisa Italy,"The paper introduces a feature selection wrapper designed specifically for Echo State Networks. It defines a feature scoring heuristics, applicable to generic subset search algorithms, which allows to reduce the need for model retraining with respect to wrappers in literature. The experimental assessment on real-word noisy sequential data shows that the proposed method can identify a compact set of relevant, highly predictive features with as little as 60% of the time required by the original wrapper. * This work is partially supported by the EU FP7 RUBICON project (contract n. 269914).",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-104.pdf,2015,71.66666666666667,"ESNigma: Efficient feature selection for Echo State Networks The paper introduces a feature selection wrapper designed specifically for Echo State Networks. It defines a feature scoring heuristics, applicable to generic subset search algorithms, which allows to reduce the need for model retraining with respect to wrappers in literature. The experimental assessment on real-word noisy sequential data shows that the proposed method can identify a compact set of relevant, highly predictive features with as little as 60% of the time required by the original wrapper. * This work is partially supported by the EU FP7 RUBICON project (contract n. 269914)."
Exact ICL maximization in a non-stationary time extension of the latent block model for dynamic networks,"Marco Corneli, Pierre Latouche, Fabrice Rossi",1 - Université Paris 1 Panthéon-Sorbonne -Laboratoire SAMM 90 rue de Tolbiac F-75634 Paris Cedex 13 France,"The latent block model (LBM) is a flexible probabilistic tool to describe interactions between node sets in bipartite networks, but it does not account for interactions of time varying intensity between nodes in unknown classes. In this paper we propose a non stationary temporal extension of the LBM that clusters simultaneously the two node sets of a bipartite network and constructs classes of time intervals on which interactions are stationary. The number of clusters as well as the membership to classes are obtained by maximizing the exact complete-data integrated likelihood relying on a greedy search approach. Experiments on simulated and real data are carried out in order to assess the proposed methodology.",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-106.pdf,2015,98.0392156862745,"Exact ICL maximization in a non-stationary time extension of the latent block model for dynamic networks The latent block model (LBM) is a flexible probabilistic tool to describe interactions between node sets in bipartite networks, but it does not account for interactions of time varying intensity between nodes in unknown classes. In this paper we propose a non stationary temporal extension of the LBM that clusters simultaneously the two node sets of a bipartite network and constructs classes of time intervals on which interactions are stationary. The number of clusters as well as the membership to classes are obtained by maximizing the exact complete-data integrated likelihood relying on a greedy search approach. Experiments on simulated and real data are carried out in order to assess the proposed methodology."
Using the Mean Absolute Percentage Error for Regression Models,"Arnaud De Myttenaere, Boris Golden, Bénédicte Le Grand, Fabrice Rossi","1 - Université Paris 1 Panthéon -Sorbonne -SAMM EA 90 rue de Tolbiac 4534, 75013 Paris France
2 - Panthéon -Sorbonne -Centre de Recherche en Informatique 90 rue de Tolbiac 75013 Paris France
4 - Université Paris
6 - 1 -Viadeo 30 rue de la Victoire 75009 Paris France",We study in this paper the consequences of using the Mean Absolute Percentage Error (MAPE) as a measure of quality for regression models. We show that finding the best model under the MAPE is equivalent to doing weighted Mean Absolute Error (MAE) regression. We show that universal consistency of Empirical Risk Minimization remains possible using the MAPE instead of the MAE.,Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-107.pdf,2015,100.0,Using the Mean Absolute Percentage Error for Regression Models We study in this paper the consequences of using the Mean Absolute Percentage Error (MAPE) as a measure of quality for regression models. We show that finding the best model under the MAPE is equivalent to doing weighted Mean Absolute Error (MAE) regression. We show that universal consistency of Empirical Risk Minimization remains possible using the MAPE instead of the MAE.
Towards a Tomographic Index of Systemic Risk Measures *,"Kaj-Mikael Björk, Patrick Kouontchou, Amaury Lendasse, Yoan Miche, Bertrand Maillet, Jan-Magnus Janssonin Aukio, Helsinki Finland","1 - BMA Department Arcada University of Applied Sciences
2 - -Variances and University de Lorraine (CEREFIGE) Ile du Saulcy 57045 Metz cedex 01 France
3 - Seamans Center for the Engineering Arts and Sciences Iowa City University of Iowa Arcada University of Applied Sciences 3131, 52242 Iowa United States of America
4 - Nokia Solutions and Networks Group Aalto University School of Science Konemiehentie 2 FI-00076 Finland
6 - Place du Maréchal de Lattre de Tassigny LEO/CNRS and LBI) University of Paris Dauphine and Orléans (LEDa-SDFi 75775 Paris Cedex 16 France","Due to the recent financial crisis, several systemic risk measures have been proposed in the literature for quantifying financial systemwide distress. In this note we propose an aggregated Index for financial systemic risk measurement based on EOF and ICA analyses on the several systemic risk measures released in the recent literature. We use this index to further identify the states of the market as suggested in Kouontchou et al.  [7] . We show, by characterizing markets conditions with a robust Kohonen Self-Organizing Maps algorithm that this measure is directly linked to crises markets states and there is a strong link between return and systemic risk. * We thank Gregory Jannin, Alexandre Jasinski, Alejandro Modesto and Alexandre Moustacchi for an excellent research assistance. The fifth author thanks the support of the Risk Foundation Chair Dauphine-ENSAE-Groupama ""Behavioral and Household Finance, Individual and Collective Risk Attitudes"" (Louis Bachelier Institute) and all authors acknowledge the support by the Global Risk Institute (www.globalriskinstitute.com). Some extra materials related to this article can be found at: www.systemic-risk-hub.org. The usual disclaimer applies.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-108.pdf,2015,98.14814814814815,"Towards a Tomographic Index of Systemic Risk Measures * Due to the recent financial crisis, several systemic risk measures have been proposed in the literature for quantifying financial systemwide distress. In this note we propose an aggregated Index for financial systemic risk measurement based on EOF and ICA analyses on the several systemic risk measures released in the recent literature. We use this index to further identify the states of the market as suggested in Kouontchou et al.  [7] . We show, by characterizing markets conditions with a robust Kohonen Self-Organizing Maps algorithm that this measure is directly linked to crises markets states and there is a strong link between return and systemic risk. * We thank Gregory Jannin, Alexandre Jasinski, Alejandro Modesto and Alexandre Moustacchi for an excellent research assistance. The fifth author thanks the support of the Risk Foundation Chair Dauphine-ENSAE-Groupama ""Behavioral and Household Finance, Individual and Collective Risk Attitudes"" (Louis Bachelier Institute) and all authors acknowledge the support by the Global Risk Institute (www.globalriskinstitute.com). Some extra materials related to this article can be found at: www.systemic-risk-hub.org. The usual disclaimer applies."
Supervised Manifold Learning with Incremental Stochastic Embeddings,Oliver Kramer,1 - Computational Intelligence Group Carl von Ossietzky University 26111 Oldenburg Germany,"In this paper, we introduce an incremental dimensionality reduction approach for labeled data. The algorithm incrementally samples in latent space and chooses a solution that minimizes the nearest neighbor classification error taking into account label information. We introduce and compare two optimization approaches to generate supervised embeddings, i.e., an incremental solution construction method and a re-embedding approach. Both methods have in common that the objective is to minimize the nearest neighbor classification error computed in the low-dimensional space. The resulting embedding is a surrogate of the high-dimensional labeled set. The set allows conclusions about the data set structure and can be used as preprocessing step for classification of labeled patterns.",Manifold learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-109.pdf,2015,100.0,"Supervised Manifold Learning with Incremental Stochastic Embeddings In this paper, we introduce an incremental dimensionality reduction approach for labeled data. The algorithm incrementally samples in latent space and chooses a solution that minimizes the nearest neighbor classification error taking into account label information. We introduce and compare two optimization approaches to generate supervised embeddings, i.e., an incremental solution construction method and a re-embedding approach. Both methods have in common that the objective is to minimize the nearest neighbor classification error computed in the low-dimensional space. The resulting embedding is a surrogate of the high-dimensional labeled set. The set allows conclusions about the data set structure and can be used as preprocessing step for classification of labeled patterns."
SMO Lattices for the Parallel Training of Support Vector Machines,"Markus Kächele, Günther Palm, Friedhelm Schwenker",1 - Ulm University -Institute of Neural Information Processing 89069 Ulm Germany,"In this work, a method is proposed to train Support Vector Machines in parallel. The difference to other parallel implementations is that the problem is decomposed into hierarchically connected nodes and that each node does not have to fully optimize its local problem. Instead Lagrange multipliers are filtered and transferred between nodes during runtime, with important ones ascending and unimportant ones descending inside the architecture. Experimental validation demonstrates the advantages in terms of speed in comparison to other approaches.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-110.pdf,2015,100.0,"SMO Lattices for the Parallel Training of Support Vector Machines In this work, a method is proposed to train Support Vector Machines in parallel. The difference to other parallel implementations is that the problem is decomposed into hierarchically connected nodes and that each node does not have to fully optimize its local problem. Instead Lagrange multipliers are filtered and transferred between nodes during runtime, with important ones ascending and unimportant ones descending inside the architecture. Experimental validation demonstrates the advantages in terms of speed in comparison to other approaches."
Online Learning with Operator-valued Kernels,"Julien Audiffren, Hachem Kadri","1 - CMLA -ENS CACHAN 61 Avenue du president Wilson 94230 Cachan FRANCE
2 - LIF -Aix Marseille Université 163 avenue de Luminy 13288 Marseille FRANCE","We consider the problem of learning a vector-valued function f in an online learning setting. The function f is assumed to lie in a reproducing Hilbert space of operator-valued kernels. We describe an online algorithm for learning f while taking into account the output structure. This algorithm, OLOK, extends the standard kernel-based online learning algorithm NORMA from scalar-valued to operator-valued setting. We report a cumulative error bound that holds both for classification and regression. Our experiments show that the proposed algorithm achieves good performance results with low computational cost. * Work partially supported by the CNRS PEPS project FLAME and by French ANR Projects LAMPADA (ANR-09-EMER-007) and GRETA (ANR-12-BS02-0004).",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-111.pdf,2015,100.0,"Online Learning with Operator-valued Kernels We consider the problem of learning a vector-valued function f in an online learning setting. The function f is assumed to lie in a reproducing Hilbert space of operator-valued kernels. We describe an online algorithm for learning f while taking into account the output structure. This algorithm, OLOK, extends the standard kernel-based online learning algorithm NORMA from scalar-valued to operator-valued setting. We report a cumulative error bound that holds both for classification and regression. Our experiments show that the proposed algorithm achieves good performance results with low computational cost. * Work partially supported by the CNRS PEPS project FLAME and by French ANR Projects LAMPADA (ANR-09-EMER-007) and GRETA (ANR-12-BS02-0004)."
An Ensemble Learning Technique for Multipartite Ranking,"Stéphan Clémençon, Sylvain Robbiano","1 - UMR Telecom ParisTech CNRS No. 5141 LTCI Institut Mines Telecom 46 rue Barrault 75013 Paris FRANCE
2 - University College of London -Dept of Statistical Science Gower Street WC1E 6BT London UK","Decision tree induction algorithms, possibly combined with a consensus technique, have been recently successfully extended to multipartite ranking. It is the goal of this paper to address certain aspects of their weakness, instability and lack of smoothness namely, by proposing dedicated ensemble learning strategies. A shown by numerical experiments, bootstrap aggregation combined with a certain amount of feature randomization dramatically improve performance of such ranking methods, in terms of accuracy and robustness both at the same time.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-112.pdf,2015,100.0,"An Ensemble Learning Technique for Multipartite Ranking Decision tree induction algorithms, possibly combined with a consensus technique, have been recently successfully extended to multipartite ranking. It is the goal of this paper to address certain aspects of their weakness, instability and lack of smoothness namely, by proposing dedicated ensemble learning strategies. A shown by numerical experiments, bootstrap aggregation combined with a certain amount of feature randomization dramatically improve performance of such ranking methods, in terms of accuracy and robustness both at the same time."
"Enhancing learning at work. How to combine theoretical and data-driven approaches, and multiple levels of data?","Virpi Kalakoski, Henriikka Ratilainen, Linda Drupsteen","1 - Finnish Institute of Occupational Health -Brain and Technology Topeliuksenkatu 41a A 00270 Helsinki Finland
3 - -TNO -Urban and Environmental Safety Schipholweg 77-89 2316 ZL Leiden The Netherlands","This research plan focuses on learning at work. Our aim is to gather empirical data on multiple factors that can affect learning for work, and to apply computational methods in order to understand the preconditions of effective learning. The design will systematically combine theory-and data-driven approaches to study (i) whether principles of effective learning found in previous studies apply to real life settings, (ii) what interactions between individual and organizational factors are related to learning outcomes, and (iii) new connections and phenomena relevant to enhance learning in real life.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-113.pdf,2015,100.0,"Enhancing learning at work. How to combine theoretical and data-driven approaches, and multiple levels of data? This research plan focuses on learning at work. Our aim is to gather empirical data on multiple factors that can affect learning for work, and to apply computational methods in order to understand the preconditions of effective learning. The design will systematically combine theory-and data-driven approaches to study (i) whether principles of effective learning found in previous studies apply to real life settings, (ii) what interactions between individual and organizational factors are related to learning outcomes, and (iii) new connections and phenomena relevant to enhance learning in real life."
PCA-based algorithm for constructing ensembles of feature ranking filters,"Andrey Filchenkov, Vladislav Dolganov, Ivan Smetannikov","1 - ITMO University -International Laboratory ""Computer technology"" Kronverksky Ave. 49 St 197101 Petersburg Russia",Feature filtering algorithms are commonly used in feature selection for high-dimensional datasets due to their simplicity and efficacy. Each of these algorithms has its own strengths and weaknesses. Ensemble of different ranking methods is a way to provide a stable and efficacious ranking algorithm. We propose a PCA-based algorithm for filter ranking algorithms ensemble. We compared this algorithm with four other rank aggregation algorithms on five different datasets used in the NIPS-2003 feature selection challenge. We evaluated the stability of the resulting rankings and the AUC score for four classifiers learnt on resulting feature sets. The proposed method has shown better stability and above-average efficacy.,Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-114.pdf,2015,79.43262411347519,PCA-based algorithm for constructing ensembles of feature ranking filters Feature filtering algorithms are commonly used in feature selection for high-dimensional datasets due to their simplicity and efficacy. Each of these algorithms has its own strengths and weaknesses. Ensemble of different ranking methods is a way to provide a stable and efficacious ranking algorithm. We propose a PCA-based algorithm for filter ranking algorithms ensemble. We compared this algorithm with four other rank aggregation algorithms on five different datasets used in the NIPS-2003 feature selection challenge. We evaluated the stability of the resulting rankings and the AUC score for four classifiers learnt on resulting feature sets. The proposed method has shown better stability and above-average efficacy.
Designing Semantic Feature Spaces for Brain-Reading,"L Pipanmaekaporn, L Tajtelbom, V Guigue, T Artières","1 - King Mongkut's University of Technology North Bangkok Thailand
2 - Laboratoire d'Informatique de Paris 6 (LIP6) Paris France
4 - Laboratoire d'Informatique Fondamentale (LIF) Marseille France","We focus on a brain-reading task which consists in discovering a word a person is thinking of based on an fMRI image of their brain. Previous studies have demonstrated the feasibility of this brain-reading task through the design of what has been called a semantic space, i.e. a continuous low dimensional space reflecting the similarity between words. So far the best results have been achieved by carefully designing this semantic space by hand which limits the generalization of such a method. We propose to automatically design several semantic spaces from linguistic resources and to combine them in a principled way and achieve results comparable to that of manually built semantic spaces.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-115.pdf,2015,62.745098039215684,"Designing Semantic Feature Spaces for Brain-Reading We focus on a brain-reading task which consists in discovering a word a person is thinking of based on an fMRI image of their brain. Previous studies have demonstrated the feasibility of this brain-reading task through the design of what has been called a semantic space, i.e. a continuous low dimensional space reflecting the similarity between words. So far the best results have been achieved by carefully designing this semantic space by hand which limits the generalization of such a method. We propose to automatically design several semantic spaces from linguistic resources and to combine them in a principled way and achieve results comparable to that of manually built semantic spaces."
A Robust Neural Robot Navigation Using a Combination of Deliberative and Reactive Control Architectures,"D Rojas Castro, A Revel, M Ménard","1 - Computing Science Department Laboratory of Informatics, Image and Interaction (L3I) University of La Rochelle 17000 -La Rochelle France","This paper proposes a hybrid neural-based control architecture for robot indoor navigation. This architecture preserves all the advantages of reactive architectures such as rapid responses to unforeseen problems in dynamic environments while combining them with the global knowledge of the world used in deliberative architectures. In order to take the right decision during navigation, the reactive module allows the robot to corroborate the dynamic visual perception with the a priori knowledge of the world gathered from a previously examined floor plan. Experiments with the robot functioning based on the proposed architecture in a simple navigation scenario prove the feasibility of the approach.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-116.pdf,2015,100.0,"A Robust Neural Robot Navigation Using a Combination of Deliberative and Reactive Control Architectures This paper proposes a hybrid neural-based control architecture for robot indoor navigation. This architecture preserves all the advantages of reactive architectures such as rapid responses to unforeseen problems in dynamic environments while combining them with the global knowledge of the world used in deliberative architectures. In order to take the right decision during navigation, the reactive module allows the robot to corroborate the dynamic visual perception with the a priori knowledge of the world gathered from a previously examined floor plan. Experiments with the robot functioning based on the proposed architecture in a simple navigation scenario prove the feasibility of the approach."
Learning Recurrent Dynamics using Differential Evolution,"Sebastian Otte, Fabian Becker, Martin Butz, Marcus Liwicki, Andreas Zell","1 - University of Tuebingen -Cognitive Systems Group Tuebingen Germany
3 - University of Tuebingen -Cognitive Modelling Group Tuebingen Germany
4 - University of Kaiserslautern -Multimedia Analysis and Data Mining Kaiserslautern Germany","This paper presents an efficient and powerful approach for learning dynamics with Recurrent Neural Networks (RNNs). No specialized or fine-tuned RNNs are used but rather standard RNNs with one fully connected hidden layer. The training procedure is based on a variant of Differential Evolution (DE) with a modified mutation schemey that allows to reduce the population size in our setup down to five, but still yields very good results even within a few generations. For several common Multiple Superimposed Oscillator (MSO) instances new state-of-the-art results are presented, which are across the board multiple magnitudes better than the achieved results published so far. Furthermore, for new and even more difficult instances, i.e., MSO9-MSO12, our setup achieves lower error rates than reported previously for the best system on MSO5-MSO8.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-118.pdf,2015,100.0,"Learning Recurrent Dynamics using Differential Evolution This paper presents an efficient and powerful approach for learning dynamics with Recurrent Neural Networks (RNNs). No specialized or fine-tuned RNNs are used but rather standard RNNs with one fully connected hidden layer. The training procedure is based on a variant of Differential Evolution (DE) with a modified mutation schemey that allows to reduce the population size in our setup down to five, but still yields very good results even within a few generations. For several common Multiple Superimposed Oscillator (MSO) instances new state-of-the-art results are presented, which are across the board multiple magnitudes better than the achieved results published so far. Furthermore, for new and even more difficult instances, i.e., MSO9-MSO12, our setup achieves lower error rates than reported previously for the best system on MSO5-MSO8."
Fast Greedy Insertion and Deletion in Sparse Gaussian Process Regression,"Jens Schreiter, Duy Nguyen-Tuong, Heiner Markert, Michael Hanselmann, Marc Toussaint, Robert Bosch, Gmbh -70442 Stuttgart -Germany",1 - University of Stuttgart -MLR Laboratory 70569 Stuttgart Germany,"In this paper, we introduce a new and straightforward criterion for successive insertion and deletion of training points in sparse Gaussian process regression. Our novel approach is based on an approximation of the selection technique proposed by Smola and Bartlett  [1] . It is shown that the resulting selection strategies are as fast as the purely randomized schemes for insertion and deletion of training points. Experiments on real-world robot data demonstrate that our obtained regression models are competitive with the computationally intensive state-of-the-art methods in terms of generalization accuracy.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-12.pdf,2015,70.83333333333333,"Fast Greedy Insertion and Deletion in Sparse Gaussian Process Regression In this paper, we introduce a new and straightforward criterion for successive insertion and deletion of training points in sparse Gaussian process regression. Our novel approach is based on an approximation of the selection technique proposed by Smola and Bartlett  [1] . It is shown that the resulting selection strategies are as fast as the purely randomized schemes for insertion and deletion of training points. Experiments on real-world robot data demonstrate that our obtained regression models are competitive with the computationally intensive state-of-the-art methods in terms of generalization accuracy."
Combining higher-order N-grams and intelligent sample selection to improve language modeling for Handwritten Text Recognition,"Jafar Tanha, Jesse De Does, Katrien Depuydt",1 - Institute for Dutch Lexicology (INL) Leiden Netherlands,"We combine two techniques to improve the language modeling component of a Handwritten Text Recognition (HTR) system. On the one hand, we apply a previously developed intelligent sample selection approach to language model adaptation for handwritten text recognition, which exploits a combination of in-domain and out-of-domain data for construction of language models. On the other hand, we apply rescoring methods to enable more complex language modeling in HTR. It is shown that these techniques complement each other very well, and that the combination leads to a significant error reduction in a practical HTR task for historical data. * The research leading to these results has received funding from the European Union's Seventh Framework Programme (FP7/2007-2013) under grant agreement no. 600707 -tran-Scriptorium.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-120.pdf,2015,100.0,"Combining higher-order N-grams and intelligent sample selection to improve language modeling for Handwritten Text Recognition We combine two techniques to improve the language modeling component of a Handwritten Text Recognition (HTR) system. On the one hand, we apply a previously developed intelligent sample selection approach to language model adaptation for handwritten text recognition, which exploits a combination of in-domain and out-of-domain data for construction of language models. On the other hand, we apply rescoring methods to enable more complex language modeling in HTR. It is shown that these techniques complement each other very well, and that the combination leads to a significant error reduction in a practical HTR task for historical data. * The research leading to these results has received funding from the European Union's Seventh Framework Programme (FP7/2007-2013) under grant agreement no. 600707 -tran-Scriptorium."
Robust Visual Terrain Classification with Recurrent Neural Networks,"Sebastian Otte, Stefan Laible, Richard Hanten, Marcus Liwicki, Andreas Zell","1 - University of Tuebingen -Cognitive Systems Group Tuebingen Germany
4 - University of Kaiserslautern -Multimedia Analysis and Data Mining Kaiserslautern Germany","A novel approach for robust visual terrain classification by generating feature sequences on repeatedly mutated image patches is presented. These sequences providing the feature vector progress under a certain image operation are learned with Recurrent Neural Networks (RNNs). The approach is studied for image patch based terrain classification for wheeled robots. Thereby, various RNN architectures, namely, standard RNNs, Long Short Term Memory networks (LSTMs), Dynamic Cortex Memory networks (DCMs) as well as bidirectional variants of the mentioned architecture are investigated and compared to recently used stateof-the-art methods for real-time terrain classification. The results show that the presented approach outperforms previous methods significantly.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-122.pdf,2015,100.0,"Robust Visual Terrain Classification with Recurrent Neural Networks A novel approach for robust visual terrain classification by generating feature sequences on repeatedly mutated image patches is presented. These sequences providing the feature vector progress under a certain image operation are learned with Recurrent Neural Networks (RNNs). The approach is studied for image patch based terrain classification for wheeled robots. Thereby, various RNN architectures, namely, standard RNNs, Long Short Term Memory networks (LSTMs), Dynamic Cortex Memory networks (DCMs) as well as bidirectional variants of the mentioned architecture are investigated and compared to recently used stateof-the-art methods for real-time terrain classification. The results show that the presented approach outperforms previous methods significantly."
Learning objects from RGB-D sensors using point cloud-based neural networks,"Marcelo Soares, Pablo Barros, German Parisi, Stefan Wermter","1 - Department of Computer Science University of Hamburg
2 - Vogt-Koelln-Strasse 30 22527 Hamburg Germany","In this paper we present a scene understanding approach for assistive robotics based on learning to recognize different objects from RGB-D devices. Using the depth information it is possible to compute descriptors that capture the geometrical relations among the points that constitute an object or extract features from multiple viewpoints. We developed a framework for testing different neural models that receive this depth information as input. Also, we propose a novel approach using three-dimensional RGB-D information as input to Convolutional Neural Networks. We found F1-scores greater than 0.9 for the majority of the objects tested, showing that the adopted approach is effective as well for classification.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-124.pdf,2015,100.0,"Learning objects from RGB-D sensors using point cloud-based neural networks In this paper we present a scene understanding approach for assistive robotics based on learning to recognize different objects from RGB-D devices. Using the depth information it is possible to compute descriptors that capture the geometrical relations among the points that constitute an object or extract features from multiple viewpoints. We developed a framework for testing different neural models that receive this depth information as input. Also, we propose a novel approach using three-dimensional RGB-D information as input to Convolutional Neural Networks. We found F1-scores greater than 0.9 for the majority of the objects tested, showing that the adopted approach is effective as well for classification."
Training Multi-Layer Perceptron with Multi-Objective Optimization and Spherical Weights Representation,"Honovan Rocha, Marcelo Costa, Antônio Braga","1 - Graduate Program in Electrical Engineering -Federal University of Minas Gerais -Av. Antônio Carlos 6627, 31270-901 Belo Horizonte MG Brazil",This paper proposes a novel representation of the parameters of neural networks in which the weights are projected into a new space defined by a radius r and a vector of angles Θ. This spherical representation further simplifies the multi-objective learning problem in which error and norm functions are optimized to generate Pareto sets. Using spherical weights the error is minimized using a mono-objective problem to the vector of angles whereas the radius (or norm) is fixed. Results indicate that spherical weights generate more reliable and accurate Pareto set estimates as compared to standard multi-objective approach.,Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-125.pdf,2015,100.0,Training Multi-Layer Perceptron with Multi-Objective Optimization and Spherical Weights Representation This paper proposes a novel representation of the parameters of neural networks in which the weights are projected into a new space defined by a radius r and a vector of angles Θ. This spherical representation further simplifies the multi-objective learning problem in which error and norm functions are optimized to generate Pareto sets. Using spherical weights the error is minimized using a mono-objective problem to the vector of angles whereas the radius (or norm) is fixed. Results indicate that spherical weights generate more reliable and accurate Pareto set estimates as compared to standard multi-objective approach.
Measuring scoring efficiency through goal expectancy estimation,"H Ruiz, P Lisboa, P Neilson, W Gregson","1 - School of Computing and Mathematical Sciences -Department of Mathematics and Statistics -LJMU L3 3AF Liverpool UK
2 - -Performance Lab -Prozone Sports Ltd LS11 8BN Leeds UK
5 - The Football Exchange -LJMU L3 3AF Liverpool UK","Association football is characterized by the lowest scoring rate of all major sports. A typical value of less than 3 goals per game makes it difficult to find strong effects on goal scoring. Instead of goals, one can focus on the production of shots, increasing the available sample size. However, the value of shots depends heavily on different factors, and it is important to take this variability into account. In this paper, we use a multilayer perceptron to build a goal expectancy model that estimates the conversion probability of shots, and use it to evaluate the scoring performance of Premier League footballers.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-126.pdf,2015,100.0,"Measuring scoring efficiency through goal expectancy estimation Association football is characterized by the lowest scoring rate of all major sports. A typical value of less than 3 goals per game makes it difficult to find strong effects on goal scoring. Instead of goals, one can focus on the production of shots, increasing the available sample size. However, the value of shots depends heavily on different factors, and it is important to take this variability into account. In this paper, we use a multilayer perceptron to build a goal expectancy model that estimates the conversion probability of shots, and use it to evaluate the scoring performance of Premier League footballers."
A flat neural network architecture to represent movement primitives with integrated sequencing,"Andre Lemme, Jochen Steil",1 - Faculty of Technology Institute for Cognition and Robotics (CoR-Lab) Bielefeld University 33615 Bielefeld Germany,"The paper proposes a minimalistic network to learn a set of movement primitives and their sequencing in one single feedforward network. Utilizing an extreme learning machine with output feedback and a simple inhibition mechanism, this approach can sequence movement primitives efficiently with very moderate network size. It can interpolate movement primitives to create new motions. This work thus demonstrates that an unspecific single hidden layer, that is a flat representation is sufficient to efficiently compose complex sequences, a task which usually requires hierarchy, multiple timescales and multi-level control mechanisms.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-127.pdf,2015,100.0,"A flat neural network architecture to represent movement primitives with integrated sequencing The paper proposes a minimalistic network to learn a set of movement primitives and their sequencing in one single feedforward network. Utilizing an extreme learning machine with output feedback and a simple inhibition mechanism, this approach can sequence movement primitives efficiently with very moderate network size. It can interpolate movement primitives to create new motions. This work thus demonstrates that an unspecific single hidden layer, that is a flat representation is sufficient to efficiently compose complex sequences, a task which usually requires hierarchy, multiple timescales and multi-level control mechanisms."
Dynamic Gesture Recognition Using Echo State Networks,"Doreen Jirak, Pablo Barros, Stefan Wermter",1 - Department of Informatics University of Hamburg Vogt-Koelln-Str. 30 22527 Hamburg Germany,"In the last decade, training recurrent neural networks (RNN) using techniques from the area of reservoir computing (RC) became more attractive for learning sequential data due to the ease of network training. Although successfully applied in the language and speech domains, only little is known about using RC techniques for dynamic gesture recognition. We therefore conducted experiments on command gestures using Echo State Networks (ESN) to investigate both the effect of different gesture sequence representations and different parameter configurations. For recognition we employed the ensemble technique, i.e. using ESN as weak classifiers. Our results show that using ESN is a promising approach for dynamic gesture recognition and we give indications for future experiments.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-128.pdf,2015,69.81132075471699,"Dynamic Gesture Recognition Using Echo State Networks In the last decade, training recurrent neural networks (RNN) using techniques from the area of reservoir computing (RC) became more attractive for learning sequential data due to the ease of network training. Although successfully applied in the language and speech domains, only little is known about using RC techniques for dynamic gesture recognition. We therefore conducted experiments on command gestures using Echo State Networks (ESN) to investigate both the effect of different gesture sequence representations and different parameter configurations. For recognition we employed the ensemble technique, i.e. using ESN as weak classifiers. Our results show that using ESN is a promising approach for dynamic gesture recognition and we give indications for future experiments."
Feature and kernel learning,"Verónica Bolón-Canedo, Michele Donini, Fabio Aiolli","1 - Department of Computer Science University of A Coruña Campus de Elviña s/n 15071 A Coruña Spain
2 - Department of Mathematics Via Trieste University of Padova 63 35121 Padova Italy","Feature selection and weighting has been an active research area in the last few decades finding success in many different applications. With the advent of Big Data, the adequate identification of the relevant features has converted feature selection in an even more indispensable step. On the other side, in kernel methods features are implicitly represented by means of feature mappings and kernels. It has been shown that the correct selection of the kernel is a crucial task, as long as an erroneous selection can lead to poor performance. Unfortunately, manually searching for an optimal kernel is a time-consuming and a sub-optimal choice. This tutorial is concerned with the use of data to learn features and kernels automatically. We provide a survey of recent methods developed for feature selection/learning and their application to real world problems, together with a review of the contributions to the ESANN 2015 special session on Feature and Kernel Learning.",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-13.pdf,2015,100.0,"Feature and kernel learning Feature selection and weighting has been an active research area in the last few decades finding success in many different applications. With the advent of Big Data, the adequate identification of the relevant features has converted feature selection in an even more indispensable step. On the other side, in kernel methods features are implicitly represented by means of feature mappings and kernels. It has been shown that the correct selection of the kernel is a crucial task, as long as an erroneous selection can lead to poor performance. Unfortunately, manually searching for an optimal kernel is a time-consuming and a sub-optimal choice. This tutorial is concerned with the use of data to learn features and kernels automatically. We provide a survey of recent methods developed for feature selection/learning and their application to real world problems, together with a review of the contributions to the ESANN 2015 special session on Feature and Kernel Learning."
Exploiting the ODD framework to define a novel effective graph kernel,"Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti","1 - ALT Research Group Qatar Computing Research Institute
2 - Department of Mathematics via Trieste 63 University of Padova Padova Italy","In this paper, we show how the Ordered Decomposition DAGs kernel framework, a framework that allows the definition of graph kernels from tree kernels, allows to easily define new state-of-the-art graph kernels. Here we consider a quite fast graph kernel based on the Subtree kernel (ST), and we improve it by increasing its expressivity by adding new features involving partial tree features. While the worst-case complexity of the new obtained graph kernel does not increase, its effectiveness is improved, as shown on several chemical datasets, reaching state-of-the-art performances.",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-130.pdf,2015,100.0,"Exploiting the ODD framework to define a novel effective graph kernel In this paper, we show how the Ordered Decomposition DAGs kernel framework, a framework that allows the definition of graph kernels from tree kernels, allows to easily define new state-of-the-art graph kernels. Here we consider a quite fast graph kernel based on the Subtree kernel (ST), and we improve it by increasing its expressivity by adding new features involving partial tree features. While the worst-case complexity of the new obtained graph kernel does not increase, its effectiveness is improved, as shown on several chemical datasets, reaching state-of-the-art performances."
Asynchronous decentralized convex optimization through short-term gradient averaging,"Jerome Fellus, David Picard, Philippe-Henri Gosselin",1 - ETIS -UMR CNRS 8051 ENSEA -Universite de Cergy-Pontoise,"This paper considers decentralized convex optimization over a network in large scale contexts, where large simultaneously applies to number of training examples, dimensionality and number of networking nodes. We first propose a centralized optimization scheme that generalizes successful existing methods based on gradient averaging, improving their flexibility by making the number of averaged gradients an explicit parameter of the method. We then propose an asynchronous distributed algorithm that implements this original scheme for large decentralized computing networks.",Manifold learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-131.pdf,2015,100.0,"Asynchronous decentralized convex optimization through short-term gradient averaging This paper considers decentralized convex optimization over a network in large scale contexts, where large simultaneously applies to number of training examples, dimensionality and number of networking nodes. We first propose a centralized optimization scheme that generalizes successful existing methods based on gradient averaging, improving their flexibility by making the number of averaged gradients an explicit parameter of the method. We then propose an asynchronous distributed algorithm that implements this original scheme for large decentralized computing networks."
Gabriel Graph for Dataset Structure and Large Margin Classification: A Bayesian Approach,"Luiz Torres, Cristiano Castro, Antônio Braga","1 - Federal University of Minas Gerais Department of Electronics Engineering Av. Antonio Carlos 6627, 30161-970 Belo Horizonte Pampulha, MG Brazil","This paper presents a geometrical approach for obtaining large margin classifiers. The method aims at exploring the geometrical properties of the dataset from the structure of a Gabriel graph, which represents pattern relations according to a given distance metric, such as the Euclidean distance. Once the graph is generated, geometric vectors, analogous to SVM's support vectors are obtained in order to yield the final large margin solution from a Gaussian mixture model approach. Preliminary experiments have shown that the solutions obtained with the proposed method are close to those obtained with SVMs.",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-132.pdf,2015,100.0,"Gabriel Graph for Dataset Structure and Large Margin Classification: A Bayesian Approach This paper presents a geometrical approach for obtaining large margin classifiers. The method aims at exploring the geometrical properties of the dataset from the structure of a Gabriel graph, which represents pattern relations according to a given distance metric, such as the Euclidean distance. Once the graph is generated, geometric vectors, analogous to SVM's support vectors are obtained in order to yield the final large margin solution from a Gaussian mixture model approach. Preliminary experiments have shown that the solutions obtained with the proposed method are close to those obtained with SVMs."
Unsupervised Dimensionality Reduction for Transfer Learning,"Patrick Blöbaum, Alexander Schulz, Barbara Hammer",1 - CITEC center of excellence Bielefeld University Germany,"We investigate the suitability of unsupervised dimensionality reduction (DR) for transfer learning in the context of different representations of the source and target domain. Essentially, unsupervised DR establishes a link of source and target domain by representing the data in a common latent space. We consider two settings: a linear DR of source and target data which establishes correspondences of the data and an according transfer, and its combination with a non-linear DR which allows to adapt to more complex data characterised by a global non-linear structure.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-134.pdf,2015,100.0,"Unsupervised Dimensionality Reduction for Transfer Learning We investigate the suitability of unsupervised dimensionality reduction (DR) for transfer learning in the context of different representations of the source and target domain. Essentially, unsupervised DR establishes a link of source and target domain by representing the data in a common latent space. We consider two settings: a linear DR of source and target data which establishes correspondences of the data and an according transfer, and its combination with a non-linear DR which allows to adapt to more complex data characterised by a global non-linear structure."
Ensemble Learning with Dynamic Ordered Pruning for Regression,"Kaushala Dias, Terry Windeatt",1 - Centre for Vision Speech and Signal Processing Faculty of Engineering and Physical Sciences University of Surrey GU2 7XH Guildford Surrey United Kingdom,"A novel method of introducing diversity into ensemble learning predictors for regression problems is presented. The proposed method prunes the ensemble while simultaneously training, as part of the same learning process. Here not all members of the ensemble are trained, but selectively trained, resulting in a diverse selection of ensemble members that have strengths in different parts of the training set. The result is that the prediction accuracy and generalization ability of the trained ensemble is enhanced. Pruning heuristics attempt to combine accurate yet complementary members; therefore this method enhances the performance by dynamically modifying the pruned aggregation through distributing the ensemble member selection over the entire dataset. A comparison is drawn with Negative Correlation Learning and a static ensemble pruning approach used in regression to highlight the performance improvement yielded by the dynamic method. Experimental comparison is made using Multiple Layer Perceptron predictors on benchmark datasets.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-135.pdf,2015,100.0,"Ensemble Learning with Dynamic Ordered Pruning for Regression A novel method of introducing diversity into ensemble learning predictors for regression problems is presented. The proposed method prunes the ensemble while simultaneously training, as part of the same learning process. Here not all members of the ensemble are trained, but selectively trained, resulting in a diverse selection of ensemble members that have strengths in different parts of the training set. The result is that the prediction accuracy and generalization ability of the trained ensemble is enhanced. Pruning heuristics attempt to combine accurate yet complementary members; therefore this method enhances the performance by dynamically modifying the pruned aggregation through distributing the ensemble member selection over the entire dataset. A comparison is drawn with Negative Correlation Learning and a static ensemble pruning approach used in regression to highlight the performance improvement yielded by the dynamic method. Experimental comparison is made using Multiple Layer Perceptron predictors on benchmark datasets."
A simple technique for improving multi-class classification with neural networks,"Thomas Kopinski, Alexander Gepperth, Uwe Handmann","1 - University Ruhr West -Computer Science Institute Lützowstrasse 5 46236 Bottrop Germany
2 - ENSTA ParisTech 828 Blvd des Maréchaux 91762 Palaiseau France","We present a novel method to perform multi-class pattern classification with neural networks and test it on a challenging 3D hand gesture recognition problem. Our method consists of a standard oneagainst-all (OAA) classification, followed by another network layer classifying the resulting class scores, possibly augmented by the original raw input vector. This allows the network to disambiguate hard-to-separate classes as the distribution of class scores carries considerable information as well, and is in fact often used for assessing the confidence of a decision. We show that by this approach we are able to significantly boost our results, overall as well as for particular difficult cases, on the hard 10-class gesture classification task.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-136.pdf,2015,100.0,"A simple technique for improving multi-class classification with neural networks We present a novel method to perform multi-class pattern classification with neural networks and test it on a challenging 3D hand gesture recognition problem. Our method consists of a standard oneagainst-all (OAA) classification, followed by another network layer classifying the resulting class scores, possibly augmented by the original raw input vector. This allows the network to disambiguate hard-to-separate classes as the distribution of class scores carries considerable information as well, and is in fact often used for assessing the confidence of a decision. We show that by this approach we are able to significantly boost our results, overall as well as for particular difficult cases, on the hard 10-class gesture classification task."
Geometrical homotopy for data visualization,"Diego Peluffo-Ordóñez, Juan Alvarado-Pérez, John Lee, Michel Verleysen","1 - Universidad de Salamanca 3-Machine Learning Group -ICTEAM
2 - Université Catholique de Louvain
3 - Molecular Imaging Radiotherapy and Oncology -IREC Université Catholique de Louvain
4 - Faculty of Engineering Universidad Cooperativa de 1-Eslinga research group Colombia","This work presents an approach allowing for an interactive visualization of dimensionality reduction outcomes, which is based on an extended view of conventional homotopy. The pairwise functional followed from a simple homotopic function can be incorporated within a geometrical framework in order to yield a biparametric approach able to combine several kernel matrices. Therefore, the users can establish the mixture of kernels in an intuitive fashion by only varying two parameters. Our approach is tested by using kernel alternatives for conventional methods of spectral dimensionality reduction such as multidimensional scalling, locally linear embedding and laplacian eigenmaps. The proposed mixture represents every single dimensionality reduction approach as well as helps users to find a suitable representation of embedded data.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-137.pdf,2015,100.0,"Geometrical homotopy for data visualization This work presents an approach allowing for an interactive visualization of dimensionality reduction outcomes, which is based on an extended view of conventional homotopy. The pairwise functional followed from a simple homotopic function can be incorporated within a geometrical framework in order to yield a biparametric approach able to combine several kernel matrices. Therefore, the users can establish the mixture of kernels in an intuitive fashion by only varying two parameters. Our approach is tested by using kernel alternatives for conventional methods of spectral dimensionality reduction such as multidimensional scalling, locally linear embedding and laplacian eigenmaps. The proposed mixture represents every single dimensionality reduction approach as well as helps users to find a suitable representation of embedded data."
Graphs in machine learning: an introduction,"Pierre Latouche, Fabrice Rossi","1 - Université Paris 1 Panthéon-Sorbonne -Laboratoire
2 - SAMM EA 90 rue de Tolbiac 4543, F-75634 Paris Cedex 13 France","Graphs are commonly used to characterise interactions between objects of interest. Because they are based on a straightforward formalism, they are used in many scientific fields from computer science to historical sciences. In this paper, we give an introduction to some methods relying on graphs for learning. This includes both unsupervised and supervised methods. Unsupervised learning algorithms usually aim at visualising graphs in latent spaces and/or clustering the nodes. Both focus on extracting knowledge from graph topologies. While most existing techniques are only applicable to static graphs, where edges do not evolve through time, recent developments have shown that they could be extended to deal with evolving networks. In a supervised context, one generally aims at inferring labels or numerical values attached to nodes using both the graph and, when they are available, node characteristics. Balancing the two sources of information can be challenging, especially as they can disagree locally or globally. In both contexts, supervised and unsupervised, data can be relational (augmented with one or several global graphs) as described above, or graph valued. In this latter case, each object of interest is given as a full graph (possibly completed by other characteristics). In this context, natural tasks include graph clustering (as in producing clusters of graphs rather than clusters of nodes in a single graph), graph classification, etc. 
 Real networks One of the first practical studies on graphs can be dated back to the original work of Moreno [51]  in the 30s. Since then, there has been a growing interest in graph analysis associated with strong developments in the modelling and the processing of these data. Graphs are now used in many scientific fields. In Biology [54, 2, 7] , for instance, metabolic networks can describe pathways of biochemical reactions  [41] , while in social sciences networks are used to represent relation ties between actors  [66, 56, 36, 34] . Other examples include powergrids [71] and the web  [75] . Recently, networks have also been considered in other areas such as geography  [22]  and history  [59, 39] . In machine learning, networks are seen as powerful tools to model problems in order to extract information from data and for prediction purposes. This is the object of this paper. For more complete surveys, we refer to  [28, 62, 49, 45] . In this section, we introduce notations and highlight properties shared by most real networks. In Section 2, we then consider methods aiming at extracting information from a unique network. We will particularly focus on clustering methods where the goal is to find clusters of vertices. Finally, in Section 3, techniques that take a series of networks into account, where each network is",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-14.pdf,2015,90.69767441860466,"Graphs in machine learning: an introduction Graphs are commonly used to characterise interactions between objects of interest. Because they are based on a straightforward formalism, they are used in many scientific fields from computer science to historical sciences. In this paper, we give an introduction to some methods relying on graphs for learning. This includes both unsupervised and supervised methods. Unsupervised learning algorithms usually aim at visualising graphs in latent spaces and/or clustering the nodes. Both focus on extracting knowledge from graph topologies. While most existing techniques are only applicable to static graphs, where edges do not evolve through time, recent developments have shown that they could be extended to deal with evolving networks. In a supervised context, one generally aims at inferring labels or numerical values attached to nodes using both the graph and, when they are available, node characteristics. Balancing the two sources of information can be challenging, especially as they can disagree locally or globally. In both contexts, supervised and unsupervised, data can be relational (augmented with one or several global graphs) as described above, or graph valued. In this latter case, each object of interest is given as a full graph (possibly completed by other characteristics). In this context, natural tasks include graph clustering (as in producing clusters of graphs rather than clusters of nodes in a single graph), graph classification, etc. 
 Real networks One of the first practical studies on graphs can be dated back to the original work of Moreno [51]  in the 30s. Since then, there has been a growing interest in graph analysis associated with strong developments in the modelling and the processing of these data. Graphs are now used in many scientific fields. In Biology [54, 2, 7] , for instance, metabolic networks can describe pathways of biochemical reactions  [41] , while in social sciences networks are used to represent relation ties between actors  [66, 56, 36, 34] . Other examples include powergrids [71] and the web  [75] . Recently, networks have also been considered in other areas such as geography  [22]  and history  [59, 39] . In machine learning, networks are seen as powerful tools to model problems in order to extract information from data and for prediction purposes. This is the object of this paper. For more complete surveys, we refer to  [28, 62, 49, 45] . In this section, we introduce notations and highlight properties shared by most real networks. In Section 2, we then consider methods aiming at extracting information from a unique network. We will particularly focus on clustering methods where the goal is to find clusters of vertices. Finally, in Section 3, techniques that take a series of networks into account, where each network is"
Multi-objective optimization perspectives on reinforcement learning algorithms using reward vectors,Mȃdȃlina Drugan,1 - Artificial Intelligence Lab Vrije Universiteit Brussels Pleinlaan 2 1050-B Brussels Belgium,"Reinforcement learning is a machine learning area that studies which actions an agent can take in order to optimize a cumulative reward function. Recently, a new class of reinforcement learning algorithms with multiple, possibly conflicting, reward functions was proposed. We call this class of algorithms the multi-objective reinforcement learning (MORL) paradigm. We give an overview on multi-objective optimization techniques imported in MORL and their theoretical simplified variant with a single state, namely the multi-objective multi-armed bandits (MOMAB) paradigm. * Madalina M. Drugan was supported by the IWT-SBO project PERPETUAL (gr. nr. 110041) and FWO project ""Multi-criteria RL"" (gr. nr. G.087814N).",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-15.pdf,2015,100.0,"Multi-objective optimization perspectives on reinforcement learning algorithms using reward vectors Reinforcement learning is a machine learning area that studies which actions an agent can take in order to optimize a cumulative reward function. Recently, a new class of reinforcement learning algorithms with multiple, possibly conflicting, reward functions was proposed. We call this class of algorithms the multi-objective reinforcement learning (MORL) paradigm. We give an overview on multi-objective optimization techniques imported in MORL and their theoretical simplified variant with a single state, namely the multi-objective multi-armed bandits (MOMAB) paradigm. * Madalina M. Drugan was supported by the IWT-SBO project PERPETUAL (gr. nr. 110041) and FWO project ""Multi-criteria RL"" (gr. nr. G.087814N)."
Unsupervised dimensionality reduction: the challenges of big data visualisation,"Kerstin Bunte, John Lee","1 - Université catholique de Louvain -ICTEAM Institute -MLG Place du Levant 3 B-1348 -Louvain-la-Neuve Belgium
3 - Université catholique de Louvain -IREC Institute -MIRO Avenue Hippocrate 55 B-1200 Bruxelles Belgium","Dimensionality reduction is an unsupervised task that allows high-dimensional data to be processed or visualised in lower-dimensional spaces. This tutorial reviews the basic principles of dimensionality reduction and discusses some of the approaches that were published over the past years from the perspective of their application to big data. The tutorial ends with a short review of papers about dimensionality reduction in these proceedings, as well as some perspectives for the near future.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-16.pdf,2015,98.08917197452229,"Unsupervised dimensionality reduction: the challenges of big data visualisation Dimensionality reduction is an unsupervised task that allows high-dimensional data to be processed or visualised in lower-dimensional spaces. This tutorial reviews the basic principles of dimensionality reduction and discusses some of the approaches that were published over the past years from the perspective of their application to big data. The tutorial ends with a short review of papers about dimensionality reduction in these proceedings, as well as some perspectives for the near future."
Advances in Learning Analytics and Educational Data Mining,"Mehrnoosh Vahdat, Alessandro Ghio, Luca Oneto, Davide Anguita, Mathias Funk, Matthias Rauterberg","1 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy
2 - Department of Industrial Design Technical University Eindhoven P.O. Box 513 5600 MB Eindhoven The Netherlands
3 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy","The growing interest in recent years towards Learning Analytics (LA) and Educational Data Mining (EDM) has enabled novel approaches and advancements in educational settings. The wide variety of research and practice in this context has enforced important possibilities and applications from adaptation and personalization of Technology Enhanced Learning (TEL) systems to improvement of instructional design and pedagogy choices based on students needs. LA and EDM play an important role in enhancing learning processes by offering innovative methods of development and integration of more personalized, adaptive, and interactive educational environments. This has motivated the organization of the ESANN 2015 Special Session in Advances in Learning Analytics and Educational Data Mining. Here, a review of research and practice in LA and EDM is presented accompanied by the most central methods, benefits, and challenges of the field. Additionally, this paper covers a review of novel contributions into the Special Session. * This work was supported in part by the Erasmus Mundus Joint Doctorate in Interactive and Cognitive Environments, which is funded by the EACEA Agency of the European Commission under EMJD ICE FPA n o 2010-0012.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-18.pdf,2015,79.3103448275862,"Advances in Learning Analytics and Educational Data Mining The growing interest in recent years towards Learning Analytics (LA) and Educational Data Mining (EDM) has enabled novel approaches and advancements in educational settings. The wide variety of research and practice in this context has enforced important possibilities and applications from adaptation and personalization of Technology Enhanced Learning (TEL) systems to improvement of instructional design and pedagogy choices based on students needs. LA and EDM play an important role in enhancing learning processes by offering innovative methods of development and integration of more personalized, adaptive, and interactive educational environments. This has motivated the organization of the ESANN 2015 Special Session in Advances in Learning Analytics and Educational Data Mining. Here, a review of research and practice in LA and EDM is presented accompanied by the most central methods, benefits, and challenges of the field. Additionally, this paper covers a review of novel contributions into the Special Session. * This work was supported in part by the Erasmus Mundus Joint Doctorate in Interactive and Cognitive Environments, which is funded by the EACEA Agency of the European Commission under EMJD ICE FPA n o 2010-0012."
I see you: On Neural Networks for Indoor Geolocation,"Johannes Pohl, Andreas Noack",1 - University of Applied Sciences Stralsund Germany,"We propose a new passive system for indoor localization of mobile nodes. After the setup, our system only relies on arbitrary wireless communication from the nodes, whereby neither the mobile nodes nor the communication needs to be under our control. The presented system is composed of three Artificial Neural Networks (ANN) using a radiomap approach and the Received Signal Strength (RSS) for localization. A Probabilistic Neural Network (PNN) decides between two Generalized Regression Neural Networks (GRNN) that process the actual RSS measurement. In practical experiments we achieve a mean location error of 0.58 m which is 22.64% better than a single GRNN approach in our setup.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-2.pdf,2015,78.84615384615384,"I see you: On Neural Networks for Indoor Geolocation We propose a new passive system for indoor localization of mobile nodes. After the setup, our system only relies on arbitrary wireless communication from the nodes, whereby neither the mobile nodes nor the communication needs to be under our control. The presented system is composed of three Artificial Neural Networks (ANN) using a radiomap approach and the Received Signal Strength (RSS) for localization. A Probabilistic Neural Network (PNN) decides between two Generalized Regression Neural Networks (GRNN) that process the actual RSS measurement. In practical experiments we achieve a mean location error of 0.58 m which is 22.64% better than a single GRNN approach in our setup."
Improving the Random Forest Algorithm by Randomly Varying the Size of the Bootstrap Samples for Low Dimensional Data Sets,"Md Nasim, Md Islam",1 - School of Computing and Mathematics Centre for Research in Complex Systems (CRiCS Charles Sturt University 2795 Bathurst NSW Australia,"The Random Forest algorithm generates quite diverse decision trees as the base classifiers for high dimensional data sets. However, for low dimensional data sets the diversity among the trees falls sharply. In Random Forest, the size of the bootstrap samples generally remains the same every time to generate a decision tree as the base classifier. In this paper we propose to vary the size of the bootstrap samples randomly within a predefined range in order to increase diversity among the trees. We conduct an elaborate experimentation on several low dimensional data sets from UCI Machine Learning Repository. The experimental results show the effectiveness of our proposed technique.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-21.pdf,2015,68.59504132231405,"Improving the Random Forest Algorithm by Randomly Varying the Size of the Bootstrap Samples for Low Dimensional Data Sets The Random Forest algorithm generates quite diverse decision trees as the base classifiers for high dimensional data sets. However, for low dimensional data sets the diversity among the trees falls sharply. In Random Forest, the size of the bootstrap samples generally remains the same every time to generate a decision tree as the base classifier. In this paper we propose to vary the size of the bootstrap samples randomly within a predefined range in order to increase diversity among the trees. We conduct an elaborate experimentation on several low dimensional data sets from UCI Machine Learning Repository. The experimental results show the effectiveness of our proposed technique."
The prediction of learning performance using features of note taking activities,"Minoru Nakayama, Kouichi Mutsuura, Hiroh Yamamoto","1 - Human System Science Tokyo Institute of Technology Ookayama Meguro-ku 152-8552 Tokyo Japan
2 - School of Economics Shinshu University Asahi 390-8621 Matsumoto Japan
3 - Shinshu University Asahi 390-8621 Matsumoto Japan","To promote effective learning in online learning environments, the prediction of learning performance is necessary, using various features of learning behaviour. In a blended learning course, participant's note taking activity reflects learning performance, and the possibility of predicting performance in final exams is examined using metrics of participant's characteristics and features of the contents of notes taken during the course. According to the results of this prediction performance, features of notetaking activities are a significant source of information to predict the score of final exams. Also, the accuracy of this prediction was evaluated using factors of the feature extraction procedure and the course instructions.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-22.pdf,2015,100.0,"The prediction of learning performance using features of note taking activities To promote effective learning in online learning environments, the prediction of learning performance is necessary, using various features of learning behaviour. In a blended learning course, participant's note taking activity reflects learning performance, and the possibility of predicting performance in final exams is examined using metrics of participant's characteristics and features of the contents of notes taken during the course. According to the results of this prediction performance, features of notetaking activities are a significant source of information to predict the score of final exams. Also, the accuracy of this prediction was evaluated using factors of the feature extraction procedure and the course instructions."
A New Fuzzy Neural System with Applications,"Yuanyuan Chai, Jun Chen, Wei Luo","1 - Defense Science and Technology Information Center -Network Center Fucheng Road 26#, Haidian district Beijing China, China","Through a comprehensive study of existing fuzzy neural systems, this paper presents a Choquet integral-OWA operator based fuzzy neural system named AggFNS as a new hybrid method of CI, which has advantages in universal fuzzy inference operators and importance factor expression during reasoning process. AggFNS was applied in traffic level of service evaluation problem and the experimental results showed that AggFNS has great nonlinear mapping function and approximation capability by training, which could be used for complex systems modeling, prediction and control.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-23.pdf,2015,88.37209302325581,"A New Fuzzy Neural System with Applications Through a comprehensive study of existing fuzzy neural systems, this paper presents a Choquet integral-OWA operator based fuzzy neural system named AggFNS as a new hybrid method of CI, which has advantages in universal fuzzy inference operators and importance factor expression during reasoning process. AggFNS was applied in traffic level of service evaluation problem and the experimental results showed that AggFNS has great nonlinear mapping function and approximation capability by training, which could be used for complex systems modeling, prediction and control."
Weighted Clustering of Sparse Educational Data,"Mirka Saarela, Tommi Kärkkäinen",1 - Department of Mathematical Information Technology University of Jyväskylä 40014 Jyväskylä Finland,"Clustering as an unsupervised technique is predominantly used in unweighted settings. In this paper, we present an efficient version of a robust clustering algorithm for sparse educational data that takes the weights, aligning a sample with the corresponding population, into account. The algorithm is utilized to divide the Finnish student population of PISA 2012 (the latest data from the Programme for International Student Assessment) into groups, according to their attitudes and perceptions towards mathematics, for which one third of the data is missing. Furthermore, necessary modifications of three cluster indices to reveal an appropriate number of groups are proposed and demonstrated.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-24.pdf,2015,100.0,"Weighted Clustering of Sparse Educational Data Clustering as an unsupervised technique is predominantly used in unweighted settings. In this paper, we present an efficient version of a robust clustering algorithm for sparse educational data that takes the weights, aligning a sample with the corresponding population, into account. The algorithm is utilized to divide the Finnish student population of PISA 2012 (the latest data from the Programme for International Student Assessment) into groups, according to their attitudes and perceptions towards mathematics, for which one third of the data is missing. Furthermore, necessary modifications of three cluster indices to reveal an appropriate number of groups are proposed and demonstrated."
A WiSARD-based multi-term memory framework for online tracking of objects,"Daniel Do Nascimento, Rafael De Carvalho, Félix Mora-Camino, Priscila Lima, Felipe França","1 - COPPE Universidade Federal do Rio de Janeiro 2 -NCE BRAZIL
3 - Universidade Federal do Tocantins UFT BRAZIL
4 - Ecole Nationale de l'Aviation Civile -Laboratoire d'Automatique FRANCE","In this paper it is proposed a generic object tracker with realtime performance. The proposed tracker is inspired on the hierarchical short-term and medium-term memories for which patterns are stored as discriminators of a WiSARD weightless neural network. This approach is evaluated through benchmark video sequences published by Babenko et al. Experiments show that the WiSARD-based approach outperforms most of the previous results in the literature, with respect to the same dataset.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-26.pdf,2015,100.0,"A WiSARD-based multi-term memory framework for online tracking of objects In this paper it is proposed a generic object tracker with realtime performance. The proposed tracker is inspired on the hierarchical short-term and medium-term memories for which patterns are stored as discriminators of a WiSARD weightless neural network. This approach is evaluated through benchmark video sequences published by Babenko et al. Experiments show that the WiSARD-based approach outperforms most of the previous results in the literature, with respect to the same dataset."
Thompson Sampling for Multi-Objective Multi-Armed Bandits Problem,"Saba Yahyaa, Bernard Manderick",1 - Computational Modeling group Computer Science Department Artificial Intelligence Lab Vrije Universiteit Brussel Pleinlaan 2 1050 Brussels Belgium,"The multi-objective multi-armed bandit (M OM AB) problem is a sequential decision process with stochastic rewards. Each arm generates a vector of rewards instead of a single scalar reward. Moreover, these multiple rewards might be conflicting. The M OM AB-problem has a set of Pareto optimal arms and an agent's goal is not only to find that set but also to play evenly or fairly the arms in that set. To find the Pareto optimal arms, linear scalarized function or Pareto dominance relations can be used. The linear scalarized function converts the multiobjective optimization problem into a single objective one and is a very popular approach because of its simplicity. The Pareto dominance relations optimizes directly the multi-objective problem. In this paper, we extend the Thompson Sampling policy to be used in the M OM AB problem. We propose Pareto Thompson Sampling and linear scalarized Thompson Sampling approaches. We compare empirically between Pareto Thompson Sampling and linear scalarized Thompson Sampling on a test suite of M OM AB problems with Bernoulli distributions. Pareto Thompson Sampling is the approach with the best empirical performance.",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-27.pdf,2015,100.0,"Thompson Sampling for Multi-Objective Multi-Armed Bandits Problem The multi-objective multi-armed bandit (M OM AB) problem is a sequential decision process with stochastic rewards. Each arm generates a vector of rewards instead of a single scalar reward. Moreover, these multiple rewards might be conflicting. The M OM AB-problem has a set of Pareto optimal arms and an agent's goal is not only to find that set but also to play evenly or fairly the arms in that set. To find the Pareto optimal arms, linear scalarized function or Pareto dominance relations can be used. The linear scalarized function converts the multiobjective optimization problem into a single objective one and is a very popular approach because of its simplicity. The Pareto dominance relations optimizes directly the multi-objective problem. In this paper, we extend the Thompson Sampling policy to be used in the M OM AB problem. We propose Pareto Thompson Sampling and linear scalarized Thompson Sampling approaches. We compare empirically between Pareto Thompson Sampling and linear scalarized Thompson Sampling on a test suite of M OM AB problems with Bernoulli distributions. Pareto Thompson Sampling is the approach with the best empirical performance."
On the equivalence between regularized NMF and similarity-augmented graph partitioning,"Anthony Coutant, Hoel Le Capitaine, Philippe Leray",1 - LINA (UMR CNRS 6241) -DUKe Research Group Ecole Polytechnique Université de Nantes France,"Many papers pointed out the interest of (co-)clustering both data and features in a dataset to obtain better performances than methods focused on data only. In addition, recent work have shown that data and features lie in low dimensional manifolds embedded into the original space and this information has been introduced as regularization terms in clustering objectives. Very popular and recent examples are regularized NMF algorithms. However, these techniques have difficulties to avoid local optima and require high computation times, making them inadequate for large scale data. In this paper, we show that NMF with manifolds regularization on a binary matrix is mathematically equivalent to an edgecut partitioning in a graph augmented with manifolds information in the case of hard co-clustering. Based on these results, we explore experimentally the efficiency of regularized graph partitioning methods for hard coclustering on more relaxed datasets and show that regularized multi-level graph partitioning is much faster and often find better clustering results than regularized NMF, and other well-known algorithms.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-28.pdf,2015,100.0,"On the equivalence between regularized NMF and similarity-augmented graph partitioning Many papers pointed out the interest of (co-)clustering both data and features in a dataset to obtain better performances than methods focused on data only. In addition, recent work have shown that data and features lie in low dimensional manifolds embedded into the original space and this information has been introduced as regularization terms in clustering objectives. Very popular and recent examples are regularized NMF algorithms. However, these techniques have difficulties to avoid local optima and require high computation times, making them inadequate for large scale data. In this paper, we show that NMF with manifolds regularization on a binary matrix is mathematically equivalent to an edgecut partitioning in a graph augmented with manifolds information in the case of hard co-clustering. Based on these results, we explore experimentally the efficiency of regularized graph partitioning methods for hard coclustering on more relaxed datasets and show that regularized multi-level graph partitioning is much faster and often find better clustering results than regularized NMF, and other well-known algorithms."
Predicting the profitability of agricultural enterprises in dairy farming,"Maria Yli-Heikkilä, Jukka Tauriainen, Mika Sulkava","1 - Natural Resources Institute Finland (Luke) -Economics and Social Sciences Tietotie 2 C FI-31600 Jokioinen Finland
2 - Natural Resources Institute Finland (Luke) -Economics and Social Sciences Kampusranta 9 C FI-60320 Seinäjoki Finland
3 - Natural Resources Institute Finland (Luke) -Economics and Social Sciences Latokartanonkaari 9 FI-00790 Helsinki Finland","Profitability and other economic aspects of agriculture can be analyzed using various machine learning methods. In this paper, we compare linear, additive and recursive partitioning -based models for predicting the profitability of farms using information easily available to a dairy farmer. We find that an ensemble of recursive partitioning methods provides the best prediction accuracy. We also analyze the importance of the predictor variables. These findings may turn out to be useful in increasing our understanding of the factors affecting farm profitability and developing a web-service for farmers to predict the performance of their own farm enterprise.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-29.pdf,2015,100.0,"Predicting the profitability of agricultural enterprises in dairy farming Profitability and other economic aspects of agriculture can be analyzed using various machine learning methods. In this paper, we compare linear, additive and recursive partitioning -based models for predicting the profitability of farms using information easily available to a dairy farmer. We find that an ensemble of recursive partitioning methods provides the best prediction accuracy. We also analyze the importance of the predictor variables. These findings may turn out to be useful in increasing our understanding of the factors affecting farm profitability and developing a web-service for farmers to predict the performance of their own farm enterprise."
Comparison of Numerical Models and Statistical Learning for Wind Speed Prediction,"Nils Treiber, Stephan Späth, Justin Heinermann, Lueder Von Bremen, Oliver Kramer","1 - Computational Intelligence Group Carl von Ossietzky University 26111 Oldenburg Germany
2 - ForWind -Center for Wind Energy Research Carl von Ossietzky University 26129 Oldenburg Germany","After decades of dominating wind forecasts based on numerical weather predictions, statistical models gained attention for shortestterm forecast horizons in the recent past. A rigorous experimental comparison between both model types is rare. In this paper, we compare COSMO-DE EPS forecasts from the German Meteorological Service (DWD) postprocessed with non-homogeneous Gaussian regression to a multivariate support vector regression model. Further, a hybrid model is introduced that employs a weighted prediction of both approaches.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-31.pdf,2015,100.0,"Comparison of Numerical Models and Statistical Learning for Wind Speed Prediction After decades of dominating wind forecasts based on numerical weather predictions, statistical models gained attention for shortestterm forecast horizons in the recent past. A rigorous experimental comparison between both model types is rare. In this paper, we compare COSMO-DE EPS forecasts from the German Meteorological Service (DWD) postprocessed with non-homogeneous Gaussian regression to a multivariate support vector regression model. Further, a hybrid model is introduced that employs a weighted prediction of both approaches."
An affinity matrix approach for structure selection of extreme learning machines,"David Pinto, Andre Lemos, Antonio Braga","1 - Dept of Electronics Federal University of Minas Gerais Belo Horizonte, Minas Gerais Brazil","This paper proposes a novel pruning approach for Extreme Learning Machines. Hidden neurons ranking and selection are performed using a priori information expressed by affinity matrices. We show that the similarity between the affinity matrix of the input patterns and the affinity matrix of the hidden layer output patterns can be seen as a measure of the data structural retention through the network. However, from a certain similarity level, adding new hidden nodes will have small or no effect on the amount of information propagated from the input. The proposed approach automatically determines this level and hence the suitable number of hidden nodes. Experiments are performed using classification problems to validate the proposed approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-32.pdf,2015,100.0,"An affinity matrix approach for structure selection of extreme learning machines This paper proposes a novel pruning approach for Extreme Learning Machines. Hidden neurons ranking and selection are performed using a priori information expressed by affinity matrices. We show that the similarity between the affinity matrix of the input patterns and the affinity matrix of the hidden layer output patterns can be seen as a measure of the data structural retention through the network. However, from a certain similarity level, adding new hidden nodes will have small or no effect on the amount of information propagated from the input. The proposed approach automatically determines this level and hence the suitable number of hidden nodes. Experiments are performed using classification problems to validate the proposed approach."
Bernoulli Bandits An Empirical Comparison,Unknown,"1 - Computer Sciences Department -AI Lab Vrije Universiteit Brussel 2 -B-1050 Pleinlaan, Brussels Belgium
2 - Moi University P.o -Box 3900-30100 -Eldoret Kenya","An empirical comparative study is made of a sample of action selection policies on a test suite of the Bernoulli multi-armed bandit with K = 10, K = 20 and K = 50 arms, each for which we consider several success probabilities. For such problems the rewards are either Success or Failure with unknown success rate. Our study focusses ongreedy, UCB1-Tuned, Thompson sampling, the Gittin's index policy, the knowledge gradient and a new hybrid algorithm. The last two are not wellknown in computer science. In this paper, we examine policy dependence on the horizon and report results which suggest that a new hybridized procedure based on Thompsons sampling improves on its regret.",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-33.pdf,2015,67.46987951807229,"Bernoulli Bandits An Empirical Comparison An empirical comparative study is made of a sample of action selection policies on a test suite of the Bernoulli multi-armed bandit with K = 10, K = 20 and K = 50 arms, each for which we consider several success probabilities. For such problems the rewards are either Success or Failure with unknown success rate. Our study focusses ongreedy, UCB1-Tuned, Thompson sampling, the Gittin's index policy, the knowledge gradient and a new hybrid algorithm. The last two are not wellknown in computer science. In this paper, we examine policy dependence on the horizon and report results which suggest that a new hybridized procedure based on Thompsons sampling improves on its regret."
I/S-Race: An iterative Multi-Objective Racing Algorithm for the SVM Parameter Selection Problem,"Péricles Miranda, Ricardo Silva, Ricardo Prudêncio","1 - Centro de Informática Universidade Federal de Pernambuco Brazil
2 - DEINFO -Universidade Federal Rural de Pernambuco Brazil","Finding appropriate values for the parameters of an algorithm is an important and time consuming task. Recent studies have shown that racing algorithms can effectively handle this task. This paper presents a multi-objective racing algorithm called iterative S-Race (I/S-Race), which efficiently addresses multi-objective model selection problems in the sense of Pareto optimality. We evaluate the I/S-Race for selecting parameters of SVMs, considering 20 widely-used classification datasets. The results revealed that the I/S-Race is an efficient and effective algorithm for automatic model selection, when compared to a brute-force multi-objective selection approach and the S-Race algorithm.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-34.pdf,2015,100.0,"I/S-Race: An iterative Multi-Objective Racing Algorithm for the SVM Parameter Selection Problem Finding appropriate values for the parameters of an algorithm is an important and time consuming task. Recent studies have shown that racing algorithms can effectively handle this task. This paper presents a multi-objective racing algorithm called iterative S-Race (I/S-Race), which efficiently addresses multi-objective model selection problems in the sense of Pareto optimality. We evaluate the I/S-Race for selecting parameters of SVMs, considering 20 widely-used classification datasets. The results revealed that the I/S-Race is an efficient and effective algorithm for automatic model selection, when compared to a brute-force multi-objective selection approach and the S-Race algorithm."
Learning Matrix Quantization and Variants of Relevance Learning,"K Domaschke, M Kaden, M Lange, T Villmann","1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia Germany
4 - 1 -Life Science Inkubator Dresden Dresden Germany","We propose an extension of the learning vector quantization framework for matrix data. Data in matrix form occur in several areas like gray-scale images, time dependent spectra or fMRI data. If the matrix data are vectorized, important spatial information may be lost. Thus, processing matrix data in matrix form seems to be more appropriate. However, it requires matrix dissimilarities for data comparison. Here Schatten-p-norms come into play. We show that they can be used in a natural way replacing the vector dissimilarities in the learning framework. Moreover, we transfer the concept of vectorial relevance learning also to this new matrix variant. We apply the resulting learning matrix quantization approach to the classification of time-dependent fluorescence spectra as an exemplary real world application. 2 Learning Vector Quantization based on l p -norms LVQ was introduced by KOHONEN as an intuitive prototype based learning classifier for vector data heuristically approximating a Bayes-classifier  [11] . The generalized learn- * M. Kaden is supported by a grant of the European Social Fund, Saxony (ESF).",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-35.pdf,2015,80.95238095238095,"Learning Matrix Quantization and Variants of Relevance Learning We propose an extension of the learning vector quantization framework for matrix data. Data in matrix form occur in several areas like gray-scale images, time dependent spectra or fMRI data. If the matrix data are vectorized, important spatial information may be lost. Thus, processing matrix data in matrix form seems to be more appropriate. However, it requires matrix dissimilarities for data comparison. Here Schatten-p-norms come into play. We show that they can be used in a natural way replacing the vector dissimilarities in the learning framework. Moreover, we transfer the concept of vectorial relevance learning also to this new matrix variant. We apply the resulting learning matrix quantization approach to the classification of time-dependent fluorescence spectra as an exemplary real world application. 2 Learning Vector Quantization based on l p -norms LVQ was introduced by KOHONEN as an intuitive prototype based learning classifier for vector data heuristically approximating a Bayes-classifier  [11] . The generalized learn- * M. Kaden is supported by a grant of the European Social Fund, Saxony (ESF)."
Autoencoding Time Series for Visualisation,"Nikolaos Gianniotis, Dennis Kügler, Peter Tiňo, Kai Polsterer, Ranjeev Misra","1 - Astroinformatics -Heidelberg Institute of Theoretical Studies Schloss Wolfsbrunnenweg 35 D-69118 Heidelberg Germany
3 - School of Computer Science The University of Birmingham B15 2TT Birmingham UK
5 - Inter-University Center for Astronomy and Astrophysics Post Bag 4 411007 Ganeshkhind, Pune India","We present an algorithm for the visualisation of time series. To that end we employ echo state networks to convert time series into a suitable vector representation which is capable of capturing the latent dynamics of the time series. Subsequently, the obtained vector representations are put through an autoencoder and the visualisation is constructed using the activations of the ""bottleneck"". The crux of the work lies with defining an objective function that quantifies the reconstruction error of these representations in a principled manner. We demonstrate the method on synthetic and real data.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-37.pdf,2015,83.33333333333334,"Autoencoding Time Series for Visualisation We present an algorithm for the visualisation of time series. To that end we employ echo state networks to convert time series into a suitable vector representation which is capable of capturing the latent dynamics of the time series. Subsequently, the obtained vector representations are put through an autoencoder and the visualisation is constructed using the activations of the ""bottleneck"". The crux of the work lies with defining an objective function that quantifies the reconstruction error of these representations in a principled manner. We demonstrate the method on synthetic and real data."
Solar PV Power Forecasting Using Extreme Learning Machine and Information Fusion,"Hélène Le Cadre, Ignacio Aravena, Anthony Papavasiliou","1 - Université catholique de Louvain -CORE Voie du Roman Pays 34 1348 Louvain-la-Neuve Belgium
3 - PSL Research university -CMA CS 1-MINES ParisTech, 10207 rue Claude Daunesse 06904 Sophia Antipolis Cedex France","We provide a learning algorithm combining distributed Extreme Learning Machine and an information fusion rule based on the aggregation of experts advice, to build day ahead probabilistic solar PV power production forecasts. These forecasts use, apart from the current day solar PV power production, local meteorological inputs, the most valuable of which is shown to be precipitation. Experiments are then run in one French region, Provence-Alpes-Côte d'Azur, to evaluate the algorithm performance. 
 Motivation Renewable energy integration in electric power systems is progressing at an unprecedented pace, particularly in Europe. The integration of renewable resources, however, poses several challenges to the current paradigm for operating power systems. One major challenge is to mitigate the effects of the unpredictability and volatility of renewable supply, which stems from its strong dependence on weather conditions. Reserves i.e., capacity with the ability to be activated/deactivated in a short time interval, are used to handle uncertainty in power systems operations. They can be procured by flexible generation units and flexible loads in the system. Generally speaking, renewable energy integration drives system operators to increase the reserve margin. The determination of the reserve margin then becomes critical. An overestimation of reserves would result in excess online generation, which is expensive and also undermines the environmental benefits of renewable energy. An underestimation of reserves, on the other hand, can compromise system security. Currently, the process of determining reserves requirements is carried out based on ad-hoc rules, or long-term studies, in most systems. Stochastic programming is a framework that relies on an explicit modeling of uncertainty in optimization problems. When applied to the short-term scheduling of power systems, it endogenously optimizes the required reserves for the time horizon to which it is applied, outperforming ad-hoc rules in the presence of both renewable energy and component failures  [5] . The drawback of stochastic programming is that it requires a probabilistic description of the uncertain parameters, which is usually unavailable and difficult to estimate. This paper presents an algorithm based on Extreme Learning Machine (ELM), that uses daily production data and local meteorological inputs to produce a 24",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-39.pdf,2015,100.0,"Solar PV Power Forecasting Using Extreme Learning Machine and Information Fusion We provide a learning algorithm combining distributed Extreme Learning Machine and an information fusion rule based on the aggregation of experts advice, to build day ahead probabilistic solar PV power production forecasts. These forecasts use, apart from the current day solar PV power production, local meteorological inputs, the most valuable of which is shown to be precipitation. Experiments are then run in one French region, Provence-Alpes-Côte d'Azur, to evaluate the algorithm performance. 
 Motivation Renewable energy integration in electric power systems is progressing at an unprecedented pace, particularly in Europe. The integration of renewable resources, however, poses several challenges to the current paradigm for operating power systems. One major challenge is to mitigate the effects of the unpredictability and volatility of renewable supply, which stems from its strong dependence on weather conditions. Reserves i.e., capacity with the ability to be activated/deactivated in a short time interval, are used to handle uncertainty in power systems operations. They can be procured by flexible generation units and flexible loads in the system. Generally speaking, renewable energy integration drives system operators to increase the reserve margin. The determination of the reserve margin then becomes critical. An overestimation of reserves would result in excess online generation, which is expensive and also undermines the environmental benefits of renewable energy. An underestimation of reserves, on the other hand, can compromise system security. Currently, the process of determining reserves requirements is carried out based on ad-hoc rules, or long-term studies, in most systems. Stochastic programming is a framework that relies on an explicit modeling of uncertainty in optimization problems. When applied to the short-term scheduling of power systems, it endogenously optimizes the required reserves for the time horizon to which it is applied, outperforming ad-hoc rules in the presence of both renewable energy and component failures  [5] . The drawback of stochastic programming is that it requires a probabilistic description of the uncertain parameters, which is usually unavailable and difficult to estimate. This paper presents an algorithm based on Extreme Learning Machine (ELM), that uses daily production data and local meteorological inputs to produce a 24"
Learning Sparse Feature Representations using Probabilistic Quadtrees and Deep Belief Nets,"Saikat Basu, Manohar Karki, Sangram Ganguly, Robert Dibiano, Supratik Mukhopadhyay, Ramakrishna Nemani","1 - Department of Computer Science Baton Rouge Louisiana State University 70803 Louisiana USA
3 - Bay Area Environmental Research Institute (BAERI) /NASA Ames Research Center 94035 Moffett Field California USA
6 - NASA Advanced Supercomputing Division
7 - NASA Ames Research Center 94035 Moffett Field California USA","Learning sparse feature representations is a useful instrument for solving an unsupervised learning problem. In this paper, we present three labeled handwritten digit datasets, collectively called n-MNIST. Then, we propose a novel framework for the classification of handwritten digits that learns sparse representations using probabilistic quadtrees and Deep Belief Nets. On the MNIST and n-MNIST datasets, our framework shows promising results and significantly outperforms traditional Deep Belief Networks.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-40.pdf,2015,100.0,"Learning Sparse Feature Representations using Probabilistic Quadtrees and Deep Belief Nets Learning sparse feature representations is a useful instrument for solving an unsupervised learning problem. In this paper, we present three labeled handwritten digit datasets, collectively called n-MNIST. Then, we propose a novel framework for the classification of handwritten digits that learns sparse representations using probabilistic quadtrees and Deep Belief Nets. On the MNIST and n-MNIST datasets, our framework shows promising results and significantly outperforms traditional Deep Belief Networks."
Morisita-Based Feature Selection for Regression Problems,"Jean Golay, Michael Leuenberger, Mikhail Kanevski","1 - Surface Dynamics (IDYST) University of Lausanne -Institute of Earth
2 - UNIL-Mouline 1015 Lausanne Switzerland","Data acquisition, storage and management have been improved, while the factors of many phenomena are not well known. Consequently, irrelevant and redundant features artificially increase the size of datasets, which complicates learning tasks, such as regression. To address this problem, feature selection methods have been proposed. This research introduces a new supervised filter based on the Morisita estimator of intrinsic dimension. The algorithm is simple and does not rely on arbitrary parameters. It is applied to both synthetic and real data and a comparison with a wrapper based on extreme learning machine is conducted.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-41.pdf,2015,71.42857142857143,"Morisita-Based Feature Selection for Regression Problems Data acquisition, storage and management have been improved, while the factors of many phenomena are not well known. Consequently, irrelevant and redundant features artificially increase the size of datasets, which complicates learning tasks, such as regression. To address this problem, feature selection methods have been proposed. This research introduces a new supervised filter based on the Morisita estimator of intrinsic dimension. The algorithm is simple and does not rely on arbitrary parameters. It is applied to both synthetic and real data and a comparison with a wrapper based on extreme learning machine is conducted."
Adaptive structure metrics for automated feedback provision in Java programming,"Benjamin Paassen, Bassam Mokbel, Barbara Hammer",1 - CITEC centre of excellence Bielefeld University Germany,"Today's learning supporting systems for programming mostly rely on pre-coded feedback provision, such that their applicability is restricted to modelled tasks. In this contribution, we investigate the suitability of machine learning techniques to automate this process by means of a presentation of similar solution strategies from a set of stored examples. To this end we apply structure metric learning methods in local and global alignment which can be used to compare Java programs. We demonstrate that automatically adapted metrics better identify the underlying programming strategy as compared to their default counterparts in a benchmark example from programming. * Funding by the DFG under grant numbers HA 2719/6-1 and HA 2719/6-2 and the CITEC center of excellence is gratefully acknowledged.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-43.pdf,2015,100.0,"Adaptive structure metrics for automated feedback provision in Java programming Today's learning supporting systems for programming mostly rely on pre-coded feedback provision, such that their applicability is restricted to modelled tasks. In this contribution, we investigate the suitability of machine learning techniques to automate this process by means of a presentation of similar solution strategies from a set of stored examples. To this end we apply structure metric learning methods in local and global alignment which can be used to compare Java programs. We demonstrate that automatically adapted metrics better identify the underlying programming strategy as compared to their default counterparts in a benchmark example from programming. * Funding by the DFG under grant numbers HA 2719/6-1 and HA 2719/6-2 and the CITEC center of excellence is gratefully acknowledged."
Online One-class Classification for Intrusion Detection Based on the Mahalanobis Distance,"Patric Nader, Paul Honeine, Pierre Beauseroy",1 - Institut Charles Delaunay (CNRS) Université de technologie de Troyes 10000 Troyes France,"Machine learning techniques have been very popular in the past decade for their ability to detect hidden patterns in large volumes of data. Researchers have been developing online intrusion detection algorithms based on these techniques. In this paper, we propose an online one-class classification approach based on the Mahalanobis distance which takes into account the covariance in each feature direction and the different scaling of the coordinate axes. We define the one-class problem by two concentric hyperspheres enclosing the support vectors of the description. We update the classifier at each time step. The tests are conducted on real data.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-45.pdf,2015,100.0,"Online One-class Classification for Intrusion Detection Based on the Mahalanobis Distance Machine learning techniques have been very popular in the past decade for their ability to detect hidden patterns in large volumes of data. Researchers have been developing online intrusion detection algorithms based on these techniques. In this paper, we propose an online one-class classification approach based on the Mahalanobis distance which takes into account the covariance in each feature direction and the different scaling of the coordinate axes. We define the one-class problem by two concentric hyperspheres enclosing the support vectors of the description. We update the classifier at each time step. The tests are conducted on real data."
Resource-efficient incremental learning in very high dimensions,"Alexander Gepperth, Mathieu Lefort, Thomas Hecht, Ursula Körner","1 - ENSTA ParisTech/UIIS INRIA FLOWERS 828 Boulevard des Maréchaux 200 avenue de la Vieille Tour 91762, 33405 Palaiseau, Talence Cedex France
4 - Honda Research Institute Europe GmbH Carl-Legien-Str.30 73076 Offenbach am Main Germany","We propose a three-layer neural architecture for incremental multi-class learning that remains resource-efficient even when the number of input dimensions is very high (≥ 1000). This so-called projectionprediction (PROPRE) architecture is strongly inspired by biological information processing in that it uses a prototype-based, topologically organized hidden layers trained with the SOM learning rule controlled by a global, task-related error signal. Furthermore, the SOM learning adapts only the weights of localized neural sub-populations that are similar to the input, which explicitly avoids the catastrophic forgetting effect of MLPs in case new input statistics are presented to the architecture. As the readout layer uses simple linear regression, the approach essentially applies locally linear models to ""receptive fields"" (RF) defined by SOM prototypes, whereas RF shape is implicitly defined by adjacent prototypes (which avoids the storage of covariance matrices that gets prohibitive for high input dimensionality). Both RF centers and shapes are jointly adapted w.r.t. input statistics and the classification task. Tests on the MNIST dataset show that the algorithm achieves compares favorably compared to the state-of-the-art LWPR algorithm at vastly decreased resource requirements. * Thomas Hecht gratefully acknowledges financial support by the French Armaments Procurement Agency (DGA) and Ecole Polytechnique.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-46.pdf,2015,80.95238095238095,"Resource-efficient incremental learning in very high dimensions We propose a three-layer neural architecture for incremental multi-class learning that remains resource-efficient even when the number of input dimensions is very high (≥ 1000). This so-called projectionprediction (PROPRE) architecture is strongly inspired by biological information processing in that it uses a prototype-based, topologically organized hidden layers trained with the SOM learning rule controlled by a global, task-related error signal. Furthermore, the SOM learning adapts only the weights of localized neural sub-populations that are similar to the input, which explicitly avoids the catastrophic forgetting effect of MLPs in case new input statistics are presented to the architecture. As the readout layer uses simple linear regression, the approach essentially applies locally linear models to ""receptive fields"" (RF) defined by SOM prototypes, whereas RF shape is implicitly defined by adjacent prototypes (which avoids the storage of covariance matrices that gets prohibitive for high input dimensionality). Both RF centers and shapes are jointly adapted w.r.t. input statistics and the classification task. Tests on the MNIST dataset show that the algorithm achieves compares favorably compared to the state-of-the-art LWPR algorithm at vastly decreased resource requirements. * Thomas Hecht gratefully acknowledges financial support by the French Armaments Procurement Agency (DGA) and Ecole Polytechnique."
A New Genetic Algorithm for Multi-Label Correlation-Based Feature Selection,"Suwimol Jungjit, Alex Freitas",1 - School of Computing University of Kent Canterbury CT2 7NF UK,"This paper proposes a new Genetic Algorithm for Multi-Label Correlation-Based Feature Selection (GA-ML-CFS). This GA performs a global search in the space of candidate feature subsets, in order to select a high-quality feature subset that is used by a multi-label classification algorithm -in this work, the Multi-Label k-NN algorithm. We compare the results of GA-ML-CFS with the results of the previously proposed Hill-Climbing for Multi-Label Correlation-Based Feature Selection (HC-ML-CFS), across 10 multi-label datasets.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-48.pdf,2015,82.66666666666667,"A New Genetic Algorithm for Multi-Label Correlation-Based Feature Selection This paper proposes a new Genetic Algorithm for Multi-Label Correlation-Based Feature Selection (GA-ML-CFS). This GA performs a global search in the space of candidate feature subsets, in order to select a high-quality feature subset that is used by a multi-label classification algorithm -in this work, the Multi-Label k-NN algorithm. We compare the results of GA-ML-CFS with the results of the previously proposed Hill-Climbing for Multi-Label Correlation-Based Feature Selection (HC-ML-CFS), across 10 multi-label datasets."
Human Algorithmic Stability and Human Rademacher Complexity,"Mehrnoosh Vahdat, Luca Oneto, Alessandro Ghio, Davide Anguita, Mathias Funk, Matthias Rauterberg","1 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy
2 - Department of Industrial Design Technical University Eindhoven P.O. Box 513 5600 MB Eindhoven The Netherlands
4 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy","In Machine Learning (ML), the learning process of an algorithm given a set of evidences is studied via complexity measures. The way towards using ML complexity measures in the Human Learning (HL) domain has been paved by a previous study, which introduced Human Rademacher Complexity (HRC): in this work, we introduce Human Algorithmic Stability (HAS). Exploratory experiments, performed on a group of students, show the superiority of HAS against HRC, since HAS allows grasping the nature and complexity of the task to learn. * This work was supported in part by the Erasmus Mundus Joint Doctorate in Interactive and Cognitive Environments, which is funded by the EACEA Agency of the European Commission under EMJD ICE FPA n o 2010-2012.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-49.pdf,2015,100.0,"Human Algorithmic Stability and Human Rademacher Complexity In Machine Learning (ML), the learning process of an algorithm given a set of evidences is studied via complexity measures. The way towards using ML complexity measures in the Human Learning (HL) domain has been paved by a previous study, which introduced Human Rademacher Complexity (HRC): in this work, we introduce Human Algorithmic Stability (HAS). Exploratory experiments, performed on a group of students, show the superiority of HAS against HRC, since HAS allows grasping the nature and complexity of the task to learn. * This work was supported in part by the Erasmus Mundus Joint Doctorate in Interactive and Cognitive Environments, which is funded by the EACEA Agency of the European Commission under EMJD ICE FPA n o 2010-2012."
One-Vs-All Binarization Technique in the Context of Random Forest,"Md Nasim, Md Islam",1 - School of Computing and Mathematics Centre for Research in Complex Systems (CRiCS Charles Sturt University 2795 Bathurst NSW Australia,"Binarization techniques are widely used to solve multi-class classification problems. These techniques reduce the classification complexity of multi-class classification problems by dividing the original data set into two-class segments or replicas. Then a set of simpler classifiers are learnt from the two-class segments or replicas. The outputs from these classifiers are combined for final classification. Binarization can improve prediction accuracy when compared to a single classifier. However, to be declared as a superior technique, binarization techniques need to prove themselves in the context of ensemble classifiers such as Random Forest. Random Forest is a state-of-the-art popular decision forest building algorithm which focuses on generating diverse decision trees as the base classifiers. In this paper we evaluate one-vs-all binarization technique in the context of Random Forest. We present an elaborate experimental result involving ten widely used data sets from the UCI Machine Learning Repository. The experimental results exhibit the effectiveness of one-vs-all binarization technique in the context of Random Forest.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-5.pdf,2015,69.23076923076923,"One-Vs-All Binarization Technique in the Context of Random Forest Binarization techniques are widely used to solve multi-class classification problems. These techniques reduce the classification complexity of multi-class classification problems by dividing the original data set into two-class segments or replicas. Then a set of simpler classifiers are learnt from the two-class segments or replicas. The outputs from these classifiers are combined for final classification. Binarization can improve prediction accuracy when compared to a single classifier. However, to be declared as a superior technique, binarization techniques need to prove themselves in the context of ensemble classifiers such as Random Forest. Random Forest is a state-of-the-art popular decision forest building algorithm which focuses on generating diverse decision trees as the base classifiers. In this paper we evaluate one-vs-all binarization technique in the context of Random Forest. We present an elaborate experimental result involving ten widely used data sets from the UCI Machine Learning Repository. The experimental results exhibit the effectiveness of one-vs-all binarization technique in the context of Random Forest."
Model Selection for Big Data: Algorithmic Stability and Bag of Little Bootstraps on GPUs,"Luca Oneto, Bernardo Pilarz, Alessandro Ghio, Davide Anguita","1 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy
3 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy","Model selection is a key step in learning from data, because it allows to select optimal models, by avoiding both under-and over-fitting. However, in the Big Data framework, the effectiveness of a model selection approach is assessed not only through the accuracy of the learned model but also through the time and computational resources needed to complete the procedure. In this paper, we propose two model selection approaches for Least Squares Support Vector Machine (LS-SVM) classifiers, based on Fully-empirical Algorithmic Stability (FAS) and Bag of Little Bootstraps (BLB). The two methods scale sub-linearly respect to the size of the learning set and, therefore, are well suited for big data applications. Experiments are performed on a Graphical Processing Unit (GPU), showing up to 30x speed-ups with respect to conventional CPU-based implementations.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-50.pdf,2015,100.0,"Model Selection for Big Data: Algorithmic Stability and Bag of Little Bootstraps on GPUs Model selection is a key step in learning from data, because it allows to select optimal models, by avoiding both under-and over-fitting. However, in the Big Data framework, the effectiveness of a model selection approach is assessed not only through the accuracy of the learned model but also through the time and computational resources needed to complete the procedure. In this paper, we propose two model selection approaches for Least Squares Support Vector Machine (LS-SVM) classifiers, based on Fully-empirical Algorithmic Stability (FAS) and Bag of Little Bootstraps (BLB). The two methods scale sub-linearly respect to the size of the learning set and, therefore, are well suited for big data applications. Experiments are performed on a Graphical Processing Unit (GPU), showing up to 30x speed-ups with respect to conventional CPU-based implementations."
Discovering temporally extended features for reinforcement learning in domains with delayed causalities,"Robert Lieck, Marc Toussaint",1 - Universität Stuttgart -Machine Learning and Robotics Lab Universitätsstraße 38 -70569 Stuttgart Germany,"Discovering temporally delayed causalities from data raises notoriously hard problems in reinforcement learning. In this paper we define a space of temporally extended features, designed to capture such causal structures, using a generating operation. Our discovery algorithm PULSE exploits the generating operation to efficiently discover a sparse subset of features. We provide convergence guarantees and apply our method to train a model-based as well as a model-free agent in different domains. In terms of achieved rewards and the number of required features our methods can achieve much better results than other feature expansion methods.",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-52.pdf,2015,100.0,"Discovering temporally extended features for reinforcement learning in domains with delayed causalities Discovering temporally delayed causalities from data raises notoriously hard problems in reinforcement learning. In this paper we define a space of temporally extended features, designed to capture such causal structures, using a generating operation. Our discovery algorithm PULSE exploits the generating operation to efficiently discover a sparse subset of features. We provide convergence guarantees and apply our method to train a model-based as well as a model-free agent in different domains. In terms of achieved rewards and the number of required features our methods can achieve much better results than other feature expansion methods."
Gaussian process modelling of multiple short time series,"Hande Topa, Antti Honkela","1 - Department of Information and Computer Science Helsinki Institute for Information Technology HIIT
2 - Aalto University Espoo Finland
3 - Department of Computer Science Helsinki Institute for Information Technology HIIT
4 - University of Helsinki Helsinki Finland","We study effective Gaussian process (GP) modelling of multiple short time series. These problems are common for example when applying GP models independently to each gene in a gene expression time series data set. Such sets typically contain very few time points and hence naive application of common GP modelling techniques can lead to severe over-fitting in a significant fraction of the fitted models, depending on the details of the data set. We propose avoiding over-fitting by constraining the GP length-scale to values that are compatible with the spacing of the time points. We demonstrate that this eliminates otherwise serious over-fitting in real experiment using GP model to rank single nucleotide polymorphisms (SNPs) based on their likelihood of being under natural selection.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-54.pdf,2015,100.0,"Gaussian process modelling of multiple short time series We study effective Gaussian process (GP) modelling of multiple short time series. These problems are common for example when applying GP models independently to each gene in a gene expression time series data set. Such sets typically contain very few time points and hence naive application of common GP modelling techniques can lead to severe over-fitting in a significant fraction of the fitted models, depending on the details of the data set. We propose avoiding over-fitting by constraining the GP length-scale to values that are compatible with the spacing of the time points. We demonstrate that this eliminates otherwise serious over-fitting in real experiment using GP model to rank single nucleotide polymorphisms (SNPs) based on their likelihood of being under natural selection."
Long Short Term Memory Networks for Anomaly Detection in Time Series,"Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, Puneet Agarwal","1 - TCS Research Delhi India
2 - Jawaharlal Nehru University New Delhi India","Long Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length, due to their ability to maintain long term memory. Stacking recurrent hidden layers in such networks also enables the learning of higher level temporal features, for faster learning with sparser representations. In this paper, we use stacked LSTM networks for anomaly/fault detection in time series. A network is trained on non-anomalous data and used as a predictor over a number of time steps. The resulting prediction errors are modeled as a multivariate Gaussian distribution, which is used to assess the likelihood of anomalous behavior. The efficacy of this approach is demonstrated on four datasets: ECG, space shuttle, power demand, and multi-sensor engine dataset.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-56.pdf,2015,100.0,"Long Short Term Memory Networks for Anomaly Detection in Time Series Long Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length, due to their ability to maintain long term memory. Stacking recurrent hidden layers in such networks also enables the learning of higher level temporal features, for faster learning with sparser representations. In this paper, we use stacked LSTM networks for anomaly/fault detection in time series. A network is trained on non-anomalous data and used as a predictor over a number of time steps. The resulting prediction errors are modeled as a multivariate Gaussian distribution, which is used to assess the likelihood of anomalous behavior. The efficacy of this approach is demonstrated on four datasets: ECG, space shuttle, power demand, and multi-sensor engine dataset."
An objective function for self-limiting neural plasticity rules,"Rodrigo Echeveste, Claudius Gros",1 - Institute for Theoretical Physics Goethe University Frankfurt Frankfurt am Main Germany,"Self-organization provides a framework for the study of systems in which complex patterns emerge from simple rules, without the guidance of external agents or fine tuning of parameters. Within this framework, one can formulate a guiding principle for plasticity in the context of unsupervised learning, in terms of an objective function. In this work we derive Hebbian, self-limiting synaptic plasticity rules from such an objective function and then apply the rules to the non-linear bars problem.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-58.pdf,2015,99.21259842519686,"An objective function for self-limiting neural plasticity rules Self-organization provides a framework for the study of systems in which complex patterns emerge from simple rules, without the guidance of external agents or fine tuning of parameters. Within this framework, one can formulate a guiding principle for plasticity in the context of unsupervised learning, in terms of an objective function. In this work we derive Hebbian, self-limiting synaptic plasticity rules from such an objective function and then apply the rules to the non-linear bars problem."
Pareto front of bi-objective kernel-based nonnegative matrix factorization,"Fei Zhu, Paul Honeine",1 - Institut Charles Delaunay (CNRS) Université de Technologie de Troyes France,"The nonnegative matrix factorization (NMF) is a powerful data analysis and dimensionality reduction technique. So far, the NMF has been limited to a single-objective problem in either its linear or nonlinear kernel-based formulation. This paper presents a novel bi-objective NMF model based on kernel machines, where the decomposition is performed simultaneously in both input and feature spaces. The problem is solved employing the sum-weighted approach. Without loss of generality, we study the case of the Gaussian kernel, where the multiplicative update rules are derived and the Pareto front is approximated. The performance of the proposed method is demonstrated for unmixing hyperspectral images.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-59.pdf,2015,100.0,"Pareto front of bi-objective kernel-based nonnegative matrix factorization The nonnegative matrix factorization (NMF) is a powerful data analysis and dimensionality reduction technique. So far, the NMF has been limited to a single-objective problem in either its linear or nonlinear kernel-based formulation. This paper presents a novel bi-objective NMF model based on kernel machines, where the decomposition is performed simultaneously in both input and feature spaces. The problem is solved employing the sum-weighted approach. Without loss of generality, we study the case of the Gaussian kernel, where the multiplicative update rules are derived and the Pareto front is approximated. The performance of the proposed method is demonstrated for unmixing hyperspectral images."
Optimal transport for semi-supervised domain adaptation,"Denis Rousselle, Stéphane Canu","1 - Normandie Université INSA de Rouen -LITIS EA 4108 Avenue de l'Université BP 8 76801 Saint-Etienne-du-Rouvray FRANCE
2 - Thales Underwater Systems Route de sainte Anne du Portzic 43814, 29238 Brest cedex 3 CS FRANCE","Domain adaption for semi-supervised learning is still a challenging task. Indeed, available solutions are often slow and fail to provide relevant interpretations. Here we propose a new algorithm to solve this problem of semi-supervised domain adaptation efficiently, by using an adapted combination of transportation algorithms. Our empirical evidence supports our initial intuition, showing the interest of the proposed method. 
 Motivation Statistical learning usually makes the assumption that training and testing data are drawn from the same distribution. Dataset shift occurs when this assumption is violated [for a detailed presentation see 1]. In that case, the problem amounts to finding a transformation that transports data and learned structures from a training domain, toward a test domain. This is the problem of domain adaptation (DA). Our work focuses on a particular case of domain adaptation for supervised learning, when a subset of the target labels is known. This problem is referred as semi-supervised domain adaptation. An interesting solution to semi-supervised domain adaptation has been introduced by Gong et al. [2]  providing state-of-the-art results. Their solution is a kernel-based method that takes advantage of directly exploiting data lowdimensional structures. This approach is also interesting because it facilitates comparisons. Indeed, it focuses only on data domain adaptation, regardless the classifier used to perform the supervised classification task. However, in their approach, dimension reduction used is computationally expensive and leads to the loss of data interpretability. Inspired by  [3] , we propose to address this domain adaptation issue by using an efficient and easy to parallelize optimal transport algorithm, adapted for semi-supervised domain adaptation. Furthermore, our method can be physically interpreted since links between source and target data are explicit. Before presenting our method, some notations have to be introduced. Observed input in the source domain is X s of size n s observations × d variables associated with the probability distribution μ s while Y s ∈ L ns denotes the associated labels, L being the discrete set of all possible labels. Analogously, (X t , Y t ) denote data in the target domain of size n t associated with the probability distribution μ t .",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-61.pdf,2015,100.0,"Optimal transport for semi-supervised domain adaptation Domain adaption for semi-supervised learning is still a challenging task. Indeed, available solutions are often slow and fail to provide relevant interpretations. Here we propose a new algorithm to solve this problem of semi-supervised domain adaptation efficiently, by using an adapted combination of transportation algorithms. Our empirical evidence supports our initial intuition, showing the interest of the proposed method. 
 Motivation Statistical learning usually makes the assumption that training and testing data are drawn from the same distribution. Dataset shift occurs when this assumption is violated [for a detailed presentation see 1]. In that case, the problem amounts to finding a transformation that transports data and learned structures from a training domain, toward a test domain. This is the problem of domain adaptation (DA). Our work focuses on a particular case of domain adaptation for supervised learning, when a subset of the target labels is known. This problem is referred as semi-supervised domain adaptation. An interesting solution to semi-supervised domain adaptation has been introduced by Gong et al. [2]  providing state-of-the-art results. Their solution is a kernel-based method that takes advantage of directly exploiting data lowdimensional structures. This approach is also interesting because it facilitates comparisons. Indeed, it focuses only on data domain adaptation, regardless the classifier used to perform the supervised classification task. However, in their approach, dimension reduction used is computationally expensive and leads to the loss of data interpretability. Inspired by  [3] , we propose to address this domain adaptation issue by using an efficient and easy to parallelize optimal transport algorithm, adapted for semi-supervised domain adaptation. Furthermore, our method can be physically interpreted since links between source and target data are explicit. Before presenting our method, some notations have to be introduced. Observed input in the source domain is X s of size n s observations × d variables associated with the probability distribution μ s while Y s ∈ L ns denotes the associated labels, L being the discrete set of all possible labels. Analogously, (X t , Y t ) denote data in the target domain of size n t associated with the probability distribution μ t ."
Ranking Overlap and Outlier Points in Data using Soft Kernel Spectral Clustering,"Raghvendra Mall, Rocco Langone, Johan Suykens",1 - KU Leuven ESAT/STADIUS Kasteelpark Arenberg 10 B-3001 Leuven Belgium,"Soft clustering algorithms can handle real-life datasets better as they capture the presence of inherent overlapping clusters. A soft kernel spectral clustering (SKSC) method proposed in [1] exploited the eigen-projections of the points to assign them different cluster membership probabilities. In this paper, we detect points in dense overlapping regions as overlap points. We also identify the outlier points by exploiting the eigen-projections. We then propose novel ranking techniques using structure and similarity properties in the eigen-space to rank these overlap and outlier points. By ranking the overlap and outlier points we provide an order for the most and least influential points in the dataset. We demonstrate the effectiveness of our ranking measures on several datasets.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-64.pdf,2015,100.0,"Ranking Overlap and Outlier Points in Data using Soft Kernel Spectral Clustering Soft clustering algorithms can handle real-life datasets better as they capture the presence of inherent overlapping clusters. A soft kernel spectral clustering (SKSC) method proposed in [1] exploited the eigen-projections of the points to assign them different cluster membership probabilities. In this paper, we detect points in dense overlapping regions as overlap points. We also identify the outlier points by exploiting the eigen-projections. We then propose novel ranking techniques using structure and similarity properties in the eigen-space to rank these overlap and outlier points. By ranking the overlap and outlier points we provide an order for the most and least influential points in the dataset. We demonstrate the effectiveness of our ranking measures on several datasets."
Pareto Local Policy Search for MOMDP Planning,"Chiel Kooijman, Maarten De Waard, Maarten Inja, Diederik Roijers, Shimon Whiteson",1 - University of Amsterdam Science Park 904 1098 XH Amsterdam The Netherlands,"Standard single-objective methods such as value iteration are not applicable to multi-objective Markov decision processes (MOMDPs) because they depend on a maximization, which is not defined if the rewards are multi-dimensional. As a result, special multi-objective algorithms are needed to find a set of policies that contains all optimal trade-offs between objectives, i.e. a set of Pareto optimal policies. In this paper, we propose Pareto local policy search (PLoPS), a new planning method for MOMDPs based on Pareto local search (PLS)  [3] . This method produces a good set of policies by iteratively scanning the neighbourhood of locally non-dominated policies for improvements. It is fast because neighbouring policies can be quickly identified as improvements, and their values can be computed incrementally. We test the performance of PLoPS on several MOMDP benchmarks, and compare it to popular decision-theoretic and evolutionary alternatives. The results show that PLoPS outperforms the alternatives.",Emerging techniques and applications in multi-objective reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-65.pdf,2015,91.56626506024097,"Pareto Local Policy Search for MOMDP Planning Standard single-objective methods such as value iteration are not applicable to multi-objective Markov decision processes (MOMDPs) because they depend on a maximization, which is not defined if the rewards are multi-dimensional. As a result, special multi-objective algorithms are needed to find a set of policies that contains all optimal trade-offs between objectives, i.e. a set of Pareto optimal policies. In this paper, we propose Pareto local policy search (PLoPS), a new planning method for MOMDPs based on Pareto local search (PLS)  [3] . This method produces a good set of policies by iteratively scanning the neighbourhood of locally non-dominated policies for improvements. It is fast because neighbouring policies can be quickly identified as improvements, and their values can be computed incrementally. We test the performance of PLoPS on several MOMDP benchmarks, and compare it to popular decision-theoretic and evolutionary alternatives. The results show that PLoPS outperforms the alternatives."
Powered-Two-Wheeler safety critical events recognition using a mixture model with quadratic logistic proportions,"Ferhat Attal, Abderrahmane Boubezoul, Allou Samé, Latifa Oukhellou",1 - Université Paris-Est -IFSTTAR,"This paper presents a statistical methodology that uses both acceleration and angular velocity signals to detect critical safety events for Powered Two Wheelers (PTW). The problem of recognition of critical events has been performed towards two steps: (1) the feature extraction step, where the multidimensional time trajectories of accelerometer/gyroscope data were modeled and segmented by using a specific mixture model with quadratic logistic proportions; (2) the classification step, which consists in using the k-nearest neighbor (k-NN) algorithm in order to assign each trajectory characterized by its extracted features to one of the three classes namely Fall, near Fall and Naturalistic riding. The results show the ability of the proposed methodology to detect critical safety events for Powered Two Wheelers.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-66.pdf,2015,90.09009009009009,"Powered-Two-Wheeler safety critical events recognition using a mixture model with quadratic logistic proportions This paper presents a statistical methodology that uses both acceleration and angular velocity signals to detect critical safety events for Powered Two Wheelers (PTW). The problem of recognition of critical events has been performed towards two steps: (1) the feature extraction step, where the multidimensional time trajectories of accelerometer/gyroscope data were modeled and segmented by using a specific mixture model with quadratic logistic proportions; (2) the classification step, which consists in using the k-nearest neighbor (k-NN) algorithm in order to assign each trajectory characterized by its extracted features to one of the three classes namely Fall, near Fall and Naturalistic riding. The results show the ability of the proposed methodology to detect critical safety events for Powered Two Wheelers."
The Use of RBF Neural Network to Predict Building's Corners Hygrothermal Behavior,"Roberto Freire, ; Leandro, S Coelho, Gerson Dos Santos, Viviana Mariani, Nathan Mendes, Divani Da, S Carvalho","1 - Pontifical Catholic University of Parana (PUCPR) -Polytechnic School Rua Imaculada Conceição 1555. Postal Code 80215-901 Curitiba Brazil
3 - Federal Technological University of Parana -Department of Mechanical Engineering Av. Monteiro Lobato Km 04
4 - Postal Code 84016-210 Ponta Grossa Brazil","In this paper, a radial basis function neural network (RBF-NN) was combined with two optimization techniques, the expectation-maximization clustering method was used to tune the Gaussian activation functions centers, and the differential evolution was adopted to optimize the spreads and to local search of the centers. The modified RBF-NN was employed to predict building corners hygrothermal behavior. These specific regions of buildings are still barely explored due to modelling complexity, high computer run time, numerical divergence and highly moisture-dependent properties. Moreover, these specific building areas are constantly affected by moisture accumulation and mould growth, conditions that favor structure damages.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-67.pdf,2015,74.07407407407408,"The Use of RBF Neural Network to Predict Building's Corners Hygrothermal Behavior In this paper, a radial basis function neural network (RBF-NN) was combined with two optimization techniques, the expectation-maximization clustering method was used to tune the Gaussian activation functions centers, and the differential evolution was adopted to optimize the spreads and to local search of the centers. The modified RBF-NN was employed to predict building corners hygrothermal behavior. These specific regions of buildings are still barely explored due to modelling complexity, high computer run time, numerical divergence and highly moisture-dependent properties. Moreover, these specific building areas are constantly affected by moisture accumulation and mould growth, conditions that favor structure damages."
Median-LVQ for Classification of Dissimilarity Data based on ROC-Optimization,"D Nebel, T Villmann",1 - University of Appl. Sciences Mittweida -Dept. of Mathematics Mittweida Saxonia Germany,"In this article we consider a median variant of the learning vector quantization (LVQ) classifier for classification of dissimilarity data. However, beside the median aspect, we propose to optimize the receiver-operating characteristics (ROC) instead of the classification accuracy. In particular, we present a probabilistic LVQ model with an adaptation scheme based on a generalized Expectation-Maximization-procedure, which allows a maximization of the area under the ROCcurve for those dissimilarity data. The basic idea behind is the utilization of ordered pairs as a structured input for learning. The new scheme can be seen as a supplement to the recently introduced LVQ-scheme for ROC-optimization of vector data.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-85.pdf,2015,57.55395683453237,"Median-LVQ for Classification of Dissimilarity Data based on ROC-Optimization In this article we consider a median variant of the learning vector quantization (LVQ) classifier for classification of dissimilarity data. However, beside the median aspect, we propose to optimize the receiver-operating characteristics (ROC) instead of the classification accuracy. In particular, we present a probabilistic LVQ model with an adaptation scheme based on a generalized Expectation-Maximization-procedure, which allows a maximization of the area under the ROCcurve for those dissimilarity data. The basic idea behind is the utilization of ordered pairs as a structured input for learning. The new scheme can be seen as a supplement to the recently introduced LVQ-scheme for ROC-optimization of vector data."
Learning missing edges via kernels in partially-known graphs,"Senka Krivic, Sandor Szedmak, Hanchen Xiong, Justus Piater",1 - Institute of Computer Science University of Innsbruck Technikerstr.21a A-6020 -Innsbruck Austria,"This paper deals with the problem of learning unknown edges with attributes in a partially-given multigraph. The method is an extension of Maximum Margin Multi-Valued Regression (M 3 VM) to the case where those edges are characterized by different attributes. It is applied on a large-scale problem where an agent tries to learn unknown object-object relations by exploiting known such relations. The method can handle not only binary relations but also complex, structured relations such as text, images, collections of labels, categories, etc., which can be represented by kernels. We compare the performance with a specialized, state-of-the-art matrix completion method.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-69.pdf,2015,100.0,"Learning missing edges via kernels in partially-known graphs This paper deals with the problem of learning unknown edges with attributes in a partially-given multigraph. The method is an extension of Maximum Margin Multi-Valued Regression (M 3 VM) to the case where those edges are characterized by different attributes. It is applied on a large-scale problem where an agent tries to learn unknown object-object relations by exploiting known such relations. The method can handle not only binary relations but also complex, structured relations such as text, images, collections of labels, categories, etc., which can be represented by kernels. We compare the performance with a specialized, state-of-the-art matrix completion method."
Probabilistic Classification Vector Machine at large scale,"Frank-Michael Schleif, Andrej Gisbrecht, Peter Tino","1 - School of Computer Science The University of Birmingham Edgbaston Birmingham B15 2TT United Kingdom
2 - Theoretical Computer Science University of Bielefeld 33619 Bielefeld Germany",Probabilistic kernel classifiers are effective approaches to solve classification problems but only few of them can be applied to indefinite kernels as typically observed in life science problems and are often limited to rather small scale problems. We provide a novel batch formulation of the Probabilistic Classification Vector Machine for large scale metric and non-metric data.,Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-7.pdf,2015,100.0,Probabilistic Classification Vector Machine at large scale Probabilistic kernel classifiers are effective approaches to solve classification problems but only few of them can be applied to indefinite kernels as typically observed in life science problems and are often limited to rather small scale problems. We provide a novel batch formulation of the Probabilistic Classification Vector Machine for large scale metric and non-metric data.
Combining dissimilarity measures for prototype-based classification,"Ernest Mwebaze, Gjalt Bearda, Michael Biehl, Dietlind Zühlke","1 - Department of Information Technology Plot 56 Makerere University Makerere University Pool Road Kampala Uganda
2 - Johann Bernoulli Institute for Mathematics and Computer Science University of Groningen P.O. Box 407 9700 AK Groningen The Netherlands
4 - Department of Organized Knowledge Schloss Birlinghoven Fraunhofer Institute IAIS 53757 Sankt Augustin Germany","Prototype-based classification, identifying representatives of the data and suitable measures of dissimilarity, has been used successfully for tasks where interpretability of the classification is key. In many practical problems, one object is represented by a collection of different subsets of features, that might require different dissimilarity measures. In this paper we present a technique for combining different dissimilarity measures into a Learning Vector Quantization classification scheme for heterogeneous, mixed data. To illustrate the method we apply it to diagnosing viral crop disease in cassava plants from histograms (HSV) and shape features (SIFT) extracted from cassava leaf images. Our results demonstrate the feasibility of the method and increased performance compared to previous approaches.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-73.pdf,2015,100.0,"Combining dissimilarity measures for prototype-based classification Prototype-based classification, identifying representatives of the data and suitable measures of dissimilarity, has been used successfully for tasks where interpretability of the classification is key. In many practical problems, one object is represented by a collection of different subsets of features, that might require different dissimilarity measures. In this paper we present a technique for combining different dissimilarity measures into a Learning Vector Quantization classification scheme for heterogeneous, mixed data. To illustrate the method we apply it to diagnosing viral crop disease in cassava plants from histograms (HSV) and shape features (SIFT) extracted from cassava leaf images. Our results demonstrate the feasibility of the method and increased performance compared to previous approaches."
Efficient unsupervised clustering for spatial bird population analysis along the Loire river,"Aurore Payen, Ludovic Journaux, Clément Delion, Lucile Sautot, Bruno Faivre","1 - Université de Bourgogne -LE2I Avenue Alain Savary 21000 Dijon France
2 - Université de Bourgogne -Biogéosciences 6 Boulevard Gabriel 21000 Dijon France
4 - 1-AgroSup Dijon 26 Boulevard Docteur Petitjean 21000 Dijon","This paper deals with application and comparison of Nonlinear Dimensionality Reduction (NLDR) methods on natural high dimensional bird communities dataset along the Loire River (France). In this context, biologists usually use the well-known PCA in order to explain the upstream-downstream gradient. Unfortunately this method was unsuccessful on this kind of nonlinear dataset. This paper aims at comparing recent NLDR methods coupled with different data transformations in order to find out the best approach. Results show that Multiscale Jensen-Shannon Embedding (Ms JSE) outperforms all the other methods in this context. * Data acquisition received financial support from the FEDER Loire, Etablissement Public Loire, DREAL de Bassin Centre (Etude des oiseaux nicheurs de la Loire et de l'Allier sur l'ensemble de leurs cours) to BF, and from the Région Bourgogne (PARI, Projet Agrale 5) to BF. Data analysis received support from the French Ministry of Agriculture (Bourse FCPR to LS).",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-74.pdf,2015,99.45945945945947,"Efficient unsupervised clustering for spatial bird population analysis along the Loire river This paper deals with application and comparison of Nonlinear Dimensionality Reduction (NLDR) methods on natural high dimensional bird communities dataset along the Loire River (France). In this context, biologists usually use the well-known PCA in order to explain the upstream-downstream gradient. Unfortunately this method was unsuccessful on this kind of nonlinear dataset. This paper aims at comparing recent NLDR methods coupled with different data transformations in order to find out the best approach. Results show that Multiscale Jensen-Shannon Embedding (Ms JSE) outperforms all the other methods in this context. * Data acquisition received financial support from the FEDER Loire, Etablissement Public Loire, DREAL de Bassin Centre (Etude des oiseaux nicheurs de la Loire et de l'Allier sur l'ensemble de leurs cours) to BF, and from the Région Bourgogne (PARI, Projet Agrale 5) to BF. Data analysis received support from the French Ministry of Agriculture (Bourse FCPR to LS)."
NLDR methods for high dimensional VNIRS dataset: application to vineyard soils characterization,"Clément Delion, Ludovic Journaux, Aurore Payen, Lucile Sautot, Emmanuel Chevigny, Pierre Curmi","1 - Université de Bourgogne UMR6306 LE2I Avenue Alain Savary 21000 Dijon France
2 - Université de Bourgogne UMR6282 Biogéosciences 6 Boulevard Gabriel 21000 Dijon France
3 - UMR6298 ArteHis Université de Bourgogne 6 Boulevard Gabriel, 5-AgroSup Dijon -UMR1347 Agroécologie BP 86510 21000, 21000 Dijon, Dijon France, France
4 - 1-AgroSup Dijon 26 Boulevard du Docteur Petitjean 21000 Dijon France",In the context of vineyard soils characterization this paper explores and compare dierent recent Non Linear Dimensionality Reduction (NLDR) methods on a high-dimensional Visible and Near InfraRed Spectroscopy (VNIRS) dataset. NLDR methods are based on k-neighborhood criterion and euclidean and fractional distances metrics are tested. Results show that Multiscale Jensen-Shannon Embedding (Ms JSE) coupled with euclidean distance outperform all over methods. Application on data is performed at dierent spatial localization and at dierent depths of soil.,Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-75.pdf,2015,93.6842105263158,NLDR methods for high dimensional VNIRS dataset: application to vineyard soils characterization In the context of vineyard soils characterization this paper explores and compare dierent recent Non Linear Dimensionality Reduction (NLDR) methods on a high-dimensional Visible and Near InfraRed Spectroscopy (VNIRS) dataset. NLDR methods are based on k-neighborhood criterion and euclidean and fractional distances metrics are tested. Results show that Multiscale Jensen-Shannon Embedding (Ms JSE) coupled with euclidean distance outperform all over methods. Application on data is performed at dierent spatial localization and at dierent depths of soil.
Real-time activity recognition via deep learning of motion features,"Kishore Konda, Pramod Chandrashekhariah, Roland Memisevic, Jochen Triesch","1 - Goethe University Frankfurt Germany
2 - Frankfurt Institute for Advanced Studies Germany
3 - -University of Montreal Canada","Activity recognition is a challenging computer vision problem with countless applications. Here we present a real time activity recognition system using deep learning of local motion feature representations. Our approach learns to directly extract energy based motion features from video blocks. We implement the system on a distributed computing architecture and evaluate its performance on the iCub humanoid robot. We demonstrate real time performance using GPUs, paving the way for wide deployment of activity recognition systems in real world scenarios.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-76.pdf,2015,100.0,"Real-time activity recognition via deep learning of motion features Activity recognition is a challenging computer vision problem with countless applications. Here we present a real time activity recognition system using deep learning of local motion feature representations. Our approach learns to directly extract energy based motion features from video blocks. We implement the system on a distributed computing architecture and evaluate its performance on the iCub humanoid robot. We demonstrate real time performance using GPUs, paving the way for wide deployment of activity recognition systems in real world scenarios."
Using self-organizing maps for regression: the importance of the output function,"Thomas Hecht, Mathieu Lefort, Alexander Gepperth","1 - boulevard des Maréchaux ENSTA ParisTech -UIIS division 858 91762 Palaiseau France
3 - Inria FLOWERS -Inria Bordeaux Sud-Ouest 200 avenue de la Vieille Tour 33405 Talence France","Self-organizing map (SOM) is a powerful paradigm that is extensively applied for clustering and visualization purpose. It is also used for regression learning, especially in robotics, thanks to its ability to provide a topological projection of high dimensional non linear data. In this case, data extracted from the SOM are usually restricted to the best matching unit (BMU), which is the usual way to use SOM for classification, where class labels are attached to individual neurons. In this article, we investigate the influence of considering more information from the SOM than just the BMU when performing regression. For this purpose, we quantitatively study several output functions for the SOM, when using these data as input of a linear regression, and find that the use of additional activities to the BMU can strongly improve regression performance. Thus, we propose an unified and generic framework that embraces a large spectrum of models from the traditional way to use SOM, with the best matching unit as output, to models related to the radial basis function network paradigm, when using local receptive field as output. * Thomas Hecht gratefully acknowledges funding support by the ""Direction Générale de l'Armement"" (DGA) and École Polytechnique.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-77.pdf,2015,100.0,"Using self-organizing maps for regression: the importance of the output function Self-organizing map (SOM) is a powerful paradigm that is extensively applied for clustering and visualization purpose. It is also used for regression learning, especially in robotics, thanks to its ability to provide a topological projection of high dimensional non linear data. In this case, data extracted from the SOM are usually restricted to the best matching unit (BMU), which is the usual way to use SOM for classification, where class labels are attached to individual neurons. In this article, we investigate the influence of considering more information from the SOM than just the BMU when performing regression. For this purpose, we quantitatively study several output functions for the SOM, when using these data as input of a linear regression, and find that the use of additional activities to the BMU can strongly improve regression performance. Thus, we propose an unified and generic framework that embraces a large spectrum of models from the traditional way to use SOM, with the best matching unit as output, to models related to the radial basis function network paradigm, when using local receptive field as output. * Thomas Hecht gratefully acknowledges funding support by the ""Direction Générale de l'Armement"" (DGA) and École Polytechnique."
Prediction of Concrete Carbonation Depth using Decision Trees,"Woubishet Taffese, Esko Sistonen, Jari Puttonen",1 - Department of Civil and Structural Engineering Aalto University P. O. Box 12100 FI-00076 Aalto Finland,"In this work, three carbonation depth predicting models using decision tree approach are developed. Carbonation, in urban areas is often a reason for reinforcement steel corrosion that causes premature degradation, loss of serviceability and safety of reinforced concrete structures. The adopted decision trees are regression tree, bagged ensemble and reduced bagged ensemble regression tree. The evaluation of the predictions performance of the developed models reveals that all the three models perform reasonably well. Among them, reduced bagged ensemble regression tree showed the highest prediction and generalization capability.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-79.pdf,2015,72.1311475409836,"Prediction of Concrete Carbonation Depth using Decision Trees In this work, three carbonation depth predicting models using decision tree approach are developed. Carbonation, in urban areas is often a reason for reinforcement steel corrosion that causes premature degradation, loss of serviceability and safety of reinforced concrete structures. The adopted decision trees are regression tree, bagged ensemble and reduced bagged ensemble regression tree. The evaluation of the predictions performance of the developed models reveals that all the three models perform reasonably well. Among them, reduced bagged ensemble regression tree showed the highest prediction and generalization capability."
A Generalised Label Noise Model for Classification,Jakramate Bootkrajang,"1 - Department of Computer Science Chiang Mai University Muang Chiang Mai 50200 Thailand
2 - Faculty of Science Chiang Mai University","Learning from labelled data is becoming more and more challenging due to inherent imperfection of training labels. In this paper, we propose a new, generalised label noise model which is able to withstand the negative effect of both random noise and a wide range of non-random label noises. Empirical studies using three real-world datasets with inherent annotation errors demonstrate that the proposed generalised label noise model improves, in terms of classification accuracy, over existing label noise modelling approaches.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-80.pdf,2015,82.0,"A Generalised Label Noise Model for Classification Learning from labelled data is becoming more and more challenging due to inherent imperfection of training labels. In this paper, we propose a new, generalised label noise model which is able to withstand the negative effect of both random noise and a wide range of non-random label noises. Empirical studies using three real-world datasets with inherent annotation errors demonstrate that the proposed generalised label noise model improves, in terms of classification accuracy, over existing label noise modelling approaches."
Survival Analysis with Cox Regression and Random Non-linear Projections,"Samuel Branders, Benoît Frénay, Pierre Dupont","1 - ICTEAM/INGI -Machine Learning Group Université catholique de Louvain Place Sainte Barbe 2 1348 Louvain-la-Neuve Belgium
2 - Faculty of Computer Science Université de Namur Rue Grandgagnage 21 5000 Namur Belgium","Proportional Cox hazard models are commonly used in survival analysis, since they define risk scores which can be directly interpreted in terms of hazards. Yet they cannot account for non-linearities in their covariates. This paper shows how to use random non-linear projections to efficiently address this limitation.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-81.pdf,2015,100.0,"Survival Analysis with Cox Regression and Random Non-linear Projections Proportional Cox hazard models are commonly used in survival analysis, since they define risk scores which can be directly interpreted in terms of hazards. Yet they cannot account for non-linearities in their covariates. This paper shows how to use random non-linear projections to efficiently address this limitation."
"Online multiclass learning with ""bandit"" feedback under a Passive-Aggressive approach","Hongliang Zhong, Emmanuel Daucé, Liva Ralaivola","1 - Aix-Marseille Université 2-Institut de Neurosciences des Systèmes Laboratoire d'Informatique Fondamentale CNRS UMR 7279
2 - INSERM UMR 1106 Aix-Marseille Université 3-Ecole Centrale Marseille France","This paper presents a new approach to online multi-class learning with bandit feedback. This algorithm, named PAB (Passive Aggressive in Bandit) is a variant of Online Passive-Aggressive Algorithm proposed by  [2] , the latter being an e↵ective framework for performing max-margin online learning. We analyze some of its operating principles, and show it to provide a good and scalable solution to the bandit classification problem, particularly in the case of a real-world dataset where it outperforms the best existing algorithms.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-82.pdf,2015,100.0,"Online multiclass learning with ""bandit"" feedback under a Passive-Aggressive approach This paper presents a new approach to online multi-class learning with bandit feedback. This algorithm, named PAB (Passive Aggressive in Bandit) is a variant of Online Passive-Aggressive Algorithm proposed by  [2] , the latter being an e↵ective framework for performing max-margin online learning. We analyze some of its operating principles, and show it to provide a good and scalable solution to the bandit classification problem, particularly in the case of a real-world dataset where it outperforms the best existing algorithms."
Learning features on tear film lipid layer classification,"Beatriz Remeseiro, Verónica Bolón-Canedo, Amparo Alonso-Betanzos, Manuel Penedo",1 - Departamento de Computación Universidade da Coruña Campus de Elviña s/n 15071 A Coruña Spain,"Dry eye is a prevalent disease which leads to irritation of the ocular surface, and is associated with symptoms of discomfort and dryness. The Guillon tear film classification system is one of the most common procedures to diagnose this disease. Previous research has demonstrated that this classification can be automatized by means of image processing and machine learning techniques. However, all approaches for automatic classification have been focused on dark eyes, since they are most common in humans. This paper introduces a methodology making use of feature selection methods, to learn which features are the most relevant for each type of eyes and, thus, improving the automatic classification of the tear film lipid layer independently of the color of the eyes. Experimental results showed the adequacy of the proposed methodology, achieving classification rates over 90%, while producing unbiased results and working in real-time. * This research has been partially funded by the Secretaría de Estado de Investigación of the Spanish Government and FEDER funds of the European Union through the research projects TIN2012-37954 and PI14/02161; and by the Consellería de Industria of the Xunta de Galicia through the research projects GPC2013/065 and GRC2014/035. We would also like to thank the Optometry Service of the University of Santiago de Compostela (Spain) for providing us with the annotated datasets.",Feature and kernel learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-83.pdf,2015,100.0,"Learning features on tear film lipid layer classification Dry eye is a prevalent disease which leads to irritation of the ocular surface, and is associated with symptoms of discomfort and dryness. The Guillon tear film classification system is one of the most common procedures to diagnose this disease. Previous research has demonstrated that this classification can be automatized by means of image processing and machine learning techniques. However, all approaches for automatic classification have been focused on dark eyes, since they are most common in humans. This paper introduces a methodology making use of feature selection methods, to learn which features are the most relevant for each type of eyes and, thus, improving the automatic classification of the tear film lipid layer independently of the color of the eyes. Experimental results showed the adequacy of the proposed methodology, achieving classification rates over 90%, while producing unbiased results and working in real-time. * This research has been partially funded by the Secretaría de Estado de Investigación of the Spanish Government and FEDER funds of the European Union through the research projects TIN2012-37954 and PI14/02161; and by the Consellería de Industria of the Xunta de Galicia through the research projects GPC2013/065 and GRC2014/035. We would also like to thank the Optometry Service of the University of Santiago de Compostela (Spain) for providing us with the annotated datasets."
On the use of machine learning techniques for the analysis of spontaneous reactions in automated hearing assessment,"Verónica Bolón-Canedo, Alba Fernández, Amparo Alonso-Betanzos, Marcos Ortega, Manuel Penedo",1 - Department of Computer Science University of A Coruña Campus de Elviña s/n 15071 -A Coruña Spain,"Lack of hearing is one of the most frequent sensory deficits among elder population. Its correct assessment becomes complicated for audiologists when there are severe difficulties in the communication with the patient. Trying to facilitate this task, this paper proposes a methodology for the correct classification of eye gestural reactions to the auditory stimuli by using machine learning approaches. After extracting the features from the existing videos, we applied several classifiers and managed to improve the detection of the most important classes through the use of oversampling techniques in a novel way. This methodology showed promising results, with true positive rates over 0.96 for the critical classes and global classification rates over 97%, paving the way to its inclusion in a fully automated tool.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-84.pdf,2015,100.0,"On the use of machine learning techniques for the analysis of spontaneous reactions in automated hearing assessment Lack of hearing is one of the most frequent sensory deficits among elder population. Its correct assessment becomes complicated for audiologists when there are severe difficulties in the communication with the patient. Trying to facilitate this task, this paper proposes a methodology for the correct classification of eye gestural reactions to the auditory stimuli by using machine learning approaches. After extracting the features from the existing videos, we applied several classifiers and managed to improve the detection of the most important classes through the use of oversampling techniques in a novel way. This methodology showed promising results, with true positive rates over 0.96 for the critical classes and global classification rates over 97%, paving the way to its inclusion in a fully automated tool."
Data Analytics for Drilling Operational States Classifications,"Galina Veres, Zoheir Sabeur, Woubishet Taffese, Esko Sistonen, Jari Puttonen, Marcelo Soares, Pablo Barros, German Parisi, Stefan Wermter","1 - IT Innovation Center -Electronics and Computer Science Faculty of Physical Sciences and Engineering University of Southampton
2 - Gamma House Enterprise Road SO16 7NS Southampton UK
3 - Department of Civil and Structural Engineering Aalto University P. O. Box 12100 FI-00076 Aalto Finland
4 - Department of Computer Science University of Hamburg
5 - Vogt-Koelln-Strasse 30 22527 Hamburg Germany","This paper provides benchmarks for the identification of best performance classifiers for the detection of operational states in industrial drilling operations. Multiple scenarios for the detection of the operational states are tested on a rig with various drilling wells. Drilling data are extremely challenging due to their non-linear and stochastic natures, notwithstanding the embedded noise in them and unbalancing. Nevertheless, there is a possibility to deploy robust classifiers to overcome such challenges and achieve good automated detection of states. Three classifiers with best classification rates of drilling operational states were identified in this study.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-85.pdf,2015,100.0,"Data Analytics for Drilling Operational States Classifications This paper provides benchmarks for the identification of best performance classifiers for the detection of operational states in industrial drilling operations. Multiple scenarios for the detection of the operational states are tested on a rig with various drilling wells. Drilling data are extremely challenging due to their non-linear and stochastic natures, notwithstanding the embedded noise in them and unbalancing. Nevertheless, there is a possibility to deploy robust classifiers to overcome such challenges and achieve good automated detection of states. Three classifiers with best classification rates of drilling operational states were identified in this study."
High-School Dropout Prediction Using Machine Learning: A Danish Large-scale Study,"Nicolae-Bogdan ¸ara, Rasmus Halland, Christian Igel, Stephen Alstrup","1 - Department of Computer Science University of Copenhagen Denmark
2 - MaCom A/S Denmark","Pupils not finishing their secondary education are a big societal problem. Previous studies indicate that machine learning can be used to predict high-school dropout, which allows early interventions. To the best of our knowledge, this paper presents the first large-scale study of that kind. It considers pupils that were at least six months into their Danish high-school education, with the goal to predict dropout in the subsequent three months. We combined information from the MaCom Lectio study administration system, which is used by most Danish high schools, with data from public online sources (name database, travel planner, governmental statistics). In contrast to existing studies that were based on only a few hundred students, we considered a considerably larger sample of 36299 pupils for training and 36299 for testing. We evaluated different machine learning methods. A random forest classifier achieved an accuracy of 93.47 % and an area under the curve of 0.965. Given the large sample, we conclude that machine learning can be used to reliably detect high-school dropout given the information already available to many schools.",Advances in learning analytics and educational data mining,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-86.pdf,2015,100.0,"High-School Dropout Prediction Using Machine Learning: A Danish Large-scale Study Pupils not finishing their secondary education are a big societal problem. Previous studies indicate that machine learning can be used to predict high-school dropout, which allows early interventions. To the best of our knowledge, this paper presents the first large-scale study of that kind. It considers pupils that were at least six months into their Danish high-school education, with the goal to predict dropout in the subsequent three months. We combined information from the MaCom Lectio study administration system, which is used by most Danish high schools, with data from public online sources (name database, travel planner, governmental statistics). In contrast to existing studies that were based on only a few hundred students, we considered a considerably larger sample of 36299 pupils for training and 36299 for testing. We evaluated different machine learning methods. A random forest classifier achieved an accuracy of 93.47 % and an area under the curve of 0.965. Given the large sample, we conclude that machine learning can be used to reliably detect high-school dropout given the information already available to many schools."
A State-Space Model for the Dynamic Random Subgraph Model,"Rawya Zreik, Pierre Latouche, Charles Bouveyron","1 - Laboratoire SAMM Université Paris 1 Panthéon-Sorbonne 2-Laboratoire MAP5 4543 EA
2 - UMR CNRS 8145 Université Paris Descartes","In recent years, many random graph models have been proposed to extract information from networks. The principle is to look for groups of vertices with homogenous connection profiles. Most of these models are suitable for static networks and can handle different types of edges. This work is motivated by the need of analyzing an evolving network describing email communications between employees of the Enron compagny where social positions play an important role. Therefore, in this paper, we consider the random subgraph model (RSM) which was proposed recently to model networks through latent clusters built within known partitions. Using a state space model to characterize the cluster proportions, RSM is then extended in order to deal with dynamic networks. We call the latter the dynamic random subgraph model (dRSM).",Graphs in machine learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-87.pdf,2015,100.0,"A State-Space Model for the Dynamic Random Subgraph Model In recent years, many random graph models have been proposed to extract information from networks. The principle is to look for groups of vertices with homogenous connection profiles. Most of these models are suitable for static networks and can handle different types of edges. This work is motivated by the need of analyzing an evolving network describing email communications between employees of the Enron compagny where social positions play an important role. Therefore, in this paper, we consider the random subgraph model (RSM) which was proposed recently to model networks through latent clusters built within known partitions. Using a state space model to characterize the cluster proportions, RSM is then extended in order to deal with dynamic networks. We call the latter the dynamic random subgraph model (dRSM)."
Certainty-based Prototype Insertion/Deletion for Classification with Metric Adaptation,"Lydia Fischer, Barbara Hammer, Heiko Wersing","1 - HONDA Research Institute Europe GmbH Carl-Legien-Str. 30 63065 Offenbach Germany
2 - Bielefeld University Universitätsstr. 25 33615 Bielefeld Germany","We propose an extension of prototype-based classification models to automatically adjust model complexity, thus offering a powerful technique for online, incremental learning tasks. The incremental technique is based on the notion of the certainty of an observed classification. Unlike previous work, we can incorporate matrix learning into the framework by relying on the cost function of generalised learning vector quantisation (GLVQ) for prototype insertion, deletion, as well as training. In several benchmarks, we demonstrate that the proposed method provides comparable results to offline counterparts and an incremental support vector machine, while enabling a better control of the required memory.",Prototype-based and weightless models,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-88.pdf,2015,76.74418604651163,"Certainty-based Prototype Insertion/Deletion for Classification with Metric Adaptation We propose an extension of prototype-based classification models to automatically adjust model complexity, thus offering a powerful technique for online, incremental learning tasks. The incremental technique is based on the notion of the certainty of an observed classification. Unlike previous work, we can incorporate matrix learning into the framework by relying on the cost function of generalised learning vector quantisation (GLVQ) for prototype insertion, deletion, as well as training. In several benchmarks, we demonstrate that the proposed method provides comparable results to offline counterparts and an incremental support vector machine, while enabling a better control of the required memory."
Revisiting ant colony algorithms to seismic faults detection,"W Maciel, C Vasconcelos, P Silva, M Gattass","1 - Pontifícia Universidade Católica do Rio de Janeiro -Tecgraf Institute Marquês de São Vicente 225 Gávea, Rio de Janeiro Brazil
2 - Department of Computer Science Universidade Federal Fluminense
3 - Lara Vilela 126, São Domingos Niterói Brazil","Seismic fault extracting is a time consuming task that can be aided by image enhancement of fault areas. The recent literature addresses this task by using ant colony optimization (ACO) algorithms to highlight the fault edges. This work proposes improvements to current state of the art methods by revisiting and/or reincorporating classic aspects of ACO, such as ant distribution, pheromone evaporation and deposition, not previously considered in this seismic fault enhancement scenario.The proposed approach arrives at good results presenting images with little noise and great localization of fault edges.",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-89.pdf,2015,100.0,"Revisiting ant colony algorithms to seismic faults detection Seismic fault extracting is a time consuming task that can be aided by image enhancement of fault areas. The recent literature addresses this task by using ant colony optimization (ACO) algorithms to highlight the fault edges. This work proposes improvements to current state of the art methods by revisiting and/or reincorporating classic aspects of ACO, such as ant distribution, pheromone evaporation and deposition, not previously considered in this seismic fault enhancement scenario.The proposed approach arrives at good results presenting images with little noise and great localization of fault edges."
Reducing offline evaluation bias of collaborative filtering algorithms,"Arnaud De Myttenaere, Boris Golden, Bénédicte Le Grand, Fabrice Rossi","1 - Université Paris 1 Panthéon -Sorbonne -SAMM EA 90 rue de Tolbiac 4534, 75013 Paris France
2 - Panthéon -Sorbonne -Centre de Recherche en Informatique 90 rue de Tolbiac 75013 Paris France
4 - Université Paris
6 - 1 -Viadeo 30 rue de la Victoire 75009 Paris France","Recommendation systems have been integrated into the majority of large online systems to filter and rank information according to user profiles. It thus influences the way users interact with the system and, as a consequence, bias the evaluation of the performance of a recommendation algorithm computed using historical data (via offline evaluation). This paper presents a new application of a weighted offline evaluation to reduce this bias for collaborative filtering algorithms.",Regression and prediction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-90.pdf,2015,91.47286821705426,"Reducing offline evaluation bias of collaborative filtering algorithms Recommendation systems have been integrated into the majority of large online systems to filter and rank information according to user profiles. It thus influences the way users interact with the system and, as a consequence, bias the evaluation of the performance of a recommendation algorithm computed using historical data (via offline evaluation). This paper presents a new application of a weighted offline evaluation to reduce this bias for collaborative filtering algorithms."
"Hierarchical, prototype-based clustering of multiple time series with missing values","Pekka Wartiainen, Tommi Kärkkäinen",1 - Department of Mathematical Information Technology University of Jyvaskyla University of Jyvaskyla P.O. Box 35 40014 Finland,"A novel technique based on a robust clustering algorithm and multiple internal cluster indices is proposed. The suggested, hierarchical approach allows one to generate a dynamic decision tree like structure to represent the original data in the leaf nodes. It is applied here to divide a given set of multiple time series containing missing values into disjoint subsets. The whole algorithm is first described and then experimented with one particular data set from the UCI repository, already used in [1] for a similar exploration. The obtained results are very promising.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-91.pdf,2015,100.0,"Hierarchical, prototype-based clustering of multiple time series with missing values A novel technique based on a robust clustering algorithm and multiple internal cluster indices is proposed. The suggested, hierarchical approach allows one to generate a dynamic decision tree like structure to represent the original data in the leaf nodes. It is applied here to divide a given set of multiple time series containing missing values into disjoint subsets. The whole algorithm is first described and then experimented with one particular data set from the UCI repository, already used in [1] for a similar exploration. The obtained results are very promising."
Solving Constrained Lasso and Elastic Net Using ν-SVMs,"Carlos Alaíz, Alberto Torres, José Dorronsoro",1 - Departamento de Ingeniería Informática Tomás y Valiente 11 Universidad Autónoma de Madrid 28049 Madrid Spain,"Many important linear sparse models have at its core the Lasso problem, for which the GLMNet algorithm is often considered as the current state of the art. Recently M. Jaggi has observed that Constrained Lasso (CL) can be reduced to a SVM-like problem, which opens the way to use efficient SVM algorithms to solve CL. We will refine Jaggi's arguments to reduce CL as well as constrained Elastic Net to a Nearest Point Problem and show experimentally that the well known LIBSVM library results in a faster convergence than GLMNet for small problems and also, if properly adapted, for larger ones.","Feature and model selection, sparse models",https://www.esann.org/sites/default/files/proceedings/legacy/es2015-95.pdf,2015,67.88990825688073,"Solving Constrained Lasso and Elastic Net Using ν-SVMs Many important linear sparse models have at its core the Lasso problem, for which the GLMNet algorithm is often considered as the current state of the art. Recently M. Jaggi has observed that Constrained Lasso (CL) can be reduced to a SVM-like problem, which opens the way to use efficient SVM algorithms to solve CL. We will refine Jaggi's arguments to reduce CL as well as constrained Elastic Net to a Nearest Point Problem and show experimentally that the well known LIBSVM library results in a faster convergence than GLMNet for small problems and also, if properly adapted, for larger ones."
Diffusion Maps Parameters Selection Based on Neighbourhood Preservation,"Carlos Alaíz, Ángela Fernández, José Dorronsoro",1 - Universidad Autónoma de Madrid & Instituto de Ingeniería del Conocimiento Tomás y Valiente 11 28049 Madrid Spain,"Diffusion Maps is one of the leading methods for dimensionality reduction, although it requires to fix a certain number of parameters that can be crucial for its performance. This parameter selection is usually based on the expertise of the user, as there are no unified criterion for evaluating the quality of the embedding. We propose to use a neighbourhood preservation measure as the criterion for fixing these parameters. As we shall see, this approach provides good embedding parameters without needing problem specific knowledge. * With partial support from Spain's grants TIN2013-42351-P and S2013/ICE-2845 CASI-CAM-CM, and the Cátedra UAM-ADIC in Data Science and Machine Learning. The authors also acknowledge the use of the facilities of Centro de Computación Científica (CCC) at UAM.",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-97.pdf,2015,81.69014084507043,"Diffusion Maps Parameters Selection Based on Neighbourhood Preservation Diffusion Maps is one of the leading methods for dimensionality reduction, although it requires to fix a certain number of parameters that can be crucial for its performance. This parameter selection is usually based on the expertise of the user, as there are no unified criterion for evaluating the quality of the embedding. We propose to use a neighbourhood preservation measure as the criterion for fixing these parameters. As we shall see, this approach provides good embedding parameters without needing problem specific knowledge. * With partial support from Spain's grants TIN2013-42351-P and S2013/ICE-2845 CASI-CAM-CM, and the Cátedra UAM-ADIC in Data Science and Machine Learning. The authors also acknowledge the use of the facilities of Centro de Computación Científica (CCC) at UAM."
Rank-Constrainted Optimization: A Riemannian Manifold Approach * †,"Guifang Zhou, Wen Huang, Kyle Gallivan, Paul Van Dooren, P.-A Absil","1 - Department of Mathematics Florida State University 1017 Academic Way 32306-4510 Tallahassee FL US
2 - Université catholique de Louvain -ICTEAM Institute Avenue G. Lemaître 4 1348 Louvain-la-Neuve Belgium",This paper presents an algorithm that solves optimization problems on a matrix manifold M ⊆ R m×n with an additional rank inequality constraint. New geometric objects are defined to facilitate efficiently finding a suitable rank. The convergence properties of the algorithm are given and a weighted low-rank approximation problem is used to illustrate the efficiency and effectiveness of the algorithm.,Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-122,2015,51.470588235294116,Rank-Constrainted Optimization: A Riemannian Manifold Approach * † This paper presents an algorithm that solves optimization problems on a matrix manifold M ⊆ R m×n with an additional rank inequality constraint. New geometric objects are defined to facilitate efficiently finding a suitable rank. The convergence properties of the algorithm are given and a weighted low-rank approximation problem is used to illustrate the efficiency and effectiveness of the algorithm.
Adaptive dissimilarity weighting for prototype-based classification optimizing mixtures of dissimilarities,"M Kaden, D Nebel, T Villmann",1 - Computational Intelligence Group University of Applied Sciences Mittweida Technikumplatz 17 09648 Mittweida Germany,"In this paper we propose an adaptive bilinear mixing of dissimilarities for better classification learning. In particular, we focus on prototype based learning like learning vector quantization. In this sense the learning of the mixture can be seen as a kind of dissimilarity learning as counterpart to dissimilarity selection in advance. We demonstrate this approach working for relational as well as median variants of prototype learning for proximity data.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-100.pdf,2016,100.0,"Adaptive dissimilarity weighting for prototype-based classification optimizing mixtures of dissimilarities In this paper we propose an adaptive bilinear mixing of dissimilarities for better classification learning. In particular, we focus on prototype based learning like learning vector quantization. In this sense the learning of the mixture can be seen as a kind of dissimilarity learning as counterpart to dissimilarity selection in advance. We demonstrate this approach working for relational as well as median variants of prototype learning for proximity data."
Policy-gradient Methods for Decision Trees,"Aurélia Léon, Ludovic Denoyer","1 - UMR 7606 Sorbonne Universités UPMC Univ Paris 06 LIP6, F-75005 Paris France","We propose a new type of decision trees able to learn at the same time how inputs fall in the tree and which predictions are associated to the leaves. The main advantage of this approach is to be based on the optimization of a global loss function instead of using heuristic-based greedy techniques, while keeping the good characteristics of decision trees. The learning algorithm is inspired by reinforcement learning and based on gradient-descent based methods, allowing a fast optimization. Moreover the algorithm is not limited to (mono-label) classification task and can be used for any predictive problem while a derivable loss function exist. Experimental results show the effectiveness of the method w.r.t baselines. 1 Note that the model naturally handles other predictive problems when a derivable loss function exists, and is not restricted to classification.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-102.pdf,2016,80.95238095238095,"Policy-gradient Methods for Decision Trees We propose a new type of decision trees able to learn at the same time how inputs fall in the tree and which predictions are associated to the leaves. The main advantage of this approach is to be based on the optimization of a global loss function instead of using heuristic-based greedy techniques, while keeping the good characteristics of decision trees. The learning algorithm is inspired by reinforcement learning and based on gradient-descent based methods, allowing a fast optimization. Moreover the algorithm is not limited to (mono-label) classification task and can be used for any predictive problem while a derivable loss function exist. Experimental results show the effectiveness of the method w.r.t baselines. 1 Note that the model naturally handles other predictive problems when a derivable loss function exists, and is not restricted to classification."
Learning Embeddings for Completion and Prediction of Relationnal Multivariate Time-Series,"Ali Ziat, Gabriella Contardo, Nicolas Baskiotis, Ludovic Denoyer","1 - Institut VEDECOM Versailles France
2 - UMR 7606 Sorbonne Universités UPMC Univ Paris 06 LIP6, F-75005 Paris France","We focus on learning over multivariate and relational timeseries where relations are modeled by a graph. We propose a model that is able to simultaneously fill in missing values and predict future ones. This approach is based on representation learning techniques, where temporal data are represented in a latent vector space so as to capture the dynamicity of the process and also the relations between the different sources. Information completion (missing values) and prediction are performed simultaneously using a unique formalism, whereas most often they are addressed separately using different methods.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-103.pdf,2016,100.0,"Learning Embeddings for Completion and Prediction of Relationnal Multivariate Time-Series We focus on learning over multivariate and relational timeseries where relations are modeled by a graph. We propose a model that is able to simultaneously fill in missing values and predict future ones. This approach is based on representation learning techniques, where temporal data are represented in a latent vector space so as to capture the dynamicity of the process and also the relations between the different sources. Information completion (missing values) and prediction are performed simultaneously using a unique formalism, whereas most often they are addressed separately using different methods."
Anomaly detection on spectrograms using datadriven and fixed dictionary representations,"M Abdel-Sayed, D Duclos, G Faÿ, J Lacaille, M Mougeot","1 - -SafranTech (SAFRAN) -TSI Rue des Jeunes Bois Châteaufort 78772 Magny-Les-Hameaux France
2 - Ecole CentraleSupélec -MICS Grande Voie des Vignes 92290 Châtenay-Malabry France
3 - Université Paris Diderot -LPMA 5 rue Thomas Mann 75013 Paris France
6 - Snecma (SAFRAN) Rond point René Ravaud 77550 Moissy-Cramayel France","Spectrograms provide a visual representation of the vibrations of civil aircraft engines. The vibrations contain information relative to damage in the engine, if any. This representation is noisy, high dimensional and the relevant signatures relative to damages concern only a small part of the spectrogram. All these arguments lead to difficulties to automatically detect anomalies in the spectrogram. Adequate lower dimensional representations of the spectrograms are needed. In this paper, we study two types of representations with dictionary, a data-driven one and a non-adaptive one and we show their benefits for automatic anomaly detection.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-104.pdf,2016,93.71428571428572,"Anomaly detection on spectrograms using datadriven and fixed dictionary representations Spectrograms provide a visual representation of the vibrations of civil aircraft engines. The vibrations contain information relative to damage in the engine, if any. This representation is noisy, high dimensional and the relevant signatures relative to damages concern only a small part of the spectrogram. All these arguments lead to difficulties to automatically detect anomalies in the spectrogram. Adequate lower dimensional representations of the spectrograms are needed. In this paper, we study two types of representations with dictionary, a data-driven one and a non-adaptive one and we show their benefits for automatic anomaly detection."
"Feature Binding in Deep Convolution Networks with Recurrences, Oscillations, and Top-Down Modulated Dynamics","Martin Mundt, Sebastian Blaes, Thomas Burwick",1 - Frankfurt Institute for Advanced Studies (FIAS) Goethe University Frankfurt Ruth Moufang-Str. 1 60438 Frankfurt am Main Germany,"Deep convolution networks are extended with an oscillatory phase dynamics and recurrent couplings that are based on convolution and deconvolution. Moreover, top-down modulation is included that enforces the dynamical selection and grouping of features of the recognized object into assemblies based on temporal coherence. With respect to image processing, it is demonstrated how the combination of these mechanisms allow for the segmentation of the parts of the objects that are relevant for its classification.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-105.pdf,2016,77.77777777777779,"Feature Binding in Deep Convolution Networks with Recurrences, Oscillations, and Top-Down Modulated Dynamics Deep convolution networks are extended with an oscillatory phase dynamics and recurrent couplings that are based on convolution and deconvolution. Moreover, top-down modulation is included that enforces the dynamical selection and grouping of features of the recognized object into assemblies based on temporal coherence. With respect to image processing, it is demonstrated how the combination of these mechanisms allow for the segmentation of the parts of the objects that are relevant for its classification."
Spatial Chirp-Z Transformer Networks,"Jonas Degrave, Sander Dieleman, Joni Dambre, Francis Wyffels",1 - Electric and Information Systems (ELIS) Ghent University Sint Pietersnieuwstraat 41 9000 Gent Belgium,"Convolutional Neural Networks are often used for computer vision solutions, because of their inherent modeling of the translation invariance in images. In this paper, we propose a new module to model rotation and scaling invariances in images. To do this, we rely on the chirp-Z transform to perform the desired translation, rotation and scaling in the frequency domain. This approach has the benefit that it scales well and that it is differentiable because of the computationally cheap sincinterpolation. * The research leading to these results has received funding from the European Commission (EC) Human Brain Project under grant agreement No 604102, and from the Agency for Innovation by Science and Technology in Flanders (IWT). The Tesla K40 used for this research was donated by the NVIDIA Corporation.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-107.pdf,2016,100.0,"Spatial Chirp-Z Transformer Networks Convolutional Neural Networks are often used for computer vision solutions, because of their inherent modeling of the translation invariance in images. In this paper, we propose a new module to model rotation and scaling invariances in images. To do this, we rely on the chirp-Z transform to perform the desired translation, rotation and scaling in the frequency domain. This approach has the benefit that it scales well and that it is differentiable because of the computationally cheap sincinterpolation. * The research leading to these results has received funding from the European Commission (EC) Human Brain Project under grant agreement No 604102, and from the Agency for Innovation by Science and Technology in Flanders (IWT). The Tesla K40 used for this research was donated by the NVIDIA Corporation."
Gaussian process prediction for time series of structured data,"Benjamin Paassen, Christina Göpfert, Barbara Hammer",1 - CITEC center of excellence Bielefeld University Germany,"Time series prediction constitutes a classic topic in machine learning with wide-ranging applications, but mostly restricted to the domain of vectorial sequence entries. In recent years, time series of structured data (such as sequences, trees or graph structures) have become more and more important, for example in social network analysis or intelligent tutoring systems. In this contribution, we propose an extension of time series models to strucured data based on Gaussian processes and structure kernels. We also provide speedup techniques for predictions in linear time, and we evaluate our approach on real data from the domain of intelligent tutoring systems. * Funding by the DFG under grant number HA 2719/6-2 and the CITEC center of excellence (EXC 277) is gratefully acknowledged.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-109.pdf,2016,100.0,"Gaussian process prediction for time series of structured data Time series prediction constitutes a classic topic in machine learning with wide-ranging applications, but mostly restricted to the domain of vectorial sequence entries. In recent years, time series of structured data (such as sequences, trees or graph structures) have become more and more important, for example in social network analysis or intelligent tutoring systems. In this contribution, we propose an extension of time series models to strucured data based on Gaussian processes and structure kernels. We also provide speedup techniques for predictions in linear time, and we evaluate our approach on real data from the domain of intelligent tutoring systems. * Funding by the DFG under grant number HA 2719/6-2 and the CITEC center of excellence (EXC 277) is gratefully acknowledged."
Assessment of diabetic retinopathy risk with random forests,"Silvia Sanromà, Antonio Moreno, Aida Valls, Pedro Romero, Sofia De La Riva, Ramon Sagarra","1 - Departament d'Enginyeria Informàtica
4 - Hospital Universitari Sant Joan -Universitat Rovira i Virgili Av. Dr. Josep Laporte
5 - 43204 Reus Spain
10 - Matemàtiques -Universitat Rovira i Virgili Av.Països Catalans 26. 43007-Tarragona Spain","Diabetic retinopathy is one of the most usual morbidities associated to diabetes. Its appropriate control requires the implementation of expensive screening programs. This paper reports the use of Random Forests to build a classifier which may determine, with sensitivity and specificity levels over 80%, whether a diabetic person is likely to develop retinopathy. The use of this model in a decision support tool may help doctors to determine the best screening periodicity for each person, so that an appropriate care is provided and human, material and economic resources are more efficiently employed. * This study was funded by the research projects PI12/01535 and PI15/01150 (Instituto de Salud Carlos III) and the URV grant 2014PFR-URV-B2-60. † http://www.who.int/features/factfiles/diabetes/facts/en/ ‡ For example, the American Diabetes Association [2], the American Academy of Ophthalmology and the Royal College of Ophthalmologists [3].",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-11.pdf,2016,100.0,"Assessment of diabetic retinopathy risk with random forests Diabetic retinopathy is one of the most usual morbidities associated to diabetes. Its appropriate control requires the implementation of expensive screening programs. This paper reports the use of Random Forests to build a classifier which may determine, with sensitivity and specificity levels over 80%, whether a diabetic person is likely to develop retinopathy. The use of this model in a decision support tool may help doctors to determine the best screening periodicity for each person, so that an appropriate care is provided and human, material and economic resources are more efficiently employed. * This study was funded by the research projects PI12/01535 and PI15/01150 (Instituto de Salud Carlos III) and the URV grant 2014PFR-URV-B2-60. † http://www.who.int/features/factfiles/diabetes/facts/en/ ‡ For example, the American Diabetes Association [2], the American Academy of Ophthalmology and the Royal College of Ophthalmologists [3]."
Kernel based collaborative filtering for very large scale top-N item recommendation,"Mirko Polato, Fabio Aiolli",1 - Department of Mathematics Via Trieste University of Padova 63 35121 Padova Italy,"The increasing availability of implicit feedback datasets has raised the interest in developing effective collaborative filtering techniques able to deal asymmetrically with unambiguous positive feedback and ambiguous negative feedback. In this paper, we propose a principled kernelbased collaborative filtering method for top-N item recommendation with implicit feedback. We present an efficient implementation using the linear kernel, and how to generalize it to other kernels preserving efficiency. We compare our method with the state-of-the-art algorithm on the Million Songs Dataset achieving an execution about 5 time faster, while having comparable effectiveness.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-111.pdf,2016,100.0,"Kernel based collaborative filtering for very large scale top-N item recommendation The increasing availability of implicit feedback datasets has raised the interest in developing effective collaborative filtering techniques able to deal asymmetrically with unambiguous positive feedback and ambiguous negative feedback. In this paper, we propose a principled kernelbased collaborative filtering method for top-N item recommendation with implicit feedback. We present an efficient implementation using the linear kernel, and how to generalize it to other kernels preserving efficiency. We compare our method with the state-of-the-art algorithm on the Million Songs Dataset achieving an execution about 5 time faster, while having comparable effectiveness."
Deep Learning Vector Quantization,"Harm De Vries, Roland Memisevic, Aaron Courville",1 - Université de Montréal,"While deep neural nets (DNN's) achieve impressive performance on image recognition tasks, previous studies have reported that DNN's give high confidence predictions for unrecognizable images. Motivated by the observation that such fooling examples might be caused by the extrapolating nature of the log-softmax, we propose to combine neural networks with Learning Vector Quantization (LVQ). Our proposed method, called Deep LVQ (DLVQ), achieves comparable performance on MNIST while being more robust against fooling and adversarial examples.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-112.pdf,2016,100.0,"Deep Learning Vector Quantization While deep neural nets (DNN's) achieve impressive performance on image recognition tasks, previous studies have reported that DNN's give high confidence predictions for unrecognizable images. Motivated by the observation that such fooling examples might be caused by the extrapolating nature of the log-softmax, we propose to combine neural networks with Learning Vector Quantization (LVQ). Our proposed method, called Deep LVQ (DLVQ), achieves comparable performance on MNIST while being more robust against fooling and adversarial examples."
Multicriteria optimized MLP for imbalanced learning,"Paavo Nieminen, Tommi Kärkkäinen",1 - Department of Mathematical Information Technology University of Jyväskylä P.O. Box 35 40014 Finland,"Classifier construction for data with imbalanced class frequencies needs special attention if good classification accuracy for all the classes is sought. When the classes are not separable, i.e., when the distributions of observations in the classes overlap, it is impossible to achieve ideal accuracy for all the classes at once. We suggest a versatile multicriteria optimization formulation for imbalanced classification and demonstrate its applicability using a single hidden layer perceptron as the classifier model.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-113.pdf,2016,100.0,"Multicriteria optimized MLP for imbalanced learning Classifier construction for data with imbalanced class frequencies needs special attention if good classification accuracy for all the classes is sought. When the classes are not separable, i.e., when the distributions of observations in the classes overlap, it is impossible to achieve ideal accuracy for all the classes at once. We suggest a versatile multicriteria optimization formulation for imbalanced classification and demonstrate its applicability using a single hidden layer perceptron as the classifier model."
Simultaneous estimation of rewards and dynamics from noisy expert demonstrations,"Michael Herman, Tobias Gindele, Jörg Wagner, Felix Schmitt, Wolfram Burgard, Robert Bosch, Gmbh -70442 Stuttgart -Germany",1 - Department of Computer Science University of Freiburg 79110 Freiburg Germany,"Inverse Reinforcement Learning (IRL) describes the problem of learning an unknown reward function of a Markov Decision Process (MDP) from demonstrations of an expert. Current approaches typically require the system dynamics to be known or additional demonstrations of state transitions to be available to solve the inverse problem accurately. If these assumptions are not satisfied, heuristics can be used to compensate the lack of a model of the system dynamics. However, heuristics can add bias to the solution. To overcome this, we present a gradient-based approach, which simultaneously estimates rewards, dynamics, and the parameterizable stochastic policy of an expert from demonstrations, while the stochastic policy is a function of optimal Q-values.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-114.pdf,2016,100.0,"Simultaneous estimation of rewards and dynamics from noisy expert demonstrations Inverse Reinforcement Learning (IRL) describes the problem of learning an unknown reward function of a Markov Decision Process (MDP) from demonstrations of an expert. Current approaches typically require the system dynamics to be known or additional demonstrations of state transitions to be available to solve the inverse problem accurately. If these assumptions are not satisfied, heuristics can be used to compensate the lack of a model of the system dynamics. However, heuristics can add bias to the solution. To overcome this, we present a gradient-based approach, which simultaneously estimates rewards, dynamics, and the parameterizable stochastic policy of an expert from demonstrations, while the stochastic policy is a function of optimal Q-values."
ÒØ ÐÓÛ Ö Ò ÔÔÖÓÜ Ñ Ø ÓÒ Ú ÐØ ÖÒ Ø Ò Ð ×Ø ×ÕÙ Ö × ÓÖ × Ð Ð ÖÒ Ð Ð ÖÒ Ò,È Ýù×,Unknown,"Stocks of the German Prime standard have to publish financial reports every three months which were not used fully for fundamental analysis so far. Through web scrapping, an up-to-date high-dimensional dataset of 45 features of 269 companies was extracted, but finding meaningful cluster structures in a high-dimensional dataset with a low number of cases is still a challenge in data science. A hybrid of a swarm with a SOM called Databionic swarm (DBS) found meaningful structures in the financial reports. Using the Chord distance the DBS algorithm results in a topographic map of high-dimensional structures and a clustering. Knowledge from the clustering is acquired using CART. The cluster structures can be explained by simple rules that allow predicting which future stock courses will fall with a 70% probability.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-34.pdf,2016,21.164021164021165,"ÒØ ÐÓÛ Ö Ò ÔÔÖÓÜ Ñ Ø ÓÒ Ú ÐØ ÖÒ Ø Ò Ð ×Ø ×ÕÙ Ö × ÓÖ × Ð Ð ÖÒ Ð Ð ÖÒ Ò Stocks of the German Prime standard have to publish financial reports every three months which were not used fully for fundamental analysis so far. Through web scrapping, an up-to-date high-dimensional dataset of 45 features of 269 companies was extracted, but finding meaningful cluster structures in a high-dimensional dataset with a low number of cases is still a challenge in data science. A hybrid of a swarm with a SOM called Databionic swarm (DBS) found meaningful structures in the financial reports. Using the Chord distance the DBS algorithm results in a topographic map of high-dimensional structures and a clustering. Knowledge from the clustering is acquired using CART. The cluster structures can be explained by simple rules that allow predicting which future stock courses will fall with a 70% probability."
Parallelized rotation and flipping INvariant Kohonen maps (PINK ) on GPUs,Unknown,"1 - -HITS gGmbH (Heidelberg Institute for Theoretical Studies) -Astroinformatics Schloss Wolfsbrunnenweg 35 69118 Heidelberg Germany
2 - Radboud University Nijmegen -Institute for Computing and Information Sciences Toernooiveld 212 6525 AJ Nijmegen The Netherlands
3 - Department of Computer Science University of Copenhagen Sigurdsgade 41 2200 København N -Denmark","Morphological classification is one of the most demanding challenges in astronomy. With the advent of all-sky surveys, an enormous amount of imaging data is publicly available. These data are typically analyzed by experts or encouraged amateur volunteers. For upcoming surveys with billions of objects, however, such an approach is not feasible anymore. In this work, we present a simple yet effective variant of a rotation-invariant self-organizing map that is suitable for many analysis tasks in astronomy. We show how to reduce the computational complexity via modern GPUs and apply the resulting framework to galaxy data for morphological analysis. * KLP,BD,NG gratefully acknowledge the support of the Klaus Tschira Foundation. CI gratefully acknowledges support from The Danish Council for Independent Research through the project ""Surveying the sky using machine learning"". 1 A preliminary version of this work not containing the GPU implementation and restricted to single-channel image data has been presented  [3] .",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-116.pdf,2016,99.3103448275862,"Parallelized rotation and flipping INvariant Kohonen maps (PINK ) on GPUs Morphological classification is one of the most demanding challenges in astronomy. With the advent of all-sky surveys, an enormous amount of imaging data is publicly available. These data are typically analyzed by experts or encouraged amateur volunteers. For upcoming surveys with billions of objects, however, such an approach is not feasible anymore. In this work, we present a simple yet effective variant of a rotation-invariant self-organizing map that is suitable for many analysis tasks in astronomy. We show how to reduce the computational complexity via modern GPUs and apply the resulting framework to galaxy data for morphological analysis. * KLP,BD,NG gratefully acknowledge the support of the Klaus Tschira Foundation. CI gratefully acknowledges support from The Danish Council for Independent Research through the project ""Surveying the sky using machine learning"". 1 A preliminary version of this work not containing the GPU implementation and restricted to single-channel image data has been presented  [3] ."
Multispectral Pedestrian Detection using Deep Fusion Convolutional Neural Networks,"Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke, Robert Bosch, Gmbh -70442 Stuttgart -Germany",1 - -University Bonn -Computer Science VI Autonomous Intelligent Systems Friedrich-Ebert-Allee 144 53113 Bonn Germany,"Robust vision-based pedestrian detection is a crucial feature of future autonomous systems. Thermal cameras provide an additional input channel that helps solving this task and deep convolutional networks are the currently leading approach for many pattern recognition problems, including object detection. In this paper, we explore the potential of deep models for multispectral pedestrian detection. We investigate two deep fusion architectures and analyze their performance on multispectral data. Our results show that a pre-trained late-fusion architecture significantly outperforms the current state-of-the-art ACF+T+THOG solution.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-118.pdf,2016,100.0,"Multispectral Pedestrian Detection using Deep Fusion Convolutional Neural Networks Robust vision-based pedestrian detection is a crucial feature of future autonomous systems. Thermal cameras provide an additional input channel that helps solving this task and deep convolutional networks are the currently leading approach for many pattern recognition problems, including object detection. In this paper, we explore the potential of deep models for multispectral pedestrian detection. We investigate two deep fusion architectures and analyze their performance on multispectral data. Our results show that a pre-trained late-fusion architecture significantly outperforms the current state-of-the-art ACF+T+THOG solution."
Controlling Adaptive Quantum-Phase Estimation with Scalable Reinforcement Learning,"Pantita Palittapongarnpim, Peter Wittek, Barry Sanders","1 - Institute for Quantum Science and Technology University of Calgary Calgary T2N 1N4 Alberta Canada
2 - ICFO The Institute of Photonic Sciences Castelldefels (Barcelona) 08860 Spain
3 - University of Borås Borås 501 90 Sweden
5 - -Program in Quantum Information Science Canadian Institute for Advanced Research Toronto M5G 1Z8 Ontario Canada","We develop a reinforcement-learning algorithm to construct a feedback policy that delivers quantum-enhanced interferometric-phase estimation up to 100 photons in a noisy environment. We ensure scalability of the calculations by distributing the workload in a cluster and by vectorizing time-critical operations. We also improve running time by introducing accept-reject criteria to terminate calculation when a successful result is reached. Furthermore, we make the learning algorithm robust to noise by fine-tuning how the objective function is evaluated. The results show the importance and relevance of well-designed classical machine learning algorithms in quantum physics problems.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-12.pdf,2016,81.70731707317074,"Controlling Adaptive Quantum-Phase Estimation with Scalable Reinforcement Learning We develop a reinforcement-learning algorithm to construct a feedback policy that delivers quantum-enhanced interferometric-phase estimation up to 100 photons in a noisy environment. We ensure scalability of the calculations by distributing the workload in a cluster and by vectorizing time-critical operations. We also improve running time by introducing accept-reject criteria to terminate calculation when a successful result is reached. Furthermore, we make the learning algorithm robust to noise by fine-tuning how the objective function is evaluated. The results show the importance and relevance of well-designed classical machine learning algorithms in quantum physics problems."
Activity recognition with echo state networks using 3D body joints and objects category,"Luiza Mici, Xavier Hinaut, Stefan Wermter",1 - Department of Informatics University of Hamburg Vogt-Koelln-Strasse 30 22527 Hamburg Germany,"In this paper we present our experiments with an echo state network (ESN) for the task of classifying high-level human activities from video data. ESNs are recurrent neural networks which are biologically plausible, fast to train and they perform well in processing arbitrary sequential data. We focus on the integration of body motion with the information on objects manipulated during the activity, in order to overcome the visual ambiguities introduced by the processing of articulated body motion. We investigate the outputs learned and the accuracy of classification obtained with ESNs by using a challenging dataset of long high-level activities. We finally report the results achieved on this dataset.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-120.pdf,2016,100.0,"Activity recognition with echo state networks using 3D body joints and objects category In this paper we present our experiments with an echo state network (ESN) for the task of classifying high-level human activities from video data. ESNs are recurrent neural networks which are biologically plausible, fast to train and they perform well in processing arbitrary sequential data. We focus on the integration of body motion with the information on objects manipulated during the activity, in order to overcome the visual ambiguities introduced by the processing of articulated body motion. We investigate the outputs learned and the accuracy of classification obtained with ESNs by using a challenging dataset of long high-level activities. We finally report the results achieved on this dataset."
Word Embeddings for Morphologically Rich Languages,Pyry Takala,1 - Department of Computer Science PL11000 Aalto University 00076 Aalto Finland,"Word-embedding models commonly treat words as unique symbols, for which a lower-dimensional embedding can be looked up. These representations generalize poorly with morphologically rich languages, as vectors for all possible inflections cannot be stored, and words with the same stem do not share a similar representation. We study alternative representations for words, including one subword-model and two character-based models. Our methods outperform classical word embeddings for a morphologically rich language, Finnish, on tasks requiring sophisticated understanding of grammar and context. Our embeddings are easier to implement than previously proposed methods, and can be used to form word-representations for any common language processing tasks.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-121.pdf,2016,100.0,"Word Embeddings for Morphologically Rich Languages Word-embedding models commonly treat words as unique symbols, for which a lower-dimensional embedding can be looked up. These representations generalize poorly with morphologically rich languages, as vectors for all possible inflections cannot be stored, and words with the same stem do not share a similar representation. We study alternative representations for words, including one subword-model and two character-based models. Our methods outperform classical word embeddings for a morphologically rich language, Finnish, on tasks requiring sophisticated understanding of grammar and context. Our embeddings are easier to implement than previously proposed methods, and can be used to form word-representations for any common language processing tasks."
A new penalisation term for image retrieval in clique neural networks,"Romain Huet, Nicolas Courty, Sébastien Lefèvre",1 - UMR 6074 Univ. Bretagne-Sud IRISA F-56000 Vannes France,"Neural networks that are able to retrieve store and retrieve information constitue an old but still active area of research. Among the different existing architectures, recurrent networks that combine associative memory with error correcting properties based on cliques have recently shown good performances on storing arbitrary random messages. However, they fail in scaling up to large dimensions data such as images, mostly because the distribution of activated neurons is not uniform in the network. We propose in this paper a new penalization term that alleviates this problem, and shows its efficiency on partially erased images reconstruction problem. * The authors acknowledge the support of the CominLabs excellence cluster (SENSE project) and the Région Bretagne (SPANNVIS doctoral grant).","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-122.pdf,2016,100.0,"A new penalisation term for image retrieval in clique neural networks Neural networks that are able to retrieve store and retrieve information constitue an old but still active area of research. Among the different existing architectures, recurrent networks that combine associative memory with error correcting properties based on cliques have recently shown good performances on storing arbitrary random messages. However, they fail in scaling up to large dimensions data such as images, mostly because the distribution of activated neurons is not uniform in the network. We propose in this paper a new penalization term that alleviates this problem, and shows its efficiency on partially erased images reconstruction problem. * The authors acknowledge the support of the CominLabs excellence cluster (SENSE project) and the Région Bretagne (SPANNVIS doctoral grant)."
Informative Data Projections: A Framework and Two Examples,"Tijl De Bie, Jefrey Lijffijt, Raúl Santos-Rodríguez, Bo Kang","1 - Data Science Lab -Ghent University
2 - Dept. of Engineering Mathematics University of Bristol","Projection Pursuit aims to facilitate visual exploration of high-dimensional data by identifying interesting low-dimensional projections. A major challenge in Projection Pursuit is the design of a projection index -a suitable quality measure to maximise. We introduce a strategy for tackling this problem based on quantifying the amount of information a projection conveys, given a user's prior beliefs about the data. The resulting projection index is a subjective quantity, explicitly dependent on the intended user. As an illustration, we developed this principle for two kinds of prior beliefs; the first leads to PCA, the second leads to a novel projection index, which we call t-PCA, that can be regarded as a robust PCA-variant. We demonstrate t-PCA's usefulness in comparative experiments against PCA and FastICA, a popular PP method.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-123.pdf,2016,62.06896551724138,"Informative Data Projections: A Framework and Two Examples Projection Pursuit aims to facilitate visual exploration of high-dimensional data by identifying interesting low-dimensional projections. A major challenge in Projection Pursuit is the design of a projection index -a suitable quality measure to maximise. We introduce a strategy for tackling this problem based on quantifying the amount of information a projection conveys, given a user's prior beliefs about the data. The resulting projection index is a subjective quantity, explicitly dependent on the intended user. As an illustration, we developed this principle for two kinds of prior beliefs; the first leads to PCA, the second leads to a novel projection index, which we call t-PCA, that can be regarded as a robust PCA-variant. We demonstrate t-PCA's usefulness in comparative experiments against PCA and FastICA, a popular PP method."
RBClust: High quality class-specific clustering using rule-based classification,"Michael Siers, Zahidul Islam",1 - School of Computing and Mathematics Charles Sturt University Panorama Avenue 2795 NSW Australia,"Within a class-labeled dataset, there are typically two or more possible class labels. Class-specific subsets of the dataset have the same class label for each record. Class-specific clusters are the groups of similar records within these subsets. There exists many machine learning techniques which require class-specific clusters. We propose RBClust, a rule based method for finding class-specific clusters. We demonstrate that when compared to traditional clustering methods, the proposed method achieves better cluster quality, and computation time is significantly lower.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-124.pdf,2016,100.0,"RBClust: High quality class-specific clustering using rule-based classification Within a class-labeled dataset, there are typically two or more possible class labels. Class-specific subsets of the dataset have the same class label for each record. Class-specific clusters are the groups of similar records within these subsets. There exists many machine learning techniques which require class-specific clusters. We propose RBClust, a rule based method for finding class-specific clusters. We demonstrate that when compared to traditional clustering methods, the proposed method achieves better cluster quality, and computation time is significantly lower."
On the Improvement of Static Force Capacity of Humanoid Robots based on Plants Behavior,"Juliano Pierezan, Roberto Freire, Lucas Weihmann, Gilberto Reynoso-Meza, Leandro Dos, S Coelho","1 - Federal University of Parana (UFPR) -Dept. of Electrical Engineering Rua Carlos Pradi Jardim das Américas. Postal Code 82590-300 Curitiba PR Brazil
2 - Pontifical Catholic University of Parana (PUCPR) -Polytechnic School Rua Imaculada Conceição 1555. Postal Code 80215-901 Curitiba PR Brazil
3 - Federal University of Santa Catarina (UFSC) -Dept. of Naval Engineering Rua Dr João Colin Santo Antônio. Postal Code: 89.218-035 2700 Joinville SC Brazil","Humanoid robots need to interact with the environment and are constantly in rigid contact with objects. When a task must be performed, multiple contact points are responsible to add a degree of complexity to their control and, due to excessive efforts in joints, the durability of the components may be affected. This work presents the use of a recent proposed metaheuristic called Runner-Root Algorithm (RRA) applied on the static force capacity optimization of a humanoid robot. The performance of this algorithm was evaluated and compared to four well stablished methods showing promising results for RRA in this type of application.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-125.pdf,2016,72.41379310344827,"On the Improvement of Static Force Capacity of Humanoid Robots based on Plants Behavior Humanoid robots need to interact with the environment and are constantly in rigid contact with objects. When a task must be performed, multiple contact points are responsible to add a degree of complexity to their control and, due to excessive efforts in joints, the durability of the components may be affected. This work presents the use of a recent proposed metaheuristic called Runner-Root Algorithm (RRA) applied on the static force capacity optimization of a humanoid robot. The performance of this algorithm was evaluated and compared to four well stablished methods showing promising results for RRA in this type of application."
From User-independent to Personal Human Activity Recognition Models Using Smartphone Sensors,"Pekka Siirtola, Heli Koskimäki, Juha Röning",1 - Biomimetics and Intelligent Systems Group University of Oulu P.O. BOX 4500 FI-90014 Oulu Finland,"In this study, a novel method to obtain user-dependent human activity recognition models unobtrusively by using the sensors of a smartphone is presented. The recognition consists of two models: sensor fusion-based user-independent model for data labeling and single sensor-based userdependent model for final recognition. The functioning of the presented method is tested with human activity data set, including data from accelerometer and magnetometer, and with two classifiers. Comparison of the detection accuracies of the proposed method to traditional userindependent model shows that the presented method has potential, when the method is tested with two classifiers and five persons, in nine cases out of ten it is better than the traditional method, but more experiments using different sensor combinations should be made to show the full potential of the method.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-126.pdf,2016,100.0,"From User-independent to Personal Human Activity Recognition Models Using Smartphone Sensors In this study, a novel method to obtain user-dependent human activity recognition models unobtrusively by using the sensors of a smartphone is presented. The recognition consists of two models: sensor fusion-based user-independent model for data labeling and single sensor-based userdependent model for final recognition. The functioning of the presented method is tested with human activity data set, including data from accelerometer and magnetometer, and with two classifiers. Comparison of the detection accuracies of the proposed method to traditional userindependent model shows that the presented method has potential, when the method is tested with two classifiers and five persons, in nine cases out of ten it is better than the traditional method, but more experiments using different sensor combinations should be made to show the full potential of the method."
Auto-adaptive Laplacian Pyramids,"Ángela Fernández, Neta Rabin, Dalia Fishelov, José Dorronsoro","1 - Instituto de Ingeniería del Conocimiento
2 - Department Exact Sciences Afeka
5 - Universidad Autónoma de Madrid","An important challenge in Data Mining and Machine Learning is the proper analysis of a given dataset, especially for understanding and working with functions defined over it. In this paper we propose Auto-adaptive Laplacian Pyramids (ALP) for target function smoothing when the target function is defined on a high-dimensional dataset. The proposed algorithm automatically selects the optimal function resolution (stopping time) adapted to the data defined and its noise. We illustrate its application on a radiation forecasting example. * With partial support from Spain's grants TIN2013-42351-P (MINECO) and S2013/ICE-2845 CASI-CAM-CM (Comunidad de Madrid), and the UAM-ADIC Chair for Data Science and Machine Learning. The authors gratefully acknowledge the use of the facilities of Centro de Computación Científica (CCC) at UAM. They wish to thank Prof. Ronald R. Coifman for helpful remarks.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-131.pdf,2016,100.0,"Auto-adaptive Laplacian Pyramids An important challenge in Data Mining and Machine Learning is the proper analysis of a given dataset, especially for understanding and working with functions defined over it. In this paper we propose Auto-adaptive Laplacian Pyramids (ALP) for target function smoothing when the target function is defined on a high-dimensional dataset. The proposed algorithm automatically selects the optimal function resolution (stopping time) adapted to the data defined and its noise. We illustrate its application on a radiation forecasting example. * With partial support from Spain's grants TIN2013-42351-P (MINECO) and S2013/ICE-2845 CASI-CAM-CM (Comunidad de Madrid), and the UAM-ADIC Chair for Data Science and Machine Learning. The authors gratefully acknowledge the use of the facilities of Centro de Computación Científica (CCC) at UAM. They wish to thank Prof. Ronald R. Coifman for helpful remarks."
Using a Feature Selection Ensemble on DNA Microarray Datasets,"Borja Seijo-Pardo, Verónica Bolón-Canedo, Amparo Alonso-Betanzos",1 - Department of Computer Science University of A Coruña Campus de Elviña s/n 15071 -A Coruña Spain,"DNA microarray has brought a difficult challenge for researchers due to the high number of gene expression contained and the small samples size. Therefore, feature selection has become an indispensable preprocessing step. In this paper we propose an ensemble for feature selection based on combining rankings of features. The individual rankings are combined with different aggregation methods, and a practical subset of features is selected according to a data complexity measure -the inverse of Fisher discriminant ratio-. The proposed ensemble, tested on seven different DNA microarray datasets using a Support Vector Machine as classifier, was able to obtain the best results in different scenarios.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-133.pdf,2016,73.77049180327869,"Using a Feature Selection Ensemble on DNA Microarray Datasets DNA microarray has brought a difficult challenge for researchers due to the high number of gene expression contained and the small samples size. Therefore, feature selection has become an indispensable preprocessing step. In this paper we propose an ensemble for feature selection based on combining rankings of features. The individual rankings are combined with different aggregation methods, and a practical subset of features is selected according to a data complexity measure -the inverse of Fisher discriminant ratio-. The proposed ensemble, tested on seven different DNA microarray datasets using a Support Vector Machine as classifier, was able to obtain the best results in different scenarios."
Data complexity measures for analyzing the effect of SMOTE over microarrays,"L Morán-Fernández, V Bolón-Canedo, A Alonso-Betanzos",1 - Computer Science Dept Laboratory for Research and Development in Artificial Intelligence (LIDIA) University of A Coruña 15071 A Coruña Spain,"Microarray classification is a challenging issue for machine learning researchers mainly due to the fact that there is a mismatch between gene dimension and sample size. Besides, this type of data have other properties that can complicate the classification task, such as class imbalance. A common approach to deal with the problem of imbalanced datasets is the use of a preprocessing step trying to cope with this imbalance. In this work we analyze the usefulness of the data complexity measures in order to evaluate the behavior of the SMOTE algorithm before and after applying feature gene selection.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-134.pdf,2016,100.0,"Data complexity measures for analyzing the effect of SMOTE over microarrays Microarray classification is a challenging issue for machine learning researchers mainly due to the fact that there is a mismatch between gene dimension and sample size. Besides, this type of data have other properties that can complicate the classification task, such as class imbalance. A common approach to deal with the problem of imbalanced datasets is the use of a preprocessing step trying to cope with this imbalance. In this work we analyze the usefulness of the data complexity measures in order to evaluate the behavior of the SMOTE algorithm before and after applying feature gene selection."
One-class classification algorithm based on convex hull,"Diego Fernandez-Francos, Oscar Fontenla-Romero, Amparo Alonso-Betanzos",1 - Department of Computer Science University of A Coruña Spain,"A new version of a one-class classification algorithm is presented in this paper. In it, convex hull (CH) is used to define the boundary of the target class defining the one-class problem. An approximation of the D-dimensional CH decision is made by using random projections and an ensemble of models in very low-dimensional spaces. Expansion and reduction of the CH model prevents over-fitting. So a different method to obtain the expanded polytope is proposed in order to avoid some undesirable behavior detected in the original algorithm in certain situations. Besides, this modification allows the use of a new parameter, the CH center, that provides even more flexibility to our proposal. Experimental results showed that the new algorithm is significantly better, regarding accuracy, than the previous work on a large number of datasets. * This work has been supported by the Secretaría de Estado de Investigación of the Spanish Government (Grants TIN2012-37954 and TIN2015-65069-C2-1-R). Diego Fernandez Francos would like to thank the Ministerio de Ciencia e Innovación for FPI supporting grant.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-136.pdf,2016,100.0,"One-class classification algorithm based on convex hull A new version of a one-class classification algorithm is presented in this paper. In it, convex hull (CH) is used to define the boundary of the target class defining the one-class problem. An approximation of the D-dimensional CH decision is made by using random projections and an ensemble of models in very low-dimensional spaces. Expansion and reduction of the CH model prevents over-fitting. So a different method to obtain the expanded polytope is proposed in order to avoid some undesirable behavior detected in the original algorithm in certain situations. Besides, this modification allows the use of a new parameter, the CH center, that provides even more flexibility to our proposal. Experimental results showed that the new algorithm is significantly better, regarding accuracy, than the previous work on a large number of datasets. * This work has been supported by the Secretaría de Estado de Investigación of the Spanish Government (Grants TIN2012-37954 and TIN2015-65069-C2-1-R). Diego Fernandez Francos would like to thank the Ministerio de Ciencia e Innovación for FPI supporting grant."
RNAsynth: constraints learning for RNA inverse folding,"Parastou Fabrizio Costa, Robert Kohvaei, Kleinkauf",1 - Institut für Informatik Albert-Ludwigs-Universität Freiburg Georges-Köhler-Allee 106 D-79110 Freiburg Germany,"RNA polymers are an important class of molecules: not only they are involved in a variety of biological functions, from coding to decoding, from regulation to expression of genes, but crucially, they are nowadays easily synthesizable, opening interesting application scenarios in biotechnological and biomedical domains. Here we propose a constructive machine learning framework to aid in the rational design of such polymers. Using a graph kernel approach in a supervised setting we define an importance notion over molecular parts. We then convert the set of most important parts into specific sequence and structure constraints. Finally an inverse folding algorithm uses these constraints to compute the desired RNA sequence.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-137.pdf,2016,99.08256880733946,"RNAsynth: constraints learning for RNA inverse folding RNA polymers are an important class of molecules: not only they are involved in a variety of biological functions, from coding to decoding, from regulation to expression of genes, but crucially, they are nowadays easily synthesizable, opening interesting application scenarios in biotechnological and biomedical domains. Here we propose a constructive machine learning framework to aid in the rational design of such polymers. Using a graph kernel approach in a supervised setting we define an importance notion over molecular parts. We then convert the set of most important parts into specific sequence and structure constraints. Finally an inverse folding algorithm uses these constraints to compute the desired RNA sequence."
Automatic detection of EEG Arousals,"Isaac Fernández-Varela, Elena Hernández-Pereira, Diego Álvarez-Estévez, Vicente Moret-Bonillo","1 - Departamento de Computación Facultade de Informática Universidade da Coruña Campus de Elviña A Coruña -Spain
3 - Sleep Center & Clinical Neurophysiology -MCH en Bronovo-Nebo Lijnbaan 32 2512 VA The Hague -Netherlands","Fragmented sleep is commonly caused by arousals that can be detected with the observation of electroencephalographic (EEG) signals. As this is a time consuming task, automatization processes are required. A method using signal processing and machine learning models, for arousal detection, is presented. Relevant events are identified in the EEG signals and in the electromyography, during the signal processing phase. After discarding those events that do not meet the required characteristics, the resulting set is used to extract multiple parameters. Several machine learning models -Fisher's Linear Discriminant, Artificial Neural Networks and Support Vector Machines -are fed with these parameters. The final proposed model, a combination of the different individual models, was used to conduct experiments on 26 patients, reporting a sensitivity of 0.72 and a specificity of 0.89, while achieving an error of 0.13, in the arousal events detection.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-138.pdf,2016,74.28571428571429,"Automatic detection of EEG Arousals Fragmented sleep is commonly caused by arousals that can be detected with the observation of electroencephalographic (EEG) signals. As this is a time consuming task, automatization processes are required. A method using signal processing and machine learning models, for arousal detection, is presented. Relevant events are identified in the EEG signals and in the electromyography, during the signal processing phase. After discarding those events that do not meet the required characteristics, the resulting set is used to extract multiple parameters. Several machine learning models -Fisher's Linear Discriminant, Artificial Neural Networks and Support Vector Machines -are fed with these parameters. The final proposed model, a combination of the different individual models, was used to conduct experiments on 26 patients, reporting a sensitivity of 0.72 and a specificity of 0.89, while achieving an error of 0.13, in the arousal events detection."
Gesture Recognition with a Convolutional Long Short-Term Memory Recurrent Neural Network,"Eleni Tsironi, Pablo Barros, Stefan Wermter",1 - Department of Computer Science University of Hamburg Vogt-Koelln-Strasse 30 D-22527 Hamburg Germany,"Inspired by the adequacy of convolutional neural networks in implicit extraction of visual features and the efficiency of Long Short-Term Memory Recurrent Neural Networks in dealing with long-range temporal dependencies, we propose a Convolutional Long Short-Term Memory Recurrent Neural Network (CNNLSTM) for the problem of dynamic gesture recognition. The model is able to successfully learn gestures varying in duration and complexity and proves to be a significant base for further development. Finally, the new gesture command TsironiGR-dataset for human-robot interaction is presented for the evaluation of CNNLSTM.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-139.pdf,2016,100.0,"Gesture Recognition with a Convolutional Long Short-Term Memory Recurrent Neural Network Inspired by the adequacy of convolutional neural networks in implicit extraction of visual features and the efficiency of Long Short-Term Memory Recurrent Neural Networks in dealing with long-range temporal dependencies, we propose a Convolutional Long Short-Term Memory Recurrent Neural Network (CNNLSTM) for the problem of dynamic gesture recognition. The model is able to successfully learn gestures varying in duration and complexity and proves to be a significant base for further development. Finally, the new gesture command TsironiGR-dataset for human-robot interaction is presented for the evaluation of CNNLSTM."
"Study on the loss of information caused by the ""positivation"" of graph kernels for 3D shapes",Gaëlle Loosli,1 - UMR 6158 Clermont Université -Université Blaise Pascal CNRS LIMOS Aubière France,"In the presented experimental study, we compare the classification power of two variations of the same graph kernel. One variation is designed to produce semi-definite positive kernel matrices (K matching ) and is an approximation of the other one, which is indefinite (Kmax). We show that using adaptated tools to deal with indefiniteness (KSVM), the original indefinite kernel outperforms its positive definite approximate version. We also propose a slight improvement of the KSVM method, which produces non sparse solutions, by adding a fast post-processing step that gives a sparser solution.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-14.pdf,2016,100.0,"Study on the loss of information caused by the ""positivation"" of graph kernels for 3D shapes In the presented experimental study, we compare the classification power of two variations of the same graph kernel. One variation is designed to produce semi-definite positive kernel matrices (K matching ) and is an approximation of the other one, which is indefinite (Kmax). We show that using adaptated tools to deal with indefiniteness (KSVM), the original indefinite kernel outperforms its positive definite approximate version. We also propose a slight improvement of the KSVM method, which produces non sparse solutions, by adding a fast post-processing step that gives a sparser solution."
Interpretability of Machine Learning Models and Representations: an Introduction,"Adrien Bibal, Benoît Frénay",1 - Université de Namur -Faculté d'informatique Rue Grandgagnage 21 5000 Namur Belgium,"Interpretability is often a major concern in machine learning. Although many authors agree with this statement, interpretability is often tackled with intuitive arguments, distinct (yet related) terms and heuristic quantifications. This short survey aims to clarify the concepts related to interpretability and emphasises the distinction between interpreting models and representations, as well as heuristic-based and user-based approaches.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-141.pdf,2016,81.25,"Interpretability of Machine Learning Models and Representations: an Introduction Interpretability is often a major concern in machine learning. Although many authors agree with this statement, interpretability is often tackled with intuitive arguments, distinct (yet related) terms and heuristic quantifications. This short survey aims to clarify the concepts related to interpretability and emphasises the distinction between interpreting models and representations, as well as heuristic-based and user-based approaches."
"Feature definition, analysis and selection for lung nodule classification in chest computerized tomography images","Luis Gonçalves, Jorge Novo, Aurélio Campilho","1 - INESC TEC -INESC Technology and Science 2-Faculdade de Engenharia
2 - Universidade do Porto FEUP Campus Dr. Roberto Frias 4200 -465 Porto Portugal
3 - Department of Computer Science University of A Coruña Campus de Elviña 15071 A Coruña Spain","This work presents the results of the characterization of lung nodules in chest Computerized Tomography for benign/malignant classification. A set of image features was used in the Computer-aided Diagnosis system to distinguish benign from malignant nodules and, therefore, diagnose lung cancer. A filter-based feature selection approach was used in order to define an optimal subset with higher accuracy. A large and heterogeneous set of 293 features was defined, including shape, intensity and texture features. We used different KNN and SVM classifiers to evaluate the features subsets. The estimated results were tested in a dataset annotated by radiologists. Promising results were obtained with an area under the Receiver Operating Characteristic curve (AUC value) of 96.2 ± 0.5% using SVM.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-142.pdf,2016,100.0,"Feature definition, analysis and selection for lung nodule classification in chest computerized tomography images This work presents the results of the characterization of lung nodules in chest Computerized Tomography for benign/malignant classification. A set of image features was used in the Computer-aided Diagnosis system to distinguish benign from malignant nodules and, therefore, diagnose lung cancer. A filter-based feature selection approach was used in order to define an optimal subset with higher accuracy. A large and heterogeneous set of 293 features was defined, including shape, intensity and texture features. We used different KNN and SVM classifiers to evaluate the features subsets. The estimated results were tested in a dataset annotated by radiologists. Promising results were obtained with an area under the Receiver Operating Characteristic curve (AUC value) of 96.2 ± 0.5% using SVM."
Spatio-temporal feature selection for black-box weather forecasting,"Zahra Karevan, Johan Suykens",1 - KU Leuven ESAT-STADIUS Kasteelpark Arenberg 10 B-3001 Leuven Belgium,"In this paper, a data-driven modeling technique is proposed for temperature forecasting. Due to the high dimensionality, LASSO is used as feature selection approach. Considering spatio-temporal structure of the weather dataset, first LASSO is applied in a spatial and temporal scenario, independently. Next, a feature is included in the model if it is selected by both. Finally, Least Squares Support Vector Machines (LS-SVM) regression is used to learn the model. The experimental results show that spatio-temporal LASSO improves the performance and is competitive with the state-of-the-art methods. As a case study, the prediction of the temperature in Brussels is considered.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-143.pdf,2016,100.0,"Spatio-temporal feature selection for black-box weather forecasting In this paper, a data-driven modeling technique is proposed for temperature forecasting. Due to the high dimensionality, LASSO is used as feature selection approach. Considering spatio-temporal structure of the weather dataset, first LASSO is applied in a spatial and temporal scenario, independently. Next, a feature is included in the model if it is selected by both. Finally, Least Squares Support Vector Machines (LS-SVM) regression is used to learn the model. The experimental results show that spatio-temporal LASSO improves the performance and is competitive with the state-of-the-art methods. As a case study, the prediction of the temperature in Brussels is considered."
Boosting face recognition via neural Super-Resolution,Guillaume Berger,1 - Clément Peyrard and Moez Baccouche Orange Labs -4 rue du Clos Courtel 35510 Cesson-Sévigné France,"We propose a two-step neural approach for face Super-Resolution (SR) to improve face recognition performance. It consists in first performing generic SR on the entire image, based on Convolutional Neural Networks, followed by a specific local SR step for each facial component, using neural autoencoders. Obtained results on the LFW dataset for a ×4 upscaling factor demonstrate that the method improves both image reconstruction (+2.80 dB in PSNR) and recognition performance (+3.94 points in mean accuracy), compared with ×4 bicubic interpolation. 
 A two-step neural approach for face Super-Resolution This section describes the proposed approach (see Fig.  1 ). In the first step, a highresolution image is generated using a generic SR approach. During the second step, localized SR is performed on facial components.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-144.pdf,2016,100.0,"Boosting face recognition via neural Super-Resolution We propose a two-step neural approach for face Super-Resolution (SR) to improve face recognition performance. It consists in first performing generic SR on the entire image, based on Convolutional Neural Networks, followed by a specific local SR step for each facial component, using neural autoencoders. Obtained results on the LFW dataset for a ×4 upscaling factor demonstrate that the method improves both image reconstruction (+2.80 dB in PSNR) and recognition performance (+3.94 points in mean accuracy), compared with ×4 bicubic interpolation. 
 A two-step neural approach for face Super-Resolution This section describes the proposed approach (see Fig.  1 ). In the first step, a highresolution image is generated using a generic SR approach. During the second step, localized SR is performed on facial components."
Spatiotemporal ICA improves the selection of differentially expressed genes,"Emilie Renard, Andrew Teschendorff, P.-A Absil","1 - Université catholique de Louvain -ICTEAM Institute Avenue Georges Lemaître 4 B-1348 Louvain-la-Neuve Belgium
2 - University College London -Cancer Institute 72 Huntley Street WC1E 6BT London United Kingdom
3 - PI Computational Systems Genomics -CAS-MPG Partner Institute for Computational Biology 320 Yue Yang Road -Shanghai 200031 China","Selecting differentially expressed genes with respect to some phenotype of interest is a difficult task, especially in the presence of confounding factors. We propose to use a spatiotemporal independent component analysis to model those factors, and to combine information from different spatiotemporal parameter values to improve the set of selected genes. We show on real datasets that the proposed method allows to significantly increase the proportion of genes related to the phenotype of interest in the final selection. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-145.pdf,2016,100.0,"Spatiotemporal ICA improves the selection of differentially expressed genes Selecting differentially expressed genes with respect to some phenotype of interest is a difficult task, especially in the presence of confounding factors. We propose to use a spatiotemporal independent component analysis to model those factors, and to combine information from different spatiotemporal parameter values to improve the set of selected genes. We show on real datasets that the proposed method allows to significantly increase the proportion of genes related to the phenotype of interest in the final selection. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office."
Enhancing a Social Science Model-building Workflow with Interactive Visualisation,"Cagatay Turkay, Aidan Slingsby, Kaisa Lahtinen, Sarah Butt, Jason Dykes","1 - Centre for Comparative Social Surveys City University London UK
3 - Department of Computer Science City University London 1-giCentre UK","Models can help scientists study and understand phenomena. Such models need to be informed by theory. We report on the early stages of our ongoing study in which we use interactive visualisation to help improve the construction of theory-driven models, by facilitating the exploration of statistical summaries of input variables, compare the quality of alternative models and keep track of the model-building process. Later work will investigate whether machine-learning techniques can be incorporated without compromising the models' theoretical bases.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-147.pdf,2016,83.9506172839506,"Enhancing a Social Science Model-building Workflow with Interactive Visualisation Models can help scientists study and understand phenomena. Such models need to be informed by theory. We report on the early stages of our ongoing study in which we use interactive visualisation to help improve the construction of theory-driven models, by facilitating the exploration of statistical summaries of input variables, compare the quality of alternative models and keep track of the model-building process. Later work will investigate whether machine-learning techniques can be incorporated without compromising the models' theoretical bases."
Grounding the Experience of a Visual Field through Sensorimotor Contingencies,"Alban Laflaquière, Garcia Ortiz, Ahmed Faraz Khan",1 - AI Lab Aldebaran Robotics 43 rue du Colonel Pierre Avia 75015 Paris France,"Artificial perception is traditionally handled by hand-designing specific algorithms. However, a truly autonomous robot should develop perceptive abilities on its own by interacting with its environment. The sensorimotor contingencies theory proposes to ground those abilities in the way the agent can actively transform its sensory inputs. This work presents an application of this approach to the discovery of a visual field. It shows how an agent can capture regularities induced by its visual sensor in a sensorimotor predictive model. A formalism is proposed to address this problem and tested on a simulated system.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-148.pdf,2016,68.83116883116884,"Grounding the Experience of a Visual Field through Sensorimotor Contingencies Artificial perception is traditionally handled by hand-designing specific algorithms. However, a truly autonomous robot should develop perceptive abilities on its own by interacting with its environment. The sensorimotor contingencies theory proposes to ground those abilities in the way the agent can actively transform its sensory inputs. This work presents an application of this approach to the discovery of a visual field. It shows how an agent can capture regularities induced by its visual sensor in a sensorimotor predictive model. A formalism is proposed to address this problem and tested on a simulated system."
Measuring the Expressivity of Graph Kernels through the Rademacher Complexity,"Luca Oneto, Nicolò Navarin, Michele Donini, Alessandro Sperduti, Fabio Aiolli, Davide Anguita","1 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy
2 - Department of Mathematics University of Padua Via Trieste 63 I-35121 Padova Italy","Graph kernels are widely adopted in real-world applications that involve learning on graph data. Different graph kernels have been proposed in literature, but no theoretical comparison among them is present. In this paper we provide a formal definition for the expressiveness of a graph kernel by means of the Rademacher Complexity, and analyze the differences among some state-of-the-art graph kernels. Results on real world datasets confirm some known properties of graph kernels, showing that the Rademacher Complexity is indeed a suitable measure for this analysis.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-150.pdf,2016,100.0,"Measuring the Expressivity of Graph Kernels through the Rademacher Complexity Graph kernels are widely adopted in real-world applications that involve learning on graph data. Different graph kernels have been proposed in literature, but no theoretical comparison among them is present. In this paper we provide a formal definition for the expressiveness of a graph kernel by means of the Rademacher Complexity, and analyze the differences among some state-of-the-art graph kernels. Results on real world datasets confirm some known properties of graph kernels, showing that the Rademacher Complexity is indeed a suitable measure for this analysis."
Initializing Nonnegative Matrix Factorization using the Successive Projection Algorithm for multi-parametric medical image segmentation,"N Sauwen, M Acou, H Bharath, D Sima, J Veraart, F Maes, U Himmelreich, E Achten, S Van Huffel","1 - Department of Electrical Engineering (ESAT) -KU Leuven STADIUS Centre for Dynamical Systems Signal Processing and Data Analytics -Leuven Belgium
2 - iMinds -Department Medical Information Technologies Belgium
3 - Department of Radiology -Ghent Ghent University Hospital Belgium
8 - Department of Physics -Antwerp Department of Electrical Engineering (ESAT) University of Antwerp -iMinds Vision Lab 5-KU Leuven Belgium
9 - Department of Imaging and Pathology PSI Centre for Processing Speech and Images -Leuven 6-KU Leuven Belgium
10 - Biomedical MRI/MoSAIC -Leuven Belgium","As nonnegative matrix factorization (NMF) represents a nonconvex problem, the quality of its solution will depend on the initialization of the factor matrices. This study proposes the Successive Projection Algorithm (SPA) as a feasible NMF initialization method. SPA is applied to a multi-parametric MRI dataset for automated NMF brain tumor segmentation. SPA provides fast and reproducible estimates of the tissue sources, and segmentation quality is found to be similar compared to repetitive random initialization.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-152.pdf,2016,60.74074074074074,"Initializing Nonnegative Matrix Factorization using the Successive Projection Algorithm for multi-parametric medical image segmentation As nonnegative matrix factorization (NMF) represents a nonconvex problem, the quality of its solution will depend on the initialization of the factor matrices. This study proposes the Successive Projection Algorithm (SPA) as a feasible NMF initialization method. SPA is applied to a multi-parametric MRI dataset for automated NMF brain tumor segmentation. SPA provides fast and reproducible estimates of the tissue sources, and segmentation quality is found to be similar compared to repetitive random initialization."
Multi-Task Learning for Speech Recognition: An Overview,"Gueorgui Pironkov, Stéphane Dupont, Thierry Dutoit",1 - TCTS Lab University of Mons Belgium,"Generalization is a common issue for automatic speech recognition. A successful method used to improve recognition results consists of training a single system to solve multiple related tasks in parallel. This overview investigates which auxiliary tasks are helpful for speech recognition when multi-task learning is applied on a deep learning based acoustic model. The impact of multi-task learning on speech recognition related tasks, such as speaker adaptation, or robustness to noise, is also examined.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-154.pdf,2016,63.63636363636363,"Multi-Task Learning for Speech Recognition: An Overview Generalization is a common issue for automatic speech recognition. A successful method used to improve recognition results consists of training a single system to solve multiple related tasks in parallel. This overview investigates which auxiliary tasks are helpful for speech recognition when multi-task learning is applied on a deep learning based acoustic model. The impact of multi-task learning on speech recognition related tasks, such as speaker adaptation, or robustness to noise, is also examined."
Converting SVDD Scores into Probability Estimates,"Meriem Azami, Carole Lartizien, Stéphane Canu","1 - UMR5220; Inserm U1044 Université de Lyon CREATIS CNRS
2 - INSA-Lyon Univ. Lyon
3 - France
7 - LITIS INSA de Rouen Normandie Université, Saint-Etienne-du-Rouvray 76801 France","To enable post-processing, the output of a support vector data description (SVDD) should be a calibrated probability as done for SVM. Standard SVDD does not provide such probabilities. To create probabilities, we first generalize the SVDD model and propose two calibration functions. The first one uses a sigmoid model and the other one is based on a generalized extreme distribution model. To estimate calibration parameters, we use the consistency property of the estimator associated with a single SVDD model. A synthetic dataset and datasets from the UCI repository are used to compare the performance against a robust kernel density estimator.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-158.pdf,2016,73.46938775510203,"Converting SVDD Scores into Probability Estimates To enable post-processing, the output of a support vector data description (SVDD) should be a calibrated probability as done for SVM. Standard SVDD does not provide such probabilities. To create probabilities, we first generalize the SVDD model and propose two calibration functions. The first one uses a sigmoid model and the other one is based on a generalized extreme distribution model. To estimate calibration parameters, we use the consistency property of the estimator associated with a single SVDD model. A synthetic dataset and datasets from the UCI repository are used to compare the performance against a robust kernel density estimator."
Comparison of three algorithms for parametric change-point detection,"Cynthia Faure, Jean-Marc Bardet, Madalina Olteanu, Jérôme Lacaille","1 - SAMM EA Université Panthéon Sorbonne 4543 Paris France
4 - -Snecma (Safran Group) France","Numerous sensors placed on aircraft engines capture a considerable amount of data during tests or flights. In order to detect potential crucial changes of characteristic features, it is relevant to develop powerful statistical algorithms. This manuscript aims at detecting change-points, in an off-line framework, in piecewise-linear models and with an unknown number of change-points. In this context, three recent algorithms are considered, implemented and compared on simulated and real data.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-159.pdf,2016,100.0,"Comparison of three algorithms for parametric change-point detection Numerous sensors placed on aircraft engines capture a considerable amount of data during tests or flights. In order to detect potential crucial changes of characteristic features, it is relevant to develop powerful statistical algorithms. This manuscript aims at detecting change-points, in an off-line framework, in piecewise-linear models and with an unknown number of change-points. In this context, three recent algorithms are considered, implemented and compared on simulated and real data."
Towards incremental deep learning: multi-level change detection in a hierarchical recognition architecture,"Thomas Hecht, Alexander Gepperth",1 - U2IS ENSTA ParisTech INRIA Université Paris-Saclay 828 bd des Maréchaux 91762 Palaiseau Cedex France,"We present a trainable hierarchical architecture capable of detecting newness (or outliers) at all hierarchical levels. This contribution paves the way for deep neural architectures that are able to learn in an incremental fashion, for which the ability to detect newness is an indispensable prerequisite. We verify the ability to detect newness by conducting experiments on the MNIST database, where we introduce either localized changes, by adding noise to a small patch of the input, or global changes, by changing the global arrangement of local patterns which is not detectable at the local level. * Dr. Alexander Gepperth is also with INRIA FLOWERS. Thomas Hecht gratefully acknowledges funding support by the ""Direction Générale de l'Armement"" (DGA) and École Polytechnique.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-160.pdf,2016,96.80365296803653,"Towards incremental deep learning: multi-level change detection in a hierarchical recognition architecture We present a trainable hierarchical architecture capable of detecting newness (or outliers) at all hierarchical levels. This contribution paves the way for deep neural architectures that are able to learn in an incremental fashion, for which the ability to detect newness is an indispensable prerequisite. We verify the ability to detect newness by conducting experiments on the MNIST database, where we introduce either localized changes, by adding noise to a small patch of the input, or global changes, by changing the global arrangement of local patterns which is not detectable at the local level. * Dr. Alexander Gepperth is also with INRIA FLOWERS. Thomas Hecht gratefully acknowledges funding support by the ""Direction Générale de l'Armement"" (DGA) and École Polytechnique."
Semi-Supervised Classification of Social Textual Data Using WiSARD,"Fabio Rangel, Fabrício Firmino, Priscila Machado, Vieira Lima, Jonice Oliveira",1 - Federal University of Rio de Janeiro (UFRJ) Pos-Graduation Program in Informatics (PPGI) Av. Athos da S. Ramos 149. Rio de Janeiro RJ Brazil,"Text categorization is a problem which can be addressed by a semi-supervised learning classifier, since the annotation process is costly and ponderous. The semi-supervised approach is also adequate in the context of social network text categorization, due to its adaptation to class distribution changes. This article presents a novel approach for semi-supervised learning based on WiSARD classifier (SSW), and compares it to other already established mechanisms (S3VM and NB-EM), over three different datasets. The novel approach showed to be up to fifty times faster than S3VM and EM-NB with competitive accuracies.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-161.pdf,2016,100.0,"Semi-Supervised Classification of Social Textual Data Using WiSARD Text categorization is a problem which can be addressed by a semi-supervised learning classifier, since the annotation process is costly and ponderous. The semi-supervised approach is also adequate in the context of social network text categorization, due to its adaptation to class distribution changes. This article presents a novel approach for semi-supervised learning based on WiSARD classifier (SSW), and compares it to other already established mechanisms (S3VM and NB-EM), over three different datasets. The novel approach showed to be up to fifty times faster than S3VM and EM-NB with competitive accuracies."
On the equivalence between algorithms for Non-negative Matrix Factorization and Latent Dirichlet Allocation,"Thiago De, Paulo Faleiros, Alneu De, Andrade Lopes","1 - Thanks to FAPESP (Fundação de Amparo à Pesquisa do Estado de São Paulo 2011, 23689-9 Projeto
2 - Institute of Mathematics and Computer Science University of São Paulo 13560-970 São Carlos SP Brazil","LDA (Latent Dirichlet Allocation ) and NMF (Non-negative Matrix Factorization) are two popular techniques to extract topics in a textual document corpus. This paper shows that NMF with Kullback-Leibler divergence approximate the LDA model under a uniform Dirichlet prior, therefore the comparative analysis can be useful to elucidate the implementation of variational inference algorithm for LDA.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-162.pdf,2016,100.0,"On the equivalence between algorithms for Non-negative Matrix Factorization and Latent Dirichlet Allocation LDA (Latent Dirichlet Allocation ) and NMF (Non-negative Matrix Factorization) are two popular techniques to extract topics in a textual document corpus. This paper shows that NMF with Kullback-Leibler divergence approximate the LDA model under a uniform Dirichlet prior, therefore the comparative analysis can be useful to elucidate the implementation of variational inference algorithm for LDA."
Extending a two-variable mean to a multi-variable mean,"Estelle Massart, Julien Hendrickx, P.-A Absil",1 - Université catholique de Louvain -ICTEAM Institute B-1348 Louvain-la-Neuve Belgium,"We consider the problem of extending any two-variable mean M (•, •) to a multi-variable mean, using no other tool than M (•, •) itself. Pálfia proposed an iterative procedure that consists in evaluating successively two-variable means according to a cyclic pattern. We propose here a variant of his procedure to improve the convergence speed. Our approach consists in re-ordering the iterates after each iteration in order to speed up the transfer of information between successive iterates. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-164.pdf,2016,100.0,"Extending a two-variable mean to a multi-variable mean We consider the problem of extending any two-variable mean M (•, •) to a multi-variable mean, using no other tool than M (•, •) itself. Pálfia proposed an iterative procedure that consists in evaluating successively two-variable means according to a cyclic pattern. We propose here a variant of his procedure to improve the convergence speed. Our approach consists in re-ordering the iterates after each iteration in order to speed up the transfer of information between successive iterates. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office."
Human-Centered Machine Learning Through Interactive Visualization: Review and Open Challenges,"Dominik Sacha, Michael Sedlmair, Leishi Zhang, John Lee, Daniel Weiskopf, Stephen North, Daniel Keim","1 - University of Konstanz Germany
2 - University of Vienna Austria
3 - Middlesex University UK
4 - Université catholique de Louvain Belgium
5 - University of Stuttgart Germany 6-Infovisible Oldwick NJ USA","The goal of visual analytics (VA) systems is to solve complex problems by integrating automated data analysis methods, such as machine learning (ML) algorithms, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and makes the crucial interplay between automated algorithms and interactive visualizations more concrete. The framework is illustrated through several examples. We derive three open research challenges at the intersection of ML and visualization research that will lead to more effective data analysis.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-166.pdf,2016,75.26881720430107,"Human-Centered Machine Learning Through Interactive Visualization: Review and Open Challenges The goal of visual analytics (VA) systems is to solve complex problems by integrating automated data analysis methods, such as machine learning (ML) algorithms, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and makes the crucial interplay between automated algorithms and interactive visualizations more concrete. The framework is illustrated through several examples. We derive three open research challenges at the intersection of ML and visualization research that will lead to more effective data analysis."
Unsupervised Cross-Subject BCI Learning and Classification using Riemannian Geometry,"Samaneh Nasiri, Ghosheh Bolagh, Mohammad Shamsollahi, Christian Jutten, Marco Congedo","1 - Department of Electrical Engineering -Biomedical Signal and Image Processing Lab (BiSIPL Sharif University of Technology Tehran Iran
3 - -Grenoble Image Parole Signal Automatique (GIPSA) Laboratory CNRS University of Grenoble-Alpes Grenoble Institute of Technology Grenoble France","The inter-subject variability poses a challenge in cross-subject Brain-Computer Interface learning and classification. As a matter of fact, in cross-subject learning not all available subjects may improve the performance on a test subject. In order to address this problem we propose a subject selection algorithm and we investigate the use of this algorithm in the Riemannian geometry classification framework. We demonstrate that this new approach can significantly improve cross-subject learning without the need of any labeled data from test subjects.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-167.pdf,2016,100.0,"Unsupervised Cross-Subject BCI Learning and Classification using Riemannian Geometry The inter-subject variability poses a challenge in cross-subject Brain-Computer Interface learning and classification. As a matter of fact, in cross-subject learning not all available subjects may improve the performance on a test subject. In order to address this problem we propose a subject selection algorithm and we investigate the use of this algorithm in the Riemannian geometry classification framework. We demonstrate that this new approach can significantly improve cross-subject learning without the need of any labeled data from test subjects."
Semantic Role Labelling for Robot Instructions using Echo State Networks,"Johannes Twiefel, Xavier Hinaut, Stefan Wermter",1 - Department Informatik Universität Hamburg Vogt-Kölln-Straße 30 D-22527 Hamburg Germany,"To control a robot in a real-world robot scenario, a real-time parser is needed to create semantic representations from natural language which can be interpreted. The parser should be able to create the hierarchical tree-like representations without consulting external systems to show its learning capabilities. We propose an efficient Echo State Networkbased parser for robotic commands and only relies on the training data. The system generates a single semantic tree structure in real-time which can be executed by a robot arm manipulating objects. Four of six other approaches, which in most cases generate multiple trees and select one of them as the solution, were outperformed with 64.2% tree accuracy on difficult unseen natural language (74.1% under best conditions) on the same dataset.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-168.pdf,2016,100.0,"Semantic Role Labelling for Robot Instructions using Echo State Networks To control a robot in a real-world robot scenario, a real-time parser is needed to create semantic representations from natural language which can be interpreted. The parser should be able to create the hierarchical tree-like representations without consulting external systems to show its learning capabilities. We propose an efficient Echo State Networkbased parser for robotic commands and only relies on the training data. The system generates a single semantic tree structure in real-time which can be executed by a robot arm manipulating objects. Four of six other approaches, which in most cases generate multiple trees and select one of them as the solution, were outperformed with 64.2% tree accuracy on difficult unseen natural language (74.1% under best conditions) on the same dataset."
Modelling of Parameterized Processes via Regression in the Model Space,"Witali Aswolinskiy, René Reinhart, Jochen Steil",1 - Research Institute for Cognition and Robotics -CoR-Lab Universitätsstraße 25 33615 Bielefeld Germany,"We consider the modelling of parameterized processes, where the goal is to model the process for new parameter value combinations. We compare the classical regression approach to a modular approach based on regression in the model space: First, for each process parametrization a model is learned. Second, a mapping from process parameters to model parameters is learned. We evaluate both approaches on a real and a synthetic dataset and show the advantages of the regression in the model space. * This work is funded by the German Federal Ministry of Education and Research (BMBF) within the Leading-Edge Cluster Competition ""it's OWL"" (intelligent technical systems Os-tWestfalenLippe). The authors thank Hesse GmbH [1] and Infineon Technologies AG [2] for permission to use the data from the project 'Intelligent Copper Bonding' (InCuB)  [3] .",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-169.pdf,2016,78.57142857142857,"Modelling of Parameterized Processes via Regression in the Model Space We consider the modelling of parameterized processes, where the goal is to model the process for new parameter value combinations. We compare the classical regression approach to a modular approach based on regression in the model space: First, for each process parametrization a model is learned. Second, a mapping from process parameters to model parameters is learned. We evaluate both approaches on a real and a synthetic dataset and show the advantages of the regression in the model space. * This work is funded by the German Federal Ministry of Education and Research (BMBF) within the Leading-Edge Cluster Competition ""it's OWL"" (intelligent technical systems Os-tWestfalenLippe). The authors thank Hesse GmbH [1] and Infineon Technologies AG [2] for permission to use the data from the project 'Intelligent Copper Bonding' (InCuB)  [3] ."
Machine learning for medical applications,"Verónica Bolón-Canedo, Beatriz Remeseiro, Amparo Alonso-Betanzos, Aurélio Campilho","1 - Departamento de Computación Universidade da Coruña Campus de Elviña s/n 15071 A Coruña Spain
2 - INESC TEC -INESC Technology and Science Campus da FEUP Rua Dr. Roberto Frias 4200-465 Porto Portugal
5 - Faculdade de Engenharia Universidade do Porto Campus da FEUP Rua Dr. Roberto Frias 4200-465 Porto Portugal","Machine learning has been well applied and recognized as an effective tool to handle a wide range of real situations, including medical applications. In this scenario, it can help to alleviate problems typically suffered by researchers in this field, such as saving time for practitioners and providing unbiased results. This tutorial is concerned with the use of machine learning techniques to solve different medical problems. We provide a survey of recent methods developed or applied to this context, together with a review of novel contributions to the ESANN 2016 special session on Machine learning for medical applications.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-17.pdf,2016,100.0,"Machine learning for medical applications Machine learning has been well applied and recognized as an effective tool to handle a wide range of real situations, including medical applications. In this scenario, it can help to alleviate problems typically suffered by researchers in this field, such as saving time for practitioners and providing unbiased results. This tutorial is concerned with the use of machine learning techniques to solve different medical problems. We provide a survey of recent methods developed or applied to this context, together with a review of novel contributions to the ESANN 2016 special session on Machine learning for medical applications."
Maximum likelihood learning of RBMs with Gaussian visible units on the Stiefel manifold,"Ryo Karakida, Masato Okada, Shun-Ichi Amari","1 - Department of Complexity Science and Engineering The University of Tokyo Chiba Japan
3 - RIKEN Brain Science Institute Saitama Japan","The restricted Boltzmann machine (RBM) is a generative model widely used as an essential component of deep networks. However, it is hard to train RBMs by using maximum likelihood (ML) learning because many iterations of Gibbs sampling take too much computational time. In this study, we reveal that, if we consider RBMs with Gaussian visible units and constrain the weight matrix to the Stiefel manifold, we can easily compute analytical values of the likelihood and its gradients. The proposed algorithm on the Stiefel manifold achieves comparable performance to the standard learning algorithm.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-170.pdf,2016,100.0,"Maximum likelihood learning of RBMs with Gaussian visible units on the Stiefel manifold The restricted Boltzmann machine (RBM) is a generative model widely used as an essential component of deep networks. However, it is hard to train RBMs by using maximum likelihood (ML) learning because many iterations of Gibbs sampling take too much computational time. In this study, we reveal that, if we consider RBMs with Gaussian visible units and constrain the weight matrix to the Stiefel manifold, we can easily compute analytical values of the likelihood and its gradients. The proposed algorithm on the Stiefel manifold achieves comparable performance to the standard learning algorithm."
Performance assessment of quantum clustering in non-spherical data distributions,"Raúl Casaña-Eslava, José Martín-Guerrero, Ian Jarman, Paulo Lisboa","1 - School of Computing and Mathematical Sciences Liverpool John Moores University United Kingdom
2 - Department of Electronic Engineering University of Valencia Spain","This work deals with the performance of Quantum Clustering (QC) when applied to non-spherically distributed data sets; in particular, QC outperforms K-Means when applied to a data set that contains information of different olive oil areas. The Jaccard score can be set depending on QC parameters; this enables to find local maxima by tuning QC parameters, thus showing up the underlying data structure. In conclusion, QC appears as a promising solution to deal with nonspherical data distributions; however, some improvements are still needed, for example, in order to find out a way to detect the appropriate number of clusters for a given data set.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-171.pdf,2016,100.0,"Performance assessment of quantum clustering in non-spherical data distributions This work deals with the performance of Quantum Clustering (QC) when applied to non-spherically distributed data sets; in particular, QC outperforms K-Means when applied to a data set that contains information of different olive oil areas. The Jaccard score can be set depending on QC parameters; this enables to find local maxima by tuning QC parameters, thus showing up the underlying data structure. In conclusion, QC appears as a promising solution to deal with nonspherical data distributions; however, some improvements are still needed, for example, in order to find out a way to detect the appropriate number of clusters for a given data set."
A Reservoir Activation Kernel for Trees,"Davide Bacciu, Claudio Gallicchio, Alessio Micheli",1 - Dipartimento di Informatica Università di Pisa Italy,We introduce an efficient tree kernel for reservoir computing models exploiting the recursive encoding of the structure in the state activations of the untrained recurrent layer. We discuss how the contractive property of the reservoir induces a topographic organization of the state space that can be used to compute structural matches in terms of pairwise distances between points in the state space. The experimental analysis shows that the proposed kernel is capable of achieving competitive classification results by relying on very small reservoirs comprising as little as 10 sparsely connected recurrent neurons.,Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-172.pdf,2016,79.48717948717949,A Reservoir Activation Kernel for Trees We introduce an efficient tree kernel for reservoir computing models exploiting the recursive encoding of the structure in the state activations of the untrained recurrent layer. We discuss how the contractive property of the reservoir induces a topographic organization of the state space that can be used to compute structural matches in terms of pairwise distances between points in the state space. The experimental analysis shows that the proposed kernel is capable of achieving competitive classification results by relying on very small reservoirs comprising as little as 10 sparsely connected recurrent neurons.
Using Semantic Similarity for Multi-Label Zero-Shot Classification of Text Documents,"Sappadla Prateek Veeranna, Jinseok Nam, Eneldo Mencía, Johannes Fürnkranz","1 - Birla Institute of Technology and Science -Pilani India
2 - Knowledge Engineering Group -TU Darmstadt Germany
3 - -Knowledge Discovery in Scientific Literature -DIPF Germany","In this paper, we examine a simple approach to zero-shot multi-label text classification, i.e., to the problem of predicting multiple, possibly previously unseen labels for a document. In particular, we propose to use a semantic embedding of label and document words and base the prediction of previously unseen labels on the similarity between the label name and the document words in this embedding. Experiments on three textual datasets across various domains show that even such a simple technique yields considerable performance improvements over a simple uninformed baseline.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-174.pdf,2016,73.80952380952381,"Using Semantic Similarity for Multi-Label Zero-Shot Classification of Text Documents In this paper, we examine a simple approach to zero-shot multi-label text classification, i.e., to the problem of predicting multiple, possibly previously unseen labels for a document. In particular, we propose to use a semantic embedding of label and document words and base the prediction of previously unseen labels on the similarity between the label name and the document words in this embedding. Experiments on three textual datasets across various domains show that even such a simple technique yields considerable performance improvements over a simple uninformed baseline."
Deep Reservoir Computing: A Critical Analysis,"Claudio Gallicchio, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"In this paper we propose an empirical analysis of deep recurrent neural networks (RNNs) with stacked layers. The analysis aims at the study and proposal of approaches to develop and enhance multiple timescale and hierarchical dynamics in deep recurrent architectures, within the efficient Reservoir Computing (RC) approach for RNN modeling. Results point out the actual relevance of layering and RC parameters aspects on the diversification of temporal representations in deep recurrent models.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-175.pdf,2016,100.0,"Deep Reservoir Computing: A Critical Analysis In this paper we propose an empirical analysis of deep recurrent neural networks (RNNs) with stacked layers. The analysis aims at the study and proposal of approaches to develop and enhance multiple timescale and hierarchical dynamics in deep recurrent architectures, within the efficient Reservoir Computing (RC) approach for RNN modeling. Results point out the actual relevance of layering and RC parameters aspects on the diversification of temporal representations in deep recurrent models."
RSS-based Robot Localization in Critical Environments using Reservoir Computing,"Mauro Dragone, Claudio Gallicchio, Roberto Guzman, Alessio Micheli","1 - School of Computer Science and Statistics Trinity College Dublin College Green Dublin 2 Ireland
2 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy
3 - Robotnik Automation S.L.L. Pl Fte. del Jarro C/Ciudad de Barcelona 3A -46988 Paterna, Valencia Spain","Supporting both accurate and reliable localization in critical environments is key to increasing the potential of logistic mobile robots. This paper presents a system for indoor robot localization based on Reservoir Computing from noisy radio signal strength index (RSSI) data generated by a network of sensors. The proposed approach is assessed under different conditions in a real-world hospital environment. Experimental results show that the resulting system represents a good trade-off between localization performance and deployment complexity, with the ability to recover from cases in which permanent changes in the environment affect its generalization performance.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-176.pdf,2016,100.0,"RSS-based Robot Localization in Critical Environments using Reservoir Computing Supporting both accurate and reliable localization in critical environments is key to increasing the potential of logistic mobile robots. This paper presents a system for indoor robot localization based on Reservoir Computing from noisy radio signal strength index (RSSI) data generated by a network of sensors. The proposed approach is assessed under different conditions in a real-world hospital environment. Experimental results show that the resulting system represents a good trade-off between localization performance and deployment complexity, with the ability to recover from cases in which permanent changes in the environment affect its generalization performance."
Instance and Feature Weighted k-Nearest-Neighbours Algorithm,"Gabriel Prat, Lluís Belanche",1 - Computer Science Department Universitat Politècnica de Catalunya Omega Building Jordi Girona 1-3 08034 Barcelona Spain,"We present a novel method that aims at providing a more stable selection of feature subsets when variations in the training process occur. This is accomplished by using an instance-weighting process -assigning different importances to instances-as a preprocessing step to a feature weighting method that is independent of the learner, and then making good use of both sets of computed weigths in a standard Nearest-Neighbours classifier. We report extensive experimentation in well-known benchmarking datasets as well as some challenging microarray gene expression problems. Our results show increases in stability for most subset sizes and most problems, without compromising prediction accuracy. 
 Preliminaries Let D = {(x 1 , t 1 ), . . . , (x N , t N )} be a training data set of length N , each instance x n ∈ R d with its corresponding class label t n . The margin of an instance with 605",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-178.pdf,2016,55.46218487394958,"Instance and Feature Weighted k-Nearest-Neighbours Algorithm We present a novel method that aims at providing a more stable selection of feature subsets when variations in the training process occur. This is accomplished by using an instance-weighting process -assigning different importances to instances-as a preprocessing step to a feature weighting method that is independent of the learner, and then making good use of both sets of computed weigths in a standard Nearest-Neighbours classifier. We report extensive experimentation in well-known benchmarking datasets as well as some challenging microarray gene expression problems. Our results show increases in stability for most subset sizes and most problems, without compromising prediction accuracy. 
 Preliminaries Let D = {(x 1 , t 1 ), . . . , (x N , t N )} be a training data set of length N , each instance x n ∈ R d with its corresponding class label t n . The margin of an instance with 605"
Bayesian mixture of spatial spline regressions,Faicel Chamroukhi,"1 - UMR 7296 Université de Toulon CNRS LSIS 83957 La Garde France
2 - Laboratoire de Mathématiques Paul Painlevé UMR CNRS 8524 Université Lille","We introduce a Bayesian mixture of spatial spline regressions with mixed-effects (BMSSR) for density estimation and model-based clustering of spatial functional data. The model, through its Bayesian formulation, allows to integrate possible prior knowledge on the data structure and constitute a good alternative to a recent mixture of spatial spline regressions model estimated in a maximum likelihood framework via the expectation-maximization (EM) algorithm. The Bayesian model inference is performed by Markov Chain Monte Carlo (MCMC) sampling. We derive a Gibbs sampler to infer the model and apply it on simulated surfaces and a real problem of handwritten digit recognition using the MNIST data.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-179.pdf,2016,100.0,"Bayesian mixture of spatial spline regressions We introduce a Bayesian mixture of spatial spline regressions with mixed-effects (BMSSR) for density estimation and model-based clustering of spatial functional data. The model, through its Bayesian formulation, allows to integrate possible prior knowledge on the data structure and constitute a good alternative to a recent mixture of spatial spline regressions model estimated in a maximum likelihood framework via the expectation-maximization (EM) algorithm. The Bayesian model inference is performed by Markov Chain Monte Carlo (MCMC) sampling. We derive a Gibbs sampler to infer the model and apply it on simulated surfaces and a real problem of handwritten digit recognition using the MNIST data."
"Information Visualisation and Machine Learning: Characteristics, Convergence and Perspective","Benoît Frénay, Bruno Dumas",1 - Faculty of Computer Science PReCISE Rue Grandgagnage 22 Université de Namur 5000 Namur Belgium,"This paper discusses how information visualisation and machine learning can cross-fertilise. On the one hand, the user-centric field of information visualisation can help machine learning to better integrate users in the learning, assessment and interpretation processes. On the other hand, machine learning can provide powerful algorithms for clustering, dimensionality reduction, data cleansing, outlier detection, etc. Such inference tools are required to create efficient visualisations. This paper highlight opportunities to collaborate for experts in both fields.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-18.pdf,2016,71.73913043478262,"Information Visualisation and Machine Learning: Characteristics, Convergence and Perspective This paper discusses how information visualisation and machine learning can cross-fertilise. On the one hand, the user-centric field of information visualisation can help machine learning to better integrate users in the learning, assessment and interpretation processes. On the other hand, machine learning can provide powerful algorithms for clustering, dimensionality reduction, data cleansing, outlier detection, etc. Such inference tools are required to create efficient visualisations. This paper highlight opportunities to collaborate for experts in both fields."
How Machine Learning won the Higgs Boson Challenge,"Claire Adam-Bourdarios, Glen Cowan, Cécile Germain, Isabelle Guyon, Balàzs Kégl, David Rousseau","1 - -LRI UPSud Université Paris-Saclay France
2 - LAL IN2P3/CNRS France
3 - -Royal Holloway London UK
5 - CNRS/INRIA France
7 - ChaLearn USA","In 2014 we ran a very successful machine learning challenge in High Ernergy physics attracting 1785 teams, which exposed the machine learning community for the first time to the problem of ""learning to discover"" (www.kaggle.com/c/higgs-boson). While physicists had the opportunity to improve on the state-of-the-art using ""feature engineering"" based on physics principles, this was not the determining factor in winning the challenge. Rather, the challenge revealed that the central difficulty of the problem is to develop a strategy to optimize directly the Approximate Median Significance (AMS) objective function, which is a particularly challenging and novel problem. This objective function aims at increasing the power of a statistical test. The top ranking learning machines span a variety of techniques including deep learning and gradient tree boosting. This paper presents the problem setting and analyzes the results.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-181.pdf,2016,72.0,"How Machine Learning won the Higgs Boson Challenge In 2014 we ran a very successful machine learning challenge in High Ernergy physics attracting 1785 teams, which exposed the machine learning community for the first time to the problem of ""learning to discover"" (www.kaggle.com/c/higgs-boson). While physicists had the opportunity to improve on the state-of-the-art using ""feature engineering"" based on physics principles, this was not the determining factor in winning the challenge. Rather, the challenge revealed that the central difficulty of the problem is to develop a strategy to optimize directly the Approximate Median Significance (AMS) objective function, which is a particularly challenging and novel problem. This objective function aims at increasing the power of a statistical test. The top ranking learning machines span a variety of techniques including deep learning and gradient tree boosting. This paper presents the problem setting and analyzes the results."
Discriminative Dimensionality Reduction in Kernel Space,"Alexander Schulz, Barbara Hammer","1 - CITEC centre of excellence
2 - Bielefeld University Germany","Modern nonlinear dimensionality reduction (DR) techniques enable an efficient visual data inspection in the form of scatter plots, but they suffer from the fact that DR is inherently ill-posed. Discriminative dimensionality reduction (DiDi) offers one remedy, since it allows a practitioner to identify what is relevant and what should be regarded as noise by means of auxiliary information such as class labels. Powerful DiDi methods exist, but they are restricted to vectorial data only. In this contribution, we extend one particularly promising approach to non-vectorial data characterised by a kernel. This enables us to apply discriminative dimensionality reduction to complex, possibly discrete or structured data. * Funding from DFG under grant number HA2719/7-1 and by the CITEC center of excellence (EXC277) is gratefully acknowledged.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-186.pdf,2016,67.27272727272727,"Discriminative Dimensionality Reduction in Kernel Space Modern nonlinear dimensionality reduction (DR) techniques enable an efficient visual data inspection in the form of scatter plots, but they suffer from the fact that DR is inherently ill-posed. Discriminative dimensionality reduction (DiDi) offers one remedy, since it allows a practitioner to identify what is relevant and what should be regarded as noise by means of auxiliary information such as class labels. Powerful DiDi methods exist, but they are restricted to vectorial data only. In this contribution, we extend one particularly promising approach to non-vectorial data characterised by a kernel. This enables us to apply discriminative dimensionality reduction to complex, possibly discrete or structured data. * Funding from DFG under grant number HA2719/7-1 and by the CITEC center of excellence (EXC277) is gratefully acknowledged."
Using Robust Extreme Learning Machines to Predict Cotton Yarn Strength and Hairiness,"Diego Mesquita, Antonio Neto, José Queiroz Neto, João Gomes, Leonardo Rodrigues","1 - Federal University of Ceará -Computer Science Department Rua Campus do Pici sn -Fortaleza-CE Brazil
5 - Institute of Aeronautics and Space -Electronics Division Praça Marechal Eduardo Gomes 50
6 - São José dos Campos-SP Brazil","Cotton yarn is often spun from a mixture of distinct cotton bales. Although many studies have presented efforts to predict hairiness and strength from cotton properties, the heterogeneity of this mixture and its influence in such values have been neglected so far. In this work the properties of the cotton bale mixture are modeled as random variables and a robust variant of the Extreme Learning Machine (ELM) to address the cotton quality prediction problem is proposed. A real world dataset collected from a textile industry was used to compare the performance of the proposed model with a traditional ELM and a linear regression model. The results showed that the proposed method outperformed the benchmark methods in terms of Average Root Mean Square Error (ARMSE).",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-187.pdf,2016,100.0,"Using Robust Extreme Learning Machines to Predict Cotton Yarn Strength and Hairiness Cotton yarn is often spun from a mixture of distinct cotton bales. Although many studies have presented efforts to predict hairiness and strength from cotton properties, the heterogeneity of this mixture and its influence in such values have been neglected so far. In this work the properties of the cotton bale mixture are modeled as random variables and a robust variant of the Extreme Learning Machine (ELM) to address the cotton quality prediction problem is proposed. A real world dataset collected from a textile industry was used to compare the performance of the proposed model with a traditional ELM and a linear regression model. The results showed that the proposed method outperformed the benchmark methods in terms of Average Root Mean Square Error (ARMSE)."
K-means for Datasets with Missing Attributes: Building Soft Constraints with Observed and Imputed Values,"Diego Mesquita, João Gomes, Leonardo Rodrigues","1 - Federal University of Ceará -Computer Science Department Rua Campus do Pici sn -Fortaleza-CE Brazil
3 - Institute of Aeronautics and Space -Electronics Division Praça Marechal Eduardo Gomes 50
4 - São José dos Campos-SP Brazil","Clustering methods have a wide range of applications. However, the presence of missing attribute values on the dataset may limit the use of clustering methods. Developing clustering methods that can deal with missing data has been a topic of interest among researchers in recent years. This work presents a variant of the well known k-means algorithm that can handle missing data. The proposed algorithm uses one type of soft constraints for observed data and a second type for imputed data. Four public datasets were used in the experiments in order to compare the performance of the proposed model with a traditional k-means algorithm and an algorithm that uses soft constraints only for observed data. The results showed that the proposed method outperformed the benchmark methods for all datasets considered in the experiments.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-188.pdf,2016,100.0,"K-means for Datasets with Missing Attributes: Building Soft Constraints with Observed and Imputed Values Clustering methods have a wide range of applications. However, the presence of missing attribute values on the dataset may limit the use of clustering methods. Developing clustering methods that can deal with missing data has been a topic of interest among researchers in recent years. This work presents a variant of the well known k-means algorithm that can handle missing data. The proposed algorithm uses one type of soft constraints for observed data and a second type for imputed data. Four public datasets were used in the experiments in order to compare the performance of the proposed model with a traditional k-means algorithm and an algorithm that uses soft constraints only for observed data. The results showed that the proposed method outperformed the benchmark methods for all datasets considered in the experiments."
Incremental learning algorithms and applications,"Alexander Gepperth, Barbara Hammer","1 - UIIS ENSTA ParisTech INRIA Université Paris-Saclay 828 Bvd des Maréchaux 91762 Palaiseau Cedex France
2 - Bielefeld University CITEC centre of excellence Universitätsstrasse 21-23 D-33594 Bielefeld Germany","Incremental learning refers to learning from streaming data, which arrive over time, with limited memory resources and, ideally, without sacrificing model accuracy. This setting fits different application scenarios such as learning in changing environments, model personalisation, or lifelong learning, and it offers an elegant scheme for big data processing by means of its sequential treatment. In this contribution, we formalise the concept of incremental learning, we discuss particular challenges which arise in this setting, and we give an overview about popular approaches, its theoretical foundations, and applications which emerged in the last years.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-19.pdf,2016,100.0,"Incremental learning algorithms and applications Incremental learning refers to learning from streaming data, which arrive over time, with limited memory resources and, ideally, without sacrificing model accuracy. This setting fits different application scenarios such as learning in changing environments, model personalisation, or lifelong learning, and it offers an elegant scheme for big data processing by means of its sequential treatment. In this contribution, we formalise the concept of incremental learning, we discuss particular challenges which arise in this setting, and we give an overview about popular approaches, its theoretical foundations, and applications which emerged in the last years."
Physics and Machine Learning: Emerging Paradigms,"José Martín-Guerrero, Paulo Lisboa, Alfredo Vellido","1 - Dept. of Electronic Engineering -Universitat de València Av. de la Universitat, s/n 46100 Burjassot València Spain
2 - Dept. of Mathematics and Statistics -Liverpool John Moores University Byrom St L3 3AF Liverpool United Kingdom
3 - Dept. of Computer Science Univ. Politècnica de Catalunya C. Jordi Girona 1-3 08034 Barcelona Spain","Current research in Machine Learning (ML) combines the study of variations on well-established methods with cutting-edge breakthroughs based on completely new approaches. Among the latter, emerging paradigms from Physics have taken special relevance in recent years. Although still in its initial stages, Quantum Machine Learning (QML) shows promising ways to speed up some of the costly ML calculations with a similar or even better performance than existing approaches. Two additional advantages are related to the intrinsic probabilistic approach of QML, since quantum states are genuinely probabilistic, and to the capability of finding the global optimum of a given cost function by means of adiabatic quantum optimization, thus circumventing the usual problem of local minima. Another Physics approach for ML comes from Statistical Physics and is linked to Information theory in supervised and semi-supervised learning frameworks. On the other hand, and from the perspective of Physics, ML can provide solutions by extracting knowledge from huge amounts of data, as it is common in many experiments in the field, such as those related to High Energy Physics for elementary-particle research and Observational Astronomy.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-20.pdf,2016,100.0,"Physics and Machine Learning: Emerging Paradigms Current research in Machine Learning (ML) combines the study of variations on well-established methods with cutting-edge breakthroughs based on completely new approaches. Among the latter, emerging paradigms from Physics have taken special relevance in recent years. Although still in its initial stages, Quantum Machine Learning (QML) shows promising ways to speed up some of the costly ML calculations with a similar or even better performance than existing approaches. Two additional advantages are related to the intrinsic probabilistic approach of QML, since quantum states are genuinely probabilistic, and to the capability of finding the global optimum of a given cost function by means of adiabatic quantum optimization, thus circumventing the usual problem of local minima. Another Physics approach for ML comes from Statistical Physics and is linked to Information theory in supervised and semi-supervised learning frameworks. On the other hand, and from the perspective of Physics, ML can provide solutions by extracting knowledge from huge amounts of data, as it is common in many experiments in the field, such as those related to High Energy Physics for elementary-particle research and Observational Astronomy."
Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,"Luca Oneto, Nicolò Navarin, Michele Donini, Fabio Aiolli, Davide Anguita","1 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy
2 - Department of Mathematics University of Padua Via Trieste 63 I-35121 Padova -Italy
5 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy","Kernel methods consistently outperformed previous generations of learning techniques. They provide a flexible and expressive learning framework that has been successfully applied to a wide range of real world problems but, recently, novel algorithms, such as Deep Neural Networks and Ensemble Methods, have increased their competitiveness against them. Due to the current data growth in size, heterogeneity and structure, the new generation of algorithms are expected to solve increasingly challenging problems. This must be done under growing constraints such as computational resources, memory budget and energy consumption. For these reasons, new ideas have to come up in the field of kernel learning, such as deeper kernels and novel algorithms, to fill the gap that now exists with the most recent learning paradigms. The purpose of this special session is to highlight recent advances in learning with kernels. In particular, this session welcomes contributions toward the solution of the weaknesses (e.g. scalability, computational efficiency and too shallow kernels) and the improvement of the strengths (e.g. the ability of dealing with structural data) of the state of the art kernel methods. We also encourage the submission of new theoretical results in the Statistical Learning Theory framework and innovative solutions to real world problems.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-21.pdf,2016,100.0,"Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints Kernel methods consistently outperformed previous generations of learning techniques. They provide a flexible and expressive learning framework that has been successfully applied to a wide range of real world problems but, recently, novel algorithms, such as Deep Neural Networks and Ensemble Methods, have increased their competitiveness against them. Due to the current data growth in size, heterogeneity and structure, the new generation of algorithms are expected to solve increasingly challenging problems. This must be done under growing constraints such as computational resources, memory budget and energy consumption. For these reasons, new ideas have to come up in the field of kernel learning, such as deeper kernels and novel algorithms, to fill the gap that now exists with the most recent learning paradigms. The purpose of this special session is to highlight recent advances in learning with kernels. In particular, this session welcomes contributions toward the solution of the weaknesses (e.g. scalability, computational efficiency and too shallow kernels) and the improvement of the strengths (e.g. the ability of dealing with structural data) of the state of the art kernel methods. We also encourage the submission of new theoretical results in the Statistical Learning Theory framework and innovative solutions to real world problems."
Learning in indefinite proximity spaces -recent trends,"Frank-Michael Schleif, Peter Tino, Yingyu Liang","1 - School of Computer Science University of Birmingham B15 2TT Edgbaston, Birmingham United Kingdom
3 - School of Computer Science Princeton University Princeton USA","Efficient learning of a data analysis task strongly depends on the data representation. Many methods rely on symmetric similarity or dissimilarity representations by means of metric inner products or distances, providing easy access to powerful mathematical formalisms like kernel approaches. Similarities and dissimilarities are however often naturally obtained by non-metric proximity measures which can not easily be handled by classical learning algorithms. Major efforts have been undertaken to provide approaches which can either directly be used for such data or to make standard methods available for these type of data. We provide an overview about recent achievements in the field of learning with indefinite proximities.",Indefinite proximity learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-22.pdf,2016,80.0,"Learning in indefinite proximity spaces -recent trends Efficient learning of a data analysis task strongly depends on the data representation. Many methods rely on symmetric similarity or dissimilarity representations by means of metric inner products or distances, providing easy access to powerful mathematical formalisms like kernel approaches. Similarities and dissimilarities are however often naturally obtained by non-metric proximity measures which can not easily be handled by classical learning algorithms. Major efforts have been undertaken to provide approaches which can either directly be used for such data or to make standard methods available for these type of data. We provide an overview about recent achievements in the field of learning with indefinite proximities."
Challenges in Deep Learning,"Plamen Angelov, Alessandro Sperduti","1 - Lancaster University -School of Computing and Communications Lancaster LA14WA United Kingdom
2 - Department of Mathematics Via Trieste University of Padova 63 35121 Padova Italy","In recent years, Deep Learning methods and architectures have reached impressive results, allowing quantum-leap improvements in performance in many difficult tasks, such as speech recognition, end-toend machine translation, image classification/understanding, just to name a few. After a brief introduction to some of the main achievements of Deep Learning, we discuss what we think are the general challenges that should be addressed in the future. We close with a review of the contributions to the ESANN 2016 special session on Deep Learning.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-23.pdf,2016,100.0,"Challenges in Deep Learning In recent years, Deep Learning methods and architectures have reached impressive results, allowing quantum-leap improvements in performance in many difficult tasks, such as speech recognition, end-toend machine translation, image classification/understanding, just to name a few. After a brief introduction to some of the main achievements of Deep Learning, we discuss what we think are the general challenges that should be addressed in the future. We close with a review of the contributions to the ESANN 2016 special session on Deep Learning."
An Experiment in Pre-Emphasizing Diversified Deep Neural Classifiers,"Ricardo Alvear-Sandoval, Aníbal Figueiras-Vidal","1 - L+/Dept Univ. Carlos III de Madrid -GAMMA Signal Theory and Communications Av. Universidad 30 28911 Leganés, Madrid Spain","We explore if adding a pre-emphasis step to diversified deep auto-encoding based classifiers serves to further improve their performance with respect to those obtained just separately using pre-emphasis or diversification. An experiment with a number of well-known databases, selected because they have some complementary characteristics, shows that further improvement does appear, the main condition for it simply being to select general and flexible enough pre-emphasis forms. Other manners of combining diversity and pre-emphasis require more research effort, as well as to investigate if other deep architectures can also obtain benefits from these ideas.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-27.pdf,2016,100.0,"An Experiment in Pre-Emphasizing Diversified Deep Neural Classifiers We explore if adding a pre-emphasis step to diversified deep auto-encoding based classifiers serves to further improve their performance with respect to those obtained just separately using pre-emphasis or diversification. An experiment with a number of well-known databases, selected because they have some complementary characteristics, shows that further improvement does appear, the main condition for it simply being to select general and flexible enough pre-emphasis forms. Other manners of combining diversity and pre-emphasis require more research effort, as well as to investigate if other deep architectures can also obtain benefits from these ideas."
Clustering From Two Data Sources Using a Kernel-Based Approach with Weight Coupling,"Lynn Houthuys, Rocco Langone, Johan Suykens",1 - Department of Electrical Engineering ESAT-STADIUS KU Leuven Kasteelpark Arenberg 10 B-3001 Leuven Belgium,"In many clustering problems there are multiple data sources which are available. Although each one could individually be used for clustering, exploiting information from all data sources together can be relevant to find a clustering that is more accurate. Here a new model is proposed for clustering when two data sources are available. This model is called Binary View Kernel Spectral Clustering (BVKSC) and is based on a constrained optimization formulation typical to Least Squares Support Vector Machines (LS-SVM). The model includes a coupling term, where the weights of the two different data sources are coupled in the primal model. This coupling term makes it possible to exploit the additional information from each other data source. Experimental comparisons with a number of similar methods show that using two data sources can improve the clustering results and that the proposed method is competitive in performance to other state-of-the-art methods.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-28.pdf,2016,75.90361445783132,"Clustering From Two Data Sources Using a Kernel-Based Approach with Weight Coupling In many clustering problems there are multiple data sources which are available. Although each one could individually be used for clustering, exploiting information from all data sources together can be relevant to find a clustering that is more accurate. Here a new model is proposed for clustering when two data sources are available. This model is called Binary View Kernel Spectral Clustering (BVKSC) and is based on a constrained optimization formulation typical to Least Squares Support Vector Machines (LS-SVM). The model includes a coupling term, where the weights of the two different data sources are coupled in the primal model. This coupling term makes it possible to exploit the additional information from each other data source. Experimental comparisons with a number of similar methods show that using two data sources can improve the clustering results and that the proposed method is competitive in performance to other state-of-the-art methods."
Incremental hierarchical indexing and visualisation of large image collections,"Frédéric Rayar, Sabine Barrat, Fatma Bouali, Gilles Venturini","1 - Université François-Rabelais de Tours 64, avenue Jean Portalis 6300, 37200 Tours LI EA France
4 - Université de Lille 2 IUT Dpt STID 25-27
5 - rue du Maréchal Foch 59100 Roubaix france","Ever-growing image collections are common in several fields such as health, digital humanities or social networks. Nowadays, there is a lack of visualisation tools to browse such large image collection. In this work, the incremental indexing and the visualisation of large image collections is done jointly. The BIRCH algorithm is improved to incrementally yield a hierarchical indexing structure. A custom web platform is presented to visualise the structure that is built. The proposed method is tested with two large image collections, up to one million images.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-29.pdf,2016,100.0,"Incremental hierarchical indexing and visualisation of large image collections Ever-growing image collections are common in several fields such as health, digital humanities or social networks. Nowadays, there is a lack of visualisation tools to browse such large image collection. In this work, the incremental indexing and the visualisation of large image collections is done jointly. The BIRCH algorithm is improved to incrementally yield a hierarchical indexing structure. A custom web platform is presented to visualise the structure that is built. The proposed method is tested with two large image collections, up to one million images."
Learning with hard constraints as a limit case of learning with soft constraints,"Giorgio Gnecco, Marco Gori, Stefano Melacci, Marcello Sanguineti","1 - IMT -School for Advanced Studies -DYSCO Piazza S. Francesco 19 Lucca Italy
2 - University of Siena -DIISM Via Roma 56 Siena Italy
4 - University of Genoa -DIBRIS Via all'Opera Pia 13 Genoa Italy","We show that the optimal solution to the learning problem with hard bilateral and linear pointwise constraints stated therein can be obtained as the limit of the sequence of optimal solutions to the related learning problems with soft bilateral and linear pointwise constraints, when the penalty parameter tends to infinity.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-32.pdf,2016,100.0,"Learning with hard constraints as a limit case of learning with soft constraints We show that the optimal solution to the learning problem with hard bilateral and linear pointwise constraints stated therein can be obtained as the limit of the sequence of optimal solutions to the related learning problems with soft bilateral and linear pointwise constraints, when the penalty parameter tends to infinity."
"Genetic Algorithm with Novel Crossover, Selection and Health Check for Clustering","A Beg, Md Islam",1 - School of Computing and Mathematics Charles Sturt University Panorama Avenue 2795 Bathurst Australia,"We propose a genetic algorithm for clustering records, where the algorithm contains new approaches for various genetic operations including crossover and selection. We also propose a health check operation that finds sick chromosomes of a population and probabilistically replaces them with healthy chromosomes found in the previous generations. The proposed approaches improve the chromosome quality within a population, which then contribute in achieving good clustering solution. We use fifteen datasets to compare our technique with five existing techniques in terms of two cluster evaluation criteria. The experimental results indicate a clear superiority of the proposed technique over the existing techniques.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-37.pdf,2016,100.0,"Genetic Algorithm with Novel Crossover, Selection and Health Check for Clustering We propose a genetic algorithm for clustering records, where the algorithm contains new approaches for various genetic operations including crossover and selection. We also propose a health check operation that finds sick chromosomes of a population and probabilistically replaces them with healthy chromosomes found in the previous generations. The proposed approaches improve the chromosome quality within a population, which then contribute in achieving good clustering solution. We use fifteen datasets to compare our technique with five existing techniques in terms of two cluster evaluation criteria. The experimental results indicate a clear superiority of the proposed technique over the existing techniques."
Bag-of-steps: Predicting Lower-limb Fracture Rehabilitation Length,"Albert Pla, Beatriz López, Cristofor Nogueira, Natalia Mordvaniuk, Taco Blokhuis, Herman Holtslag","1 - University of Girona -Institut d'Informatica i Aplicacions
5 - University Medical Center Utrecht
7 - Girona Spain","This paper presents bag-of-steps, a new methodology to predict the rehabilitation length of a patient by monitoring the weight he is bearing in his injured leg and using a predictive model based on the bag-of-words technique. A force sensor is used to monitor and characterize the patient's gait, obtaining a set of step descriptors. These are later used to define a vocabulary of steps that can be used to describe rehabilitation sessions. Sessions are finally fed to a support vector machine classifier that performs the final rehabilitation estimation. * The work described in this paper was carried out as part of the MoSHCA project funded by the spanish INNPACTO program and the European ERDF funds (Ref. EUREKA ITEA 2 n o 11027 -IPT-2012-0943-300000 / Ref. DPI2013-47450-C2-1-R). Evalan has had no influence on the interpretation of data and the final conclusions drawn. The Sensistep device is available for the European market (www.sensistep.com)",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-39.pdf,2016,90.9090909090909,"Bag-of-steps: Predicting Lower-limb Fracture Rehabilitation Length This paper presents bag-of-steps, a new methodology to predict the rehabilitation length of a patient by monitoring the weight he is bearing in his injured leg and using a predictive model based on the bag-of-words technique. A force sensor is used to monitor and characterize the patient's gait, obtaining a set of step descriptors. These are later used to define a vocabulary of steps that can be used to describe rehabilitation sessions. Sessions are finally fed to a support vector machine classifier that performs the final rehabilitation estimation. * The work described in this paper was carried out as part of the MoSHCA project funded by the spanish INNPACTO program and the European ERDF funds (Ref. EUREKA ITEA 2 n o 11027 -IPT-2012-0943-300000 / Ref. DPI2013-47450-C2-1-R). Evalan has had no influence on the interpretation of data and the final conclusions drawn. The Sensistep device is available for the European market (www.sensistep.com)"
A State-Space Model on Interactive Dimensionality Reduction,"Ignacio Díaz, Abel Cuadrado, Michel Verleysen","1 - Electrical Engineering Dept Dept. 2 University of Oviedo Edif campus de Viesques s/n 33204 Gijón SPAIN
3 - Univ. Catholique de Louvain -Machine Learning Group ICTEAM ELEN -Place du Levant 1348 Louvain-la-Neuve Belgium","In this work, we present a conceptual approach to the convergence dynamics of interactive dimensionality reduction (iDR) algorithms from the perspective of a well stablished theoretical model, namely statespace theory. The expected benefits are twofold: 1) suggesting new ways to import well known ideas from the state-space theory that help in the characterization and development of iDR algorithms and 2) providing a conceptual model for user interaction in iDR algorithms, that can be easily adopted for future interactive machine learning (iML) tools. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO) and FEDER funds from the EU under grant DPI2015-69891-C2-2-R.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-41.pdf,2016,84.7457627118644,"A State-Space Model on Interactive Dimensionality Reduction In this work, we present a conceptual approach to the convergence dynamics of interactive dimensionality reduction (iDR) algorithms from the perspective of a well stablished theoretical model, namely statespace theory. The expected benefits are twofold: 1) suggesting new ways to import well known ideas from the state-space theory that help in the characterization and development of iDR algorithms and 2) providing a conceptual model for user interaction in iDR algorithms, that can be easily adopted for future interactive machine learning (iML) tools. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO) and FEDER funds from the EU under grant DPI2015-69891-C2-2-R."
Comparison of Four-and Six-Layered Configurations for Deep Network Pretraining,"Jan Hänninen, Tommi Kärkkäinen",1 - Department of Mathematical Information Technology University of Jyväskylä P.O. Box 35 40014 Finland,"Using simpler building blocks to initially construct a deep network, with their finetuning for the full architecture, is known to improve the deep learning process. However, in many cases the pretrained networks are obtained using different training algorithms than used in their final combination. Here we introduce and compare four possible architectures to pretrain a deep, feedforward network architecture, using exactly the same formulation throughout. Based on the analytical formulations and experimental results, one of the tested configurations is concluded as the recommended approach for the initial phase of deep learning.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-45.pdf,2016,95.54140127388536,"Comparison of Four-and Six-Layered Configurations for Deep Network Pretraining Using simpler building blocks to initially construct a deep network, with their finetuning for the full architecture, is known to improve the deep learning process. However, in many cases the pretrained networks are obtained using different training algorithms than used in their final combination. Here we introduce and compare four possible architectures to pretrain a deep, feedforward network architecture, using exactly the same formulation throughout. Based on the analytical formulations and experimental results, one of the tested configurations is concluded as the recommended approach for the initial phase of deep learning."
Tuning the Distribution Dependent Prior in the PAC-Bayes Framework based on Empirical Data,"Luca Oneto, Sandro Ridella, Davide Anguita","1 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy
2 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy","In this paper we further develop the idea that the PAC-Bayes prior can be defined based on the data-generating distribution. In particular, following Catoni [1], we refine some recent generalisation bounds on the risk of the Gibbs Classifier, when the prior is defined in terms of the data generating distribution, and the posterior is defined in terms of the observed one. Moreover we show that the prior and the posterior distributions can be tuned based on the observed samples without worsening the convergence rate of the bounds and with a marginal impact on their constants.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-46.pdf,2016,100.0,"Tuning the Distribution Dependent Prior in the PAC-Bayes Framework based on Empirical Data In this paper we further develop the idea that the PAC-Bayes prior can be defined based on the data-generating distribution. In particular, following Catoni [1], we refine some recent generalisation bounds on the risk of the Gibbs Classifier, when the prior is defined in terms of the data generating distribution, and the posterior is defined in terms of the observed one. Moreover we show that the prior and the posterior distributions can be tuned based on the observed samples without worsening the convergence rate of the bounds and with a marginal impact on their constants."
"Supervised quantum gate ""teaching"" for quantum hardware design","Leonardo Banchi, Nicola Pancotti, Sougato Bose","1 - Department of Physics and Astronomy University College London Gower Street WC1E 6BT London United Kingdom
2 - Max-Planck-Institut für Quantenoptik Hans-Kopfermann-Straße 1 85748 Garching Germany",We show how to train a quantum network of pairwise interacting qubits such that its evolution implements a target quantum algorithm into a given network subset. Our strategy is inspired by supervised learning and is designed to help the physical construction of a quantum computer which operates with minimal external classical control. * L.B. and S.B. acknowledge the financial support by the ERC under Starting Grant 308253 PACOMANEDIA.,Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-47.pdf,2016,100.0,"Supervised quantum gate ""teaching"" for quantum hardware design We show how to train a quantum network of pairwise interacting qubits such that its evolution implements a target quantum algorithm into a given network subset. Our strategy is inspired by supervised learning and is designed to help the physical construction of a quantum computer which operates with minimal external classical control. * L.B. and S.B. acknowledge the financial support by the ERC under Starting Grant 308253 PACOMANEDIA."
Random Forests Model Selection,"Ilenia Orlandi, Luca Oneto, Davide Anguita",1 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy,"Random Forests (RF) of tree classifiers are a popular ensemble method for classification. RF have shown to be effective in many different real world classification problems and nowadays are considered as one of the best learning algorithms in this context. In this paper we discuss the effect of the hyperparameters of the RF over the accuracy of the final model, with particular reference to different theoretically grounded weighing strategies of the tree in the forest. In this way we go against the common misconception which considers RF as an hyperparameter-free learning algorithm. Results on a series of benchmark datasets show that performing an accurate Model Selection procedure can greatly improve the accuracy of the final RF classifier.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-48.pdf,2016,100.0,"Random Forests Model Selection Random Forests (RF) of tree classifiers are a popular ensemble method for classification. RF have shown to be effective in many different real world classification problems and nowadays are considered as one of the best learning algorithms in this context. In this paper we discuss the effect of the hyperparameters of the RF over the accuracy of the final model, with particular reference to different theoretically grounded weighing strategies of the tree in the forest. In this way we go against the common misconception which considers RF as an hyperparameter-free learning algorithm. Results on a series of benchmark datasets show that performing an accurate Model Selection procedure can greatly improve the accuracy of the final RF classifier."
On the analysis of feature selection techniques in a conjunctival hyperemia grading framework,"L Brea, N Barreira, N Sánchez, A Mosquera, C García-Resúa, E Yebra-Pimentel","1 - Dept. Computer Science Univ. of A Coruna Spain
4 - Dept. Electronics and Comp. Science Univ. of Santiago de Compostela Spain
5 - Dept. Applied Physics Univ. of Santiago de Compostela Spain","Hyperemia is a parameter that describes the degree of redness in a tissue. When it affects the bulbar conjunctiva, it can serve as an early indicator for pathologies such as dry eye syndrome. Hyperemia is measured using scales, which are collections of images that show different severity levels. Features computed from the images can be used to develop an automatic grading system with the help of machine learning algorithms. In this work, we present a methodology that analyses the influence of each feature when determining the hyperemia level.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-49.pdf,2016,100.0,"On the analysis of feature selection techniques in a conjunctival hyperemia grading framework Hyperemia is a parameter that describes the degree of redness in a tissue. When it affects the bulbar conjunctiva, it can serve as an early indicator for pathologies such as dry eye syndrome. Hyperemia is measured using scales, which are collections of images that show different severity levels. Features computed from the images can be used to develop an automatic grading system with the help of machine learning algorithms. In this work, we present a methodology that analyses the influence of each feature when determining the hyperemia level."
Neuro-Percolation as a Superposition of Random-Walks,Gaetano Aiello,1 - Dipartimento di Fisica e Chimica Viale delle Scienze Universita' di Palermo Ed. 18 90128 Palermo Italy,"Axons of pioneers neurons are actively directed towards their targets by signaling molecules. The result is a highly stereotyped axonal trajectory. The tip of the axon appears to proceed erratically, which has favored models of axon guidance as random-walk processes. In reality, axon guidance is basically a deterministic process, although largely unknown. Random-walk models assume noise as a representation of what is actually unknown. Wadsworth's guidance gives an experimental account of the axonal bending as induced by addition/subtraction of specific guidance agents. The axonal trajectory, however, is not a simple random-walk but a series of Wiener-Lévy stochastic processes.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-5.pdf,2016,75.0,"Neuro-Percolation as a Superposition of Random-Walks Axons of pioneers neurons are actively directed towards their targets by signaling molecules. The result is a highly stereotyped axonal trajectory. The tip of the axon appears to proceed erratically, which has favored models of axon guidance as random-walk processes. In reality, axon guidance is basically a deterministic process, although largely unknown. Random-walk models assume noise as a representation of what is actually unknown. Wadsworth's guidance gives an experimental account of the axonal bending as induced by addition/subtraction of specific guidance agents. The axonal trajectory, however, is not a simple random-walk but a series of Wiener-Lévy stochastic processes."
Sparse Least Squares Support Vector Machines via Multiresponse Sparse Regression,"David Clifte, S Vieira, Ajalmar Rocha Neto, Antonio Wendell, O Rodrigues","1 - Department of Teleinformatics Av. Treze de Maio Federal Institute of Ceará (IFCE) 2081 Benfica, Fortaleza, Ceará Brazil","Least Square Support Vector Machines (LSSVMs) are an alternative to SVMs because the training process for LSSVMs is based on solving a linear equation system while the training process for SVMs relies on solving a quadratic programming optimization problem. Despite solving a linear system is easier than solving a quadratic programming optimization problem, the absence of sparsity in the Lagrange multiplier vector obtained after training a LSSVM model is an important drawback. To overcome this drawback, we present a new approach for sparse LSSVM called Optimally Pruned LSSVM (OP-LSSVM). Our proposal is based on a ranking method, named Multiresponse Sparse Regression (MRSR), which is used to sort the patterns in terms of relevance. After that, the leave-one-out (LOO) criterion is also used in order to select an appropriate number of support vectors. Our proposal was inspired by a recent methodology called OP-ELM, which prunes hidden neurons of Extreme Learning Machines. Therefore, in this paper, we put LSSVM and MRSR to work together in order to achieve sparse classifiers, as well as one can see that we achieved equivalent (or even superior) performance for real-world classification tasks.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-53.pdf,2016,100.0,"Sparse Least Squares Support Vector Machines via Multiresponse Sparse Regression Least Square Support Vector Machines (LSSVMs) are an alternative to SVMs because the training process for LSSVMs is based on solving a linear equation system while the training process for SVMs relies on solving a quadratic programming optimization problem. Despite solving a linear system is easier than solving a quadratic programming optimization problem, the absence of sparsity in the Lagrange multiplier vector obtained after training a LSSVM model is an important drawback. To overcome this drawback, we present a new approach for sparse LSSVM called Optimally Pruned LSSVM (OP-LSSVM). Our proposal is based on a ranking method, named Multiresponse Sparse Regression (MRSR), which is used to sort the patterns in terms of relevance. After that, the leave-one-out (LOO) criterion is also used in order to select an appropriate number of support vectors. Our proposal was inspired by a recent methodology called OP-ELM, which prunes hidden neurons of Extreme Learning Machines. Therefore, in this paper, we put LSSVM and MRSR to work together in order to achieve sparse classifiers, as well as one can see that we achieved equivalent (or even superior) performance for real-world classification tasks."
Learning Contextual Affordances with an Associative Neural Architecture,"Francisco Cruz, German Parisi, Stefan Wermter",1 - Department of Informatics University of Hamburg Vogt-Koelln-Strasse 30 22527 Hamburg Germany,"Affordances are an effective method to anticipate the effect of actions performed by an agent interacting with objects. In this work, we present a robotic cleaning task using contextual affordances, i.e. an extension of affordances which takes into account the current state. We implement an associative neural architecture for predicting the effect of performed actions with different objects to avoid failed states. Experimental results on a simulated robot environment show that our associative memory is able to learn in short time and predict future states with high accuracy.",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-54.pdf,2016,77.46478873239437,"Learning Contextual Affordances with an Associative Neural Architecture Affordances are an effective method to anticipate the effect of actions performed by an agent interacting with objects. In this work, we present a robotic cleaning task using contextual affordances, i.e. an extension of affordances which takes into account the current state. We implement an associative neural architecture for predicting the effect of performed actions with different objects to avoid failed states. Experimental results on a simulated robot environment show that our associative memory is able to learn in short time and predict future states with high accuracy."
Stochastic Gradient Estimate Variance in Contrastive Divergence and Persistent Contrastive Divergence,Mathias Berglund,1 - Department of Information and Computer Science Espoo Aalto University Finland,"Contrastive Divergence (CD) and Persistent Contrastive Divergence (PCD) are popular methods for training Restricted Boltzmann Machines. However, both methods use an approximate method for sampling from the model distribution. As a side effect, these approximations yield significantly different biases and variances for stochastic gradient estimates of individual data points. It is well known that CD yields a biased gradient estimate. In this paper we however show empirically that CD has a lower stochastic gradient estimate variance than unbiased sampling, while the mean of subsequent PCD estimates has a higher variance than independent sampling. The results give one explanation to the finding that CD can be used with smaller minibatches or higher learning rates than PCD. 1 Persistent Contrastive Divergence is also known as Stochastic Maximum Likelihood 2 The topic has been covered in e.g. [8], although for a Boltzmann machine with only one visible and hidden neuron. 3 There are however tricks to be able to increase the learning rate of PCD, see e.g.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-6.pdf,2016,74.25742574257426,"Stochastic Gradient Estimate Variance in Contrastive Divergence and Persistent Contrastive Divergence Contrastive Divergence (CD) and Persistent Contrastive Divergence (PCD) are popular methods for training Restricted Boltzmann Machines. However, both methods use an approximate method for sampling from the model distribution. As a side effect, these approximations yield significantly different biases and variances for stochastic gradient estimates of individual data points. It is well known that CD yields a biased gradient estimate. In this paper we however show empirically that CD has a lower stochastic gradient estimate variance than unbiased sampling, while the mean of subsequent PCD estimates has a higher variance than independent sampling. The results give one explanation to the finding that CD can be used with smaller minibatches or higher learning rates than PCD. 1 Persistent Contrastive Divergence is also known as Stochastic Maximum Likelihood 2 The topic has been covered in e.g. [8], although for a Boltzmann machine with only one visible and hidden neuron. 3 There are however tricks to be able to increase the learning rate of PCD, see e.g."
Multi-step strategy for mortality assessment in cardiovascular risk patients with imbalanced data,"Fernando Mateo, Emilio Soria-Olivas, Marcelino Martínez-Sober, María Téllez-Plaza, Juan Gómez-Sanchis, Josep Redón","1 - Instituto de Investigacion Sanitaria (INCLIVA) Avda. Menéndez Pelayo 4 46010 Valencia Spain
2 - University of Valencia -Department of Electronics Engineering Avda. Universidades s/n 46100 Burjassot Spain","The assessment of mortality in patients with cardiovascular disease (CVD) risk factors is typically a challenging task given the large amount of collected variables and the imbalance between classes. This is the case of the ESCARVAL-RISK dataset, a large cardiovascular followup record spanning 4 years. This study intends to give insight into: a) the performance of variable selection methods, b) the best class balancing method and c) choosing an adequate classifier to predict mortality. We conclude that combining ADASYN with SVM classifiers without and with AUC score-based feature selection, and RUSBoost combined with boosting tree ensembles are the most suitable methodologies among the tested.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-60.pdf,2016,100.0,"Multi-step strategy for mortality assessment in cardiovascular risk patients with imbalanced data The assessment of mortality in patients with cardiovascular disease (CVD) risk factors is typically a challenging task given the large amount of collected variables and the imbalance between classes. This is the case of the ESCARVAL-RISK dataset, a large cardiovascular followup record spanning 4 years. This study intends to give insight into: a) the performance of variable selection methods, b) the best class balancing method and c) choosing an adequate classifier to predict mortality. We conclude that combining ADASYN with SVM classifiers without and with AUC score-based feature selection, and RUSBoost combined with boosting tree ensembles are the most suitable methodologies among the tested."
Bayesian Semi Non-negative Matrix Factorisation,"Albert Vilamala, Alfredo Vellido, Lluís Belanche",1 - Universitat Politècnica de Catalunya -Computer Science Department Omega Building Jordi Girona 1-3 08034 Barcelona Spain,"Non-negative Matrix Factorisation (NMF) has become a standard method for source identification when data, sources and mixing coefficients are constrained to be positive-valued. The method has recently been extended to allow for negative-valued data and sources in the form of Semi-and Convex-NMF. In this paper, we re-elaborate Semi-NMF within a full Bayesian framework. This provides solid foundations for parameter estimation and, importantly, a principled method to address the problem of choosing the most adequate number of sources to describe the observed data. The proposed Bayesian Semi-NMF is preliminarily evaluated here in a real neuro-oncology problem.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-62.pdf,2016,91.48936170212765,"Bayesian Semi Non-negative Matrix Factorisation Non-negative Matrix Factorisation (NMF) has become a standard method for source identification when data, sources and mixing coefficients are constrained to be positive-valued. The method has recently been extended to allow for negative-valued data and sources in the form of Semi-and Convex-NMF. In this paper, we re-elaborate Semi-NMF within a full Bayesian framework. This provides solid foundations for parameter estimation and, importantly, a principled method to address the problem of choosing the most adequate number of sources to describe the observed data. The proposed Bayesian Semi-NMF is preliminarily evaluated here in a real neuro-oncology problem."
The WiSARD Classifier,"Massimo De Gregorio, Maurizio Giordano","1 - Istituto di Scienze Applicate e Sistemi Intelligenti ""E","WiSARD is a weightless neural model which essentially uses look up tables to store the function computed by each neuron rather than storing it in weights of neuron connections. Although WiSARD was originally conceived as a pattern recognition device mainly focusing on image processing, in this work we show how it is possible to build a multi-class classifier method in Machine Learning (ML) domain based on WiSARD that shows equivalent performances to ML state-of-the-art methods. 
 WiSARD in numeric and symbolic domain WiSARD (Wilkes, Stonham and Aleksander Recognition Device) was the first artificial neural network machine to be patented and produced commercially  [2] . WiSARD is composed of a set of classifiers, called discriminators, each",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-63.pdf,2016,100.0,"The WiSARD Classifier WiSARD is a weightless neural model which essentially uses look up tables to store the function computed by each neuron rather than storing it in weights of neuron connections. Although WiSARD was originally conceived as a pattern recognition device mainly focusing on image processing, in this work we show how it is possible to build a multi-class classifier method in Machine Learning (ML) domain based on WiSARD that shows equivalent performances to ML state-of-the-art methods. 
 WiSARD in numeric and symbolic domain WiSARD (Wilkes, Stonham and Aleksander Recognition Device) was the first artificial neural network machine to be patented and produced commercially  [2] . WiSARD is composed of a set of classifiers, called discriminators, each"
A fast learning algorithm for high dimensional problems: an application to microarrays,"Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas, Beatriz Pérez-Sánchez, David Martínez-Rego, Diego Rego-Fernández","1 - Department of Computer Science University of A Coruña
2 - Faculty of Informatics. Campus de Elviña s/n. -A Coruña Spain","In this work, a new learning method for one-layer neural network based on a singular value decomposition is presented. The optimal parameters of the model can be obtained by means of a system of linear equations whose complexity depends on the number of samples. This approach provides a fast learning algorithm for huge dimensional problems where the number of inputs is higher than the number of data points. These kinds of situations appear, for example, in DNA microarrays scenarios. An experimental study over eleven microarray datasets shows that the proposed method is able to outperform other representative classifiers, in terms of CPU time, without significant loss of accuracy.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-67.pdf,2016,100.0,"A fast learning algorithm for high dimensional problems: an application to microarrays In this work, a new learning method for one-layer neural network based on a singular value decomposition is presented. The optimal parameters of the model can be obtained by means of a system of linear equations whose complexity depends on the number of samples. This approach provides a fast learning algorithm for huge dimensional problems where the number of inputs is higher than the number of data points. These kinds of situations appear, for example, in DNA microarrays scenarios. An experimental study over eleven microarray datasets shows that the proposed method is able to outperform other representative classifiers, in terms of CPU time, without significant loss of accuracy."
Enhanced learning for agents in quantum-accessible environments,"Vedran Dunjko, Jacob Taylor, Hans Briegel","1 - Institut für Theoretische Physik Universität Innsbruck Technikerstraße 25 A-6020 Innsbruck Austria
2 - Joint Center for Quantum Information and Computer Science University of Maryland 20742 College Park MD USA
3 - Joint Quantum Institute National Institute of Standards and Technology Gaithersburg 20899 MD USA","In this paper we provide a broad framework for describing learning agents in general quantum environments. We analyze the types of classically specified environments which allow for quantum enhancements in learning, by contrasting environments to quantum oracles. We show that whether or not quantum improvements are at all possible depends on the internal structure of the quantum environment. If the environments have an appropriate structure, we show that near-generic improvements in learning times are possible in a broad range of scenarios.",Physics and Machine Learning: Emerging Paradigms,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-7.pdf,2016,100.0,"Enhanced learning for agents in quantum-accessible environments In this paper we provide a broad framework for describing learning agents in general quantum environments. We analyze the types of classically specified environments which allow for quantum enhancements in learning, by contrasting environments to quantum oracles. We show that whether or not quantum improvements are at all possible depends on the internal structure of the quantum environment. If the environments have an appropriate structure, we show that near-generic improvements in learning times are possible in a broad range of scenarios."
Visualizing Stacked Autoencoder Language Learning,"Trevor Barron, Matthew Whitehead",1 - Department of Mathematics and Computer Science Colorado College 14 E. Cache La Poudre St 80903 Colorado Springs CO USA,"Visualizing the features of unsupervised deep networks is an important part of understanding what a network has learned. In this paper, we present a method for visualizing a deep autoencoder's hidden layers when trained on natural language data. Our method provides researchers insight into the semantic language features the network has extracted from the dataset. It can also show a big picture view of what a network has learned and how the various features the network has extracted relate to one another in semantic hierarchies. We hope that these visualizations will aid human understanding of deep networks and can help guide future experiments.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-70.pdf,2016,67.34693877551021,"Visualizing Stacked Autoencoder Language Learning Visualizing the features of unsupervised deep networks is an important part of understanding what a network has learned. In this paper, we present a method for visualizing a deep autoencoder's hidden layers when trained on natural language data. Our method provides researchers insight into the semantic language features the network has extracted from the dataset. It can also show a big picture view of what a network has learned and how the various features the network has extracted relate to one another in semantic hierarchies. We hope that these visualizations will aid human understanding of deep networks and can help guide future experiments."
Choosing the Best Algorithm for an Incremental On-line Learning Task,"Viktor Losing, Barbara Hammer, Heiko Wersing","1 - Bielefeld University Universitaetsstr. 25 33615 Bielefeld Germany
2 - HONDA Research Institute Europe GmbH Carl-Legien-Str. 30 63065 Offenbach Germany","Recently, incremental and on-line learning gained more attention especially in the context of big data and learning from data streams, conflicting with the traditional assumption of complete data availability. Even though a variety of different methods are available, it often remains unclear which of them is suitable for a specific task and how they perform in comparison to each other. We analyze the key properties of seven incremental methods representing different algorithm classes. Our extensive evaluation on data sets with different characteristics gives an overview of the performance with respect to accuracy as well as model complexity, facilitating the choice of the best method for a given application.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-71.pdf,2016,70.58823529411764,"Choosing the Best Algorithm for an Incremental On-line Learning Task Recently, incremental and on-line learning gained more attention especially in the context of big data and learning from data streams, conflicting with the traditional assumption of complete data availability. Even though a variety of different methods are available, it often remains unclear which of them is suitable for a specific task and how they perform in comparison to each other. We analyze the key properties of seven incremental methods representing different algorithm classes. Our extensive evaluation on data sets with different characteristics gives an overview of the performance with respect to accuracy as well as model complexity, facilitating the choice of the best method for a given application."
Fast in-memory spectral clustering using a fixed-size approach,"R Langone, R Mall, V Jumutc, J Suykens","1 - KU Leuven ESAT-STADIUS Kasteelpark Arenberg 10 B-3001 Leuven Belgium
2 - Qatar Computing Research Institute (QCRI) Doha Qatar","Spectral clustering represents a successful approach to data clustering. Despite its high performance in solving complex tasks, it is often disregarded in favor of the less accurate k-means algorithm because of its computational inefficiency. In this article we present a fast in-memory spectral clustering algorithm, which can handle millions of datapoints at a desktop PC scale. The proposed technique relies on a kernel-based formulation of the spectral clustering problem, also known as kernel spectral clustering. In particular, we use a fixed-size approach based on an approximation of the feature map via the Nyström method to solve the primal optimization problem. We experimented on several small and large scale real-world datasets to show the computational efficiency and clustering quality of the proposed algorithm.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-72.pdf,2016,100.0,"Fast in-memory spectral clustering using a fixed-size approach Spectral clustering represents a successful approach to data clustering. Despite its high performance in solving complex tasks, it is often disregarded in favor of the less accurate k-means algorithm because of its computational inefficiency. In this article we present a fast in-memory spectral clustering algorithm, which can handle millions of datapoints at a desktop PC scale. The proposed technique relies on a kernel-based formulation of the spectral clustering problem, also known as kernel spectral clustering. In particular, we use a fixed-size approach based on an approximation of the feature map via the Nyström method to solve the primal optimization problem. We experimented on several small and large scale real-world datasets to show the computational efficiency and clustering quality of the proposed algorithm."
Augmenting a convolutional neural network with local histograms -A case study in crop classification from high-resolution UAV imagery,"Julien Rebetez, Héctor Satizábal, Matteo Mota, Dorothea Noll, Lucie Büchi, Marina Wendling, Bertrand Cannelle, Andres Perez-Uribe, Stéphane Burgos","1 - University of Applied Sciences Western Switzerland
7 - Bern University of Applied Sciences School of Agricultural, Forest and Food Sciences HAFL -Zollikofen
8 - Institute for Plant Production Sciences Nyon Switzerland",The advent of affordable drones capable of taking high resolution images of agricultural fields creates new challenges and opportunities in aerial scene understanding. This paper tackles the problem of recognizing crop types from aerial imagery and proposes a new hybrid neural network architecture which combines histograms and convolutional units. We evaluate the performance of the hybrid model on a 23-class classification task and compare it to convolutional and histogram-based models. The result is an improvement of the classification performance.,Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-74.pdf,2016,99.625468164794,Augmenting a convolutional neural network with local histograms -A case study in crop classification from high-resolution UAV imagery The advent of affordable drones capable of taking high resolution images of agricultural fields creates new challenges and opportunities in aerial scene understanding. This paper tackles the problem of recognizing crop types from aerial imagery and proposes a new hybrid neural network architecture which combines histograms and convolutional units. We evaluate the performance of the hybrid model on a 23-class classification task and compare it to convolutional and histogram-based models. The result is an improvement of the classification performance.
Human Detection and Classification of Landing Sites for Search and Rescue Drones,"Felipe Martins, Marc De Groot, Xeryus Stokkel, Marco Wiering","1 - Science and Tech. of Espirito Santo -Serra Federal Institute of Educ Campus Rod. ES-010, km 6, 5 -Manguinhos 29173-087 Serra ES Brazil
2 - University of Groningen -Artificial Intelligence and Cognitive Engineering PO Box 407 9700 AK Groningen Netherlands","Search and rescue is often time and labour intensive. We present a system to be used in drones to make search and rescue operations more effective. The system uses a drone downward facing camera to detect people and to evaluate potential sites as being safe or not for the drone to land. Histogram of Oriented Gradients (HOG) features are extracted and a Support Vector Machine (SVM) is used as classifier. Our results show good performance on classifying frames as containing people (Sensitivity > 78%, Specificity > 83%), and distinguishing between safe and dangerous landing sites (Sensitivity > 87%, Specificity > 98%).",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-75.pdf,2016,66.25,"Human Detection and Classification of Landing Sites for Search and Rescue Drones Search and rescue is often time and labour intensive. We present a system to be used in drones to make search and rescue operations more effective. The system uses a drone downward facing camera to detect people and to evaluate potential sites as being safe or not for the drone to land. Histogram of Oriented Gradients (HOG) features are extracted and a Support Vector Machine (SVM) is used as classifier. Our results show good performance on classifying frames as containing people (Sensitivity > 78%, Specificity > 83%), and distinguishing between safe and dangerous landing sites (Sensitivity > 87%, Specificity > 98%)."
Fast Support Vector Clustering,"Tung Pham, Trung Le, Thai Le, Dat Tran","1 - Faculty of Information Technology VNUHCM -University of Science Vietnam
2 - Faculty of Information Technology HCMc University of Pedagogy Vietnam
4 - Faculty of Education Science Technology and Maths University of Canberra Australia","Support-based clustering has recently drawn plenty of attention because of its applications in solving the difficult and diverse clustering or outlier detection problem. Support-based clustering method undergoes two phases: finding the domain of novelty and doing clustering assignment. To find the domain of novelty, the training time given by the current solvers is typically quadratic in the training size. It precludes the usage of support-based clustering method for the large-scale datasets. In this paper, we propose applying Stochastic Gradient Descent framework to the first phase of support-based clustering for finding the domain of novelty in form of a half-space and a new strategy to do the clustering assignment. We validate our proposed method on the well-known datasets for clustering to show that the proposed method offers a comparable clustering quality to Support Vector Clustering while being faster than this method.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-77.pdf,2016,100.0,"Fast Support Vector Clustering Support-based clustering has recently drawn plenty of attention because of its applications in solving the difficult and diverse clustering or outlier detection problem. Support-based clustering method undergoes two phases: finding the domain of novelty and doing clustering assignment. To find the domain of novelty, the training time given by the current solvers is typically quadratic in the training size. It precludes the usage of support-based clustering method for the large-scale datasets. In this paper, we propose applying Stochastic Gradient Descent framework to the first phase of support-based clustering for finding the domain of novelty in form of a half-space and a new strategy to do the clustering assignment. We validate our proposed method on the well-known datasets for clustering to show that the proposed method offers a comparable clustering quality to Support Vector Clustering while being faster than this method."
Spectral clustering and discriminant analysis for unsupervised feature selection,"Xiucai Ye, Kaiyang Ji, Tetsuya Sakurai",1 - Department of Computer Science University of Tsukuba Tsukuba Japan,"In this paper, we propose a novel method for unsupervised feature selection, which utilizes spectral clustering and discriminant analysis to learn the cluster labels of data. During the learning of cluster labels, feature selection is performed simultaneously. By imposing row sparsity on the transformation matrix, the proposed method optimizes for selecting the most discriminative features which better capture both the global and local structure of data. We develop an iterative algorithm to effectively solve the optimization problem in our method. Experimental results on different real-world data demonstrate the effectiveness of the proposed method.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-78.pdf,2016,100.0,"Spectral clustering and discriminant analysis for unsupervised feature selection In this paper, we propose a novel method for unsupervised feature selection, which utilizes spectral clustering and discriminant analysis to learn the cluster labels of data. During the learning of cluster labels, feature selection is performed simultaneously. By imposing row sparsity on the transformation matrix, the proposed method optimizes for selecting the most discriminative features which better capture both the global and local structure of data. We develop an iterative algorithm to effectively solve the optimization problem in our method. Experimental results on different real-world data demonstrate the effectiveness of the proposed method."
Localized discriminative Gaussian process latent variable model for text-dependent speaker verification,"Nooshin Maghsoodi, Hossein Sameti, Hossein Zeinali","1 - Dept of Computer Engineering Tehran Sharif University of Technology Iran
4 - Dept of Information Technology Brno Brno University of Technology Czech Republic","The duration of utterances is one of the effective factors on the performance of speaker verification systems. Text dependent speaker verification suffers from both short duration and unmatched content between enrollment and test segments. In this paper, we use Discriminative Gaussian Process Latent Variable Model (DGPLVM) to deal with the uncertainty caused by short duration. This is the first attempt to utilize Gaussian Process for speaker verification. Also, to manage the unmatched content between enrollment and test segments we proposed the localized-DGPLVM that trains DGPLVM for each phrase in dataset. Experiments show the relative improvement of 27.4% in EER on RSR2015.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-79.pdf,2016,100.0,"Localized discriminative Gaussian process latent variable model for text-dependent speaker verification The duration of utterances is one of the effective factors on the performance of speaker verification systems. Text dependent speaker verification suffers from both short duration and unmatched content between enrollment and test segments. In this paper, we use Discriminative Gaussian Process Latent Variable Model (DGPLVM) to deal with the uncertainty caused by short duration. This is the first attempt to utilize Gaussian Process for speaker verification. Also, to manage the unmatched content between enrollment and test segments we proposed the localized-DGPLVM that trains DGPLVM for each phrase in dataset. Experiments show the relative improvement of 27.4% in EER on RSR2015."
Stacked Denoising Autoencoders for the Automatic Recognition of Microglial Cells' State,"Sofia Fernandes, Ricardo Sousa, Renato Socodato, Luís Silva","1 - Instituto de Investigação e Inovação em Saúde (i3S) and Instituto de Engenharia Biomédica (INEB)
3 - Instituto de Investigação e Inovação em Saúde (i3S) and Instituto de Biologia Molecular e Celular (IBMC) Universidade do Porto Porto Portugal","We present the first study for the automatic recognition of microglial cells' state using stacked denoising autoencoders. Microglia has a pivotal role as sentinel of neuronal diseases where its state (resting, transition or active) is indicative of what is occurring in the Central Nervous System. In this work we delve on different strategies to best learn a stacked denoising autoencoder for that purpose and show that the transition state is the most hard to recognize while an accuracy of approximately 64% is obtained with a dataset of 45 images.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-8.pdf,2016,73.5632183908046,"Stacked Denoising Autoencoders for the Automatic Recognition of Microglial Cells' State We present the first study for the automatic recognition of microglial cells' state using stacked denoising autoencoders. Microglia has a pivotal role as sentinel of neuronal diseases where its state (resting, transition or active) is indicative of what is occurring in the Central Nervous System. In this work we delve on different strategies to best learn a stacked denoising autoencoder for that purpose and show that the transition state is the most hard to recognize while an accuracy of approximately 64% is obtained with a dataset of 45 images."
"An Immune-Inspired, Dependence-Based Approach to Blind Inversion of Wiener Systems","Stephanie Milena Alvarez Fernandez, Romis Attux, Denis Fantinato, Jugurta Montalvão, Daniel Silva","1 - University of Brasilia -Dept. of Electrical Engineering
2 - School of Electrical and Computer Engineering University of Campinas
4 - Federal University of Sergipe -Dept. of Electrical Engineering","In this work, we present a comparative analysis of two methods -based on the autocorrelation and autocorrentropy functions -for representing the time structure of a given signal in the context of the unsupervised inversion of Wiener systems by Hammerstein systems. Linear stages with and without feedback are considered and an immune-inspired algorithm is used to allow parameter optimization without the need for manipulating the cost function, and also with a significant probability of global convergence. The results indicate that both functions provide effective means for system inversion and also illustrate the effect of linear feedback on the overall system performance.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-81.pdf,2016,100.0,"An Immune-Inspired, Dependence-Based Approach to Blind Inversion of Wiener Systems In this work, we present a comparative analysis of two methods -based on the autocorrelation and autocorrentropy functions -for representing the time structure of a given signal in the context of the unsupervised inversion of Wiener systems by Hammerstein systems. Linear stages with and without feedback are considered and an immune-inspired algorithm is used to allow parameter optimization without the need for manipulating the cost function, and also with a significant probability of global convergence. The results indicate that both functions provide effective means for system inversion and also illustrate the effect of linear feedback on the overall system performance."
A machine learning pipeline for supporting differentiation of glioblastomas from single brain metastases,"Victor Mocioiu, Nuno Pedrosa De Barros, Sandra Ortega-Martorell, Johannes Slotboom, Urspeter Knecht, Carles Arús, Alfredo Vellido, Margarida Julià-Sapé","1 - Universitat Autònoma de Barcelona-Departament de Bioquímica i Biologia Molecular Cerdanyola del Vallès 08193 Barcelona Spain
2 - Centro de Investigación Biomédica en Red en Bioingeniería Biomateriales y Nanomedicina CIBER-BBN Cerdanyola del Vallès Barcelona Spain
3 - University Hospital Bern -SCAN Freiburgstrasse 4 3010 Bern Switzerland
4 - School of Computing and Mathematical Sciences Liverpool John Moores University Liverpool UK
11 - Departament de Ciències de la Computació Universitat Politècnica de Catalunya Campus Nord 08034 Edifici Omega, Barcelona Spain","Machine learning has provided, over the last decades, tools for knowledge extraction in complex medical domains. Most of these tools, though, are ad hoc solutions and lack the systematic approach that would be required to become mainstream in medical practice. In this brief paper, we define a machine learning-based analysis pipeline for helping in a difficult problem in the field of neuro-oncology, namely the discrimination of brain glioblastomas from single brain metastases. This pipeline involves source extraction using k-Meansinitialized Convex Non-negative Matrix Factorization and a collection of classifiers, including Logistic Regression, Linear Discriminant Analysis, AdaBoost, and Random Forests.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-82.pdf,2016,100.0,"A machine learning pipeline for supporting differentiation of glioblastomas from single brain metastases Machine learning has provided, over the last decades, tools for knowledge extraction in complex medical domains. Most of these tools, though, are ad hoc solutions and lack the systematic approach that would be required to become mainstream in medical practice. In this brief paper, we define a machine learning-based analysis pipeline for helping in a difficult problem in the field of neuro-oncology, namely the discrimination of brain glioblastomas from single brain metastases. This pipeline involves source extraction using k-Meansinitialized Convex Non-negative Matrix Factorization and a collection of classifiers, including Logistic Regression, Linear Discriminant Analysis, AdaBoost, and Random Forests."
Parallelized Unsupervised Feature Selection for Large-Scale Network Traffic Analysis,"Bruno Ordozgoiti, Sandra Canaval, Alberto Mozo",1 - Departamento de Sistemas Informáticos Universidad Politécnica de Madrid,"In certain domains, where model interpretability is highly valued, feature selection is often the only possible option for dimensionality reduction. However, two key problems arise. First, the size of data sets today makes it unfeasible to run centralized feature selection algorithms in reasonable amounts of time. Second, the impossibility of labeling data sets rules out supervised techniques. We propose an unsupervised feature selection algorithm based on a new formulation of the leverage scores. We derive an efficient parallelized approach over the Resilient Distributed Datasets abstraction, making it applicable to the enormous data sets often present in network traffic analysis. * The research leading to these results has received funding from the European Union under the FP7 grant agreement n. 619633 ( project ONTIC) and H2020 grant agreement n. 671625 (project CogNet)",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-84.pdf,2016,70.23809523809523,"Parallelized Unsupervised Feature Selection for Large-Scale Network Traffic Analysis In certain domains, where model interpretability is highly valued, feature selection is often the only possible option for dimensionality reduction. However, two key problems arise. First, the size of data sets today makes it unfeasible to run centralized feature selection algorithms in reasonable amounts of time. Second, the impossibility of labeling data sets rules out supervised techniques. We propose an unsupervised feature selection algorithm based on a new formulation of the leverage scores. We derive an efficient parallelized approach over the Resilient Distributed Datasets abstraction, making it applicable to the enormous data sets often present in network traffic analysis. * The research leading to these results has received funding from the European Union under the FP7 grant agreement n. 619633 ( project ONTIC) and H2020 grant agreement n. 671625 (project CogNet)"
PSCEG: An unbiased Parallel Subspace Clustering algorithm using Exact Grids,"Bo Zhu, Bruno Ordozgoiti, Alberto Mozo",1 - Departamento de Sistemas Informáticos Universidad Politécnica de Madrid,"The quality of grid-based subspace clustering is highly dependent on the grid size and the positions of dense units, and many existing methods use sensitive global density thresholds that are difficult to set a priori. We propose PSCEG, a new approach that generates an exact grid without the need to specify its size based on the distribution of each dimension. In addition, we define an adaptive density estimator that avoids dimensionality bias. A parallel implementation of our algorithm using Resilient Distributed Datasets achieves a significant speedup w.r.t. the number of cores in high dimensional scenarios. Experimental results on synthetic and real datasets show PSCEG outperforms existing alternatives. * The research leading to these results has received funding from the European Union under the FP7 grant agreement n. 619633 (project ONTIC) and H2020 grant agreement n. 671625 (project CogNet)",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-85.pdf,2016,69.33333333333334,"PSCEG: An unbiased Parallel Subspace Clustering algorithm using Exact Grids The quality of grid-based subspace clustering is highly dependent on the grid size and the positions of dense units, and many existing methods use sensitive global density thresholds that are difficult to set a priori. We propose PSCEG, a new approach that generates an exact grid without the need to specify its size based on the distribution of each dimension. In addition, we define an adaptive density estimator that avoids dimensionality bias. A parallel implementation of our algorithm using Resilient Distributed Datasets achieves a significant speedup w.r.t. the number of cores in high dimensional scenarios. Experimental results on synthetic and real datasets show PSCEG outperforms existing alternatives. * The research leading to these results has received funding from the European Union under the FP7 grant agreement n. 619633 (project ONTIC) and H2020 grant agreement n. 671625 (project CogNet)"
Deep Multi-Task Learning with evolving weights,"Soufiane Belharbi, Romain Hérault, Clément Chatelain, Sébastien Adam","1 - INSA de Rouen -LITIS EA 4108, 76800 Saint Étienne du Rouvray France
4 - Université de Rouen UFR des Sciences -LITIS EA 4108, 76800 Saint Étienne du Rouvray France",Pre-training of deep neural networks has been abandoned in the last few years. The main reason is the difficulty to control the overfitting and tune the consequential raised number of hyper-parameters. In this paper we use a multi-task learning framework that gathers weighted supervised and unsupervised tasks. We propose to evolve the weights along the learning epochs in order to avoid the break in the sequential transfer learning used in the pre-training scheme. This framework allows the use of unlabeled data. Extensive experiments on MNIST showed interesting results.,"Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-87.pdf,2016,73.91304347826086,Deep Multi-Task Learning with evolving weights Pre-training of deep neural networks has been abandoned in the last few years. The main reason is the difficulty to control the overfitting and tune the consequential raised number of hyper-parameters. In this paper we use a multi-task learning framework that gathers weighted supervised and unsupervised tasks. We propose to evolve the weights along the learning epochs in order to avoid the break in the sequential transfer learning used in the pre-training scheme. This framework allows the use of unlabeled data. Extensive experiments on MNIST showed interesting results.
Distributed learning algorithm for feedforward neural networks,"Oscar Fontenla-Romero, Beatriz Pérez-Sánchez, Bertha Guijarro-Berdiñas, Diego Rego-Fernández",1 - Department of Computer Science University of A Coruña Spain,"With the appearance of huge data sets new challenges have risen regarding the scalability and efficiency of Machine Learning algorithms, and both distributed computing and randomized algorithms have become effective ways to handle them. Taking advantage of these two approaches, a distributed learning algorithm for two-layer neural networks is proposed. Results demonstrate a similar accuracy when compared to an equivalent non-distributed approach whilst providing some advantages that make it especially well-suited for Big Data sets: over 50% savings in computational time; low communication and storage cost; no hyperparameters to be tuned; it allows online learning and it is privacy-preserving.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-9.pdf,2016,100.0,"Distributed learning algorithm for feedforward neural networks With the appearance of huge data sets new challenges have risen regarding the scalability and efficiency of Machine Learning algorithms, and both distributed computing and randomized algorithms have become effective ways to handle them. Taking advantage of these two approaches, a distributed learning algorithm for two-layer neural networks is proposed. Results demonstrate a similar accuracy when compared to an equivalent non-distributed approach whilst providing some advantages that make it especially well-suited for Big Data sets: over 50% savings in computational time; low communication and storage cost; no hyperparameters to be tuned; it allows online learning and it is privacy-preserving."
"Watch, Ask, Learn, and Improve: a lifelong learning cycle for visual recognition","Christoph Käding, Erik Rodner, Alexander Freytag, Joachim Denzler",1 - Computer Vision Group Friedrich Schiller University Jena Germany,"We present WALI, a prototypical system that learns object categories over time by continuously watching online videos. WALI actively asks questions to a human annotator about the visual content of observed video frames. Thereby, WALI is able to receive information about new categories and to simultaneously improve its generalization abilities. The functionality of WALI is driven by scalable active learning, efficient incremental learning, as well as state-of-the-art visual descriptors. In our experiments, we show qualitative and quantitative statistics about WALI's learning process. WALI runs continuously and regularly asks questions.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-91.pdf,2016,100.0,"Watch, Ask, Learn, and Improve: a lifelong learning cycle for visual recognition We present WALI, a prototypical system that learns object categories over time by continuously watching online videos. WALI actively asks questions to a human annotator about the visual content of observed video frames. Thereby, WALI is able to receive information about new categories and to simultaneously improve its generalization abilities. The functionality of WALI is driven by scalable active learning, efficient incremental learning, as well as state-of-the-art visual descriptors. In our experiments, we show qualitative and quantitative statistics about WALI's learning process. WALI runs continuously and regularly asks questions."
Initialization of Big Data Clustering using Distributionally Balanced Folding,"Joonas Hämäläinen, Tommi Kärkkäinen",1 - Department of Mathematical Information Technology University of Jyväskylä P.O. Box 35 40014 Finland,"Use of distributionally balanced folding to speed up the initialization phase of K-means++ clustering method, targeting for big data applications, is proposed and tested. The approach is first described and then experimented, by focusing on the effects of the sampling method when the number of folds created is varied. In the tests, quality of the final clustering results were assessed and scalability of a distributed implementation was demonstrated. The experiments support the viability of the proposed approach.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-93.pdf,2016,72.72727272727273,"Initialization of Big Data Clustering using Distributionally Balanced Folding Use of distributionally balanced folding to speed up the initialization phase of K-means++ clustering method, targeting for big data applications, is proposed and tested. The approach is first described and then experimented, by focusing on the effects of the sampling method when the number of folds created is varied. In the tests, quality of the final clustering results were assessed and scalability of a distributed implementation was demonstrated. The experiments support the viability of the proposed approach."
Neural Fitted Actor-Critic,"Matthieu Zimmer, Boniface Yann, Alain Dutech","1 - UMR 7503 University of Lorraine LORIA F-54000 Nancy France (
3 - UMR 7503 INRIA LORIA F-54000 Nancy France","A novel reinforcement learning algorithm that deals with both continuous state and action spaces is proposed. Domain knowledge requirements are kept minimal by using non-linear estimators and since the algorithm does not need prior trajectories or known goal states. The new actor-critic algorithm is on-policy, offline and model-free. It considers discrete time, stationary policies, and maximizes the discounted sum of rewards. Experimental results on two common environments, showing the good performance of the proposed algorithm, are presented. * The data has been numerically analyzed with the free software package GNU Octave  [15] . Experiments presented in this paper were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by Inria and including CNRS, RENATER and several Universities as well as other organizations (see https://www.grid5000.fr).",Robotics and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-94.pdf,2016,61.53846153846154,"Neural Fitted Actor-Critic A novel reinforcement learning algorithm that deals with both continuous state and action spaces is proposed. Domain knowledge requirements are kept minimal by using non-linear estimators and since the algorithm does not need prior trajectories or known goal states. The new actor-critic algorithm is on-policy, offline and model-free. It considers discrete time, stationary policies, and maximizes the discounted sum of rewards. Experimental results on two common environments, showing the good performance of the proposed algorithm, are presented. * The data has been numerically analyzed with the free software package GNU Octave  [15] . Experiments presented in this paper were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by Inria and including CNRS, RENATER and several Universities as well as other organizations (see https://www.grid5000.fr)."
Differentiable piecewise-Bézier interpolation on Riemannian manifolds,"P.-A Absil, Pierre-Yves Gousenbourger, Paul Striewski, Benedikt Wirth","1 - Université catholique de Louvain -ICTEAM Institute B-1348 Louvain-la-Neuve Belgium
3 - Institute for Numerical and Applied Mathematics University of Münster Einsteinstraße 62 D-48149 Münster Germany","We propose a generalization of classical Euclidean piecewise-Bézier surfaces to manifolds, and we use this generalization to compute a C 1 -surface interpolating a given set of manifold-valued data points associated to a regular 2D grid. We then propose an efficient algorithm to compute the control points defining the surface based on the Euclidean concept of natural C 2 -splines and show examples on different manifolds. Fig. 1: C 1 -Bézier spline surface on the Riemannian space of shells interpolating the red shapes. The Bézier surface (gray shapes) is driven by the control points (green).",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-96.pdf,2016,100.0,"Differentiable piecewise-Bézier interpolation on Riemannian manifolds We propose a generalization of classical Euclidean piecewise-Bézier surfaces to manifolds, and we use this generalization to compute a C 1 -surface interpolating a given set of manifold-valued data points associated to a regular 2D grid. We then propose an efficient algorithm to compute the control points defining the surface based on the Euclidean concept of natural C 2 -splines and show examples on different manifolds. Fig. 1: C 1 -Bézier spline surface on the Riemannian space of shells interpolating the red shapes. The Bézier surface (gray shapes) is driven by the control points (green)."
Memory management for data streams subject to concept drift,"Pierre-Xavier Loeffel, Christophe Marsala, Marcin Detyniecki","1 - Sorbonne Universités UPMC Univ Paris 06 -CNRS 7606 4 place Jussieu LIP6 UMR, 75005 Paris France
3 - Polish Academy of Sciences -IBS PAN Warsaw Poland","Learning on data streams subject to concept drifts is a challenging task. A successful algorithm must keep memory consumption constant regardless of the amount of data processed, and at the same time, retain good adaptation and prediction capabilities by effectively selecting which observations should be stored into memory. We claim that, instead of using a temporal window to discard observations with a time stamp criterion, it is better to retain observations that minimize the change in outputted prediction and rule learned with the full memory case. Experimental results for the Droplets algorithm, on 6 artificial and semi-artificial datasets reproducing various types of drifts back this claim.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-97.pdf,2016,100.0,"Memory management for data streams subject to concept drift Learning on data streams subject to concept drifts is a challenging task. A successful algorithm must keep memory consumption constant regardless of the amount of data processed, and at the same time, retain good adaptation and prediction capabilities by effectively selecting which observations should be stored into memory. We claim that, instead of using a temporal window to discard observations with a time stamp criterion, it is better to retain observations that minimize the change in outputted prediction and rule learned with the full memory case. Experimental results for the Droplets algorithm, on 6 artificial and semi-artificial datasets reproducing various types of drifts back this claim."
Deep Neural Network Analysis of Go Games: Which Stones Motivate a Move?,"Thomas Burwick, Luke Ewig",1 - Frankfurt Institute for Advanced Studies Goethe University Frankfurt Ruth Moufang-Str. 1 60438 Frankfurt am Main Germany,"Recently, deep learning was used to construct deep convolution network models for move prediction in Go. Here, we develop methods to analyze the inner workings of the resulting deep architectures. Our example network is learned and tested using a database of over 83,000 expert games with over 17 million moves. We present ways of visualizing the learned features (""shapes"") and a method to derive aspects of the motivation behind the expert's moves. The discussed methods are inspired by recent progress made in constructing saliency maps for image classification.","Deep learning, text, image and signal processing",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-98.pdf,2016,73.23943661971832,"Deep Neural Network Analysis of Go Games: Which Stones Motivate a Move? Recently, deep learning was used to construct deep convolution network models for move prediction in Go. Here, we develop methods to analyze the inner workings of the resulting deep architectures. Our example network is learned and tested using a database of over 83,000 expert games with over 17 million moves. We present ways of visualizing the learned features (""shapes"") and a method to derive aspects of the motivation behind the expert's moves. The discussed methods are inspired by recent progress made in constructing saliency maps for image classification."
Active transfer learning for activity recognition,"Tom Diethe, Niall Twomey, Peter Flach",1 - Intelligent Systems Laboratory University of Bristol UK,"We examine activity recognition from accelerometers, which provides at least two major challenges for machine learning. Firstly, the deployment context is likely to differ from the learning context. Secondly, accurate labelling of training data is time-consuming and error-prone. This calls for a combination of active and transfer learning. We derive a hierarchical Bayesian model that is a natural fit to such problems, and provide empirical validation on synthetic and publicly available datasets. The results show that by combining active and transfer learning, we can achieve faster learning with fewer labels on a target domain than by either alone.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-99.pdf,2016,100.0,"Active transfer learning for activity recognition We examine activity recognition from accelerometers, which provides at least two major challenges for machine learning. Firstly, the deployment context is likely to differ from the learning context. Secondly, accurate labelling of training data is time-consuming and error-prone. This calls for a combination of active and transfer learning. We derive a hierarchical Bayesian model that is a natural fit to such problems, and provide empirical validation on synthetic and publicly available datasets. The results show that by combining active and transfer learning, we can achieve faster learning with fewer labels on a target domain than by either alone."
Environmental signal processing: new trends and applications,"Matthieu Puigt, Gilles Delmaire, Gilles Roussel","1 - Univ. Littoral Côte d'Opale LISIC -EA 4491, F-62228 Calais France","In the last years, environmental monitoring was shown to be a major application field of modern signal processing and machine learning techniques. In particular, it provides some interesting problems for which specific signal methods were proposed. In this session, we aim to review some recent advances in this topic. We propose a taxonomy of the major trends in environmental surveillance according to the characteristics of the sensing devices, i.e., (i) for a unique sensor or an array of sensors (e.g., bio-sensor, chemical sensor arrays), (ii) for remote observation, and (iii) using large-scale sensor networks. 
 Chemometrics for single sensor and sensor arrays Processing single environmental sensors or sensor arrays arised as a major topic in environmental monitoring, known under the name of chemometrics. Indeed, while sensors used in source apportionment provide fine particulate analyzed by chemists which must then be numerically processed to enhance their interpretability, there has also been an increasing need to process data from 205",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-1.pdf,2017,100.0,"Environmental signal processing: new trends and applications In the last years, environmental monitoring was shown to be a major application field of modern signal processing and machine learning techniques. In particular, it provides some interesting problems for which specific signal methods were proposed. In this session, we aim to review some recent advances in this topic. We propose a taxonomy of the major trends in environmental surveillance according to the characteristics of the sensing devices, i.e., (i) for a unique sensor or an array of sensors (e.g., bio-sensor, chemical sensor arrays), (ii) for remote observation, and (iii) using large-scale sensor networks. 
 Chemometrics for single sensor and sensor arrays Processing single environmental sensors or sensor arrays arised as a major topic in environmental monitoring, known under the name of chemometrics. Indeed, while sensors used in source apportionment provide fine particulate analyzed by chemists which must then be numerically processed to enhance their interpretability, there has also been an increasing need to process data from 205"
Learning Null Space Projections Fast,"Jeevan Manavalan, Matthew Howard","1 - Department of Informatics Strand King's College London Kings College WC2R 2LS Strand, London United Kingdom","Typically robot interactions with the environment may involve some type of constraint which impedes the motion of the system. This paper proposes an approach to learn kinematic constraints from observed movements. Our method derives the null space projection of a kinematically constrained system using gradient descent. Moreover, we compare this method to the existing brute force-based approach for learning constraints on data sets of different dimensionality, to demonstrate how it can learn constraints from data sets of a much higher dimensionality.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-10.pdf,2017,77.77777777777779,"Learning Null Space Projections Fast Typically robot interactions with the environment may involve some type of constraint which impedes the motion of the system. This paper proposes an approach to learn kinematic constraints from observed movements. Our method derives the null space projection of a kinematically constrained system using gradient descent. Moreover, we compare this method to the existing brute force-based approach for learning constraints on data sets of different dimensionality, to demonstrate how it can learn constraints from data sets of a much higher dimensionality."
TimeNet: Pre-trained deep recurrent neural network for time series classification,"Pankaj Malhotra, Vishnu Tv, Lovekesh Vig, Puneet Agarwal, Gautam Shroff",1 - TCS Research New Delhi India,"Inspired by the tremendous success of deep Convolutional Neural Networks as generic feature extractors for images, we propose TimeNet: a deep recurrent neural network (RNN) trained on diverse time series in an unsupervised manner using sequence to sequence (seq2seq) models to extract features from time series. Rather than relying on data from the problem domain, TimeNet attempts to generalize time series representation across domains by ingesting time series from several domains simultaneously. Once trained, TimeNet can be used as a generic off-the-shelf feature extractor for time series. The representations or embeddings given by a pre-trained TimeNet are found to be useful for time series classification (TSC). For several publicly available datasets from UCR TSC Archive and an industrial telematics sensor data from vehicles, we observe that a classifier learned over the TimeNet embeddings yields significantly better performance compared to (i) a classifier learned over the embeddings given by a domain-specific RNN, as well as (ii) a nearest neighbor classifier based on Dynamic Time Warping.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-100.pdf,2017,100.0,"TimeNet: Pre-trained deep recurrent neural network for time series classification Inspired by the tremendous success of deep Convolutional Neural Networks as generic feature extractors for images, we propose TimeNet: a deep recurrent neural network (RNN) trained on diverse time series in an unsupervised manner using sequence to sequence (seq2seq) models to extract features from time series. Rather than relying on data from the problem domain, TimeNet attempts to generalize time series representation across domains by ingesting time series from several domains simultaneously. Once trained, TimeNet can be used as a generic off-the-shelf feature extractor for time series. The representations or embeddings given by a pre-trained TimeNet are found to be useful for time series classification (TSC). For several publicly available datasets from UCR TSC Archive and an industrial telematics sensor data from vehicles, we observe that a classifier learned over the TimeNet embeddings yields significantly better performance compared to (i) a classifier learned over the embeddings given by a domain-specific RNN, as well as (ii) a nearest neighbor classifier based on Dynamic Time Warping."
Deep convolutional neural networks for detecting noisy neighbours in cloud infrastructure,"Bruno Ordozgoiti, Alberto Mozo, Sandra Canaval, Udi Margolin, Elisha Rosensweig, Itai Segall","1 - Departamento de Sistemas Informáticos Universidad Politécnica de Madrid
4 - Nokia Israel","Cloud infrastructure in data centers is expected to be one of the main technologies supporting Internet communications in the coming years. Virtualization is employed to achieve the flexibility and dynamicity required by the wide variety of applications used today. Therefore, optimal allocation of virtual machines is key to ensuring performance and efficiency. Noisy neighbor is a term used to describe virtual machines competing for physical resources and thus disturbing each other, a phenomenon that can dramatically degrade their performance. Detecting noisy neighbors using simple thresholding approaches is ineffective. To exploit the time-series nature of cloud monitoring data, we propose an approach based on deep convolutional networks. We test it on real infrastructure data and show it outperforms well-known classifiers in detecting noisy neighbors. * The research leading to these results has received funding from the European Union under the FP7 grant agreement n. 619633 ( project ONTIC) and H2020 grant agreement n. 671625 (project CogNet).",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-102.pdf,2017,100.0,"Deep convolutional neural networks for detecting noisy neighbours in cloud infrastructure Cloud infrastructure in data centers is expected to be one of the main technologies supporting Internet communications in the coming years. Virtualization is employed to achieve the flexibility and dynamicity required by the wide variety of applications used today. Therefore, optimal allocation of virtual machines is key to ensuring performance and efficiency. Noisy neighbor is a term used to describe virtual machines competing for physical resources and thus disturbing each other, a phenomenon that can dramatically degrade their performance. Detecting noisy neighbors using simple thresholding approaches is ineffective. To exploit the time-series nature of cloud monitoring data, we propose an approach based on deep convolutional networks. We test it on real infrastructure data and show it outperforms well-known classifiers in detecting noisy neighbors. * The research leading to these results has received funding from the European Union under the FP7 grant agreement n. 619633 ( project ONTIC) and H2020 grant agreement n. 671625 (project CogNet)."
Solving Inverse Source Problems for Sources with Arbitrary Shapes using Sensor Networks,"John Murray-Bruce, Pier Dragotti",1 - Imperial College London -Electrical and Electronic Engineering Department South Kensington -London United Kingdom,"Recently, the use of wireless sensor networks for environmental monitoring has been a topic of intensive research. The sensor nodes obtain spatiotemporal samples of physical fields over the region of interest. For most cases these fields are driven by well-known partial differential equations-the diffusion and wave equations for example-and this prior knowledge can be used to solve such physics-driven inverse source problems (ISPs). In this work, we demonstrate how to estimate the unknown source shape inducing the field by assuming that it can be described by a model having a finite number of unknown parameters.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-103.pdf,2017,100.0,"Solving Inverse Source Problems for Sources with Arbitrary Shapes using Sensor Networks Recently, the use of wireless sensor networks for environmental monitoring has been a topic of intensive research. The sensor nodes obtain spatiotemporal samples of physical fields over the region of interest. For most cases these fields are driven by well-known partial differential equations-the diffusion and wave equations for example-and this prior knowledge can be used to solve such physics-driven inverse source problems (ISPs). In this work, we demonstrate how to estimate the unknown source shape inducing the field by assuming that it can be described by a model having a finite number of unknown parameters."
Hierarchical Combination of Video Features for Personalised Pain Level Recognition,"Patrick Thiam, Viktor Kessler, Friedhelm Schwenker",1 - Ulm University -Institute of Neural Information Processing James-Franck-Ring 89061 Ulm Germany,"In this work, we present a personalised participant independent pain recognition system based on the video channel. Instead of using an entire annotated dataset to train a classification model that would be later applied to an unseen participant, a similarity metric is used to select the most interesting annotated samples based on the data of the unseen participant. These samples are subsequently used to train a model adapted to the unseen participant. The selection process helps to avoid redundant and irrelevant data samples, thus improves the performance as well as the efficiency of the trained model. From the video channel, several features are extracted and subsequently fed into an hierarchical fusion architecture to further improve the performance of the system.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-104.pdf,2017,100.0,"Hierarchical Combination of Video Features for Personalised Pain Level Recognition In this work, we present a personalised participant independent pain recognition system based on the video channel. Instead of using an entire annotated dataset to train a classification model that would be later applied to an unseen participant, a similarity metric is used to select the most interesting annotated samples based on the data of the unseen participant. These samples are subsequently used to train a model adapted to the unseen participant. The selection process helps to avoid redundant and irrelevant data samples, thus improves the performance as well as the efficiency of the trained model. From the video channel, several features are extracted and subsequently fed into an hierarchical fusion architecture to further improve the performance of the system."
Structure Optimization for Deep Multimodal Fusion Networks using Graph-Induced Kernels,"Dhanesh Ramachandram, Michal Lisicki, Timothy Shields, Mohamed Amer, Graham Taylor","1 - School of Engineering -Machine Learning Research Group University of Guelph Canada
3 - -Center for Vision Technologies SRI International USA","A popular testbed for deep learning has been multimodal recognition of human activity or gesture involving diverse inputs such as video, audio, skeletal pose and depth images. Deep learning architectures have excelled on such problems due to their ability to combine modality representations at different levels of nonlinear feature extraction. However, designing an optimal architecture in which to fuse such learned representations has largely been a non-trivial human engineering effort. We treat fusion structure optimization as a hyper-parameter search and cast it as a discrete optimization problem under the Bayesian optimization framework. We propose a novel graph-induced kernel to compute structural similarities in the search space of tree-structured multimodal architectures and demonstrate its effectiveness using two challenging multimodal human activity recognition datasets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-108.pdf,2017,74.4186046511628,"Structure Optimization for Deep Multimodal Fusion Networks using Graph-Induced Kernels A popular testbed for deep learning has been multimodal recognition of human activity or gesture involving diverse inputs such as video, audio, skeletal pose and depth images. Deep learning architectures have excelled on such problems due to their ability to combine modality representations at different levels of nonlinear feature extraction. However, designing an optimal architecture in which to fuse such learned representations has largely been a non-trivial human engineering effort. We treat fusion structure optimization as a hyper-parameter search and cast it as a discrete optimization problem under the Bayesian optimization framework. We propose a novel graph-induced kernel to compute structural similarities in the search space of tree-structured multimodal architectures and demonstrate its effectiveness using two challenging multimodal human activity recognition datasets."
Real-time convolutional networks for sonar image classification in low-power embedded systems,Matias Valdenegro-Toro,1 - Ocean Systems Laboratory -School of Engineering & Physical Sciences Heriot-Watt University EH14 4AS Edinburgh UK,"Deep Neural Networks have impressive classification performance, but this comes at the expense of significant computational resources at inference time. Autonomous Underwater Vehicles use low-power embedded systems for sonar image perception, and cannot execute large neural networks in real-time. We propose the use of max-pooling aggressively, and we demonstrate it with a Fire-based module and a new Tiny module that includes max-pooling in each module. By stacking them we build networks that achieve the same accuracy as bigger ones, while reducing the number of parameters and considerably increasing computational performance. Our networks can classify a 96 × 96 sonar image with 98.8 − 99.7% accuracy on only 41 to 61 milliseconds on a Raspberry Pi 2, which corresponds to speedups of 28.6 − 19.7.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-109.pdf,2017,100.0,"Real-time convolutional networks for sonar image classification in low-power embedded systems Deep Neural Networks have impressive classification performance, but this comes at the expense of significant computational resources at inference time. Autonomous Underwater Vehicles use low-power embedded systems for sonar image perception, and cannot execute large neural networks in real-time. We propose the use of max-pooling aggressively, and we demonstrate it with a Fire-based module and a new Tiny module that includes max-pooling in each module. By stacking them we build networks that achieve the same accuracy as bigger ones, while reducing the number of parameters and considerably increasing computational performance. Our networks can classify a 96 × 96 sonar image with 98.8 − 99.7% accuracy on only 41 to 61 milliseconds on a Raspberry Pi 2, which corresponds to speedups of 28.6 − 19.7."
A multi-criteria meta-learning method to select under-sampling algorithms for imbalanced datasets,"Romero Morais, B Miranda, Ricardo Silva",1 - Universidade Federal de Pernambuco -CIn -Recife Brazil,"Standard classifiers consider a balanced distribution of examples' classes in the data, thus, imbalanced datasets may hinder the learning process. Sampling techniques balance the data by adjusting the examples' classes distribution. However, selecting an appropriate sampling technique and its parameters for a given imbalanced dataset is still an open problem. This work proposes a method that uses Meta-Learning to recommend a technique for an imbalanced dataset considering multiple performance criteria. The experiments revealed that the proposal reached results comparable to those achieved by the brute-force approach, overcame the techniques with their default parameters most of the time, and always surpassed the random search approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-11.pdf,2017,100.0,"A multi-criteria meta-learning method to select under-sampling algorithms for imbalanced datasets Standard classifiers consider a balanced distribution of examples' classes in the data, thus, imbalanced datasets may hinder the learning process. Sampling techniques balance the data by adjusting the examples' classes distribution. However, selecting an appropriate sampling technique and its parameters for a given imbalanced dataset is still an open problem. This work proposes a method that uses Meta-Learning to recommend a technique for an imbalanced dataset considering multiple performance criteria. The experiments revealed that the proposal reached results comparable to those achieved by the brute-force approach, overcame the techniques with their default parameters most of the time, and always surpassed the random search approach."
Degrees of Freedom in Regression Ensembles,"Henry Wj Reeve, Gavin Brown",1 - School of Computer Science Kilburn Building University of Manchester University of Manchester Oxford Rd M13 9PL Manchester,"Negative correlation learning is an effective approach to ensemble learning in which model diversity is encouraged through a correlation penalty term. The level of emphasis placed upon the correlation penalty term is controlled by the diversity parameter. We shall provide a degrees of freedom analysis of negative correlation learning. Our contributions are as follows: we give an exact formula for the effective degrees of freedom in a negative correlation ensemble with fixed basis functions; we show that the effective degrees of freedom is a continuous, convex and monotonically increasing function of the diversity parameter; finally, we show that the degrees of freedom formula gives rise to an efficient way to tune the diversity parameter on large data sets. * The authors gratefully acknowledge the support of the EPSRC for the LAMBDA project (EP/N035127/1) and the Manchester Centre for Doctoral Training (EP/1038099/1). We would also like to thank Kit Elliot and the anonymous reviewers for useful feedback.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-110.pdf,2017,100.0,"Degrees of Freedom in Regression Ensembles Negative correlation learning is an effective approach to ensemble learning in which model diversity is encouraged through a correlation penalty term. The level of emphasis placed upon the correlation penalty term is controlled by the diversity parameter. We shall provide a degrees of freedom analysis of negative correlation learning. Our contributions are as follows: we give an exact formula for the effective degrees of freedom in a negative correlation ensemble with fixed basis functions; we show that the effective degrees of freedom is a continuous, convex and monotonically increasing function of the diversity parameter; finally, we show that the degrees of freedom formula gives rise to an efficient way to tune the diversity parameter on large data sets. * The authors gratefully acknowledge the support of the EPSRC for the LAMBDA project (EP/N035127/1) and the Manchester Centre for Doctoral Training (EP/1038099/1). We would also like to thank Kit Elliot and the anonymous reviewers for useful feedback."
Feature Extraction for On-Road Vehicle Detection Based on Support Vector Machine,"Samuel Giatti Da, Silva Filho, Roberto Zanetti Freire, Leandro Dos, Santos Coelho","1 - Pontifical Catholic University of Parana -PUCPR -Polytechnic School Imaculada Conceição 1155 -Postal Code 80215-901 Curitiba PR Brazil
4 - Federal University of Parana (UFPR) -Dept. of Electrical Engineering Av. Cel. Francisco H. dos Santos 210 -Postal Code 82590-300 Curitiba PR Brazil","Inspired by alarming statistics of deaths and injuries in car accidents, this work presents the development of vehicles detection method, which is part of an Advanced Driving Assistance System. A computer vision software capable to interpret real-time events on roads, that can identify vehicles based on Support Vector Machine, was presented and evaluated by adopting two distinct techniques for features extraction. Comparisons between two feature extraction techniques (Invariant Features Transform and Histogram of Oriented Gradients) were presented, and promising results in terms of vehicles identification accuracy were obtained when a frame scan technique was integrated to the system.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-112.pdf,2017,100.0,"Feature Extraction for On-Road Vehicle Detection Based on Support Vector Machine Inspired by alarming statistics of deaths and injuries in car accidents, this work presents the development of vehicles detection method, which is part of an Advanced Driving Assistance System. A computer vision software capable to interpret real-time events on roads, that can identify vehicles based on Support Vector Machine, was presented and evaluated by adopting two distinct techniques for features extraction. Comparisons between two feature extraction techniques (Invariant Features Transform and Histogram of Oriented Gradients) were presented, and promising results in terms of vehicles identification accuracy were obtained when a frame scan technique was integrated to the system."
Pseudo-Analytical Solutions for Stochastic Options Pricing Using Monte Carlo Simulation and Breeding PSO-Trained Neural Networks,"Sam Palmer, Denise Gorse",1 - Dept of Computer Science University College London Gower Street WC1E 6BT London UK,"We introduce a novel methodology for pricing options which uses a particle swarm trained neural network to approximate the solution of a stochastic pricing model. The performance of the network is compared to the analytical solution for European call options and the errors shown statistically comparable to Monte Carlo pricing. The work provides a proof of concept that can be extended to more complex options for which no analytical solutions exist, the pricing method presented here delivering results several orders of magnitude faster than the Monte Carlo pricing method used by default in the financial industry. 
 Financial background An option gives its owner the right, but not obligation, to trade a certain amount of an underlying asset at some future time. A call option gives its owner the right to buy that amount of the asset, a put option the right to sell. In the simplest case, referred to as a European option, the time in question is the date on which the contract matures; however many more complex financial derivative products have been devised.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-113.pdf,2017,64.84375,"Pseudo-Analytical Solutions for Stochastic Options Pricing Using Monte Carlo Simulation and Breeding PSO-Trained Neural Networks We introduce a novel methodology for pricing options which uses a particle swarm trained neural network to approximate the solution of a stochastic pricing model. The performance of the network is compared to the analytical solution for European call options and the errors shown statistically comparable to Monte Carlo pricing. The work provides a proof of concept that can be extended to more complex options for which no analytical solutions exist, the pricing method presented here delivering results several orders of magnitude faster than the Monte Carlo pricing method used by default in the financial industry. 
 Financial background An option gives its owner the right, but not obligation, to trade a certain amount of an underlying asset at some future time. A call option gives its owner the right to buy that amount of the asset, a put option the right to sell. In the simplest case, referred to as a European option, the time in question is the date on which the contract matures; however many more complex financial derivative products have been devised."
A Deep Q-Learning Agent for the L-Game with Variable Batch Training,"Petros Giannakopoulos, Yannis Cotronis",1 - Dept of Informatics and Telecommunications Ilisia National and Kapodistrian University of Athens 15784 Greece,"We employ the Deep Q-Learning algorithm with Experience Replay to train an agent capable of achieving a high-level of play in the L-Game while selflearning from low-dimensional states. We also employ variable batch size for training in order to mitigate the loss of the rare reward signal and significantly accelerate training. Despite the large action space due to the number of possible moves, the low-dimensional state space and the rarity of rewards, which only come at the end of a game, DQL is successful in training an agent capable of strong play without the use of any search methods or domain knowledge.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-115.pdf,2017,96.92307692307692,"A Deep Q-Learning Agent for the L-Game with Variable Batch Training We employ the Deep Q-Learning algorithm with Experience Replay to train an agent capable of achieving a high-level of play in the L-Game while selflearning from low-dimensional states. We also employ variable batch size for training in order to mitigate the loss of the rare reward signal and significantly accelerate training. Despite the large action space due to the number of possible moves, the low-dimensional state space and the rarity of rewards, which only come at the end of a game, DQL is successful in training an agent capable of strong play without the use of any search methods or domain knowledge."
Learning sparse models of diffusive graph signals,"Shuyu Dong, Dorina Thanou, P.-A Absil, Pascal Frossard","1 - ICTEAM Institute Université catholique de Louvain B-1348 Louvain-la-Neuve Belgium
2 - Ecole polytechnique fédérale de Lausanne LTS4 Route Cantonale CH-1015 Lausanne Switzerland","Graph signals that describe data living on irregularly structured domains provide a generic representation for structured information in very diverse applications. The effective analysis and processing of such signals however necessitate good models that identify the most relevant signal components. In this paper, we propose to learn sparse representation models for graph signals that describe heat diffusion processes. This consists in learning a dictionary that incorporates spectral properties of an implicit graph diffusion kernel. The underlying formulation enables the identification of both sparse features and an adaptive graph structure from mere signal observations. Experiments on synthetic and real datasets show that the proposed dictionaries not only reflect the underlying diffusion process but also significantly reduce over-fitting of data in comparison to state-of-the-art methods. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-116.pdf,2017,100.0,"Learning sparse models of diffusive graph signals Graph signals that describe data living on irregularly structured domains provide a generic representation for structured information in very diverse applications. The effective analysis and processing of such signals however necessitate good models that identify the most relevant signal components. In this paper, we propose to learn sparse representation models for graph signals that describe heat diffusion processes. This consists in learning a dictionary that incorporates spectral properties of an implicit graph diffusion kernel. The underlying formulation enables the identification of both sparse features and an adaptive graph structure from mere signal observations. Experiments on synthetic and real datasets show that the proposed dictionaries not only reflect the underlying diffusion process but also significantly reduce over-fitting of data in comparison to state-of-the-art methods. * This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimization), funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office."
Acceleration of Prototype Based Models with Cascade Computation,"Cem Karaoguz, Alexander Gepperth","1 - ENSTA ParisTech -UIIS Lab University of Paris-Saclay 91762 Palaiseau France
2 - University of Applied Sciences Fulda -Applied Computer Science department Leipzigerstr. 123 36037 Fulda Germany","Prototype-based generative description of data space is shown to be effective in incremental learning. However, computation of similarities of input vectors to prototypes may be demanding especially in the face of high input dimensions and high number of prototypes. The main contribution of the paper is the acceleration of the prototype-based model by a cascade computation approach. The evaluation of the presented architecture on a human detection and pose estimation problem shows that the cascade computation results in a significant reduction of computational resource requirements at the expense of minor degradations in the classification performance.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-117.pdf,2017,100.0,"Acceleration of Prototype Based Models with Cascade Computation Prototype-based generative description of data space is shown to be effective in incremental learning. However, computation of similarities of input vectors to prototypes may be demanding especially in the face of high input dimensions and high number of prototypes. The main contribution of the paper is the acceleration of the prototype-based model by a cascade computation approach. The evaluation of the presented architecture on a human detection and pose estimation problem shows that the cascade computation results in a significant reduction of computational resource requirements at the expense of minor degradations in the classification performance."
A Novel Principle for Causal Inference in Data with Small Error Variance,"Patrick Blöbaum, Shohei Shimizu, Takashi Washio",1 - The Institute of Scientific and Industrial Research Osaka University,"Causal inference addresses the problem of identifying cause and effect variables in observed data. While most of the current techniques base heavily on exploiting asymmetries in the error noise, these techniques struggle in data that only contain small noise. We present a novel principle for causal inference in a bivariate setting with small error variance. For this, we exploit an asymmetry in the prediction error under the assumption of additive noise and an independence between data generating mechanism and its input. The applicability of our approach is corroborated with empirical evaluations in artificial and real-world data sets.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-12.pdf,2017,79.16666666666666,"A Novel Principle for Causal Inference in Data with Small Error Variance Causal inference addresses the problem of identifying cause and effect variables in observed data. While most of the current techniques base heavily on exploiting asymmetries in the error noise, these techniques struggle in data that only contain small noise. We present a novel principle for causal inference in a bivariate setting with small error variance. For this, we exploit an asymmetry in the prediction error under the assumption of additive noise and an independence between data generating mechanism and its input. The applicability of our approach is corroborated with empirical evaluations in artificial and real-world data sets."
Learning Dot Product Polynomials for multiclass problems,"Lauriola Ivano, Donini Michele, Aiolli Fabio","1 - Department of Mathematics University of Padova via Trieste 63 Padova Italy
2 - -Computational Statistics and Machine Learning (CSML) Istituto Italiano di Tecnologia Via Morego 30 Genova Italy","Several mechanisms exist in the literature to solve a multiclass classification problem exploiting a binary kernel-machine. Most of them are based on problem decomposition that consists on splitting the problem in many binary tasks. These tasks have different complexity and they require different kernels. Our goal is to use the Multiple Kernel Learning (MKL) paradigm to learn the best dot-product kernel for each decomposed binary task. In this context, we propose an efficient learning procedure to reduce the searching space of hyperparameters, showing its empirically effectiveness.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-120.pdf,2017,71.42857142857143,"Learning Dot Product Polynomials for multiclass problems Several mechanisms exist in the literature to solve a multiclass classification problem exploiting a binary kernel-machine. Most of them are based on problem decomposition that consists on splitting the problem in many binary tasks. These tasks have different complexity and they require different kernels. Our goal is to use the Multiple Kernel Learning (MKL) paradigm to learn the best dot-product kernel for each decomposed binary task. In this context, we propose an efficient learning procedure to reduce the searching space of hyperparameters, showing its empirically effectiveness."
Active learning strategy for CNN combining batchwise Dropout and Query-By-Committee,"Melanie Ducoffe, Frederic Precioso","1 - UMR UNS-CNRS Univ. Nice Sophia Antipolis I3S, 7271 06900 Sophia Antipolis France","While the current trend is to increase the depth of neural networks to improve their performance, the size of the training database has to grow accordingly. We thus notice an emergence of tremendous databases, although providing labels to build a training set still remains a very expensive task. In this paper, we tackle the problem of selecting the samples to be labeled in an online fashion. We present an active learning strategy based on query by committee and dropout technique to train a Convolutional Neural Network (CNN). We evaluate our active learning strategy for CNN on MNIST and USPS benchmarks, showing in particular that selecting less than 22 % from the annotated database is enough to get similar error rate as using the full training set. 
 Introduction The relation between the depth of the architecture, the required amount of training data and the final accuracy of the decision has not only been observed experimentally but it has also been explained in various papers. In their paper [1], Bengio et al. explain clearly that complex decisions can be seen as highly-varying functions and that the decision making algorithm which intends to comprehend all these variations must be composed of many non-linearities. This specificity of deep architectures also impacts the representation compactness of highly-varying functions. In this same paper, they illustrate how deep architectures outperform shallow ones in terms of number of computational units required and thus training samples, in order to represent a given function. Their examples highlight even the differences in representation compactness between deep architectures, with respect to the problem. Considering the huge amount of parameters to be learnt in order to address ImageNet Challenge (60 million parameters for AlexNet, winner in 2012, to reach 152 layers with Microsoft ResNet winner in 2015), one can understand that the training set has to be huge too. Furthermore, in order to better cover the dispersion of the input distribution, strategies to extend the training set have arisen. When considering the difficulty and the cost to gather relevant annotations for Challenges such as ImageNet, the interest for methods working with smaller training sets is increasing. Our work focuses on the selection of a better subset to be annotated for training, exploiting the theory of committee decisions. We propose a low computation adaptation of Query-By-Committee strategy (QBC) for deep learning. Indeed the huge number of parameters to be determined in a deep architecture prevents us from training a committee of deep networks. Instead, we train a full 595",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-122.pdf,2017,100.0,"Active learning strategy for CNN combining batchwise Dropout and Query-By-Committee While the current trend is to increase the depth of neural networks to improve their performance, the size of the training database has to grow accordingly. We thus notice an emergence of tremendous databases, although providing labels to build a training set still remains a very expensive task. In this paper, we tackle the problem of selecting the samples to be labeled in an online fashion. We present an active learning strategy based on query by committee and dropout technique to train a Convolutional Neural Network (CNN). We evaluate our active learning strategy for CNN on MNIST and USPS benchmarks, showing in particular that selecting less than 22 % from the annotated database is enough to get similar error rate as using the full training set. 
 Introduction The relation between the depth of the architecture, the required amount of training data and the final accuracy of the decision has not only been observed experimentally but it has also been explained in various papers. In their paper [1], Bengio et al. explain clearly that complex decisions can be seen as highly-varying functions and that the decision making algorithm which intends to comprehend all these variations must be composed of many non-linearities. This specificity of deep architectures also impacts the representation compactness of highly-varying functions. In this same paper, they illustrate how deep architectures outperform shallow ones in terms of number of computational units required and thus training samples, in order to represent a given function. Their examples highlight even the differences in representation compactness between deep architectures, with respect to the problem. Considering the huge amount of parameters to be learnt in order to address ImageNet Challenge (60 million parameters for AlexNet, winner in 2012, to reach 152 layers with Microsoft ResNet winner in 2015), one can understand that the training set has to be huge too. Furthermore, in order to better cover the dispersion of the input distribution, strategies to extend the training set have arisen. When considering the difficulty and the cost to gather relevant annotations for Challenges such as ImageNet, the interest for methods working with smaller training sets is increasing. Our work focuses on the selection of a better subset to be annotated for training, exploiting the theory of committee decisions. We propose a low computation adaptation of Query-By-Committee strategy (QBC) for deep learning. Indeed the huge number of parameters to be determined in a deep architecture prevents us from training a committee of deep networks. Instead, we train a full 595"
Efficient Neural-based patent document segmentation with Term Order Probabilities,"Danilo Carvalho, Minh-Le Nguyen","1 - School of Information Science Advanced Institute of Science and Technology Nomi City Ishikawa Japan, Japan","The internationally growing trend of patent applications puts great pressure on the agents involved in managing this kind of information and creates a demand for efficient and effective patent analysis methods. This work presents a computationally efficient approach for patent document segmentation based on structured ANNs and a simple distributional semantics composition method. The conducted experiments indicate effectiveness of the approach, which benefits a wide array of patent processing techniques that work upon structured inputs.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-123.pdf,2017,100.0,"Efficient Neural-based patent document segmentation with Term Order Probabilities The internationally growing trend of patent applications puts great pressure on the agents involved in managing this kind of information and creates a demand for efficient and effective patent analysis methods. This work presents a computationally efficient approach for patent document segmentation based on structured ANNs and a simple distributional semantics composition method. The conducted experiments indicate effectiveness of the approach, which benefits a wide array of patent processing techniques that work upon structured inputs."
The Conjunctive Disjunctive Node Kernel,"Dinh Van, Alessandro Sperduti, Fabrizio Costa","1 - Department of Mathematics Padova University Trieste 63 35121 Padova Italy
3 - Department of Computer Science University of Exeter EX4 4QF Exeter UK","Gene-disease associations are inferred on the basis of similarities between the proteins encoded by genes. Biological relationships used to define similarities range from interacting proteins, proteins that participate in pathways and protein expression profiles. Though graph kernel methods have become a prominent approach for association prediction, most solutions are based on a notion of information diffusion that does not capture the specificity of different network parts. Here we propose a graph kernel method that explicitly models the configuration of each gene's context. An empirical evaluation on several biological databases shows that our proposal is competitive w.r.t. state-of-the-art kernel approaches.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-127.pdf,2017,100.0,"The Conjunctive Disjunctive Node Kernel Gene-disease associations are inferred on the basis of similarities between the proteins encoded by genes. Biological relationships used to define similarities range from interacting proteins, proteins that participate in pathways and protein expression profiles. Though graph kernel methods have become a prominent approach for association prediction, most solutions are based on a notion of information diffusion that does not capture the specificity of different network parts. Here we propose a graph kernel method that explicitly models the configuration of each gene's context. An empirical evaluation on several biological databases shows that our proposal is competitive w.r.t. state-of-the-art kernel approaches."
Invariant representations of images for better learning,"Muthuvel Murugan, K Subrahmanyam","1 - Department of Computer Science Chennai Mathematical Institute
2 - Chennai Mathematical Institute Chennai India","We study the problem of obtaining representations of images which are invariant to transformation of the image under rotations, towards improving supervised learning. We show that using simple ideas from group representation theory we get invariant representations of images. Off the shelf learning algorithms perform much better on such representations. We develop on ideas by Cohen and Welling [1] to construct these invariant representations.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-130.pdf,2017,100.0,"Invariant representations of images for better learning We study the problem of obtaining representations of images which are invariant to transformation of the image under rotations, towards improving supervised learning. We show that using simple ideas from group representation theory we get invariant representations of images. Off the shelf learning algorithms perform much better on such representations. We develop on ideas by Cohen and Welling [1] to construct these invariant representations."
Indoor air pollutant sources using blind source separation methods,"Rachid Ouaret, Anda Ionescu, Olivier Ramalho, Yves Candau","1 - Center for Study and Research on Thermics, Environment -University Paris-Est Systems University Paris-Est Créteil 61 avenue du Général de Gaulle F-94010 Créteil Cedex France
3 - Scientific and Technical Centre for Building (CSTB) -University Paris-Est 84 avenue Jean Jaurès 77420 Champs-sur-Marne France","The objective of this study is to separate different sources of variability of air pollutant concentrations time series of particulate matter (PM) monitored in real indoor environments. Different blind source separation (BSS) methods (ICA, PMF, NMF) were applied in order to identify the PM sources and their contributions. The source profiles were characterized by their autocorrelation functions (ACF) which were compared to the ACFs of other variables. Their interpretation was completed by the analysis of polar plots including exogenous factors. Source contributions were also quantified.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-131.pdf,2017,65.15151515151516,"Indoor air pollutant sources using blind source separation methods The objective of this study is to separate different sources of variability of air pollutant concentrations time series of particulate matter (PM) monitored in real indoor environments. Different blind source separation (BSS) methods (ICA, PMF, NMF) were applied in order to identify the PM sources and their contributions. The source profiles were characterized by their autocorrelation functions (ACF) which were compared to the ACFs of other variables. Their interpretation was completed by the analysis of polar plots including exogenous factors. Source contributions were also quantified."
WiSARD rp for Change Detection in Video Sequences,"Massimo De Gregorio, Maurizio Giordano","1 - Istituto di Scienze Applicate e Sistemi Intelligenti ""E","Weightless neural networks (WNNs) have been successfully used as learners and detectors of background regions in video processing, as they feature fast learning algorithm, noise tolerance and an incremental update of learnt knowledge, also referred to as online training. These features make WNNs suitable and effective to be used for change detection in scenarios in which environmental changes (light, camera view, cluttered background) and moving objects force the modeling of background regions to change continuously, and in drastic ways. In this paper, we present a change detection method in video processing that uses a WNN, called WiSARD rp , as underlying learning mechanism, equipped with a reinforcing/weakening scheme, that builds and continuously updates a model of background at pixel-level. The performance of the proposed change detection method is evaluated on the ChangeDetection.net video archive.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-133.pdf,2017,94.84536082474226,"WiSARD rp for Change Detection in Video Sequences Weightless neural networks (WNNs) have been successfully used as learners and detectors of background regions in video processing, as they feature fast learning algorithm, noise tolerance and an incremental update of learnt knowledge, also referred to as online training. These features make WNNs suitable and effective to be used for change detection in scenarios in which environmental changes (light, camera view, cluttered background) and moving objects force the modeling of background regions to change continuously, and in drastic ways. In this paper, we present a change detection method in video processing that uses a WNN, called WiSARD rp , as underlying learning mechanism, equipped with a reinforcing/weakening scheme, that builds and continuously updates a model of background at pixel-level. The performance of the proposed change detection method is evaluated on the ChangeDetection.net video archive."
Approximated Neighbours MinHash Graph Node Kernel,"Nicolò Navarin, Alessandro Sperduti",1 - Department of Mathematics University of Padova via Trieste 63 Padova Italy,"In this paper, we propose a scalable kernel for nodes in a (huge) graph. In contrast with other state-of-the-art kernels that scale more than quadratically in the number of nodes, our approach scales linearly in the average out-degree and quadratically in the number of nodes (for the Gram matrix computation). The kernel presented in this paper considers neighbours as sets, thus it ignores edge weights. Nevertheless, experimental results on real-world datasets show promising results.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-134.pdf,2017,100.0,"Approximated Neighbours MinHash Graph Node Kernel In this paper, we propose a scalable kernel for nodes in a (huge) graph. In contrast with other state-of-the-art kernels that scale more than quadratically in the number of nodes, our approach scales linearly in the average out-degree and quadratically in the number of nodes (for the Gram matrix computation). The kernel presented in this paper considers neighbours as sets, thus it ignores edge weights. Nevertheless, experimental results on real-world datasets show promising results."
Attention-based Information Fusion using Multi-Encoder-Decoder Recurrent Neural Networks,"Stephan Baier, Sigurd Spieckermann, Volker Tresp","1 - Ludwig Maximilian University Oettingenstr. 67 Munich Germany
2 - Siemens AG, Corporate Technology Otto-Hahn-Ring 6 Munich Germany","With the rising number of interconnected devices and sensors, modeling distributed sensor networks is of increasing interest. Recurrent neural networks (RNN) are considered particularly well suited for modeling sensory and streaming data. When predicting future behavior, incorporating information from neighboring sensor stations is often beneficial. We propose a new RNN based architecture for context specific information fusion across multiple spatially distributed sensor stations. Hereby, latent representations of multiple local models, each modeling one sensor station, are jointed and weighted, according to their importance for the prediction. The particular importance is assessed depending on the current context using a separate attention function. We demonstrate the effectiveness of our model on three different real-world sensor network datasets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-135.pdf,2017,100.0,"Attention-based Information Fusion using Multi-Encoder-Decoder Recurrent Neural Networks With the rising number of interconnected devices and sensors, modeling distributed sensor networks is of increasing interest. Recurrent neural networks (RNN) are considered particularly well suited for modeling sensory and streaming data. When predicting future behavior, incorporating information from neighboring sensor stations is often beneficial. We propose a new RNN based architecture for context specific information fusion across multiple spatially distributed sensor stations. Hereby, latent representations of multiple local models, each modeling one sensor station, are jointed and weighted, according to their importance for the prediction. The particular importance is assessed depending on the current context using a separate attention function. We demonstrate the effectiveness of our model on three different real-world sensor network datasets."
Application of Tensor and Matrix Completion on Environmental Sensing Data,"Michalis Giannopoulos, Sofia Savvaki, Grigorios Tsagkatakis, Panagiotis Tsakalides","1 - -Institute of Computer Science Foundation for Research and Technology Hellas (FORTH) Heraklion 70013 Greece
2 - Department of Computer Science University of Crete Heraklion 70013 Greece","As environmental resources utilization becomes more and more crucial, Wireless Sensor Networks (WSNs) are introduced in order to capture the variation of diverse parameters. However, limitations such as network connectivity, power consumption, and storage capacity lead to missing measurements from such networked sensors. To address this problem, we investigate the potential of recovering high dimensional environmental signals from small sets of observations. To account for the dimensionality of the data, we invoke tensor modelling and we propose a low-rank tensor recovery formulation. Experimental results using real WSN data from an indoor industrial environment as well as from an outdoor natural environment demonstrate that the estimation of missing measurements is much better addressed when structural information is considered.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-136.pdf,2017,100.0,"Application of Tensor and Matrix Completion on Environmental Sensing Data As environmental resources utilization becomes more and more crucial, Wireless Sensor Networks (WSNs) are introduced in order to capture the variation of diverse parameters. However, limitations such as network connectivity, power consumption, and storage capacity lead to missing measurements from such networked sensors. To address this problem, we investigate the potential of recovering high dimensional environmental signals from small sets of observations. To account for the dimensionality of the data, we invoke tensor modelling and we propose a low-rank tensor recovery formulation. Experimental results using real WSN data from an indoor industrial environment as well as from an outdoor natural environment demonstrate that the estimation of missing measurements is much better addressed when structural information is considered."
A neuro-symbolic approach to GPS trajectory classification,"Raul Barbosa, Douglas Cardoso, Diego Carvalho, Felipe França, -Coord Eng, Cefet Da Computação -Pt, Rj, Brazil","1 - PESC/COPPE UFRJ Brazil
3 - PPPRO CEFET/RJ Brazil","This paper proposes approaches to GPS trajectory classification problem in the context of the Rio de Janeiro's public transit system (with hundreds or more classes). We adopt a weightless neural network architecture combined with both spatial partition and multiclass decision graphs, inspired by a neuro-symbolic sense of adding knowledge from the domain as opposed to the use of a raw machine learning. Experimental results show performance boosts when using some of the proposed strategies.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-138.pdf,2017,100.0,"A neuro-symbolic approach to GPS trajectory classification This paper proposes approaches to GPS trajectory classification problem in the context of the Rio de Janeiro's public transit system (with hundreds or more classes). We adopt a weightless neural network architecture combined with both spatial partition and multiclass decision graphs, inspired by a neuro-symbolic sense of adding knowledge from the domain as opposed to the use of a raw machine learning. Experimental results show performance boosts when using some of the proposed strategies."
Comparison of manual and semi-manual delineations for classifying glioblastoma multiforme patients based on histogram and texture MRI features,"Adrian Ion-Mȃrgineanu, Sofie Van Cauter, Diana Sima, Frederik Maes, Stefan Sunaert, Uwe Himmelreich, Sabine Van Huffel","1 - -KU Leuven -ESAT -STADIUS 2-imec Leuven, Leuven Belgium, Belgium
2 - Department of Radiology University Hospitals of Leuven Leuven Belgium
4 - -KU Leuven -ESAT -PSI 5-KU Leuven, Leuven Belgium
5 - Department of Imaging and Pathology Biomedical MRI/MoSAIC Leuven Belgium",In this paper we study the task of classifying the follow-up course of brain tumour patients that had surgery. Multiple magnetic resonance imaging brain scans were taken for each patient. We propose a simple method of delineating the contrast enhancing tumour lesion based on the total tumour region. We compare balanced accuracy values after tuning SVM-lin and SVM-rbf on histogram and 3-D texture features extracted from semi-manual and manual delineations. Results show that our proposed delineating method outperforms the classical method.,"Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-139.pdf,2017,100.0,Comparison of manual and semi-manual delineations for classifying glioblastoma multiforme patients based on histogram and texture MRI features In this paper we study the task of classifying the follow-up course of brain tumour patients that had surgery. Multiple magnetic resonance imaging brain scans were taken for each patient. We propose a simple method of delineating the contrast enhancing tumour lesion based on the total tumour region. We compare balanced accuracy values after tuning SVM-lin and SVM-rbf on histogram and 3-D texture features extracted from semi-manual and manual delineations. Results show that our proposed delineating method outperforms the classical method.
Fast Hyperparameter Selection for Graph Kernels via Subsampling and Multiple Kernel Learning,"Michele Donini, Nicolò Navarin, Ivano Lauriola, Fabio Aiolli, Fabrizio Costa","1 - Computational Statistics and Machine Learning (CSML) Istituto Italiano di Tecnologia Via Morego 30 Genova Italy
2 - Department of Mathematics University of Padova via Trieste 63 Padova Italy
5 - Department of Computer Science University of Exeter EX4 4QF Exeter UK","Model selection is one of the most computationally expensive tasks in a machine learning application. When dealing with kernel methods for structures, the choice with the largest impact on the overall performance is the selection of the feature bias, i.e. the choice of the concrete kernel for structures. Each kernel in turn exposes several hyper-parameters which also need to be fine tuned. Multiple Kernel Learning offers a way to approach this computational bottleneck by generating a combination of different kernels under different parametric settings. However, this solution still requires the computation of many large kernel matrices. In this paper we propose a method to efficiently select a small number of kernels on a subset of the original data, gaining a dramatic reduction in the runtime without a significant loss of predictive performance.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-140.pdf,2017,82.6086956521739,"Fast Hyperparameter Selection for Graph Kernels via Subsampling and Multiple Kernel Learning Model selection is one of the most computationally expensive tasks in a machine learning application. When dealing with kernel methods for structures, the choice with the largest impact on the overall performance is the selection of the feature bias, i.e. the choice of the concrete kernel for structures. Each kernel in turn exposes several hyper-parameters which also need to be fine tuned. Multiple Kernel Learning offers a way to approach this computational bottleneck by generating a combination of different kernels under different parametric settings. However, this solution still requires the computation of many large kernel matrices. In this paper we propose a method to efficiently select a small number of kernels on a subset of the original data, gaining a dramatic reduction in the runtime without a significant loss of predictive performance."
ELM vs. WiSARD: a performance comparison,"Fernando Luiz, Felipe Oliveira, França",1 - Systems Engineering and Computer Science Program COPPE Universidade Federal do Rio de Janeiro RJ Brazil,"The extreme learning machine (ELM) is known for being a fast learning neural model. This work presents a performance comparison between ELM and the WiSARD weightless neural network model, regarding training and testing times, and classification accuracy as well. The two models were implemented in the same programming language and experiments were carried out on the same hardware environment. By using a group of datasets from the public repositories UCI and Statlog, experimental results shows that the WiSARD presented training times approximately one order of magnitude smaller than ELM, while classification accuracy varied according the number of classes involved. However, while WiSARD's architecture setups were not exhaustively searched, architecture setups for ELM were kept the same as the ones found in the literature as the best for each given dataset.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-141.pdf,2017,100.0,"ELM vs. WiSARD: a performance comparison The extreme learning machine (ELM) is known for being a fast learning neural model. This work presents a performance comparison between ELM and the WiSARD weightless neural network model, regarding training and testing times, and classification accuracy as well. The two models were implemented in the same programming language and experiments were carried out on the same hardware environment. By using a group of datasets from the public repositories UCI and Statlog, experimental results shows that the WiSARD presented training times approximately one order of magnitude smaller than ELM, while classification accuracy varied according the number of classes involved. However, while WiSARD's architecture setups were not exhaustively searched, architecture setups for ELM were kept the same as the ones found in the literature as the best for each given dataset."
High dimensionality voltammetric biosensor data processed with artificial neural networks,"Andreu González-Calabuig, Georgina Faura, Manel Del Valle","1 - Department of Chemistry Sensors and Biosensors Group Universitat Autònoma de Barcelona Edifici Cn 08193 Bellaterra, Barcelona Spain","This work report the coupling of an array of voltammetric sensors with artificial neural networks (ANN), usually named Electronic Tongue, for the simultaneous quantification of tryptophan, tyrosine and cysteine aminoacids. The obtained signals were compressed using fast Fourier transform (FFT) and then the ANN model was constructed from a set of low-frequency components. An ANN predictive model was obtained by back-propagation, which had 160 input neurons, one hidden layer with 7 neurons and used purelin and satlins functions in the hidden and output layer respectively, trained with a factorial design scheme . The model attained a total normalized root mean square error of 0.032 for an independent test set of data (n=15).",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-149.pdf,2017,100.0,"High dimensionality voltammetric biosensor data processed with artificial neural networks This work report the coupling of an array of voltammetric sensors with artificial neural networks (ANN), usually named Electronic Tongue, for the simultaneous quantification of tryptophan, tyrosine and cysteine aminoacids. The obtained signals were compressed using fast Fourier transform (FFT) and then the ANN model was constructed from a set of low-frequency components. An ANN predictive model was obtained by back-propagation, which had 160 input neurons, one hidden layer with 7 neurons and used purelin and satlins functions in the hidden and output layer respectively, trained with a factorial design scheme . The model attained a total normalized root mean square error of 0.032 for an independent test set of data (n=15)."
Learning human behaviors and lifestyle by capturing temporal relations in mobility patterns,"Eyal Zion, Boaz Lerner",1 - Ben-Gurion University of the Negev Beer Sheva Israel,"Many applications benefit from learning human behaviors and lifestyle. Different trajectories can represent a behavior, and previous behaviors and trajectories can influence decisions on further behaviors and on visiting future places and taking familiar or new trajectories. To more accurately explain and predict personal behavior, we extend a topic model to capture temporal relations among previous trajectories/weeks and current ones. In addition, we show how different trajectories may have the same latent cause, which we relate to lifestyle. The code for our algorithm is available online.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-152.pdf,2017,100.0,"Learning human behaviors and lifestyle by capturing temporal relations in mobility patterns Many applications benefit from learning human behaviors and lifestyle. Different trajectories can represent a behavior, and previous behaviors and trajectories can influence decisions on further behaviors and on visiting future places and taking familiar or new trajectories. To more accurately explain and predict personal behavior, we extend a topic model to capture temporal relations among previous trajectories/weeks and current ones. In addition, we show how different trajectories may have the same latent cause, which we relate to lifestyle. The code for our algorithm is available online."
Myoelectrical signal classification based on S transform and two-directional 2DPCA,"Hong-Bo Xie, Hui Liu","1 - -ARC Centre of Excellence for Mathematical and Statistical Frontiers Queensland University of Technology
2 - School of Electrical Information Engineering Jiangsu University Zhenjiang 212013 China
3 - 4000 Brisbane QLD Australia","In order to extract discriminative information, time-frequency matrix is often transformed into a 1D vector followed by principal component analysis. This study contributes a two-directional two-dimensional principal component analysis (2D 2 PCA) based technique for time-frequency feature extraction. 2D 2 PCA is directly conducted on the time-frequency matrix obtained from the S transform rather than 1D vectors for feature extraction. The proposed method can significantly reduce the computational cost while capture the directions of maximal time-frequency matrix variance. The efficiency and effectiveness of the proposed method is demonstrated by classifying eight hand motions using four-channel myoelectric signals recorded in health subjects and amputees.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-16.pdf,2017,100.0,"Myoelectrical signal classification based on S transform and two-directional 2DPCA In order to extract discriminative information, time-frequency matrix is often transformed into a 1D vector followed by principal component analysis. This study contributes a two-directional two-dimensional principal component analysis (2D 2 PCA) based technique for time-frequency feature extraction. 2D 2 PCA is directly conducted on the time-frequency matrix obtained from the S transform rather than 1D vectors for feature extraction. The proposed method can significantly reduce the computational cost while capture the directions of maximal time-frequency matrix variance. The efficiency and effectiveness of the proposed method is demonstrated by classifying eight hand motions using four-channel myoelectric signals recorded in health subjects and amputees."
The Top 10 Topics in Machine Learning Revisited: A Quantitative Meta-Study,"Patrick Glauner, Manxing Du, Victor Paraschiv, Andrey Boytsov, Isabel Andrade, Jorge Meira, Petko Valtchev, Radu State","1 - Interdisciplinary Centre for Security, Reliability and Trust University of Luxembourg 4 rue Alphonse Weicker 2721 Luxembourg Luxembourg
3 - Numbers of others London United Kingdom
5 - American Express Sussex House Civic Way RH15 9AQ Burgess Hill United Kingdom
8 - Department of Computer Science av. President Kennedy University of Quebec 201, H2X 3Y7 Montreal, Montreal Canada","Which topics of machine learning are most commonly addressed in research? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers. In our study, we revisit this question from a quantitative perspective. Concretely, we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences. We then use machine learning in order to determine the top 10 topics in machine learning. We not only include models, but provide a holistic view across optimization, data, features, etc. This quantitative approach allows reducing the bias of surveys. It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are. This allows researchers to identify popular topics as well as new and rising topics for their research.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-17.pdf,2017,100.0,"The Top 10 Topics in Machine Learning Revisited: A Quantitative Meta-Study Which topics of machine learning are most commonly addressed in research? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers. In our study, we revisit this question from a quantitative perspective. Concretely, we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences. We then use machine learning in order to determine the top 10 topics in machine learning. We not only include models, but provide a holistic view across optimization, data, features, etc. This quantitative approach allows reducing the bias of surveys. It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are. This allows researchers to identify popular topics as well as new and rising topics for their research."
Partition-wise Recurrent Neural Networks for Point-based AIS Trajectory Classification,"Xiang Jiang, Erico De Souza, Xuan Liu, Haji Behrouz, Soleimani, Xiaoguang Wang, Daniel Silver, Stan Matwin","1 - Faculty of Computer Science Dalhousie University Halifax NS Canada
2 - Institute for Big Data Analytics Dalhousie University Halifax NS Canada
8 - Jodrey School of Computer Science Acadia University Wolfville NS Canada
9 - Institute of Computer Science Polish Academy of Sciences Warsaw Poland","We present Partition-wise Recurrent Neural Networks (pRNNs) for point-based trajectory classification to detect fishing activities in the ocean. This method partitions each feature and uses region-specific parameters for distinct partitions, which can greatly improve the expressive power of deep recurrent neural networks on low-dimensional yet heterogeneous trajectory data. We show that our approach outperforms the state-of-the-art systems.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-18.pdf,2017,100.0,"Partition-wise Recurrent Neural Networks for Point-based AIS Trajectory Classification We present Partition-wise Recurrent Neural Networks (pRNNs) for point-based trajectory classification to detect fishing activities in the ocean. This method partitions each feature and uses region-specific parameters for distinct partitions, which can greatly improve the expressive power of deep recurrent neural networks on low-dimensional yet heterogeneous trajectory data. We show that our approach outperforms the state-of-the-art systems."
Biomedical data analysis in translational research: Integration of expert knowledge and interpretable models,"G Bhanot, M Biehl, T Villmann, D Zühlke","1 - Department of Molecular Biology and Biochemistry Piscataway -Rutgers University 08854 NJ USA
2 - Johann Bernoulli Institute for Mathematics and Computer Science University of Groningen Nijenborgh 9 9747AG Groningen The Netherlands
3 - Computational Intelligence Group University of Applied Sciences Technikumplatz 17 D-09648 Mittweida Germany
4 - Seven Principles AG Erna-Scheffler-Str. 1A D-51103 Köln Germany","In various fields of biomedical research, the availability of electronic data has increased tremendously. Not only is the amount of disease specific data increasing, but so is its structural complexity in terms of dimensionality, multi-modality and inhomogeneity. Consequently, there is an urgent need for better coordination between bio-medical and computational researchers in order to make an impact on patient care. In any such effort, the integration of expert knowledge is essential. A careful synthesis of good analytical techniques applied to relevant medical questions would make the analysis both accurate and interpretable and facilitate transdisciplinary collaboration. This article summarizes recent challenges and introduces the contributions to this ESANN special session. * The authors thank the Leibniz Center for Informatics -Schloss Dagstuhl for the organization and support of Seminar 16261  [14] , where the idea for this ESANN 2017 special session was initiated.",Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-2.pdf,2017,88.88888888888889,"Biomedical data analysis in translational research: Integration of expert knowledge and interpretable models In various fields of biomedical research, the availability of electronic data has increased tremendously. Not only is the amount of disease specific data increasing, but so is its structural complexity in terms of dimensionality, multi-modality and inhomogeneity. Consequently, there is an urgent need for better coordination between bio-medical and computational researchers in order to make an impact on patient care. In any such effort, the integration of expert knowledge is essential. A careful synthesis of good analytical techniques applied to relevant medical questions would make the analysis both accurate and interpretable and facilitate transdisciplinary collaboration. This article summarizes recent challenges and introduces the contributions to this ESANN special session. * The authors thank the Leibniz Center for Informatics -Schloss Dagstuhl for the organization and support of Seminar 16261  [14] , where the idea for this ESANN 2017 special session was initiated."
Non-negative Matrix Factorization as a pre-processing tool for travelers temporal profiles clustering,"Léna Carel, Pierre Alquier","1 - CREST ENSAE Université Paris Saclay 3 avenue Pierre Larousse 92245 Malakoff CEDEX -France
2 - TRANSDEV Group 32 boulevard Gallieni 92130 Issy-les-Moulineaux France",We propose to use non-negative matrix factorization (NMF) to build a dictionary of travelers temporal profiles. Clustering based on decomposition in this dictionary rather than on the full profiles (as in previous works) lead to more interpretable clusters.,"Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-22.pdf,2017,79.20792079207921,Non-negative Matrix Factorization as a pre-processing tool for travelers temporal profiles clustering We propose to use non-negative matrix factorization (NMF) to build a dictionary of travelers temporal profiles. Clustering based on decomposition in this dictionary rather than on the full profiles (as in previous works) lead to more interpretable clusters.
Collaborative Filtering with Neural Networks,"Josef Feigl, Martin Bogdan",1 - Department of Computer Engineering University of Leipzig Augustusplatz 10 04109 Leipzig Germany,"Collaborative filtering methods try to determine a user's preferences given their historical usage data. In this paper, a flexible neural network architecture to solve collaborative filtering problems is reviewed and further developed. It will be shown how modern adaptive learning rate methods can be modified to allow the network to be trained in about half the time without sacrificing any predictive performance. Additionally, the effects of Dropout on the performance of the model are evaluated. The results of this approach are demonstrated on the Netflix Prize dataset.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-23.pdf,2017,93.18181818181819,"Collaborative Filtering with Neural Networks Collaborative filtering methods try to determine a user's preferences given their historical usage data. In this paper, a flexible neural network architecture to solve collaborative filtering problems is reviewed and further developed. It will be shown how modern adaptive learning rate methods can be modified to allow the network to be trained in about half the time without sacrificing any predictive performance. Additionally, the effects of Dropout on the performance of the model are evaluated. The results of this approach are demonstrated on the Netflix Prize dataset."
A Simple Cluster Validation Index with Maximal Coverage,"Susanne Jauhiainen, Tommi Kärkkäinen",1 - Department of Mathematical Information Technology University of Jyvaskyla Finland,"Clustering is an unsupervised technique to detect general, distinct profiles from a given dataset. Similarly to the existence of various different clustering methods and algorithms, there exists many cluster validation methods and indices to suggest the number of clusters. The purpose of this paper is, firstly, to propose a new, simple internal cluster validation index. The index has a maximal coverage: also one cluster, i.e., lack of division of a dataset into disjoint subsets, can be detected. Secondly, the proposed index is compared to the available indices from five different packages implemented in R or Matlab to assess its utilizability. The comparison also suggests many interesting findings in the available implementations of the existing indices. The experiments and the comparison support the viability of the proposed cluster validation index.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-24.pdf,2017,100.0,"A Simple Cluster Validation Index with Maximal Coverage Clustering is an unsupervised technique to detect general, distinct profiles from a given dataset. Similarly to the existence of various different clustering methods and algorithms, there exists many cluster validation methods and indices to suggest the number of clusters. The purpose of this paper is, firstly, to propose a new, simple internal cluster validation index. The index has a maximal coverage: also one cluster, i.e., lack of division of a dataset into disjoint subsets, can be detected. Secondly, the proposed index is compared to the available indices from five different packages implemented in R or Matlab to assess its utilizability. The comparison also suggests many interesting findings in the available implementations of the existing indices. The experiments and the comparison support the viability of the proposed cluster validation index."
Using Degree Constrained Gravity Null-Models to understand the structure of journeys' networks in Bicycle Sharing Systems,"Remy Cazabet, Pierre Borgnat, Pablo Jensen","1 - Sorbonne Universites UPMC Univ Paris 06 CNRS LIP6 UMR 7606 Paris France
2 - Univ Lyon Ens de Lyon
3 - Laboratoire de Physique Univ Claude Bernard CNRS Lyon France","Bicycle Sharing Systems are now ubiquitous in large cities around the world. In most of these systems, journeys' data can be extracted, providing rich information to better understand it. Recent works have used network based-machine learning, and in particular space-corrected node clustering, to analyse such datasets. In this paper, we show that spatial-null models used in previous methods have a systematic bias, and we propose a degree-contrained null-model to improve the results. We finally apply the proposed method on the BSS of a city.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-25.pdf,2017,68.59504132231405,"Using Degree Constrained Gravity Null-Models to understand the structure of journeys' networks in Bicycle Sharing Systems Bicycle Sharing Systems are now ubiquitous in large cities around the world. In most of these systems, journeys' data can be extracted, providing rich information to better understand it. Recent works have used network based-machine learning, and in particular space-corrected node clustering, to analyse such datasets. In this paper, we show that spatial-null models used in previous methods have a systematic bias, and we propose a degree-contrained null-model to improve the results. We finally apply the proposed method on the BSS of a city."
ELM Preference Learning for Physiological Data,"Davide Bacciu, Michele Colombo, Davide Morelli, David Plans","1 - Dipartimento di Informatica Università di Pisa Italy
3 - BioBeats Group Ltd -London UK
6 - Center for Digital Economy University of Surrey UK","The work confronts two approaches to realize preference learning using Extreme Learning Machine networks, relaying on limited and subject-dependant information concerning pairwise relations between data samples. We describe an application within the context of assessing the effect of breathing exercises on heart-rate variability, using a dataset of over 19K exercising sessions. Results highlight the importance of using weight sharing architectures to learn smooth and generalizable complete orders induced by the preference relation.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-27.pdf,2017,100.0,"ELM Preference Learning for Physiological Data The work confronts two approaches to realize preference learning using Extreme Learning Machine networks, relaying on limited and subject-dependant information concerning pairwise relations between data samples. We describe an application within the context of assessing the effect of breathing exercises on heart-rate variability, using a dataset of over 19K exercising sessions. Results highlight the importance of using weight sharing architectures to learn smooth and generalizable complete orders induced by the preference relation."
A Performance Acceleration Algorithm of Spectral Unmixing via Subset Selection,"Jing Ke, Yi Guo, Arcot Sowmya, Tomasz Bednarz","1 - School of Computer Science and Engineering University of New South Wales
2 - School of Computing, Engineering and Mathematics Commonwealth Scientific and Industrial Research Organization Data 61 (CSIRO Data 61) 3
3 - Western Sydney University Sydney Australia",An acceleration algorithm for spectral unmixing approach is proposed based on subset selection. The method classifies the pixels in a spectral image into accurate and approximated unmixing groups based on the similarity and dissimilarity of geomorphological features in neighboring areas. Real spectral images are used for unmixing benchmark tests for accuracy and performance verification. The results reveal good performance speedup with only small accuracy loss.,"Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-29.pdf,2017,87.17948717948718,A Performance Acceleration Algorithm of Spectral Unmixing via Subset Selection An acceleration algorithm for spectral unmixing approach is proposed based on subset selection. The method classifies the pixels in a spectral image into accurate and approximated unmixing groups based on the similarity and dissimilarity of geomorphological features in neighboring areas. Real spectral images are used for unmixing benchmark tests for accuracy and performance verification. The results reveal good performance speedup with only small accuracy loss.
"Processing, mining and visualizing massive urban data","Pierre Borgnat, Etienne Côme, Latifa Oukhellou","1 - Laboratoire de Physique de l' École normale supérieure de Lyon CNRS Université de Lyon 46 allée d'Italie F-69364 Lyon Cedex 7 France
2 - Université Paris-Est, COSYS GRETTIA F-77447 Marne-la-Vallée IFSTTAR France","The development of smart technologies and the advent of new observation capabilities have increased the availability of massive urban datasets that can greatly benefit urban studies. For example, a large amount of urban data is collected by various sensors, such as smart meters, or provided by GSM, Wi-Fi or Bluetooth records, ticketing data, geotagged posts on social networks, etc. Analysis of such digital records can help to build decision-making tools (for analytical, forecasting and display purposes) with a view to better understanding the operating of urban systems, to enable urban stakeholders to plan better when extending infrastructures and to provide better services to citizens in order to assist the development of the city and improve quality of life. This paper will focus on three main domains of application: transportation and mobility, water and energy.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-3.pdf,2017,100.0,"Processing, mining and visualizing massive urban data The development of smart technologies and the advent of new observation capabilities have increased the availability of massive urban datasets that can greatly benefit urban studies. For example, a large amount of urban data is collected by various sensors, such as smart meters, or provided by GSM, Wi-Fi or Bluetooth records, ticketing data, geotagged posts on social networks, etc. Analysis of such digital records can help to build decision-making tools (for analytical, forecasting and display purposes) with a view to better understanding the operating of urban systems, to enable urban stakeholders to plan better when extending infrastructures and to provide better services to citizens in order to assist the development of the city and improve quality of life. This paper will focus on three main domains of application: transportation and mobility, water and energy."
Approximate operations in Convolutional Neural Networks with RNS data representation,"Valentina Arrigoni, Beatrice Rossi, Pasqualina Fragneto, Giuseppe Desoli","1 - Dipartimento di Matematica via Saldini 50 Università degli Studi di Milano Milan Italy
2 - STMicroelectronics -AST via Olivetti 2 Agrate Brianza -Italy","In this work we modify the inference stage of a generic CNN by approximating computations using a data representation based on a Residue Number System at low-precision and introducing rescaling stages for weights and activations. In particular, we exploit an innovative procedure to tune up the system parameters that handles the reduced resolution while minimizing rounding and overflow errors. Our method decreases the hardware complexity of dot product operators and enables a parallelized implementation operating on values represented with few bits, with minimal loss in the overall accuracy of the network.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-30.pdf,2017,100.0,"Approximate operations in Convolutional Neural Networks with RNS data representation In this work we modify the inference stage of a generic CNN by approximating computations using a data representation based on a Residue Number System at low-precision and introducing rescaling stages for weights and activations. In particular, we exploit an innovative procedure to tune up the system parameters that handles the reduced resolution while minimizing rounding and overflow errors. Our method decreases the hardware complexity of dot product operators and enables a parallelized implementation operating on values represented with few bits, with minimal loss in the overall accuracy of the network."
Extracting Urban Water Usage Habits from Smart Meter Data: a Functional Clustering Approach,"N Cheifetz, A Samé, Z Noumir, A.-C Sandraz, C Féliers, V Heim","1 - Université Paris-Est IFSTTAR COSYS 3-Syndicat des Eaux d'Ile de France, 120 Boulevard Saint-Germain F-77447, F-75006 Marne-la-Vallée, Paris GRETTIA
3 - 1-Veolia Eau d'Ile de France, 28 Boulevard de Pesaro F-92751 Nanterre","Through automated meter reading systems, recent development of smart grids offers the opportunity for an efficient and responsible management of water resources. The present paper describes a novel methodology for identifying relevant usage profiles from hourly water consumption series collected by smart meters located on a water distribution network. The proposed approach operates in two stages. First, an additive time series decomposition model is used in order to extract seasonal patterns from the time series. Then, two functional clustering approaches are used to group the extracted seasonal patterns into homogeneous clusters: a functional version of the well-known K-means algorithm, and a Fourier regression mixture-model-based algorithm. The two clustering strategies are applied to real world data from a smart grid deployed on a large water distribution network in France and a realistic interpretation of the consumption habits is given to each cluster.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-31.pdf,2017,71.42857142857143,"Extracting Urban Water Usage Habits from Smart Meter Data: a Functional Clustering Approach Through automated meter reading systems, recent development of smart grids offers the opportunity for an efficient and responsible management of water resources. The present paper describes a novel methodology for identifying relevant usage profiles from hourly water consumption series collected by smart meters located on a water distribution network. The proposed approach operates in two stages. First, an additive time series decomposition model is used in order to extract seasonal patterns from the time series. Then, two functional clustering approaches are used to group the extracted seasonal patterns into homogeneous clusters: a functional version of the well-known K-means algorithm, and a Fourier regression mixture-model-based algorithm. The two clustering strategies are applied to real world data from a smart grid deployed on a large water distribution network in France and a realistic interpretation of the consumption habits is given to each cluster."
Spikes as Regularizers,Anders Søgaard,1 - Department of Computer Science Copenhagen University of Copenhagen DK-2200 Denmark,"We present a confidence-based single-layer feed-forward learning algorithm Spiral (Spike Regularized Adaptive Learning) relying on an encoding of activation spikes. We adaptively update a weight vector relying on confidence estimates and activation offsets relative to previous activity. We regularize updates proportionally to item-level confidence and weightspecific support, loosely inspired by the observation from neurophysiology that high spike rates are sometimes accompanied by low temporal precision. Our experiments suggest that the new learning algorithm Spiral is more robust and less prone to overfitting than both the averaged perceptron and Arow.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-32.pdf,2017,50.0,"Spikes as Regularizers We present a confidence-based single-layer feed-forward learning algorithm Spiral (Spike Regularized Adaptive Learning) relying on an encoding of activation spikes. We adaptively update a weight vector relying on confidence estimates and activation offsets relative to previous activity. We regularize updates proportionally to item-level confidence and weightspecific support, loosely inspired by the observation from neurophysiology that high spike rates are sometimes accompanied by low temporal precision. Our experiments suggest that the new learning algorithm Spiral is more robust and less prone to overfitting than both the averaged perceptron and Arow."
Learning convolutional neural network to maximize Pos@Top performance measure,"Yanyan Geng, Ru-Ze Liang, Weizhi Li, Jingbin Wang, Gaoyuan Liang, Chenhao Xu, Jing-Yan Wang","1 - Provincial Key Laboratory for Computer Information Processing Technology Soochow University 215006 Suzhou China
2 - King Abdullah University of Science and Technology 23955 Thuwal Saudi Arabia
3 - Suning Commerce R&D Center USA, Inc 94304 Palo Alto CA United States
4 - Information Technology Service Center Intermediate People's Court of Linyi City Linyi China
5 - Jiangsu University of Technology 213001 Jiangsu China
6 - New York University Abu Dhabi Abu Dhabi United Arab Emirates","In the machine learning problems, the performance measure is used to evaluate the machine learning models. Recently, the number positive data points ranked at the top positions (Pos@Top) has been a popular performance measure in the machine learning community. In this paper, we propose to learn a convolutional neural network (CNN) model to maximize the Pos@Top performance measure. The CNN model is used to represent the multi-instance data point, and a classifier function is used to predict the label from the its CNN representation. We propose to minimize the loss function of Pos@Top over a training set to learn the filters of CNN and the classifier parameter. The classifier parameter vector is solved by the Lagrange multiplier method, and the filters are updated by the gradient descent method alternately in an iterative algorithm. Experiments over benchmark data sets show that the proposed method outperforms the state-of-the-art Pos@Top maximization methods.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-33.pdf,2017,100.0,"Learning convolutional neural network to maximize Pos@Top performance measure In the machine learning problems, the performance measure is used to evaluate the machine learning models. Recently, the number positive data points ranked at the top positions (Pos@Top) has been a popular performance measure in the machine learning community. In this paper, we propose to learn a convolutional neural network (CNN) model to maximize the Pos@Top performance measure. The CNN model is used to represent the multi-instance data point, and a classifier function is used to predict the label from the its CNN representation. We propose to minimize the loss function of Pos@Top over a training set to learn the filters of CNN and the classifier parameter. The classifier parameter vector is solved by the Lagrange multiplier method, and the filters are updated by the gradient descent method alternately in an iterative algorithm. Experiments over benchmark data sets show that the proposed method outperforms the state-of-the-art Pos@Top maximization methods."
Fine-grained Event Learning of Human-Object Interaction with LSTM-CRF,"Tuan Do, James Pustejovsky",1 - Department of Computer Science Waltham Brandeis University Massachusetts -United States of America,"Event learning is one of the most important problems in AI. However, notwithstanding significant research efforts, it is still a very complex task, especially when the events involve the interaction of humans or agents with other objects, as it requires modeling human kinematics and object movements. This study proposes a methodology for learning complex human-object interaction (HOI) events, involving the recording, annotation and classification of event interactions. For annotation, we allow multiple interpretations of a motion capture by slicing over its temporal span; for classification, we use Long-Short Term Memory (LSTM) sequential models with Conditional Randon Field (CRF) for constraints of outputs. Using a setup involving captures of human-object interaction as three dimensional inputs, we argue that this approach could be used for event types involving complex spatio-temporal dynamics.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-34.pdf,2017,72.46376811594203,"Fine-grained Event Learning of Human-Object Interaction with LSTM-CRF Event learning is one of the most important problems in AI. However, notwithstanding significant research efforts, it is still a very complex task, especially when the events involve the interaction of humans or agents with other objects, as it requires modeling human kinematics and object movements. This study proposes a methodology for learning complex human-object interaction (HOI) events, involving the recording, annotation and classification of event interactions. For annotation, we allow multiple interpretations of a motion capture by slicing over its temporal span; for classification, we use Long-Short Term Memory (LSTM) sequential models with Conditional Randon Field (CRF) for constraints of outputs. Using a setup involving captures of human-object interaction as three dimensional inputs, we argue that this approach could be used for event types involving complex spatio-temporal dynamics."
Scalable approximate k-NN Graph construction based on Locality Sensitive Hashing,"Carlos Eiras-Franco, Leslie Kanthan, Amparo Alonso-Betanzos, David Martínez-Rego","1 - Department of Computer Science University of Corunna
2 - Department of Maths and Computer Science University College London","Nearest neighbours graphs are a pervasive basic construct in areas such as Data mining, Machine Learning and Information Retrieval. Among them, the k Nearest Neighbours Graph (kNNG), is probably the most studied of all. Unfortunately, its naïve construction is in O(n 2 ) for n data points, which becomes a quagmire when scaling to Big Data. However sub-quadratic construction of kNNG remains an open question. This paper explores an adaptive algorithm based on Locality Sensitive Hashing which presents good performance on distributed architectures. * This research has been supported in part by the Spanish Ministerio de Economía y Competitividad (project TIN 2015-65069-C2-1-R), partially funded by FEDER funds of the EU and by the Consellería de Industria of the Xunta de Galicia (project GRC2014/035).",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-35.pdf,2017,100.0,"Scalable approximate k-NN Graph construction based on Locality Sensitive Hashing Nearest neighbours graphs are a pervasive basic construct in areas such as Data mining, Machine Learning and Information Retrieval. Among them, the k Nearest Neighbours Graph (kNNG), is probably the most studied of all. Unfortunately, its naïve construction is in O(n 2 ) for n data points, which becomes a quagmire when scaling to Big Data. However sub-quadratic construction of kNNG remains an open question. This paper explores an adaptive algorithm based on Locality Sensitive Hashing which presents good performance on distributed architectures. * This research has been supported in part by the Spanish Ministerio de Economía y Competitividad (project TIN 2015-65069-C2-1-R), partially funded by FEDER funds of the EU and by the Consellería de Industria of the Xunta de Galicia (project GRC2014/035)."
Outlining a simple and robust method for the automatic detection of EEG arousals,"Isaac Fernández-Varela, Diego Álvarez-Estévez, Elena Hernández-Pereira, Vicente Moret-Bonillo","1 - Departamento de Computación Facultade de Informática Universidade da Coruña Campus de Elviña A Coruña -Spain
2 - Sleep Center & Clinical Neurophysiology Haaglanden Medisch Centrum Lijnbaan 32 2512 VA The Hague -Netherlands","This work proposes a new technique for the automatic detection of electroencephalographic (EEG) arousals in sleep polysomnographic recordings. We have developed a non-computationally complex algorithm with the idea of providing an easy integration into different software platforms. The approach combines different well-known signal analyses to identify relevant arousal patterns. Special emphasis is carried out to produce a robust, artifact tolerant algorithm. The resulting approach was tested using a database of 6 polysomnographic recordings from real patients, achieving an average kappa index of 0.77 with respect to the visual scorings made by clinical experts.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-36.pdf,2017,100.0,"Outlining a simple and robust method for the automatic detection of EEG arousals This work proposes a new technique for the automatic detection of electroencephalographic (EEG) arousals in sleep polysomnographic recordings. We have developed a non-computationally complex algorithm with the idea of providing an easy integration into different software platforms. The approach combines different well-known signal analyses to identify relevant arousal patterns. Special emphasis is carried out to produce a robust, artifact tolerant algorithm. The resulting approach was tested using a database of 6 polysomnographic recordings from real patients, achieving an average kappa index of 0.77 with respect to the visual scorings made by clinical experts."
Algebraic multigrid support vector machines,"Ehsan Sadrfaridpour, Sandeep Jeereddy, Ken Kennedy, Andre Luckow, Talayeh Razzaghi, Ilya Safro","1 - School of Computing Clemson University Clemson SC USA
2 - -Innovation Lab BMW Group IT Research Center Information Management Americas Greenville SC USA","The support vector machine is a flexible optimization-based technique widely used for classification problems. In practice, its training part becomes computationally expensive on large-scale data sets because of such reasons as the complexity and number of iterations in the parameter fitting methods, underlying optimization solvers, and nonlinearity of kernels. We introduce a fast multilevel framework for solving support vector machine models that is inspired by the algebraic multigrid. Significant improvement in the running has been achieved without any loss in the quality. The proposed technique is highly beneficial on imbalanced sets. We demonstrate computational results on publicly available and industrial data sets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-37.pdf,2017,100.0,"Algebraic multigrid support vector machines The support vector machine is a flexible optimization-based technique widely used for classification problems. In practice, its training part becomes computationally expensive on large-scale data sets because of such reasons as the complexity and number of iterations in the parameter fitting methods, underlying optimization solvers, and nonlinearity of kernels. We introduce a fast multilevel framework for solving support vector machine models that is inspired by the algebraic multigrid. Significant improvement in the running has been achieved without any loss in the quality. The proposed technique is highly beneficial on imbalanced sets. We demonstrate computational results on publicly available and industrial data sets."
Predicting Time Series with Space-Time Convolutional and Recurrent Neural Networks,"Wolfgang Groß, Sascha Lange, Joschka Bödecker, Manuel Blum","1 - PSIORI -Freiburg im Breisgau Germany
2 - University of Osnabrück -Institute of Cognitive Science Germany
4 - University of Freiburg -Machine Learning Lab Germany
7 - Addison Fischer Institute for Research and Ethical Use of Artificial Intelligence","Convolutional neural networks (CNNs) with their ability to learn useful spatial features have revolutionized computer vision. The network topology of CNNs exploits the spatial relationship among the pixels in an image and this is one of the reasons for their success. In other domains deep learning has been less successful because it is not clear how the structure of non-spatial data can constrain network topology. Here, we show how multivariate time series can be interpreted as space-time pictures, thus expanding the applicability of the tricks-of-the-trade for CNNs to this important domain. We demonstrate that our model beats more traditional state-of-the-art models at predicting price development on the European Power Exchange (EPEX). Furthermore, we find that the features discovered by CNNs on raw data beat the features that were hand-designed by an expert.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-38.pdf,2017,100.0,"Predicting Time Series with Space-Time Convolutional and Recurrent Neural Networks Convolutional neural networks (CNNs) with their ability to learn useful spatial features have revolutionized computer vision. The network topology of CNNs exploits the spatial relationship among the pixels in an image and this is one of the reasons for their success. In other domains deep learning has been less successful because it is not clear how the structure of non-spatial data can constrain network topology. Here, we show how multivariate time series can be interpreted as space-time pictures, thus expanding the applicability of the tricks-of-the-trade for CNNs to this important domain. We demonstrate that our model beats more traditional state-of-the-art models at predicting price development on the European Power Exchange (EPEX). Furthermore, we find that the features discovered by CNNs on raw data beat the features that were hand-designed by an expert."
A decision support system based on cellular automata to help the control of late blight in tomato cultures,"Gizelle Vianna, Gustavo Oliveira, Gabriel Cunha",1 - Department of Mathematics BR-465 Universidade Federal Rural do Rio de Janeiro Km 7 Seropédica Brazil,"We designed and implemented a decision support system for small tomatoes producers that investigates ways to recognize the late blight disease from the analysis of digital images of tomatoes, using a pair of multilayer perceptron neural network. The networks outputs are used to calculate the damage level at each plant and to construct a situation map of a farm where a cellular automata simulates the outbreak evolution over the fields. The simulator can test different pesticides actions, helping in the decision on when to start the spraying and in the analysis of losses and gains of each choice of action.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-39.pdf,2017,100.0,"A decision support system based on cellular automata to help the control of late blight in tomato cultures We designed and implemented a decision support system for small tomatoes producers that investigates ways to recognize the late blight disease from the analysis of digital images of tomatoes, using a pair of multilayer perceptron neural network. The networks outputs are used to calculate the damage level at each plant and to construct a situation map of a farm where a cellular automata simulates the outbreak evolution over the fields. The simulator can test different pesticides actions, helping in the decision on when to start the spraying and in the analysis of losses and gains of each choice of action."
Hyper-spectral frequency selection for the classification of vegetation diseases,"K Dijkstra, J Van De Loosdrecht, L Schomaker, M Wiering","1 - NHL University of Applied Sciences Centre of Expertise in Computer Vision P.O. Box 1080 8900 CB Leeuwarden Netherlands
2 - Institute of Artificial Intelligence and Cognitive Engineering University of Groningen PO Box 407 9700 AK Groningen Netherlands","Reducing the use of pesticides by early visual detection of diseases in precision agriculture is important. Because of the color similarity between potato-plant diseases, narrow band hyper-spectral imaging is required. Payload constraints on unmanned aerial vehicles require reduction of spectral bands. Therefore, we present a methodology for per-patch classification combined with hyper-spectral band selection. In controlled experiments performed on a set of individual leaves, we measure the performance of five classifiers and three dimensionality-reduction methods with three patch sizes. With the best-performing classifier an error rate of 1.5% is achieved for distinguishing two important potato-plant diseases. 
 Introduction The Netherlands has a leading role in the cultivation and export of seed potatoes, mainly due to their high quality. Monitoring quality and optimizing crop yield are therefore important. Agricultural fields are regularly checked for diseased plants, which are prevented or counteracted using pesticides. Many types of leaf damages can occur, varying from environmental effects [1] to fungal infections. When a disease is incorrectly diagnosed, a wrong treatment could be chosen. For example, pesticides are applied while there is no fungal infection. This could have a negative impact on the environment or even promote resistance to pesticides. Two commonly-confused damages on potato plants are caused by either an Alternaria fungal infection or by exposure to ozone (O 3 ) [2]. Both produce similar brownish lesions on the leaf (Figure  1 ). Alternaria should be treated with pesticides while ozone damage should not. This makes a correct diagnosis important. Unmanned Aerial Vehicles (UAVs) are popular for monitoring agricultural fields  [3] . Examples are vegetation index calculation [4], crop recognition [5] and disease detection  [6] . These applications often use commodity multi-spectral cameras which only measure Blue, Green, Red, Red Edge and Near Infrared spectral wavelengths. These sensors are not particularly suitable for detecting subtle color differences in potato leaf lesions because of their broad spectral sensitivity and limited spectral resolution.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-40.pdf,2017,100.0,"Hyper-spectral frequency selection for the classification of vegetation diseases Reducing the use of pesticides by early visual detection of diseases in precision agriculture is important. Because of the color similarity between potato-plant diseases, narrow band hyper-spectral imaging is required. Payload constraints on unmanned aerial vehicles require reduction of spectral bands. Therefore, we present a methodology for per-patch classification combined with hyper-spectral band selection. In controlled experiments performed on a set of individual leaves, we measure the performance of five classifiers and three dimensionality-reduction methods with three patch sizes. With the best-performing classifier an error rate of 1.5% is achieved for distinguishing two important potato-plant diseases. 
 Introduction The Netherlands has a leading role in the cultivation and export of seed potatoes, mainly due to their high quality. Monitoring quality and optimizing crop yield are therefore important. Agricultural fields are regularly checked for diseased plants, which are prevented or counteracted using pesticides. Many types of leaf damages can occur, varying from environmental effects [1] to fungal infections. When a disease is incorrectly diagnosed, a wrong treatment could be chosen. For example, pesticides are applied while there is no fungal infection. This could have a negative impact on the environment or even promote resistance to pesticides. Two commonly-confused damages on potato plants are caused by either an Alternaria fungal infection or by exposure to ozone (O 3 ) [2]. Both produce similar brownish lesions on the leaf (Figure  1 ). Alternaria should be treated with pesticides while ozone damage should not. This makes a correct diagnosis important. Unmanned Aerial Vehicles (UAVs) are popular for monitoring agricultural fields  [3] . Examples are vegetation index calculation [4], crop recognition [5] and disease detection  [6] . These applications often use commodity multi-spectral cameras which only measure Blue, Green, Red, Red Edge and Near Infrared spectral wavelengths. These sensors are not particularly suitable for detecting subtle color differences in potato leaf lesions because of their broad spectral sensitivity and limited spectral resolution."
Accelerating stochastic kernel SOM,"Jérôme Mariette, Fabrice Rossi, Madalina Olteanu, Nathalie Villa-Vialaneix","1 - MIAT Université de Toulouse INRA 31326 Castanet-Tolosan France
2 - SAMM Université Paris 1 4543, F-75634 Paris EA France","Analyzing non vectorial data has become a common trend in a number of real-life applications. Various prototype-based methods have been extended to answer this need by means of kernalization that embed data into an (implicit) Euclidean space. One drawback of those approaches is their complexity, which is commonly of order the square or the cube of the number of observations. In this paper, we propose an efficient method to reduce complexity of the stochastic kernel SOM. The results are illustrated on large datasets and compared to the standard kernel SOM. The approach has been implemented in the last version of the R package SOMbrero 1 .","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-41.pdf,2017,100.0,"Accelerating stochastic kernel SOM Analyzing non vectorial data has become a common trend in a number of real-life applications. Various prototype-based methods have been extended to answer this need by means of kernalization that embed data into an (implicit) Euclidean space. One drawback of those approaches is their complexity, which is commonly of order the square or the cube of the number of observations. In this paper, we propose an efficient method to reduce complexity of the stochastic kernel SOM. The results are illustrated on large datasets and compared to the standard kernel SOM. The approach has been implemented in the last version of the R package SOMbrero 1 ."
Automatic Crime Report Classification through a Weightless Neural Network,"Rafael Pinho, Walkir Brito, Claudia Motta, Priscila Vieira Lima",1 - Federal University of Rio de Janeiro (UFRJ) Pos-Graduation Program in Informatics (PPGI) Rio de Janeiro RJ Brazil,Anonymous crime reporting is a tool that helps to reduce and prevent crime occurrences. The classification of the crime reports received by the call center is necessary for the data organization and also to stipulate the importance of a particular report and its relation to others. The objective of this work is to develop a system that assists the call center's operator by recommending classification to new reports. The system uses a weightless neural network that automatically attribute a class to a report. At the end of this work it was possible to observe that automatic classifications of crime reports with high accuracy are possible using a weightless neural network.,Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-42.pdf,2017,70.3448275862069,Automatic Crime Report Classification through a Weightless Neural Network Anonymous crime reporting is a tool that helps to reduce and prevent crime occurrences. The classification of the crime reports received by the call center is necessary for the data organization and also to stipulate the importance of a particular report and its relation to others. The objective of this work is to develop a system that assists the call center's operator by recommending classification to new reports. The system uses a weightless neural network that automatically attribute a class to a report. At the end of this work it was possible to observe that automatic classifications of crime reports with high accuracy are possible using a weightless neural network.
Random projection initialization for deep neural networks,"Piotr Wójcik, Marcin Kurdziel","1 - Faculty of Computer Science AGH University of Science and Technology
2 - Electronics and Telecommunications Department of Computer Science al. A. Mickiewicza 30 30-059 Krakow Poland","In this work we propose to initialize rectifier neural networks with random projection matrices. We focus on Convolutional Neural Networks and fully-connected networks with pretraining. Our results show, that in convolutional networks a well designed random projection initialization can perform better than the current state-of-the-art He's initialization. Specifically, in our evaluation, initialization based on the Subsampled Randomized Hadamard Transform consistently outperformed He's initialization on several evaluated image classification datasets.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-43.pdf,2017,100.0,"Random projection initialization for deep neural networks In this work we propose to initialize rectifier neural networks with random projection matrices. We focus on Convolutional Neural Networks and fully-connected networks with pretraining. Our results show, that in convolutional networks a well designed random projection initialization can perform better than the current state-of-the-art He's initialization. Specifically, in our evaluation, initialization based on the Subsampled Randomized Hadamard Transform consistently outperformed He's initialization on several evaluated image classification datasets."
A Robust Minimal Learning Machine based on the M-Estimator,"João Gomes, Diego Mesquita, Ananda Freire, Amauri Souza Junior, Tommi Karkkainen","1 - Department of Computer Science Federal University of Ceará -UFC Fortaleza-CE Brazil
3 - Department of Teleinformatics Federal Institute of Ceará Fortaleza-CE Brazil
5 - Department of Math. Information Technology University of Jyvaskyla Finland","In this paper we propose a robust Minimal Learning Machine (R-RLM) for regression problems. The proposed method uses a robust M-estimator to generate a linear mapping between input and output distances matrices of MLM. The R-MLM was tested on one synthetic and three real world datasets that were contaminated with an increasing number of outliers. The method achieved a performance comparable to the robust Extreme Learning Machine (R-RLM) and thus can be seen as a valid alternative for regression tasks on datasets with outliers. Recently, a new supervised learning method, called Minimal Learning Machine (MLM,  [5] ), was proposed. The technique achieved promising results on applications like face recognition [6] and systems identification  [7] . MLM is based on the idea of the existence of a mapping between the geometric configurations of points in the input and output space. The main advantages of MLM include fast training, simple formulation, and only one hyperparameter to be optimized (number of reference points).","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-44.pdf,2017,100.0,"A Robust Minimal Learning Machine based on the M-Estimator In this paper we propose a robust Minimal Learning Machine (R-RLM) for regression problems. The proposed method uses a robust M-estimator to generate a linear mapping between input and output distances matrices of MLM. The R-MLM was tested on one synthetic and three real world datasets that were contaminated with an increasing number of outliers. The method achieved a performance comparable to the robust Extreme Learning Machine (R-RLM) and thus can be seen as a valid alternative for regression tasks on datasets with outliers. Recently, a new supervised learning method, called Minimal Learning Machine (MLM,  [5] ), was proposed. The technique achieved promising results on applications like face recognition [6] and systems identification  [7] . MLM is based on the idea of the existence of a mapping between the geometric configurations of points in the input and output space. The main advantages of MLM include fast training, simple formulation, and only one hyperparameter to be optimized (number of reference points)."
Investigating Optical Transmission Error Correction using Wavelet Transforms,"Weam Binjumah, Alexey Redyuk, Rod Adams, Neil Davey, Yi Sun","1 - The School of Computer Science University of Hertfordshire AL10 9AB -UK Hatfield
2 - Department of Computer Science The Community College
3 - Taibah University Madinah -KSA
4 - -Institute of Computational Technologies SB RAS Novosibirsk 6 Acad. Lavrentiev avenue 630090 Russia","Reducing bit error rate and improving performance of modern coherent optical communication system is a significant issue. As the distance travelled by the information signal increases, bit error rate will degrade. Support Vector Machines are the most up to date machine learning method for error correction in optical transmission systems. Wavelet transform has been a popular method to signals processing. In this study, results show that the bit error rate can be improved by using classification based on wavelet transforms (WT) and support vector machine (SVM).","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-45.pdf,2017,65.78947368421053,"Investigating Optical Transmission Error Correction using Wavelet Transforms Reducing bit error rate and improving performance of modern coherent optical communication system is a significant issue. As the distance travelled by the information signal increases, bit error rate will degrade. Support Vector Machines are the most up to date machine learning method for error correction in optical transmission systems. Wavelet transform has been a popular method to signals processing. In this study, results show that the bit error rate can be improved by using classification based on wavelet transforms (WT) and support vector machine (SVM)."
Complex activity patterns generated by short-term synaptic plasticity,"Bulcsú Sándor, Claudius Gros",1 - Institute for Theoretical Physics Goethe University Frankfurt Frankfurt am Main Germany,"Short-term synaptic plasticity (STSP) affects the efficiency of synaptic transmission for persistent presynaptic activities. We consider attractor neural networks, for which the attractors are given, in the absence of STSP, by cell assemblies of excitatory cliques. We show that STSP may transform these attracting states into attractor relics, inducing ongoing transient-state dynamics in terms of sequences of transiently activated cell assemblies, the former attractors. Subsequent cell assemblies may be both disjoint or partially overlapping. It may hence be possible to use the resulting dynamics for the generation of motor control sequences.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-47.pdf,2017,100.0,"Complex activity patterns generated by short-term synaptic plasticity Short-term synaptic plasticity (STSP) affects the efficiency of synaptic transmission for persistent presynaptic activities. We consider attractor neural networks, for which the attractors are given, in the absence of STSP, by cell assemblies of excitatory cliques. We show that STSP may transform these attracting states into attractor relics, inducing ongoing transient-state dynamics in terms of sequences of transiently activated cell assemblies, the former attractors. Subsequent cell assemblies may be both disjoint or partially overlapping. It may hence be possible to use the resulting dynamics for the generation of motor control sequences."
Viral Initialization for Spectral Clustering,"Vahan Petrosyan, Alexandre Proutiere",1 - Royal Institute of Technology (KTH) -Department of Automatic Control Stockholm Sweden school,"Spectral Clustering is one of the most widely used clustering algorithms. To find k clusters, it runs the K-means algorithm on the top k eigenvectors of a Laplacian matrix constructed from the data. As a consequence, it inherits the initialization issues of K-means. In this paper, we propose Viral Initialization (VI), a novel initialization procedure implemented in the Spectral Clustering algorithm before K-means is applied. VI is designed so that the resulting clusterings exhibit low normalized cut (Ncuts) values. This design principle is aligned with the recent observation that ""good"" clusterings have low Ncuts values. We show, through extensive numerical experiments, that the Spectral Clustering algorithm with VI consistently outperforms other state-of-the-art clustering techniques. 1 E.g., A ij = exp − ||x i −x j || 2 2σ if i = j and 0 otherwise.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-49.pdf,2017,70.45454545454545,"Viral Initialization for Spectral Clustering Spectral Clustering is one of the most widely used clustering algorithms. To find k clusters, it runs the K-means algorithm on the top k eigenvectors of a Laplacian matrix constructed from the data. As a consequence, it inherits the initialization issues of K-means. In this paper, we propose Viral Initialization (VI), a novel initialization procedure implemented in the Spectral Clustering algorithm before K-means is applied. VI is designed so that the resulting clusterings exhibit low normalized cut (Ncuts) values. This design principle is aligned with the recent observation that ""good"" clusterings have low Ncuts values. We show, through extensive numerical experiments, that the Spectral Clustering algorithm with VI consistently outperforms other state-of-the-art clustering techniques. 1 E.g., A ij = exp − ||x i −x j || 2 2σ if i = j and 0 otherwise."
Training Convolutional Networks with Weight-wise Adaptive Learning Rates,"Alan Mosca, George Magoulas",1 - Department of Computer Science and Information Systems Birkbeck College University of London Malet Street London United Kingdom,"Current state-of-the-art Deep Learning classification with Convolutional Neural Networks achieves very impressive results, which are, in some cases, close to human level performance. However, training these methods to their optimal performance requires very long training periods, usually by applying the Stochastic Gradient Descent method. We show that by applying more modern methods, which involve adapting a different learning rate for each weight rather than using a single, global, learning rate for the entire network, we are able to reach close to state-of-the-art performance on the same architectures, and improve the training time and accuracy.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-50.pdf,2017,77.77777777777779,"Training Convolutional Networks with Weight-wise Adaptive Learning Rates Current state-of-the-art Deep Learning classification with Convolutional Neural Networks achieves very impressive results, which are, in some cases, close to human level performance. However, training these methods to their optimal performance requires very long training periods, usually by applying the Stochastic Gradient Descent method. We show that by applying more modern methods, which involve adapting a different learning rate for each weight rather than using a single, global, learning rate for the entire network, we are able to reach close to state-of-the-art performance on the same architectures, and improve the training time and accuracy."
Generalization Performances of Randomized Classifiers and Algorithms built on Data Dependent Distributions,"Luca Oneto, Sandro Ridella, Davide Anguita","1 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy
2 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy","In this paper we prove that a randomized algorithm based on the data generating dependent prior and data dependent posterior Boltzmann distributions of Catoni (  2007 ) is Differentially Private (DP) and shows better generalization properties than the Gibbs (randomized) classifier associated to the same distributions. For this purpose, we will develop a tight DP-based generalization bound, which improve over the current state-of-the-art Hoeffding-type bound.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-53.pdf,2017,100.0,"Generalization Performances of Randomized Classifiers and Algorithms built on Data Dependent Distributions In this paper we prove that a randomized algorithm based on the data generating dependent prior and data dependent posterior Boltzmann distributions of Catoni (  2007 ) is Differentially Private (DP) and shows better generalization properties than the Gibbs (randomized) classifier associated to the same distributions. For this purpose, we will develop a tight DP-based generalization bound, which improve over the current state-of-the-art Hoeffding-type bound."
Dropout Prediction at University of Genoa: a Privacy Preserving Data Driven Approach,"Luca Oneto, Anna Siri, Gianvittorio Luria, Davide Anguita","1 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy
2 - DIMA -University of Genova Via Dodecaneso 35 I-16146 Genova Italy","Nowadays many educational institutions crucially need to understand the dynamics at the basis of the university dropout (UD) phenomenon. However, the most informative educational data are personal and subject to strict privacy constraints. The challenge is therefore to develop a data driven system which accurately predicts students dropouts while preserving the privacy of individual data instances. In the present paper we investigate this problem, making use of data collected at University of Genoa as a case study.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-54.pdf,2017,100.0,"Dropout Prediction at University of Genoa: a Privacy Preserving Data Driven Approach Nowadays many educational institutions crucially need to understand the dynamics at the basis of the university dropout (UD) phenomenon. However, the most informative educational data are personal and subject to strict privacy constraints. The challenge is therefore to develop a data driven system which accurately predicts students dropouts while preserving the privacy of individual data instances. In the present paper we investigate this problem, making use of data collected at University of Genoa as a case study."
Moving Least Squares Support Vector Machines for weather temperature prediction,"Zahra Karevan, Yunlong Feng, Johan Suykens",1 - KU Leuven ESAT-STADIUS Kasteelpark Arenberg 10 B-3001 Leuven Belgium,"Local learning methods have been investigated by many researchers. While global learning methods consider the same weight for all training points in model fitting, local learning methods assume that the training samples in the test point region are more influential. In this paper, we propose Moving Least Squares Support Vector Machines (M-LSSVM) in which each training sample is involved in the model fitting depending on the similarity between its feature vector and the one of the test point. The experimental results on an application of weather forecasting indicate that the proposed method can improve the prediction performance.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-55.pdf,2017,100.0,"Moving Least Squares Support Vector Machines for weather temperature prediction Local learning methods have been investigated by many researchers. While global learning methods consider the same weight for all training points in model fitting, local learning methods assume that the training samples in the test point region are more influential. In this paper, we propose Moving Least Squares Support Vector Machines (M-LSSVM) in which each training sample is involved in the model fitting depending on the similarity between its feature vector and the one of the test point. The experimental results on an application of weather forecasting indicate that the proposed method can improve the prediction performance."
Uncertain Photometric Redshifts via Combining Deep Convolutional and Mixture Density Networks,"A D'isanto, K Polsterer",1 - Heidelberg Institute for Theoretical Studies (HITS) Schloss-Wolfsbrunnenweg 35 69118 Heidelberg GERMANY,"The need for accurate photometric redshifts estimation is a major subject in Astronomy. This is due to the necessity of efficiently obtaining redshift information without the need for spectroscopic analysis. We propose a method for determining accurate multi-modal predictive densities for redshift, using Mixture Density Networks and Deep Convolutional Networks. A comparison with the Random Forest is carried out and superior performance of the proposed architecture is demonstrated.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-56.pdf,2017,76.34408602150538,"Uncertain Photometric Redshifts via Combining Deep Convolutional and Mixture Density Networks The need for accurate photometric redshifts estimation is a major subject in Astronomy. This is due to the necessity of efficiently obtaining redshift information without the need for spectroscopic analysis. We propose a method for determining accurate multi-modal predictive densities for redshift, using Mixture Density Networks and Deep Convolutional Networks. A comparison with the Random Forest is carried out and superior performance of the proposed architecture is demonstrated."
An EM transfer learning algorithm with applications in bionic hand prostheses,"Benjamin Paaßen, Alexander Schulz, Janne Hahne, Barbara Hammer","1 - CITEC center of excellence Bielefeld University Germany
3 - Department of Trauma Surgery Neurorehabilitaiton Systems Research Group Orthopedic Surgery and Hand Surgery Universiy Medical Center Göttingen Germany","Modern bionic hand prostheses feature unprecedented functionality, permitting motion in multiple degrees of freedom (DoFs). However, conventional user interfaces allow for contolling only one DoF at a time. An intuitive, direct and simultaneous control of multiple DoFs requires machine learning models. Unfortunately, such models are not yet sufficiently robust to real-world disturbances, such as electrode shifts. We propose a novel expectation maximization approach for transfer learning to rapidly recalibrate a machine learning model if disturbances occur. In our experimental evaluation we show that even if few data points are available which do not cover all classes, our proposed approach finds a viable transfer mapping which improves classification accuracy significantly and outperforms all tested baselines. * Funding by the DFG under grant number HA 2719/6-2, the CITEC center of excellence (EXC 277), and the EU-Project ""Input"" (grant number 687795) is gratefully acknowledged.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-57.pdf,2017,100.0,"An EM transfer learning algorithm with applications in bionic hand prostheses Modern bionic hand prostheses feature unprecedented functionality, permitting motion in multiple degrees of freedom (DoFs). However, conventional user interfaces allow for contolling only one DoF at a time. An intuitive, direct and simultaneous control of multiple DoFs requires machine learning models. Unfortunately, such models are not yet sufficiently robust to real-world disturbances, such as electrode shifts. We propose a novel expectation maximization approach for transfer learning to rapidly recalibrate a machine learning model if disturbances occur. In our experimental evaluation we show that even if few data points are available which do not cover all classes, our proposed approach finds a viable transfer mapping which improves classification accuracy significantly and outperforms all tested baselines. * Funding by the DFG under grant number HA 2719/6-2, the CITEC center of excellence (EXC 277), and the EU-Project ""Input"" (grant number 687795) is gratefully acknowledged."
Algorithmic challenges in Big Data analytics,"Verónica Bolón-Canedo, Beatriz Remeseiro, Konstantinos Sechidis, David Martinez-Rego, Amparo Alonso-Betanzos","1 - Departamento de Computación Universidade da Coruña Campus de Elviña s/n 15071 A Coruña Spain
2 - Departament de Matemàtiques i Informàtica Universitat de Barcelona Gran Via de les Corts Catalanes 585 08007 Barcelona Spain
3 - School of Computer Science University of Manchester M13 9PL Manchester UK
4 - Engineering Building University College London Malet Place WC1E 7JE London UK","This session studies specific challenges that Machine Learning (ML) algorithms have to tackle when faced with Big Data problems. These challenges can arise when any of the dimensions in a ML problem grows significantly: a) size of training set, b) size of test set or c) dimensionality. The studies included in this edition explore the extension of previous ML algorithms and practices to Big Data scenarios. Namely, specific algorithms for recurrent neural network training, ensemble learning, anomaly detection and clustering are proposed. The results obtained show that this new trend of ML problems presents both a challenge and an opportunity to obtain results which could allow ML to be integrated in many new applications in years to come. * This research has been partially funded by project TIN-2015-65069-C2-1-R of Ministerio de Economía y Competitividad (MINECO) of the Spanish Government, and Xunta de Galicia project GRC2014/035, both partially funded by FEDER funds of the European Union. Beatriz Remeseiro acknowledges the support of MINECO under Juan de la Cierva Program (ref. FJCI-2014-21194).",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-6.pdf,2017,79.54545454545455,"Algorithmic challenges in Big Data analytics This session studies specific challenges that Machine Learning (ML) algorithms have to tackle when faced with Big Data problems. These challenges can arise when any of the dimensions in a ML problem grows significantly: a) size of training set, b) size of test set or c) dimensionality. The studies included in this edition explore the extension of previous ML algorithms and practices to Big Data scenarios. Namely, specific algorithms for recurrent neural network training, ensemble learning, anomaly detection and clustering are proposed. The results obtained show that this new trend of ML problems presents both a challenge and an opportunity to obtain results which could allow ML to be integrated in many new applications in years to come. * This research has been partially funded by project TIN-2015-65069-C2-1-R of Ministerio de Economía y Competitividad (MINECO) of the Spanish Government, and Xunta de Galicia project GRC2014/035, both partially funded by FEDER funds of the European Union. Beatriz Remeseiro acknowledges the support of MINECO under Juan de la Cierva Program (ref. FJCI-2014-21194)."
Latent variable analysis in hospital electric power demand using non-negative matrix factorization,"Diego García, Ignacio Díaz, Daniel Pérez, Abel Cuadrado, Manuel Domínguez","1 - Electrical Engineering Dept University of Oviedo Edif. Dept Campus de Viesques s/n 33204 Gijón SPAIN
5 - SUPPRESS Research Group University of Leon
6 - Escuela de Ingenierías Campus de Vegazana 24007 León Spain","Energy disaggregation techniques have recently attracted much interest, since they allow to obtain latent patterns from power demand data in buildings, revealing useful information to the user. Unsupervised methods are specially attractive, since they do not require labeled datasets. Particularly, non-negative matrix factorization (NMF) methods allow to decompose a single power demand measurement over a certain time period into a set of components or ""parts"" that are sparse, nonnegative and sum up the original measured quantity. Such components reveal hidden temporal patterns and events along this period, related to scheduling events and/or demand patterns from subsystems in the network, that are very useful within an energy efficiency context. In this paper we use this approach on demand data from a hospital during a oneyear period, using a calendar visualization of the components, revealing relevant facts about the energy expenditure. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO)and FEDER funds from the EU under grant DPI2015-69891-C2-1/2-R.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-60.pdf,2017,100.0,"Latent variable analysis in hospital electric power demand using non-negative matrix factorization Energy disaggregation techniques have recently attracted much interest, since they allow to obtain latent patterns from power demand data in buildings, revealing useful information to the user. Unsupervised methods are specially attractive, since they do not require labeled datasets. Particularly, non-negative matrix factorization (NMF) methods allow to decompose a single power demand measurement over a certain time period into a set of components or ""parts"" that are sparse, nonnegative and sum up the original measured quantity. Such components reveal hidden temporal patterns and events along this period, related to scheduling events and/or demand patterns from subsystems in the network, that are very useful within an energy efficiency context. In this paper we use this approach on demand data from a hospital during a oneyear period, using a calendar visualization of the components, revealing relevant facts about the energy expenditure. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO)and FEDER funds from the EU under grant DPI2015-69891-C2-1/2-R."
Learning Semantic Prediction using Pretrained Deep Feedforward Networks,"Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke, Robert Bosch, Gmbh -70442 Stuttgart -Germany",1 - Computer Science VI University of Bonn Autonomous Intelligent Systems Friedrich-Ebert-Allee 144 53113 Bonn Germany,"The ability to predict future environment states is crucial for anticipative behavior of autonomous agents. Deep learning based methods have proven to solve key perception challenges but currently mainly operate in a non-predictive fashion. We bridge this gap by proposing an approach to transform trained feed-forward networks into predictive ones via a combination of a recurrent predictive module with a teacher-student training strategy. This transformation can be conducted without the need of labeled data in a fully self-supervised fashion. Using simulated data, we demonstrate the ability of the resulting model to temporally predict a task-specific representation and additionally show the benefits of using our approach even when no corresponding feed-forward model is available.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-61.pdf,2017,100.0,"Learning Semantic Prediction using Pretrained Deep Feedforward Networks The ability to predict future environment states is crucial for anticipative behavior of autonomous agents. Deep learning based methods have proven to solve key perception challenges but currently mainly operate in a non-predictive fashion. We bridge this gap by proposing an approach to transform trained feed-forward networks into predictive ones via a combination of a recurrent predictive module with a teacher-student training strategy. This transformation can be conducted without the need of labeled data in a fully self-supervised fashion. Using simulated data, we demonstrate the ability of the resulting model to temporally predict a task-specific representation and additionally show the benefits of using our approach even when no corresponding feed-forward model is available."
Support Vector Components Analysis,"Michiel Van Der Ree, Jos Roerdink, Christophe Phillips, Gaëtan Garraux, Eric Salmon, Marco Wiering","1 - Johann Bernoulli Institute for Mathematics and Computer Science University of Groningen Nijenborgh 9 Groningen The Netherlands
2 - Cyclotron Research Centre University of Liège Allée du Six Aôut 8 B30 Liège Belgium
5 - Institute of Artificial Intelligence Cognitive Engineering University of Groningen Nijenborgh 9 Groningen The Netherlands
6 - 1-Semiotic Labs B.V. Science Park 402 Amsterdam The Netherlands","In this paper we propose a novel method for learning a distance metric in the process of training Support Vector Machines (SVMs) with the radial basis function kernel. A transformation matrix is adapted in such a way that the SVM dual objective of a classification problem is optimized. By using a wide transformation matrix the method can effectively be used as a means of supervised dimensionality reduction. We compare our method with other algorithms on a toy dataset and on PETscans of patients with various Parkinsonisms, finding that our method either outperforms or performs on par with the other algorithms.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-63.pdf,2017,67.64705882352942,"Support Vector Components Analysis In this paper we propose a novel method for learning a distance metric in the process of training Support Vector Machines (SVMs) with the radial basis function kernel. A transformation matrix is adapted in such a way that the SVM dual objective of a classification problem is optimized. By using a wide transformation matrix the method can effectively be used as a means of supervised dimensionality reduction. We compare our method with other algorithms on a toy dataset and on PETscans of patients with various Parkinsonisms, finding that our method either outperforms or performs on par with the other algorithms."
Scholar Performance Prediction using Boosted Regression Trees Techniques,"Bernardo Stearns, Fabio Rangel, Flavio Rangel, Fabrício Firmino De Faria, Jonice Oliveira",1 - Federal University of Rio de Janeiro (UFRJ) Graduate Program in Informatics (PPGI) Av. Athos da S. Ramos 149. Rio de Janeiro RJ Brazil,The possibility of predicting a student performance based only on their socioeconomic status may help to infer what cultural features are important in education. This work was based on scores and socioeconomic data from the most popular exam to enter universities in Brazil: the National High School Exam. Statistical and computational methods used in data mining were applied on a data set of 8 millions data points from Brazil's National High School Exam to examine the predictability of the performance in Mathematics based on socioeconomic status. The results showed that it is possible to predict a students' scores using two ensemble techniques: AdaBoost and Gradient Boosting. The latter presented better results.,"Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-65.pdf,2017,100.0,Scholar Performance Prediction using Boosted Regression Trees Techniques The possibility of predicting a student performance based only on their socioeconomic status may help to infer what cultural features are important in education. This work was based on scores and socioeconomic data from the most popular exam to enter universities in Brazil: the National High School Exam. Statistical and computational methods used in data mining were applied on a data set of 8 millions data points from Brazil's National High School Exam to examine the predictability of the performance in Mathematics based on socioeconomic status. The results showed that it is possible to predict a students' scores using two ensemble techniques: AdaBoost and Gradient Boosting. The latter presented better results.
POKer: a Partial Order Kernel for Comparing Strings with Alternative Substrings,"Maryam Abdollahyan, Fabrizio Smeraldi",1 - School of Electronic Engineering and Computer Science Queen Mary University of London Mile End Road E1 4NS London UK,"We introduce a Partial Order Kernel (POKer) on the weighted sum of local alignment scores that can be used for comparison and classification of strings containing alternative substrings of variable length. POKer is defined over the product of two directed acyclic graphs, each representing a string with alternative substrings, and is computed efficiently using dynamic programming. We evaluate the performance of POKer with Support Vector Machines on a dataset of strings generated by detecting overlapping motifs in a set of simulated DNA sequences. Compared to a generalization of a state-of-the-art string kernel, POKer achieves a higher classification accuracy.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-66.pdf,2017,100.0,"POKer: a Partial Order Kernel for Comparing Strings with Alternative Substrings We introduce a Partial Order Kernel (POKer) on the weighted sum of local alignment scores that can be used for comparison and classification of strings containing alternative substrings of variable length. POKer is defined over the product of two directed acyclic graphs, each representing a string with alternative substrings, and is computed efficiently using dynamic programming. We evaluate the performance of POKer with Support Vector Machines on a dataset of strings generated by detecting overlapping motifs in a set of simulated DNA sequences. Compared to a generalization of a state-of-the-art string kernel, POKer achieves a higher classification accuracy."
Feature Relevance Bounds for Linear Classification,"Christina Göpfert, Lukas Pfannschmidt, Barbara Hammer",1 - CITEC center of excellence Bielefeld University Germany,"Biomedical applications often aim for an identification of relevant features for a given classification task, since these carry the promise of semantic insight into the underlying process. For correlated input dimensions, feature relevances are not unique, and the identification of meaningful subtle biomarkers remains a challenge. One approach is to identify intervals for the possible relevance of given features, a problem related to all-relevant feature determination. In this contribution, we address the important case of linear classifiers and we reformulate the inference of feature relevance bounds as a convex optimization problem. We demonstrate the superiority of the resulting technique in comparison to popular feature-relevance determination methods in several benchmarks. * Funding within the DFG international research training group DiDy (IGK 1906)  and the CITEC center of excellence (EXC 277) is gratefully acknowledged.",Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-67.pdf,2017,100.0,"Feature Relevance Bounds for Linear Classification Biomedical applications often aim for an identification of relevant features for a given classification task, since these carry the promise of semantic insight into the underlying process. For correlated input dimensions, feature relevances are not unique, and the identification of meaningful subtle biomarkers remains a challenge. One approach is to identify intervals for the possible relevance of given features, a problem related to all-relevant feature determination. In this contribution, we address the important case of linear classifiers and we reformulate the inference of feature relevance bounds as a convex optimization problem. We demonstrate the superiority of the resulting technique in comparison to popular feature-relevance determination methods in several benchmarks. * Funding within the DFG international research training group DiDy (IGK 1906)  and the CITEC center of excellence (EXC 277) is gratefully acknowledged."
Fisher Memory of Linear Wigner Echo State Networks,Peter Tiňo,1 - School of Computer Science The University of Birmingham B15 2TT Birmingham United Kingdom,"We study asymptotic properties of Fisher memory of linear Echo State Networks with randomized reservoir coupling prescribed by the class of Wigner matrices. Several properties of Fisher memory normalized per state space dimension are derived. In particular, we show that as the system size grows, the contribution of self-coupling of self-loops on reservoir units to the Fisher memory is negligible. Furthermore, we prove that the maximal Fisher memory is achieved when the input-to-state coupling is colinear with the dominant eigenvector of the state space coupling matrix. Finally, we show that when the input-to-state coupling is colinear with the sum of eigenvectors of the state space coupling, the expected normalized memory is four time smaller than the maximal memory value.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-69.pdf,2017,62.0,"Fisher Memory of Linear Wigner Echo State Networks We study asymptotic properties of Fisher memory of linear Echo State Networks with randomized reservoir coupling prescribed by the class of Wigner matrices. Several properties of Fisher memory normalized per state space dimension are derived. In particular, we show that as the system size grows, the contribution of self-coupling of self-loops on reservoir units to the Fisher memory is negligible. Furthermore, we prove that the maximal Fisher memory is achieved when the input-to-state coupling is colinear with the dominant eigenvector of the state space coupling matrix. Finally, we show that when the input-to-state coupling is colinear with the sum of eigenvectors of the state space coupling, the expected normalized memory is four time smaller than the maximal memory value."
Physical activity recognition from sub-bandage sensors using both feature selection and extraction,"Eleonora D'andrea, Fabio Di, Valentina Dini, Beatrice Lazzerini, Marco Romanelli, Pietro Salvo","1 - Department of Information Engineering University of Pisa
2 - Largo Lucio Lazzarino 1 56122 Pisa Italy
3 - Department of Chemistry and Industrial Chemistry Via Giuseppe Moruzzi University of Pisa 13 56124 Pisa -Italy
4 - Department of Dermatology University of Pisa Wound Healing Research Unit Via Roma 67 56124 Pisa -Italy
9 - National Council of Research -Institute of Clinical Physiology (IFC-CNR Via Moruzzi 1 56124 Pisa Italy","In this paper, we present a neural network-based approach to classify the activities performed by 40 subjects by analyzing sub-bandage pressure signals. The approach includes an input dimensionality reduction obtained employing both feature extraction and feature selection techniques. The results show that our model is able to classify the activities performed with 98.12% accuracy.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-70.pdf,2017,100.0,"Physical activity recognition from sub-bandage sensors using both feature selection and extraction In this paper, we present a neural network-based approach to classify the activities performed by 40 subjects by analyzing sub-bandage pressure signals. The approach includes an input dimensionality reduction obtained employing both feature extraction and feature selection techniques. The results show that our model is able to classify the activities performed with 98.12% accuracy."
Large-scale nonlinear dimensionality reduction for network intrusion detection,"Yasir Hamid, Ludovic Journaux, John Lee, Lucile Sautot, Bushra Nabi, M Sugumaran","1 - Department of C.S.E Pondicherry Engineering College Pondicherry-14 India
2 - CNRS Univ. Bourgogne Franche-Comté LE2I UMR6306 AgroSup Dijon France
3 - UMR TETIS Univ. catholique de Louvain UCL/SSS IREC/MIRO 4-AgroParistech Bruxelles Belgium
4 - Maison de la télédétection Montpellier France
5 - Department of Botany University of Kashmir","Network intrusion detection (NID) is a complex classification problem. In this paper, we combine classification with recent and scalable nonlinear dimensionality reduction (NLDR) methods. Classification and DR are not necessarily adversarial, provided adequate cluster magnification occurring in NLDR methods like t-SNE: DR mitigates the curse of dimensionality, while cluster magnification can maintain class separability. We demonstrate experimentally the effectiveness of the approach by analyzing and comparing results on the big KDD99 dataset, using both NLDR quality assessment and classification rate for SVMs and random forests. Since data involves features of mixed types (numerical and categorical), the use of Gower's similarity coefficient as metric further improves the results over the classical similarity metric.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-71.pdf,2017,100.0,"Large-scale nonlinear dimensionality reduction for network intrusion detection Network intrusion detection (NID) is a complex classification problem. In this paper, we combine classification with recent and scalable nonlinear dimensionality reduction (NLDR) methods. Classification and DR are not necessarily adversarial, provided adequate cluster magnification occurring in NLDR methods like t-SNE: DR mitigates the curse of dimensionality, while cluster magnification can maintain class separability. We demonstrate experimentally the effectiveness of the approach by analyzing and comparing results on the big KDD99 dataset, using both NLDR quality assessment and classification rate for SVMs and random forests. Since data involves features of mixed types (numerical and categorical), the use of Gower's similarity coefficient as metric further improves the results over the classical similarity metric."
Multiscale Spatio-Temporal Data Aggregation and Mapping for Urban Data Exploration,"Etienne Côme, Anaïs Remy","1 - Université Paris-Est, COSYS GRETTIA F-77447 Marne-la-Vallée IFSTTAR France
2 - SNCF, Innovation & Recherche 40 avenue des terroirs de France 75611 Paris France","Maps seem the most intuitive way to visualize massive urban data but they also raise some well-known graphical problems (such as visual clutter, etc.). This paper focuses on processing massive spatiotemporal data in order to ease multi-scale exploration. To this end, we describe a preprocessing tool that enables the automatic creation of a multi-resolution grid from a high resolution grid of spatio-temporal data in a format compatible with webmapping applications (vector tiles). The use of this tool is exemplified through a prototype that offers the possibility to navigate into a massive itinerary request dataset collected in the Ile-de-France region.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-72.pdf,2017,100.0,"Multiscale Spatio-Temporal Data Aggregation and Mapping for Urban Data Exploration Maps seem the most intuitive way to visualize massive urban data but they also raise some well-known graphical problems (such as visual clutter, etc.). This paper focuses on processing massive spatiotemporal data in order to ease multi-scale exploration. To this end, we describe a preprocessing tool that enables the automatic creation of a multi-resolution grid from a high resolution grid of spatio-temporal data in a format compatible with webmapping applications (vector tiles). The use of this tool is exemplified through a prototype that offers the possibility to navigate into a massive itinerary request dataset collected in the Ile-de-France region."
Detection of non-recurrent road traffic events based on clustering indicators,"Pierre-Antoine Laharotte, Billot Romain, Nour-Eddin El-Faouzi","1 - ENTPE/IFSTTAR -LICIT Université de Lyon
3 - Maurice Audin -Vaulx-en-Velin F69518 2 France
4 - Telecom Bretagne -Institut Mines Telecom -Département LUSSI Technopole Brest Iroise -CS 83818 -, F29238 Brest France","Based on a clustering indicator, an alteration of the classical road traffic indicators is proposed for incident detection. The resulting filter method reduces the inaccuracies of comparable detection method and enables to better separate usual traffic patterns from non-recurrent situations. Three alternative detection approaches are considered as baseline comparison for performance estimation.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-73.pdf,2017,100.0,"Detection of non-recurrent road traffic events based on clustering indicators Based on a clustering indicator, an alteration of the classical road traffic indicators is proposed for incident detection. The resulting filter method reduces the inaccuracies of comparable detection method and enables to better separate usual traffic patterns from non-recurrent situations. Three alternative detection approaches are considered as baseline comparison for performance estimation."
Impact of the initialisation of a blind unmixing method dealing with intra-class variability,"Charlotte Revel, Yannick Deville, Veronique Achard, Xavier Briottet","1 - Institut de Recherche en Astrophysique et Planétologie Universié de Toulouse UPS-CNRS-OMP IRAP 14 Av. Edouard Belin F-31400 Toulouse France
2 - ONERA "" The French Aerospace Lab"" 2 Av. Edouard Belin 31000 Toulouse France","In hyperspectral imagery, unmixing methods are often used to analyse the composition of the pixels. Such methods usually suppose that a single spectral signature, called an endmember, can be associated with each pure material present in the scene. Such an assumption is no more valid for materials that exhibit spectral variability due to illumination conditions, weathering, slight variations of the composition, etc. In this paper, we investigate a new method based on the assumption of a linear mixing model, that deals with intra-class spectral variability. A new formulation of the linear mixing is provided. In our model a pure material cannot be described by a single spectrum in the image but it can in a pixel. An approach method is presented to handle this new model. It is based on pixel-by-pixel Nonnegative Matrix Factorization (NMF) methods. The methods are tested on a semi-synthetic data set built with spectra extracted from a real hyperspectral image and mixtures of these spectra. We particularly focused our tests to study the impact of the initialisation of our methods.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-74.pdf,2017,100.0,"Impact of the initialisation of a blind unmixing method dealing with intra-class variability In hyperspectral imagery, unmixing methods are often used to analyse the composition of the pixels. Such methods usually suppose that a single spectral signature, called an endmember, can be associated with each pure material present in the scene. Such an assumption is no more valid for materials that exhibit spectral variability due to illumination conditions, weathering, slight variations of the composition, etc. In this paper, we investigate a new method based on the assumption of a linear mixing model, that deals with intra-class spectral variability. A new formulation of the linear mixing is provided. In our model a pure material cannot be described by a single spectrum in the image but it can in a pixel. An approach method is presented to handle this new model. It is based on pixel-by-pixel Nonnegative Matrix Factorization (NMF) methods. The methods are tested on a semi-synthetic data set built with spectra extracted from a real hyperspectral image and mixtures of these spectra. We particularly focused our tests to study the impact of the initialisation of our methods."
Piecewise-Bézier C 1 smoothing on manifolds with application to wind field estimation,"Pierre-Yves Gousenbourger, Estelle Massart, Antoni Musolas, P.-A Absil, Julien Hendrickx, Laurent Jacques, Youssef Marzouk","1 - ICTEAM Institute Université catholique de Louvain Louvain-la-Neuve Belgium
3 - Dept. of Aeronautics and Astronautics MIT Cambridge USA","We propose an algorithm for fitting C 1 piecewise-Bézier curves to (possibly corrupted) data points on manifolds. The curve is chosen as a compromise between proximity to data points and regularity. We apply our algorithm as an example to fit a curve to a set of low-rank covariance matrices, a task arising in wind field modeling. We show that our algorithm has denoising abilities for this application.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-77.pdf,2017,98.22485207100591,"Piecewise-Bézier C 1 smoothing on manifolds with application to wind field estimation We propose an algorithm for fitting C 1 piecewise-Bézier curves to (possibly corrupted) data points on manifolds. The curve is chosen as a compromise between proximity to data points and regularity. We apply our algorithm as an example to fit a curve to a set of low-rank covariance matrices, a task arising in wind field modeling. We show that our algorithm has denoising abilities for this application."
Distance metric learning: A two-phase approach,"Bac Nguyen, Carlos Morell, Bernard De Baets","1 - Department of Mathematical Modelling, Statistics and Bioinformatics Ghent University Coupure links 653 9000 Ghent Belgium
2 - Department of Computer Science Universidad Central de Las Villas 54830 Santa Clara, Villa Clara CP Cuba","Distance metric learning has been successfully incorporated in many machine learning applications. The main challenge arises from the positive semidefiniteness constraint on the Mahalanobis matrix, which results in a high computational cost. In this paper, we develop a novel approach to reduce this computational burden. We first map each training example into a new space by an orthonormal transformation. Then, in the transformed space, we simply learn a diagonal matrix. This twophase approach is thus much easier and less costly than learning a full Mahalanobis matrix in one phase as is commonly done.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-8.pdf,2017,95.65217391304348,"Distance metric learning: A two-phase approach Distance metric learning has been successfully incorporated in many machine learning applications. The main challenge arises from the positive semidefiniteness constraint on the Mahalanobis matrix, which results in a high computational cost. In this paper, we develop a novel approach to reduce this computational burden. We first map each training example into a new space by an orthonormal transformation. Then, in the transformed space, we simply learn a diagonal matrix. This twophase approach is thus much easier and less costly than learning a full Mahalanobis matrix in one phase as is commonly done."
Imitation learning for a continuum trunk robot,"Milad Malekzadeh, J Queißer, J Steil","1 - Institute for Robotics and Process Control Technische Universität Braunschweig Muehlenpfordtstr. 23 D-38106 Braunschweig Germany
2 - Research Institute of Cognition and Robotics -Bielefeld University Universitätsstr. 25 33615 Bielefeld Germany","The paper applies learning from demonstration (LfD) for high-level trajectory planning and movement control of the Bionic Handling Assistant (BHA) robot. For such soft continuum robot with mechanical elasticity and complex dynamics it is difficult to use kinesthetic teaching to collect demonstration data. We propose to use an active compliant controller to this aim and record both position and orientation of the BHA's end-effector. Subsequently, this data is then encoded with a state-of-the-art task-parameterized probabilistic Gaussian mixture model and its performance and generalization is experimentally evaluated. * M. Malekzadeh is funded by H2020 under GA 644727 -CogIMon. J. Q. received funding from the Cluster of Excellence 277 -Cognitive Interaction Technology and has been supported by the CODEFROR project (FP7-PIRSES-2013-612555).","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-80.pdf,2017,100.0,"Imitation learning for a continuum trunk robot The paper applies learning from demonstration (LfD) for high-level trajectory planning and movement control of the Bionic Handling Assistant (BHA) robot. For such soft continuum robot with mechanical elasticity and complex dynamics it is difficult to use kinesthetic teaching to collect demonstration data. We propose to use an active compliant controller to this aim and record both position and orientation of the BHA's end-effector. Subsequently, this data is then encoded with a state-of-the-art task-parameterized probabilistic Gaussian mixture model and its performance and generalization is experimentally evaluated. * M. Malekzadeh is funded by H2020 under GA 644727 -CogIMon. J. Q. received funding from the Cluster of Excellence 277 -Cognitive Interaction Technology and has been supported by the CODEFROR project (FP7-PIRSES-2013-612555)."
Mutual information for improving the efficiency of the SCH algorithm,"D Fernandez-Francos, O Fontenla-Romero, A Alonso-Betanzos, G Brown","1 - Department of Computer Science University of A Coruna Spain
4 - -MLO Group University of Manchester United Kingdon","A new approach for improving the efficiency of a one-class classification algorithm making it more suitable for big datasets is presented in this work. The original algorithm, called SCH algorithm, approximates a Ddimensional convex hull decision by means of random projections and an ensemble of 2-dimensional decisions. With this new approach we try to get rid of the less relevant projections that lead to bad classification models in the low dimensional space. For that, after the training phase, a new stage based on mutual information is added to the original algorithm in order to remove the unnecessary projections, maintaining the information contained in the model (and thus the accuracy) while making it lightweight. This reduces remarkably the computational time of the testing phase. Finally, some experimental results demonstrate the effectiveness and efficiency of these approach.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-82.pdf,2017,100.0,"Mutual information for improving the efficiency of the SCH algorithm A new approach for improving the efficiency of a one-class classification algorithm making it more suitable for big datasets is presented in this work. The original algorithm, called SCH algorithm, approximates a Ddimensional convex hull decision by means of random projections and an ensemble of 2-dimensional decisions. With this new approach we try to get rid of the less relevant projections that lead to bad classification models in the low dimensional space. For that, after the training phase, a new stage based on mutual information is added to the original algorithm in order to remove the unnecessary projections, maintaining the information contained in the model (and thus the accuracy) while making it lightweight. This reduces remarkably the computational time of the testing phase. Finally, some experimental results demonstrate the effectiveness and efficiency of these approach."
Non-negative decomposition of geophysical dynamics,"Manuel López-Radcenco, Abdeldjalil Aïssa-El-Bey, Pierre Ailliot, Ronan Fablet","1 - Télécom Bretagne UMR CNRS 6285 Lab-STICC Institut Mines-Télécom
2 - Technopôle Brest-Iroise CS83818 29238, Cedex 3 Brest France
7 - UMR CNRS 6205 LMBA Université de Brest 6, Avenue Victor Le Gorgeu B.P. 809 29285 Brest Cedex France","The decomposition of geophysical processes into relevant modes is a key issue for characterization, forecasting and reconstruction problems. The blind separation of contributions from different sources is a well-studied problem in signal and image processing. Recently, significant advances have been reported with the introduction of non-negative and sparse formulations. In this work, we address an extension to the blind decomposition of linear operators or transfer functions between variables of interest with an emphasis on a non-negative setting. As illustrated here, such decompositions are of key interest for the analysis of geophysical dynamics and the relationships between different geophysical variables.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-83.pdf,2017,100.0,"Non-negative decomposition of geophysical dynamics The decomposition of geophysical processes into relevant modes is a key issue for characterization, forecasting and reconstruction problems. The blind separation of contributions from different sources is a well-studied problem in signal and image processing. Recently, significant advances have been reported with the introduction of non-negative and sparse formulations. In this work, we address an extension to the blind decomposition of linear operators or transfer functions between variables of interest with an emphasis on a non-negative setting. As illustrated here, such decompositions are of key interest for the analysis of geophysical dynamics and the relationships between different geophysical variables."
Prediction of preterm infant mortality with Gaussian process classification,"Olli-Pekka Rinta-Koski, Simo Särkkä, Jaakko Hollmén, Markus Leskinen, Sture Andersson","1 - Department of Computer Science Espoo Aalto University Finland
2 - Aalto University -Dept. of Electrical Engineering and Automation Espoo Finland
4 - University of Helsinki Helsinki University Hospital Helsinki Finland","We present a method for predicting preterm infant inhospital-mortality using Bayesian Gaussian process classification. We combined features extracted from sensor measurements, made during the first 24 hours of care for 581 Very Low Birth Weight infants, with standard clinical features calculated on arrival at the Neonatal Intensive Care Unit. We achieved a classification result with area under curve of 0.94 (standard error 0.02), which is in excess of the results achieved by using the clinical standard SNAP-II and SNAPPE-II scores.",Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-86.pdf,2017,100.0,"Prediction of preterm infant mortality with Gaussian process classification We present a method for predicting preterm infant inhospital-mortality using Bayesian Gaussian process classification. We combined features extracted from sensor measurements, made during the first 24 hours of care for 581 Very Low Birth Weight infants, with standard clinical features calculated on arrival at the Neonatal Intensive Care Unit. We achieved a classification result with area under curve of 0.94 (standard error 0.02), which is in excess of the results achieved by using the clinical standard SNAP-II and SNAPPE-II scores."
A distributed approach for classification using distance metrics,"L Morán-Fernández, V Bolón-Canedo, A Alonso-Betanzos",1 - Computer Science Dept Laboratory for Research and Development in Artificial Intelligence (LIDIA) Universidade da Coruña 15071 A Coruña Spain,"To cope with the huge quantity of data that fast development of sensoring, networking and inexpensive data storage has come, many distributed approaches have been developed during the last years. The main reason is that, when dealing with large datasets, most existing data mining algorithms do not scale well, and their efficiency may significantly deteriorate. Thus, we present a distributed approach by samples in which the original dataset will be divided into several nodes or processors. For classifying a new test sample, first we compute the distance to the data on each node, and then it will be classified by the model learned from the ""closest"" data. The proposed method has proved to be useful, demonstrating important savings in runtime and satisfactory performance.",Algorithmic Challenges in Big Data Analytics,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-87.pdf,2017,100.0,"A distributed approach for classification using distance metrics To cope with the huge quantity of data that fast development of sensoring, networking and inexpensive data storage has come, many distributed approaches have been developed during the last years. The main reason is that, when dealing with large datasets, most existing data mining algorithms do not scale well, and their efficiency may significantly deteriorate. Thus, we present a distributed approach by samples in which the original dataset will be divided into several nodes or processors. For classifying a new test sample, first we compute the distance to the data on each node, and then it will be classified by the model learned from the ""closest"" data. The proposed method has proved to be useful, demonstrating important savings in runtime and satisfactory performance."
Criticality in Biocomputation,Tjeerd Olde Scheper,1 - Department of Computing Communication Technologies Oxford Brookes University Wheatley Campus OX33 1HX Oxford United Kingdom,"Complexity in biological computation is one of the recognised means by which biological systems manage to function in a complex chaotic world. The ability to function and solve problems irrespective of scale and relative complexity, including higher-order interactions, is essential to the efficacy of biological systems. However, it has been unclear how the required complexity can be introduced to allow these functions to be realised. Nonlinear local interactions are required to combine into a global stable system. The property of criticality, that is exhibited by many nonlinear physical systems, can be exploited to allow local nonlinear oscillators to interact, resulting in a globally stable system. This concept introduces robustness, as well as, a means to control global stability. 
 Criticality The property of physical systems to demonstrate criticality is based on local nonlinear interactions of many small components that contribute to the system [1]. These interactions are not significantly large at the scale of each component, but are contributing factors due to the nonlinear interactions of these components to the global stable state of the system. Criticality is seen in the global state of the system where the system changes state due to its apparent proximity to a critical point. This is often observed as rapid transitions from one state to the next. For example, in the case of a avalanche of snow or sand, where a previously apparent stable state rapidly changes to a different stable state. Similar dynamics have been observed in biological systems, in particular in neural dynamics  [2] . The functional role of criticality is here under investigation. So far, it appears to be mostly related to network complexity and power law relations within those networks. Even though it is still not clear if power law relations are a true property of most systems of interest  [3] , there is certainly a potential for criticality to play an important role in many aspects of biological computation. 
 Nonlinear control Although the concept of criticality has been known for some time now, its exact role and relation to dynamic systems has not yet been determined sufficiently. This can be attributed to the issue of reliably and robustly creating a dynamic system which exhibits criticality. Quite a lot is known about linear systems with relatively complex interactions, however complex interactions in nonlinear systems often quickly degenerate into unstable or chaotic systems. It is argued that biological systems are capable of exerting localised control on the many 323","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-89.pdf,2017,100.0,"Criticality in Biocomputation Complexity in biological computation is one of the recognised means by which biological systems manage to function in a complex chaotic world. The ability to function and solve problems irrespective of scale and relative complexity, including higher-order interactions, is essential to the efficacy of biological systems. However, it has been unclear how the required complexity can be introduced to allow these functions to be realised. Nonlinear local interactions are required to combine into a global stable system. The property of criticality, that is exhibited by many nonlinear physical systems, can be exploited to allow local nonlinear oscillators to interact, resulting in a globally stable system. This concept introduces robustness, as well as, a means to control global stability. 
 Criticality The property of physical systems to demonstrate criticality is based on local nonlinear interactions of many small components that contribute to the system [1]. These interactions are not significantly large at the scale of each component, but are contributing factors due to the nonlinear interactions of these components to the global stable state of the system. Criticality is seen in the global state of the system where the system changes state due to its apparent proximity to a critical point. This is often observed as rapid transitions from one state to the next. For example, in the case of a avalanche of snow or sand, where a previously apparent stable state rapidly changes to a different stable state. Similar dynamics have been observed in biological systems, in particular in neural dynamics  [2] . The functional role of criticality is here under investigation. So far, it appears to be mostly related to network complexity and power law relations within those networks. Even though it is still not clear if power law relations are a true property of most systems of interest  [3] , there is certainly a potential for criticality to play an important role in many aspects of biological computation. 
 Nonlinear control Although the concept of criticality has been known for some time now, its exact role and relation to dynamic systems has not yet been determined sufficiently. This can be attributed to the issue of reliably and robustly creating a dynamic system which exhibits criticality. Quite a lot is known about linear systems with relatively complex interactions, however complex interactions in nonlinear systems often quickly degenerate into unstable or chaotic systems. It is argued that biological systems are capable of exerting localised control on the many 323"
Feature Extraction and Learning for RSSI based Indoor Device Localization,"Stavros Timotheatos, Grigorios Tsagkatakis, Panagiotis Tsakalides, Panos Trahanias",1 - Institute of Computer Science Foundation for Research and Technology -Hellas (FORTH) Heraklion Crete Greece,"In this paper, we study and experimentally compare two state-of-the-art methods for low dimensional feature extraction, within the context of RSSI fingerprinting for localization. On one hand, we consider Stacked Autoencoders, a prominent example of a deep learning architecture, while on the other hand, we explore Random Projections, a universal feature extraction approach. Experimental results suggest that feature learning has a dramatic impact on the subsequent analysis like location based classification.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-90.pdf,2017,100.0,"Feature Extraction and Learning for RSSI based Indoor Device Localization In this paper, we study and experimentally compare two state-of-the-art methods for low dimensional feature extraction, within the context of RSSI fingerprinting for localization. On one hand, we consider Stacked Autoencoders, a prominent example of a deep learning architecture, while on the other hand, we explore Random Projections, a universal feature extraction approach. Experimental results suggest that feature learning has a dramatic impact on the subsequent analysis like location based classification."
Supporting Generative Models of Spatial Behavior by User Interaction,"Ronny Hug, Wolfgang Hübner, Michael Arens",1 - Fraunhofer Institute of Optronics System Technologies and Image Exploitation Gutleuthausstraße 1 76275 Ettlingen,"The analysis of spatial behavior in terms of motion profiles recorded along trajectories is a widely used technique in video analysis. Inherent to this approach is the problem to assign a meaningful score to observations. This score builds the basis for classification, ranking, or to generate user feedback. Score assignment can be done in terms of deviations from normal behavior, where normality is determined by learning a generative model. A general drawback is that the unsupervised learning process often assigns non-intuitive scores. In order to address this problem this paper proposes the usage of interactive concepts, which support the learning process. Interaction thereby strongly utilizes the generative models capabilities to synthesize samples, to give insight into the underlying representation. Initial results are shown on a trajectory rating task, illustrating the feasibility of the proposed approach.","Signal and image processing, collaborative filtering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-91.pdf,2017,67.64705882352942,"Supporting Generative Models of Spatial Behavior by User Interaction The analysis of spatial behavior in terms of motion profiles recorded along trajectories is a widely used technique in video analysis. Inherent to this approach is the problem to assign a meaningful score to observations. This score builds the basis for classification, ranking, or to generate user feedback. Score assignment can be done in terms of deviations from normal behavior, where normality is determined by learning a generative model. A general drawback is that the unsupervised learning process often assigns non-intuitive scores. In order to address this problem this paper proposes the usage of interactive concepts, which support the learning process. Interaction thereby strongly utilizes the generative models capabilities to synthesize samples, to give insight into the underlying representation. Initial results are shown on a trajectory rating task, illustrating the feasibility of the proposed approach."
Advanced Query Strategies for Active Learning with Extreme Learning Machine,"Anton Akusok, Emil Eirola, Yoan Miche, Andrey Gritsenko, Amaury Lendasse, Jan-Magnus Janssonin Aukio 1 -Finland","1 - Department of Business Management and Analytics Arcada University of Applied Sciences
3 - Nokia Solutions and Networks Group -Espoo Finland
4 - Department on Mechanical and Industrial Engineering Seamans Center for the Engineering Arts and Sciences The University of Iowa USA
6 - The Iowa Informatics Initiative Seamans Center for the Engineering Arts and Sciences The University of Iowa USA","This work proposes three new query strategies for active learning. They are built on modern developments in Extreme Learning Machine (ELM): class-weighted ELM, prediction intervals with ELM, and mislabeled samples detection with ELM. Both ELM and active learning are important methods of applied machine learning. Combined, they offer a fast and precise tool for practical data acquisition in classification tasks where raw data is cheap but labels are expensive to get. Some proposed methods rival the state-of-the-art in performance and speed, based on testing with three real world datasets.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-92.pdf,2017,91.3907284768212,"Advanced Query Strategies for Active Learning with Extreme Learning Machine This work proposes three new query strategies for active learning. They are built on modern developments in Extreme Learning Machine (ELM): class-weighted ELM, prediction intervals with ELM, and mislabeled samples detection with ELM. Both ELM and active learning are important methods of applied machine learning. Combined, they offer a fast and precise tool for practical data acquisition in classification tasks where raw data is cheap but labels are expensive to get. Some proposed methods rival the state-of-the-art in performance and speed, based on testing with three real world datasets."
Anomaly detection and characterization in smart card logs using NMF and Tweets,"Emeric Tonnelier, Nicolas Baskiotis, Vincent Guigue, Patrick Gallinari",1 - UPMC -Sorbonne Universités -LIP6 -CNRS 4 place Jussieu 75005 Paris,"This article describes a novel approach to detect anomalies in smart card logs. In this study, we chose to work on a 24h base for every station in the Parisian metro network. We also consider separately the 7 days of the week. We first build a robust averaged reference for (day,station) couples and then, we focus on the difference between particular situations and references. All experiments are conducted both on the raw data and using an NMF denoised approximation of the log flow. We demonstrate the interest and the robustness of the latter strategy. Then we mine RATP 1 Twitter account to obtain ground truth information about operating incidents. This synchronized flow is used to evaluate our models.","Processing, Mining and Visualizing Massive Urban Data",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-93.pdf,2017,100.0,"Anomaly detection and characterization in smart card logs using NMF and Tweets This article describes a novel approach to detect anomalies in smart card logs. In this study, we chose to work on a 24h base for every station in the Parisian metro network. We also consider separately the 7 days of the week. We first build a robust averaged reference for (day,station) couples and then, we focus on the difference between particular situations and references. All experiments are conducted both on the raw data and using an NMF denoised approximation of the log flow. We demonstrate the interest and the robustness of the latter strategy. Then we mine RATP 1 Twitter account to obtain ground truth information about operating incidents. This synchronized flow is used to evaluate our models."
Comparison of strategies to learn from imbalanced classes for computer aided diagnosis of inborn steroidogenic disorders,"Sreejita Ghosh, Elizabeth Baranowski, Rick Van Veen, Gert-Jan De Vries, Michael Biehl, Wiebke Arlt, Peter Tino, Kerstin Bunte","1 - University of Groningen -Johann Bernoulli Institute NL
2 - University of Birmingham -Institute of Metabolism and Systems Research UK
3 - Philips Research De Montfort University UK
4 - Philips Research -Healthcare NL
7 - School of Computer Science University of Birmingham UK","In the bio-medical domain, a high detection rate of possibly rare diseases is usually highly desirable while errors in the majority class (e.g. healthy controls) may be more acceptable. Hence, optimizing the overall predictive accuracy is often unsuitable. Here, we analyse a large data set of urine GC/MS measurements from 829 controls and 68 patients suffering from one of three inborn steroidogenic disorders. We use 2 comparable algorithms able to handle large amounts of missing data. Furthermore, we compare a variety of different strategies to deal with the highly imbalanced data, including undersampling, oversampling and the introduction of class-specific costs.",Biomedical data analysis in translational research: integration of expert knowledge and interpretable models,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-94.pdf,2017,100.0,"Comparison of strategies to learn from imbalanced classes for computer aided diagnosis of inborn steroidogenic disorders In the bio-medical domain, a high detection rate of possibly rare diseases is usually highly desirable while errors in the majority class (e.g. healthy controls) may be more acceptable. Hence, optimizing the overall predictive accuracy is often unsuitable. Here, we analyse a large data set of urine GC/MS measurements from 829 controls and 68 patients suffering from one of three inborn steroidogenic disorders. We use 2 comparable algorithms able to handle large amounts of missing data. Furthermore, we compare a variety of different strategies to deal with the highly imbalanced data, including undersampling, oversampling and the introduction of class-specific costs."
Reducing Variance due to Importance Weighting in Covariate Shift Bias Correction,"Van-Tinh Tran, Alex Aussem",1 - UMR 5205 University of Lyon 1 LIRIS 69622 Lyon France,"Covariate shift is a problem in machine learning when the input distributions of training and test data are different (p(x) = p (x)) while their conditional distribution p(y|x) is the same. A common technique to deal with this problem, called importance weighting, amounts to reweighting the training instances in order to make them resemble the test distribution. However this usually comes at the expense of a reduction of the effective sample size, which is harmful when the initial training sample size is already small. In this paper, we show that there exists a weighting scheme on the unlabeled data such that the combination of the weighted unlabeled data and the labeled training data mimics the test distribution. We further prove that the labels are missing at random in this combined data set and thus can be imputed safely in order to mitigate the undesirable sample-size-reduction effect of importance weighting. A series of experiments on synthetic and real-world data are conducted to demonstrate the efficiency of our approach.","Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-95.pdf,2017,71.25,"Reducing Variance due to Importance Weighting in Covariate Shift Bias Correction Covariate shift is a problem in machine learning when the input distributions of training and test data are different (p(x) = p (x)) while their conditional distribution p(y|x) is the same. A common technique to deal with this problem, called importance weighting, amounts to reweighting the training instances in order to make them resemble the test distribution. However this usually comes at the expense of a reduction of the effective sample size, which is harmful when the initial training sample size is already small. In this paper, we show that there exists a weighting scheme on the unlabeled data such that the combination of the weighted unlabeled data and the labeled training data mimics the test distribution. We further prove that the labels are missing at random in this combined data set and thus can be imputed safely in order to mitigate the undesirable sample-size-reduction effect of importance weighting. A series of experiments on synthetic and real-world data are conducted to demonstrate the efficiency of our approach."
Fusion of Stereo Vision for Pedestrian Recognition using Convolutional Neural Networks,"Dȃnut ¸ovidiu Pop, Alexandrina Rogozan, Fawzi Nashashibi, Abdelaziz Bensrhair","1 - INRIA Paris -RITS Team Paris France
2 - INSA Rouen -LITIS Laboratory Rouen France
3 - Department of Computer Science Babeş-Bolyai University
4 - Cluj Napoca Romania","Pedestrian detection is a highly debated issue in the scientific community due to its outstanding importance for a large number of applications, especially in the fields of automotive safety, robotics and surveillance. In spite of the widely varying methods developed in recent years, pedestrian detection is still an open challenge whose accuracy and robustness has to be improved. Therefore, in this paper, we focus on improving the classification component in the pedestrian detection task on the Daimler stereo vision data set by adopting two approaches: 1) by combining three image modalities (intensity, depth and flow) to feed a unique convolutional neural network (CNN) and 2) by fusing the results of three independent CNNs.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-96.pdf,2017,100.0,"Fusion of Stereo Vision for Pedestrian Recognition using Convolutional Neural Networks Pedestrian detection is a highly debated issue in the scientific community due to its outstanding importance for a large number of applications, especially in the fields of automotive safety, robotics and surveillance. In spite of the widely varying methods developed in recent years, pedestrian detection is still an open challenge whose accuracy and robustness has to be improved. Therefore, in this paper, we focus on improving the classification component in the pedestrian detection task on the Daimler stereo vision data set by adopting two approaches: 1) by combining three image modalities (intensity, depth and flow) to feed a unique convolutional neural network (CNN) and 2) by fusing the results of three independent CNNs."
Scalable Hybrid Deep Neural Kernel Networks,"Siamak Mehrkanoon, Andreas Zell, Johan Suykens","1 - Department of Electrical Engineering ESAT-STADIUS, KU Leuven B-3001 Leuven Belgium
2 - Computer Science Department University of Tuebingen Sand 1 72076 Tuebingen Germany","This paper introduces a novel hybrid deep neural kernel framework. The proposed deep learning model follows a combination of neural networks based architecture and a kernel based model. In particular, here an explicit feature map, based on random Fourier features, is used to make the transition between the two architectures more straightforward as well as making the model scalable to large datasets by solving the optimization problem in the primal. The introduced framework can be considered as the first building block for the development of even deeper models and more advanced architectures. Experimental results show a significant improvement over shallow models on several medium to large scale real-life datasets.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-97.pdf,2017,100.0,"Scalable Hybrid Deep Neural Kernel Networks This paper introduces a novel hybrid deep neural kernel framework. The proposed deep learning model follows a combination of neural networks based architecture and a kernel based model. In particular, here an explicit feature map, based on random Fourier features, is used to make the transition between the two architectures more straightforward as well as making the model scalable to large datasets by solving the optimization problem in the primal. The introduced framework can be considered as the first building block for the development of even deeper models and more advanced architectures. Experimental results show a significant improvement over shallow models on several medium to large scale real-life datasets."
Comparison of Adaptive MCMC Samplers,"Edna Milgo, Nixon Ronoh, Peter Waiganjo, Bernard Manderick","1 - Artificial Intelligence Lab Pleinlaan Vrije Universiteit Brussel 2 -1050 Brussel Belgium
2 - Moi University P.O. Box 3900-30100 Eldoret Kenya
5 - University of Nairobi P.O. Box 30197 00100 Nairobi Kenya
7 - VLIR-UOS Vrije Universiteit Brussel and Moi University",We compare three adaptive MCMC samplers to Metropolis-Hastings algorithm with optimal proposal distribution as our benchmark. We transform a simple Evolution Strategy algorithm into a sampler and show that it already outperforms the other samplers on the test suite used in the initial research on adaptive MCMC.,"Regression, robots and biological systems",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-98.pdf,2017,64.7887323943662,Comparison of Adaptive MCMC Samplers We compare three adaptive MCMC samplers to Metropolis-Hastings algorithm with optimal proposal distribution as our benchmark. We transform a simple Evolution Strategy algorithm into a sampler and show that it already outperforms the other samplers on the test suite used in the initial research on adaptive MCMC.
Bioinformatics and Medicine in the Era of Deep Learning,"Davide Bacciu, Paulo Lisboa, José Martín, Ruxandra Stoean, Alfredo Vellido","1 - Università di Pisa Italy
2 - Liverpool John Moores University UK
3 - Universitat de València Spain
4 - University of Craiova Romania
5 - Universidad Politécnica de Cataluña Spain","Many of the current scientific advances in the life sciences have their origin in the intensive use of data for knowledge discovery. In no area this is so clear as in bioinformatics, led by technological breakthroughs in data acquisition technologies. It has been argued that bioinformatics could quickly become the field of research generating the largest data repositories, beating other data-intensive areas such as high-energy physics or astroinformatics. Over the last decade, deep learning has become a disruptive advance in machine learning, giving new live to the long-standing connectionist paradigm in artificial intelligence. Deep learning methods are ideally suited to large-scale data and, therefore, they should be ideally suited to knowledge discovery in bioinformatics and biomedicine at large. In this brief paper, we review key aspects of the application of deep learning in bioinformatics and medicine, drawing from the themes covered by the contributions to an ESANN 2018 special session devoted to this topic. * D.Bacciu is funded by the Italian MIUR under project SIR-RBSI14STDE † A. Vellido is funded by the Spanish MINECO under project TIN2016-79576-R",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-1.pdf,2018,80.0,"Bioinformatics and Medicine in the Era of Deep Learning Many of the current scientific advances in the life sciences have their origin in the intensive use of data for knowledge discovery. In no area this is so clear as in bioinformatics, led by technological breakthroughs in data acquisition technologies. It has been argued that bioinformatics could quickly become the field of research generating the largest data repositories, beating other data-intensive areas such as high-energy physics or astroinformatics. Over the last decade, deep learning has become a disruptive advance in machine learning, giving new live to the long-standing connectionist paradigm in artificial intelligence. Deep learning methods are ideally suited to large-scale data and, therefore, they should be ideally suited to knowledge discovery in bioinformatics and biomedicine at large. In this brief paper, we review key aspects of the application of deep learning in bioinformatics and medicine, drawing from the themes covered by the contributions to an ESANN 2018 special session devoted to this topic. * D.Bacciu is funded by the Italian MIUR under project SIR-RBSI14STDE † A. Vellido is funded by the Spanish MINECO under project TIN2016-79576-R"
Stellar formation rates in galaxies using Machine Learning models,"Michele Delli Veneri, Stefano Cavuoti, Massimo Brescia, Giuseppe Riccio, Giuseppe Longo","1 - Dipartimento di Fisica ""E. Pancini"" Universitá degli Studi Federico II via Cintia 6 I-80135 Napoli Italia
3 - INAF -Osservatorio Astronomico di Capodimonte via Moiariello 16 I-80131 Napoli Italia
4 - INFN -Napoli Unit via Cintia 6 I-80135 Napoli Italia",Global Stellar Formation Rates or SFRs are crucial to constrain theories of galaxy formation and evolution. SFR's are usually estimated via spectroscopic observations which require too much previous telescope time and therefore cannot match the needs of modern precision cosmology. We therefore propose a novel method to estimate SFRs for large samples of galaxies using a variety of supervised ML models.,Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-100.pdf,2018,61.53846153846154,Stellar formation rates in galaxies using Machine Learning models Global Stellar Formation Rates or SFRs are crucial to constrain theories of galaxy formation and evolution. SFR's are usually estimated via spectroscopic observations which require too much previous telescope time and therefore cannot match the needs of modern precision cosmology. We therefore propose a novel method to estimate SFRs for large samples of galaxies using a variety of supervised ML models.
"Combining latent tree modeling with a random forest-based approach, for genetic association studies","Christine Sinoquet, Kamel Mekhnacha","1 - Probayes 180 avenue de l'Europe 38330 Inovallée, Montbonnot France
2 - UMR CNRS 6004 Université de Nantes 1 -LS2N, 2 rue de la Houssinière, BP 92208 44322 Nantes Cedex France
3 - Centre de Calcul Intensif des Pays de la Loire Nantes France","Association studies have been widely used to discover the genetic basis of complex phenotypes. However, standard univariate tests, and their alternatives, do not fully exploit the dependences between genetic markers. In this paper, we propose Sylva, a hybrid approach in which a random forest framework based on embedded trees benefits from a probabilistic graphical model. The latter is a collection of tree-shaped Bayesian networks with latent variables. We extensively compared Sylva and T-Trees, on simulated and real data. Sylva outperforms the already highly performant T-Trees, in a vast majority of cases.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-101.pdf,2018,100.0,"Combining latent tree modeling with a random forest-based approach, for genetic association studies Association studies have been widely used to discover the genetic basis of complex phenotypes. However, standard univariate tests, and their alternatives, do not fully exploit the dependences between genetic markers. In this paper, we propose Sylva, a hybrid approach in which a random forest framework based on embedded trees benefits from a probabilistic graphical model. The latter is a collection of tree-shaped Bayesian networks with latent variables. We extensively compared Sylva and T-Trees, on simulated and real data. Sylva outperforms the already highly performant T-Trees, in a vast majority of cases."
Interpretation of Convolutional Neural Networks for Speech Regression from Electrocorticography,"Miguel Angrick, Christian Herff, Jerry Shih, Dean Krusienski, Tanja Schultz","1 - University of Bremen -Cognitive Systems Lab Enrique-Schmidt-Straße 5 28359 Bremen Germany
3 - ASPEN Lab Old Dominion University 5115 Hampton Blvd 23529 Norfolk VA USA
4 - UC San Diego Health -Epilepsy Center 200 West Arbor Drive 92103 San Diego CA USA","The direct synthesis of continuously spoken speech from neural activity is envisioned to enable fast and intuitive Brain-Computer Interfaces. Earlier results indicate that intracranial recordings reveal very suitable signal characteristics for direct synthesis. To map the complex dynamics of neural activity to spectral representations of speech, Convolutional Neural Networks (CNNs) can be trained. However, the resulting networks are hard to interpret and thus provide little opportunity to gain insights on neural processes underlying speech. Here, we show that CNNs are useful to reconstruct speech from intracranial recordings of brain activity and propose an approach to interpret the trained CNNs.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-102.pdf,2018,80.0,"Interpretation of Convolutional Neural Networks for Speech Regression from Electrocorticography The direct synthesis of continuously spoken speech from neural activity is envisioned to enable fast and intuitive Brain-Computer Interfaces. Earlier results indicate that intracranial recordings reveal very suitable signal characteristics for direct synthesis. To map the complex dynamics of neural activity to spectral representations of speech, Convolutional Neural Networks (CNNs) can be trained. However, the resulting networks are hard to interpret and thus provide little opportunity to gain insights on neural processes underlying speech. Here, we show that CNNs are useful to reconstruct speech from intracranial recordings of brain activity and propose an approach to interpret the trained CNNs."
Effect of context in swipe gesture-based continuous authentication on smartphones,"Pekka Siirtola, Jukka Komulainen, Vili Kellokumpu","1 - Biomimetics and Intelligent Systems Group University of Oulu
2 - Center for Machine Vision and Signal Analysis University of Oulu
4 - Bittium Wireless Ltd","This work investigates how context should be taken into account when performing continuous authentication of a smartphone user based on touchscreen and accelerometer readings extracted from swipe gestures. The study is conducted on the publicly available HMOG dataset consisting of 100 study subjects performing pre-defined reading and navigation tasks while sitting and walking. It is shown that context-specific models are needed for different smartphone usage and human activity scenarios to minimize authentication error. Also, the experimental results suggests that utilization of phone movement improves swipe gesture-based verification performance only when the user is moving.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-104.pdf,2018,100.0,"Effect of context in swipe gesture-based continuous authentication on smartphones This work investigates how context should be taken into account when performing continuous authentication of a smartphone user based on touchscreen and accelerometer readings extracted from swipe gestures. The study is conducted on the publicly available HMOG dataset consisting of 100 study subjects performing pre-defined reading and navigation tasks while sitting and walking. It is shown that context-specific models are needed for different smartphone usage and human activity scenarios to minimize authentication error. Also, the experimental results suggests that utilization of phone movement improves swipe gesture-based verification performance only when the user is moving."
Forecasting Business Failure in Highly Imbalanced Distribution based on Delay Line Reservoir,"A Rodan, P Castillo, H Faris, M Al-Zoubi, A Mora, H Jawazneh","1 - Higher Colleges of Technology United Arab Emirates
2 - King Abdullah II School for Information Technology The University of Jordan Jordan
3 - Department of Computer Architecture and Technology
4 - ETSIIT and CITIC University of Granada Spain
7 - Department of Computer Sciences and Technology ESIT
8 - International University of La Rioja (UNIR) Spain","Bankruptcy is a critical financial problem that affects a high number of companies around the world. Thus, in recent years an increasing number of researchers have tried to solve it by applying different machine-learning models as powerful tools for the different economical agents related to the company. In this work, we propose the use of a simple deterministic delay line reservoir (DLR) state space by combining it with three popular classification algorithms (J48, k-NN, and MLP) as an efficient and accurate solution to the bankruptcy prediction problem. The proposed approach is evaluated on a real world dataset collected from Spanish companies. Obtained results show that the proposed models have a higher predictive ability than traditional classification approaches (without DLR reservoir state), resulting in a suitable and efficient alternative approach to solve this complex problem.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-105.pdf,2018,100.0,"Forecasting Business Failure in Highly Imbalanced Distribution based on Delay Line Reservoir Bankruptcy is a critical financial problem that affects a high number of companies around the world. Thus, in recent years an increasing number of researchers have tried to solve it by applying different machine-learning models as powerful tools for the different economical agents related to the company. In this work, we propose the use of a simple deterministic delay line reservoir (DLR) state space by combining it with three popular classification algorithms (J48, k-NN, and MLP) as an efficient and accurate solution to the bankruptcy prediction problem. The proposed approach is evaluated on a real world dataset collected from Spanish companies. Obtained results show that the proposed models have a higher predictive ability than traditional classification approaches (without DLR reservoir state), resulting in a suitable and efficient alternative approach to solve this complex problem."
Short-term Memory of Deep RNN,Claudio Gallicchio,1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"The extension of deep learning towards temporal data processing is gaining an increasing research interest. In this paper we investigate the properties of state dynamics developed in successive levels of deep recurrent neural networks (RNNs) in terms of short-term memory abilities. Our results reveal interesting insights that shed light on the nature of layering as a factor of RNN design. Noticeably, higher layers in a hierarchically organized RNN architecture results to be inherently biased towards longer memory spans even prior to training of the recurrent connections. Moreover, in the context of Reservoir Computing framework, our analysis also points out the benefit of a layered recurrent organization as an efficient approach to improve the memory skills of reservoir models.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-107.pdf,2018,100.0,"Short-term Memory of Deep RNN The extension of deep learning towards temporal data processing is gaining an increasing research interest. In this paper we investigate the properties of state dynamics developed in successive levels of deep recurrent neural networks (RNNs) in terms of short-term memory abilities. Our results reveal interesting insights that shed light on the nature of layering as a factor of RNN design. Noticeably, higher layers in a hierarchically organized RNN architecture results to be inherently biased towards longer memory spans even prior to training of the recurrent connections. Moreover, in the context of Reservoir Computing framework, our analysis also points out the benefit of a layered recurrent organization as an efficient approach to improve the memory skills of reservoir models."
Behaviour-Based Working Memory Capacity Classification Using Recurrent Neural Networks,"Mazen Salous, Felix Putze",1 - University of Bremen -Cognitive Systems Lab Bremen Germany,"A user's working memory capacity is a crucial factor for successful Human Computer Interaction (HCI). While reliable tests for working memory capacity are available, they are time-consuming, stressful, and not well-integrated into HCI applications. This paper presents a classifier based on Long Short Term Memory networks to exploit sparse temporal dependencies in behavioural data, collected in a complex, memory-intense interaction task, to classify working memory capacity. A cognitive user simulation is introduced to generate additional training data episodes that follow the behaviour of existing real data. We show that the classifier outperforms a linear baseline especially for short segments of data. * This work has been done within the project DINCO ""Detection of Interaction Competencies and Obstacles"". We thank the German Research Foundation (DFG) for funding DINCO project under the reference number PU 613/1-1.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-108.pdf,2018,88.37209302325581,"Behaviour-Based Working Memory Capacity Classification Using Recurrent Neural Networks A user's working memory capacity is a crucial factor for successful Human Computer Interaction (HCI). While reliable tests for working memory capacity are available, they are time-consuming, stressful, and not well-integrated into HCI applications. This paper presents a classifier based on Long Short Term Memory networks to exploit sparse temporal dependencies in behavioural data, collected in a complex, memory-intense interaction task, to classify working memory capacity. A cognitive user simulation is introduced to generate additional training data episodes that follow the behaviour of existing real data. We show that the classifier outperforms a linear baseline especially for short segments of data. * This work has been done within the project DINCO ""Detection of Interaction Competencies and Obstacles"". We thank the German Research Foundation (DFG) for funding DINCO project under the reference number PU 613/1-1."
Mixture of Hidden Markov Models as Tree Encoder,"Davide Bacciu, Daniele Castellana",1 - Dipartimento di Informatica Università di Pisa Italy,The paper introduces a new probabilistic tree encoder based on a mixture of Bottom-up Hidden Tree Markov Models. The ability to recognise similar structures in data is experimentally assessed both in clusterization and classification tasks. The results of these preliminary experiments suggest that the model can be successfully used to compress the tree structural and label patterns in a vectorial representation.,Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-112.pdf,2018,98.9247311827957,Mixture of Hidden Markov Models as Tree Encoder The paper introduces a new probabilistic tree encoder based on a mixture of Bottom-up Hidden Tree Markov Models. The ability to recognise similar structures in data is experimentally assessed both in clusterization and classification tasks. The results of these preliminary experiments suggest that the model can be successfully used to compress the tree structural and label patterns in a vectorial representation.
One-class Autoencoder approach to classify Raman spectra outliers,"Katharina Hofer-Schmitz, Phuong-Ha Nguyen, Kristian Berwanger",1 - Fraunhofer Institute for Applied Information Technology FIT Schloss Birlinghoven 53754 Sankt Augustin Germany,"We present an one-class Anomaly detector based on (deep) Autoencoder for Raman spectra. Omitting preprocessing of the spectra, we use raw data of our main class to learn the reconstruction, with many typical noise sources automatically reduced as the outcome. To separate anomalies from the norm class, we use several, independent statistical metrics for a majority voting. Our evaluation shows a f1-score of up to 99% success.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-113.pdf,2018,100.0,"One-class Autoencoder approach to classify Raman spectra outliers We present an one-class Anomaly detector based on (deep) Autoencoder for Raman spectra. Omitting preprocessing of the spectra, we use raw data of our main class to learn the reconstruction, with many typical noise sources automatically reduced as the outcome. To separate anomalies from the norm class, we use several, independent statistical metrics for a majority voting. Our evaluation shows a f1-score of up to 99% success."
Prototype-based Analysis of GAMA Galaxy Catalogue Data,"Aleke Nolte, Lingyu Wang, Michael Biehl","1 - Inst. for Mathematics and Computer Science Univ. of Groningen -Johann Bernoulli P.O. Box 407 9700 AK Groningen The Netherlands
2 - SRON Netherlands Institute for Space Research University of Groningen -Katpeyn Astronomical Institute Landleven 12 -9747 AD Groningen The Netherlands","We present a prototype-based machine learning analysis of labeled galaxy catalogue data containing parameters from the Galaxy and Mass Assembly (GAMA) survey. Using both an unsupervised and supervised method, the Self-Organizing Map and Generalized Relevance Matrix Learning Vector Quantization, we find that the data does not fully support the popular visual-inspection-based galaxy classification scheme employed to categorize the galaxies. In particular, only one class, the Little Blue Spheroids, is consistently separable from the other classes. In a proof-of-concept experiment, we present the galaxy parameters that are most discriminative for this class.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-115.pdf,2018,55.55555555555556,"Prototype-based Analysis of GAMA Galaxy Catalogue Data We present a prototype-based machine learning analysis of labeled galaxy catalogue data containing parameters from the Galaxy and Mass Assembly (GAMA) survey. Using both an unsupervised and supervised method, the Self-Organizing Map and Generalized Relevance Matrix Learning Vector Quantization, we find that the data does not fully support the popular visual-inspection-based galaxy classification scheme employed to categorize the galaxies. In particular, only one class, the Little Blue Spheroids, is consistently separable from the other classes. In a proof-of-concept experiment, we present the galaxy parameters that are most discriminative for this class."
K-Spectral Centroid : Extension and Optimizations,"Brieuc Conan-Guez, Alain Gély, Lydia Boudjeloud-Assala, Alexandre Blansché",1 - Université de Lorraine CNRS F-57000 Metz LORIA France,"In this work, we address the problem of unsupervised classification of large time series datasets. We focus on K-Spectral Centroid (KSC), a k-means-like model, devised for time series clustering. KSC relies on a custom dissimilarity measure between time series, which is invariant to time shifting and Y-scaling. KSC has two downsides: firstly its dissimilarity measure only makes sense for non negative time series. Secondly the KSC algorithm is relatively demanding in terms of computation time. In this paper, we present a natural extension of the KSC dissimilarity measure to time series of arbitrary signs. We show that this new measure is a metric distance. We propose to speed up this extended KSC (EKSC) thanks to four exact optimizations. Finally, we compare EKSC to a similar model, K-Shape, on real world datasets.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-116.pdf,2018,61.855670103092784,"K-Spectral Centroid : Extension and Optimizations In this work, we address the problem of unsupervised classification of large time series datasets. We focus on K-Spectral Centroid (KSC), a k-means-like model, devised for time series clustering. KSC relies on a custom dissimilarity measure between time series, which is invariant to time shifting and Y-scaling. KSC has two downsides: firstly its dissimilarity measure only makes sense for non negative time series. Secondly the KSC algorithm is relatively demanding in terms of computation time. In this paper, we present a natural extension of the KSC dissimilarity measure to time series of arbitrary signs. We show that this new measure is a metric distance. We propose to speed up this extended KSC (EKSC) thanks to four exact optimizations. Finally, we compare EKSC to a similar model, K-Shape, on real world datasets."
Structuring and Solving Multi-Criteria Decision Making Problems using Artificial Neural Networks: a Smartphone Recommendation Case,"Amaral De Sousa Victor, Simonofski Anthony, Snoeck Monique, Jureta Ivan","1 - Department Oude Markt 13 -KU Leuven -LIRIS 3000 Leuven Belgium
4 - UNamur -PReCISE Rue de Bruxelles 61 5000 Namur Belgium","Several techniques can be used to solve multi-criteria decision making (MCDM) problems and to provide a global ranking of the alternatives considered. However, in a context with a high number of alternatives and where decision criteria relate to soft goals, the decision problem is particularly hard to solve. This paper analyzes the use of artificial neural networks to improve the relevance of the ranking of alternatives delivered by MCDM problem-solving techniques. Afterwards, a model using a combination of artificial neural networks and of the weighted sum model, a particular MCDM problem-solving technique, is built to recommend smartphones.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-118.pdf,2018,76.15384615384615,"Structuring and Solving Multi-Criteria Decision Making Problems using Artificial Neural Networks: a Smartphone Recommendation Case Several techniques can be used to solve multi-criteria decision making (MCDM) problems and to provide a global ranking of the alternatives considered. However, in a context with a high number of alternatives and where decision criteria relate to soft goals, the decision problem is particularly hard to solve. This paper analyzes the use of artificial neural networks to improve the relevance of the ranking of alternatives delivered by MCDM problem-solving techniques. Afterwards, a model using a combination of artificial neural networks and of the weighted sum model, a particular MCDM problem-solving technique, is built to recommend smartphones."
Differential private relevance learning,"Johannes Brinkrolf, Kolja Berger, Barbara Hammer",1 - CITEC center of excellence Bielefeld University Germany,"Digital information is collected daily in growing volumes. Mutual benefits drive the demand for the exchange and publication of data among parties. However, it is often unclear how to handle these data properly in the case that the data contains sensitive information. Differential privacy has become a powerful principle for privacy-preserving data analysis tasks in the last few years, since it entails a formal privacy guarantee for such settings. This is obtained by a separation of the utility of the database and the risk of an individual to lose his/her privacy. In this contribution, we introduce the Laplace mechanism and a stochastic gradient descent methodology which guarantee differential privacy  [1] . Then, we show how these paradigms can be incorporated into two popular machine learning algorithm, namely GLVQ and GMLVQ. We demonstrate the results of privacy-preserving LVQ based on three benchmarks. * Funding by the CITEC center of excellence (EXC 277) is gratefully acknowledged.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-119.pdf,2018,100.0,"Differential private relevance learning Digital information is collected daily in growing volumes. Mutual benefits drive the demand for the exchange and publication of data among parties. However, it is often unclear how to handle these data properly in the case that the data contains sensitive information. Differential privacy has become a powerful principle for privacy-preserving data analysis tasks in the last few years, since it entails a formal privacy guarantee for such settings. This is obtained by a separation of the utility of the database and the risk of an individual to lose his/her privacy. In this contribution, we introduce the Laplace mechanism and a stochastic gradient descent methodology which guarantee differential privacy  [1] . Then, we show how these paradigms can be incorporated into two popular machine learning algorithm, namely GLVQ and GMLVQ. We demonstrate the results of privacy-preserving LVQ based on three benchmarks. * Funding by the CITEC center of excellence (EXC 277) is gratefully acknowledged."
Surprisal-Based Activation in Recurrent Neural Networks,"Tayfun Alpay, Stefan Wermter",1 - Department of Informatics University of Hamburg Vogt-Koelln-Str. 30 22527 Hamburg Germany,"Learning hierarchical abstractions from sequences is a challenging and open problem for Recurrent Neural Networks (RNNs). This is mainly due to the difficulty of detecting features that span over long distances with also different frequencies. In this paper, we address this challenge by introducing surprisal-based activation, a novel method to preserve activations contingent on encoding-based self-information. The preserved activations can be considered as temporal shortcuts with perfect memory. We evaluate surprisal-based activation on language modelling by testing it on the Penn Treebank corpus and find that it can improve performance when compared to a baseline RNN.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-211,2018,70.58823529411764,"Surprisal-Based Activation in Recurrent Neural Networks Learning hierarchical abstractions from sequences is a challenging and open problem for Recurrent Neural Networks (RNNs). This is mainly due to the difficulty of detecting features that span over long distances with also different frequencies. In this paper, we address this challenge by introducing surprisal-based activation, a novel method to preserve activations contingent on encoding-based self-information. The preserved activations can be considered as temporal shortcuts with perfect memory. We evaluate surprisal-based activation on language modelling by testing it on the Penn Treebank corpus and find that it can improve performance when compared to a baseline RNN."
Efficient Approximate Representations of Computationally Expensive Features,"Raul Santos-Rodriguez, Niall Twomey",1 - Intelligent Systems Laboratory University of Bristol UK,"High computational complexity is often a barrier to achieving desired representations in resource-constrained settings. This paper introduces a simple and computationally cheap method of approximating complex features. We do so by carefully constraining the architecture of Neural Networks (NNs) and regress from raw data to the intended feature representation. Our analysis focuses on spectral features, and demonstrates how low-capacity networks can capture the end-to-end dynamics of cascaded composite functions. Not only do approximating NNs simplify the analysis pipeline, but our approach produces feature representations up to 20 times more quickly. Excellent feature fidelity is achieved in our experimental analysis with feature approximations, but we also report nearly indistinguishable predictive performance when comparing between exact and approximate representations.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-122.pdf,2018,76.82119205298014,"Efficient Approximate Representations of Computationally Expensive Features High computational complexity is often a barrier to achieving desired representations in resource-constrained settings. This paper introduces a simple and computationally cheap method of approximating complex features. We do so by carefully constraining the architecture of Neural Networks (NNs) and regress from raw data to the intended feature representation. Our analysis focuses on spectral features, and demonstrates how low-capacity networks can capture the end-to-end dynamics of cascaded composite functions. Not only do approximating NNs simplify the analysis pipeline, but our approach produces feature representations up to 20 times more quickly. Excellent feature fidelity is achieved in our experimental analysis with feature approximations, but we also report nearly indistinguishable predictive performance when comparing between exact and approximate representations."
Slowness-based neural visuomotor control with an Intrinsically motivated Continuous Actor-Critic,"Muhammad Burhan Hafez, Matthias Kerzel, Cornelius Weber, Stefan Wermter",1 - Department of Informatics University of Hamburg Vogt-Koelln-Str. 30 22527 Hamburg Germany,"In this paper, we present a new visually guided exploration approach for autonomous learning of visuomotor skills. Our approach uses hierarchical Slow Feature Analysis for unsupervised learning of efficient state representation and an Intrinsically motivated Continuous Actor-Critic learner for neuro-optimal control. The system learns online an ensemble of local forward models and generates an intrinsic reward based on the learning progress of each learned forward model. Combined with the external reward, the intrinsic reward guides the system's exploration strategy. We evaluate the approach for the task of learning to reach an object using raw pixel data in a realistic robot simulator. The results show that the control policies learned with our approach are significantly better both in terms of length and average reward than those learned with any of the baseline algorithms.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-123.pdf,2018,100.0,"Slowness-based neural visuomotor control with an Intrinsically motivated Continuous Actor-Critic In this paper, we present a new visually guided exploration approach for autonomous learning of visuomotor skills. Our approach uses hierarchical Slow Feature Analysis for unsupervised learning of efficient state representation and an Intrinsically motivated Continuous Actor-Critic learner for neuro-optimal control. The system learns online an ensemble of local forward models and generates an intrinsic reward based on the learning progress of each learned forward model. Combined with the external reward, the intrinsic reward guides the system's exploration strategy. We evaluate the approach for the task of learning to reach an object using raw pixel data in a realistic robot simulator. The results show that the control policies learned with our approach are significantly better both in terms of length and average reward than those learned with any of the baseline algorithms."
On aggregation in ranking median regression,"Stephan Clémençon, Anna Korba",1 - Telecom ParisTech -LTCI Université Paris Saclay 46 rue Barrault 75634 Paris France,"In the present era of personalized customer services and recommender systems, predicting the preferences of an individual over a set of items indexed by n = {1, . . . , n}, n ≥ 1, based on its characteristics, modelled as a r.v. X say, is an ubiquitous issue. Though easy to state, this predictive problem referered to as ranking median regression (RMR in short) is very difficult to solve in practice. The major challenge lies in the fact that, here, the (discrete) output space is the symmetric group Sn, composed of all permutations of n , of explosive cardinality n!, and which is not a subset of a vector space. It is thus far from straightforward to build (non parametric) predictive rules taking their values in Sn, except by means of ranking aggregation techniques implemented at a local level, as proposed in [1] or  [2] . However, such local learning techniques exhibit high instability and it is the main goal of this paper to investigate to which extent Kemeny ranking aggregation of randomized RMR rules may remedy this drawback. Beyond a theoretical analysis establishing its validity, the relevance of this novel ensemble learning technique is supported by experimental results.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-124.pdf,2018,100.0,"On aggregation in ranking median regression In the present era of personalized customer services and recommender systems, predicting the preferences of an individual over a set of items indexed by n = {1, . . . , n}, n ≥ 1, based on its characteristics, modelled as a r.v. X say, is an ubiquitous issue. Though easy to state, this predictive problem referered to as ranking median regression (RMR in short) is very difficult to solve in practice. The major challenge lies in the fact that, here, the (discrete) output space is the symmetric group Sn, composed of all permutations of n , of explosive cardinality n!, and which is not a subset of a vector space. It is thus far from straightforward to build (non parametric) predictive rules taking their values in Sn, except by means of ranking aggregation techniques implemented at a local level, as proposed in [1] or  [2] . However, such local learning techniques exhibit high instability and it is the main goal of this paper to investigate to which extent Kemeny ranking aggregation of randomized RMR rules may remedy this drawback. Beyond a theoretical analysis establishing its validity, the relevance of this novel ensemble learning technique is supported by experimental results."
Anomaly Detection in Star Light Curves using Hierarchical Gaussian Processes,"Haoyan Chen, Tom Diethe, Niall Twomey, Peter Flach","1 - University of Bristol -Intelligent Systems Group Bristol UK
3 - Amazon Research Cambridge Cambridge UK","Here we examine astronomical time-series called light-curve data, which represent the brightness of celestial objects over a period of time. We focus specifically on the task of finding anomalies in three sets of light-curves of periodic variable stars. We employ a hierarchical Gaussian process to create a general and stable model of time series for anomaly detection, and apply this approach to the light curve problem. Hierarchical Gaussian processes require only a few additional parameters than Gaussian processes and incur negligible additional computational complexity. Additionally, the additional parameters are objectively optimised in a principled probabilistic framework. Experimentally, our approach outperforms several baselines and highlights several anomalous light curves in the datasets investigated.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-125.pdf,2018,76.31578947368422,"Anomaly Detection in Star Light Curves using Hierarchical Gaussian Processes Here we examine astronomical time-series called light-curve data, which represent the brightness of celestial objects over a period of time. We focus specifically on the task of finding anomalies in three sets of light-curves of periodic variable stars. We employ a hierarchical Gaussian process to create a general and stable model of time series for anomaly detection, and apply this approach to the light curve problem. Hierarchical Gaussian processes require only a few additional parameters than Gaussian processes and incur negligible additional computational complexity. Additionally, the additional parameters are objectively optimised in a principled probabilistic framework. Experimentally, our approach outperforms several baselines and highlights several anomalous light curves in the datasets investigated."
Efficient Accuracy Estimation for Instance-Based Incremental Active Learning,"Christian Limberg, Heiko Wersing, Helge Ritter","1 - Bielefeld University CoR-Lab Universitätsstraße 25 33615 Bielefeld Germany
2 - HONDA Research Institute Europe GmbH Carl-Legien-Straße 30 63065 Offenbach Germany","Estimating system's accuracy is crucial for applications of incremental learning. In this paper, we introduce the Distogram Estimation (DGE) approach to estimate the accuracy of instance-based classifiers. By calculating relative distances to samples it is possible to train an offline regression model, capable of predicting the classifier's accuracy on unseen data. Our approach requires only a few supervised samples for training and can instantaneously be applied on unseen data afterwards. We evaluate our method on five benchmark data sets and for a robot object recognition task. Our algorithm clearly outperforms two baseline methods both for random and active selection of incremental training examples.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-127.pdf,2018,73.6842105263158,"Efficient Accuracy Estimation for Instance-Based Incremental Active Learning Estimating system's accuracy is crucial for applications of incremental learning. In this paper, we introduce the Distogram Estimation (DGE) approach to estimate the accuracy of instance-based classifiers. By calculating relative distances to samples it is possible to train an offline regression model, capable of predicting the classifier's accuracy on unseen data. Our approach requires only a few supervised samples for training and can instantaneously be applied on unseen data afterwards. We evaluate our method on five benchmark data sets and for a robot object recognition task. Our algorithm clearly outperforms two baseline methods both for random and active selection of incremental training examples."
Controlling Biological Neural Networks with Deep Reinforcement Learning,"Jan Wülfing, Sreedhar Kumar, Joschka Boedecker, Martin Riedmiller, Ulrich Egert","1 - -Univ. of Freiburg -Dept. of Computer Science Germany
2 - Univ. of Freiburg -Dept. of Microsystems Engineering Germany
3 - -Univ. of Freiburg -Bernstein Center Freiburg Germany 4-DeepMind -London UK","Targeted interaction with networks in the brain is of immense therapeutic relevance. The highly dynamic nature of neuronal networks and changes with progressive diseases create an urgent need for closedloop control. Without adequate mathematical models of such complex networks, however, it remains unclear how tractable control problems can be formulated for neurobiological systems. Reinforcement learning (RL) could be a promising tool to address such challenges. Nevertheless, RL methods have rarely been applied to live, plastic neural networks. This study demonstrates that RL methods could help control response properties of biological neural networks with little prior knowledge of their complex dynamics.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-128.pdf,2018,77.46478873239437,"Controlling Biological Neural Networks with Deep Reinforcement Learning Targeted interaction with networks in the brain is of immense therapeutic relevance. The highly dynamic nature of neuronal networks and changes with progressive diseases create an urgent need for closedloop control. Without adequate mathematical models of such complex networks, however, it remains unclear how tractable control problems can be formulated for neurobiological systems. Reinforcement learning (RL) could be a promising tool to address such challenges. Nevertheless, RL methods have rarely been applied to live, plastic neural networks. This study demonstrates that RL methods could help control response properties of biological neural networks with little prior knowledge of their complex dynamics."
Latent representations of transient candidates from an astronomical image difference pipeline using Variational Autoencoders,"Pablo Huijse, Nicolas Astorga, Pablo Estévez, Giuliano Pignata","1 - Universidad de Chile -Dept. of Electrical Engineering Av. Tupper 2007 Santiago Chile
2 - Millennium Institute of Astrophysics Av. Vicuña Mackenna 4860 Macul, Santiago Chile
7 - Universidad Andrés Bello -Dept. of Astrophysics Fernández Concha 700 Las Condes Santiago Chile","The Chilean Automatic Supernovae SEarch (CHASE) is a survey designed to detect early Supernovae. In this paper we explore deep autoencoders to obtain a compressed latent space for a large transient candidate database from the CHASE image difference pipeline. Compared to conventional methods, the latent variables obtained with variational autoencoders preserve more information and are more discriminative towards real astronomical transients.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-130.pdf,2018,100.0,"Latent representations of transient candidates from an astronomical image difference pipeline using Variational Autoencoders The Chilean Automatic Supernovae SEarch (CHASE) is a survey designed to detect early Supernovae. In this paper we explore deep autoencoders to obtain a compressed latent space for a large transient candidate database from the CHASE image difference pipeline. Compared to conventional methods, the latent variables obtained with variational autoencoders preserve more information and are more discriminative towards real astronomical transients."
DEEP: Decomposition Feature Enhancement Procedure for Graphs,"Dinh Van Tran, Nicolò Navarin, Alessandro Sperduti","1 - Department of Mathematics Via Trieste 63 University of Padova 35121 Padova Italy
4 - Department of Mathematics University of Padova
5 - DEEPer project","When dealing with machine learning on graphs, one of the most successfully approaches is the one of kernel methods. Depending if one is interested in predicting properties of graphs (e.g. graph classification) or to predict properties of nodes in a single graph (e.g. graph node classification), different kernel functions should be adopted. In the last few years, several kernels for graphs have been defined in literature that extract local features from the input graphs, obtaining both efficiency and state-of-the-art predictive performances. Recently, some work has been done in this direction also regarding graph node kernels, but the majority of the graph node kernels available in literature consider only global information, that can be not optimal for many tasks. In this paper, we propose a procedure that allows to transform a local graph kernel in a kernel for nodes in a single, huge graph. We apply a specific instantiation to the task of disease gene prioritization from the bioinformatics domain, improving the state of the art in many diseases.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-131.pdf,2018,85.0,"DEEP: Decomposition Feature Enhancement Procedure for Graphs When dealing with machine learning on graphs, one of the most successfully approaches is the one of kernel methods. Depending if one is interested in predicting properties of graphs (e.g. graph classification) or to predict properties of nodes in a single graph (e.g. graph node classification), different kernel functions should be adopted. In the last few years, several kernels for graphs have been defined in literature that extract local features from the input graphs, obtaining both efficiency and state-of-the-art predictive performances. Recently, some work has been done in this direction also regarding graph node kernels, but the majority of the graph node kernels available in literature consider only global information, that can be not optimal for many tasks. In this paper, we propose a procedure that allows to transform a local graph kernel in a kernel for nodes in a single, huge graph. We apply a specific instantiation to the task of disease gene prioritization from the bioinformatics domain, improving the state of the art in many diseases."
Temporal modeling of ALS using longitudinal data and long-short term memory-based algorithm,"Aviv Nahon, Boaz Lerner",1 - Department of Industrial Engineering and Management Beer Sheva Ben-Gurion University of the Negev Israel,"ALS is a neurodegenerative disease where factors such as disease progression rate and pattern vary greatly among patients. Since patient functionality deteriorates over time, we model ALS temporally to mimic the physician's reasoning by incorporating old with new information using a long-short term memory (LSTM) network. We demonstrate that the LSTM achieves a higher accuracy than a random forest in disease state prediction, and improves accuracy with data from additional clinic visits. Being an anytime predictor, our model can help physicians and caregivers to adjust patients' treatment and living environment along the disease period, improving patients' life quality.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-133.pdf,2018,100.0,"Temporal modeling of ALS using longitudinal data and long-short term memory-based algorithm ALS is a neurodegenerative disease where factors such as disease progression rate and pattern vary greatly among patients. Since patient functionality deteriorates over time, we model ALS temporally to mimic the physician's reasoning by incorporating old with new information using a long-short term memory (LSTM) network. We demonstrate that the LSTM achieves a higher accuracy than a random forest in disease state prediction, and improves accuracy with data from additional clinic visits. Being an anytime predictor, our model can help physicians and caregivers to adjust patients' treatment and living environment along the disease period, improving patients' life quality."
Scalable robust clustering method for large and sparse data,"Joonas Hämäläinen, Tommi Kärkkäinen, Tuomo Rossi",1 - Faculty of Information Technology University of Jyvaskyla University of Jyvaskyla P.O. Box 35 FI-40014 Finland,"Datasets for unsupervised clustering can be large and sparse, with significant portion of missing values. We present here a scalable version of a robust clustering method with the available data strategy. More precisely, a general algorithm is described and the accuracy and scalability of a distributed implementation of the algorithm is tested. The obtained results allow us to conclude the viability of the proposed approach.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-134.pdf,2018,100.0,"Scalable robust clustering method for large and sparse data Datasets for unsupervised clustering can be large and sparse, with significant portion of missing values. We present here a scalable version of a robust clustering method with the available data strategy. More precisely, a general algorithm is described and the accuracy and scalability of a distributed implementation of the algorithm is tested. The obtained results allow us to conclude the viability of the proposed approach."
Local Rademacher Complexity Machine,"Luca Oneto, Sandro Ridella, Davide Anguita","1 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy
2 - DITEN -University of Genova Via Opera Pia 11A I-16145 Genova Italy","In this paper we present the Local Rademacher Complexity Machine, a transposition of the Local Rademacher Complexity Theory into a learning algorithm. By exploiting a series of real world small-sample datasets, we show the advantages of our proposal with respect to the Support Vector Machines, i.e. the transposition of the milestone results of V. N. Vapnik and A. Chervonenkis into a learning algorithm.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-139.pdf,2018,100.0,"Local Rademacher Complexity Machine In this paper we present the Local Rademacher Complexity Machine, a transposition of the Local Rademacher Complexity Theory into a learning algorithm. By exploiting a series of real world small-sample datasets, we show the advantages of our proposal with respect to the Support Vector Machines, i.e. the transposition of the milestone results of V. N. Vapnik and A. Chervonenkis into a learning algorithm."
Learning compressed representations of blood samples time series with missing data,"Maria Filippo, Karl Bianchi, Robert Mikalsen, Jenssen",1 - Machine Learning Group -UiT Arctic University of Norway,"Clinical measurements collected over time are naturally represented as multivariate time series (MTS), which often contain missing data. An autoencoder can learn low dimensional vectorial representations of MTS that preserve important data characteristics, but cannot deal explicitly with missing data. In this work, we propose a new framework that combines an autoencoder with the Time series Cluster Kernel (TCK), a kernel that accounts for missingness patterns in MTS. Via kernel alignment, we incorporate TCK in the autoencoder to improve the learned representations in presence of missing data. We consider a classification problem of MTS with missing values, representing blood samples of patients with surgical site infection. With our approach, rather than with a standard autoencoder, we learn representations in low dimensions that can be classified better.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-14.pdf,2018,100.0,"Learning compressed representations of blood samples time series with missing data Clinical measurements collected over time are naturally represented as multivariate time series (MTS), which often contain missing data. An autoencoder can learn low dimensional vectorial representations of MTS that preserve important data characteristics, but cannot deal explicitly with missing data. In this work, we propose a new framework that combines an autoencoder with the Time series Cluster Kernel (TCK), a kernel that accounts for missingness patterns in MTS. Via kernel alignment, we incorporate TCK in the autoencoder to improve the learned representations in presence of missing data. We consider a classification problem of MTS with missing values, representing blood samples of patients with surgical site infection. With our approach, rather than with a standard autoencoder, we learn representations in low dimensions that can be classified better."
LANN-DSVD: A privacy-preserving distributed algorithm for machine learning,"Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas, Beatriz Pérez-Sánchez, Marcelo Gómez-Casal",1 - Universidade da Coruña Centro de Investigación en Tecnologías de la Información y las Comunicaciones (CITIC) Elviña 15071 Spain,"In the Big Data era new challenges have arisen in machine learning related with the Volume (high number of samples or variables), the Velocity, etc. making many of the classic and brilliant methods not applicable. One main concern derives from Privacy issues when data is distributed and cannot be shared among locations. Herein, we present LANN-DSVD a non iterative algorithm for One-Layer Neural Networks that allows distributed learning guaranteeing privacy. Moreover, it is non iterative, parameter-free and provides incremental learning, thus making it very suitable to manage huge and/or continuous data. Results demonstrate its competitiveness both in efficiency and efficacy.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-140.pdf,2018,100.0,"LANN-DSVD: A privacy-preserving distributed algorithm for machine learning In the Big Data era new challenges have arisen in machine learning related with the Volume (high number of samples or variables), the Velocity, etc. making many of the classic and brilliant methods not applicable. One main concern derives from Privacy issues when data is distributed and cannot be shared among locations. Herein, we present LANN-DSVD a non iterative algorithm for One-Layer Neural Networks that allows distributed learning guaranteeing privacy. Moreover, it is non iterative, parameter-free and provides incremental learning, thus making it very suitable to manage huge and/or continuous data. Results demonstrate its competitiveness both in efficiency and efficacy."
Near-optimal facial emotion classification using a WiSARD-based weightless system,"Leopoldo Lusquino Filho, Felipe França, Priscila Lima","1 - PESC COPPE
3 - NCE Universidade Federal do Rio de Janeiro Brazil","The recognition of facial expressions through the use of a WiSARD-based n-tuple classifier is explored in this work. The competitiveness of this weightless neural network is tested in the specific challenge of identifying emotions from photos of faces, limited to the six basic emotions described in the seminal work of  Ekman and Friesen (1977)  on identification of facial expressions. Current state-of-the-art for this problem uses a convolutional neural network (CNN), with accuracy of 100% and 99.6% in the Cohn-Kanade and MMI datasets, respectively, with the proposed WiSARD-based architecture reaching accuracy of 100% and 99.4% in the same datasets.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-141.pdf,2018,100.0,"Near-optimal facial emotion classification using a WiSARD-based weightless system The recognition of facial expressions through the use of a WiSARD-based n-tuple classifier is explored in this work. The competitiveness of this weightless neural network is tested in the specific challenge of identifying emotions from photos of faces, limited to the six basic emotions described in the seminal work of  Ekman and Friesen (1977)  on identification of facial expressions. Current state-of-the-art for this problem uses a convolutional neural network (CNN), with accuracy of 100% and 99.6% in the Cohn-Kanade and MMI datasets, respectively, with the proposed WiSARD-based architecture reaching accuracy of 100% and 99.4% in the same datasets."
Spatial Pooling as Feature Selection Method for Object Recognition,"Murat Kirtay, Lorenzo Vannucci, Ugo Albanese, Alessandro Ambrosano, Egidio Falotico, Cecilia Laschi",1 - The BioRobotics Institute Scuola Superiore Sant'Anna Pontedera (PI) Italy,"This paper reports our work on object recognition by using the spatial pooler of Hierarchical Temporal Memory (HTM) as a method for feature selection. To perform the recognition task, we employed this pooling method to select features from COIL-100 dataset. We benchmarked the results with state-of-the-art feature extraction methods while using different amounts of training data (from 5% to 45%). The results indicate that the performed method is effective for object recognition with a low amount of training data in which state-of-the-art feature extraction methods show limitations.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-142.pdf,2018,68.18181818181819,"Spatial Pooling as Feature Selection Method for Object Recognition This paper reports our work on object recognition by using the spatial pooler of Hierarchical Temporal Memory (HTM) as a method for feature selection. To perform the recognition task, we employed this pooling method to select features from COIL-100 dataset. We benchmarked the results with state-of-the-art feature extraction methods while using different amounts of training data (from 5% to 45%). The results indicate that the performed method is effective for object recognition with a low amount of training data in which state-of-the-art feature extraction methods show limitations."
Set point thresholds from topological data analysis and an outlier detector,Alessio Carrega,1 - aizoOn -Technology Consulting Torre San Vincenzo Via San Vincenzo 2 16-th floor 16121 Genova Italy,"We provide an algorithm for unsupervised or semi-supervised learning to determine, once the input settings are given, a very easily described zone of optimal execution settings for a production. A region is very easily described if anyone can determine whether a point is inside it and select a point on it with a certain range of choice. This can be applied both in production optimization and in predictive maintenance. Part of the method is based on a topological data analysis tool: Mapper. We also provide a method to detect outliers on new data.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-143.pdf,2018,100.0,"Set point thresholds from topological data analysis and an outlier detector We provide an algorithm for unsupervised or semi-supervised learning to determine, once the input settings are given, a very easily described zone of optimal execution settings for a production. A region is very easily described if anyone can determine whether a point is inside it and select a point on it with a certain range of choice. This can be applied both in production optimization and in predictive maintenance. Part of the method is based on a topological data analysis tool: Mapper. We also provide a method to detect outliers on new data."
Unsupervised domain adaptation of deep object detectors,"Debjeet Majumdar, Vinay Namboodiri",1 - Indian Institute of Technology Kanpur -Computer Science and Engineering Kalyanpur 208016 Kanpur Uttar Pradesh India,"Domain adaptation has been understood and adopted in vision. Recently with the advent of deep learning there are a number of techniques that propose methods for deep learning based domain adaptation. However, the methods proposed have been used for adapting object classification techniques. In this paper, we solve for domain adaptation of object detection that is more commonly used. We adapt deep adaptation techniques for the Faster R-CNN framework. The techniques that we adapt are the recent techniques based on Gradient Reversal and Maximum Mean Discrepancy (MMD) reduction based techniques. Among them we show that the MK-MMD based method when used appropriately provides the best results. We analyze our model with standard real world settings by using Pascal VOC as source and MS-COCO as target and show a gain of 2.5 mAP at IoU of 0.5 over a source only trained model. We show that this improvement is statistically significant.",Shallow and Deep models for transfer learning and domain adaptation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-145.pdf,2018,100.0,"Unsupervised domain adaptation of deep object detectors Domain adaptation has been understood and adopted in vision. Recently with the advent of deep learning there are a number of techniques that propose methods for deep learning based domain adaptation. However, the methods proposed have been used for adapting object classification techniques. In this paper, we solve for domain adaptation of object detection that is more commonly used. We adapt deep adaptation techniques for the Faster R-CNN framework. The techniques that we adapt are the recent techniques based on Gradient Reversal and Maximum Mean Discrepancy (MMD) reduction based techniques. Among them we show that the MK-MMD based method when used appropriately provides the best results. We analyze our model with standard real world settings by using Pascal VOC as source and MS-COCO as target and show a gain of 2.5 mAP at IoU of 0.5 over a source only trained model. We show that this improvement is statistically significant."
Evolutionary RL for Container Loading,"S Saikia, R Verma, P Agarwal, G Shroff, L Vig, A Srinivasan",1 - Department of Computer Science BITS-Pilani Goa,"Loading the containers on the ship from a yard, is an important part of port operations. Finding the optimal sequence for the loading of containers, is known to be computationally hard and is an example of combinatorial optimization, which leads to the application of simple heuristics in practice. In this paper, we propose an approach which uses a mix of Evolutionary Strategies and Reinforcement Learning (RL) techniques to find an approximation of the optimal solution. The RL based agent uses the Policy Gradient method, an evolutionary reward strategy and a Pool of good (not-optimal) solutions to find the approximation. We find that the RL agent learns near-optimal solutions that outperforms the heuristic solutions. We also observe that the RL agent assisted with a pool generalizes better for unseen problems than an RL agent without a pool. We present our results on synthetic data as well as on subsets of real-world problems taken from container terminal. The results validate that our approach does comparatively better than the heuristics solutions available, and adapts to unseen problems better.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-149.pdf,2018,100.0,"Evolutionary RL for Container Loading Loading the containers on the ship from a yard, is an important part of port operations. Finding the optimal sequence for the loading of containers, is known to be computationally hard and is an example of combinatorial optimization, which leads to the application of simple heuristics in practice. In this paper, we propose an approach which uses a mix of Evolutionary Strategies and Reinforcement Learning (RL) techniques to find an approximation of the optimal solution. The RL based agent uses the Policy Gradient method, an evolutionary reward strategy and a Pool of good (not-optimal) solutions to find the approximation. We find that the RL agent learns near-optimal solutions that outperforms the heuristic solutions. We also observe that the RL agent assisted with a pool generalizes better for unseen problems than an RL agent without a pool. We present our results on synthetic data as well as on subsets of real-world problems taken from container terminal. The results validate that our approach does comparatively better than the heuristics solutions available, and adapts to unseen problems better."
Regularize and Explicit Collaborative Filtering With Textual Attention,"Charles-Emmanuel Dias, Vincent Guigue, Patrick Gallinari","1 - UMR 7606 Sorbonne Universités UPMC Univ Paris 06 LIP6, F-75005 Paris France","Recommendation can be seen as tantamount to blind sentiment analysis, i.e. a sentiment prediction without text data. In that sense, we aim at encoding priors on users and items while reading their reviews, using a deep architecture with personalized attention modeling. Following this idea, we build an hybrid hierarchical sentiment classifier which is then used as a recommender system in inference.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-152.pdf,2018,70.0,"Regularize and Explicit Collaborative Filtering With Textual Attention Recommendation can be seen as tantamount to blind sentiment analysis, i.e. a sentiment prediction without text data. In that sense, we aim at encoding priors on users and items while reading their reviews, using a deep architecture with personalized attention modeling. Following this idea, we build an hybrid hierarchical sentiment classifier which is then used as a recommender system in inference."
Incremental learning with deep neural networks using a test-time oracle,"Alexander Gepperth, Saad Gondal",1 - Dept of Applied Computer Science University of Applied Sciences Fulda Leipzigerstr. 123 36037 Fulda Germany,"We present a simple idea to avoid catastrophic forgetting when training deep neural networks (DNNs) on class-incremental tasks. This means that initial training is conducted on a sub-task described by a dataset D1, whereas re-training is conducted subsequently, on a sub-task described by a dataset D2 that is composed of different classes. As our recent work suggest that DNNs perform very poorly at this problem, we propose a simple extension that proposes an individually trained readout layer for each sub-task. While this is unproblematic for training, a clustering method (the oracle) is used at test time to determine which sub-task a sample most likely belongs to. Experiments on simple benchmarks derived from MNIST show the effectiveness of this method for which a dedicated TensorFlow implementation is made available.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-154.pdf,2018,100.0,"Incremental learning with deep neural networks using a test-time oracle We present a simple idea to avoid catastrophic forgetting when training deep neural networks (DNNs) on class-incremental tasks. This means that initial training is conducted on a sub-task described by a dataset D1, whereas re-training is conducted subsequently, on a sub-task described by a dataset D2 that is composed of different classes. As our recent work suggest that DNNs perform very poorly at this problem, we propose a simple extension that proposes an individually trained readout layer for each sub-task. While this is unproblematic for training, a clustering method (the oracle) is used at test time to determine which sub-task a sample most likely belongs to. Experiments on simple benchmarks derived from MNIST show the effectiveness of this method for which a dedicated TensorFlow implementation is made available."
Active Learning based on Transfer Learning Techniques for Image Classification,"Daniela Onita, Adriana Birlutiu",1 - Faculty of Science -1 Decembrie 1918 University of Alba Iulia Gabriel Bethlen Nr.5 510009 Alba Iulia -Romania,"In many imaging tasks only an expert can annotate the data. Though domain experts are available, their labor is expensive and we would like to avoid querying them whenever possible. Our task is to make use of our resources as efficient as possible for a learning task. There are various ways of working in cases of labelled data shortage. This type of learning problems can be approached with Active and Transfer Learning techniques. Active Learning and Transfer Learning have demonstrated their efficiency and ability to train accurate models with significantly reduced amount of training data in many real-life applications. In this paper we investigate the combination of Active and Transfer Learning for building an efficient algorithm for image classification. The experimental results show that by combining active and transfer learning, we can learn faster with fewer labels on a target domain than by random selection.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-155.pdf,2018,100.0,"Active Learning based on Transfer Learning Techniques for Image Classification In many imaging tasks only an expert can annotate the data. Though domain experts are available, their labor is expensive and we would like to avoid querying them whenever possible. Our task is to make use of our resources as efficient as possible for a learning task. There are various ways of working in cases of labelled data shortage. This type of learning problems can be approached with Active and Transfer Learning techniques. Active Learning and Transfer Learning have demonstrated their efficiency and ability to train accurate models with significantly reduced amount of training data in many real-life applications. In this paper we investigate the combination of Active and Transfer Learning for building an efficient algorithm for image classification. The experimental results show that by combining active and transfer learning, we can learn faster with fewer labels on a target domain than by random selection."
Non-Negative Tensor Dictionary Learning,"Abraham Traoré, Maxime Berar, Alain Rakotomamonjy",1 - LITIS Normandie Université University of Rouen 76800 Saint-Etienne du Rouvray FRANCE,"A challenge faced by dictionary learning and non-negative matrix factorization is to efficiently model, in a context of feature learning, temporal patterns for data presenting sequential (two-dimensional) structure such as spectrograms. In this paper, we address this issue through tensor factorization. For this purpose, we make clear the connection between dictionary learning and tensor factorization when several examples are available. From this connection, we derive a novel (supervised) learning problem which induces emergence of temporal patterns in the learned dictionary. Obtained features are compared in a classification framework with those obtained by NMF and achieve promising results.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-156.pdf,2018,100.0,"Non-Negative Tensor Dictionary Learning A challenge faced by dictionary learning and non-negative matrix factorization is to efficiently model, in a context of feature learning, temporal patterns for data presenting sequential (two-dimensional) structure such as spectrograms. In this paper, we address this issue through tensor factorization. For this purpose, we make clear the connection between dictionary learning and tensor factorization when several examples are available. From this connection, we derive a novel (supervised) learning problem which induces emergence of temporal patterns in the learned dictionary. Obtained features are compared in a classification framework with those obtained by NMF and achieve promising results."
An extension of nonstationary fuzzy sets to heteroskedastic fuzzy time series,"Marcos Alves, Petrônio Cândido De Lima E Silva, Carlos Severiano Junior, Gustavo Linhares Vieira, Frederico Gadelha Guimaraes, Hossein Sadaei","1 - Graduate Program in Electrical Engineering -Universidade Federal de Minas Gerais Av 6627, 31270-901 Belo Horizonte Antônio Carlos, MG Brazil
3 - Instituto Federal do Norte de Minas Gerais (IFNMG) Rua Coronel Luiz Pires Montes Claros 202 Centro, MG Brazil
5 - Instituto Federal de Minas Gerais (IFMG) -Campus Sabará Av. Serra da Piedade Morada da Serra 299 Sabará Conj, MG Brazil
7 - Universidade Federal de Minas Gerais (UFMG) -Dept. of Electrical Engineering Av Belo Horizonte 6627, 31270-901 Antonio Carlos, MG Brazil","Most applications deal with unconditional variance of the time series. Fuzzy time series allow an inexpensive computation to forecasting dynamic processes and uncertainties. In this paper we have extended the concept of nonstationary fuzzy sets to Fuzzy Time Series, termed Nonstationary Fuzzy Time Series (NSFTS). While some models require new data before adapting, the NSFTS is capable of adapting to heteroskedastic time series. In the experiments, NSFTS outperformed other known FTS methods with box-cox transformations available. Statistical tests in three different datasets indicate that the results achieved by the proposed model are either superior or non-inferior to other FTS models. * This work has been supported by the Brazilian agencies FAPEMIG, CAPES and CNPq.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-157.pdf,2018,100.0,"An extension of nonstationary fuzzy sets to heteroskedastic fuzzy time series Most applications deal with unconditional variance of the time series. Fuzzy time series allow an inexpensive computation to forecasting dynamic processes and uncertainties. In this paper we have extended the concept of nonstationary fuzzy sets to Fuzzy Time Series, termed Nonstationary Fuzzy Time Series (NSFTS). While some models require new data before adapting, the NSFTS is capable of adapting to heteroskedastic time series. In the experiments, NSFTS outperformed other known FTS methods with box-cox transformations available. Statistical tests in three different datasets indicate that the results achieved by the proposed model are either superior or non-inferior to other FTS models. * This work has been supported by the Brazilian agencies FAPEMIG, CAPES and CNPq."
G-Rap: Interactive text synthesis using recurrent neural network suggestions,"Udo Schlegel, Eren Cakmak, Juri Buchmüller, Daniel Keim",1 - University of Konstanz -Data Analysis and Visualization Group Konstanz Germany,"Finding the best neural network configuration for a given goal can be challenging, especially when it is not possible to assess the output quality of a network automatically. We present G-Rap, an interactive interface based on Visual Analytics principles for comparing outputs of multiple RNNs for the same training data. G-Rap enables an iterative result generation process that allows a user to evaluate the outputs with contextual statistics.",Interaction and User Integration in Machine Learning for Information Visualisation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-158.pdf,2018,98.68421052631578,"G-Rap: Interactive text synthesis using recurrent neural network suggestions Finding the best neural network configuration for a given goal can be challenging, especially when it is not possible to assess the output quality of a network automatically. We present G-Rap, an interactive interface based on Visual Analytics principles for comparing outputs of multiple RNNs for the same training data. G-Rap enables an iterative result generation process that allows a user to evaluate the outputs with contextual statistics."
Comparison of Cluster Validation Indices with Missing Data,"Marko Niemelä, Sami Äyrämö, Tommi Kärkkäinen","1 - Faculty of Information Technology University of Jyvaskylä PO Box 35 FI-40014 Jyväskylä Finland
2 - Niilo Mäki Institute PO Box 35 FI-40014 Jyväskylä Finland","Clustering is an unsupervised machine learning technique, which aims to divide a given set of data into subsets. The number of hidden groups in cluster analysis is not always obvious and, for this purpose, various cluster validation indices have been suggested. Recently some studies reviewing validation indices have been provided, but any experiments against missing data are not yet available. In this paper, performance of ten well-known indices on ten synthetic data sets with various ratios of missing values is measured using squared euclidean and city block distances based clustering. The original indices are modified for a city block distance in a novel way. Experiments illustrate the different degree of stability for the indices with respect to the missing data. * The work has been supported by the Academy of Finland from the project 311737 ( DysGeBra) † The work has been supported by the Academy of Finland from the projects 311877 (Demo) and 315550 (HNP-AI)",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-16.pdf,2018,74.13793103448276,"Comparison of Cluster Validation Indices with Missing Data Clustering is an unsupervised machine learning technique, which aims to divide a given set of data into subsets. The number of hidden groups in cluster analysis is not always obvious and, for this purpose, various cluster validation indices have been suggested. Recently some studies reviewing validation indices have been provided, but any experiments against missing data are not yet available. In this paper, performance of ten well-known indices on ten synthetic data sets with various ratios of missing values is measured using squared euclidean and city block distances based clustering. The original indices are modified for a city block distance in a novel way. Experiments illustrate the different degree of stability for the indices with respect to the missing data. * The work has been supported by the Academy of Finland from the project 311737 ( DysGeBra) † The work has been supported by the Academy of Finland from the projects 311877 (Demo) and 315550 (HNP-AI)"
Radar Based Pedestrian Detection using Support Vector Machine and the Micro Doppler Effect,"João Victor, Bruneti Severino, Alessandro Zimmer, Leandro Dos, Santos Coelho, Roberto Freire","1 - Pontifical Catholic University of Parana -PUCPR -Polytechnic School Imaculada Conceição 1155 -Postal Code 80215-901 Curitiba PR Brazil
2 - Federal University of Parana (UFPR) -Dept. of Electrical Engineering","Based on alarming statistics related to both pedestrian fatalities and injuries in traffic accidents, this paper presents the development of a pedestrian detection method for an Advanced Driving Assistance System (ADAS). Using a 79GHz automotive radar, a signal processing application that can early identify pedestrians in short range situations using Support Vector Machine (SVM) was presented and evaluated in order to improve the velocity resolution for the micro Doppler effects extraction. By assuming pre-processing multiobjective optimization, promising results in terms of velocity resolution and measuring time were obtained, improving the accuracy of the classifier.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-161.pdf,2018,100.0,"Radar Based Pedestrian Detection using Support Vector Machine and the Micro Doppler Effect Based on alarming statistics related to both pedestrian fatalities and injuries in traffic accidents, this paper presents the development of a pedestrian detection method for an Advanced Driving Assistance System (ADAS). Using a 79GHz automotive radar, a signal processing application that can early identify pedestrians in short range situations using Support Vector Machine (SVM) was presented and evaluated in order to improve the velocity resolution for the micro Doppler effects extraction. By assuming pre-processing multiobjective optimization, promising results in terms of velocity resolution and measuring time were obtained, improving the accuracy of the classifier."
Image-to-Text Transduction with Spatial Self-Attention,"Sebastian Springenberg, Egor Lakomkin, Cornelius Weber, Stefan Wermter",1 - University of Hamburg -Dept. of Informatics Knowledge Technology Vogt-Kölln-Straße 30 22527 Hamburg Germany,"Attention mechanisms have been shown to improve recurrent encoder-decoder architectures in sequence-to-sequence learning scenarios. Recently, the Transformer model has been proposed which only applies dot-product attention and omits recurrent operations to obtain a sourcetarget mapping  [5] . In this paper we show that the concepts of self-and inter-attention can effectively be applied in an image-to-text task. The encoder applies pre-trained convolution and pooling operations followed by self-attention to obtain an image feature representation. Self-attention combines image features of regions based on their similarity before they are made accessible to the decoder through inter-attention.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-162.pdf,2018,100.0,"Image-to-Text Transduction with Spatial Self-Attention Attention mechanisms have been shown to improve recurrent encoder-decoder architectures in sequence-to-sequence learning scenarios. Recently, the Transformer model has been proposed which only applies dot-product attention and omits recurrent operations to obtain a sourcetarget mapping  [5] . In this paper we show that the concepts of self-and inter-attention can effectively be applied in an image-to-text task. The encoder applies pre-trained convolution and pooling operations followed by self-attention to obtain an image feature representation. Self-attention combines image features of regions based on their similarity before they are made accessible to the decoder through inter-attention."
Deep Echo State Networks for Diagnosis of Parkinson's Disease,"Claudio Gallicchio, Alessio Micheli, Luca Pedrelli",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"In this paper, we introduce a novel approach for diagnosis of Parkinson's Disease (PD) based on deep Echo State Networks (ESNs). The identification of PD is performed by analyzing the whole time-series collected from a tablet device during the sketching of spiral tests, without the need for feature extraction and data preprocessing. We evaluated the proposed approach on a public dataset of spiral tests. The results of experimental analysis show that DeepESNs perform significantly better than shallow ESN model. Overall, the proposed approach obtains stateof-the-art results in the identification of PD on this kind of temporal data.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-163.pdf,2018,100.0,"Deep Echo State Networks for Diagnosis of Parkinson's Disease In this paper, we introduce a novel approach for diagnosis of Parkinson's Disease (PD) based on deep Echo State Networks (ESNs). The identification of PD is performed by analyzing the whole time-series collected from a tablet device during the sketching of spiral tests, without the need for feature extraction and data preprocessing. We evaluated the proposed approach on a public dataset of spiral tests. The results of experimental analysis show that DeepESNs perform significantly better than shallow ESN model. Overall, the proposed approach obtains stateof-the-art results in the identification of PD on this kind of temporal data."
Properties of adv −1 -Adversarials of Adversarials,"Nils Worzyk, Oliver Kramer",1 - University of Oldenburg -Dept. of Computing Science Oldenburg Germany,"Neural networks are very successful in the domain of image processing, but they are still vulnerable against adversarial imagescarefully crafted images to fool the neural network during image classification. There are already some attacks to create those adversarial images, therefore the transition from original images to adversarial images is well understood. In this paper we apply adversarial attacks on adversarial images. These new images are called adv −1 . The goal is to investigate the transition from adversarial images to adv −1 images. This knowledge can be used to 1.) identify adversarial images and 2.) to find the original class of adversarial images.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-164.pdf,2018,88.67924528301887,"Properties of adv −1 -Adversarials of Adversarials Neural networks are very successful in the domain of image processing, but they are still vulnerable against adversarial imagescarefully crafted images to fool the neural network during image classification. There are already some attacks to create those adversarial images, therefore the transition from original images to adversarial images is well understood. In this paper we apply adversarial attacks on adversarial images. These new images are called adv −1 . The goal is to investigate the transition from adversarial images to adv −1 images. This knowledge can be used to 1.) identify adversarial images and 2.) to find the original class of adversarial images."
A Sub-Layered Hierarchical Pyramidal Neural Architecture for Facial Expression Recognition,"Henrique Siqueira, Pablo Barros, Sven Magg, Cornelius Weber, Stefan Wermter",1 - Knowledge Technology Department of Informatics University of Hamburg Vogt-Koelln-Str. 30 22527 Hamburg Germany,"In domains where computational resources and labeled data are limited, such as in robotics, deep networks with millions of weights might not be the optimal solution. In this paper, we introduce a connectivity scheme for pyramidal architectures to increase their capacity for learning features. Experiments on facial expression recognition of unseen people demonstrate that our approach is a potential candidate for applications with restricted resources, due to good generalization performance and low computational cost. We show that our approach generalizes as well as convolutional architectures in this task but uses fewer trainable parameters and is more robust for low-resolution faces.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-166.pdf,2018,100.0,"A Sub-Layered Hierarchical Pyramidal Neural Architecture for Facial Expression Recognition In domains where computational resources and labeled data are limited, such as in robotics, deep networks with millions of weights might not be the optimal solution. In this paper, we introduce a connectivity scheme for pyramidal architectures to increase their capacity for learning features. Experiments on facial expression recognition of unseen people demonstrate that our approach is a potential candidate for applications with restricted resources, due to good generalization performance and low computational cost. We show that our approach generalizes as well as convolutional architectures in this task but uses fewer trainable parameters and is more robust for low-resolution faces."
Regularised maximum-likelihood inference of mixture of experts for regression and clustering,"Bao Huynh, Faicel Chamroukhi",1 - Normandie Univ UNICAEN CNRS LMNO 14000 Caen France,"Variable selection is fundamental to high-dimensional statistical modeling, and is challenging in particular in unsupervised modeling, including mixture models. We propose a regularised maximumlikelihood inference of the Mixture of Experts model which is able to deal with potentially correlated features and encourages sparse models in a potentially high-dimensional scenarios. We develop a hybrid Expectation-Majorization-Maximization (EM/MM) algorithm for model fitting. Unlike state-of-the art regularised ML inference [1, 2], the proposed modeling doesn't require an approximate of the regularisation. The proposed algorithm allows to automatically obtain sparse solutions without thresholding, and includes coordinate descent updates avoiding matrix inversion. An experimental study shows the capability of the algorithm to retrieve sparse solutions and for model fitting in model-based clustering of regression data.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-167.pdf,2018,100.0,"Regularised maximum-likelihood inference of mixture of experts for regression and clustering Variable selection is fundamental to high-dimensional statistical modeling, and is challenging in particular in unsupervised modeling, including mixture models. We propose a regularised maximumlikelihood inference of the Mixture of Experts model which is able to deal with potentially correlated features and encourages sparse models in a potentially high-dimensional scenarios. We develop a hybrid Expectation-Majorization-Maximization (EM/MM) algorithm for model fitting. Unlike state-of-the art regularised ML inference [1, 2], the proposed modeling doesn't require an approximate of the regularisation. The proposed algorithm allows to automatically obtain sparse solutions without thresholding, and includes coordinate descent updates avoiding matrix inversion. An experimental study shows the capability of the algorithm to retrieve sparse solutions and for model fitting in model-based clustering of regression data."
Boolean kernels for interpretable kernel machines,"Mirko Polato, Fabio Aiolli",1 - Department of Mathematics Via Trieste University of Padova 63 35121 Padova Italy,"Most of the machine learning (ML) community's efforts in the last decades have been devoted to improving the power and the prediction quality of ML models at the expense of their interpretability. However, nowadays, ML is becoming more and more ubiquitous and it is increasingly demanded the need for models that can be interpreted. To this end, in this work we propose a method for extracting explanation rules from a kernel machine. The core idea is based on using kernels with feature spaces composed by logical propositions. On top of that, a searching algorithm tries to retrieve the most relevant features/rules that can be used to explain the trained model. Experiments on several benchmarks and artificial datasets show the effectiveness of the proposed approach.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-168.pdf,2018,100.0,"Boolean kernels for interpretable kernel machines Most of the machine learning (ML) community's efforts in the last decades have been devoted to improving the power and the prediction quality of ML models at the expense of their interpretability. However, nowadays, ML is becoming more and more ubiquitous and it is increasingly demanded the need for models that can be interpreted. To this end, in this work we propose a method for extracting explanation rules from a kernel machine. The core idea is based on using kernels with feature spaces composed by logical propositions. On top of that, a searching algorithm tries to retrieve the most relevant features/rules that can be used to explain the trained model. Experiments on several benchmarks and artificial datasets show the effectiveness of the proposed approach."
Continuous convolutional object tracking,"Peer Springstübe, Stefan Heinrich, Stefan Wermter",1 - Universität Hamburg -Dept. Informatics -Knowledge Technology Group Vogt-Koelln-Str 30 -22527 Hamburg Germany,"Tracking arbitrary objects is a challenging task in visual computing. A central problem is the need to adapt to the changing appearance of an object, particularly under strong transformation and occlusion. We propose a tracking framework that utilises the strengths of Convolutional Neural Networks (CNNs) to create a robust and adaptive model of the object from training data produced during tracking. An incremental update mechanism provides increased performance and reduces training during tracking, allowing its real-time use. * The authors gratefully acknowledge partial support from the German Research Foundation DFG under project CML (TRR 169).",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-169.pdf,2018,100.0,"Continuous convolutional object tracking Tracking arbitrary objects is a challenging task in visual computing. A central problem is the need to adapt to the changing appearance of an object, particularly under strong transformation and occlusion. We propose a tracking framework that utilises the strengths of Convolutional Neural Networks (CNNs) to create a robust and adaptive model of the object from training data produced during tracking. An incremental update mechanism provides increased performance and reduces training during tracking, allowing its real-time use. * The authors gratefully acknowledge partial support from the German Research Foundation DFG under project CML (TRR 169)."
Estimation of Human Concentration using Echo State Networks,"Hikmat Dashdamirov, Sebastián Basterrech","1 - Department of Computer Science Faculty of Electrical Engineering and Computer Science VŠB-Technical University of Ostrava Ostrava Czech Republic
2 - Department of Computer Science Faculty of Electrical Engineering Czech Technical University Prague Czech Republic","We introduce a very simple and portable device for estimating the human concentration. We developed a Brain-Computer Interface system based on EEG signals which is able to produce highly accurate prediction of the human activities. There are two types of mental activities, one requires high concentration and another one requires relaxation. We show that it is possible to estimate the human concentration with few brain signals. The classification problem is solved using Neural Networks. In particular, we obtain a very accurate classifier using the fast and robust Echo State Network method.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-172.pdf,2018,96.72131147540983,"Estimation of Human Concentration using Echo State Networks We introduce a very simple and portable device for estimating the human concentration. We developed a Brain-Computer Interface system based on EEG signals which is able to produce highly accurate prediction of the human activities. There are two types of mental activities, one requires high concentration and another one requires relaxation. We show that it is possible to estimate the human concentration with few brain signals. The classification problem is solved using Neural Networks. In particular, we obtain a very accurate classifier using the fast and robust Echo State Network method."
Generative Kernel PCA,"Joachim Schreurs, Johan Suykens",1 - Department of Electrical Engineering KU Leuven ESAT-STADIUS Kasteelpark Arenberg 10 B-3001 Leuven Belgium,"Kernel PCA has shown to be a powerful feature extractor within many applications. Using the Restricted Kernel Machine formulation, a representation using visible and hidden units is obtained. This enables the exploration of new insights and connections between Restricted Boltzmann machines and kernel methods. This paper explores these connections, introducing a generative kernel PCA which can be used to generate new data, as well as denoise a given training dataset. This in a non-probabilistic setting. Moreover, relations with linear PCA and a preimage reconstruction method are introduced in this paper.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-173.pdf,2018,100.0,"Generative Kernel PCA Kernel PCA has shown to be a powerful feature extractor within many applications. Using the Restricted Kernel Machine formulation, a representation using visible and hidden units is obtained. This enables the exploration of new insights and connections between Restricted Boltzmann machines and kernel methods. This paper explores these connections, introducing a generative kernel PCA which can be used to generate new data, as well as denoise a given training dataset. This in a non-probabilistic setting. Moreover, relations with linear PCA and a preimage reconstruction method are introduced in this paper."
A Sharper Bound on the Rademacher Complexity of Margin Multi-category Classifiers,"Khadija Musayeva, Fabien Lauer, Yann Guermeur",1 - LORIA University of Lorraine CNRS Nancy France,"One of the main open problems in the theory of margin multicategory pattern classification is the dependency of a guaranteed risk on the number C of categories, the sample size m and the margin parameter γ. This paper derives a new bound on the probability of error of margin multicategory classifiers under minimal learnability assumptions. It improves the dependency on C over the state of the art. This is achieved through the introduction of a new Sauer-Shelah lemma.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-174.pdf,2018,72.8395061728395,"A Sharper Bound on the Rademacher Complexity of Margin Multi-category Classifiers One of the main open problems in the theory of margin multicategory pattern classification is the dependency of a guaranteed risk on the number C of categories, the sample size m and the margin parameter γ. This paper derives a new bound on the probability of error of margin multicategory classifiers under minimal learnability assumptions. It improves the dependency on C over the state of the art. This is achieved through the introduction of a new Sauer-Shelah lemma."
"Enhancement of a stochastic Markov blanket framework with ant colony optimization, to uncover epistasis in genetic association studies","Christine Sinoquet, Clément Niel","1 - UMR CNRS 6004 Université de Nantes 1 -LS2N, 2 rue de la Houssinière, BP 92208 44322 Nantes Cedex France
2 - Centre de Calcul Intensif des Pays de la Loire Nantes France","In association genetics, many studies rely on univariate statistical tests to reveal genotype-phenotype relationships, and are thus prone to miss the situations of epistasis (interaction between genes). We designed SMMB (Multiple Stochastic Markov blankets), and SMMB-ACO, a variant combined with ant colony optimization, to detect epistasis. We compare our proposals with three other methods. SMMB-ACO outperforms the other methods for 50% of simulated datasets. On real datasets, the detection ability of SMMB-ACO is close to that of the best approach, which is a slow method, and SMMB-ACO is the fastest algorithm behind a much less performing method. * C. Niel was supported by the Research project GRIOTE (Pays de la Loire region, France) and the EGID LabEx (Lille, France). The software development and the realization of experiments were performed in part at the CCIPL (",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-175.pdf,2018,94.02985074626866,"Enhancement of a stochastic Markov blanket framework with ant colony optimization, to uncover epistasis in genetic association studies In association genetics, many studies rely on univariate statistical tests to reveal genotype-phenotype relationships, and are thus prone to miss the situations of epistasis (interaction between genes). We designed SMMB (Multiple Stochastic Markov blankets), and SMMB-ACO, a variant combined with ant colony optimization, to detect epistasis. We compare our proposals with three other methods. SMMB-ACO outperforms the other methods for 50% of simulated datasets. On real datasets, the detection ability of SMMB-ACO is close to that of the best approach, which is a slow method, and SMMB-ACO is the fastest algorithm behind a much less performing method. * C. Niel was supported by the Research project GRIOTE (Pays de la Loire region, France) and the EGID LabEx (Lille, France). The software development and the realization of experiments were performed in part at the CCIPL ("
Quantifying the Reservoir Quality using Dimensionality Reduction Techniques,"Tomas Burianek, Sebastián Basterrech","1 - Department of Computer Science Faculty of Electrical Engineering and Computer Science V ŠB-Technical University of Ostrava Ostrava-Poruba Czech Republic
2 - Department of Computer Science Faculty of Electrical Engineering Czech Technical University Prague Czech Republic","Echo State Network is a particular type of Recurrent Neural Networks that combines principles from kernels, linear regression and dynamical systems. The neural network has a random initialized hiddenhidden weights (reservoir) that keeps fixed during the training. The reservoir projects the input patterns onto a feature map. Here, we present a correlation analysis between the input space and the feature map. We use a dimensionality reduction technique (Sammon Mapping) for representing the input space. We show a correlation between the Sammon energy and the model accuracy, which can be useful for defining good reservoir topologies.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-176.pdf,2018,100.0,"Quantifying the Reservoir Quality using Dimensionality Reduction Techniques Echo State Network is a particular type of Recurrent Neural Networks that combines principles from kernels, linear regression and dynamical systems. The neural network has a random initialized hiddenhidden weights (reservoir) that keeps fixed during the training. The reservoir projects the input patterns onto a feature map. Here, we present a correlation analysis between the input space and the feature map. We use a dimensionality reduction technique (Sammon Mapping) for representing the input space. We show a correlation between the Sammon energy and the model accuracy, which can be useful for defining good reservoir topologies."
A variable projection method for block term decomposition of higher-order tensors,"Guillaume Olikier, P.-A Absil, Lieven De Lathauwer","1 - Université catholique de Louvain -ICTEAM Institute B-1348 Louvain-la-Neuve Belgium
3 - Electrical Engineering Department (ESAT) KU Leuven B-3000 Leuven Belgium","Higher-order tensors have become popular in many areas of applied mathematics such as statistics, scientific computing, signal processing or machine learning, notably thanks to the many possible ways of decomposing a tensor. In this paper, we focus on the best approximation in the least-squares sense of a higher-order tensor by a block term decomposition. Using variable projection, we express the tensor approximation problem as a minimization of a cost function on a Cartesian product of Stiefel manifolds. We present numerical experiments where variable projection makes a steepest-descent method approximately twice faster.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-177.pdf,2018,100.0,"A variable projection method for block term decomposition of higher-order tensors Higher-order tensors have become popular in many areas of applied mathematics such as statistics, scientific computing, signal processing or machine learning, notably thanks to the many possible ways of decomposing a tensor. In this paper, we focus on the best approximation in the least-squares sense of a higher-order tensor by a block term decomposition. Using variable projection, we express the tensor approximation problem as a minimization of a cost function on a Cartesian product of Stiefel manifolds. We present numerical experiments where variable projection makes a steepest-descent method approximately twice faster."
Feature selection for label ranking,"Noelia Sánchez-Maroño, Beatriz Pérez-Sánchez",1 - Coruña Research Center on Information and Communication Technologies (CITIC) University of A Campus de Elviña 15071 Spain,"Over the last years, feature selection and label ranking have attracted considerable attention in Artificial Intelligence research. Feature selection has been applied to many machine learning problems with excellent results. However, studies about its combination with label ranking are undeveloped. This paper presents a novelty work that uses feature selection filters as a preprocessing step for label ranking. Experimental results show a significant reduction, up to 33%, in the number of features used for the label ranking problems whereas the performance results are competitive in terms of similarity measure.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-179.pdf,2018,100.0,"Feature selection for label ranking Over the last years, feature selection and label ranking have attracted considerable attention in Artificial Intelligence research. Feature selection has been applied to many machine learning problems with excellent results. However, studies about its combination with label ranking are undeveloped. This paper presents a novelty work that uses feature selection filters as a preprocessing step for label ranking. Experimental results show a significant reduction, up to 33%, in the number of features used for the label ranking problems whereas the performance results are competitive in terms of similarity measure."
Cheetah Based Optimization Algorithm: A Novel Swarm Intelligence Paradigm,"Carlos Klein, Viviana Mariani, Leandro Dos, Santos Coelho","1 - Federal University of Parana UFPR -Dept. of Electrical Engineering PGEE Rua Carlos Pradi Jardim das Américas. Postal Code 82590-300 Curitiba PR Brazil
2 - Pontifical Catholic University of Parana -PUCPR -Polytechnic School Imaculada Conceição 1155 Prado Velho","All the new gadgets, systems and advances in technology are bringing the actual engineers problems with increasing complexity. To solve those problems, the optimization algorithms are popping up to support and even improve the actual scenario. Several stochastic optimization paradigms called metaheuristics are being proposed each year and the inspiration comes from animals, plants, experiments, chemical processes or simply math. In this paper, a cheetah based optimization algorithm (CBA) is proposed, capturing the social behavior from those animals. The proposed CBA is validated against seven known optimizers using three different benchmark problems. Finally, some considerations about research issues and directions in the CBA design are given.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-18.pdf,2018,100.0,"Cheetah Based Optimization Algorithm: A Novel Swarm Intelligence Paradigm All the new gadgets, systems and advances in technology are bringing the actual engineers problems with increasing complexity. To solve those problems, the optimization algorithms are popping up to support and even improve the actual scenario. Several stochastic optimization paradigms called metaheuristics are being proposed each year and the inspiration comes from animals, plants, experiments, chemical processes or simply math. In this paper, a cheetah based optimization algorithm (CBA) is proposed, capturing the social behavior from those animals. The proposed CBA is validated against seven known optimizers using three different benchmark problems. Finally, some considerations about research issues and directions in the CBA design are given."
Capturing Variabilities from Computed Tomography Images with Generative Adversarial Networks,"Umair Javaid, John Lee","1 - Université Catholique de Louvain -ICTEAM Place du Levant L5.03.02, 1348 Louvain-la-Neuve Belgium
2 - Université Catholique de Louvain -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium","With the advent of Deep Learning (DL) techniques, especially Generative Adversarial Networks (GANs), data augmentation and generation are quickly evolving domains that have raised much interest recently. However, the DL techniques are data demanding and since, medical data is not easily accessible, they suffer from data insufficiency. To deal with this limitation, different data augmentation techniques are used. Here, we propose a novel unsupervised data-driven approach for data augmentation that can generate 2D Computed Tomography (CT) images using a simple GAN. The generated CT images have good global and local features of a real CT image and can be used to augment the training datasets for effective learning. In this proof-of-concept study, we show that our proposed solution using GANs is able to capture some of the global and local CT variabilities. Our network is able to generate visually realistic CT images and we aim to further enhance its output by scaling it to a higher resolution and potentially from 2D to 3D.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-180.pdf,2018,82.72251308900523,"Capturing Variabilities from Computed Tomography Images with Generative Adversarial Networks With the advent of Deep Learning (DL) techniques, especially Generative Adversarial Networks (GANs), data augmentation and generation are quickly evolving domains that have raised much interest recently. However, the DL techniques are data demanding and since, medical data is not easily accessible, they suffer from data insufficiency. To deal with this limitation, different data augmentation techniques are used. Here, we propose a novel unsupervised data-driven approach for data augmentation that can generate 2D Computed Tomography (CT) images using a simple GAN. The generated CT images have good global and local features of a real CT image and can be used to augment the training datasets for effective learning. In this proof-of-concept study, we show that our proposed solution using GANs is able to capture some of the global and local CT variabilities. Our network is able to generate visually realistic CT images and we aim to further enhance its output by scaling it to a higher resolution and potentially from 2D to 3D."
The Minimum Effort Maximum Output Principle applied to Multiple Kernel Learning,"Ivano Lauriola, Mirko Polato, Fabio Aiolli",1 - Department of Mathematics University of Padova Via Trieste 63 Padova Italy,"The Multiple Kernel Learning (MKL) paradigm aims at learning the representation from data reducing the effort devoted to the choice of the kernel's hyperparameters. Typically, the resulting kernel is obtained as the maximal margin combination of a set of base kernels. When too expressive base kernels are provided to the MKL algorithm, the solution found by these algorithms can overfit data. In this paper, we propose a novel MKL algorithm which takes into consideration the expressiveness of the obtained representation in its objective function in such a way that a trade-off between large margins and simple hypothesis spaces can be found. Moreover, an empirical comparison against hard baselines and state-of-the-art MKL methods on several real-world datasets is presented showing the merits of the proposed algorithm especially with respect to the robustness to overfitting.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-181.pdf,2018,60.75949367088608,"The Minimum Effort Maximum Output Principle applied to Multiple Kernel Learning The Multiple Kernel Learning (MKL) paradigm aims at learning the representation from data reducing the effort devoted to the choice of the kernel's hyperparameters. Typically, the resulting kernel is obtained as the maximal margin combination of a set of base kernels. When too expressive base kernels are provided to the MKL algorithm, the solution found by these algorithms can overfit data. In this paper, we propose a novel MKL algorithm which takes into consideration the expressiveness of the obtained representation in its objective function in such a way that a trade-off between large margins and simple hypothesis spaces can be found. Moreover, an empirical comparison against hard baselines and state-of-the-art MKL methods on several real-world datasets is presented showing the merits of the proposed algorithm especially with respect to the robustness to overfitting."
Learning with a Fisher surrogate loss in a small data regime,Mousaab Djerrab,"1 - Alexandre Garcia and Florence d'Alché-Buc LTCI Télécom ParisTech
2 - Université Paris-Saclay 75013 Paris France","We introduce a novel framework, Output Fisher Embedding Regression (OFER), that uses a Fisher vector representation of output data and provides prediction by solving an appropriate pre-image problem. OFER takes advantage of the implicit structure of the marginal probability distribution of the output to improve performance in prediction. Although the proposed approach is general and versatile, we put a stress on the Gaussian mixture model for modelling the output data and design a closedform solution for the corresponding pre-image problem. Numerical results on a drug activity prediction task and a semantic multi-class classification show the relevance of the approach in small data regime.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-182.pdf,2018,100.0,"Learning with a Fisher surrogate loss in a small data regime We introduce a novel framework, Output Fisher Embedding Regression (OFER), that uses a Fisher vector representation of output data and provides prediction by solving an appropriate pre-image problem. OFER takes advantage of the implicit structure of the marginal probability distribution of the output to improve performance in prediction. Although the proposed approach is general and versatile, we put a stress on the Gaussian mixture model for modelling the output data and design a closedform solution for the corresponding pre-image problem. Numerical results on a drug activity prediction task and a semantic multi-class classification show the relevance of the approach in small data regime."
Adaptive random forests for data stream regression,"Heitor Gomes, Jean Barddal, Luis Boiko, Albert Bifet","1 - Department of Computer Science and Networks (INFRES) Télécom ParisTech Université Paris-Saclay Paris France
3 - Programa de Pós-Graduação em Informática (PPGIa) Pontifícia Universidade Católica do Paraná Curitiba Brazil","Data stream mining is a hot topic in the machine learning community that tackles the problem of learning and updating predictive models as new data becomes available over time. Even though several new methods are proposed every year, most focus on the classification task and overlook the regression task. In this paper, we propose an adaptation to the Adaptive Random Forest so that it can handle regression tasks, namely ARF-Reg. ARF-Reg is empirically evaluated and compared to the state-of-the-art data stream regression algorithms, thus highlighting its applicability in different data stream scenarios.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-183.pdf,2018,100.0,"Adaptive random forests for data stream regression Data stream mining is a hot topic in the machine learning community that tackles the problem of learning and updating predictive models as new data becomes available over time. Even though several new methods are proposed every year, most focus on the classification task and overlook the regression task. In this paper, we propose an adaptation to the Adaptive Random Forest so that it can handle regression tasks, namely ARF-Reg. ARF-Reg is empirically evaluated and compared to the state-of-the-art data stream regression algorithms, thus highlighting its applicability in different data stream scenarios."
Perplexity-free t-SNE and twice Student tt-SNE,"Cyril De Bodt, Dounia Mulders, Michel Verleysen, John Lee","1 - ICTEAM/ELEN Place du Levant Université catholique de Louvain
4 - Université catholique de Louvain -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium
5 - L5.03.02, 1348 Louvain-la-Neuve Belgium","In dimensionality reduction and data visualisation, t-SNE has become a popular method. In this paper, we propose two variants to the Gaussian similarities used to characterise the neighbourhoods around each high-dimensional datum in t-SNE. A first alternative is to use t distributions like already used in the low-dimensional embedding space; a variable degree of freedom accounts for the intrinsic dimensionality of data. The second variant relies on compounds of Gaussian neighbourhoods with growing widths, thereby suppressing the need for the user to adjust a single size or perplexity. In both cases, heavy-tailed distributions thus characterise the neighbourhood relationships in the data space. Experiments show that both variants are competitive with t-SNE, at no extra cost.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-185.pdf,2018,100.0,"Perplexity-free t-SNE and twice Student tt-SNE In dimensionality reduction and data visualisation, t-SNE has become a popular method. In this paper, we propose two variants to the Gaussian similarities used to characterise the neighbourhoods around each high-dimensional datum in t-SNE. A first alternative is to use t distributions like already used in the low-dimensional embedding space; a variable degree of freedom accounts for the intrinsic dimensionality of data. The second variant relies on compounds of Gaussian neighbourhoods with growing widths, thereby suppressing the need for the user to adjust a single size or perplexity. In both cases, heavy-tailed distributions thus characterise the neighbourhood relationships in the data space. Experiments show that both variants are competitive with t-SNE, at no extra cost."
Transferring Style in Motion Capture Sequences with Adversarial Learning,"Qi Wang, Mickael Chen, Thierry Artières, Ludovic Denoyer","1 - UMR 7279 Ecole Centrale de Marseille 2-LIF AixMarseille Université -CNRS 3-Laboratoire d'Informatique de Paris 6
2 - Université Pierre et Marie Curie","We focus on style transfer for sequential data in a supervised setting. Assuming sequential data include both content and style information we want to learn models able to transform a sequence into another one with the same content information but with the style of another one, from a training dataset where content and style labels are available. Following works on image generation and edition with adversarial learning we explore the design of neural network architectures for the task of sequence edition that we apply to motion capture sequences. * Qi Wang's Ph.D. thesis is funded by China Scholarship Council. † Part of this work has been funded by the French ANR project Deep In France.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-188.pdf,2018,86.11111111111111,"Transferring Style in Motion Capture Sequences with Adversarial Learning We focus on style transfer for sequential data in a supervised setting. Assuming sequential data include both content and style information we want to learn models able to transform a sequence into another one with the same content information but with the style of another one, from a training dataset where content and style labels are available. Following works on image generation and edition with adversarial learning we explore the design of neural network architectures for the task of sequence edition that we apply to motion capture sequences. * Qi Wang's Ph.D. thesis is funded by China Scholarship Council. † Part of this work has been funded by the French ANR project Deep In France."
Person Identification and Discovery With Wrist Worn Accelerometer Data,"Ryan Mcconville, Raúl Santos-Rodríguez, Niall Twomey",1 - University of Bristol UK,"Internet of Things (IoT) devices with embedded accelerometers continue to grow in popularity. These are often attached to individuals, whether they are a mobile phone in a pocket or a smartwatch on a wrist, and are constantly capturing data of a personal nature. In this work we propose a method for person identification using accelerometer data via supervised machine learning techniques. Further, we introduce the first unsupervised method for discovering individuals using the same accelerometer. We report the performance both in terms of classification and clustering using a publicly available dataset covering a large number of activities of daily living. While this has numerous benefits in tasks such as activity recognition and biometrics, this work also motivates the debate and discussion around privacy concerns of the analysis of accelerometer data.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-190.pdf,2018,100.0,"Person Identification and Discovery With Wrist Worn Accelerometer Data Internet of Things (IoT) devices with embedded accelerometers continue to grow in popularity. These are often attached to individuals, whether they are a mobile phone in a pocket or a smartwatch on a wrist, and are constantly capturing data of a personal nature. In this work we propose a method for person identification using accelerometer data via supervised machine learning techniques. Further, we introduce the first unsupervised method for discovering individuals using the same accelerometer. We report the performance both in terms of classification and clustering using a publicly available dataset covering a large number of activities of daily living. While this has numerous benefits in tasks such as activity recognition and biometrics, this work also motivates the debate and discussion around privacy concerns of the analysis of accelerometer data."
Vector Field Based Neural Networks,"Daniel Vieira, Fabio Rangel, Fabrício Firmino, Joao Paixao",1 - Universidade Federal do Rio de Janeiro (UFRJ) Graduation Program in Informatics (PPGI) Av. Athos da Silveira Ramos 149 Rio de Janeiro RJ Brazil,A novel Neural Network architecture is proposed using the mathematically and physically rich idea of vector fields as hidden layers to perform nonlinear transformations in the data. The data points are interpreted as particles moving along a flow defined by the vector field which intuitively represents the desired movement to enable classification. The architecture moves the data points from their original configuration to a new one following the streamlines of the vector field with the objective of achieving a final configuration where classes are separable. An optimization problem is solved through gradient descent to learn this vector field.,Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-192.pdf,2018,100.0,Vector Field Based Neural Networks A novel Neural Network architecture is proposed using the mathematically and physically rich idea of vector fields as hidden layers to perform nonlinear transformations in the data. The data points are interpreted as particles moving along a flow defined by the vector field which intuitively represents the desired movement to enable classification. The architecture moves the data points from their original configuration to a new one following the streamlines of the vector field with the objective of achieving a final configuration where classes are separable. An optimization problem is solved through gradient descent to learn this vector field.
Opposite neighborhood: a new method to select reference points of minimal learning machines,"Madson Dias, Lucas De Sousa, Ajalmar Da Rocha Neto, Amauri De Souza Júnior","1 - Department of Teleinformatics Federal Institute of Ceará 13 de Maio Avenue 2081 Fortaleza, Ceará Brazil","This paper introduces a new approach to select reference points in minimal learning machines (MLMs) for classification tasks. The MLM training procedure comprises the selection of a subset of the data, named reference points (RPs), that is used to build a linear regression model between distances taken in the input and output spaces. In this matter, we propose a strategy, named opposite neighborhood (ON), to tackle the problem of selecting RPs by locating RPs out of class-overlapping regions. Experiments were carried out using UCI data sets. As a result, the proposal is able to both produce sparser models and achieve competitive performance when compared to the regular MLM.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-198.pdf,2018,100.0,"Opposite neighborhood: a new method to select reference points of minimal learning machines This paper introduces a new approach to select reference points in minimal learning machines (MLMs) for classification tasks. The MLM training procedure comprises the selection of a subset of the data, named reference points (RPs), that is used to build a linear regression model between distances taken in the input and output spaces. In this matter, we propose a strategy, named opposite neighborhood (ON), to tackle the problem of selecting RPs by locating RPs out of class-overlapping regions. Experiments were carried out using UCI data sets. As a result, the proposal is able to both produce sparser models and achieve competitive performance when compared to the regular MLM."
Pollen Grain Recognition Using Convolutional Neural Network,"Natalia Khanzhina, Evgeny Putin, Andrey Filchenkov, Elena Zamyatina","1 - Lab 49 Kronverksky Pr ITMO University -Computer Technology 197101 St. Petersburg Russia
4 - School of Economics"" Faculty of Economics, Management, and Business Informatics National Research University ""Higher 38 Studencheskaya st 614070 Perm -Russia
5 - Department of Mechanics and Mathematics 15 Bukireva st -Perm State National Research University 614990 Perm -Russia","This paper addresses two problems: the automated pollen species recognition and counting them on an image obtained with a lighting microscope. Automation of pollen recognition is required in several domains, including allergy and asthma prevention in medicine and honey quality control in the nutrition industry. We propose a deep learning solution based on a convolutional neural network for classification, feature extraction and image segmentation. Our approach achieves state-of-theart results in terms of accuracy. For 5 species, the approach provides 99.8% of accuracy, for 11 species -95.9%.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-199.pdf,2018,77.96610169491525,"Pollen Grain Recognition Using Convolutional Neural Network This paper addresses two problems: the automated pollen species recognition and counting them on an image obtained with a lighting microscope. Automation of pollen recognition is required in several domains, including allergy and asthma prevention in medicine and honey quality control in the nutrition industry. We propose a deep learning solution based on a convolutional neural network for classification, feature extraction and image segmentation. Our approach achieves state-of-theart results in terms of accuracy. For 5 species, the approach provides 99.8% of accuracy, for 11 species -95.9%."
Machine Learning and Data Analysis in Astroinformatics,"Michael Biehl, Kerstin Bunte, Guiseppe Longo, Peter Tino","1 - Intelligent Systems Group University of Groningen P.O. Box 407 9700 AK Groningen The Netherlands
3 - Dipartimento di Fisica ""E. Pancini"" Universitá degli Studi Federico II via Cintia 6 I-80135 Napoli Italia
4 - School of Computer Science University of Birmingham B15 2TT Birmingham UK","Astroinformatics is a new discipline at the cross-road of astronomy, advanced statistics and computer science. With next generation sky surveys, space missions and modern instrumentation astronomy will enter the Petascale regime raising the demand for advanced computer science techniques with hard-and software solutions for data management, analysis, efficient automation and knowledge discovery. This tutorial reviews important developments in astroinformatics over the past years and discusses some relevant research questions and concrete problems. The contribution ends with a short review of the special session papers in these proceedings, as well as perspectives and challenges for the near future.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-2.pdf,2018,66.66666666666667,"Machine Learning and Data Analysis in Astroinformatics Astroinformatics is a new discipline at the cross-road of astronomy, advanced statistics and computer science. With next generation sky surveys, space missions and modern instrumentation astronomy will enter the Petascale regime raising the demand for advanced computer science techniques with hard-and software solutions for data management, analysis, efficient automation and knowledge discovery. This tutorial reviews important developments in astroinformatics over the past years and discusses some relevant research questions and concrete problems. The contribution ends with a short review of the special session papers in these proceedings, as well as perspectives and challenges for the near future."
Pairwise Image Ranking with Deep Comparative Networks,"Aymen Cherif, Salim Jouili, Eura Nova",Unknown,"We focus our work on instance-level image retrieval. We approach this problem from the point of view of learning to rank. We explore the idea of using the pairwise ranking model instead of providing a similarity measure between a query and a candidate document. We also investigate the ability of this model to learn high level query-document joint features. Our preliminary results show that the end-to-end approach is not only able to learn a better preference function, but also to drive the model to learn better high level features.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-200.pdf,2018,72.72727272727273,"Pairwise Image Ranking with Deep Comparative Networks We focus our work on instance-level image retrieval. We approach this problem from the point of view of learning to rank. We explore the idea of using the pairwise ranking model instead of providing a similarity measure between a query and a candidate document. We also investigate the ability of this model to learn high level query-document joint features. Our preliminary results show that the end-to-end approach is not only able to learn a better preference function, but also to drive the model to learn better high level features."
Temporal Transfer Learning for Drift Adaptation,"Peter Jansen, Jaime Carbonell",1 - Carnegie Mellon University -Language Technologies Institute Pittsburgh PA USA,"Whereas detecting and adapting to concept drift has been well studied, predicting temporal drift of decision boundaries has received much less attention. This paper proposes a method for drift prediction, drift projection, and active-learning for adjusting the projected decision boundary so as to regain accuracy with minimal additional labeled samples. The method works with different underlying learning algorithms. Results on several data sets with translational and rotational drift and corresponding boundary projection show regained accuracy with significantly fewer labeled samples, even in the presence of noisy drift.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-48,2018,65.1685393258427,"Temporal Transfer Learning for Drift Adaptation Whereas detecting and adapting to concept drift has been well studied, predicting temporal drift of decision boundaries has received much less attention. This paper proposes a method for drift prediction, drift projection, and active-learning for adjusting the projected decision boundary so as to regain accuracy with minimal additional labeled samples. The method works with different underlying learning algorithms. Results on several data sets with translational and rotational drift and corresponding boundary projection show regained accuracy with significantly fewer labeled samples, even in the presence of noisy drift."
CDTW-based classification for Parkinson's Disease diagnosis,"Nicolas Khoury, Ferhat Attal, Yacine Amirat, Abdelghani Chibani, Samer Mohammed",1 - LISSI Laboratory Est Creteil University Paris,"This paper presents a new classification approach for Parkinson's Disease (PD) diagnosis using Continuous Dynamic Time Warping (CDTW) technique and gait cycles data. These data are the vertical Ground Reaction Forces (vGRFs) recordings collected from eight force sensors placed in each shoe sole worn by each subject. The proposed approach exploits the principle of the repetition of gait cycle patterns to discriminate healthy subjects from PD subjects. The repetition of gait cycles is evaluated using the similarity of the time-series corresponding to stance phases estimated by applying the CDTW technique. The CDTW distances, extracted from gait cycles, are used as inputs of a binary classifier discriminating healthy subjects from PD subjects. Different classification methods are evaluated, including four supervised methods: K-Nearest Neighbours (K-NN), Decision Tree (DT), Random Forest (RF), and Support Vector Machines (SVM), and two unsupervised ones: Gaussian Mixture Model (GMM), and K-means. The proposed approach compares favorably with a classification based on standard features.","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-203.pdf,2018,100.0,"CDTW-based classification for Parkinson's Disease diagnosis This paper presents a new classification approach for Parkinson's Disease (PD) diagnosis using Continuous Dynamic Time Warping (CDTW) technique and gait cycles data. These data are the vertical Ground Reaction Forces (vGRFs) recordings collected from eight force sensors placed in each shoe sole worn by each subject. The proposed approach exploits the principle of the repetition of gait cycle patterns to discriminate healthy subjects from PD subjects. The repetition of gait cycles is evaluated using the similarity of the time-series corresponding to stance phases estimated by applying the CDTW technique. The CDTW distances, extracted from gait cycles, are used as inputs of a binary classifier discriminating healthy subjects from PD subjects. Different classification methods are evaluated, including four supervised methods: K-Nearest Neighbours (K-NN), Decision Tree (DT), Random Forest (RF), and Support Vector Machines (SVM), and two unsupervised ones: Gaussian Mixture Model (GMM), and K-means. The proposed approach compares favorably with a classification based on standard features."
Clustering with Decision Trees: Divisive and Agglomerative Approach,"Lauriane Castin, Benoit Frénay",1 - Faculty of Computer Science NADI Institute -PReCISE Research Center Université de Namur 21 -5000 Namur Belgium,"Decision trees are mainly used to perform classification tasks. Samples are submitted to a test in each node of the tree and guided through the tree based on the result. Decision trees can also be used to perform clustering, with a few adjustments. On one hand, new split criteria must be discovered to construct the tree without the knowledge of samples labels. On the other hand, new algorithms must be applied to merge subclusters at leaf nodes into actual clusters. In this paper, new split criteria and agglomeration algorithms are developed for clustering, with results comparable to other existing clustering techniques.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-22.pdf,2018,85.07462686567165,"Clustering with Decision Trees: Divisive and Agglomerative Approach Decision trees are mainly used to perform classification tasks. Samples are submitted to a test in each node of the tree and guided through the tree based on the result. Decision trees can also be used to perform clustering, with a few adjustments. On one hand, new split criteria must be discovered to construct the tree without the knowledge of samples labels. On the other hand, new algorithms must be applied to merge subclusters at leaf nodes into actual clusters. In this paper, new split criteria and agglomeration algorithms are developed for clustering, with results comparable to other existing clustering techniques."
Interaction and User Integration in Machine Learning for Information Visualisation,"Bruno Dumas, Benoît Frénay, John Lee","1 - Faculty of Computer Science NADI Institute -PReCISE Research Center Université de Namur 21 -5000 Namur Belgium
3 - Université catholique de Louvain -SST/ICTEAM SSS/IREC Place du Levant 3 1348 Louvain-la-Neuve Belgium","Many methods have been developed in machine learning (ML) for information visualisation (infovis). For example, PCA, MDS, t-SNE and improvements are standard tools to reduce the dimensionality of high dimensional datasets for visualisation purposes. However, multiple other means are regularly used in the field of infovis when tackling datasets with high dimensionality. Letting the user manipulate the visualisation is one of these means, either through selection, navigation or filtering. Introducing manipulation of the visualisation also integrates the user as a core aspect of a given system. In the context of machine learning, beyond the informational and exploratory use of infovis, users' feedback can for example be highly informational to drive the dimensionality reduction process. This special session of the ESANN conference is a followup of the special session on ""Information Visualisation and Machine Learning: Techniques, Validation and Integration"" at ESANN 2016. It aims to gather researchers that integrate users in the core of ML methods for infovis. New algorithms and frameworks are welcome, as well as experimental use cases that bring new insight in the integration of interaction and user integration in ML for infovis. This special session aims to provide practitioners from both communities a common forum of discussion where issues at the crossroads of machine learning and information visualisation could be discussed.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-5,2018,66.66666666666667,"Interaction and User Integration in Machine Learning for Information Visualisation Many methods have been developed in machine learning (ML) for information visualisation (infovis). For example, PCA, MDS, t-SNE and improvements are standard tools to reduce the dimensionality of high dimensional datasets for visualisation purposes. However, multiple other means are regularly used in the field of infovis when tackling datasets with high dimensionality. Letting the user manipulate the visualisation is one of these means, either through selection, navigation or filtering. Introducing manipulation of the visualisation also integrates the user as a core aspect of a given system. In the context of machine learning, beyond the informational and exploratory use of infovis, users' feedback can for example be highly informational to drive the dimensionality reduction process. This special session of the ESANN conference is a followup of the special session on ""Information Visualisation and Machine Learning: Techniques, Validation and Integration"" at ESANN 2016. It aims to gather researchers that integrate users in the core of ML methods for infovis. New algorithms and frameworks are welcome, as well as experimental use cases that bring new insight in the integration of interaction and user integration in ML for infovis. This special session aims to provide practitioners from both communities a common forum of discussion where issues at the crossroads of machine learning and information visualisation could be discussed."
Dynamic autonomous image segmentation based on Grow Cut,"Alexandru Ion Marinescu, Zoltán Bálint, Laura Dioşan, Anca Andreica, Cristina Szabo, Silviu Ianc","1 - IMOGEN Research Institute County Clinical Emergency Hospital 400006 Cluj-Napoca România
2 - Faculty of Mathematics and Computer Sciences Babeş-Bolyai University 400084 Cluj-Napoca România
4 - Faculty of Physics Babeş-Bolyai University 400084 Cluj-Napoca România","The main incentive of this paper is to provide an enhanced approach for 2D medical image segmentation based on the Unsupervised Grow Cut algorithm, a method that requires no prior training. This paper assumes that the reader is, to some extent, familiar with cellular automata and their function as they make up the core of this technique. The benchmarks were performed on 2D MRI images of the heart and chest cavity. We obtained a significant increase in the output quality as compared to classical Unsupervised Grow Cut by using standard measures, based on the existence of accurate ground truth. This increase was obtained by dynamically altering the local threshold parameter. In conclusion, our approach provides the opportunity to become a building block of a computer aided diagnostic system.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-32.pdf,2018,100.0,"Dynamic autonomous image segmentation based on Grow Cut The main incentive of this paper is to provide an enhanced approach for 2D medical image segmentation based on the Unsupervised Grow Cut algorithm, a method that requires no prior training. This paper assumes that the reader is, to some extent, familiar with cellular automata and their function as they make up the core of this technique. The benchmarks were performed on 2D MRI images of the heart and chest cavity. We obtained a significant increase in the output quality as compared to classical Unsupervised Grow Cut by using standard measures, based on the existence of accurate ground truth. This increase was obtained by dynamically altering the local threshold parameter. In conclusion, our approach provides the opportunity to become a building block of a computer aided diagnostic system."
Cache-efficient Gradient Descent Algorithm,"Imen Chakroun, Tom Aa, Thomas Ashby",1 - Exascience Life Lab IMEC Leuven Belgium,"Best practice when using Stochastic Gradient Descent (SGD) suggests randomising the order of training points and streaming the whole set through the learner. This results in extremely low temporal locality of access to the training set and, thus, makes minimal use of the small, fast layers of memory in an High Performance Computing (HPC) memory hierarchy. While mini-batch SGD is often used to control the noise on the gradient and make convergence smoother and more easy to identify than SGD, it suffers from the same extremely low temporal locality. In this paper we introduce Sliding Window SGD (SW-SGD) which uses temporal locality of training point access in an attempt to combine the advantages of SGD with mini batch-SGD by leveraging HPC memory hierarchies. We give initial results on a classification and a regression problems using the MNIST and CHEMBL datasets showing that memory hierarchies can be used to improve the performances of gradient algorithms.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-33.pdf,2018,100.0,"Cache-efficient Gradient Descent Algorithm Best practice when using Stochastic Gradient Descent (SGD) suggests randomising the order of training points and streaming the whole set through the learner. This results in extremely low temporal locality of access to the training set and, thus, makes minimal use of the small, fast layers of memory in an High Performance Computing (HPC) memory hierarchy. While mini-batch SGD is often used to control the noise on the gradient and make convergence smoother and more easy to identify than SGD, it suffers from the same extremely low temporal locality. In this paper we introduce Sliding Window SGD (SW-SGD) which uses temporal locality of training point access in an attempt to combine the advantages of SGD with mini batch-SGD by leveraging HPC memory hierarchies. We give initial results on a classification and a regression problems using the MNIST and CHEMBL datasets showing that memory hierarchies can be used to improve the performances of gradient algorithms."
Meerkats-inspired Algorithm for Global Optimization Problems,"Carlos Klein, Leandro Dos, Santos Coelho","1 - Federal University of Parana UFPR -Dept. of Electrical Engineering Rua Carlos Pradi Jardim das Américas. Postal Code 82590-300 Curitiba PR Brazil
2 - Pontifical Catholic University of Parana -PUCPR -Polytechnic School Imaculada Conceição Prado Velho -Postal Code 1155, 80215-901 Curitiba
3 - PR -Brazil Industrial and Systems Engineering Graduate Program -PPGEPS","Bio-inspired computing has been a relevant topic in scientific, computing and engineering fields in recent years. Most bio-inspired metaheuristics model a specific phenomenon or mechanism based on which they tackle optimization problems. This paper introduced the meerkats-inspired algorithm (MEA) a novel population-based swarm intelligence algorithm for global optimization in the continuous domain. The performance of MEA is showcased on six classical constrained engineering problems from literature. Numerical results and comparisons with other state of the art stochastic algorithms are also provided. Results analysis reveal that the MEA produced consistent results when compared with other optimizers.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-35.pdf,2018,100.0,"Meerkats-inspired Algorithm for Global Optimization Problems Bio-inspired computing has been a relevant topic in scientific, computing and engineering fields in recent years. Most bio-inspired metaheuristics model a specific phenomenon or mechanism based on which they tackle optimization problems. This paper introduced the meerkats-inspired algorithm (MEA) a novel population-based swarm intelligence algorithm for global optimization in the continuous domain. The performance of MEA is showcased on six classical constrained engineering problems from literature. Numerical results and comparisons with other state of the art stochastic algorithms are also provided. Results analysis reveal that the MEA produced consistent results when compared with other optimizers."
Emerging Trends in Machine Learning: Beyond Conventional Methods and Data,"Luca Oneto, Nicolò Navarin, Michele Donini, Davide Anguita","1 - DIBRIS -University of Genova Via Opera Pia 13 I-16145 Genova Italy
2 - Department of Mathematics University of Padua Via Trieste 63 I-35121 Padova -Italy
3 - IIT -Istituto Italiano di Tecnologia Via Morego 30 I-16163 Genova Italy","Recently, new promising theoretical results, techniques, and methodologies have attracted the attention of many researchers and have allowed to broaden the range of applications in which machine learning can be effectively applied in order to extract useful and actionable information from the huge amount of heterogeneous data produced everyday by an increasingly digital world. Examples of these methods and problems are: learning under privacy and anonymity constraints, learning from structured, semi-structured, multi-modal (heterogeneous) data, constructive machine learning, reliable machine learning, learning to learn, mixing deep and structured learning, semantics-enabled recommender systems, reproducibility and interpretability in machine learning, human-in-the-loop, adversarial learning. The focus of this special session is to attract both solid contributions or preliminary results which show the potentiality and the limitations of new ideas, refinements, or contaminations between the different fields of machine learning and other fields of research in solving real world problems. Both theoretical and practical results are welcome to our special session.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-4.pdf,2018,72.6027397260274,"Emerging Trends in Machine Learning: Beyond Conventional Methods and Data Recently, new promising theoretical results, techniques, and methodologies have attracted the attention of many researchers and have allowed to broaden the range of applications in which machine learning can be effectively applied in order to extract useful and actionable information from the huge amount of heterogeneous data produced everyday by an increasingly digital world. Examples of these methods and problems are: learning under privacy and anonymity constraints, learning from structured, semi-structured, multi-modal (heterogeneous) data, constructive machine learning, reliable machine learning, learning to learn, mixing deep and structured learning, semantics-enabled recommender systems, reproducibility and interpretability in machine learning, human-in-the-loop, adversarial learning. The focus of this special session is to attract both solid contributions or preliminary results which show the potentiality and the limitations of new ideas, refinements, or contaminations between the different fields of machine learning and other fields of research in solving real world problems. Both theoretical and practical results are welcome to our special session."
Understanding wafer patterns in semiconductor production with variational auto-encoders,"Tiago Santos, Roman Kern",1 - KNOW-CENTER GmbH -Graz Austria,"Semiconductor manufacturing processes critically depend on hundreds of highly complex process steps, which may cause critical deviations in the end-product. Hence, a better understanding of wafer test data patterns, which represent stress tests conducted on devices in semiconductor material slices, may lead to an improved production process. However, the shapes and types of these wafer patterns, as well as their relation to single process steps, are unknown. In a first step to address these issues, we tailor and apply a variational auto-encoder (VAE) to wafer pattern images. We find the VAE's generator allows for explorative wafer pattern analysis, and its encoder provides an effective dimensionality reduction algorithm, which, in a clustering application, performs better than several baselines such as t-SNE and yields interpretable clusters of wafer patterns.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-41.pdf,2018,100.0,"Understanding wafer patterns in semiconductor production with variational auto-encoders Semiconductor manufacturing processes critically depend on hundreds of highly complex process steps, which may cause critical deviations in the end-product. Hence, a better understanding of wafer test data patterns, which represent stress tests conducted on devices in semiconductor material slices, may lead to an improved production process. However, the shapes and types of these wafer patterns, as well as their relation to single process steps, are unknown. In a first step to address these issues, we tailor and apply a variational auto-encoder (VAE) to wafer pattern images. We find the VAE's generator allows for explorative wafer pattern analysis, and its encoder provides an effective dimensionality reduction algorithm, which, in a clustering application, performs better than several baselines such as t-SNE and yields interpretable clusters of wafer patterns."
Asymptotic statistics for multilayer perceptron with ReLu hidden units,Joseph Rynkiewicz,1 - Université Paris I -SAMM 90 rue de tolbiac Paris France,"We consider regression models involving multilayer perceptrons (MLP) with rectified linear unit (ReLu) functions for hidden units. It is a difficult task to study statistical properties of such models for several reasons: A first difficulty is that these activation functions are not differentiable everywhere, a second reason is also that in practice these models may be heavily overparametrized. In general, the estimation of the parameters of the MLP is done by minimizing a cost function, we focus here on the sum of square errors (SSE) which is the standard cost function for regression purpose. In this framework, we can characterize the asymptotic behavior of the SSE of estimated models which give information on the possible overfitting of such models. This task is done using recent methodology introduced to deal with models with a loss of identifiability which is very flexible. So, we don't have to assume that a true model exits or that a finite set of parameters realize the best regression function.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-45.pdf,2018,100.0,"Asymptotic statistics for multilayer perceptron with ReLu hidden units We consider regression models involving multilayer perceptrons (MLP) with rectified linear unit (ReLu) functions for hidden units. It is a difficult task to study statistical properties of such models for several reasons: A first difficulty is that these activation functions are not differentiable everywhere, a second reason is also that in practice these models may be heavily overparametrized. In general, the estimation of the parameters of the MLP is done by minimizing a cost function, we focus here on the sum of square errors (SSE) which is the standard cost function for regression purpose. In this framework, we can characterize the asymptotic behavior of the SSE of estimated models which give information on the possible overfitting of such models. This task is done using recent methodology introduced to deal with models with a loss of identifiability which is very flexible. So, we don't have to assume that a true model exits or that a finite set of parameters realize the best regression function."
Interactive dimensionality reduction of large datasets using interpolation,"Ignacio Díaz, Daniel Pérez, Abel Cuadrado, Diego García, Manuel Domínguez","1 - Electrical Engineering Dept University of Oviedo Edif. Dept Campus de Viesques s/n 33204 Gijón SPAIN
5 - SUPPRESS Research Group University of Leon
6 - Escuela de Ingenierías Campus de Vegazana 24007 León Spain","In this work we present an approach to achieve interactive dimensionality reduction (iDR) on large datasets. The main idea of the paper relies on using generalized regression neural network (GRNN) interpolation to obtain massive out of sample projections from iDR projections obtained on a reduced sample of the original dataset. The proposed method allows to achieve fluid iDR interaction on datasets between 45× and 100× larger than with the original DR method for similar latencies, yet achieving good distance preservation. The paper includes a rank-based comparison between the proposed method and the DR method used alone for different datasets and parameter values. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO)and FEDER funds from the EU under grants DPI2015-69891-C2-1/2-R and from the Principado de Asturias government through the predoctoral grant ""Severo Ochoa"".",Interaction and User Integration in Machine Learning for Information Visualisation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-47.pdf,2018,100.0,"Interactive dimensionality reduction of large datasets using interpolation In this work we present an approach to achieve interactive dimensionality reduction (iDR) on large datasets. The main idea of the paper relies on using generalized regression neural network (GRNN) interpolation to obtain massive out of sample projections from iDR projections obtained on a reduced sample of the original dataset. The proposed method allows to achieve fluid iDR interaction on datasets between 45× and 100× larger than with the original DR method for similar latencies, yet achieving good distance preservation. The paper includes a rank-based comparison between the proposed method and the DR method used alone for different datasets and parameter values. * The authors would like to thank financial support from the Spanish Ministry of Economy (MINECO)and FEDER funds from the EU under grants DPI2015-69891-C2-1/2-R and from the Principado de Asturias government through the predoctoral grant ""Severo Ochoa""."
Personalizing human activity recognition models using incremental learning,"Pekka Siirtola, Heli Koskimäki, Juha Röning",1 - Biomimetics and Intelligent Systems Group University of Oulu P.O. BOX 4500 FI-90014 Oulu Finland,"In this study, the aim is to personalize inertial sensor databased human activity recognition models using incremental learning. At first, the recognition is based on user-independent model. However, when personal streaming data becomes available, the incremental learning-based recognition model can be updated, and therefore personalized, based on the data without user-interruption. The used incremental learning algorithm is Learn++ which is an ensemble method that can use any classifier as a base classifier. In fact, study compares three different base classifiers: linear discriminant analysis (LDA), quadratic discriminant analysis (QDA) and classification and regression tree (CART). Experiments are based on publicly open data set and they show that already a small personal training data set can improve the classification accuracy. Improvement using LDA as base classifier is 4.6 percentage units, using QDA 2.0 percentage units, and 2.3 percentage units using CART. However, if the user-independent model used in the first phase of the recognition process is not accurate enough, personalization cannot improve recognition accuracy. 
 Problem statement and related work This study focuses on human activity recognition based on inertial sensor data collected using smartphone sensors. One of the main challenge of the field is that people are different: they are unique for instance in terms of physical characteristics, health state or gender. All of these have an effect to the data that are collected for model training. In fact, it is shown that user-independent models do not work accurately for instance if they are trained with healthy study subjects and tested with subjects who have difficulties to move  [1] . Thus, if the aim is to train a model that works with everybody, the focus of research should be on personal and personalized prediction models instead of user-independent models. However, the challenge of personal and personalized models is that they require personal training data. This normally would require an extensive, separate data collection session for each user making the approach unusable out-of-the-box. There are some attempts to personalize the recognition process without userinterruption. Siirtola et. al [2] presented a two step approach especially designed for devices that include several different types of sensors. In the first step, userindependent model that uses data from all sensors was used to label personal streaming data. This information is then used to build a light, and energy efficient personal model that uses only a sub-set of available sensors. Using the approach, recognition accuracy can be improved but the problem of the","Temporal data, sequences and incremental learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-48.pdf,2018,100.0,"Personalizing human activity recognition models using incremental learning In this study, the aim is to personalize inertial sensor databased human activity recognition models using incremental learning. At first, the recognition is based on user-independent model. However, when personal streaming data becomes available, the incremental learning-based recognition model can be updated, and therefore personalized, based on the data without user-interruption. The used incremental learning algorithm is Learn++ which is an ensemble method that can use any classifier as a base classifier. In fact, study compares three different base classifiers: linear discriminant analysis (LDA), quadratic discriminant analysis (QDA) and classification and regression tree (CART). Experiments are based on publicly open data set and they show that already a small personal training data set can improve the classification accuracy. Improvement using LDA as base classifier is 4.6 percentage units, using QDA 2.0 percentage units, and 2.3 percentage units using CART. However, if the user-independent model used in the first phase of the recognition process is not accurate enough, personalization cannot improve recognition accuracy. 
 Problem statement and related work This study focuses on human activity recognition based on inertial sensor data collected using smartphone sensors. One of the main challenge of the field is that people are different: they are unique for instance in terms of physical characteristics, health state or gender. All of these have an effect to the data that are collected for model training. In fact, it is shown that user-independent models do not work accurately for instance if they are trained with healthy study subjects and tested with subjects who have difficulties to move  [1] . Thus, if the aim is to train a model that works with everybody, the focus of research should be on personal and personalized prediction models instead of user-independent models. However, the challenge of personal and personalized models is that they require personal training data. This normally would require an extensive, separate data collection session for each user making the approach unusable out-of-the-box. There are some attempts to personalize the recognition process without userinterruption. Siirtola et. al [2] presented a two step approach especially designed for devices that include several different types of sensors. In the first step, userindependent model that uses data from all sensors was used to label personal streaming data. This information is then used to build a light, and energy efficient personal model that uses only a sub-set of available sensors. Using the approach, recognition accuracy can be improved but the problem of the"
Bidirectional deep-readout echo state networks,"Filippo Bianchi, Simone Scardapane, Sigurd Løkse, Robert Jenssen","1 - Machine Learning Group -UiT Arctic University Norway
2 - Electronics and Telecommunications (DIET) Sapienza University of Rome -Dept. of Information Engineering","We propose a deep architecture for the classification of multivariate time series. By means of a recurrent and untrained reservoir we generate a vectorial representation that embeds temporal relationships in the data. To improve the memorization capability, we implement a bidirectional reservoir, whose last state captures also past dependencies in the input. We apply dimensionality reduction to the final reservoir states to obtain compressed fixed size representations of the time series. These are subsequently fed into a deep feedforward network trained to perform the final classification. We test our architecture on benchmark datasets and on a real-world use-case of blood samples classification. Results show that our method performs better than a standard echo state network and, at the same time, achieves results comparable to a fully-trained recurrent network, but with a faster training.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-49.pdf,2018,100.0,"Bidirectional deep-readout echo state networks We propose a deep architecture for the classification of multivariate time series. By means of a recurrent and untrained reservoir we generate a vectorial representation that embeds temporal relationships in the data. To improve the memorization capability, we implement a bidirectional reservoir, whose last state captures also past dependencies in the input. We apply dimensionality reduction to the final reservoir states to obtain compressed fixed size representations of the time series. These are subsequently fed into a deep feedforward network trained to perform the final classification. We test our architecture on benchmark datasets and on a real-world use-case of blood samples classification. Results show that our method performs better than a standard echo state network and, at the same time, achieves results comparable to a fully-trained recurrent network, but with a faster training."
Shallow and Deep Models for Domain Adaptation problems,"Siamak Mehrkanoon, Matthew Blaschko, Johan Suykens","1 - Department of Electrical Engineering ESAT-STADIUS, KU Leuven B-3001 Leuven Belgium
2 - ESAT-PSI, KU Leuven Kasteelpark Arenberg 10 B-3001 Leuven Belgium","Manual labeling of sufficient training data for diverse application domains is a costly, laborious task and often prohibitive. Therefore, designing models that can leverage rich labeled data in one domain and be applicable to a different but related domain is highly desirable. In particular, domain adaptation or transfer learning algorithms seek to generalize a model trained in a source domain to a new target domain. Recent years has witnessed increasing interest in these types of models due to their practical importance in real-life applications. In this paper we provide a brief overview of recent techniques with both shallow and deep architectures for domain adaptation models.",Shallow and Deep models for transfer learning and domain adaptation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-5.pdf,2018,100.0,"Shallow and Deep Models for Domain Adaptation problems Manual labeling of sufficient training data for diverse application domains is a costly, laborious task and often prohibitive. Therefore, designing models that can leverage rich labeled data in one domain and be applicable to a different but related domain is highly desirable. In particular, domain adaptation or transfer learning algorithms seek to generalize a model trained in a source domain to a new target domain. Recent years has witnessed increasing interest in these types of models due to their practical importance in real-life applications. In this paper we provide a brief overview of recent techniques with both shallow and deep architectures for domain adaptation models."
Reinforcement Learning for High-Frequency Market Making,"Ye-Sheen Lim, Denise Gorse",1 - University College London -Computer Science Gower Street WC1E 6BT London UK,"In this paper we present the first practical application of reinforcement learning to optimal market making in high-frequency trading. States, actions, and reward formulations unique to high-frequency market making are proposed, including a novel use of the CARA utility as a terminal reward for improving learning. We show that the optimal policy trained using Q-learning outperforms state-of-the-art market making algorithms. Finally, we analyse the optimal reinforcement learning policies, and the influence of the CARA utility from a trading perspective.","Mathematical aspects of learning, and reinforcement learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2018-50.pdf,2018,100.0,"Reinforcement Learning for High-Frequency Market Making In this paper we present the first practical application of reinforcement learning to optimal market making in high-frequency trading. States, actions, and reward formulations unique to high-frequency market making are proposed, including a novel use of the CARA utility as a terminal reward for improving learning. We show that the optimal policy trained using Q-learning outperforms state-of-the-art market making algorithms. Finally, we analyse the optimal reinforcement learning policies, and the influence of the CARA utility from a trading perspective."
Neural Networks for Implicit Feedback Datasets,"Josef Feigl, Martin Bogdan",1 - Department of Computer Engineering University of Leipzig Augustusplatz 10 04109 Leipzig Germany,"Most users typically interact with products only through implicit feedback such as clicks or purchases rather than explicit userprovided information like product ratings. Learning to rank products according to individual preferences using only this implicit feedback can be helpful to make useful recommendations. In this paper, a neural network architecture to solve collaborative filtering problems for personalized rankings on implicit feedback datasets is presented. It is shown how a layer of constant weights forces the network to learn pairwise rankings. Additionally, similarities between the network and a matrix factorization model trained with Bayesian Personalized Ranking are proven. The experiments indicate state-of-the-art performance for the task of personalized ranking.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-51.pdf,2018,100.0,"Neural Networks for Implicit Feedback Datasets Most users typically interact with products only through implicit feedback such as clicks or purchases rather than explicit userprovided information like product ratings. Learning to rank products according to individual preferences using only this implicit feedback can be helpful to make useful recommendations. In this paper, a neural network architecture to solve collaborative filtering problems for personalized rankings on implicit feedback datasets is presented. It is shown how a layer of constant weights forces the network to learn pairwise rankings. Additionally, similarities between the network and a matrix factorization model trained with Bayesian Personalized Ranking are proven. The experiments indicate state-of-the-art performance for the task of personalized ranking."
Feature Noise Tuning for Resource Efficient Bayesian Network Classifiers,"Laura Galindez Olascoaga, Jonas Vlasselaer, Wannes Meert, Marian Verhelst","1 - Dept. of Electrical Engineering MICAS KU Leuven Belgium
3 - Dept. of Computer Science DTAI Leuven KU Belgium","Emerging portable applications require always-on sensing technologies to continuously monitor the environment and their user's needs. Yet, the high power consumption that results from this continuous sensing often hampers these systems' always-on functionality. In this paper we propose a hardware-aware Machine Learning scheme that exploits the devices' ability to trade-off the quality of its sensors versus its power consumption. We introduce a technique that extends Bayesian Network classifiers with hardware description nodes that encode the probabilistic relation between sensory features and their degraded versions. We show how this allows to tune the hardware device's power consumption versus inference accuracy trade-off space with fine granularity, resulting in operating points that achieve significant power savings at almost no accuracy loss. This is empirically shown on various Machine Learning benchmarking datasets.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-53.pdf,2018,76.38888888888889,"Feature Noise Tuning for Resource Efficient Bayesian Network Classifiers Emerging portable applications require always-on sensing technologies to continuously monitor the environment and their user's needs. Yet, the high power consumption that results from this continuous sensing often hampers these systems' always-on functionality. In this paper we propose a hardware-aware Machine Learning scheme that exploits the devices' ability to trade-off the quality of its sensors versus its power consumption. We introduce a technique that extends Bayesian Network classifiers with hardware description nodes that encode the probabilistic relation between sensory features and their degraded versions. We show how this allows to tune the hardware device's power consumption versus inference accuracy trade-off space with fine granularity, resulting in operating points that achieve significant power savings at almost no accuracy loss. This is empirically shown on various Machine Learning benchmarking datasets."
A Novel Filter Algorithm for Unsupervised Feature Selection Based on a Space Filling Measure,"Mohamed Laib, Mikhail Kanevski",1 - University of Lausanne -Institute of Earth Surface Dynamics Switzerland,"The research proposes a novel filter algorithm for the unsupervised feature selection problems based on a space filling measure. A well-known criterion of space filling design, called the coverage measure, is adapted to dimensionality reduction problems. Originally, this measure was developed to judge the quality of a space filling design. In this work it is used to reduce the redundancy in data. The proposed algorithm is evaluated on simulated data with several scenarios of noise injection. Furthermore, a comparison with some benchmark methods of feature selection is performed on real UCI datasets.",Clustering and feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-57.pdf,2018,79.34782608695652,"A Novel Filter Algorithm for Unsupervised Feature Selection Based on a Space Filling Measure The research proposes a novel filter algorithm for the unsupervised feature selection problems based on a space filling measure. A well-known criterion of space filling design, called the coverage measure, is adapted to dimensionality reduction problems. Originally, this measure was developed to judge the quality of a space filling design. In this work it is used to reduce the redundancy in data. The proposed algorithm is evaluated on simulated data with several scenarios of noise injection. Furthermore, a comparison with some benchmark methods of feature selection is performed on real UCI datasets."
Analysis of imputation bias for feature selection with missing data,"Borja Seijo-Pardo, Amparo Alonso-Betanzos, Kristin Bennett, Verónica Bolón-Canedo, Isabelle Guyon, Julie Josse, Mehreen Saeed","1 - U. A Coruña Spain
4 - RPI New York USA
5 - U. Paris-Saclay France
6 - Ecole Polytechnique France
7 - FAST Lahore Pakistan",We study risk/benefit tradeoff of missing value imputation in the context of feature selection. We caution against using imputation methods that may yield false positives: features not associated to the target becoming dependent as a result of imputation. We also investigate situations in which imputing missing values may be beneficial to reduce false negatives. We use causal graphs to characterize when structural bias arises and introduce a de-biased version of the t-test.,Impact of Biases in Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-58.pdf,2018,100.0,Analysis of imputation bias for feature selection with missing data We study risk/benefit tradeoff of missing value imputation in the context of feature selection. We caution against using imputation methods that may yield false positives: features not associated to the target becoming dependent as a result of imputation. We also investigate situations in which imputing missing values may be beneficial to reduce false negatives. We use causal graphs to characterize when structural bias arises and introduce a de-biased version of the t-test.
Sleep Staging with Deep Learning: A convolutional model,"Isaac Fernández-Varela, Dimitrios Athanasakis, Samuel Parsons, Elena Hernández-Pereira, Vicente Moret-Bonillo","1 - Departamento de Computación Facultade de Informática Universidade da Coruña Campus de Elviña A Coruña -Spain
2 - Data Spartan 60 Ludgate Hill EC4M 7AW London United Kingdom
3 - Department of Computer Science University College of London 66-72 Gower Street WC1E 6EA London United Kingdom","Sleep staging is a crucial task in the context of sleep studies that involves the analysis of multiple signals, thus being a very tedious and complex task. Even for a trained expert, it can take several hours to annotate the signals recorded from a patient's sleep during a single night. To solve this problem several automatic methods have been developed, although most of them rely on hand engineered features. To address the inner problems of this approach, in this work we explore the possibility of solving this problem with a deep learning network that can self-learn the relevant features from the signals. Particularly, we propose a convolutional network, obtaining higher performance than in previous methods, achieving an average precision of 0.91, recall of 0.90, and F-1 score of 0.90.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-59.pdf,2018,58.18181818181818,"Sleep Staging with Deep Learning: A convolutional model Sleep staging is a crucial task in the context of sleep studies that involves the analysis of multiple signals, thus being a very tedious and complex task. Even for a trained expert, it can take several hours to annotate the signals recorded from a patient's sleep during a single night. To solve this problem several automatic methods have been developed, although most of them rely on hand engineered features. To address the inner problems of this approach, in this work we explore the possibility of solving this problem with a deep learning network that can self-learn the relevant features from the signals. Particularly, we propose a convolutional network, obtaining higher performance than in previous methods, achieving an average precision of 0.91, recall of 0.90, and F-1 score of 0.90."
Randomized Recurrent Neural Networks,"Claudio Gallicchio, Alessio Micheli, Peter Tiňo","1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy
3 - School of Computer Science The University of Birmingham Edgbaston B15 2TT Birmingham United Kingdom","Neural Networks (NNs) with random weights represent nowadays a topic of consolidated use in the Machine Learning research community. In this contribution we focus in particular on recurrent NN models, which in a randomized setting represent a case of particular interest per se, entailing a number of intriguing research challenges primarily related to the control of the developed dynamics for the learning purposes. Framed in the Reservoir Computing paradigm, this paper aims at providing the basic elements and summarizing the recent advances on the topic of randomized recurrent NNs (divided in theoretical, architectural, deep learning and structured domain aspects), and introducing the papers accepted for the ESANN special session.",Randomized Neural Networks,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-6.pdf,2018,100.0,"Randomized Recurrent Neural Networks Neural Networks (NNs) with random weights represent nowadays a topic of consolidated use in the Machine Learning research community. In this contribution we focus in particular on recurrent NN models, which in a randomized setting represent a case of particular interest per se, entailing a number of intriguing research challenges primarily related to the control of the developed dynamics for the learning purposes. Framed in the Reservoir Computing paradigm, this paper aims at providing the basic elements and summarizing the recent advances on the topic of randomized recurrent NNs (divided in theoretical, architectural, deep learning and structured domain aspects), and introducing the papers accepted for the ESANN special session."
A Neural Network Cost Function for Highly Class-Imbalanced Data Sets,"David Twomey, Denise Gorse",1 - University College London -Computer Science Gower Street WC1E 6BT London UK,"We introduce a new cost function for the training of a neural network classifier in conditions of high class imbalance. This function, based on an approximate confusion matrix, represents a balance of sensitivity and specificity and is thus well suited to problems where cost functions such as the mean squared error and cross entropy are prone to overpredicting the majority class. The benefit of the new measure is shown on a set of common class-imbalanced datasets using the Matthews Correlation Coefficient as an independent scoring measure.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-60.pdf,2018,80.88235294117648,"A Neural Network Cost Function for Highly Class-Imbalanced Data Sets We introduce a new cost function for the training of a neural network classifier in conditions of high class imbalance. This function, based on an approximate confusion matrix, represents a balance of sensitivity and specificity and is thus well suited to problems where cost functions such as the mean squared error and cross entropy are prone to overpredicting the majority class. The benefit of the new measure is shown on a set of common class-imbalanced datasets using the Matthews Correlation Coefficient as an independent scoring measure."
Inferencing Based on Unsupervised Learning of Disentangled Representations,"Tobias Hinz, Stefan Wermter",1 - Department of Informatics Universität Hamburg Knowledge Technology Vogt-Koelln-Str. 30 22527 Hamburg Germany,"Combining Generative Adversarial Networks (GANs) with encoders that learn to encode data points has shown promising results in learning data representations in an unsupervised way. We propose a framework that combines an encoder and a generator to learn disentangled representations which encode meaningful information about the data distribution without the need for any labels. While current approaches focus mostly on the generative aspects of GANs, our framework can be used to perform inference on both real and generated data points. Experiments on several data sets show that the encoder learns interpretable, disentangled representations which encode descriptive properties and can be used to sample images that exhibit specific characteristics. * The authors gratefully acknowledge partial support from the German Research Foundation under project CML (TRR 169) and the European Union under project SECURE (No. 642667).",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-61.pdf,2018,70.27027027027026,"Inferencing Based on Unsupervised Learning of Disentangled Representations Combining Generative Adversarial Networks (GANs) with encoders that learn to encode data points has shown promising results in learning data representations in an unsupervised way. We propose a framework that combines an encoder and a generator to learn disentangled representations which encode meaningful information about the data distribution without the need for any labels. While current approaches focus mostly on the generative aspects of GANs, our framework can be used to perform inference on both real and generated data points. Experiments on several data sets show that the encoder learns interpretable, disentangled representations which encode descriptive properties and can be used to sample images that exhibit specific characteristics. * The authors gratefully acknowledge partial support from the German Research Foundation under project CML (TRR 169) and the European Union under project SECURE (No. 642667)."
Non-negative Matrix Factorization for Medical Imaging,"Miguel Atencia, Ruxandra Stoean","1 - Departamento de Matemática Aplicada Escuela de Ingenierías Industriales Universidad de Málaga 29071 Málaga Spain
2 - Department of Computer Science Faculty of Sciences University of Craiova 200585 Craiova Romania","A non-negative matrix factorization approach to dimensionality reduction is proposed to aid classification of images. The original images can be stored as lower-dimensional columns of a matrix that hold degrees of belonging to feature components, so they can be used in the training phase of the classification at lower runtime and without loss in accuracy. The extracted features can be visually examined and images reconstructed with limited error. The proof of concept is performed on a benchmark of handwritten digits, followed by the application to histopathological colorectal cancer slides. Results are encouraging, though dealing with real-world medical data raises a number of issues.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-62.pdf,2018,100.0,"Non-negative Matrix Factorization for Medical Imaging A non-negative matrix factorization approach to dimensionality reduction is proposed to aid classification of images. The original images can be stored as lower-dimensional columns of a matrix that hold degrees of belonging to feature components, so they can be used in the training phase of the classification at lower runtime and without loss in accuracy. The extracted features can be visually examined and images reconstructed with limited error. The proof of concept is performed on a benchmark of handwritten digits, followed by the application to histopathological colorectal cancer slides. Results are encouraging, though dealing with real-world medical data raises a number of issues."
Graph Based Neural Networks for Automatic Classification of Multiple Sclerosis Clinical Courses,"Francesco Calimeri, Aldo Marzullo, Claudio Stamile, Giorgio Terracina","1 - Department of Mathematics and Computer Science University of Calabria Italy
3 - INSERM U1044 CREATIS CNRS UMR5220
4 - Université de Lyon Université Lyon 1 INSA-Lyon Villeurbanne France","Automatic classification of biomedical imaging became an important field of research within the scientific community, in the latest years. Indeed, advances in image acquisition and processing techniques, along with the success of novel deep learning methods and architectures, represented a considerable support in providing better biomarkers for the characterization of several diseases, and brain diseases in particular. In this work we propose a novel neural network approach that is applied to graphs generated from MRI data in order to make predictions about the clinical status of a patient. Results show high performances in classification tasks and open interesting perspectives in the field. * The work is partially funded by an European Union's Horizon 2020 research and innovation programme under the Marie Sk lodowska-Curie grant agreement No. 690974 and by the Italian Ministry of University and Research under project ""Dottorato innovativo a caratterizzazione industriale"" PON R&I FSE-FESR 2014-2020.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-63.pdf,2018,78.94736842105263,"Graph Based Neural Networks for Automatic Classification of Multiple Sclerosis Clinical Courses Automatic classification of biomedical imaging became an important field of research within the scientific community, in the latest years. Indeed, advances in image acquisition and processing techniques, along with the success of novel deep learning methods and architectures, represented a considerable support in providing better biomarkers for the characterization of several diseases, and brain diseases in particular. In this work we propose a novel neural network approach that is applied to graphs generated from MRI data in order to make predictions about the clinical status of a patient. Results show high performances in classification tasks and open interesting perspectives in the field. * The work is partially funded by an European Union's Horizon 2020 research and innovation programme under the Marie Sk lodowska-Curie grant agreement No. 690974 and by the Italian Ministry of University and Research under project ""Dottorato innovativo a caratterizzazione industriale"" PON R&I FSE-FESR 2014-2020."
Impact of Biases in Big Data,"Patrick Glauner, Petko Valtchev, Radu State","1 - Interdisciplinary Centre for Security, Reliability and Trust University of Luxembourg 29, Avenue JF Kennedy 1855 Luxembourg Luxembourg
2 - Department of Computer Science av. President Kennedy University of Quebec 201, H2X 3Y7 Montreal, Montreal Canada","The underlying paradigm of big data-driven machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. Is having simply more data always helpful? In 1936, The Literary Digest collected 2.3M filled in questionnaires to predict the outcome of that year's US presidential election. The outcome of this big data prediction proved to be entirely wrong, whereas George Gallup only needed 3K handpicked people to make an accurate prediction. Generally, biases occur in machine learning whenever the distributions of training set and test set are different. In this work, we provide a review of different sorts of biases in (big) data sets in machine learning. We provide definitions and discussions of the most commonly appearing biases in machine learning: class imbalance and covariate shift. We also show how these biases can be quantified and corrected. This work is an introductory text for both researchers and practitioners to become more aware of this topic and thus to derive more reliable models for their learning problems.",Impact of Biases in Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-7.pdf,2018,100.0,"Impact of Biases in Big Data The underlying paradigm of big data-driven machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. Is having simply more data always helpful? In 1936, The Literary Digest collected 2.3M filled in questionnaires to predict the outcome of that year's US presidential election. The outcome of this big data prediction proved to be entirely wrong, whereas George Gallup only needed 3K handpicked people to make an accurate prediction. Generally, biases occur in machine learning whenever the distributions of training set and test set are different. In this work, we provide a review of different sorts of biases in (big) data sets in machine learning. We provide definitions and discussions of the most commonly appearing biases in machine learning: class imbalance and covariate shift. We also show how these biases can be quantified and corrected. This work is an introductory text for both researchers and practitioners to become more aware of this topic and thus to derive more reliable models for their learning problems."
Towards cognitive automotive environment modelling: reasoning based on vector representations,"Florian Mirus, Terrence Stewart, Jörg Conradt","1 - -BMW Group -Research New Technologies, Innovations Garching Germany
2 - Neuroscientific System Theory Group Technical University of Munich Munich Germany
3 - Centre for Theoretical Neuroscience University of Waterloo Waterloo ON Canada","In this paper, we propose a novel approach to knowledge representation for automotive environment modelling based on Vector Symbolic Architectures (VSAs). We build a vector representation describing structured information and relations within the current scene based on high-level object-lists perceived by individual sensors. Such a representation can be applied to different tasks with little modifications. In a sample instantiation, we focus on two example tasks, namely driving context classification and simple behavior prediction, to demonstrate the general applicability of our approach. Allowing efficient implementation in Spiking Neural Networks (SNNs), we envision to improve task performance of our approach through online-learning.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-70.pdf,2018,100.0,"Towards cognitive automotive environment modelling: reasoning based on vector representations In this paper, we propose a novel approach to knowledge representation for automotive environment modelling based on Vector Symbolic Architectures (VSAs). We build a vector representation describing structured information and relations within the current scene based on high-level object-lists perceived by individual sensors. Such a representation can be applied to different tasks with little modifications. In a sample instantiation, we focus on two example tasks, namely driving context classification and simple behavior prediction, to demonstrate the general applicability of our approach. Allowing efficient implementation in Spiking Neural Networks (SNNs), we envision to improve task performance of our approach through online-learning."
Extreme Minimal Learning Machine,Tommi Kärkkäinen,1 - Faculty of Information Technology University of Jyvaskyla Finland,"Extreme Learning Machine (ELM) and Minimal Learning Machine (MLM) are nonlinear and scalable machine learning techniques with randomly generated basis. Both techniques share a step where a matrix of weights for the linear combination of the basis is recovered. In MLM, the kernel in this step corresponds to distance calculations between the training data and a set of reference points, whereas in ELM transformation with a sigmoidal activation function is most commonly used. MLM then needs additional interpolation step to estimate the actual distance-regression based output. A natural combination of these two techniques is proposed here, i.e., to use a distance-based kernel characteristic in MLM in ELM. The experimental results show promising potential of the proposed technique.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-72.pdf,2018,100.0,"Extreme Minimal Learning Machine Extreme Learning Machine (ELM) and Minimal Learning Machine (MLM) are nonlinear and scalable machine learning techniques with randomly generated basis. Both techniques share a step where a matrix of weights for the linear combination of the basis is recovered. In MLM, the kernel in this step corresponds to distance calculations between the training data and a set of reference points, whereas in ELM transformation with a sigmoidal activation function is most commonly used. MLM then needs additional interpolation step to estimate the actual distance-regression based output. A natural combination of these two techniques is proposed here, i.e., to use a distance-based kernel characteristic in MLM in ELM. The experimental results show promising potential of the proposed technique."
Sensitivity Analysis for Predictive Uncertainty in Bayesian Neural Networks,"Stefan Depeweg, José Hernández-Lobato, Steffen Udluft, Thomas Runkler","1 - Technical Unversity of Munich Germany
2 - Siemens AG Germany
3 - University of Cambridge United Kingdom",We derive a novel sensitivity analysis of input variables for predictive epistemic and aleatoric uncertainty. We use Bayesian neural networks with latent variables as a model class and illustrate the usefulness of our sensitivity analysis on real-world datasets. Our method increases the interpretability of complex black-box probabilistic models.,Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-94.pdf,2018,59.31034482758621,Sensitivity Analysis for Predictive Uncertainty in Bayesian Neural Networks We derive a novel sensitivity analysis of input variables for predictive epistemic and aleatoric uncertainty. We use Bayesian neural networks with latent variables as a model class and illustrate the usefulness of our sensitivity analysis on real-world datasets. Our method increases the interpretability of complex black-box probabilistic models.
VisCoDeR: A Tool for Visually Comparing Dimensionality Reduction Algorithms,"Rene Cutura, Stefan Holzer, Michaël Aupetit, Michael Sedlmair","1 - Department of Computer Science University of Vienna Austria
3 - Qatar Computing Research Institute HBKU Doha Qatar
5 - Computer Science & Electrical Engineering Jacobs University Bremen Germany","We propose VisCoDeR, a tool that leverages comparative visualization to support learning and analyzing different dimensionality reduction (DR) methods. VisCoDeR fosters two modes. The Discover mode allows qualitatively comparing several DR results by juxtaposing and linking the resulting scatterplots. The Explore mode allows for analyzing hundreds of differently parameterized DR results in a quantitative way. We present use cases that show that our approach helps to understand similarities and differences between DR algorithms.",Interaction and User Integration in Machine Learning for Information Visualisation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-74.pdf,2018,73.33333333333334,"VisCoDeR: A Tool for Visually Comparing Dimensionality Reduction Algorithms We propose VisCoDeR, a tool that leverages comparative visualization to support learning and analyzing different dimensionality reduction (DR) methods. VisCoDeR fosters two modes. The Discover mode allows qualitatively comparing several DR results by juxtaposing and linking the resulting scatterplots. The Explore mode allows for analyzing hundreds of differently parameterized DR results in a quantitative way. We present use cases that show that our approach helps to understand similarities and differences between DR algorithms."
Extensive assessment of Barnes-Hut t-SNE,"Cyril De Bodt, Dounia Mulders, Michel Verleysen, John Lee","1 - Université catholique de Louvain -ICTEAM Place du Levant L5.03.02, 1348 Louvain-la-Neuve Belgium
4 - Université catholique de Louvain -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium","Stochastic Neighbor Embedding (SNE) and variants are dimensionality reduction (DR) methods able to foil the curse of dimensionality to deliver outstanding experimental results. Mitigating the crowding problem, t-SNE became an extremely popular DR scheme. Its quadratic time complexity in the number of samples is nevertheless unaffordable for big data sets. This motivates its Barnes-Hut (BH) acceleration for large-scale use. Although the latter is faster by orders of magnitude, few studies quantify its DR quality with respect to t-SNE. Extensive comparisons between t-SNE and its BH version are conducted using neighborhood preservation-based criteria. Both methods perform very similarly, suggesting the BH scheme superiority thanks to its reduced time complexity. * Computational resources have been provided by the supercomputing facilities of the Université catholique de Louvain (CISM/UCL) and the Consortium des Équipements de Calcul Intensif en Fédération Wallonie Bruxelles (C ÉCI) funded by the Fonds de la Recherche Scientifique de Belgique (F.R.S.-FNRS) under convention 2.5020.11. DM and CdB are Research Fellows of the FNRS. JL is a Senior Research Associate with the FNRS.",Nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-76.pdf,2018,100.0,"Extensive assessment of Barnes-Hut t-SNE Stochastic Neighbor Embedding (SNE) and variants are dimensionality reduction (DR) methods able to foil the curse of dimensionality to deliver outstanding experimental results. Mitigating the crowding problem, t-SNE became an extremely popular DR scheme. Its quadratic time complexity in the number of samples is nevertheless unaffordable for big data sets. This motivates its Barnes-Hut (BH) acceleration for large-scale use. Although the latter is faster by orders of magnitude, few studies quantify its DR quality with respect to t-SNE. Extensive comparisons between t-SNE and its BH version are conducted using neighborhood preservation-based criteria. Both methods perform very similarly, suggesting the BH scheme superiority thanks to its reduced time complexity. * Computational resources have been provided by the supercomputing facilities of the Université catholique de Louvain (CISM/UCL) and the Consortium des Équipements de Calcul Intensif en Fédération Wallonie Bruxelles (C ÉCI) funded by the Fonds de la Recherche Scientifique de Belgique (F.R.S.-FNRS) under convention 2.5020.11. DM and CdB are Research Fellows of the FNRS. JL is a Senior Research Associate with the FNRS."
Evolutionary Composition of Customised Fault Localisation Heuristics,"Diogo De Freitas, Plinio Leitao-Junior, Celso Camilo-Junior, Rachel Harrison","1 - Universidade Federal de Goias (UFG) -Instituto de Informatica (INF) Alameda Palmeiras Campus Samambaia Quadra D, Goiania, Goias Brazil
3 - Oxford Brookes -Dept of Computing and Communication Technologies Wheatley Campus OX33 1HX Wheatley Oxford United Kingdom",Fault localisation is one of the most difficult and costly parts in software debugging. Researchers have tried to automate this process by formulating measures for assessment of code elements' suspiciousness. This paper reports an evolutionary-based approach to combine non-linearly 34 previous measures to formulate a new program oriented fault localisation heuristic. The method was evaluated with 107 single-bug programs and compared against 35 approaches -34 spectrum-based heuristics and a previous evolutionary linear combination approach. The experiments have shown that the proposal consistently achieved competitive results compared to the others according to several effectiveness metrics. * We thank CAPES and Universidade Federal de Goias for the support and Oxford Brookes University for the facilities to develop the research.,Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-77.pdf,2018,97.05882352941177,Evolutionary Composition of Customised Fault Localisation Heuristics Fault localisation is one of the most difficult and costly parts in software debugging. Researchers have tried to automate this process by formulating measures for assessment of code elements' suspiciousness. This paper reports an evolutionary-based approach to combine non-linearly 34 previous measures to formulate a new program oriented fault localisation heuristic. The method was evaluated with 107 single-bug programs and compared against 35 approaches -34 spectrum-based heuristics and a previous evolutionary linear combination approach. The experiments have shown that the proposal consistently achieved competitive results compared to the others according to several effectiveness metrics. * We thank CAPES and Universidade Federal de Goias for the support and Oxford Brookes University for the facilities to develop the research.
Self-learning assembly systems during ramp-up,"Ralf Schönherr, Maximilian Knaller, Markus Philipp","1 - RWTH Aachen University -Dept. of Mechanical Engineering Templergraben 55 52062 Aachen -Germany
2 - Otto-von-Guericke University -Dept. of Mechanical Engineering Universitätsplatz 2 39106 Magdeburg Germany
3 - Dept. of Electrical and Computer Engineering Technical University of Munich Theresienstrasse 90 80333 Munich -Germany
4 - -BMW Group -Knorrstrasse 147 80788 Munich Germany","Achieving the targeted production volume during the rampup phase plays an important role for the economic success of manufacturing companies. But ramp-up phases are usually characterized by a high degree of uncertainty, as many situations arise for the first time. These unexpected events lead to errors and faults in automated processes which cause losses in the overall production volume. This paper proposes an architecture for assembly systems to predict and avoid faults of the assembly process during ramp-up through self-learning. Different algorithms for self-learning components are evaluated. By using real production data sets, neural networks could be identified as the best solution.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-78.pdf,2018,100.0,"Self-learning assembly systems during ramp-up Achieving the targeted production volume during the rampup phase plays an important role for the economic success of manufacturing companies. But ramp-up phases are usually characterized by a high degree of uncertainty, as many situations arise for the first time. These unexpected events lead to errors and faults in automated processes which cause losses in the overall production volume. This paper proposes an architecture for assembly systems to predict and avoid faults of the assembly process during ramp-up through self-learning. Different algorithms for self-learning components are evaluated. By using real production data sets, neural networks could be identified as the best solution."
Revisiting FISTA for Lasso: Acceleration Strategies Over The Regularization Path,"Alejandro Catalina, Carlos Alaíz, José Dorronsoro",1 - Departamento de Ingeniería Informática e Instituo de Ingeniería del Conocimiento Universidad Autónoma de Madrid Madrid Spain,"In this work we revisit FISTA algorithm for Lasso showing that recent acceleration techniques may greatly improve its basic version, resulting in a much more competitive procedure. We study the contribution of the different improvement strategies, showing experimentally that the final version becomes much faster than the standard one.",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-81.pdf,2018,100.0,"Revisiting FISTA for Lasso: Acceleration Strategies Over The Regularization Path In this work we revisit FISTA algorithm for Lasso showing that recent acceleration techniques may greatly improve its basic version, resulting in a much more competitive procedure. We study the contribution of the different improvement strategies, showing experimentally that the final version becomes much faster than the standard one."
Interpreting Deep Learning Models for Ordinal Problems,"José Amorim, Inês Domingues, Pedro Abreu, João Santos","1 - Department of Informatics Engineering Pólo II University of Coimbra -CISUC Pinhal de Marrocos 3030-290 Coimbra Portugal
2 - IPO-Porto Research Center -CI-IPOP Rua Dr. António Bernardino de Almeida 4200-072 Porto Portugal","Machine learning algorithms have evolved by exchanging simplicity and interpretability for accuracy, which prevents their adoption in critical tasks such as healthcare. Progress can be made by improving interpretability of complex models while preserving performance. This work introduces an extension of interpretable mimic learning which teaches interpretable models to mimic predictions of complex deep neural networks, not only on binary problems but also in ordinal settings. The results show that the mimic models have comparative performance to Deep Neural Network models, with the advantage of being interpretable.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-82.pdf,2018,75.92592592592592,"Interpreting Deep Learning Models for Ordinal Problems Machine learning algorithms have evolved by exchanging simplicity and interpretability for accuracy, which prevents their adoption in critical tasks such as healthcare. Progress can be made by improving interpretability of complex models while preserving performance. This work introduces an extension of interpretable mimic learning which teaches interpretable models to mimic predictions of complex deep neural networks, not only on binary problems but also in ordinal settings. The results show that the mimic models have comparative performance to Deep Neural Network models, with the advantage of being interpretable."
Globular cluster detection in the Gaia survey,"M Mohammadi, R Peletier, F Schleif, N Petkov, K Bunte","1 - Johann Bernoulli Institute University of Groningen
2 - Kapteyn Institute University of Groningen 3-Univ. of Appl. Sc. Würzburg Schweinfurt
3 - Dept. of CS Würzburg Germany","Existing algorithms for the detection of stellar structures in the Milky Way are most efficient when full phase-space and color information is available. This is rarely the case. Since recently, the Gaia satellite surveys the whole sky and is providing highly accurate positions for more than one billion sources. In this contribution we propose two independent strategies to find globular clusters in this database, based on magnitude distributions only. One approach is a nearest neighbor retrieval and the other an anomaly detection. Both techniques are able to find known globular clusters within our observation frame consistently, as well as additional candidates for further investigation.",Machine Learning and Data Analysis in Astroinformatics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-86.pdf,2018,60.0,"Globular cluster detection in the Gaia survey Existing algorithms for the detection of stellar structures in the Milky Way are most efficient when full phase-space and color information is available. This is rarely the case. Since recently, the Gaia satellite surveys the whole sky and is providing highly accurate positions for more than one billion sources. In this contribution we propose two independent strategies to find globular clusters in this database, based on magnitude distributions only. One approach is a nearest neighbor retrieval and the other an anomaly detection. Both techniques are able to find known globular clusters within our observation frame consistently, as well as additional candidates for further investigation."
Feasibility Based Large Margin Nearest Neighbor Metric Learning,"Babak Hosseini, Barbara Hammer",1 - CITEC centre of excellence Bielefeld University Bielefeld Germany,"Large margin nearest neighbor (LMNN) is a metric learner which optimizes the performance of the popular kNN classifier. However, its resulting metric relies on pre-selected target neighbors. In this paper, we address the feasibility of LMNN's optimization constraints regarding these target points, and introduce a mathematical measure to evaluate the size of the feasible region of the optimization problem. We enhance the optimization framework of LMNN by a weighting scheme which prefers data triplets which yield a larger feasible region. This increases the chances to obtain a good metric as the solution of LMNN's problem. We evaluate the performance of the resulting feasibility-based LMNN algorithm using synthetic and real datasets. The empirical results show an improved accuracy for different types of datasets in comparison to regular LMNN.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-87.pdf,2018,65.07936507936508,"Feasibility Based Large Margin Nearest Neighbor Metric Learning Large margin nearest neighbor (LMNN) is a metric learner which optimizes the performance of the popular kNN classifier. However, its resulting metric relies on pre-selected target neighbors. In this paper, we address the feasibility of LMNN's optimization constraints regarding these target points, and introduce a mathematical measure to evaluate the size of the feasible region of the optimization problem. We enhance the optimization framework of LMNN by a weighting scheme which prefers data triplets which yield a larger feasible region. This increases the chances to obtain a good metric as the solution of LMNN's problem. We evaluate the performance of the resulting feasibility-based LMNN algorithm using synthetic and real datasets. The empirical results show an improved accuracy for different types of datasets in comparison to regular LMNN."
Hierarchical Recurrent Filtering for Fully Convolutional DenseNets,"Jörg Wagner, Volker Fischer, Michael Herman, Sven Behnke","1 - Bosch Center for Artificial Intelligence 71272 Renningen Germany
2 - University of Bonn -Computer Science VI Autonomous Intelligent Systems -Friedrich-Ebert-Allee 144 53113 Bonn Germany","Generating a robust representation of the environment is a crucial ability of learning agents. Deep learning based methods have greatly improved perception systems but still fail in challenging situations. These failures are often not solvable on the basis of a single image. In this work, we present a parameter-efficient temporal filtering concept which extends an existing single-frame segmentation model to work with multiple frames. The resulting recurrent architecture temporally filters representations on all abstraction levels in a hierarchical manner, while decoupling temporal dependencies from scene representation. Using a synthetic dataset, we show the ability of our model to cope with data perturbations and highlight the importance of recurrent and hierarchical filtering.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-88.pdf,2018,100.0,"Hierarchical Recurrent Filtering for Fully Convolutional DenseNets Generating a robust representation of the environment is a crucial ability of learning agents. Deep learning based methods have greatly improved perception systems but still fail in challenging situations. These failures are often not solvable on the basis of a single image. In this work, we present a parameter-efficient temporal filtering concept which extends an existing single-frame segmentation model to work with multiple frames. The resulting recurrent architecture temporally filters representations on all abstraction levels in a hierarchical manner, while decoupling temporal dependencies from scene representation. Using a synthetic dataset, we show the ability of our model to cope with data perturbations and highlight the importance of recurrent and hierarchical filtering."
Finding the Most Interpretable MDS Rotation for Sparse Linear Models based on External Features,"Adrien Bibal, Rebecca Marion, Benoît Frénay","1 - Faculty of Computer Science NADI Institute -PReCISE Research Center University of Namur Rue Grandgagnage 21 5000 Namur Belgium
2 - ISBA -Université catholique de Louvain Voie du Roman Pays 20 1348 Louvain-la-Neuve Belgium","One approach to interpreting multidimensional scaling (MDS) embeddings is to estimate a linear relationship between the MDS dimensions and a set of external features. However, because MDS only preserves distances between instances, the MDS embedding is invariant to rotation. As a result, the weights characterizing this linear relationship are arbitrary and difficult to interpret. This paper proposes a procedure for selecting the most pertinent rotation for interpreting a 2D MDS embedding.",Emerging trends in machine learning: beyond conventional methods and data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-89.pdf,2018,66.31578947368422,"Finding the Most Interpretable MDS Rotation for Sparse Linear Models based on External Features One approach to interpreting multidimensional scaling (MDS) embeddings is to estimate a linear relationship between the MDS dimensions and a set of external features. However, because MDS only preserves distances between instances, the MDS embedding is invariant to rotation. As a result, the weights characterizing this linear relationship are arbitrary and difficult to interpret. This paper proposes a procedure for selecting the most pertinent rotation for interpreting a 2D MDS embedding."
Order Crossover for the Inventory Routing Problem,"Mohamed Salim, Amri Sakhri, Mounira Tlili, Hamid Allaoui, Ouajdi Korbaa","1 - Supérieur de Gestion de Tunis -Laboratoire Strategies for Modelling and ARtificial inTelligence -Le 2000 Bardo Tunisie
2 - Institut Supérieur de Transport et de la Logistique de Sousse -Sousse 4023 Tunisie
3 - Laboratoire de Génie Informatique et d'Automatique de l'Artois Université d'Artois 62400 Béthune France
4 - Institut Supérieur Informatique et Techniques de Communication de Sousse -Laboratoire Modeling of Automated Reasoning Systems -Hammam Sousse 4011 Tunisie","In this paper, we aim to find a solution that reduces the logistical activity costs by using new hybrid meta-heuristics. We develop, in this work, a genetic algorithm (GA) with a hybrid crossing operator. The operator considered is the Order Crossover (OX); we will test our hybrid algorithm in a Periodic Inventory Routing Problem (PIRP). Our study proves the performance of the hybrid operator OX compared with the classic GA, demonstrate the competitiveness of this innovative approach to solve the large-scale instances and bring a better quality of the solution.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-90.pdf,2018,100.0,"Order Crossover for the Inventory Routing Problem In this paper, we aim to find a solution that reduces the logistical activity costs by using new hybrid meta-heuristics. We develop, in this work, a genetic algorithm (GA) with a hybrid crossing operator. The operator considered is the Order Crossover (OX); we will test our hybrid algorithm in a Periodic Inventory Routing Problem (PIRP). Our study proves the performance of the hybrid operator OX compared with the classic GA, demonstrate the competitiveness of this innovative approach to solve the large-scale instances and bring a better quality of the solution."
Multi-omics data integration using cross-modal neural networks,"Ioana Bica, Petar Veličković, Hui Xiao, Pietro Liò",1 - Department of Computer Science and Technology University of Cambridge CB3 0FD Cambridge United Kingdom,"Successful integration of multi-omics data for prediction tasks can bring significant advantages to precision medicine and to understanding molecular systems. This paper introduces a novel neural network architecture for exploring and integrating modalities in omics datasets, especially in scenarios with a limited number of training examples available. The proposed cross-modal neural network achieves up to 99% accuracy on omics datasets. Moreover, we show how analysis of the weights and activations in the network can give us biological insights into understanding which genes are most relevant for the decision process and how different types of omics influence each other.",Deep Learning in Bioinformatics and Medicine,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-93.pdf,2018,100.0,"Multi-omics data integration using cross-modal neural networks Successful integration of multi-omics data for prediction tasks can bring significant advantages to precision medicine and to understanding molecular systems. This paper introduces a novel neural network architecture for exploring and integrating modalities in omics datasets, especially in scenarios with a limited number of training examples available. The proposed cross-modal neural network achieves up to 99% accuracy on omics datasets. Moreover, we show how analysis of the weights and activations in the network can give us biological insights into understanding which genes are most relevant for the decision process and how different types of omics influence each other."
Fast Power system security analysis with Guided Dropout,"Benjamin Donnot, Isabelle Guyon, Marc Schoenauer, Antoine Marot, Patrick Panciatici","1 - UPSud and Inria TAU Universit Ã c Paris-Saclay France
3 - ChaLearn Berkeley California † RTE France","We propose a new method to efficiently compute load-flows (the steady-state of the power-grid for given productions, consumptions and grid topology), substituting conventional simulators based on differential equation solvers. We use a deep feed-forward neural network trained with load-flows precomputed by simulation. Our architecture permits to train a network on so-called ""n-1"" problems, in which load flows are evaluated for every possible line disconnection, then generalize to ""n-2"" problems without re-training (a clear advantage because of the combinatorial nature of the problem). To that end, we developed a technique bearing similarity with ""dropout"", which we named ""guided dropout"". 
 Background and motivations Electricity is a commodity that consumers take for granted and, while governments relaying public opinion (rightfully) request that renewable energies be used increasingly, little is known about what this entails behind the scenes in additional complexity for Transmission Service Operators (TSOs) to operate the power transmission grid in security. Indeed, renewable energies such as wind and solar power are less predictable than conventional power sources (mainly thermal power plants). A power grid is considered to be operated in ""security"" (i.e. in a secure state) if it is outside a zone of ""constraints"", which includes that power flowing in every line does not exceed given limits. To that end, it is standard practice to operate the grid in real time with the so-called ""n-1"" criterion: this is a preventive measure requiring that at all times the grid would remain in a safe state even if one component (generators, lines, transformers, etc.) were disconnected. Today, the complex task of dispatchers, which are highly trained engineers, consists in analyzing situations and checking prospectively their effect using sophisticated (but slow) high-end simulators. As part of a larger project to assist TSOs in their daily operations [3], our goal in this paper is to emulate the power grid with a neural network to provide fast estimations of power flows in all lines given some ""injections"" (electricity productions and consumptions). 
 The guided dropout method Due to the combinatorial nature of changes in power grid topology, it is impractical (and slow) to train one neural network for each topology. Our idea",Regression and recommendation systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-94.pdf,2018,100.0,"Fast Power system security analysis with Guided Dropout We propose a new method to efficiently compute load-flows (the steady-state of the power-grid for given productions, consumptions and grid topology), substituting conventional simulators based on differential equation solvers. We use a deep feed-forward neural network trained with load-flows precomputed by simulation. Our architecture permits to train a network on so-called ""n-1"" problems, in which load flows are evaluated for every possible line disconnection, then generalize to ""n-2"" problems without re-training (a clear advantage because of the combinatorial nature of the problem). To that end, we developed a technique bearing similarity with ""dropout"", which we named ""guided dropout"". 
 Background and motivations Electricity is a commodity that consumers take for granted and, while governments relaying public opinion (rightfully) request that renewable energies be used increasingly, little is known about what this entails behind the scenes in additional complexity for Transmission Service Operators (TSOs) to operate the power transmission grid in security. Indeed, renewable energies such as wind and solar power are less predictable than conventional power sources (mainly thermal power plants). A power grid is considered to be operated in ""security"" (i.e. in a secure state) if it is outside a zone of ""constraints"", which includes that power flowing in every line does not exceed given limits. To that end, it is standard practice to operate the grid in real time with the so-called ""n-1"" criterion: this is a preventive measure requiring that at all times the grid would remain in a safe state even if one component (generators, lines, transformers, etc.) were disconnected. Today, the complex task of dispatchers, which are highly trained engineers, consists in analyzing situations and checking prospectively their effect using sophisticated (but slow) high-end simulators. As part of a larger project to assist TSOs in their daily operations [3], our goal in this paper is to emulate the power grid with a neural network to provide fast estimations of power flows in all lines given some ""injections"" (electricity productions and consumptions). 
 The guided dropout method Due to the combinatorial nature of changes in power grid topology, it is impractical (and slow) to train one neural network for each topology. Our idea"
An Analysis of Subtask-Dependency in Robot Command Interpretation with Dilated CNNs,"Manfred Eppe, Tayfun Alpay, Stefan Wermter",1 - Department of Informatics University of Hamburg Vogt-Koelln-Str. 30 22527 Hamburg Germany,"In this paper, we tackle sequence-to-tree transduction for language processing with neural networks implementing several subtasks, namely tokenization, semantic annotation, and tree generation. Our research question is how the individual subtasks influence the overall end-toend learning performance in case of a convolutional network with dilated perceptive fields. We investigate a benchmark problem for robot command interpretation and conclude that dilation has a strong positive effect for performing character-level transduction and for generating parsing trees.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-96.pdf,2018,78.3132530120482,"An Analysis of Subtask-Dependency in Robot Command Interpretation with Dilated CNNs In this paper, we tackle sequence-to-tree transduction for language processing with neural networks implementing several subtasks, namely tokenization, semantic annotation, and tree generation. Our research question is how the individual subtasks influence the overall end-toend learning performance in case of a convolutional network with dilated perceptive fields. We investigate a benchmark problem for robot command interpretation and conclude that dilation has a strong positive effect for performing character-level transduction and for generating parsing trees."
Reliable Patient Classification in Case of Uncertain Class Labels Using a Cross-Entropy Approach,"A Villmann, M Kaden, S Saralajew, W Hermann, T Villmann","1 - Dep. Mittweida Mittweida Berufliches Schulzentrum Döbeln-Mittweida Germany
2 - University of Applied Sciences Mittweida Saxony Institute for Comp. Intelligence and Machine Learning Mittweida Germany
3 - -Dr. Ing. h.c. F. Porsche AG Electrical/Electronics Driver Assistance Platform/Systems Weissach Germany
4 - Spital Langenthal -Neurologie SRO AG Langenthal Switzerland","Classification learning crucially depends on the correct label information in training data. We consider the problem that a respective uncertainty can neither be neglected nor it can be approximated by a statistical model. In the proposed approach each training data is equipped with a certainty value reflecting the probability of the label correctness. This information is used in the learning process for the classifier. For this purpose, we adopt the cross-entropy cost function from deep learning for a modified learning vector quantization model. We show the usefulness of this knowledge integration in medical diagnostic data analysis for detection of Wilson's disease as an example.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-97.pdf,2018,100.0,"Reliable Patient Classification in Case of Uncertain Class Labels Using a Cross-Entropy Approach Classification learning crucially depends on the correct label information in training data. We consider the problem that a respective uncertainty can neither be neglected nor it can be approximated by a statistical model. In the proposed approach each training data is equipped with a certainty value reflecting the probability of the label correctness. This information is used in the learning process for the classifier. For this purpose, we adopt the cross-entropy cost function from deep learning for a modified learning vector quantization model. We show the usefulness of this knowledge integration in medical diagnostic data analysis for detection of Wilson's disease as an example."
Systematics aware learning: a case study in High Energy Physics,"Victor Estrade, Cécile Germain, Isabelle Guyon, David Rousseau","1 - LAL LRI, TAO UPSud. 2. IN2P3
2 - Université Paris Saclay France",Experimental science often has to cope with systematic errors that coherently bias data. We analyze this issue on the analysis of data produced by experiments of the Large Hadron Collider at CERN as a case of supervised domain adaptation. Systematics-aware learning should create an efficient representation that is insensitive to perturbations induced by the systematic effects. We present an experimental comparison of the adversarial knowledge-free approach and a less data-intensive alternative.,Impact of Biases in Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-99.pdf,2018,67.71653543307087,Systematics aware learning: a case study in High Energy Physics Experimental science often has to cope with systematic errors that coherently bias data. We analyze this issue on the analysis of data produced by experiments of the Large Hadron Collider at CERN as a case of supervised domain adaptation. Systematics-aware learning should create an efficient representation that is insensitive to perturbations induced by the systematic effects. We present an experimental comparison of the adversarial knowledge-free approach and a less data-intensive alternative.
Systems with 'subjective feelings' -the perspective from weightless automata,"Igor Aleksander, Helen Morton",1 - Department of Electrical and Electronic Engineering Imperial College SW7 2PE London,"These are Christof Koch's [1] closing remarks at the 2001 Swartz Foundation workshop on Machine Consciousness, Cold Spring Harbour Laboratories: ""… we know of no fundamental law or principle operating in this universe that forbids the existence of subjective feelings in artefacts designed or evolved by humans."" This account is aimed at identifying a formal expression of the 'subjective feelings in artefacts' that Koch saw as being central to the definition of a conscious machine. It is useful to elaborate 'artefacts' as the set of systems that have a physically realizable character and an analytic description. The weightless character of the description dispels the notion that cognition and consciousness lurk within the weight values of a system.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-1.pdf,2019,95.42483660130719,"Systems with 'subjective feelings' -the perspective from weightless automata These are Christof Koch's [1] closing remarks at the 2001 Swartz Foundation workshop on Machine Consciousness, Cold Spring Harbour Laboratories: ""… we know of no fundamental law or principle operating in this universe that forbids the existence of subjective feelings in artefacts designed or evolved by humans."" This account is aimed at identifying a formal expression of the 'subjective feelings in artefacts' that Koch saw as being central to the definition of a conscious machine. It is useful to elaborate 'artefacts' as the set of systems that have a physically realizable character and an analytic description. The weightless character of the description dispels the notion that cognition and consciousness lurk within the weight values of a system."
Learning Super-resolution 3D Segmentation of Plant Root MRI Images from Few Examples,"Ali Oguz Uzman, Jannis Horn, Sven Behnke",1 - University of Bonn Computer Science Institute VI Autonomous Intelligent Systems Endenicher Allee 19a 53115 Bonn Germany,"Analyzing plant roots is crucial to understand plant performance in different soil environments. While magnetic resonance imaging (MRI) can be used to obtain 3D images of plant roots, extracting the root structural model is challenging due to highly noisy soil environments and low-resolution of MRI images. To improve both contrast and resolution, we adapt the state-of-the-art method RefineNet for 3D segmentation of the plant root MRI images in super-resolution. The networks are trained from few manual segmentations that are augmented by geometric transformations, realistic noise, and other variabilities. The resulting segmentations contain most root structures, including branches not extracted by the human annotator.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-127.pdf,2019,76.62337662337663,"Learning Super-resolution 3D Segmentation of Plant Root MRI Images from Few Examples Analyzing plant roots is crucial to understand plant performance in different soil environments. While magnetic resonance imaging (MRI) can be used to obtain 3D images of plant roots, extracting the root structural model is challenging due to highly noisy soil environments and low-resolution of MRI images. To improve both contrast and resolution, we adapt the state-of-the-art method RefineNet for 3D segmentation of the plant root MRI images in super-resolution. The networks are trained from few manual segmentations that are augmented by geometric transformations, realistic noise, and other variabilities. The resulting segmentations contain most root structures, including branches not extracted by the human annotator."
Lightweight autonomous bayesian optimization of Echo-State Networks,"Luca Cerina, Giuseppe Franco, Marco Santambrogio","1 - Politecnico di Milano -Dip. di Elettronica, Informatica e Bioingegneria Piazza Leonardo da Vinci Milano Italy
2 - Scuola Superiore Sant'Anna & Università di Pisa Pisa","Echo State Networks (ESN) represent a good option to tackle non-linear, time-dependent problems without the training complexity of standard Recurrent Neural Networks (RNNs), thanks to intrinsic dynamics that arise from untrained sparse networks. However, performance and stability of ESN are determined by their hyper-parameters, e.g. Reservoir dimension and sparsity, and the characteristics of the input, whose optimal values required time consuming procedures to be found. Here we propose an efficient automatic optimization framework for ESN based on the Bayesian Optimization given user-defined objectives, and bounded ranges on hyper-parameters. Results shown performance comparable with exhaustive grid-search optimization algorithms.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-103.pdf,2019,82.08955223880598,"Lightweight autonomous bayesian optimization of Echo-State Networks Echo State Networks (ESN) represent a good option to tackle non-linear, time-dependent problems without the training complexity of standard Recurrent Neural Networks (RNNs), thanks to intrinsic dynamics that arise from untrained sparse networks. However, performance and stability of ESN are determined by their hyper-parameters, e.g. Reservoir dimension and sparsity, and the characteristics of the input, whose optimal values required time consuming procedures to be found. Here we propose an efficient automatic optimization framework for ESN based on the Bayesian Optimization given user-defined objectives, and bounded ranges on hyper-parameters. Results shown performance comparable with exhaustive grid-search optimization algorithms."
Online Bayesian Shrinkage Regression,"Waqas Jamil, Abdelhamid Bouchachia",1 - Department of Computing and Informatics -Machine Intelligence Group Bournemouth University -Poole UK,"The present work introduces a new online regression method that extends the Shrinkage via Limit of Gibbs sampler (SLOG) in the context of online learning. In particular, we theoretically demonstrate that the proposed Online SLOG (OSLOG) is derived using the Bayesian framework without resorting to the Gibbs sampler. We also state the performance guarantee of OSLOG.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-105.pdf,2019,100.0,"Online Bayesian Shrinkage Regression The present work introduces a new online regression method that extends the Shrinkage via Limit of Gibbs sampler (SLOG) in the context of online learning. In particular, we theoretically demonstrate that the proposed Online SLOG (OSLOG) is derived using the Bayesian framework without resorting to the Gibbs sampler. We also state the performance guarantee of OSLOG."
Graph generation by sequential edge prediction,"Davide Bacciu, Alessio Micheli, Marco Podda",1 - Dept. of Computer Science University of Pisa Largo Bruno Pontecorvo 3 Pisa Italy,"Graph generation with Machine Learning models is a challenging problem with applications in various research fields. Here, we propose a recurrent Deep Learning based model to generate graphs by learning to predict their ordered edge sequence. Despite its simplicity, our experiments on a wide range of datasets show that our approach is able to generate graphs originating from very different distributions, outperforming canonical graph generative models from graph theory, and reaching performances comparable to the current state of the art on graph generation.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-107.pdf,2019,100.0,"Graph generation by sequential edge prediction Graph generation with Machine Learning models is a challenging problem with applications in various research fields. Here, we propose a recurrent Deep Learning based model to generate graphs by learning to predict their ordered edge sequence. Despite its simplicity, our experiments on a wide range of datasets show that our approach is able to generate graphs originating from very different distributions, outperforming canonical graph generative models from graph theory, and reaching performances comparable to the current state of the art on graph generation."
Prediction of Palm Oil Production with an Enhanced n-Tuple Regression Network,"Leopoldo Lusquino Filho, Luiz Oliveira, Aluizio Filho, Gabriel Guarisa, Priscila Lima, Felipe França","1 - PESC COPPE
5 - NCE Universidade Federal do Rio de Janeiro RJ Brazil","This paper introduces Regression WiSARD and ClusRegression WiSARD, two new weightless neural network models that were applied in the challenging task of predicting the total palm oil production of a set of 28 differently located sites under different climate and soil profiles. Both models were derived from the n-tuple regression weightless neural model and obtained error (MAE) rates of 0.08737% and 0.08938%, respectively, which are very competitive with the state-of-art (0.07569), whilst being four (4) orders of magnitude faster during the training phase.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-108.pdf,2019,62.33766233766234,"Prediction of Palm Oil Production with an Enhanced n-Tuple Regression Network This paper introduces Regression WiSARD and ClusRegression WiSARD, two new weightless neural network models that were applied in the challenging task of predicting the total palm oil production of a set of 28 differently located sites under different climate and soil profiles. Both models were derived from the n-tuple regression weightless neural model and obtained error (MAE) rates of 0.08737% and 0.08938%, respectively, which are very competitive with the state-of-art (0.07569), whilst being four (4) orders of magnitude faster during the training phase."
Feature and Algorithm Selection for Capacitated Vehicle Routing Problems,"Jussi Rasku, Nysret Musliu, Tommi Kärkkäinen","1 - Faculty of Information Technology University of Jyvaskyla FI-40014 Jyvaskyla Finland
2 - -CD-Lab Artis Institute of Logic and Computation, TU Wien A-1040 Vienna Austria","Many exact, heuristic, and metaheuristic algorithms have been proposed to effectively produce high quality solutions to vehicle routing problems. However, it remains an open question which algorithm is the most appropriate for solving a given problem instance, mostly because the different strengths and weaknesses of algorithms are still not well understood. We propose an extensive feature set for describing capacitated vehicle routing problem instances and illustrate how it can be used in algorithm selection, and how different feature selection approaches can be used to recognize the most relevant features for this task.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-110.pdf,2019,100.0,"Feature and Algorithm Selection for Capacitated Vehicle Routing Problems Many exact, heuristic, and metaheuristic algorithms have been proposed to effectively produce high quality solutions to vehicle routing problems. However, it remains an open question which algorithm is the most appropriate for solving a given problem instance, mostly because the different strengths and weaknesses of algorithms are still not well understood. We propose an extensive feature set for describing capacitated vehicle routing problem instances and illustrate how it can be used in algorithm selection, and how different feature selection approaches can be used to recognize the most relevant features for this task."
Topic-based Historical Information Selection for Personalized Sentiment Analysis,"Siwen Guo, Sviatlana Höhn, Christoph Schommer","1 - University of Luxembourg -CSC ILIAS Research Lab 6, Avenue de la Fonte L-4364 Esch-sur-Alzette -Luxembourg","In this paper, we present a selection approach designed for personalized sentiment analysis with the aim of extracting related information from a user's history. Analyzing a person's past is key to modeling individuality and understanding the current state of the person. We consider a user's expressions in the past as historical information, and target posts from social platforms for which Twitter texts are chosen as exemplary. While implementing the personalized model PERSEUS, we observed information loss due to the lack of flexibility regarding the design of the input sequence. To compensate this issue, we provide a procedure for information selection based on the similarities in the topics of a user's historical posts. Evaluation is conducted comparing different similarity measures, and improvements are seen with the proposed method.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-112.pdf,2019,72.5,"Topic-based Historical Information Selection for Personalized Sentiment Analysis In this paper, we present a selection approach designed for personalized sentiment analysis with the aim of extracting related information from a user's history. Analyzing a person's past is key to modeling individuality and understanding the current state of the person. We consider a user's expressions in the past as historical information, and target posts from social platforms for which Twitter texts are chosen as exemplary. While implementing the personalized model PERSEUS, we observed information loss due to the lack of flexibility regarding the design of the input sequence. To compensate this issue, we provide a procedure for information selection based on the similarities in the topics of a user's historical posts. Evaluation is conducted comparing different similarity measures, and improvements are seen with the proposed method."
Learning Rich Event Representations and Interactions for Temporal Relation Classification,"Onkar Pandit, Pascal Denis, Liva Ralaivola","1 - QARMA IUF, LIS Aix-Marseille University CNRS Marseille France
2 - Criteo AI Labs Paris France
3 - Inria Lille -Nord Europe 1-MAGNET Villeneuve d'Ascq France","Most existing systems for identifying temporal relations between events heavily rely on hand-crafted features derived from event words and explicit temporal markers. Besides, less attention has been given to automatically learning contextualized event representations or to finding complex interactions between events. This paper fills this gap in showing that a combination of rich event representations and interaction learning is essential to more accurate temporal relation classification. Specifically, we propose a method in which i) Recurrent Neural Networks (RNN) extract contextual information ii) character embeddings capture morphosemantic features (e.g. tense, mood, aspect), and iii) a deep Convolutional Neural Network (CNN) finds out intricate interactions between events. We show that the proposed approach outperforms most existing systems on the commonly used dataset while using fully automatic feature extraction and simple local inference.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-113.pdf,2019,100.0,"Learning Rich Event Representations and Interactions for Temporal Relation Classification Most existing systems for identifying temporal relations between events heavily rely on hand-crafted features derived from event words and explicit temporal markers. Besides, less attention has been given to automatically learning contextualized event representations or to finding complex interactions between events. This paper fills this gap in showing that a combination of rich event representations and interaction learning is essential to more accurate temporal relation classification. Specifically, we propose a method in which i) Recurrent Neural Networks (RNN) extract contextual information ii) character embeddings capture morphosemantic features (e.g. tense, mood, aspect), and iii) a deep Convolutional Neural Network (CNN) finds out intricate interactions between events. We show that the proposed approach outperforms most existing systems on the commonly used dataset while using fully automatic feature extraction and simple local inference."
Adversarial Robustness of Linear Models: Regularization and Dimensionality,"István Megyeri, István Hegedűs, Márk Jelasity","1 - University of Szeged Hungary
4 - -MTA-SZTE Research Group on Artificial Intelligence Hungary","Many machine learning models are sensitive to adversarial input, meaning that very small but carefully designed noise added to correctly classified examples may lead to misclassification. The reasons for this are still poorly understood, even in the simple case of linear models. Here, we study linear models and offer a number of novel insights. We focus on the effect of regularization and dimensionality. We show that in very high dimensions adversarial robustness is inherently very low due to some mathematical properties of high-dimensional spaces that have received little attention so far. We also demonstrate that-although regularization may help-adversarial robustness is harder to achieve than high accuracy during the learning process. This is typically overlooked when researchers set optimization meta-parameters.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-114.pdf,2019,83.78378378378379,"Adversarial Robustness of Linear Models: Regularization and Dimensionality Many machine learning models are sensitive to adversarial input, meaning that very small but carefully designed noise added to correctly classified examples may lead to misclassification. The reasons for this are still poorly understood, even in the simple case of linear models. Here, we study linear models and offer a number of novel insights. We focus on the effect of regularization and dimensionality. We show that in very high dimensions adversarial robustness is inherently very low due to some mathematical properties of high-dimensional spaces that have received little attention so far. We also demonstrate that-although regularization may help-adversarial robustness is harder to achieve than high accuracy during the learning process. This is typically overlooked when researchers set optimization meta-parameters."
Progress Towards Graph Optimization: Efficient Learning of Vector to Graph Space Mappings,"Stefan Mautner, Rolf Backofen, Fabrizio Costa","1 - Department of Computer Science Albert-Ludwigs-University Freiburg Georges-Koehler-Allee 106 -79110 Freiburg Germany
3 - Department of Computer Science University of Exeter EX4 4QF Exeter United Kingdom","Optimization in vector space domains is well understood. However, in high dimensional settings or when dealing with structured data such as sequences and graphs, optimization becomes difficult. A possible strategy is to map graphs to vector codes and use machine learning to learn a map from codes back to graphs. This in turn allows to employ standard optimization techniques over vectors to optimize graphs. Here we propose an approach to invert a vector mapping based on a combination of graph kernels and graph grammars. We evaluate the proposed approach in an artificial setup and on real molecular graphs.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-115.pdf,2019,100.0,"Progress Towards Graph Optimization: Efficient Learning of Vector to Graph Space Mappings Optimization in vector space domains is well understood. However, in high dimensional settings or when dealing with structured data such as sequences and graphs, optimization becomes difficult. A possible strategy is to map graphs to vector codes and use machine learning to learn a map from codes back to graphs. This in turn allows to employ standard optimization techniques over vectors to optimize graphs. Here we propose an approach to invert a vector mapping based on a combination of graph kernels and graph grammars. We evaluate the proposed approach in an artificial setup and on real molecular graphs."
Class-aware t-SNE: cat-SNE,"Cyril De Bodt, Dounia Mulders, Daniel López-Sánchez, Michel Verleysen, John Lee","1 - Université catholique de Louvain -ICTEAM Place du Levant L5.03.02, 1348 Louvain-la-Neuve Belgium
3 - Universidad de Salamanca -BISITE Research Group C/ Espejo S/N 37007 Salamanca Spain
5 - Université catholique de Louvain -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels -Belgium","Stochastic Neighbor Embedding (SNE) and variants like t-distributed SNE are popular methods of unsupervised dimensionality reduction (DR) that deliver outstanding experimental results. Regular t-SNE is often used to visualize data with class labels in colored scatterplots, even if those labels are actually not involved in the DR process. This paper proposes a modification of t-SNE that employs class labels to adjust the widths of the Gaussian neighborhoods around each datum, instead of deriving those from a perplexity set by the user. The widths are fixed to concentrate a major fraction of the probability distribution around a datum on neighbors with the same class. This tends to shrink the bulk of the classes and to stretch their low-dimensional separation. Experimental results show that the proposed class-aware t-SNE (cat-SNE) outperforms regular t-SNE in KNN classification tasks carried out in the embedding.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-117.pdf,2019,100.0,"Class-aware t-SNE: cat-SNE Stochastic Neighbor Embedding (SNE) and variants like t-distributed SNE are popular methods of unsupervised dimensionality reduction (DR) that deliver outstanding experimental results. Regular t-SNE is often used to visualize data with class labels in colored scatterplots, even if those labels are actually not involved in the DR process. This paper proposes a modification of t-SNE that employs class labels to adjust the widths of the Gaussian neighborhoods around each datum, instead of deriving those from a perplexity set by the user. The widths are fixed to concentrate a major fraction of the probability distribution around a datum on neighbors with the same class. This tends to shrink the bulk of the classes and to stretch their low-dimensional separation. Experimental results show that the proposed class-aware t-SNE (cat-SNE) outperforms regular t-SNE in KNN classification tasks carried out in the embedding."
Beyond Pham's algorithm for joint diagonalization,"Pierre Ablin, Jean-François Cardoso, Alexandre Gramfort","1 - INRIA -Parietal team 1 Rue Honoré d'Estienne d'Orves 91120 Palaiseau France
2 - CNRS -Institut d'Astrophysique de Paris 98bis boulevard Arago 75014 Paris France","The approximate joint diagonalization of a set of matrices consists in finding a basis in which these matrices are as diagonal as possible. This problem naturally appears in several statistical learning tasks such as blind signal separation. We consider the diagonalization criterion studied in a seminal paper by Pham (  2001 ), and propose a new quasi-Newton method for its optimization. Through numerical experiments on simulated and real datasets, we show that the proposed method outperforms Pham's algorithm. An open source Python package is released.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-119.pdf,2019,100.0,"Beyond Pham's algorithm for joint diagonalization The approximate joint diagonalization of a set of matrices consists in finding a basis in which these matrices are as diagonal as possible. This problem naturally appears in several statistical learning tasks such as blind signal separation. We consider the diagonalization criterion studied in a seminal paper by Pham (  2001 ), and propose a new quasi-Newton method for its optimization. Through numerical experiments on simulated and real datasets, we show that the proposed method outperforms Pham's algorithm. An open source Python package is released."
Detecting Adversarial Examples through Nonlinear Dimensionality Reduction,"Francesco Crecchi, Davide Bacciu, Battista Biggio","1 - Dipartimento di Informatica Largo Bruno Pontecorvo Universitá di Pisa 56127 Pisa Italy
3 - Universitá degli Studi di Cagliari -Dip. di Ingegneria Elettrica ed Elettronica Via Marengo 09123 Cagliari Italy","Deep neural networks are vulnerable to adversarial examples, i.e., carefully-perturbed inputs aimed to mislead classification. This work proposes a detection method based on combining non-linear dimensionality reduction and density estimation techniques. Our empirical findings show that the proposed approach is able to effectively detect adversarial examples crafted by non-adaptive attackers, i.e., not specifically tuned to bypass the detection method. Given our promising results, we plan to extend our analysis to adaptive attackers in future work.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-120.pdf,2019,93.58974358974359,"Detecting Adversarial Examples through Nonlinear Dimensionality Reduction Deep neural networks are vulnerable to adversarial examples, i.e., carefully-perturbed inputs aimed to mislead classification. This work proposes a detection method based on combining non-linear dimensionality reduction and density estimation techniques. Our empirical findings show that the proposed approach is able to effectively detect adversarial examples crafted by non-adaptive attackers, i.e., not specifically tuned to bypass the detection method. Given our promising results, we plan to extend our analysis to adaptive attackers in future work."
Detecting Ghostwriters in High Schools,"Magnus Stavngaard, August Sørensen, Stephan Lorenzen, Niklas Hjuler, Stephen Alstrup","1 - Department of Computer Science University of Copenhagen
2 - Universitetsparken 3 Copenhagen Denmark","Students hiring ghostwriters to write their assignments is an increasing problem in educational institutions all over the world, with companies selling these services as a product. In this work, we develop automatic techniques with special focus on detecting such ghostwriting in high school assignments. This is done by training deep neural networks on an unprecedented large amount of data supplied by the Danish company MaCom, which covers 90% of Danish high schools. We achieve an accuracy of 0.875 and a AUC score of 0.947 on an evenly split data set.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-121.pdf,2019,100.0,"Detecting Ghostwriters in High Schools Students hiring ghostwriters to write their assignments is an increasing problem in educational institutions all over the world, with companies selling these services as a product. In this work, we develop automatic techniques with special focus on detecting such ghostwriting in high school assignments. This is done by training deep neural networks on an unprecedented large amount of data supplied by the Danish company MaCom, which covers 90% of Danish high schools. We achieve an accuracy of 0.875 and a AUC score of 0.947 on an evenly split data set."
Transfer Learning for transferring machine-learning based models among various hyperspectral sensors,Patrick Menz,1 - Andreas Backhaus and Udo Seiffert Biosystems Engineering Fraunhofer Institute of Factory Operation and Automation (IFF) Magdeburg Germany,Using previously generated machine learning models under changing sensor hardware with nearly the same performance is a desirable goal. This constitutes a model transfer problem. We compare a Radial Basis Function Network adapted for transfer learning to a classical data alignment approach. This approach to transfer machine-learning models is tested on a task of material classification using hyperspectral imaging recorded with different camera systems and the aim to make camera systems interchangeable. The results show that a machine-learning based algorithm outperforms a state-of-the-art hyperspectral data alignment algorithm.,Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-123.pdf,2019,95.83333333333334,Transfer Learning for transferring machine-learning based models among various hyperspectral sensors Using previously generated machine learning models under changing sensor hardware with nearly the same performance is a desirable goal. This constitutes a model transfer problem. We compare a Radial Basis Function Network adapted for transfer learning to a classical data alignment approach. This approach to transfer machine-learning models is tested on a task of material classification using hyperspectral imaging recorded with different camera systems and the aim to make camera systems interchangeable. The results show that a machine-learning based algorithm outperforms a state-of-the-art hyperspectral data alignment algorithm.
Explaining classification systems using sparse dictionaries,"A Apicella, F Isgrò, R Prevete, A Sorrentino, G Tamburrini",1 - Dipartimento di Ingegneria Elettrica e delle Teconologie dell'Informazione Università degli Studi di Napoli Federico II Italy,"A pressing research topic is to find ways to explain the decisions of machine learning systems to end users, data officers, and other stakeholders. These explanations must be understandable to human beings. Much work in this field focuses on image classification, as the required explanations can rely on images, therefore making communication relatively easy, and may take into account the image as a whole. Here, we propose to exploit the representational power of sparse dictionaries to determine image local properties that can be used as crucial ingredients of humanly understandable explanations of classification decisions.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-124.pdf,2019,100.0,"Explaining classification systems using sparse dictionaries A pressing research topic is to find ways to explain the decisions of machine learning systems to end users, data officers, and other stakeholders. These explanations must be understandable to human beings. Much work in this field focuses on image classification, as the required explanations can rely on images, therefore making communication relatively easy, and may take into account the image as a whole. Here, we propose to exploit the representational power of sparse dictionaries to determine image local properties that can be used as crucial ingredients of humanly understandable explanations of classification decisions."
Design of Power-Efficient FPGA Convolutional Cores with Approximate Log Multiplier,"Leonardo Oliveira, Min Kim, Alberto Barrio, Nader Bagherzadeh, Ricardo Menotti","1 - Universidade Federal de São Carlos -Departamento de Computação -Rod. Washington Luís Km 235 Brazil
2 - Irvine -Dept. of Electrical Engineering and Computer Science University of California 5200 Engineering Hall United States of America
3 - Complutense University of Madrid -Dept of Computer Architecture and System Engineering -Ciudad Universitaria Plaza Ciencias Spain","This paper presents the design of a convolutional core that utilizes an approximate log multiplier to significantly reduce the power consumption of FPGA acceleration of convolutional neural networks. The core also exploits FPGA reconfigurability as well as the parallelism and input sharing opportunities in convolutional layers to minimize the costs. The simulation results show reductions up to 78.19% of LUT usage and 60.54% of power consumption compared to the core that uses exact fixedpoint multiplier, while maintaining comparable accuracy on a subset of MNIST dataset.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-125.pdf,2019,100.0,"Design of Power-Efficient FPGA Convolutional Cores with Approximate Log Multiplier This paper presents the design of a convolutional core that utilizes an approximate log multiplier to significantly reduce the power consumption of FPGA acceleration of convolutional neural networks. The core also exploits FPGA reconfigurability as well as the parallelism and input sharing opportunities in convolutional layers to minimize the costs. The simulation results show reductions up to 78.19% of LUT usage and 60.54% of power consumption compared to the core that uses exact fixedpoint multiplier, while maintaining comparable accuracy on a subset of MNIST dataset."
Multiple-Kernel Dictionary Learning for Reconstruction and Clustering of Unseen Multivariate Time-series,"Babak Hosseini, Barbara Hammer",1 - CITEC cluster of excellence Bielefeld University Bielefeld Germany,"There exist many approaches for description and recognition of unseen classes in datasets. Nevertheless, it becomes a challenging problem when we deal with multivariate time-series (MTS) (e.g., motion data), where we cannot apply the vectorial algorithms directly to the inputs. In this work, we propose a novel multiple-kernel dictionary learning (MKD) which learns semantic attributes based on specific combinations of MTS dimensions in the feature space. Hence, MKD can fully/partially reconstructs the unseen classes based on the training data (seen classes). Furthermore, we obtain sparse encodings for unseen classes based on the learned MKD attributes, and upon which we propose a simple but effective incremental clustering algorithm to categorize the unseen MTS classes in an unsupervised way. According to the empirical evaluation of our MKD framework on real benchmarks, it provides an interpretable reconstruction of unseen MTS data as well as a high performance regarding their online clustering.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-126.pdf,2019,67.3076923076923,"Multiple-Kernel Dictionary Learning for Reconstruction and Clustering of Unseen Multivariate Time-series There exist many approaches for description and recognition of unseen classes in datasets. Nevertheless, it becomes a challenging problem when we deal with multivariate time-series (MTS) (e.g., motion data), where we cannot apply the vectorial algorithms directly to the inputs. In this work, we propose a novel multiple-kernel dictionary learning (MKD) which learns semantic attributes based on specific combinations of MTS dimensions in the feature space. Hence, MKD can fully/partially reconstructs the unseen classes based on the training data (seen classes). Furthermore, we obtain sparse encodings for unseen classes based on the learned MKD attributes, and upon which we propose a simple but effective incremental clustering algorithm to categorize the unseen MTS classes in an unsupervised way. According to the empirical evaluation of our MKD framework on real benchmarks, it provides an interpretable reconstruction of unseen MTS data as well as a high performance regarding their online clustering."
Training networks separately on static and dynamic obstacles improves collision avoidance during indoor robot navigation,"Viktor Schmuck, David Meredith",1 - Aalborg University Aalborg Denmark,"Autonomous robot navigation and dynamic obstacle avoidance in complex, cluttered, indoor environments is a challenging task. A robust solution would allow robots to be deployed in hospitals, airports or shopping centres to serve as guides and fulfil other functions requiring safe human-robot interaction. Previous studies have explored various approaches to selecting sensor types, collecting data, and training models capable of safely avoiding unmapped, possibly dynamic obstacles in an indoor environment. In this paper we address the problem of recognizing and anticipating collisions, in order to determine when avoidance manoeuvres are required. We propose and compare two sensor-fusion and neural-network-based solutions, one in which models are trained separately on static and dynamic samples and another in which a model is trained on samples of collisions with both dynamic and static obstacles. The measured accuracies confirmed that the separately trained, ensemble models had better recognition performance, but were slower at calculation than the models trained without taking the obstacle types into account.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-129.pdf,2019,92.5,"Training networks separately on static and dynamic obstacles improves collision avoidance during indoor robot navigation Autonomous robot navigation and dynamic obstacle avoidance in complex, cluttered, indoor environments is a challenging task. A robust solution would allow robots to be deployed in hospitals, airports or shopping centres to serve as guides and fulfil other functions requiring safe human-robot interaction. Previous studies have explored various approaches to selecting sensor types, collecting data, and training models capable of safely avoiding unmapped, possibly dynamic obstacles in an indoor environment. In this paper we address the problem of recognizing and anticipating collisions, in order to determine when avoidance manoeuvres are required. We propose and compare two sensor-fusion and neural-network-based solutions, one in which models are trained separately on static and dynamic samples and another in which a model is trained on samples of collisions with both dynamic and static obstacles. The measured accuracies confirmed that the separately trained, ensemble models had better recognition performance, but were slower at calculation than the models trained without taking the obstacle types into account."
Tensor factorization to extract patterns in multimodal EEG data,"Dounia Mulders, Cyril De Bodt, Nicolas Lejeune, John Lee, André Mouraux, Michel Verleysen","1 - ICTEAM institute Université catholique de Louvain Place du Levant 3 1348 Louvain-la-Neuve Belgium
2 - -IONS institute Université catholique de Louvain Avenue Mounier 53 1200 Woluwe-Saint-Lambert Belgium","Noisy multi-way data sets are ubiquitous in many domains. In neuroscience, electroencephalogram (EEG) data are recorded during periodic stimulation from different sensory modalities, leading to steady-state (SS) recordings with at least four ways: the channels, the time, the subjects and the modalities. Improving the signal-to-noise ratio (SNR) of the SS responses is crucial to enable their practical use. Supervised spatial filtering methods can be considered for this purpose to relevantly guide the extraction of specific activity patterns. Nevertheless, such approaches are difficult to validate with few subjects and can process at most two data ways simultaneously, the remaining ones being either averaged or considered independently despite their dependencies. This paper hence designs unsupervised tensor factorization models to enable identifying meaningful underlying structures characterized in all ways of multimodal SS data. We show on EEG recordings from 15 subjects that such factorizations faithfully reveal consistent spatial topographies, time courses with enhanced SNR and subject variations of the periodic brain activity.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-130.pdf,2019,100.0,"Tensor factorization to extract patterns in multimodal EEG data Noisy multi-way data sets are ubiquitous in many domains. In neuroscience, electroencephalogram (EEG) data are recorded during periodic stimulation from different sensory modalities, leading to steady-state (SS) recordings with at least four ways: the channels, the time, the subjects and the modalities. Improving the signal-to-noise ratio (SNR) of the SS responses is crucial to enable their practical use. Supervised spatial filtering methods can be considered for this purpose to relevantly guide the extraction of specific activity patterns. Nevertheless, such approaches are difficult to validate with few subjects and can process at most two data ways simultaneously, the remaining ones being either averaged or considered independently despite their dependencies. This paper hence designs unsupervised tensor factorization models to enable identifying meaningful underlying structures characterized in all ways of multimodal SS data. We show on EEG recordings from 15 subjects that such factorizations faithfully reveal consistent spatial topographies, time courses with enhanced SNR and subject variations of the periodic brain activity."
DropConnect for Evaluation of Classification Stability in Learning Vector Quantization,"J Ravichandran, S Saralajew, T Villmann","1 - Univ. of Appl. Sciences Mittweida
2 - Saxony Institute for Comp. Intelligence and Machine Learning Computational Intelligence Research Group Mittweida 2-Dr. Ing. h.c. F. Porsche AG -Driver Assistance Systems Weissach Germany, Germany","In this paper we consider DropOut/DropConnect techniques known from deep neural networks to evaluate the stability of learning vector quantization classifiers (LVQ). For this purpose, we consider the LVQ as a multilayer network and transfer the respective concepts to LVQ. Particularly, we consider the output as a stochastic ensemble such that an information theoretic measure is obtained to judge the stability level.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-131.pdf,2019,100.0,"DropConnect for Evaluation of Classification Stability in Learning Vector Quantization In this paper we consider DropOut/DropConnect techniques known from deep neural networks to evaluate the stability of learning vector quantization classifiers (LVQ). For this purpose, we consider the LVQ as a multilayer network and transfer the respective concepts to LVQ. Particularly, we consider the output as a stochastic ensemble such that an information theoretic measure is obtained to judge the stability level."
Preconditioned Conjugate Gradient Algorithms for Graph Regularized Matrix Completion,"Shuyu Dong, P.-A Absil, Kyle Gallivan","1 - Department of Mathematics 208 Love Building Florida State University 1017 Academic Way 32306-4510 Tallahassee FL USA
2 - ICTEAM Institute Avenue Georges Lemaître 1-UCLouvain
3 - L4.05.01, 1348 Louvain-la-Neuve Belgium","Low-rank matrix completion is the problem of recovering the missing entries of a data matrix by using the assumption that a good low-rank approximation to the true matrix is possible. Much attention has been paid recently to exploiting correlations between the column/row entities through side information to improve the matrix completion quality. In this paper, we propose an efficient algorithm for solving the low-rank matrix completion with graph-based regularizers. Experiments on synthetic data show that our approach achieves significant speedup compared to the alternating minimization scheme.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-133.pdf,2019,70.23809523809523,"Preconditioned Conjugate Gradient Algorithms for Graph Regularized Matrix Completion Low-rank matrix completion is the problem of recovering the missing entries of a data matrix by using the assumption that a good low-rank approximation to the true matrix is possible. Much attention has been paid recently to exploiting correlations between the column/row entities through side information to improve the matrix completion quality. In this paper, we propose an efficient algorithm for solving the low-rank matrix completion with graph-based regularizers. Experiments on synthetic data show that our approach achieves significant speedup compared to the alternating minimization scheme."
Dynamic fairness -Breaking vicious cycles in automatic decision making,"Benjamin Paaßen, Astrid Bunge, Carolin Hainke, Leon Sindelar, Matthias Vogelsang",1 - Bielefeld University -CITEC Inspiration 1 33619 Bielefeld Germany,"In recent years, machine learning techniques have been increasingly applied in sensitive decision making processes, raising fairness concerns. Past research has shown that machine learning may reproduce and even exacerbate human bias due to biased training data or flawed model assumptions, and thus may lead to discriminatory actions. To counteract such biased models, researchers have proposed multiple mathematical definitions of fairness according to which classifiers can be optimized. However, it has also been shown that the outcomes generated by some fairness notions may be unsatisfactory. In this contribution, we add to this research by considering decision making processes in time. We establish a theoretic model in which even perfectly accurate classifiers which adhere to almost all common fairness definitions lead to stable long-term inequalities due to vicious cycles. Only demographic parity, which enforces equal rates of positive decisions across groups, avoids these effects and establishes a virtuous cycle, which leads to perfectly accurate and fair classification in the long term. * Funding by the CITEC center of excellence (EXC 277) is gratefully acknowledged.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-134.pdf,2019,99.29078014184397,"Dynamic fairness -Breaking vicious cycles in automatic decision making In recent years, machine learning techniques have been increasingly applied in sensitive decision making processes, raising fairness concerns. Past research has shown that machine learning may reproduce and even exacerbate human bias due to biased training data or flawed model assumptions, and thus may lead to discriminatory actions. To counteract such biased models, researchers have proposed multiple mathematical definitions of fairness according to which classifiers can be optimized. However, it has also been shown that the outcomes generated by some fairness notions may be unsatisfactory. In this contribution, we add to this research by considering decision making processes in time. We establish a theoretic model in which even perfectly accurate classifiers which adhere to almost all common fairness definitions lead to stable long-term inequalities due to vicious cycles. Only demographic parity, which enforces equal rates of positive decisions across groups, avoids these effects and establishes a virtuous cycle, which leads to perfectly accurate and fair classification in the long term. * Funding by the CITEC center of excellence (EXC 277) is gratefully acknowledged."
Fusing Features based on Signal Properties and TimeNet for Time Series Classification,"Arijit Ukil, Pankaj Malhotra, Soma Bandyopadhyay, Tulika Bose, Ishan Sahu, Ayan Mukherjee, Lovekesh Vig, Arpan Pal, Gautam Shroff",Unknown,"Automated feature extraction from time series to capture statistical, temporal, spectral, and morphololgical properties is highly desirable but challenging due to diverse nature of real-world time series applications. In this paper, we consider extracting a rich and robust set of time series features encompassing signal processing based features as well as generic hierarchical features extracted via deep neural networks. We present SPGF-TimeNet: a generic feature extractor for time series that allows fusion of signal processing, information-theoretic, and statistical features (Signal Properties based Generic Features (SPGF )) with features from an off-the-shelf pre-trained deep recurrent neural network (TimeNet). Through empirical evalution on diverse benchmark datasets from the UCR Time Series Classification (TSC) Archive, we show that classifiers trained on SPGF-TimeNet-based hybrid and generic features outperform state-of-the-art TSC algorithms such as BOSS, while being computationally efficient.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-135.pdf,2019,100.0,"Fusing Features based on Signal Properties and TimeNet for Time Series Classification Automated feature extraction from time series to capture statistical, temporal, spectral, and morphololgical properties is highly desirable but challenging due to diverse nature of real-world time series applications. In this paper, we consider extracting a rich and robust set of time series features encompassing signal processing based features as well as generic hierarchical features extracted via deep neural networks. We present SPGF-TimeNet: a generic feature extractor for time series that allows fusion of signal processing, information-theoretic, and statistical features (Signal Properties based Generic Features (SPGF )) with features from an off-the-shelf pre-trained deep recurrent neural network (TimeNet). Through empirical evalution on diverse benchmark datasets from the UCR Time Series Classification (TSC) Archive, we show that classifiers trained on SPGF-TimeNet-based hybrid and generic features outperform state-of-the-art TSC algorithms such as BOSS, while being computationally efficient."
On the Definition of Complex Structured Feature Spaces,"Nicolò Navarin, Dinh Tran, Alessandro Sperduti","1 - Department of Mathematics Via Trieste 63 University of Padova 35121 Padova Italy
2 - Department of Computer Science University of Freiburg Georges-Köhler-Allee 106 79110 Freiburg Germany","In this paper, we propose a graph kernel whose feature space is defined by combining pairs of features of an existing base graph kernel. Furthermore, we propose a variation where the feature space is adaptive with respect to the learning task at hand, allowing to learn a representation suited to it. Experimental results on six real-world graph datasets from different domains show that the proposed kernels are able to get a consistent performance improvement over the considered base kernel, and over previously defined feature combination methods in literature.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-137.pdf,2019,81.4814814814815,"On the Definition of Complex Structured Feature Spaces In this paper, we propose a graph kernel whose feature space is defined by combining pairs of features of an existing base graph kernel. Furthermore, we propose a variation where the feature space is adaptive with respect to the learning task at hand, allowing to learn a representation suited to it. Experimental results on six real-world graph datasets from different domains show that the proposed kernels are able to get a consistent performance improvement over the considered base kernel, and over previously defined feature combination methods in literature."
Nonnegative matrix factorization with polynomial signals via hierarchical alternating least squares,"Cécile Hautecoeur, François Glineur",1 - Université catholique de Louvain -CORE ICTEAM Institute B-1348 Louvain-la-Neuve Belgium,"Nonnegative matrix factorization (NMF) is a widely used tool in data analysis due to its ability to extract significant features from data vectors. Among algorithms developed to solve NMF, hierarchical alternating least squares (HALS) is often used to obtain state-of-the-art results. We generalize HALS to tackle an NMF problem where both input data and features consist of nonnegative polynomial signals. Compared to standard HALS applied to a discretization of the problem, our algorithm is able to recover smoother features, with a computational time growing moderately with the number of observations compared to existing approaches.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-140.pdf,2019,100.0,"Nonnegative matrix factorization with polynomial signals via hierarchical alternating least squares Nonnegative matrix factorization (NMF) is a widely used tool in data analysis due to its ability to extract significant features from data vectors. Among algorithms developed to solve NMF, hierarchical alternating least squares (HALS) is often used to obtain state-of-the-art results. We generalize HALS to tackle an NMF problem where both input data and features consist of nonnegative polynomial signals. Compared to standard HALS applied to a discretization of the problem, our algorithm is able to recover smoother features, with a computational time growing moderately with the number of observations compared to existing approaches."
Very Simple Classifier: a Concept Binary Classifier to Investigate Features Based on Subsampling and Locality,"Luca Masera, Enrico Blanzieri",1 - University of Trento Italy,We propose Very Simple Classifier (VSC) a novel method designed to incorporate the concepts of subsampling and locality in the definition of features to be used as the input of a perceptron. The rationale is that locality theoretically guarantees a bound on the generalization error. Each feature in VSC is a max-margin classifier built on randomly-selected pairs of samples. The locality in VSC is achieved by multiplying the value of the feature by a confidence measure that can be characterized in terms of the Chebichev inequality. The output of the layer is then fed in a output layer of neurons. The weights of the output layer are then determined by a regularized pseudoinverse. Extensive comparison of VSC against 9 competitors in the task of binary classification is carried out. Results on 22 benchmark datasets with fixed parameters show that VSC is competitive with the Multi Layer Perceptron (MLP) and outperforms the other competitors. An exploration of the parameter space shows VSC can outperform MLP.,Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-141.pdf,2019,65.13761467889908,Very Simple Classifier: a Concept Binary Classifier to Investigate Features Based on Subsampling and Locality We propose Very Simple Classifier (VSC) a novel method designed to incorporate the concepts of subsampling and locality in the definition of features to be used as the input of a perceptron. The rationale is that locality theoretically guarantees a bound on the generalization error. Each feature in VSC is a max-margin classifier built on randomly-selected pairs of samples. The locality in VSC is achieved by multiplying the value of the feature by a confidence measure that can be characterized in terms of the Chebichev inequality. The output of the layer is then fed in a output layer of neurons. The weights of the output layer are then determined by a regularized pseudoinverse. Extensive comparison of VSC against 9 competitors in the task of binary classification is carried out. Results on 22 benchmark datasets with fixed parameters show that VSC is competitive with the Multi Layer Perceptron (MLP) and outperforms the other competitors. An exploration of the parameter space shows VSC can outperform MLP.
Committees as Artificial Organisms -Evolution and Adaptation,Roberto Alamino,1 - Aston University -Mathematics Birmingham UK,Generalised committee machines are here proposed to model the interaction of the DNA of a simplified artificial organism with its environment and shown to induce a unique genotype-phenotype map. An application to organisms being subjected to a toxic environment is shown to allow for a generalised form of antagonistic pleiotropy. The same scenario is studied in order to show the difference in adaptation in the presence of a fitness cost given by a lower reproduction rate.,Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-142.pdf,2019,84.29752066115702,Committees as Artificial Organisms -Evolution and Adaptation Generalised committee machines are here proposed to model the interaction of the DNA of a simplified artificial organism with its environment and shown to induce a unique genotype-phenotype map. An application to organisms being subjected to a toxic environment is shown to allow for a generalised form of antagonistic pleiotropy. The same scenario is studied in order to show the difference in adaptation in the presence of a fitness cost given by a lower reproduction rate.
Bridging face and sound modalities through Domain Adaptation Metric Learning,"Christos Athanasiadis, Enrique Hortal, Stylianos Asteriadis",1 - Department of Data Science and Knowledge Engineering Maastricht University the Netherlands,"Robust emotion recognition systems require extensive training by employing huge number of training samples with purpose of generating sophisticated models. Furthermore, research is mostly focused on facial expression recognition due, mainly to, the wide availability of related datasets. However, the existence of rich and publicly available datasets is not the case for other modalities like sound and so forth. In this work, a heterogeneous domain adaptation framework is introduced for bridging two inherently different domains (namely face and audio). The purpose is to perform affect recognition on the modality where only a small amount of data is available, leveraging large amounts of data from another modality. * This work was totally supported by the Horizon 2020 funded project MaTHiSiS (Managing Affective-learning THrough Intelligent atoms and Smart InteractionS) nr. 687772 (http://www.mathisis-project.eu/).",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-143.pdf,2019,73.6842105263158,"Bridging face and sound modalities through Domain Adaptation Metric Learning Robust emotion recognition systems require extensive training by employing huge number of training samples with purpose of generating sophisticated models. Furthermore, research is mostly focused on facial expression recognition due, mainly to, the wide availability of related datasets. However, the existence of rich and publicly available datasets is not the case for other modalities like sound and so forth. In this work, a heterogeneous domain adaptation framework is introduced for bridging two inherently different domains (namely face and audio). The purpose is to perform affect recognition on the modality where only a small amount of data is available, leveraging large amounts of data from another modality. * This work was totally supported by the Horizon 2020 funded project MaTHiSiS (Managing Affective-learning THrough Intelligent atoms and Smart InteractionS) nr. 687772 (http://www.mathisis-project.eu/)."
Improving Pedestrian Recognition using Incremental Cross Modality Deep Learning,"Dȃnut ¸ovidiu Pop, Alexandrina Rogozan, Fawzi Nashashibi, Abdelaziz Bensrhair","1 - INRIA Paris -RITS Team Paris France
2 - Normandie Univ -INSA Rouen LITIS Rouen -France
3 - Department of Computer Science Babeş-Bolyai University
4 - Cluj-Napoca Romania","Late fusion schemes with deep learning classification patterns set up with multi-modality images have an essential role in pedestrian protection systems since they have achieved prominent results in the pedestrian recognition task. In this paper, the late fusion scheme merged with Convolutional Neural Networks (CNN) is investigated for pedestrian recognition based on the Daimler stereo vision data sets. An independent CNN-based classifier for each imaging modality (Intensity, Depth, and Optical Flow) is handled before the fusion of its probabilistic output scores with a Multi-Layer Perceptron which provides the recognition decision. In this paper, we set out to prove that the incremental cross-modality deep learning approach enhances pedestrian recognition performances. It also outperforms state-of-the-art pedestrian classifiers on the Daimler stereovision data sets.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-144.pdf,2019,100.0,"Improving Pedestrian Recognition using Incremental Cross Modality Deep Learning Late fusion schemes with deep learning classification patterns set up with multi-modality images have an essential role in pedestrian protection systems since they have achieved prominent results in the pedestrian recognition task. In this paper, the late fusion scheme merged with Convolutional Neural Networks (CNN) is investigated for pedestrian recognition based on the Daimler stereo vision data sets. An independent CNN-based classifier for each imaging modality (Intensity, Depth, and Optical Flow) is handled before the fusion of its probabilistic output scores with a Multi-Layer Perceptron which provides the recognition decision. In this paper, we set out to prove that the incremental cross-modality deep learning approach enhances pedestrian recognition performances. It also outperforms state-of-the-art pedestrian classifiers on the Daimler stereovision data sets."
Human feedback in continuous actor-critic reinforcement learning,"Cristian Millán, Bruno Fernandes, Francisco Cruz","1 - Universidade de Pernambuco -Escola Politécnica de Pernambuco Rua Benfica 455 Recife PE -Brasil
3 - Universidad Central de Chile -Escuela de Computación e Informática Santa Isabel 1186 Santiago Chile","Reinforcement learning is utilized in contexts where an agent tries to learn from the environment. Using continuous actions, the performance may be improved in comparison to using discrete actions, however, this leads to excessive time to find a proper policy. In this work, we focus on including human feedback in reinforcement learning for a continuous action space. We unify the policy and the feedback to favor actions of low probability density. Furthermore, we compare the performance of the feedback for the continuous actor-critic algorithm and test our experiments in the cart-pole balancing task. The obtained results show that the proposed approach increases the accumulated reward in comparison to the autonomous learning method.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-149.pdf,2019,100.0,"Human feedback in continuous actor-critic reinforcement learning Reinforcement learning is utilized in contexts where an agent tries to learn from the environment. Using continuous actions, the performance may be improved in comparison to using discrete actions, however, this leads to excessive time to find a proper policy. In this work, we focus on including human feedback in reinforcement learning for a continuous action space. We unify the policy and the feedback to favor actions of low probability density. Furthermore, we compare the performance of the feedback for the continuous actor-critic algorithm and test our experiments in the cart-pole balancing task. The obtained results show that the proposed approach increases the accumulated reward in comparison to the autonomous learning method."
Using Deep Learning and Evolutionary Algorithms for Time Series Forecasting,"Rafael Gonzalez, Dante Couto Barone",1 - Institute of Informatics Federal University of Rio Grande do Sul Porto Alegre RS Brazil,"Deep Learning is one of the latest approaches in the field of artificial neural networks. Since they were first proposed, Deep Learning models have obtained state-of-art results in some problems related to classification and pattern recognition. However, such models have been little used in time series forecasting. This work aims to investigate the use of some of these architectures in this kind of problem. Another contribution is the use of one Evolutionary Algorithm to optimize the hyperparameters of these models. The advantage of the proposed method is shown on two artificial time series datasets and one electricity load demand dataset.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-15.pdf,2019,100.0,"Using Deep Learning and Evolutionary Algorithms for Time Series Forecasting Deep Learning is one of the latest approaches in the field of artificial neural networks. Since they were first proposed, Deep Learning models have obtained state-of-art results in some problems related to classification and pattern recognition. However, such models have been little used in time series forecasting. This work aims to investigate the use of some of these architectures in this kind of problem. Another contribution is the use of one Evolutionary Algorithm to optimize the hyperparameters of these models. The advantage of the proposed method is shown on two artificial time series datasets and one electricity load demand dataset."
Machine learning in research and development of new vaccines products: opportunities and challenges,"Paul Smyth, Gaël De Lannoy, Von Moritz, Alexander Stosch, Amin Pysik, Khan","1 - GSK, Technical Research and Development Rue de l'institut 83 1332 Rixensart Belgium","Modern high-throughput technologies deployed in research and development of new vaccine products have opened the door to machine learning applications that allow the automation of tasks and support for data-driven risk-based decision making. In this paper, the opportunities and the challenges faced for the deployment of machine learning algorithms in the field of vaccines development are discussed.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-152.pdf,2019,100.0,"Machine learning in research and development of new vaccines products: opportunities and challenges Modern high-throughput technologies deployed in research and development of new vaccine products have opened the door to machine learning applications that allow the automation of tasks and support for data-driven risk-based decision making. In this paper, the opportunities and the challenges faced for the deployment of machine learning algorithms in the field of vaccines development are discussed."
Weightless neural systems for deforestation surveillance and image-based navigation of UAVs in the Amazon forest,"Eduardo Ribeiro, Vitor Torres, Brayan James, Mateus Braga, Elcio Shiguemori, Haroldo Velho, Luiz Torres, Antônio Braga","1 - Department of Electronics Engineering Federal University of Minas Gerais Brazil
2 - Department of Computing and Systems Federal University of Ouro Preto Brazil
6 - Institute of Advanced Studies -IEAv
7 - Ministry of Defense São José dos Campos-SP Brazil
8 - National Institute of Space Research -INPE
9 - São José dos Campos-SP Brazil","This work proposes a novel methodology for the recognition of deforestation areas in tropical forests using weightless neural systems in UAVs. The weightless neural systems embedded in hardware brings a considerable improvement in the speed of processing of image-based navigation of UAVs. In our approach the UAV navigates at the frontier of the deforestation area by means of previously trained descriptors, being able to monitor the increase of deforestation area. Experiments using images of the Amazon rainforest have been performed to validate the proposed approach.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-153.pdf,2019,100.0,"Weightless neural systems for deforestation surveillance and image-based navigation of UAVs in the Amazon forest This work proposes a novel methodology for the recognition of deforestation areas in tropical forests using weightless neural systems in UAVs. The weightless neural systems embedded in hardware brings a considerable improvement in the speed of processing of image-based navigation of UAVs. In our approach the UAV navigates at the frontier of the deforestation area by means of previously trained descriptors, being able to monitor the increase of deforestation area. Experiments using images of the Amazon rainforest have been performed to validate the proposed approach."
MAP Best Performances Prediction for Endurance Runners,"Dimitri De Smet, Marc Francaux, Laurent Baijot, Michel Verleysen","1 - UCLouvain, IoNS Louvain-la-Neuve -Belgium
2 - Formyfit -Enghien Belgium
3 - ICTEAM 1-UCLouvain Louvain-la-Neuve Belgium","The preparation of long-distance runners requires to estimate their potential race performances beforehand. Athlete performances can be modeled based on their past records, but the task is made difficult because of the high variability in runner race performances. This paper presents a maximum a posteriori (MAP) estimation that addresses the issues related to this high variability. The inclusion of athlete priors and a specific residual model are inferred with the help of a large set of race results.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-154.pdf,2019,77.77777777777779,"MAP Best Performances Prediction for Endurance Runners The preparation of long-distance runners requires to estimate their potential race performances beforehand. Athlete performances can be modeled based on their past records, but the task is made difficult because of the high variability in runner race performances. This paper presents a maximum a posteriori (MAP) estimation that addresses the issues related to this high variability. The inclusion of athlete priors and a specific residual model are inferred with the help of a large set of race results."
L 1 -norm double backpropagation adversarial defense,"Ismaila Seck, Gaëlle Loosli, Stéphane Canu","1 - Normandie Univ INSA Rouen UNIROUEN UNIHAVRE, LITIS France
2 - UMR 6158 UCA -LIMOS CNRS Clermont-Ferrand 3-PobRun Brioude France, France","Adversarial examples are a challenging open problem for deep neural networks. We propose in this paper to add a penalization term that forces the decision function to be flat in some regions of the input space, such that it becomes, at least locally, less sensitive to attacks. Our proposition is theoretically motivated and shows on a first set of carefully conducted experiments that it behaves as expected when used alone, and seems promising when coupled with adversarial training.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-156.pdf,2019,94.11764705882352,"L 1 -norm double backpropagation adversarial defense Adversarial examples are a challenging open problem for deep neural networks. We propose in this paper to add a penalization term that forces the decision function to be flat in some regions of the input space, such that it becomes, at least locally, less sensitive to attacks. Our proposition is theoretically motivated and shows on a first set of carefully conducted experiments that it behaves as expected when used alone, and seems promising when coupled with adversarial training."
Real-time Convolutional Neural Networks for emotion and gender classification,"Octavio Arriaga, Matias Valdenegro-Toro, Paul Plöger","1 - AG Robotik University of Bremen Bremen Germany
2 - German Research Center for Artificial Intelligence Bremen Germany
3 - Hochschule Bonn-Rhein-Sieg Sankt Augustin Germany","Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-157.pdf,2019,100.0,"Real-time Convolutional Neural Networks for emotion and gender classification Emotion and gender recognition from facial features are important properties of human empathy. Robots should also have these capabilities. For this purpose we have designed special convolutional modules that allow a model to recognize emotions and gender with a considerable lower number of parameters, enabling real-time evaluation on a constrained platform. We report accuracies of 96% in the IMDB gender dataset and 66% in the FER-2013 emotion dataset, while requiring a computation time of less than 0.008 seconds on a Core i7 CPU. All our code, demos and pre-trained architectures have been released under an open-source license in our repository at https://github.com/oarriaga/face classification."
Autoregressive Convolutional Recurrent Neural Network for Univariate and Multivariate Time Series Prediction,"Matteo Maggiolo, Gerasimos Spanakis",1 - Department of Data Science and Knowledge Engineering Maastricht University 6200MD Maastricht the Netherlands,"Time Series forecasting (univariate and multivariate) is a problem of high complexity due the different patterns that have to be detected in the input, ranging from high to low frequencies ones. In this paper we propose a new model for timeseries prediction that utilizes convolutional layers for feature extraction, a recurrent encoder and a linear autoregressive component. We motivate the model and we test and compare it against a baseline of widely used existing architectures for univariate and multivariate timeseries. The proposed model appears to outperform the baselines in almost every case of the multivariate timeseries datasets, in some cases even with 50% improvement which shows the strengths of such a hybrid architecture in complex timeseries.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-159.pdf,2019,100.0,"Autoregressive Convolutional Recurrent Neural Network for Univariate and Multivariate Time Series Prediction Time Series forecasting (univariate and multivariate) is a problem of high complexity due the different patterns that have to be detected in the input, ranging from high to low frequencies ones. In this paper we propose a new model for timeseries prediction that utilizes convolutional layers for feature extraction, a recurrent encoder and a linear autoregressive component. We motivate the model and we test and compare it against a baseline of widely used existing architectures for univariate and multivariate timeseries. The proposed model appears to outperform the baselines in almost every case of the multivariate timeseries datasets, in some cases even with 50% improvement which shows the strengths of such a hybrid architecture in complex timeseries."
Feature Relevance Bounds for Ordinal Regression,"Lukas Pfannschmidt, Jonathan Jakob, Michael Biehl, Peter Tino, Barbara Hammer","1 - Intelligent Systems Group University of Groningen NL
2 - Computer Science University of Birmingham UK
3 - Bielefeld University 1 -Machine learning group DE","The increasing occurrence of ordinal data, mainly sociodemographic, led to a renewed research interest in ordinal regression, i.e. the prediction of ordered classes. Besides model accuracy, the interpretation of these models itself is of high relevance, and existing approaches therefore enforce e.g. model sparsity. For high dimensional or highly correlated data, however, this might be misleading due to strong variable dependencies. In this contribution, we aim for an identification of feature relevance bounds which -besides identifying all relevant features -explicitly differentiates between strongly and weakly relevant features. 1 1 Funding by the DFG in the frame of the graduate school DiDy (1906/3) and by the BMBF (grant number 01S18041A) is gratefully acknowledged.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-162.pdf,2019,70.2127659574468,"Feature Relevance Bounds for Ordinal Regression The increasing occurrence of ordinal data, mainly sociodemographic, led to a renewed research interest in ordinal regression, i.e. the prediction of ordered classes. Besides model accuracy, the interpretation of these models itself is of high relevance, and existing approaches therefore enforce e.g. model sparsity. For high dimensional or highly correlated data, however, this might be misleading due to strong variable dependencies. In this contribution, we aim for an identification of feature relevance bounds which -besides identifying all relevant features -explicitly differentiates between strongly and weakly relevant features. 1 1 Funding by the DFG in the frame of the graduate school DiDy (1906/3) and by the BMBF (grant number 01S18041A) is gratefully acknowledged."
Interpolation on the manifold of fixed-rank positive-semidefinite matrices for parametric model order reduction: preliminary results,"Estelle Massart, Pierre-Yves Gousenbourger, Nguyen Son, Tatjana Stykel, P.-A Absil","1 - ICTEAM Institute UCLouvain Louvain-la-Neuve Belgium
4 - Dept. Mathematics and Informatics TNUS Thai Nguyen Vietnam
5 - Institute of Mathematics University of Augsburg Augsburg Germany","We present several interpolation schemes on the manifold of fixed-rank positive-semidefinite (PSD) matrices. We explain how these techniques can be used for model order reduction of parameterized linear dynamical systems, and obtain preliminary results on an application. * Acknowledgments: this work was supported by (i) the Fonds de la Recherche Scientifique -FNRS and the Fonds Wetenschappelijk Onderzoek -Vlaanderen under EOS Project no 30468160 and (ii) ""Communauté française de Belgique -Actions de Recherche Concertées"" (contract ARC 14/19-060).",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-164.pdf,2019,100.0,"Interpolation on the manifold of fixed-rank positive-semidefinite matrices for parametric model order reduction: preliminary results We present several interpolation schemes on the manifold of fixed-rank positive-semidefinite (PSD) matrices. We explain how these techniques can be used for model order reduction of parameterized linear dynamical systems, and obtain preliminary results on an application. * Acknowledgments: this work was supported by (i) the Fonds de la Recherche Scientifique -FNRS and the Fonds Wetenschappelijk Onderzoek -Vlaanderen under EOS Project no 30468160 and (ii) ""Communauté française de Belgique -Actions de Recherche Concertées"" (contract ARC 14/19-060)."
A Simple and Effective Scheme for Data Pre-processing in Extreme Classification,"Sujay Khandagale, Rohit Babbar","1 - CS Department Mandi Indian Institute of Technology Mandi India
2 - CS Department Helsinki Aalto University Finland
3 - Aalto University Finland","Extreme multi-label classification (XMC) refers to supervised multi-label learning involving hundreds of thousand or even millions of labels. It has been shown to be an effective framework for addressing crucial tasks such as recommendation, ranking and web-advertising. In this paper, we propose a method for effective and well-motivated data pre-processing scheme in XMC. We show that our proposed algorithm, PrunEX, can remove upto 90% data in the input which is redundant from a classification view-point. Our scheme is universal in the sense it is applicable to all known public datasets in the domain of XMC.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-167.pdf,2019,100.0,"A Simple and Effective Scheme for Data Pre-processing in Extreme Classification Extreme multi-label classification (XMC) refers to supervised multi-label learning involving hundreds of thousand or even millions of labels. It has been shown to be an effective framework for addressing crucial tasks such as recommendation, ranking and web-advertising. In this paper, we propose a method for effective and well-motivated data pre-processing scheme in XMC. We show that our proposed algorithm, PrunEX, can remove upto 90% data in the input which is redundant from a classification view-point. Our scheme is universal in the sense it is applicable to all known public datasets in the domain of XMC."
Deep hybrid approach for 3D plane segmentation,"Felipe Gomez Marulanda, Pieter Libin, Timothy Verstraeten, Ann Nowé",1 - Artificial Intelligence Lab -Vrije Universiteit Brussel -Brussels Belgium,"We address the limitations of Deep learning models for 3D geometry segmentation by using Conditional Random fields (CRF). We show that CRFs can take advantage of the neighbouring structure of point clouds to assist the learning of the Deep Learning models (DL). Our hybrid PN-CRF model is able to learn more optimal weights by taking advantage of equal-segmentation assignments to neighbouring points. As a result, it increases the robustness in the model specially for segmentation tasks where correctly detecting the boundaries between segmentations is very important.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-169.pdf,2019,100.0,"Deep hybrid approach for 3D plane segmentation We address the limitations of Deep learning models for 3D geometry segmentation by using Conditional Random fields (CRF). We show that CRFs can take advantage of the neighbouring structure of point clouds to assist the learning of the Deep Learning models (DL). Our hybrid PN-CRF model is able to learn more optimal weights by taking advantage of equal-segmentation assignments to neighbouring points. As a result, it increases the robustness in the model specially for segmentation tasks where correctly detecting the boundaries between segmentations is very important."
A document detection technique using convolutional neural networks for optical character recognition systems,"Lorand Dobai, Mihai Teletin","1 - -Lateral Inc Cluj-Napoca Romania
2 - Babes-Bolyai University Cluj-Napoca Romania","An important part of an optical character recognition pipeline is the preprocessing step, whose purpose is to enhance the conditions under which the text extraction is later performed. In this paper, we present a novel deep learning based preprocessing method to jointly detect and deskew documents in digital images. Our work intends to improve the optical recognition performance, especially on frames which are skewed (slightly rotated) or have cluttered backgrounds. The proposed method achieves good document detection and deskewing results on a dataset of photos of cash receipts. 
 Literature review Various work showed that the preprocessing step is critical in order to achieve good OCR performance [1]. However, the preprocessing part is still biased on classical com-",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-17.pdf,2019,100.0,"A document detection technique using convolutional neural networks for optical character recognition systems An important part of an optical character recognition pipeline is the preprocessing step, whose purpose is to enhance the conditions under which the text extraction is later performed. In this paper, we present a novel deep learning based preprocessing method to jointly detect and deskew documents in digital images. Our work intends to improve the optical recognition performance, especially on frames which are skewed (slightly rotated) or have cluttered backgrounds. The proposed method achieves good document detection and deskewing results on a dataset of photos of cash receipts. 
 Literature review Various work showed that the preprocessing step is critical in order to achieve good OCR performance [1]. However, the preprocessing part is still biased on classical com-"
On-line learning dynamics of ReLU neural networks using statistical physics techniques,"Michiel Straat, Michael Biehl",1 - Computer Science and Artificial Intelligence Bernoulli Institute for Mathematics University of Groningen Nijenborgh 9 9747AG Groningen The Netherlands,"We introduce exact macroscopic on-line learning dynamics of two-layer neural networks with ReLU units in the form of a system of differential equations, using techniques borrowed from statistical physics. For the first experiments, numerical solutions reveal similar behavior compared to sigmoidal activation researched in earlier work. In these experiments the theoretical results show good correspondence with simulations. In overrealizable and unrealizable learning scenarios, the learning behavior of ReLU networks shows distinctive characteristics compared to sigmoidal networks. * We acknowledge financial support through the Northern Netherlands Region of Smart Factories (RoSF) consortium, see http://www.rosf.nl.",Statistical physics of learning and inference,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-173.pdf,2019,100.0,"On-line learning dynamics of ReLU neural networks using statistical physics techniques We introduce exact macroscopic on-line learning dynamics of two-layer neural networks with ReLU units in the form of a system of differential equations, using techniques borrowed from statistical physics. For the first experiments, numerical solutions reveal similar behavior compared to sigmoidal activation researched in earlier work. In these experiments the theoretical results show good correspondence with simulations. In overrealizable and unrealizable learning scenarios, the learning behavior of ReLU networks shows distinctive characteristics compared to sigmoidal networks. * We acknowledge financial support through the Northern Netherlands Region of Smart Factories (RoSF) consortium, see http://www.rosf.nl."
Application of deep neural networks for automatic planning in radiation oncology treatments,"A Barragán-Montero, D Nguyen, W Lu, M Lin, X Geets, E Sterpin, S Jiang, Ana Montero","1 - UCLouvain -Center of Molecular Imaging Radiotherapy and Oncology -Brussels Belgium
2 - -UTSouthwestern -Medical Artificial Intelligence and Automation Laboratory -Dallas USA
6 - Department of Radiation Oncology -Brussels -Cliniques universitaires Saint-Luc Belgium
8 - -KU Leuven -Laboratory of Experimental Radiotherapy -Leuven Belgium","Treatment planning for radiotherapy patients is a time-consuming and manual process. In this work, we investigate the use of deep neural networks to learn from previous clinical cases and directly predict the optimal dose distribution for a new patient. The proposed model combines two architectures, UNet and DenseNet, and used mean squared error as loss function. Ten input channels were used to include dosimetric and anatomical information. A set of 100 patients was used for training/validation and 29 for testing. Dice similarity coefficients ≥ 0.9 for the isodose-lines in the predicted versus the clinical dose showed the excellent accuracy of the model.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-174.pdf,2019,100.0,"Application of deep neural networks for automatic planning in radiation oncology treatments Treatment planning for radiotherapy patients is a time-consuming and manual process. In this work, we investigate the use of deep neural networks to learn from previous clinical cases and directly predict the optimal dose distribution for a new patient. The proposed model combines two architectures, UNet and DenseNet, and used mean squared error as loss function. Ten input channels were used to include dosimetric and anatomical information. A set of 100 patients was used for training/validation and 29 for testing. Dice similarity coefficients ≥ 0.9 for the isodose-lines in the predicted versus the clinical dose showed the excellent accuracy of the model."
Spatial analysis in high resolution geo-data,"Madalina Olteanu, Julien Randon-Furling, William Clark","1 - MaIAGE -INRA Jouy-en-Josas France
2 - SAMM -Université Panthéon Sorbonne Paris France
4 - Dpt of Geography University of California Los Angeles USA","The analysis of spatial dissimilarities across cities often relies on pre-defined areal units, leading to problems of scale, interpretability and cross-comparisons. Furthermore, traditional measures of dissimilarities tend to be single-number indices that fail to capture the complexity of segregation patterns. We present in this paper a method that allows one to extract and analyze information on all scales, at every point in the city, through a stochastic sequential aggregation procedure based on highresolution data. This method provides insightful visual representations, as well as mathematical characterizations of segregation phenomena.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-22,2019,51.48514851485149,"Spatial analysis in high resolution geo-data The analysis of spatial dissimilarities across cities often relies on pre-defined areal units, leading to problems of scale, interpretability and cross-comparisons. Furthermore, traditional measures of dissimilarities tend to be single-number indices that fail to capture the complexity of segregation patterns. We present in this paper a method that allows one to extract and analyze information on all scales, at every point in the city, through a stochastic sequential aggregation procedure based on highresolution data. This method provides insightful visual representations, as well as mathematical characterizations of segregation phenomena."
Complex Valued Gated Auto-encoder for Video Frame Prediction,"Niloofar Azizi, Nils Wandel, Sven Behnke",1 - Computer Science Department Bonn University Endenicher Allee 19a 53115 Bonn Germany,"In recent years, complex valued artificial neural networks have gained increasing interest as they allow neural networks to learn richer representations while potentially incorporating less parameters. Especially in the domain of computer graphics, many traditional operations rely heavily on computations in the complex domain, thus complex valued neural networks apply naturally. In this paper, we perform frame predictions in video sequences using a complex valued gated auto-encoder. First, our method is motivated showing how the Fourier transform can be seen as the basis for translational operations. Then, we present how a complex neural network can learn such transformations and compare its performance and parameter efficiency to a real-valued gated autoencoder. Furthermore, we show how extending both -the real and the complex valued -neural networks by using convolutional units can significantly improve prediction performance and parameter efficiency. The networks are assessed on a moving noise and a bouncing ball dataset. 
 Frame Prediction using Deconvolution A motivating example shows how the transformation between two images that are translated copies can be calculated by deconvolution.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-176.pdf,2019,100.0,"Complex Valued Gated Auto-encoder for Video Frame Prediction In recent years, complex valued artificial neural networks have gained increasing interest as they allow neural networks to learn richer representations while potentially incorporating less parameters. Especially in the domain of computer graphics, many traditional operations rely heavily on computations in the complex domain, thus complex valued neural networks apply naturally. In this paper, we perform frame predictions in video sequences using a complex valued gated auto-encoder. First, our method is motivated showing how the Fourier transform can be seen as the basis for translational operations. Then, we present how a complex neural network can learn such transformations and compare its performance and parameter efficiency to a real-valued gated autoencoder. Furthermore, we show how extending both -the real and the complex valued -neural networks by using convolutional units can significantly improve prediction performance and parameter efficiency. The networks are assessed on a moving noise and a bouncing ball dataset. 
 Frame Prediction using Deconvolution A motivating example shows how the transformation between two images that are translated copies can be calculated by deconvolution."
Sparse minimal learning machine using a diversity measure minimization,"Madson Dias, Lucas Sousa, Ajalmar Da Rocha Neto, César Mattos, João Gomes, T Kärkkäinen","1 - Department of Computer Science Federal University of Ceará Brazil
2 - Department of Teleinformatics Federal Institute of Ceará Brazil
6 - Faculty of Information Technology University of Jyvaskyla Finland","The minimal learning machine (MLM) training procedure consists in solving a linear system with multiple measurement vectors (MMV) created between the geometric configurations of points in the input and output spaces. Such geometric configurations are built upon two matrices created using subsets of input and output points, named reference points (RPs). The present paper considers an extension of the focal underdetermined system solver (FOCUSS) for MMV linear systems problems with additive noise, named regularized MMV FOCUSS (regularized M-FOCUSS), and evaluates it in the task of selecting input reference points for regression settings. Experiments were carried out using UCI datasets, where the proposal was able to produce sparser models and achieve competitive performance when compared to the regular strategy of selecting MLM input RPs.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-178.pdf,2019,100.0,"Sparse minimal learning machine using a diversity measure minimization The minimal learning machine (MLM) training procedure consists in solving a linear system with multiple measurement vectors (MMV) created between the geometric configurations of points in the input and output spaces. Such geometric configurations are built upon two matrices created using subsets of input and output points, named reference points (RPs). The present paper considers an extension of the focal underdetermined system solver (FOCUSS) for MMV linear systems problems with additive noise, named regularized MMV FOCUSS (regularized M-FOCUSS), and evaluates it in the task of selecting input reference points for regression settings. Experiments were carried out using UCI datasets, where the proposal was able to produce sparser models and achieve competitive performance when compared to the regular strategy of selecting MLM input RPs."
Model selection for Extreme Minimal Learning Machine using sampling,Tommi Kärkkäinen,1 - Faculty of Information Technology University of Jyvaskyla Finland,"A combination of Extreme Learning Machine (ELM) and Minimal Learning Machine (MLM)-to use a distance-based basis from MLM in the ridge regression like learning framework of ELM-was proposed in  [8] . In the further experiments with the technique [9], it was concluded that in multilabel classification one can obtain a good validation error level without overlearning simply by using the whole training data for constructing the basis. Here, we consider possibilities to reduce the complexity of the resulting machine learning model, referred as the Extreme Minimal Leaning Machine (EMLM), by using a bidirectional sampling strategy: To sample both the feature space and the space of observations in order to identify a simpler EMLM without sacrificing its generalization performance.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-18.pdf,2019,100.0,"Model selection for Extreme Minimal Learning Machine using sampling A combination of Extreme Learning Machine (ELM) and Minimal Learning Machine (MLM)-to use a distance-based basis from MLM in the ridge regression like learning framework of ELM-was proposed in  [8] . In the further experiments with the technique [9], it was concluded that in multilabel classification one can obtain a good validation error level without overlearning simply by using the whole training data for constructing the basis. Here, we consider possibilities to reduce the complexity of the resulting machine learning model, referred as the Extreme Minimal Leaning Machine (EMLM), by using a bidirectional sampling strategy: To sample both the feature space and the space of observations in order to identify a simpler EMLM without sacrificing its generalization performance."
Comparison between DeepESNs and gated RNNs on multivariate time-series prediction,"Claudio Gallicchio, Alessio Micheli, Luca Pedrelli",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"We propose an experimental comparison between Deep Echo State Networks (DeepESNs) and gated Recurrent Neural Networks (RNNs) on multivariate time-series prediction tasks. In particular, we compare reservoir and fully-trained RNNs able to represent signals featured by multiple time-scales dynamics. The analysis is performed in terms of efficiency and prediction accuracy on 4 polyphonic music tasks. Our results show that DeepESN is able to outperform ESN in terms of prediction accuracy and efficiency. Whereas, between fully-trained approaches, Gated Recurrent Units (GRU) outperforms Long Short-Term Memory (LSTM) and simple RNN models in most cases. Overall, DeepESN turned out to be extremely more efficient than others RNN approaches and the best solution in terms of prediction accuracy on 3 out of 4 tasks.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-184.pdf,2019,100.0,"Comparison between DeepESNs and gated RNNs on multivariate time-series prediction We propose an experimental comparison between Deep Echo State Networks (DeepESNs) and gated Recurrent Neural Networks (RNNs) on multivariate time-series prediction tasks. In particular, we compare reservoir and fully-trained RNNs able to represent signals featured by multiple time-scales dynamics. The analysis is performed in terms of efficiency and prediction accuracy on 4 polyphonic music tasks. Our results show that DeepESN is able to outperform ESN in terms of prediction accuracy and efficiency. Whereas, between fully-trained approaches, Gated Recurrent Units (GRU) outperforms Long Short-Term Memory (LSTM) and simple RNN models in most cases. Overall, DeepESN turned out to be extremely more efficient than others RNN approaches and the best solution in terms of prediction accuracy on 3 out of 4 tasks."
Modeling Sparse Data as Input for Weightless Neural Network,"Luis Kopp, José Barbosa Da, Silva Filho, Claudio Miceli De Farias, Priscila Machado, Vieira Lima","1 - Postgraduate Program in Informatics (PPGI) UFRJ Av. Athos da Silveira Ramos 149 Rio de Janeiro RJ Brazil
3 - Admiral Graça Aranha Instruction Center (CIAGA) -Brazilian Navy Av. Brasil Electricity Lab 9020, I-101 Olaria, Rio de Janeiro BL, RJ Brazil","Dealing with large and sparse input data has been a challenge to machine learning algorithms. In Natural Language Processing (NLP), such challenge is typically faced by bag-of-word solutions wherein the number of useful words is a tiny fraction of the size of the dictionary, leading to sparse input matrices. In this paper we propose aggregating features into groups at random -a simple method for coping with sparse inputs to Weightless Neural Networks (WiSARD) that would reduce the input size. As result, in the considered datasets, we found that bundles of size between 3 to 6 words are typically optimal, and yield an increase of accuracy of up to 4.5%.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-187.pdf,2019,100.0,"Modeling Sparse Data as Input for Weightless Neural Network Dealing with large and sparse input data has been a challenge to machine learning algorithms. In Natural Language Processing (NLP), such challenge is typically faced by bag-of-word solutions wherein the number of useful words is a tiny fraction of the size of the dictionary, leading to sparse input matrices. In this paper we propose aggregating features into groups at random -a simple method for coping with sparse inputs to Weightless Neural Networks (WiSARD) that would reduce the input size. As result, in the considered datasets, we found that bundles of size between 3 to 6 words are typically optimal, and yield an increase of accuracy of up to 4.5%."
Pixel-wise Conditioning of Generative Adversarial Networks,"Cyprien Ruffino, Romain Hérault, Eric Laloy, Gilles Gasso","1 - Normandie Univ UNIROUEN UNIHAVRE INSA Rouen LITIS 76 000 Rouen France
3 - Institute Environment Health and Safety Belgian Nuclear Research 200 -BE-2400 Boeretang, Mol Belgium","Generative Adversarial Networks (GANs) have proven successful for unsupervised image generation. Several works extended GANs to image inpainting by conditioning the generation with parts of the image one wants to reconstruct. However, these methods have limitations in settings where only a small subset of the image pixels is known beforehand. In this paper, we study the effectiveness of conditioning GANs by adding an explicit regularization term to enforce pixel-wise conditions when very few pixel values are provided. In addition, we also investigate the influence of this regularization term on the quality of the generated images and the satisfaction of the conditions. Conducted experiments on MNIST and FashionMNIST show evidence that this regularization term allows for controlling the trade-off between quality of the generated images and constraint satisfaction.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-189.pdf,2019,100.0,"Pixel-wise Conditioning of Generative Adversarial Networks Generative Adversarial Networks (GANs) have proven successful for unsupervised image generation. Several works extended GANs to image inpainting by conditioning the generation with parts of the image one wants to reconstruct. However, these methods have limitations in settings where only a small subset of the image pixels is known beforehand. In this paper, we study the effectiveness of conditioning GANs by adding an explicit regularization term to enforce pixel-wise conditions when very few pixel values are provided. In addition, we also investigate the influence of this regularization term on the quality of the generated images and the satisfaction of the conditions. Conducted experiments on MNIST and FashionMNIST show evidence that this regularization term allows for controlling the trade-off between quality of the generated images and constraint satisfaction."
Multilingual Short Text Categorization Using Convolutional Neural Network,"Liriam Enamoto, Li Weigang",1 - Dept of Computer Science University of Brasilia Asa Norte Brasília -DF -Brazil,"One of the most meaningful use of online social media is to communicate quickly during emergency. In case of global emergency, the threat might cross countries borders, affect different cultures and languages. This article aims to explore Convolutional Neural Network (CNN) for multilingual short text categorization in English, Japanese and Portuguese to identify useful information in social media. A CNN is constructed for this special purpose. The experiment results show that CNN model performs better than SVM even in small dataset. And more interestingly, the cross languages test suggests that English, Japanese and Portuguese text can use the same model with few hyperparameters changes.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-19.pdf,2019,73.97260273972603,"Multilingual Short Text Categorization Using Convolutional Neural Network One of the most meaningful use of online social media is to communicate quickly during emergency. In case of global emergency, the threat might cross countries borders, affect different cultures and languages. This article aims to explore Convolutional Neural Network (CNN) for multilingual short text categorization in English, Japanese and Portuguese to identify useful information in social media. A CNN is constructed for this special purpose. The experiment results show that CNN model performs better than SVM even in small dataset. And more interestingly, the cross languages test suggests that English, Japanese and Portuguese text can use the same model with few hyperparameters changes."
Direct calculation of out-of-sample predictions in multi-class kernel FDA,Matthias Treder,1 - School of Computer Science Informatics -Cardiff University CF24 3AA Cardiff United Kingdom,"After a two-class kernel Fisher Discriminant Analysis (KFDA) has been trained on the full dataset, matrix inverse updates allow for the direct calculation of out-of-sample predictions for different test sets. Here, this approach is extended to the multi-class case by casting KFDA in an Optimal Scoring framework. In simulations using 10-fold cross-validation and permutation tests the approach is shown to be more than 1000x faster than retraining the classifier in each fold. Direct out-of-sample predictions can be useful on large datasets and in studies with many training-testing iterations.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-194.pdf,2019,100.0,"Direct calculation of out-of-sample predictions in multi-class kernel FDA After a two-class kernel Fisher Discriminant Analysis (KFDA) has been trained on the full dataset, matrix inverse updates allow for the direct calculation of out-of-sample predictions for different test sets. Here, this approach is extended to the multi-class case by casting KFDA in an Optimal Scoring framework. In simulations using 10-fold cross-validation and permutation tests the approach is shown to be more than 1000x faster than retraining the classifier in each fold. Direct out-of-sample predictions can be useful on large datasets and in studies with many training-testing iterations."
Statistical Physics of Learning and Inference,"M Biehl, N Caticha, M Opper, T Villmann","1 - Computer Science and Artificial Intelligence Univ. of Groningen Bernoulli Institute for Mathematics Nijenborgh 9 NL-9747 AG Groningen The Netherlands
2 - Instituto de Física Universidade de São Paulo Caixa Postal 66318, 05315-970 São Paulo SP Brazil
3 - Department of Electrical Engineering and Computer Science Technical University Berlin D-10587 Berlin Germany
4 - Computational Intelligence Group University of Applied Sciences Mittweida Technikumplatz 17 D-09648 Mittweida Germany","The exchange of ideas between statistical physics and computer science has been very fruitful and is currently gaining momentum as a consequence of the revived interest in neural networks, machine learning and inference in general. Statistical physics methods complement other approaches to the theoretical understanding of machine learning processes and inference in stochastic modeling. They facilitate, for instance, the study of dynamical and equilibrium properties of randomized training processes in model situations. At the same time, the approach inspires novel and efficient algorithms and facilitates interdisciplinary applications in a variety of scientific and technical disciplines.",Sparse representation of data,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-97.pdf,2019,55.55555555555556,"Statistical Physics of Learning and Inference The exchange of ideas between statistical physics and computer science has been very fruitful and is currently gaining momentum as a consequence of the revived interest in neural networks, machine learning and inference in general. Statistical physics methods complement other approaches to the theoretical understanding of machine learning processes and inference in stochastic modeling. They facilitate, for instance, the study of dynamical and equilibrium properties of randomized training processes in model situations. At the same time, the approach inspires novel and efficient algorithms and facilitates interdisciplinary applications in a variety of scientific and technical disciplines."
Multi-target feature selection through output space clustering,"Konstantinos Sechidis, Eleftherios Spyromitros-Xioufis, Ioannis Vlahavas","1 - Department of Computer Science Aristotle University 54124 Thessaloniki Greece
2 - School of Computer Science University of Manchester M13 9PL Manchester UK
4 - Expedia, Geneva","A key challenge in information theoretic feature selection is to estimate mutual information expressions that capture three desirable terms: the relevancy of a feature with the output, the redundancy and the complementarity between groups of features. The challenge becomes more pronounced in multi-target problems, where the output space is multidimensional. Our work presents a generic algorithm that captures these three desirable terms and is suitable for the well-known multi-target prediction settings of multi-label/dimensional classification and multivariate regression. We achieve this by combining two ideas: deriving low-order information theoretic approximations for the input space and using clustering for deriving low-dimensional approximations of the output space.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-20.pdf,2019,100.0,"Multi-target feature selection through output space clustering A key challenge in information theoretic feature selection is to estimate mutual information expressions that capture three desirable terms: the relevancy of a feature with the output, the redundancy and the complementarity between groups of features. The challenge becomes more pronounced in multi-target problems, where the output space is multidimensional. Our work presents a generic algorithm that captures these three desirable terms and is suitable for the well-known multi-target prediction settings of multi-label/dimensional classification and multivariate regression. We achieve this by combining two ideas: deriving low-order information theoretic approximations for the input space and using clustering for deriving low-dimensional approximations of the output space."
A best-first branch-and-bound search for solving the transductive inference problem using support vector machines,"Hygor Araújo, Raul Neto, Saulo Moraes",1 - Department of Computer Science Federal University of Juiz de Fora Brazil,"In this paper, we present a new method for solving the transductive inference problem whose objective is predicting the binary labels of a subset of points of interest of an unknown decision function. We attempt to learn a decision boundary using SVM. To obtain the maximal-margin hypothesis over labeled and unlabeled samples, we employ an admissible best-first search based on margin values. Empirical evidence suggests that this globally optimal solution can obtain excellent results in the transduction problem. Due to the selection strategy used, the search algorithm explores only a small fraction of unlabeled samples making it efficiently applicable to median-sized datasets. We compare our results with the results obtained from the TSVM demonstrating better results in margin values.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-201.pdf,2019,100.0,"A best-first branch-and-bound search for solving the transductive inference problem using support vector machines In this paper, we present a new method for solving the transductive inference problem whose objective is predicting the binary labels of a subset of points of interest of an unknown decision function. We attempt to learn a decision boundary using SVM. To obtain the maximal-margin hypothesis over labeled and unlabeled samples, we employ an admissible best-first search based on margin values. Empirical evidence suggests that this globally optimal solution can obtain excellent results in the transduction problem. Due to the selection strategy used, the search algorithm explores only a small fraction of unlabeled samples making it efficiently applicable to median-sized datasets. We compare our results with the results obtained from the TSVM demonstrating better results in margin values."
Computerized tool for identification and enhanced visualization of Macular Edema regions using OCT scans,"Iago Otero, Plácido Vidal, Joaquim De Moura, Jorge Novo, Marcos Ortega","1 - Department of Computer Science University of A Coruña A Coruña (Spain
2 - CITIC -Research Center of Information and Communication Technologies University of A Coruña Coruña Spain
11 - Xunta de Galicia through Centro singular de investigación de Galicia","We propose a novel methodology using Optical Coherence Tomography (OCT) images to detect the 3 clinically defined types of Macular Edema, which is among the main causes of blindness: Diffuse Retinal Thickening (DRT), Cystoid Macular Edema (CME) and Serous Retinal Detachment (SRD). To perform this detection, we sample the images and train models to create an intuitive color map that represents the 3 pathologies to facilitate the clinical evaluation. The proposed method was tested using a dataset composed by 96 OCT images. The system provided satisfactory results with accuracy values of 90.49%, 93.23% and 88.87% for the CME, SRD and DRT detections, respectively.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-21.pdf,2019,100.0,"Computerized tool for identification and enhanced visualization of Macular Edema regions using OCT scans We propose a novel methodology using Optical Coherence Tomography (OCT) images to detect the 3 clinically defined types of Macular Edema, which is among the main causes of blindness: Diffuse Retinal Thickening (DRT), Cystoid Macular Edema (CME) and Serous Retinal Detachment (SRD). To perform this detection, we sample the images and train models to create an intuitive color map that represents the 3 pathologies to facilitate the clinical evaluation. The proposed method was tested using a dataset composed by 96 OCT images. The system provided satisfactory results with accuracy values of 90.49%, 93.23% and 88.87% for the CME, SRD and DRT detections, respectively."
Conditional WGAN for grasp generation,"Florian Patzelt, Robert Haschke, Helge Ritter",1 - Center of Excellence Cognitive Interaction Technology (CITEC) Neuroinformatics Group Bielefeld University Germany,"This work proposes a new approach to robotic grasping exploiting conditional Wasserstein generative adversarial networks (WGANs), which output promising grasp candidates from depth image inputs. In contrast to discriminative models, the WGAN approach enables deliberative navigation in the set of feasible grasps and thus allows a smooth integration with other motion planning tools. We find that the training autonomously partitioned the space of feasible grasps into several regions corresponding to different grasp types. Each region forms a smooth grasp manifold with latent parameters corresponding to important grasp parameters like approach direction. We evaluate the model in simulation on the multi-fingered Shadow Robot hand, comparing it a) to a classical grasp planner for primitive geometric object shapes and b) to a state-of-the-art discriminative network model. The proposed generative model matches the grasp success rate of its trainer models and exhibits better generalization.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-25.pdf,2019,100.0,"Conditional WGAN for grasp generation This work proposes a new approach to robotic grasping exploiting conditional Wasserstein generative adversarial networks (WGANs), which output promising grasp candidates from depth image inputs. In contrast to discriminative models, the WGAN approach enables deliberative navigation in the set of feasible grasps and thus allows a smooth integration with other motion planning tools. We find that the training autonomously partitioned the space of feasible grasps into several regions corresponding to different grasp types. Each region forms a smooth grasp manifold with latent parameters corresponding to important grasp parameters like approach direction. We evaluate the model in simulation on the multi-fingered Shadow Robot hand, comparing it a) to a classical grasp planner for primitive geometric object shapes and b) to a state-of-the-art discriminative network model. The proposed generative model matches the grasp success rate of its trainer models and exhibits better generalization."
Fast and Reliable Architecture Selection for Convolutional Neural Networks,"Lukas Hahn, Lutz Roese-Koerner, Klaus Friedrichs, Anton Kummert","1 - -Aptiv Wuppertal Germany
2 - Department of Electrical Engineering University of Wuppertal Wuppertal Germany","The performance of a Convolutional Neural Network (CNN) depends on its hyperparameters, like the number of layers, kernel sizes, or the learning rate for example. Especially in smaller networks and applications with limited computational resources, optimisation is key. We present a fast and efficient approach for CNN architecture selection. Taking into account time consumption, precision and robustness, we develop a heuristic to quickly and reliably assess a network's performance. In combination with Bayesian optimisation (BO), to effectively cover the vast parameter space, our contribution offers a plain and powerful architecture search for this machine learning technique.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-26.pdf,2019,75.67567567567568,"Fast and Reliable Architecture Selection for Convolutional Neural Networks The performance of a Convolutional Neural Network (CNN) depends on its hyperparameters, like the number of layers, kernel sizes, or the learning rate for example. Especially in smaller networks and applications with limited computational resources, optimisation is key. We present a fast and efficient approach for CNN architecture selection. Taking into account time consumption, precision and robustness, we develop a heuristic to quickly and reliably assess a network's performance. In combination with Bayesian optimisation (BO), to effectively cover the vast parameter space, our contribution offers a plain and powerful architecture search for this machine learning technique."
Privacy Preserving Synthetic Health Data,"Andrew Yale, Saloni Dash, Ritik Dutta, Isabelle Guyon, Adrien Pavao, Kristin Bennett","1 - Rensselaer Polytechnic Inst New York
2 - Department of CSIS UPSud/INRIA U. Paris-Saclay Goa Campus 3-BITS, 4-IIT Pilani, Gandhinagar France, India, India","We examine the feasibility of using synthetic medical data generated by GANs in the classroom, to teach data science in health informatics. We present an end-to-end methodology to retain instructional utility, while preserving privacy to a level, which meets regulatory requirements: (1) a GAN is trained by a certified medical-data security-aware agent, inside a secure environment; (2) the final GAN model is used outside of the secure environment by external users (instructors or researchers) to generate synthetic data. This second step facilitates data handling for external users, by avoiding de-identification, which may require special user training, be costly, and/or cause loss of data fidelity. We benchmark our proposed GAN versus various baseline methods using a novel set of metrics. At equal levels of privacy and utility, GANs provide small footprint models, meeting the desired specifications of our application domain. Data, code, and a challenge that we organized for educational purposes are available.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-29.pdf,2019,100.0,"Privacy Preserving Synthetic Health Data We examine the feasibility of using synthetic medical data generated by GANs in the classroom, to teach data science in health informatics. We present an end-to-end methodology to retain instructional utility, while preserving privacy to a level, which meets regulatory requirements: (1) a GAN is trained by a certified medical-data security-aware agent, inside a secure environment; (2) the final GAN model is used outside of the secure environment by external users (instructors or researchers) to generate synthetic data. This second step facilitates data handling for external users, by avoiding de-identification, which may require special user training, be costly, and/or cause loss of data fidelity. We benchmark our proposed GAN versus various baseline methods using a novel set of metrics. At equal levels of privacy and utility, GANs provide small footprint models, meeting the desired specifications of our application domain. Data, code, and a challenge that we organized for educational purposes are available."
"Recent trends in streaming data analysis, concept drift and analysis of dynamic data sets","Albert Bifet, Barbara Hammer, Frank-M Schleif","1 - LTCI Telecom ParisTech
2 - Université Paris-Saclay Paris France
3 - Bielefeld University
4 - CITEC centre of excellence Bielefeld Germany
5 - School of Computer Science University of Birmingham B15 2TT Edgbaston, Birmingham United Kingdom","Today, many data are not any longer static but occur as dynamic data streams with high velocity, variability and volume. This leads to new challenges to be addressed by novel or adapted algorithms. In this tutorial we provide an introduction into the field of streaming data analysis summarizing its major characteristics and highlighting important research directions in the analysis of dynamic data.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-3.pdf,2019,100.0,"Recent trends in streaming data analysis, concept drift and analysis of dynamic data sets Today, many data are not any longer static but occur as dynamic data streams with high velocity, variability and volume. This leads to new challenges to be addressed by novel or adapted algorithms. In this tutorial we provide an introduction into the field of streaming data analysis summarizing its major characteristics and highlighting important research directions in the analysis of dynamic data."
On the Speedup of Deep Reinforcement Learning Deep Q-Networks (RL-DQNs),"Anas Albaghajati, Lahouari Ghouti","1 - Minerals -Department of Information and Computer Science King Fahd University of Petroleum KFUPM Box 1128. Dhahran 31261 Saudi Arabia
3 - King Fahd University of Petroleum and Minerals","Deep reinforcement learning (DRL) merges reinforcement (RL) and deep learning (DL). In DRL-based agents rely on high-dimensional imagery inputs to make accurate decisions. Such excessively high-dimensional inputs and sophisticated algorithms require very powerful computing resources and longer training times. To alleviate the need for powerful resources and reduce the training times, this paper proposes novel solutions to mitigate the curse-of-dimensionality without compromising the DRL agent performance. Using these solutions, the deep Q-network model (DQN) and its improved versions require less training times while achieving better performance.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-32.pdf,2019,100.0,"On the Speedup of Deep Reinforcement Learning Deep Q-Networks (RL-DQNs) Deep reinforcement learning (DRL) merges reinforcement (RL) and deep learning (DL). In DRL-based agents rely on high-dimensional imagery inputs to make accurate decisions. Such excessively high-dimensional inputs and sophisticated algorithms require very powerful computing resources and longer training times. To alleviate the need for powerful resources and reduce the training times, this paper proposes novel solutions to mitigate the curse-of-dimensionality without compromising the DRL agent performance. Using these solutions, the deep Q-network model (DQN) and its improved versions require less training times while achieving better performance."
Reactive Soft Prototype Computing for frequent reoccurring Concept Drift,"Christoph Raab, Moritz Heusinger, Frank-Michael Schleif",1 - Department of Computer Science University of applied Science Würzburg-Schweinfurt Sanderheinrichsleitenweg 20 Würzburg Germany,"Todays datasets, especially in streaming context, are more and more non-static and require algorithms to detect and adapt to change. Recent work shows vital research in the field, but mainly lack stable performance during model adaptation. In this work, a concept drift detection strategy followed by a prototype based insertion strategy is proposed. Validated through experimental results on a variety of typical non-static data, our solution provides stable and quick adjustments in times of change.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-33.pdf,2019,100.0,"Reactive Soft Prototype Computing for frequent reoccurring Concept Drift Todays datasets, especially in streaming context, are more and more non-static and require algorithms to detect and adapt to change. Recent work shows vital research in the field, but mainly lack stable performance during model adaptation. In this work, a concept drift detection strategy followed by a prototype based insertion strategy is proposed. Validated through experimental results on a variety of typical non-static data, our solution provides stable and quick adjustments in times of change."
Knowledge Discovery in Quarterly Financial Data of Stocks Based on the Prime Standard using a Hybrid of a Swarm with SOM,Michael Thrun,"1 - Mathematics and Computer Science University of Marburg
2 - Hans-Meerwein Str 35032 Marburg Germany","Stocks of the German Prime standard have to publish financial reports every three months which were not used fully for fundamental analysis so far. Through web scrapping, an up-to-date high-dimensional dataset of 45 features of 269 companies was extracted, but finding meaningful cluster structures in a highdimensional dataset with a low number of cases is still a challenge in data science. A hybrid of a swarm with a SOM called Databionic swarm (DBS) found meaningful structures in the financial reports. Using the Chord distance the DBS algorithm results in a topographic map of high-dimensional structures and a clustering. Knowledge from the clustering is acquired using CART. The cluster structures can be explained by simple rules that allow predicting which future stock courses will fall with a 70% probability.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-34.pdf,2019,100.0,"Knowledge Discovery in Quarterly Financial Data of Stocks Based on the Prime Standard using a Hybrid of a Swarm with SOM Stocks of the German Prime standard have to publish financial reports every three months which were not used fully for fundamental analysis so far. Through web scrapping, an up-to-date high-dimensional dataset of 45 features of 269 companies was extracted, but finding meaningful cluster structures in a highdimensional dataset with a low number of cases is still a challenge in data science. A hybrid of a swarm with a SOM called Databionic swarm (DBS) found meaningful structures in the financial reports. Using the Chord distance the DBS algorithm results in a topographic map of high-dimensional structures and a clustering. Knowledge from the clustering is acquired using CART. The cluster structures can be explained by simple rules that allow predicting which future stock courses will fall with a 70% probability."
Conditional BRUNO: A Neural Process for Exchangeable Labelled Data,"Iryna Korshunova, Yarin Gal, Arthur Gretton, Joni Dambre","1 - Ghent University-IDLab Technologiepark-Zwijnaarde 15 9052 Ghent Belgium
2 - University of Oxford -Computer Science Department Oxford OX1 3QD UK
3 - University College London -Gatsby Computational Neuroscience Unit 25 Howland Street W1T 4JG London UK","We present a neural process that models exchangeable sequences of high-dimensional complex observations conditionally on a set of labels or tags. Our model combines the expressiveness of deep neural networks with the data-efficiency of Gaussian processes, resulting in a probabilistic model for which the posterior distribution is easy to evaluate and sample from, and the computational complexity scales linearly with the number of observations. The advantages of the proposed architecture are demonstrated on a challenging few-shot view reconstruction task which requires generalisation from short sequences of viewpoints. * We would like to thank Jonas Degrave and Ferenc Huszár for their conceptual contributions to this work. ♠ Shared authorship.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-35.pdf,2019,83.33333333333334,"Conditional BRUNO: A Neural Process for Exchangeable Labelled Data We present a neural process that models exchangeable sequences of high-dimensional complex observations conditionally on a set of labels or tags. Our model combines the expressiveness of deep neural networks with the data-efficiency of Gaussian processes, resulting in a probabilistic model for which the posterior distribution is easy to evaluate and sample from, and the computational complexity scales linearly with the number of observations. The advantages of the proposed architecture are demonstrated on a challenging few-shot view reconstruction task which requires generalisation from short sequences of viewpoints. * We would like to thank Jonas Degrave and Ferenc Huszár for their conceptual contributions to this work. ♠ Shared authorship."
Deep Autoencoder Feature Extraction for Fault Detection of Elevator Systems,"Krishna Mishra, Tomi Krogerus, Kalevi Huhtala",1 - Tampere University of Technology Tampere Finland,"In this research, we propose a generic deep autoencoder model for automated feature extraction from the elevator sensor data. Extracted deep features are classified with random forest algorithm for fault detection. Sensor data are labelled as healthy or faulty based on the maintenance actions recorded. In our research, we have included all fault types present for each elevator. The remaining healthy data is used for validation of the model to prove its efficacy in terms of avoiding false positives. We have achieved nearly 100% accuracy in fault detection along with avoiding false positives based on new extracted deep features, which outperform the results using existing features.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-37.pdf,2019,100.0,"Deep Autoencoder Feature Extraction for Fault Detection of Elevator Systems In this research, we propose a generic deep autoencoder model for automated feature extraction from the elevator sensor data. Extracted deep features are classified with random forest algorithm for fault detection. Sensor data are labelled as healthy or faulty based on the maintenance actions recorded. In our research, we have included all fault types present for each elevator. The remaining healthy data is used for validation of the model to prove its efficacy in terms of avoiding false positives. We have achieved nearly 100% accuracy in fault detection along with avoiding false positives based on new extracted deep features, which outperform the results using existing features."
Embeddings and Representation Learning for Structured Data,"Benjamin Paaßen, Claudio Gallicchio, Alessio Micheli, Alessandro Sperduti","1 - Bielefeld University -CITEC Inspiration 1 33619 Bielefeld Germany
2 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 56127 Pisa -Italy
4 - Department of Mathematics Via Trieste 63 University of Padova 35121 Padova Italy","Performing machine learning on structured data is complicated by the fact that such data does not have vectorial form. Therefore, multiple approaches have emerged to construct vectorial representations of structured data, from kernel and distance approaches to recurrent, recursive, and convolutional neural networks. Recent years have seen heightened attention in this demanding field of research and several new approaches have emerged, such as metric learning on structured data, graph convolutional neural networks, and recurrent decoder networks for structured data. In this contribution, we provide an high-level overview of the stateof-the-art in representation learning and embeddings for structured data across a wide range of machine learning fields. * Funding by the CITEC center of excellence (EXC 277) is gratefully acknowledged.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-4.pdf,2019,100.0,"Embeddings and Representation Learning for Structured Data Performing machine learning on structured data is complicated by the fact that such data does not have vectorial form. Therefore, multiple approaches have emerged to construct vectorial representations of structured data, from kernel and distance approaches to recurrent, recursive, and convolutional neural networks. Recent years have seen heightened attention in this demanding field of research and several new approaches have emerged, such as metric learning on structured data, graph convolutional neural networks, and recurrent decoder networks for structured data. In this contribution, we provide an high-level overview of the stateof-the-art in representation learning and embeddings for structured data across a wide range of machine learning fields. * Funding by the CITEC center of excellence (EXC 277) is gratefully acknowledged."
Variational auto-encoders with Student's t-prior,"Najmeh Abiri, Mattias Ohlsson","1 - Department of Astronomy and Theoretical Physics Lund University Sölvegatan 14A, SE-223 62 Lund Sweden
3 - Halmstad University -Center for Applied Intelligent Systems Research Kristian IV:s väg 3 SE-301 18 Halmstad Sweden","We propose a new structure for the variational auto-encoders (VAEs) prior, with the weakly informative multivariate Student's t-distribution. In the proposed model all distribution parameters are trained, thereby allowing for a more robust approximation of the underlying data distribution. We used Fashion-MNIST data in two experiments to compare the proposed VAEs with the standard Gaussian priors. Both experiments showed a better reconstruction of the images with VAEs using Student's t-prior distribution.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-42.pdf,2019,97.91666666666666,"Variational auto-encoders with Student's t-prior We propose a new structure for the variational auto-encoders (VAEs) prior, with the weakly informative multivariate Student's t-distribution. In the proposed model all distribution parameters are trained, thereby allowing for a more robust approximation of the underlying data distribution. We used Fashion-MNIST data in two experiments to compare the proposed VAEs with the standard Gaussian priors. Both experiments showed a better reconstruction of the images with VAEs using Student's t-prior distribution."
User-steering Interpretable Visualization with Probabilistic Principal Components Analysis,"Viet Vu, Benoît Frénay",1 - Faculty of Computer Science NADI Institute -PReCISE Research Center Université de Namur Rue Grandgagnage 21 5000 Namur Belgium,The lack of interpretability generally in machine learning and specifically in visualization is often encountered. Integration of user's feedbacks into visualization process is a potential solution. This paper shows that the user's knowledge expressed by the positions of fixed points in the visualization can be transferred directly into a probabilistic principal components analysis (PPCA) model to help user steer the visualization. Our proposed interactive PPCA model is evaluated with different datasets to prove the feasibility of creating explainable axes for the visualization.,Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-44.pdf,2019,77.77777777777779,User-steering Interpretable Visualization with Probabilistic Principal Components Analysis The lack of interpretability generally in machine learning and specifically in visualization is often encountered. Integration of user's feedbacks into visualization process is a potential solution. This paper shows that the user's knowledge expressed by the positions of fixed points in the visualization can be transferred directly into a probabilistic principal components analysis (PPCA) model to help user steer the visualization. Our proposed interactive PPCA model is evaluated with different datasets to prove the feasibility of creating explainable axes for the visualization.
LEAP nets for power grid perturbations,"B Donnot, B Donon, I Guyon • ‡, Z Liu, A Marot, P Panciatici, M Schoenauer, • Chalearn, Usa Upsud, / Inria, et al.",Unknown,"We propose a novel neural network embedding approach to model power transmission grids, in which high voltage lines are disconnected and re-connected with one-another from time to time, either accidentally or willfully. We call our architecture LEAP net, for Latent Encoding of Atypical Perturbation. Our method implements a form of transfer learning, permitting to train on a few source domains, then generalize to new target domains, without learning on any example of that domain. We evaluate the viability of this technique to rapidly assess curative actions that human operators take in emergency situations, using real historical data, from the French high voltage power grid.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-46.pdf,2019,100.0,"LEAP nets for power grid perturbations We propose a novel neural network embedding approach to model power transmission grids, in which high voltage lines are disconnected and re-connected with one-another from time to time, either accidentally or willfully. We call our architecture LEAP net, for Latent Encoding of Atypical Perturbation. Our method implements a form of transfer learning, permitting to train on a few source domains, then generalize to new target domains, without learning on any example of that domain. We evaluate the viability of this technique to rapidly assess curative actions that human operators take in emergency situations, using real historical data, from the French high voltage power grid."
Deep Convolutional Neural Network for Survival Estimation of Amyotrophic Lateral Sclerosis patients,"Enrico Grisan, Alessandro Zandonà, Barbara Camillo","1 - Department of Information Engineering University of Padova Via Gradenigo 6/b Padova Italy
3 - School of Imaging Sciences Biomedical Engineering -King's College London Lambeth Wing St. Thomas Hospital London UK","We propose a convolutional neural network (CNN) coupled with a fully connected top layer for survival estimation. We design an objective function to directly estimate the probability of survival at discrete time intervals, conditional to the patient not having incurred any adverse event at previous time points. We test our CNN and objective function on a large dataset of longitudinal data of patients with Amyotrophic Lateral Sclerosis (ALS). We compare our CNN and the objective function against other neural networks designed for survival analysis, and against the optimization of Cox-partial-likelihood or a simple logistic classifier. The use of our objective function outperforms both Cox-partial-likelihood and logistic classifier, independently of the network architecture, and our deep CNN provides the best results in terms of AU-ROC, accuracy and mean absolute error.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-48.pdf,2019,62.62626262626263,"Deep Convolutional Neural Network for Survival Estimation of Amyotrophic Lateral Sclerosis patients We propose a convolutional neural network (CNN) coupled with a fully connected top layer for survival estimation. We design an objective function to directly estimate the probability of survival at discrete time intervals, conditional to the patient not having incurred any adverse event at previous time points. We test our CNN and objective function on a large dataset of longitudinal data of patients with Amyotrophic Lateral Sclerosis (ALS). We compare our CNN and the objective function against other neural networks designed for survival analysis, and against the optimization of Cox-partial-likelihood or a simple logistic classifier. The use of our objective function outperforms both Cox-partial-likelihood and logistic classifier, independently of the network architecture, and our deep CNN provides the best results in terms of AU-ROC, accuracy and mean absolute error."
Metric Learning with Submodular Functions,"Jiajun Pan, Hoel Le Capitaine",1 - UMR CNRS 6004 University of Nantes LS2N Nantes France,"Metric learning mainly focuses on learning distances (or similarities) that use single feature weights with Lp norms, or pair of features with Mahalanobis distances. In this paper, we consider higher order interactions in the feature space, with the help of submodular set-functions. We propose to define a metric for continuous features based on Lovasz extension of submodular functions, and then present a dedicated metric learning approach. This is naturally at the price of higher complexity so that we use k-additive fuzzy measures to decrease this complexity, by reducing the order of interactions that are taken into account. This approach finally gives a computationally feasible problem. Experiments on various datasets show the effectiveness of the approach.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-49.pdf,2019,75.60975609756098,"Metric Learning with Submodular Functions Metric learning mainly focuses on learning distances (or similarities) that use single feature weights with Lp norms, or pair of features with Mahalanobis distances. In this paper, we consider higher order interactions in the feature space, with the help of submodular set-functions. We propose to define a metric for continuous features based on Lovasz extension of submodular functions, and then present a dedicated metric learning approach. This is naturally at the price of higher complexity so that we use k-additive fuzzy measures to decrease this complexity, by reducing the order of interactions that are taken into account. This approach finally gives a computationally feasible problem. Experiments on various datasets show the effectiveness of the approach."
Frequency Domain Transformer Networks for Video Prediction,"Hafez Farazi, Sven Behnke",1 - University of Bonn Computer Science Institute VI Autonomous Intelligent Systems Endenicher Allee 19a 53115 Bonn Germany,"The task of video prediction is forecasting the next frames given some previous frames. Despite much recent progress, this task is still challenging mainly due to high nonlinearity in the spatial domain. To address this issue, we propose a novel architecture, Frequency Domain Transformer Network (FDTN), which is an end-to-end learnable model that estimates and uses the transformations of the signal in the frequency domain. Experimental evaluations show that this approach can outperform some widely used video prediction methods like Video Ladder Network (VLN) and Predictive Gated Pyramids (PGP).",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-50.pdf,2019,100.0,"Frequency Domain Transformer Networks for Video Prediction The task of video prediction is forecasting the next frames given some previous frames. Despite much recent progress, this task is still challenging mainly due to high nonlinearity in the spatial domain. To address this issue, we propose a novel architecture, Frequency Domain Transformer Network (FDTN), which is an end-to-end learnable model that estimates and uses the transformations of the signal in the frequency domain. Experimental evaluations show that this approach can outperform some widely used video prediction methods like Video Ladder Network (VLN) and Predictive Gated Pyramids (PGP)."
Metric Learning with Relational Data,"Jiajun Pan, Hoel Le Capitaine",1 - UMR CNRS 6004 University of Nantes LS2N Nantes France,"The vast majority of metric learning approaches are meant to be applied on data described by feature vectors, with some notable exceptions such as times series, trees or graphs. The objective of this paper is to propose metric learning algorithms that consider multi-relational data. More specifically, we present a metric learning approach taking into account the features of the observations, as well as the relationships between observations. Experiments and comparisons of the two settings for a collective classification task on real-world datasets show that our method i) presents a better performance than other approaches in both settings, and ii) scales well with the volume of the data.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-51.pdf,2019,75.0,"Metric Learning with Relational Data The vast majority of metric learning approaches are meant to be applied on data described by feature vectors, with some notable exceptions such as times series, trees or graphs. The objective of this paper is to propose metric learning algorithms that consider multi-relational data. More specifically, we present a metric learning approach taking into account the features of the observations, as well as the relationships between observations. Experiments and comparisons of the two settings for a collective classification task on real-world datasets show that our method i) presents a better performance than other approaches in both settings, and ii) scales well with the volume of the data."
An evolutionary approach for optimizing weightless neural networks,"Maurizio Giordano, Massimo De Gregorio","1 - Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR -CNR) Via P. Castellino 111 -80131 Naples ITALY
2 - Istituto di Scienze Applicate e Sistemi Intelligenti ""E. Caianiello"" (ISASI -CNR) Via Campi Flegrei 34 -80078 Pozzuoli (NA) ITALY",WiSARD is a weightless neural network model using RAMs to store the function computed by each neuron rather than storing it in connection weights between neurons. Non-linearity in WiSARD is implemented by a mapping that splits the binary input into tuples of bits and associate these tuples to neurons. In this work we apply the evolutionary µ + λ algorithm [1] to make evolve an initial population of mappings toward the generation of new mappings granting significant improvements in classification accuracy in the conducted experiments.,60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-54.pdf,2019,100.0,An evolutionary approach for optimizing weightless neural networks WiSARD is a weightless neural network model using RAMs to store the function computed by each neuron rather than storing it in connection weights between neurons. Non-linearity in WiSARD is implemented by a mapping that splits the binary input into tuples of bits and associate these tuples to neurons. In this work we apply the evolutionary µ + λ algorithm [1] to make evolve an initial population of mappings toward the generation of new mappings granting significant improvements in classification accuracy in the conducted experiments.
Dimensionality Reduction in a Hydraulic Valve Positioning Application,Travis Wiens,1 - University of Saskatchewan -Dept of Mechanical Engineering Saskatoon Sk Canada,"This paper presents an application of neural network signal processing to estimate the position of a hydraulic valve spool, based on acoustic excitement of the spool's end chamber. The spool's end chamber acts somewhat like a Helmholtz resonator whose frequency response changes based on its volume (and therefore spool position). However, nonideal characteristics of the system including wave propagation effects and distributed parameters mean that estimating the volume is more complicated than simply evaluating the resonant frequency. In this case the frequency response has high dimensionality with high redundancy and noise. We present the use of linear and nonlinear principal component analysis to preprocess the frequency response data prior to neural network regression.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-55.pdf,2019,69.56521739130434,"Dimensionality Reduction in a Hydraulic Valve Positioning Application This paper presents an application of neural network signal processing to estimate the position of a hydraulic valve spool, based on acoustic excitement of the spool's end chamber. The spool's end chamber acts somewhat like a Helmholtz resonator whose frequency response changes based on its volume (and therefore spool position). However, nonideal characteristics of the system including wave propagation effects and distributed parameters mean that estimating the volume is more complicated than simply evaluating the resonant frequency. In this case the frequency response has high dimensionality with high redundancy and noise. We present the use of linear and nonlinear principal component analysis to preprocess the frequency response data prior to neural network regression."
A WNN model based on Probabilistic Quantum Memories,"Priscila Dos Santos, Rodrigo Sousa, Adenilton Da Silva","1 - S/N. Campus Dois Irmãos Universidade Federal Rural de Pernambuco -Departamento de Computação Rua Dom Manoel de Medeiros 52171-900 Recife, Pernambuco Brazil","In this work, we evaluate a Weightless Neural Network model based on a Probabilistic Quantum Memory. In order to evaluate the classification capabilities of this quantum model, we conducted classical experiments using an equivalent classical description of the Probabilist Quantum Memory algorithm. We present the first evaluation of a quantum weightless neural networks on public benchmark datasets.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-56.pdf,2019,100.0,"A WNN model based on Probabilistic Quantum Memories In this work, we evaluate a Weightless Neural Network model based on a Probabilistic Quantum Memory. In order to evaluate the classification capabilities of this quantum model, we conducted classical experiments using an equivalent classical description of the Probabilist Quantum Memory algorithm. We present the first evaluation of a quantum weightless neural networks on public benchmark datasets."
Experimental study of the neuron-level mechanisms emerging from backpropagation,"Simon Carbonnelle, Christophe De Vleeschouwer",1 - Université catholique de Louvain -ICTEAM Louvain-La-Neuve Belgium,"The backpropagation algorithm [1] is the most successful learning algorithm for training deep artificial neural networks. Its inner workings are in stark contrast with other learning rules, as it is based on a global, black box optimization procedure rather than the repetition of a local, neuron-level procedure (e.g. like hebbian learning [2]). In this paper, we present preliminary evidence suggesting that local, neuron-level mechanisms are in fact emerging during backpropagation-based training of neural networks and describe what could be key components of it.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-57.pdf,2019,100.0,"Experimental study of the neuron-level mechanisms emerging from backpropagation The backpropagation algorithm [1] is the most successful learning algorithm for training deep artificial neural networks. Its inner workings are in stark contrast with other learning rules, as it is based on a global, black box optimization procedure rather than the repetition of a local, neuron-level procedure (e.g. like hebbian learning [2]). In this paper, we present preliminary evidence suggesting that local, neuron-level mechanisms are in fact emerging during backpropagation-based training of neural networks and describe what could be key components of it."
TrIK-SVM : an alternative decomposition for kernel methods in Kreȋn spaces,Gaëlle Loosli,"1 - 1-PobRun Brioude France
2 - UMR 6158 UCA -LIMOS CNRS Clermont-Ferrand France","The proposed work aims at proposing a alternative kernel decomposition in the context of kernel machines with indefinite kernels. The original paper of KSVM (SVM in Kreȋn spaces) uses the eigendecomposition, our proposition avoids this decompostion. We explain how it can help in designing an algorithm that won't require to compute the full kernel matrix. Finally we illustrate the good behavior of the proposed method compared to KSVM.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-58.pdf,2019,91.82389937106919,"TrIK-SVM : an alternative decomposition for kernel methods in Kreȋn spaces The proposed work aims at proposing a alternative kernel decomposition in the context of kernel machines with indefinite kernels. The original paper of KSVM (SVM in Kreȋn spaces) uses the eigendecomposition, our proposition avoids this decompostion. We explain how it can help in designing an algorithm that won't require to compute the full kernel matrix. Finally we illustrate the good behavior of the proposed method compared to KSVM."
Beta Distribution Drift Detection for Adaptive Classifiers,"Lukas Fleckenstein, Sebastian Kauschke, Johannes Fürnkranz",1 - TU Darmstadt -Knowledge Engineering Group Hochschulstrasse 10 64289 Darmstadt Germany,"With today's abundant streams of data, the only constant we can rely on is change. For stream classification algorithms, it is necessary to adapt to concept drift. This can be achieved by monitoring the model error, and triggering counter measures as changes occur. In this paper, we propose a drift detection mechanism for batch-data that fits a beta distribution to the model error, and treats abnormal behavior as drift. It works with any given model, leverages prior knowledge about this model, and allows to set application-specific confidence thresholds. Experiments confirm that it performs well, in particular when drift occurs abruptly.","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-59.pdf,2019,100.0,"Beta Distribution Drift Detection for Adaptive Classifiers With today's abundant streams of data, the only constant we can rely on is change. For stream classification algorithms, it is necessary to adapt to concept drift. This can be achieved by monitoring the model error, and triggering counter measures as changes occur. In this paper, we propose a drift detection mechanism for batch-data that fits a beta distribution to the model error, and treats abnormal behavior as drift. It works with any given model, leverages prior knowledge about this model, and allows to set application-specific confidence thresholds. Experiments confirm that it performs well, in particular when drift occurs abruptly."
Societal Issues in Machine Learning: When Learning from Data is Not Enough,"Davide Bacciu, Battista Biggio, Paulo Lisboa, José Martín, Luca Oneto, Alfredo Vellido","1 - Department of Computer Science University of Pisa Italy
2 - University of Cagliari -Italy and Pluribus One -Italy
3 - Department of Applied Mathematics -Liverpool John Moores University U.K
4 - Department of Electronic Engineering Universitat de València Spain
6 - Intelligent Data Science and Artificial Intelligence Research Center (IDEAI) Universitat Politècnica de Catalunya-BarcelonaTech Spain
7 - Centro de Investigación Biomédica en Red -CIBER-BBN Spain","It has been argued that Artificial Intelligence (AI) is experiencing a fast process of commodification. Such characterization is on the interest of big IT companies, but it correctly reflects the current industrialization of AI. This phenomenon means that AI systems and products are reaching the society at large and, therefore, that societal issues related to the use of AI and Machine Learning (ML) cannot be ignored any longer. Designing ML models from this human-centered perspective means incorporating human-relevant requirements such as safety, fairness, privacy, and interpretability, but also considering broad societal issues such as ethics and legislation. These are essential aspects to foster the acceptance of ML-based technologies, as well as to ensure compliance with an evolving legislation concerning the impact of digital technologies on ethically and privacy sensitive matters. The ESANN special session for which this tutorial acts as an introduction aims to showcase the state of the art on these increasingly relevant topics among ML theoreticians and practitioners. For this purpose, we welcomed both solid contributions and preliminary relevant results showing the potential, the limitations and the challenges of new ideas, as well as refinements, or hybridizations among the different fields of research, ML and related approaches in facing real-world problems involving societal issues.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-6.pdf,2019,100.0,"Societal Issues in Machine Learning: When Learning from Data is Not Enough It has been argued that Artificial Intelligence (AI) is experiencing a fast process of commodification. Such characterization is on the interest of big IT companies, but it correctly reflects the current industrialization of AI. This phenomenon means that AI systems and products are reaching the society at large and, therefore, that societal issues related to the use of AI and Machine Learning (ML) cannot be ignored any longer. Designing ML models from this human-centered perspective means incorporating human-relevant requirements such as safety, fairness, privacy, and interpretability, but also considering broad societal issues such as ethics and legislation. These are essential aspects to foster the acceptance of ML-based technologies, as well as to ensure compliance with an evolving legislation concerning the impact of digital technologies on ethically and privacy sensitive matters. The ESANN special session for which this tutorial acts as an introduction aims to showcase the state of the art on these increasingly relevant topics among ML theoreticians and practitioners. For this purpose, we welcomed both solid contributions and preliminary relevant results showing the potential, the limitations and the challenges of new ideas, as well as refinements, or hybridizations among the different fields of research, ML and related approaches in facing real-world problems involving societal issues."
Deep Weisfeiler-Lehman Assignment Kernels via Multiple Kernel Learning,Nils Kriege,1 - Department of Computer Science TU Dortmund University Otto-Hahn-Str. 14 44227 Dortmund Germany,Kernels for structured data are commonly obtained by decomposing objects into their parts and adding up the similarities between all pairs of parts measured by a base kernel. Assignment kernels are based on an optimal bijection between the parts and have proven to be an effective alternative to the established convolution kernels. We explore how the base kernel can be learned as part of the classification problem. We build on the theory of valid assignment kernels derived from hierarchies defined on the parts. We show that the weights of this hierarchy can be optimized via multiple kernel learning. We apply this result to learn vertex similarities for the Weisfeiler-Lehman optimal assignment kernel for graph classification. We present first experimental results which demonstrate the feasibility and effectiveness of the approach.,Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-60.pdf,2019,60.0,Deep Weisfeiler-Lehman Assignment Kernels via Multiple Kernel Learning Kernels for structured data are commonly obtained by decomposing objects into their parts and adding up the similarities between all pairs of parts measured by a base kernel. Assignment kernels are based on an optimal bijection between the parts and have proven to be an effective alternative to the established convolution kernels. We explore how the base kernel can be learned as part of the classification problem. We build on the theory of valid assignment kernels derived from hierarchies defined on the parts. We show that the weights of this hierarchy can be optimized via multiple kernel learning. We apply this result to learn vertex similarities for the Weisfeiler-Lehman optimal assignment kernel for graph classification. We present first experimental results which demonstrate the feasibility and effectiveness of the approach.
Importance of user inputs while using incremental learning to personalize human activity recognition models,"Pekka Siirtola, Heli Koskimäki, Juha Röning",1 - Biomimetics and Intelligent Systems Group University of Oulu P.O. BOX 4500 FI-90014 Oulu Finland,"In this study, importance of user inputs is studied in the context of personalizing human activity recognition models using incremental learning. Inertial sensor data from three body positions are used, and the classification is based on Learn++ ensemble method. Three different approaches to update models are compared: non-supervised, semi-supervised and supervised. Non-supervised approach relies fully on predicted labels, supervised fully on user labeled data, and the proposed method for semisupervised learning, is a combination of these two. In fact, our experiments show that by relying on predicted labels with high confidence, and asking the user to label only uncertain observations (from 12% to 26% of the observations depending on the used base classifier), almost as low error rates can be achieved as by using supervised approach. In fact, the difference was less than 2%-units. Moreover, unlike non-supervised approach, semisupervised approach does not suffer from drastic concept drift, and thus, the error rate of the non-supervised approach is over 5%-units higher than using semi-supervised approach. 
 Problem statement and related work This study focuses on human activity recognition based on inertial sensor data collected using smartphone sensors. One of the main challenges of the field is that people are different: they are unique for instance in terms of physical characteristics, health state or gender. Due to this, it is shown that a model that provides accurate results for one person, does not necessarily work accurately with somebody else's data. For instance, user-independent models are not accurate if they are trained with healthy study subjects and tested with subjects who have difficulties to move  [1] . Personal recognition models provide better recognition rates, but the challenge is that they normally require personal training data, and therefore, a personal data gathering session  [2] . Our previous study  [3]  presented for the first time how incremental learning can be used to personalize activity recognition models without a separate data gathering session. The advantage of incremental learning is that models can continuously learn from streaming data, and therefore, adapt to the user's personal moving style. In addition, learning can be done without model retraining, instead, models are updated based on streaming data, and therefore, all the training data does not need to be kept stored. In the article, the idea was to base the recognition in the first place in a user-independent model, and use","Streaming data analysis, concept drift and analysis of dynamic data sets",https://www.esann.org/sites/default/files/proceedings/legacy/es2019-63.pdf,2019,100.0,"Importance of user inputs while using incremental learning to personalize human activity recognition models In this study, importance of user inputs is studied in the context of personalizing human activity recognition models using incremental learning. Inertial sensor data from three body positions are used, and the classification is based on Learn++ ensemble method. Three different approaches to update models are compared: non-supervised, semi-supervised and supervised. Non-supervised approach relies fully on predicted labels, supervised fully on user labeled data, and the proposed method for semisupervised learning, is a combination of these two. In fact, our experiments show that by relying on predicted labels with high confidence, and asking the user to label only uncertain observations (from 12% to 26% of the observations depending on the used base classifier), almost as low error rates can be achieved as by using supervised approach. In fact, the difference was less than 2%-units. Moreover, unlike non-supervised approach, semisupervised approach does not suffer from drastic concept drift, and thus, the error rate of the non-supervised approach is over 5%-units higher than using semi-supervised approach. 
 Problem statement and related work This study focuses on human activity recognition based on inertial sensor data collected using smartphone sensors. One of the main challenges of the field is that people are different: they are unique for instance in terms of physical characteristics, health state or gender. Due to this, it is shown that a model that provides accurate results for one person, does not necessarily work accurately with somebody else's data. For instance, user-independent models are not accurate if they are trained with healthy study subjects and tested with subjects who have difficulties to move  [1] . Personal recognition models provide better recognition rates, but the challenge is that they normally require personal training data, and therefore, a personal data gathering session  [2] . Our previous study  [3]  presented for the first time how incremental learning can be used to personalize activity recognition models without a separate data gathering session. The advantage of incremental learning is that models can continuously learn from streaming data, and therefore, adapt to the user's personal moving style. In addition, learning can be done without model retraining, instead, models are updated based on streaming data, and therefore, all the training data does not need to be kept stored. In the article, the idea was to base the recognition in the first place in a user-independent model, and use"
Short-term trajectory planning using reinforcement learning within a neuromorphic control architecture,"Florian Mirus, Benjamin Zorn, Jörg Conradt","1 - -BMW Group -Research New Technologies, Innovations Garching Germany
2 - Department of Electrical and Computer Engineering Technical University of Munich Munich Germany
5 - Department of Computational Science and Technology KTH Royal Institute of Technology Stockholm Sweden","In this paper, we present a first step towards neuromorphic vehicle control. We propose a modular and hierarchical system architecture entirely implemented in a spiking neuron substrate, which allows for the adjustment of individual components through either supervised or reinforcement learning as well as future deployment on dedicated neuromorphic hardware. In a sample instantiation, we investigate automated training of a neuromorphic trajectory selection module using reinforcement learning to demonstrate the general feasibility of our approach. We evaluate our system using the open-source race car simulator TORCS.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-65.pdf,2019,100.0,"Short-term trajectory planning using reinforcement learning within a neuromorphic control architecture In this paper, we present a first step towards neuromorphic vehicle control. We propose a modular and hierarchical system architecture entirely implemented in a spiking neuron substrate, which allows for the adjustment of individual components through either supervised or reinforcement learning as well as future deployment on dedicated neuromorphic hardware. In a sample instantiation, we investigate automated training of a neuromorphic trajectory selection module using reinforcement learning to demonstrate the general feasibility of our approach. We evaluate our system using the open-source race car simulator TORCS."
Visualizing Image Classification in Fourier Domain,"Florian Franzen, Chunrong Yuan",1 - Autonomous Systems Lab TH Köln University of Applied Sciences Betzdorfer Str. 2 50679 Cologne Germany,"Image classification is successfully done with Convolutional Neural Networks (CNN). Alternatively it can be done in Fourier domain avoiding the convolution process. In this work, we develop several neural networks (NN) for classifying images in Fourier domain. In order to understand and explain the behaviour of the built NNs, we visualize neuron activities and analyze the underlying patterns relevant for the learning and classification process. We have carried out comparative study based on several datasets. By using images of objects with partial occlusion, we are able to find out the parts that are important for the classification of certain objects.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-66.pdf,2019,84.0,"Visualizing Image Classification in Fourier Domain Image classification is successfully done with Convolutional Neural Networks (CNN). Alternatively it can be done in Fourier domain avoiding the convolution process. In this work, we develop several neural networks (NN) for classifying images in Fourier domain. In order to understand and explain the behaviour of the built NNs, we visualize neuron activities and analyze the underlying patterns relevant for the learning and classification process. We have carried out comparative study based on several datasets. By using images of objects with partial occlusion, we are able to find out the parts that are important for the classification of certain objects."
Predicting vehicle behaviour using LSTMs and a vector power representation for spatial positions,"Florian Mirus, Peter Blouw, Terrence Stewart, Jörg Conradt","1 - -BMW Group -Research New Technologies, Innovations Garching Germany
2 - Department of Electrical and Computer Engineering Technical University of Munich Munich Germany
3 - Centre for Theoretical Neuroscience -University of Waterloo Waterloo ON Canada
5 - Department of Computational Science and Technology KTH Royal Institute of Technology Stockholm Sweden","Predicting future vehicle behaviour is an essential task to enable safe and situation-aware automated driving. In this paper, we propose to encapsulate spatial information of multiple objects in a semantic vector-representation. Assuming that future vehicle motion is influenced not only by past positions but also by the behaviour of other traffic participants, we use this representation as input for a Long Short-Term Memory (LSTM) network for sequence to sequence prediction of vehicle positions. We train and evaluate our system on real-world driving data collected mainly on highways in southern Germany and compare it to other models for reference.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-67.pdf,2019,100.0,"Predicting vehicle behaviour using LSTMs and a vector power representation for spatial positions Predicting future vehicle behaviour is an essential task to enable safe and situation-aware automated driving. In this paper, we propose to encapsulate spatial information of multiple objects in a semantic vector-representation. Assuming that future vehicle motion is influenced not only by past positions but also by the behaviour of other traffic participants, we use this representation as input for a Long Short-Term Memory (LSTM) network for sequence to sequence prediction of vehicle positions. We train and evaluate our system on real-world driving data collected mainly on highways in southern Germany and compare it to other models for reference."
Towards a device-free passive presence detection system with Bluetooth Low Energy beacons,"Maximilian Münch, Karsten Huffstadt, Frank-Michael Schleif","1 - University of Applied Sciences Würzburg Schweinfurt
2 - Department of Computer Science Würzburg Germany","In an era of smart information systems and smart buildings, detecting, tracking and identifying the presence of attendants inside of enclosed rooms have evolved to a key challenge in the research area of smart building systems. Therefore, several types of sensing systems were proposed over the past decade to tackle these challenge. Depending on the component's arrangement, a distinction is made between so-called devicebased active and device-free passive sensing systems. Here we focus on the device-free passive concept and introduce a strategy of using Bluetooth Low Energy beacons for device-free presence detection.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-68.pdf,2019,100.0,"Towards a device-free passive presence detection system with Bluetooth Low Energy beacons In an era of smart information systems and smart buildings, detecting, tracking and identifying the presence of attendants inside of enclosed rooms have evolved to a key challenge in the research area of smart building systems. Therefore, several types of sensing systems were proposed over the past decade to tackle these challenge. Depending on the component's arrangement, a distinction is made between so-called devicebased active and device-free passive sensing systems. Here we focus on the device-free passive concept and introduce a strategy of using Bluetooth Low Energy beacons for device-free presence detection."
Learning Multimodal Fixed-Point Weights using Gradient Descent,"Lukas Enderich, Fabian Timm, Lars Rosenbaum, Wolfram Burgard, Robert Bosch, Gmbh -Automated Research",1 - University of Freiburg -Autonomous Intelligent Systems,"Due to their high computational complexity, deep neural networks are still limited to powerful processing units. To promote a reduced model complexity by dint of low-bit fixed-point quantization, we propose a gradient-based optimization strategy to generate a symmetric mixture of Gaussian modes (SGM) where each mode belongs to a particular quantization stage. We achieve 2-bit state-of-the-art performance and illustrate the model's ability for self-dependent weight adaptation during training.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-69.pdf,2019,66.12903225806453,"Learning Multimodal Fixed-Point Weights using Gradient Descent Due to their high computational complexity, deep neural networks are still limited to powerful processing units. To promote a reduced model complexity by dint of low-bit fixed-point quantization, we propose a gradient-based optimization strategy to generate a symmetric mixture of Gaussian modes (SGM) where each mode belongs to a particular quantization stage. We achieve 2-bit state-of-the-art performance and illustrate the model's ability for self-dependent weight adaptation during training."
Blind-Spot Network for Image Anomaly Detection: A New Approach to Diabetic Retinopathy Screening,"Shaon Sutradhar, José Rouco, Marcos Ortega","1 - CITIC -Research Center of Information and Communication Technology University of A Coruña Spain
2 - Department of Computer Science University of A Coruña Spain","The development of computer-aided screening (CAS) systems is motivated by the high prevalence and severity of the target disease along with the time taken to manually assess each case. This is the case with diabetic retinopathy screening, that is based on the manual grading of retinography images. The development of CAS systems, however, usually involves data-driven approaches that require extensive and usually scarce manually labeled datasets. With this in mind, we propose the use of unsupervised anomaly detection methods for screening that can take advantage of the large amount of healthy cases available. Concretely, we focus on reconstruction-based anomaly detection methods, which are usually approached with autoencoders. We propose a new network architecture, the Blind-Spot Network, that, according to the presented experiments, improves the performance of autoencoders in this setting.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-71.pdf,2019,76.04166666666666,"Blind-Spot Network for Image Anomaly Detection: A New Approach to Diabetic Retinopathy Screening The development of computer-aided screening (CAS) systems is motivated by the high prevalence and severity of the target disease along with the time taken to manually assess each case. This is the case with diabetic retinopathy screening, that is based on the manual grading of retinography images. The development of CAS systems, however, usually involves data-driven approaches that require extensive and usually scarce manually labeled datasets. With this in mind, we propose the use of unsupervised anomaly detection methods for screening that can take advantage of the large amount of healthy cases available. Concretely, we focus on reconstruction-based anomaly detection methods, which are usually approached with autoencoders. We propose a new network architecture, the Blind-Spot Network, that, according to the presented experiments, improves the performance of autoencoders in this setting."
"Trust, law and ideology in a NN agent model of the US Appellate Courts","Nestor Caticha, Felippe Alves","1 - Instituto de Física Universidade de São Paulo
2 - Caixa Postal 66318, 05315-970 São Paulo SP Brazil","Interacting NN are used to model US Appellate Court three judge panels. Agents, whose initial states have three contributions derived from common knowledge of the law, political affiliation and personality, learn by exchange of opinions, updating their state and trust about other agents. The model replicates data patterns only if initially the agents trust each other and are certain about their trust independently of party affiliation, showing evidence of ideological voting, dampening and amplification. Absence of law or party contribution destroys the theoretical-empirical agreement. We identify quantitative signatures for different levels of the law, ideological or idiosyncratic contributions.",Statistical physics of learning and inference,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-72.pdf,2019,100.0,"Trust, law and ideology in a NN agent model of the US Appellate Courts Interacting NN are used to model US Appellate Court three judge panels. Agents, whose initial states have three contributions derived from common knowledge of the law, political affiliation and personality, learn by exchange of opinions, updating their state and trust about other agents. The model replicates data patterns only if initially the agents trust each other and are certain about their trust independently of party affiliation, showing evidence of ideological voting, dampening and amplification. Absence of law or party contribution destroys the theoretical-empirical agreement. We identify quantitative signatures for different levels of the law, ideological or idiosyncratic contributions."
Chasing the Echo State Property,Claudio Gallicchio,1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 -56127 Pisa Italy,"Reservoir Computing (RC) provides an efficient way for designing dynamical recurrent neural models. While training is restricted to a simple output component, the recurrent connections are left untrained after initialization, subject to stability constraints specified by the Echo State Property (ESP). Literature conditions for the ESP typically fail to properly account for the effects of driving input signals, often limiting the potentialities of the RC approach. In this paper, we study the fundamental aspect of asymptotic stability of RC models in presence of driving input, introducing an empirical ESP index that enables to easily analyze the stability regimes of reservoirs. Results on two benchmark datasets reveal interesting insights on the dynamical properties of input-driven reservoirs, suggesting that the actual domain of ESP validity is much wider than what covered by literature conditions commonly used in RC practice.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-76.pdf,2019,100.0,"Chasing the Echo State Property Reservoir Computing (RC) provides an efficient way for designing dynamical recurrent neural models. While training is restricted to a simple output component, the recurrent connections are left untrained after initialization, subject to stability constraints specified by the Echo State Property (ESP). Literature conditions for the ESP typically fail to properly account for the effects of driving input signals, often limiting the potentialities of the RC approach. In this paper, we study the fundamental aspect of asymptotic stability of RC models in presence of driving input, introducing an empirical ESP index that enables to easily analyze the stability regimes of reservoirs. Results on two benchmark datasets reveal interesting insights on the dynamical properties of input-driven reservoirs, suggesting that the actual domain of ESP validity is much wider than what covered by literature conditions commonly used in RC practice."
PAC-Bayes and Fairness: Risk and Fairness Bounds on Distribution Dependent Fair Priors,"Luca Oneto, Michele Donini, Massimiliano Pontil","1 - DIBRIS -University of Genova Italy
2 - Istituto Italiano di Teconoligia Italy","We address the problem of algorithmic fairness: ensuring that sensitive information does not unfairly influence the outcome of a classifier. We face this issue in the PAC-Bayes framework and we present an approach which trades off and bounds the risk and the fairness of the Gibbs Classifier measured with respect to different state-of-the-art fairness measures. For this purpose, we further develop the idea that the PAC-Bayes prior can be defined based on the data-generating distribution without actually needing to know it. In particular, we define a prior and a posterior which gives more weight to functions which exhibit good generalization and fairness properties.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-77.pdf,2019,100.0,"PAC-Bayes and Fairness: Risk and Fairness Bounds on Distribution Dependent Fair Priors We address the problem of algorithmic fairness: ensuring that sensitive information does not unfairly influence the outcome of a classifier. We face this issue in the PAC-Bayes framework and we present an approach which trades off and bounds the risk and the fairness of the Gibbs Classifier measured with respect to different state-of-the-art fairness measures. For this purpose, we further develop the idea that the PAC-Bayes prior can be defined based on the data-generating distribution without actually needing to know it. In particular, we define a prior and a posterior which gives more weight to functions which exhibit good generalization and fairness properties."
Fairness and Accountability of machine learning Models in Railway Market: are Applicable Railway Laws Up to Regulate Them? *,"Charlotte Ducuing, Luca Oneto, Renzo Canepa","1 - Centre for IT & IP Law Katholieke Universiteit Leuven Belgium
2 - DIBRIS -University of Genova Italy
3 - Rete Ferroviaria Italiana Italy","This paper discusses whether the law is up to regulate machine learning (""ML"") model-based decision-making in the context of the railways. We especially deal with the fairness and accountability of these models when exploited in the context of train traffic management (""TTM""). Railway sector-specific regulation, in their quality as network industry, hereby serves as a pilot. We show that, even where technological solutions are available, the law needs to keep up to support and accurately regulate the use of the technological solutions and we identify stumble points in this regard. * This research has been supported by the European Union through the projects IN2DREAMS (European Union's Horizon 2020 research and innovation programme under grant agreement 777596). 1 Directive 2012/34/EU of the European Parliament and of the Council of 21 November 2012 establishing a single European railway area (""Recast Directive"") OJ L 343 14.12.2012, p. 32 as amended by Directive (EU) 2016/2370 of the European Parliament and of the Council of 14 December 2016 amending Directive 2012/34/EU as regards the opening of the market for domestic passenger transport services by rail and the governance of the railway infrastructure OJ L 352, 23.12.2016, p. 1-17. 2 Article 7 (b) of the Recast Directive. 3 See article 56 of the Recast Directive. 4 Article 56 (1) (h) of the Recast Directive.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-78.pdf,2019,85.36585365853658,"Fairness and Accountability of machine learning Models in Railway Market: are Applicable Railway Laws Up to Regulate Them? * This paper discusses whether the law is up to regulate machine learning (""ML"") model-based decision-making in the context of the railways. We especially deal with the fairness and accountability of these models when exploited in the context of train traffic management (""TTM""). Railway sector-specific regulation, in their quality as network industry, hereby serves as a pilot. We show that, even where technological solutions are available, the law needs to keep up to support and accurately regulate the use of the technological solutions and we identify stumble points in this regard. * This research has been supported by the European Union through the projects IN2DREAMS (European Union's Horizon 2020 research and innovation programme under grant agreement 777596). 1 Directive 2012/34/EU of the European Parliament and of the Council of 21 November 2012 establishing a single European railway area (""Recast Directive"") OJ L 343 14.12.2012, p. 32 as amended by Directive (EU) 2016/2370 of the European Parliament and of the Council of 14 December 2016 amending Directive 2012/34/EU as regards the opening of the market for domestic passenger transport services by rail and the governance of the railway infrastructure OJ L 352, 23.12.2016, p. 1-17. 2 Article 7 (b) of the Recast Directive. 3 See article 56 of the Recast Directive. 4 Article 56 (1) (h) of the Recast Directive."
Efficient learning of email similarities for customer support,"Jelle Bakker, Kerstin Bunte",1 - Faculty of Science and Engineering University of Groningen P.O. Box 407 9700 AK Groningen The Netherlands,"One way to increase customer satisfaction is efficient and consistent customer email support. In this contribution we investigate the use of dimensionality reduction, metric learning and classification methods to predict answer templates that can be used by an employee or retrieve historic conversations with potential suitable answers given an email query. The strategies are tested on email data and the publicly available Reuters data. We conclude that prototype-based metric learning is fast to train and the parameters provide a compressed representation of the database enabling efficient content based retrieval. Furthermore, learning customer email embeddings based on the similarity of employee answers is a promising direction for computer aided customer support.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-79.pdf,2019,100.0,"Efficient learning of email similarities for customer support One way to increase customer satisfaction is efficient and consistent customer email support. In this contribution we investigate the use of dimensionality reduction, metric learning and classification methods to predict answer templates that can be used by an employee or retrieve historic conversations with potential suitable answers given an email query. The strategies are tested on email data and the publicly available Reuters data. We conclude that prototype-based metric learning is fast to train and the parameters provide a compressed representation of the database enabling efficient content based retrieval. Furthermore, learning customer email embeddings based on the similarity of employee answers is a promising direction for computer aided customer support."
On overfitting of multilayer perceptrons for classification,Joseph Rynkiewicz,1 - Université Paris I -SAMM 90 rue de tolbiac Paris France,"In this paper, we consider classification models involving multilayer perceptrons (MLP) with rectified linear (ReLU) functions for activation units. It is a difficult task to study the statistical properties of such models. The main reason is that in practice these models may be heavily overparameterized. We study the asymptotic behavior of the difference between the loss function of estimated models and the loss function of the theoretical best model. These theoretical results give us information on the overfitting properties of such models. Some simulations illustrate our theoretical finding and raise new questions.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-80.pdf,2019,100.0,"On overfitting of multilayer perceptrons for classification In this paper, we consider classification models involving multilayer perceptrons (MLP) with rectified linear (ReLU) functions for activation units. It is a difficult task to study the statistical properties of such models. The main reason is that in practice these models may be heavily overparameterized. We study the asymptotic behavior of the difference between the loss function of estimated models and the loss function of the theoretical best model. These theoretical results give us information on the overfitting properties of such models. Some simulations illustrate our theoretical finding and raise new questions."
Active One-Shot Learning with Prototypical Networks,"Rinu Boney, Alexander Ilin",1 - Aalto University Espoo Finland,We consider the problem of active one-shot classification where a classifier needs to adapt to new tasks by requesting labels for one example per class from (potentially many) unlabeled examples. We propose a clustering approach to the problem. The features extracted with Prototypical Networks [1] are clustered using K-means and the label for one representative sample from each cluster is requested to label the whole cluster. We demonstrate good performance of this simple active adaptation strategy using image data.,Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-81.pdf,2019,64.70588235294117,Active One-Shot Learning with Prototypical Networks We consider the problem of active one-shot classification where a classifier needs to adapt to new tasks by requesting labels for one example per class from (potentially many) unlabeled examples. We propose a clustering approach to the problem. The features extracted with Prototypical Networks [1] are clustered using K-means and the label for one representative sample from each cluster is requested to label the whole cluster. We demonstrate good performance of this simple active adaptation strategy using image data.
Memory Efficient Weightless Neural Network using Bloom Filter,"Leandro Santiago, Leticia Verona, Fabio Rangel, Fabrício Firmino, Daniel Menasche, Wouter Caarls, Mauricio Breternitz, Sandip Kundu, Priscila Lima, Felipe França","1 - Federal University of Rio de Janeiro (UFRJ) 2-PUC Rio RJ Brazil, Brazil
6 - University of Lisbon 4-UMass Lisbon, Amherst Portugal, USA","Weightless Neural Networks (WNNs) are a kind of Artificial Neural Networks based on RAM memory broadly explored as solution for pattern recognition applications. Memory-oriented solutions for pattern recognition are typically very simple, and can be easily implemented in hardware and software. Nonetheless, the straightforward implementation of a WNN requires a large amount of memory resources making its adoption impracticable on memory constrained systems. In this paper, we propose a new model of WNN model which utilizes Bloom filters to implement RAM nodes. Bloom filters reduce memory requirements, and allow false positives when determining if a given pattern was already seen in data. We experimentally found that for pattern recognition purposes such false positives can build robustness into the system. The experimental results show that our model using Bloom filters achieves competitive accuracy, training time and testing time, consuming up to 6 orders of magnitude less memory resources in comparison with the standard Weightless Neural Network model.",60 Years of Weightless Neural Systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-83.pdf,2019,100.0,"Memory Efficient Weightless Neural Network using Bloom Filter Weightless Neural Networks (WNNs) are a kind of Artificial Neural Networks based on RAM memory broadly explored as solution for pattern recognition applications. Memory-oriented solutions for pattern recognition are typically very simple, and can be easily implemented in hardware and software. Nonetheless, the straightforward implementation of a WNN requires a large amount of memory resources making its adoption impracticable on memory constrained systems. In this paper, we propose a new model of WNN model which utilizes Bloom filters to implement RAM nodes. Bloom filters reduce memory requirements, and allow false positives when determining if a given pattern was already seen in data. We experimentally found that for pattern recognition purposes such false positives can build robustness into the system. The experimental results show that our model using Bloom filters achieves competitive accuracy, training time and testing time, consuming up to 6 orders of magnitude less memory resources in comparison with the standard Weightless Neural Network model."
Defending against Poisoning Attacks in Online Learning Settings,"Greg Collinge, Emil Lupu, Luis Muñoz-González",1 - Department of Computing -Imperial College London 180 Queen's Gate SW7 2AZ London United Kingdom,"Machine learning systems are vulnerable to data poisoning, a coordinated attack where a fraction of the training dataset is manipulated by an attacker to subvert learning. In this paper we first formulate an optimal attack strategy against online learning classifiers to assess worst-case scenarios. We also propose two defence mechanisms to mitigate the effect of online poisoning attacks by analysing the impact of the data points in the classifier and by means of an adaptive combination of machine learning classifiers with different learning rates. Our experimental evaluation supports the usefulness of our proposed defences to mitigate the effect of poisoning attacks in online learning settings.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-84.pdf,2019,63.49206349206349,"Defending against Poisoning Attacks in Online Learning Settings Machine learning systems are vulnerable to data poisoning, a coordinated attack where a fraction of the training dataset is manipulated by an attacker to subvert learning. In this paper we first formulate an optimal attack strategy against online learning classifiers to assess worst-case scenarios. We also propose two defence mechanisms to mitigate the effect of online poisoning attacks by analysing the impact of the data points in the classifier and by means of an adaptive combination of machine learning classifiers with different learning rates. Our experimental evaluation supports the usefulness of our proposed defences to mitigate the effect of poisoning attacks in online learning settings."
Minimax center to extract a common subspace from multiple datasets,"Emilie Renard, P.-A Absil, Kyle Gallivan","1 - Université catholique de Louvain -ICTEAM Institute Avenue Georges Lemaître 4 B-1348 Louvain-la-Neuve Belgium
3 - Department of Mathematics Florida State University 208 Love Building -1017 Academic Way -Tallahassee 32306-4510 FL USA","We address the problem of extracting common information from multiple datasets. More specifically, we look for a common subspace minimizing the maximal dissimilarity with all datasets and we propose an algorithm derived from the first order necessary conditions of optimality. On synthetic datasets the proposed method gives as good results as a Riemannian based approach, but also provides an evaluation on how far the iterate is from a critical point.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-87.pdf,2019,100.0,"Minimax center to extract a common subspace from multiple datasets We address the problem of extracting common information from multiple datasets. More specifically, we look for a common subspace minimizing the maximal dissimilarity with all datasets and we propose an algorithm derived from the first order necessary conditions of optimality. On synthetic datasets the proposed method gives as good results as a Riemannian based approach, but also provides an evaluation on how far the iterate is from a critical point."
Detecting Adversarial Examples with Inductive Venn-ABERS Predictors,"Jonathan Peck, Bart Goossens, Yvan Saeys","1 - Dept of Applied Mathematics, Computer Science and Statistics Ghent University 9000 Ghent Belgium
2 - -VIB Inflammation Research Center Data Mining and Modeling for Biomedicine 9052 Ghent Belgium
3 - -imec-IPI-Ghent University 9000 Ghent Belgium","Inductive Venn-ABERS predictors (IVAPs) are a type of probabilistic predictors with the theoretical guarantee that their predictions are perfectly calibrated. We propose to exploit this calibration property for the detection of adversarial examples in binary classification tasks. By rejecting predictions if the uncertainty of the IVAP is too high, we obtain an algorithm that is both accurate on the original test set and significantly more robust to adversarial examples. The method appears to be competitive to the state of the art in adversarial defense, both in terms of robustness as well as scalability. * We gratefully acknowledge the support of the NVIDIA corporation who provided us with a Titan Xp GPU to conduct our experiments under the GPU Grant Program. Jonathan Peck is sponsored by a Ph.D. fellowship of the Research Foundation -Flanders (FWO). Yvan Saeys is an ISAC Marylou Ingram Scholar.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-175.pdf,2019,67.25663716814158,"Detecting Adversarial Examples with Inductive Venn-ABERS Predictors Inductive Venn-ABERS predictors (IVAPs) are a type of probabilistic predictors with the theoretical guarantee that their predictions are perfectly calibrated. We propose to exploit this calibration property for the detection of adversarial examples in binary classification tasks. By rejecting predictions if the uncertainty of the IVAP is too high, we obtain an algorithm that is both accurate on the original test set and significantly more robust to adversarial examples. The method appears to be competitive to the state of the art in adversarial defense, both in terms of robustness as well as scalability. * We gratefully acknowledge the support of the NVIDIA corporation who provided us with a Titan Xp GPU to conduct our experiments under the GPU Grant Program. Jonathan Peck is sponsored by a Ph.D. fellowship of the Research Foundation -Flanders (FWO). Yvan Saeys is an ISAC Marylou Ingram Scholar."
Hybrid vibration signal monitoring approach for rolling element bearings,"Jarno Kansanaho, Tommi Kärkkäinen",1 - Faculty of Information Technology Jyvaskyla University of Jyvaskyla Finland,"New approach to identify different lifetime stages of rolling element bearings, to improve early bearing fault detection, is presented. We extract characteristic features from vibration signals generated by rolling element bearings. This data is first pre-labelled with an unsupervised clustering method. Then, supervised methods are used to improve the labelling. Moreover, we assess feature importance with each classifier. From the practical point of view, the classifiers are compared on how early emergence of a bearing fault is being suggested. The results show that all of the classifiers are usable for bearing fault detection and the importance of the features was consistent.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-90.pdf,2019,100.0,"Hybrid vibration signal monitoring approach for rolling element bearings New approach to identify different lifetime stages of rolling element bearings, to improve early bearing fault detection, is presented. We extract characteristic features from vibration signals generated by rolling element bearings. This data is first pre-labelled with an unsupervised clustering method. Then, supervised methods are used to improve the labelling. Moreover, we assess feature importance with each classifier. From the practical point of view, the classifiers are compared on how early emergence of a bearing fault is being suggested. The results show that all of the classifiers are usable for bearing fault detection and the importance of the features was consistent."
Noise helps optimization escape from saddle points in the neural dynamics,"Ying Fang, Zhaofei Yu, Feng Chen",1 - Department of Automation Center for Brain-Inspired Computing Research Tsinghua University 100084 Beijing China,"Synaptic connectivity in the brain is thought to encode the long-term memory of an organism. But experimental data point to surprising ongoing fluctuations in synaptic activity. Assuming that the brain computation and plasticity can be understood as probabilistic inference, one of the essential roles of noise is to efficiently improve the performance of optimization in the form of stochastic gradient descent. The strict saddle condition for synaptic plasticity is deduced and under such condition noise can help escape from saddle points on high dimensional domains. The theoretical result explains the stochasticity of synapses and guides us how to make use of noise. Our simulation results manifest that in the learning and test phase, the accuracy of synaptic sampling is almost 20% higher than that without noise.",Statistical physics of learning and inference,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-92.pdf,2019,100.0,"Noise helps optimization escape from saddle points in the neural dynamics Synaptic connectivity in the brain is thought to encode the long-term memory of an organism. But experimental data point to surprising ongoing fluctuations in synaptic activity. Assuming that the brain computation and plasticity can be understood as probabilistic inference, one of the essential roles of noise is to efficiently improve the performance of optimization in the form of stochastic gradient descent. The strict saddle condition for synaptic plasticity is deduced and under such condition noise can help escape from saddle points on high dimensional domains. The theoretical result explains the stochasticity of synapses and guides us how to make use of noise. Our simulation results manifest that in the learning and test phase, the accuracy of synaptic sampling is almost 20% higher than that without noise."
Modal sense classification with task-specific context embeddings,"Bo Li, Mathieu Dehouck, Pascal Denis","1 - UMR 8163 Univ. Lille CNRS STL -Savoirs Textes Langage 59000 Lille France
2 - INRIA Lille -Nord Europe 59650 Magnet, Villeneuve d'Ascq France","Sense disambiguation of modal constructions is a crucial part of natural language understanding. Framed as a supervised learning task, this problem heavily depends on an adequate feature representation of the modal verb context. Inspired by recent work on general word sense disambiguation, we propose a simple approach of modal sense classification in which standard shallow features are enhanced with task-specific context embedding features. Comprehensive experiments show that these enriched contextual representations fed into a simple SVM model lead to significant classification gains over shallow feature sets.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-93.pdf,2019,100.0,"Modal sense classification with task-specific context embeddings Sense disambiguation of modal constructions is a crucial part of natural language understanding. Framed as a supervised learning task, this problem heavily depends on an adequate feature representation of the modal verb context. Inspired by recent work on general word sense disambiguation, we propose a simple approach of modal sense classification in which standard shallow features are enhanced with task-specific context embedding features. Comprehensive experiments show that these enriched contextual representations fed into a simple SVM model lead to significant classification gains over shallow feature sets."
Deep RL for Autonomous Robots: Limitations and Safety Challenges,"Olov Andersson, Patrick Doherty",1 - Department of Computer Science Linköping University 581 83 Linköping Sweden,"With the rise of deep reinforcement learning, there has also been a string of successes on continuous control problems using physics simulators. This has lead to some optimism regarding use in autonomous robots and vehicles. However, to successful apply such techniques to the real world requires a firm grasp of their limitations. As recent work has raised questions of how diverse these simulation benchmarks really are, we here instead analyze a popular deep RL approach on toy examples from robot obstacle avoidance. We find that these converge very slowly, if at all, to safe policies. We identify convergence issues on stochastic environments and local minima as problems that warrant more attention for safety-critical control applications.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-97.pdf,2019,68.75,"Deep RL for Autonomous Robots: Limitations and Safety Challenges With the rise of deep reinforcement learning, there has also been a string of successes on continuous control problems using physics simulators. This has lead to some optimism regarding use in autonomous robots and vehicles. However, to successful apply such techniques to the real world requires a firm grasp of their limitations. As recent work has raised questions of how diverse these simulation benchmarks really are, we here instead analyze a popular deep RL approach on toy examples from robot obstacle avoidance. We find that these converge very slowly, if at all, to safe policies. We identify convergence issues on stochastic environments and local minima as problems that warrant more attention for safety-critical control applications."
Interpretable Dynamics Models for Data-Efficient Reinforcement Learning,"Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Ek","1 - Siemens AG Germany
2 - Technical University of Munich Germany
6 - University of Bristol United Kingdom","In this paper, we present a Bayesian view on model-based reinforcement learning. We use expert knowledge to impose structure on the transition model and present an efficient learning scheme based on variational inference. This scheme is applied to a heteroskedastic and bimodal benchmark problem on which we compare our results to NFQ and show how our approach yields human-interpretable insight about the underlying dynamics while also increasing data-efficiency. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01 IS 18049 A.",Classification and Bayesian learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-98.pdf,2019,84.50704225352112,"Interpretable Dynamics Models for Data-Efficient Reinforcement Learning In this paper, we present a Bayesian view on model-based reinforcement learning. We use expert knowledge to impose structure on the transition model and present an efficient learning scheme based on variational inference. This scheme is applied to a heteroskedastic and bimodal benchmark problem on which we compare our results to NFQ and show how our approach yields human-interpretable insight about the underlying dynamics while also increasing data-efficiency. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01 IS 18049 A."
Time Series Modeling of Market Price in Real-Time Bidding,"Manxing Du, Christian Hammerschmidt, Georgios Varisteas, Radu State, Mats Brorsson, Zhu Zhang","1 - University of Luxembourg Luxembourg
5 - The Royal Institute of Technology (KTH) Sweden
6 - Iowa State University -United States","Real-Time-Bidding (RTB) is one of the most popular online advertisement selling mechanisms. Modeling the highly dynamic bidding environment is crucial for making good bids. Market prices of auctions fluctuate heavily within short time spans. State-of-the-art methods neglect the temporal dependencies of bidders' behaviors. In this paper, the bid requests are aggregated by time and the mean market price per aggregated segment is modeled as a time series. We show that the Long Short Term Memory (LSTM) neural network outperforms the state-of-the-art univariate time series models by capturing the nonlinear temporal dependencies in the market price. We further improve the predicting performance by adding a summary of exogenous features from bid requests.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-99.pdf,2019,74.78260869565217,"Time Series Modeling of Market Price in Real-Time Bidding Real-Time-Bidding (RTB) is one of the most popular online advertisement selling mechanisms. Modeling the highly dynamic bidding environment is crucial for making good bids. Market prices of auctions fluctuate heavily within short time spans. State-of-the-art methods neglect the temporal dependencies of bidders' behaviors. In this paper, the bid requests are aggregated by time and the mean market price per aggregated segment is modeled as a time series. We show that the Long Short Term Memory (LSTM) neural network outperforms the state-of-the-art univariate time series models by capturing the nonlinear temporal dependencies in the market price. We further improve the predicting performance by adding a summary of exogenous features from bid requests."
Learning from Partially Labeled Data,"Siamak Mehrkanoon, Xiaolin Huang, Johan Suykens","1 - Department of Data Science and Knowledge Engineering Maastricht University The Netherlands
2 - Institute of Image Processing and Pattern Recognition Shanghai Jiao Tong University
3 - Department of Electrical Engineering ESAT-STADIUS, KU Leuven B-3001 Leuven Belgium","Providing sufficient labeled training data in many application domains is a laborious and costly task. Designing models that can learn from partially labeled data, or leveraging labeled data in one domain and unlabeled data in a different but related domain is of great interest in many applications. In particular, in this context one can refer to semi-supervised modelling, transfer learning, domain adaptation and multi-view learning among others. There are several possibilities for designing such models ranging from shallow to deep models. These type of models have received increasing interest due to their successful applications in real-life problems. This paper provides a brief overview of recent techniques in learning from partially labeled data.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-146,2020,66.66666666666667,"Learning from Partially Labeled Data Providing sufficient labeled training data in many application domains is a laborious and costly task. Designing models that can learn from partially labeled data, or leveraging labeled data in one domain and unlabeled data in a different but related domain is of great interest in many applications. In particular, in this context one can refer to semi-supervised modelling, transfer learning, domain adaptation and multi-view learning among others. There are several possibilities for designing such models ranging from shallow to deep models. These type of models have received increasing interest due to their successful applications in real-life problems. This paper provides a brief overview of recent techniques in learning from partially labeled data."
Object-centered Fourier Motion Estimation and Segment-Transformation Prediction,"Moritz Wolter, Angela Yao, Sven Behnke","1 - Computer Science Institute University of Bonn Endenicher Allee 19A 53115 Bonn Germany
2 - School of Computing National University of Singapore 13 Computing Drive 117417 Singapore","The ability to anticipate the future is essential for action planning in autonomous systems. To this end, learning video prediction methods have been developed, but current systems often produce blurred predictions. We address this issue by introducing an objectcentered movement estimation, frame prediction, and correction framework using frequency-domain approaches. We transform single objects based on estimated translation and rotation speeds which we correct using a learned encoding of the past. This results in clear predictions with few parameters. Experimental evaluation shows that our approach is accurate and efficient.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-100.pdf,2020,100.0,"Object-centered Fourier Motion Estimation and Segment-Transformation Prediction The ability to anticipate the future is essential for action planning in autonomous systems. To this end, learning video prediction methods have been developed, but current systems often produce blurred predictions. We address this issue by introducing an objectcentered movement estimation, frame prediction, and correction framework using frequency-domain approaches. We transform single objects based on estimated translation and rotation speeds which we correct using a learned encoding of the past. This results in clear predictions with few parameters. Experimental evaluation shows that our approach is accurate and efficient."
Sparse k-means for mixed data via group-sparse clustering,"Marie Chavent, Jerome Lacaille, Alex Mourer, Madalina Olteanu","1 - INRIA Bordeaux Sud-Ouest CQFD team France
2 - Safran Aircraft Engines -Datalab Villaroche France
5 - SAMM -EA 4543
6 - Université Pantheon Sorbonne France","The present manuscript tackles the issue of variable selection for clustering, in high dimensional data described both by numerical and categorical features. First, we build upon the sparse k-means algorithm with lasso penalty, and introduce the group-L1 penalty -already known in regression -in the unsupervised context. Second, we preprocess mixed data and transform categorical features into groups of dummy variables with appropriate scaling, on which one may then apply the group-sparse clustering procedure. The proposed method performs simultaneously clustering and feature selection, and provides meaningful partitions and meaningful features, numerical and categorical, for describing them.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-103.pdf,2020,85.96491228070175,"Sparse k-means for mixed data via group-sparse clustering The present manuscript tackles the issue of variable selection for clustering, in high dimensional data described both by numerical and categorical features. First, we build upon the sparse k-means algorithm with lasso penalty, and introduce the group-L1 penalty -already known in regression -in the unsupervised context. Second, we preprocess mixed data and transform categorical features into groups of dummy variables with appropriate scaling, on which one may then apply the group-sparse clustering procedure. The proposed method performs simultaneously clustering and feature selection, and provides meaningful partitions and meaningful features, numerical and categorical, for describing them."
Exploring the feature space of character-level embeddings,"Ivano Lauriola, Stefano Campese, Alberto Lavelli, Fabio Rinaldi, Fabio Aiolli","1 - University of Padova -Dept of Mathematics Padova Italy
2 - Fondazione Bruno Kessler I-38123 Trento Italy
6 - Dalle Molle Institute for Artificial Intelligence Research -IDSIA CH-6928 Manno Switzerland","Recently, character-level embeddings have become popular in the Natural Language Processing community. These representations provide a description of a word which depends solely on its inner structure, i.e. the sequence of characters. Convolutional and recurrent neural networks are the undisputed protagonists in this context, and they represent the state of the art for many character-level applications. In this work, we firstly compare different neural architectures against adaptive string kernels in simplified scenarios. Then, we propose a hybrid ensemble that injects structural kernel-based features into a neural architecture, providing an efficient and scalable solution. An all-around experimental assessment has been carried out on several string datasets, including biomedical entity recognition and sentiment analysis.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-104.pdf,2020,100.0,"Exploring the feature space of character-level embeddings Recently, character-level embeddings have become popular in the Natural Language Processing community. These representations provide a description of a word which depends solely on its inner structure, i.e. the sequence of characters. Convolutional and recurrent neural networks are the undisputed protagonists in this context, and they represent the state of the art for many character-level applications. In this work, we firstly compare different neural architectures against adaptive string kernels in simplified scenarios. Then, we propose a hybrid ensemble that injects structural kernel-based features into a neural architecture, providing an efficient and scalable solution. An all-around experimental assessment has been carried out on several string datasets, including biomedical entity recognition and sentiment analysis."
Explaining t-SNE Embeddings Locally by Adapting LIME,"Adrien Bibal, Minh Vu, Géraldin Nanfack, Benoît Frénay",1 - Faculty of Computer Science -PReCISE rue Grandgagnage 21 University of Namur -NADI B-5000 Namur Belgium,"Non-linear dimensionality reduction techniques, such as t-SNE, are widely used to visualize and analyze high-dimensional datasets. While non-linear projections can be of high quality, it is hard, or even impossible, to interpret the dimensions of the obtained embeddings. This paper adapts LIME to locally explain t-SNE embeddings. More precisely, the sampling and black-box-querying steps of LIME are modified so that they can be used to explain t-SNE locally. The result of the proposal is to provide, for a particular instance x and a particular t-SNE embedding Y, an interpretable model that locally explains the projection of x on Y. * The first three authors have contributed equally. G. Nanfack is funded by the EOS Ver-iLearn project n. 30992574 of the Fonds de la Recherche Scientifique (F.R.S-FNRS) in Belgium.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-105.pdf,2020,100.0,"Explaining t-SNE Embeddings Locally by Adapting LIME Non-linear dimensionality reduction techniques, such as t-SNE, are widely used to visualize and analyze high-dimensional datasets. While non-linear projections can be of high quality, it is hard, or even impossible, to interpret the dimensions of the obtained embeddings. This paper adapts LIME to locally explain t-SNE embeddings. More precisely, the sampling and black-box-querying steps of LIME are modified so that they can be used to explain t-SNE locally. The result of the proposal is to provide, for a particular instance x and a particular t-SNE embedding Y, an interpretable model that locally explains the projection of x on Y. * The first three authors have contributed equally. G. Nanfack is funded by the EOS Ver-iLearn project n. 30992574 of the Fonds de la Recherche Scientifique (F.R.S-FNRS) in Belgium."
Equilibrium Propagation for Complete Directed Neural Networks,"Matilde Farinha, Sérgio Pequito, Pedro Santos, Mário Figueiredo","1 - INESC-ID & Dept. of Mathematics IST University of Lisbon Portugal
2 - Instituto de Telecomunicações IST University of Lisbon Portugal
3 - Dept. of Industrial and Systems Engineering RPI Troy NY) USA
6 - Department of Industrial Systems and Engineering Rensselear Polytechnique Institute","Artificial neural networks, one of the most successful approaches to supervised learning, were originally inspired by their biological counterparts. However, the most successful learning algorithm for artificial neural networks, backpropagation, is considered biologically implausible. We contribute to the topic of biologically plausible neuronal learning by building upon and extending the equilibrium propagation learning framework. Specifically, we introduce: a new neuronal dynamics and learning rule for arbitrary network architectures; a sparsity-inducing method able to prune irrelevant connections; a dynamical-systems characterization of the models, using Lyapunov theory.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-106.pdf,2020,100.0,"Equilibrium Propagation for Complete Directed Neural Networks Artificial neural networks, one of the most successful approaches to supervised learning, were originally inspired by their biological counterparts. However, the most successful learning algorithm for artificial neural networks, backpropagation, is considered biologically implausible. We contribute to the topic of biologically plausible neuronal learning by building upon and extending the equilibrium propagation learning framework. Specifically, we introduce: a new neuronal dynamics and learning rule for arbitrary network architectures; a sparsity-inducing method able to prune irrelevant connections; a dynamical-systems characterization of the models, using Lyapunov theory."
Deep Recurrent Graph Neural Networks,"Luca Pasa, Nicolò Navarin, Alessandro Sperduti","1 - University of Padua -Department of Mathematics ""Tullio Levi-Civita"" via Trieste 63 35121 Padua Italy
2 - Department of Mathematics University of Padova
3 - DEEPer project","Graph Neural Networks (GNN)   show good results in classification and regression on graphs, notwithstanding most GNN models use a limited depth. In fact, they are composed of only a few stacked graph convolutional layers. One reason for this is the number of parameters growing with the number of GNN layers. In this paper, we show how using a recurrent graph convolution layer can help in building deeper GNNs, without increasing the complexity of the training phase, while improving on the predictive performances. We also analyze how the depth of the model influences the final result.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-107.pdf,2020,100.0,"Deep Recurrent Graph Neural Networks Graph Neural Networks (GNN)   show good results in classification and regression on graphs, notwithstanding most GNN models use a limited depth. In fact, they are composed of only a few stacked graph convolutional layers. One reason for this is the number of parameters growing with the number of GNN layers. In this paper, we show how using a recurrent graph convolution layer can help in building deeper GNNs, without increasing the complexity of the training phase, while improving on the predictive performances. We also analyze how the depth of the model influences the final result."
Language Grounded Task-Adaptation in Reinforcement Learning,"Matthias Hutsebaut-Buysse, Kevin Mets, Steven Latré",1 - Department of Computer Science University of Antwerp -imec Sint-Pietersvliet 7 2000 Antwerp Belgium,"Over its lifetime, a Reinforcement Learning agent is often instructed to perform different tasks. How to efficiently adapt a previously learned control policy from one task to another, remains an open research question. In this paper, we investigate how instructions formulated in natural language can enable faster and more effective task adaptation. Our proposed method is capable of assessing, given a set of developed base control policies, which base policy will be the most qualified to adapt to a new unseen task.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-108.pdf,2020,100.0,"Language Grounded Task-Adaptation in Reinforcement Learning Over its lifetime, a Reinforcement Learning agent is often instructed to perform different tasks. How to efficiently adapt a previously learned control policy from one task to another, remains an open research question. In this paper, we investigate how instructions formulated in natural language can enable faster and more effective task adaptation. Our proposed method is capable of assessing, given a set of developed base control policies, which base policy will be the most qualified to adapt to a new unseen task."
MultiMBNN: Matched and Balanced Causal Inference with Neural Networks,"Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee, Lovekesh Vig, Gautam Shroff","1 - TCS Research Delhi India
3 - Indraprastha Institute of Information Technology Delhi India","Causal inference (CI) in observational studies has received a lot of attention in healthcare, education, ad attribution, policy evaluation, etc. Confounding is a typical hazard, where the context affects both, the treatment assignment and response. In a multiple treatment scenario, we propose the neural network based MultiMBNN, where we overcome confounding by employing generalized propensity score based matching, and learning balanced representations. We benchmark the performance on synthetic and real-world datasets using PEHE, and mean absolute percentage error over ATE as metrics. MultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and Perfect Match (PM).","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-109.pdf,2020,100.0,"MultiMBNN: Matched and Balanced Causal Inference with Neural Networks Causal inference (CI) in observational studies has received a lot of attention in healthcare, education, ad attribution, policy evaluation, etc. Confounding is a typical hazard, where the context affects both, the treatment assignment and response. In a multiple treatment scenario, we propose the neural network based MultiMBNN, where we overcome confounding by employing generalized propensity score based matching, and learning balanced representations. We benchmark the performance on synthetic and real-world datasets using PEHE, and mean absolute percentage error over ATE as metrics. MultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and Perfect Match (PM)."
Estimating Individual Treatment Effects through Causal Populations Identification,"Céline Beji, Eric Benhamou, Michaël Bon, Florian Yger, Jamal Atif","1 - LAMSADE Paris-Dauphine University -PSL CNRS MILES Place du Maréchal de Lattre de Tassigny 75016 Paris FRANCE
3 - Ai Square Connect 3-AdWay Groupe Square","Estimating the Individual Treatment Effect from observational data, defined as the difference between outcomes with and without treatment or intervention, while observing just one of both, is a challenging problems in causal learning. In this paper, we formulate this problem as an inference from hidden variables and enforce causal constraints based on a model of four exclusive causal populations. We propose a new version of the EM algorithm, coined as Expected-Causality-Maximization (ECM) algorithm and provide hints on its convergence under mild conditions. We compare our algorithm to baseline methods on synthetic and real-world data and discuss its performances.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-110.pdf,2020,100.0,"Estimating Individual Treatment Effects through Causal Populations Identification Estimating the Individual Treatment Effect from observational data, defined as the difference between outcomes with and without treatment or intervention, while observing just one of both, is a challenging problems in causal learning. In this paper, we formulate this problem as an inference from hidden variables and enforce causal constraints based on a model of four exclusive causal populations. We propose a new version of the EM algorithm, coined as Expected-Causality-Maximization (ECM) algorithm and provide hints on its convergence under mild conditions. We compare our algorithm to baseline methods on synthetic and real-world data and discuss its performances."
Gaussian process regression for the estimation of stable univariate time-series processes,"Georgios Birpoutsoukis, Julien Hendrickx",1 - Université Catholique de Louvain -ICTEAM Avenue Georges Lemaître 4-6/L4.05.01 1348 Louvain-la-Neuve Belgium,"In this paper, estimation of AutoRegressive (AR) and Au-toRegressive Moving Average (ARMA) models is proposed in a Bayesian framework using a Gaussian Process Regression (GPR) approach. Impulse response properties of the underlying process to be modeled are exploited during the parameter estimation. As such, models of enhanced predictability can be consistently obtained, even in the case of large model orders. It is also proved that the proposed approach is strongly linked with the Prediction Error (PE) model estimation approaches, if the estimated parameters are regularized. Simulations are provided to illustrate the efficiency of the proposed approach.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-111.pdf,2020,100.0,"Gaussian process regression for the estimation of stable univariate time-series processes In this paper, estimation of AutoRegressive (AR) and Au-toRegressive Moving Average (ARMA) models is proposed in a Bayesian framework using a Gaussian Process Regression (GPR) approach. Impulse response properties of the underlying process to be modeled are exploited during the parameter estimation. As such, models of enhanced predictability can be consistently obtained, even in the case of large model orders. It is also proved that the proposed approach is strongly linked with the Prediction Error (PE) model estimation approaches, if the estimated parameters are regularized. Simulations are provided to illustrate the efficiency of the proposed approach."
Simplifying Deep Reservoir Architectures,"Claudio Gallicchio, Alessio Micheli, Antonio Sisbarra",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"We study the impact of architectural simplifications to the design of deep Reservoir Computing (RC) models. To do so, we analyze the effects of shaping the structure of reservoir matrices, reducing the complexity of the deep recurrent network to a minimal setup. Experimental results point out the benefits of a particularly simple deep RC architecture with ring topology in each reservoir layer and deterministically constructed input and inter-reservoir connections.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-112.pdf,2020,100.0,"Simplifying Deep Reservoir Architectures We study the impact of architectural simplifications to the design of deep Reservoir Computing (RC) models. To do so, we analyze the effects of shaping the structure of reservoir matrices, reducing the complexity of the deep recurrent network to a minimal setup. Experimental results point out the benefits of a particularly simple deep RC architecture with ring topology in each reservoir layer and deterministically constructed input and inter-reservoir connections."
Adversarial domain adaptation without gradient reversal layer,"Hugo Serieys, Aymen Cherif",1 - EURA NOVA -Research and Development Mont-Saint-Guibert Belgium,"Adversarial domain adaptation is one of the most efficient way to deal with the domain shift phenomenon that domain adaptation tries to solve. We propose an improvement to the popular GRL method introduced in [9], an unsupervised domain adaptation (i.e. no labels in the target domain) technique easy to implement. We call our method NoGRL, and it is inspired from generative adversarial networks  [11] . Our main idea is to dissociate prediction optimization and domain adaptation optimization. Our method outperforms results obtained by GRL in small images benchmarks.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-114.pdf,2020,100.0,"Adversarial domain adaptation without gradient reversal layer Adversarial domain adaptation is one of the most efficient way to deal with the domain shift phenomenon that domain adaptation tries to solve. We propose an improvement to the popular GRL method introduced in [9], an unsupervised domain adaptation (i.e. no labels in the target domain) technique easy to implement. We call our method NoGRL, and it is inspired from generative adversarial networks  [11] . Our main idea is to dissociate prediction optimization and domain adaptation optimization. Our method outperforms results obtained by GRL in small images benchmarks."
Image completion via nonnegative matrix factorization using HALS and B-splines,"Cécile Hautecoeur, François Glineur",1 - Université catholique de Louvain -CORE ICTEAM Institute B-1348 Louvain-la-Neuve Belgium,"When performing image completion, it is common to assume that images are smooth and low-rank, when viewed as matrices of pixel intensities. In this work, we use nonnegative matrix factorization to successively refine the image by representing alternatively rows and columns as smooth signals using splines. Previous work solved this model using an alternating direction method of multipliers. Instead, we propose to use a version of the hierarchical alternating least squares algorithm adapted to handle splines, and show in numerical experiments that it outperforms the existing method. Performance can be further improved by increasing progressively the size of used splines. We also introduce a non iterative algorithm using the same NMF approach, where factorization is computed in a fast and accurate way but for which convergence is harder to achieve.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-116.pdf,2020,93.87755102040816,"Image completion via nonnegative matrix factorization using HALS and B-splines When performing image completion, it is common to assume that images are smooth and low-rank, when viewed as matrices of pixel intensities. In this work, we use nonnegative matrix factorization to successively refine the image by representing alternatively rows and columns as smooth signals using splines. Previous work solved this model using an alternating direction method of multipliers. Instead, we propose to use a version of the hierarchical alternating least squares algorithm adapted to handle splines, and show in numerical experiments that it outperforms the existing method. Performance can be further improved by increasing progressively the size of used splines. We also introduce a non iterative algorithm using the same NMF approach, where factorization is computed in a fast and accurate way but for which convergence is harder to achieve."
Adapting Random Forests to Cope with Heavily Censored Datasets in Survival Analysis,"Tossapol Pomsuwan, Alex Freitas",1 - School of Computing University of Kent -Canterbury UK,"We address a survival analysis task where the goal is to predict the time passed until a subject is diagnosed with an age-related disease. The main challenge is that subjects' data are very often censored, i.e., their time to diagnosis is only partly known. We propose a new Random Forest variant to cope with censored data, and evaluate it in experiments predicting the time to diagnosis of 8 age-related diseases, for data from the English Longitudinal Study of Ageing (ELSA) database. In these experiments, the proposed Random Forest variant, in general, outperformed a well-known Random Forest variant for censored data.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-117.pdf,2020,100.0,"Adapting Random Forests to Cope with Heavily Censored Datasets in Survival Analysis We address a survival analysis task where the goal is to predict the time passed until a subject is diagnosed with an age-related disease. The main challenge is that subjects' data are very often censored, i.e., their time to diagnosis is only partly known. We propose a new Random Forest variant to cope with censored data, and evaluate it in experiments predicting the time to diagnosis of 8 age-related diseases, for data from the English Longitudinal Study of Ageing (ELSA) database. In these experiments, the proposed Random Forest variant, in general, outperformed a well-known Random Forest variant for censored data."
Investigating 3D-STDenseNet for Explainable Spatial Temporal Crime Forecasting,"Brian Maguire, Faisal Ghaffar",1 - Innovation Exchange -IBM Ireland,"Crime is a well-known social problem faced worldwide. With the availability of large city datasets, the scientific community for predictive policing has switched its focus from people-centric to place-centric, focusing on heterogeneous data points related to a particular geographic region in predicting crimes. Such data-driven techniques identify micro-level regions known as hotspots with high crime intensity. In this paper, we adapt the state-of-the-art spatial-temporal prediction model STDenseNetFus to predict crime in geographic regions in the presence of external factors such as a region's demographics, seasonal events and weather. We demonstrate that STDenseNet maintains prediction performance compared to previous results  [1]  on the same dataset despite significantly reduced parameter count. We further extend STDenseNetFus architecture from two-dimensional to three-dimensional convolutions and show that it further improves the prediction results. Finally we investigate the use of the DeepShap model explanation method to provide insights into the important input features effecting the model forecasts.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-118.pdf,2020,100.0,"Investigating 3D-STDenseNet for Explainable Spatial Temporal Crime Forecasting Crime is a well-known social problem faced worldwide. With the availability of large city datasets, the scientific community for predictive policing has switched its focus from people-centric to place-centric, focusing on heterogeneous data points related to a particular geographic region in predicting crimes. Such data-driven techniques identify micro-level regions known as hotspots with high crime intensity. In this paper, we adapt the state-of-the-art spatial-temporal prediction model STDenseNetFus to predict crime in geographic regions in the presence of external factors such as a region's demographics, seasonal events and weather. We demonstrate that STDenseNet maintains prediction performance compared to previous results  [1]  on the same dataset despite significantly reduced parameter count. We further extend STDenseNetFus architecture from two-dimensional to three-dimensional convolutions and show that it further improves the prediction results. Finally we investigate the use of the DeepShap model explanation method to provide insights into the important input features effecting the model forecasts."
Weighted Empirical Risk Minimization: Transfer Learning based on Importance Sampling,"Robin Vogel, Mastane Achab, Stéphan Clémençon, Charles Tillier","1 - IDEMIA
2 - Place Samuel de Champlain 92400 Courbevoie France
3 - 1-Télécom Paris 19 Place Marguerite Perey 91120 Palaiseau France","We consider statistical learning problems, when the distribution P of the training observations Z 1 , . . . , Z n differs from the distribution P involved in the risk one seeks to minimize (referred to as the test distribution) but is still defined on the same measurable space as P and dominates it. In the unrealistic case where the likelihood ratio Φ(z) = dP/dP (z) is known, one may straightforwardly extends the Empirical Risk Minimization (ERM) approach to this specific transfer learning setup using the same idea as that behind Importance Sampling, by minimizing a weighted version of the empirical risk functional computed from the 'biased' training data Z i with weights Φ(Z i ). Although the importance function Φ(z) is generally unknown in practice, we show that, in various situations frequently encountered in practice, it takes a simple form and can be directly estimated from the Z i 's and some auxiliary information on the statistical population P. By means of linearization techniques, we then prove that the generalization capacity of the approach aforementioned is preserved when plugging the resulting estimates of the Φ(Z i )'s into the weighted empirical risk. Beyond these theoretical guarantees, numerical results provide strong empirical evidence of the relevance of the approach promoted in this article.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-120.pdf,2020,99.40828402366864,"Weighted Empirical Risk Minimization: Transfer Learning based on Importance Sampling We consider statistical learning problems, when the distribution P of the training observations Z 1 , . . . , Z n differs from the distribution P involved in the risk one seeks to minimize (referred to as the test distribution) but is still defined on the same measurable space as P and dominates it. In the unrealistic case where the likelihood ratio Φ(z) = dP/dP (z) is known, one may straightforwardly extends the Empirical Risk Minimization (ERM) approach to this specific transfer learning setup using the same idea as that behind Importance Sampling, by minimizing a weighted version of the empirical risk functional computed from the 'biased' training data Z i with weights Φ(Z i ). Although the importance function Φ(z) is generally unknown in practice, we show that, in various situations frequently encountered in practice, it takes a simple form and can be directly estimated from the Z i 's and some auxiliary information on the statistical population P. By means of linearization techniques, we then prove that the generalization capacity of the approach aforementioned is preserved when plugging the resulting estimates of the Φ(Z i )'s into the weighted empirical risk. Beyond these theoretical guarantees, numerical results provide strong empirical evidence of the relevance of the approach promoted in this article."
Deep Learning to Detect Bacterial Colonies for the Production of Vaccines,"Thomas Beznik, Paul Smyth, Gael De Lannoy, John Lee","1 - Université catholique de Louvain Louvain-La-Neuve Belgium
2 - GSK Vaccines Rixensart Belgium","During the development of vaccines, bacterial colony forming units (CFUs) are counted in order to quantify the yield in the fermentation process. This manual task is time-consuming and error-prone. In this work we test multiple segmentation algorithms based on the U-Net CNN architecture and show that these offer robust, automated CFU counting. We show that the multiclass generalisation with a bespoke loss function allows distinguishing virulent and avirulent colonies with acceptable accuracy. While many possibilities are left to explore, our results show the potential of deep learning for separating and classifying bacterial colonies.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-122.pdf,2020,100.0,"Deep Learning to Detect Bacterial Colonies for the Production of Vaccines During the development of vaccines, bacterial colony forming units (CFUs) are counted in order to quantify the yield in the fermentation process. This manual task is time-consuming and error-prone. In this work we test multiple segmentation algorithms based on the U-Net CNN architecture and show that these offer robust, automated CFU counting. We show that the multiclass generalisation with a bespoke loss function allows distinguishing virulent and avirulent colonies with acceptable accuracy. While many possibilities are left to explore, our results show the potential of deep learning for separating and classifying bacterial colonies."
Recurrent Feedback Improves Recognition of Partially Occluded Objects,"Markus Ernst, Jochen Triesch, Thomas Burwick","1 - Frankfurt Institute for Advanced Studies Ruth Moufang Straße 1 60438 Frankfurt am Main Germany
2 - Goethe-Universität Frankfurt Max-von-Laue-Straße 1 60438 Frankfurt am Main Germany","Recurrent connectivity in the visual cortex is believed to aid object recognition for challenging conditions such as occlusion. Here we investigate if and how artificial neural networks also benefit from recurrence. We compare architectures composed of bottom-up, lateral and top-down connections and evaluate their performance using two novel stereoscopic occluded object datasets. We find that classification accuracy is significantly higher for recurrent models when compared to feedforward models of matched parametric complexity. Additionally we show that for challenging stimuli, the recurrent feedback is able to correctly revise the initial feedforward guess. * This work was supported by the European Union's Horizon 2020 research and innovation programme under grant agreement N o 713010 (GOAL-Robots, Goal-based Open-ended Autonomous Learning Robots).",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-123.pdf,2020,100.0,"Recurrent Feedback Improves Recognition of Partially Occluded Objects Recurrent connectivity in the visual cortex is believed to aid object recognition for challenging conditions such as occlusion. Here we investigate if and how artificial neural networks also benefit from recurrence. We compare architectures composed of bottom-up, lateral and top-down connections and evaluate their performance using two novel stereoscopic occluded object datasets. We find that classification accuracy is significantly higher for recurrent models when compared to feedforward models of matched parametric complexity. Additionally we show that for challenging stimuli, the recurrent feedback is able to correctly revise the initial feedforward guess. * This work was supported by the European Union's Horizon 2020 research and innovation programme under grant agreement N o 713010 (GOAL-Robots, Goal-based Open-ended Autonomous Learning Robots)."
3D U-Net for Segmentation of Plant Root MRI Images in Super-Resolution,"Yi Zhao, Nils Wandel, Magdalena Landl, Andrea Schnepf, Sven Behnke","1 - University of Bonn Computer Science Institute VI 53115 Bonn Germany
3 - Institute of Bio-and Geosciences 3 FZ Jülich GmbH 52425 Jülich Germany","Magnetic resonance imaging (MRI) enables plant scientists to non-invasively study root system development and root-soil interaction. Challenging recording conditions, such as low resolution and a high level of noise hamper the performance of traditional root extraction algorithms, though. We propose to increase signal-to-noise ratio and resolution by segmenting the scanned volumes into root and soil in super-resolution using a 3D U-Net. Tests on real data show that the trained network is capable to detect most roots successfully and even finds roots that were missed by human annotators. Our experiments show that the segmentation performance can be further improved with modifications of the loss function.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-127.pdf,2020,100.0,"3D U-Net for Segmentation of Plant Root MRI Images in Super-Resolution Magnetic resonance imaging (MRI) enables plant scientists to non-invasively study root system development and root-soil interaction. Challenging recording conditions, such as low resolution and a high level of noise hamper the performance of traditional root extraction algorithms, though. We propose to increase signal-to-noise ratio and resolution by segmenting the scanned volumes into root and soil in super-resolution using a 3D U-Net. Tests on real data show that the trained network is capable to detect most roots successfully and even finds roots that were missed by human annotators. Our experiments show that the segmentation performance can be further improved with modifications of the loss function."
Towards Adversarial Attack Resistant Deep Neural Networks,"Tiago Alves, Sandip Kundu","1 - -State Unversity of Rio de Janeiro -UERJ Rio de Janeiro Brazil
2 - University of Massachusetts -UMass Amherst MA United States","Recent publications have shown that neural network based classifiers are vulnerable to adversarial inputs that are virtually indistinguishable from normal data, constructed explicitly for the purpose of forcing misclassification. In this paper, we present several defenses to counter these threats. First, we observe that most adversarial attacks succeed by mounting gradient ascent on the confidence returned by the model, which allows adversary to gain understanding of the classification boundary. Our defenses are based on denying access to the precise classification boundary. Our first defense adds a controlled random noise to the output confidence levels, which prevents an adversary from converging in their numerical approximation attack. Our next defense is based on the observation that by varying the order of the training, often we arrive at models which offer the same classification accuracy, yet they are different numerically. An ensemble of such models allows us to randomly switch between these equivalent models during query which further blurs the classification boundary. We demonstrate our defense via an adversarial input generator which defeats previously published defenses but cannot breach the proposed defenses do to their non-static nature.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-128.pdf,2020,100.0,"Towards Adversarial Attack Resistant Deep Neural Networks Recent publications have shown that neural network based classifiers are vulnerable to adversarial inputs that are virtually indistinguishable from normal data, constructed explicitly for the purpose of forcing misclassification. In this paper, we present several defenses to counter these threats. First, we observe that most adversarial attacks succeed by mounting gradient ascent on the confidence returned by the model, which allows adversary to gain understanding of the classification boundary. Our defenses are based on denying access to the precise classification boundary. Our first defense adds a controlled random noise to the output confidence levels, which prevents an adversary from converging in their numerical approximation attack. Our next defense is based on the observation that by varying the order of the training, often we arrive at models which offer the same classification accuracy, yet they are different numerically. An ensemble of such models allows us to randomly switch between these equivalent models during query which further blurs the classification boundary. We demonstrate our defense via an adversarial input generator which defeats previously published defenses but cannot breach the proposed defenses do to their non-static nature."
On-edge adaptive acoustic models: an application to acoustic person presence detection,"Lode Vuegen, Peter Karsmakers","1 - Onderzoeksprogramma Artificiële Intelligentie (AI) Vlaanderen
2 - KU Leuven -Dept. of Computer Science (TC CS-ADVISE Kleinhoefstraat 4 B2440 Geel Belgium","This paper validates a machine learning framework that enables processing on resource limited devices. The discussed framework allows both inference and learning to be executed on the edge. More specifically, a Least-Squares Support Vector Machine (LS-SVM) framework with a time-recursive learning algorithm is evaluated in an application where person presence is estimated based on acoustic signals only. For this purpose, a real-life acoustical dataset of 555 hours was collected in an office environment for the evaluation of the on-edge machine learning framework. 
 Introduction Recent advances in the domain of 'Internet of Things' (IoT) have led to a wide range of off-the-shelf connected devices developed specifically for (indoor) monitoring applications. Today's IoT devices are known to be small, energy efficient and rather cheap allowing unobtrusive integrations in domestic and public environments at a low cost. As the amount of information an IoT device captures is increasing, shifting data processing closer to the sensor becomes more important and is known by 'on-edge processing'. On-edge processing reduces the communication bandwidth and related power consumption, and comes with the advantage that no privacy sensitive data must be transmitted. This work evaluates a machine learning framework based on a Least-Squares Support Vector Machine (LS-SVM) that enables both inference and learning on the network edge where typically only a limited amount of resources are available. For learning, a time-recursive LS-SVM strategy is adopted. This implies that all model parameters are updated in a stepwise manner from small batches of newly collected samples only and thereby reducing the required memory footprint of the embedded platform. The use of IoT-enabled devices to obtain an intelligent behaviour and to facilitate home automation gained a lot of research interest in recent years and is known by 'smart homes'  [1] . Research has shown that residential, public and commercial buildings account for 20% to 40% of the total energy demand in the developed countries  [2] . The main energy consumers are the so-called lighting, heating, ventilation and air conditioning (L-HVAC) systems and are accountable for up to 70% of the total energy consumption  [2] . Reliable presence detection could dynamically control the L-HVAC devices resulting in an overall reduced energy consumption and an improved user comfort.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-129.pdf,2020,100.0,"On-edge adaptive acoustic models: an application to acoustic person presence detection This paper validates a machine learning framework that enables processing on resource limited devices. The discussed framework allows both inference and learning to be executed on the edge. More specifically, a Least-Squares Support Vector Machine (LS-SVM) framework with a time-recursive learning algorithm is evaluated in an application where person presence is estimated based on acoustic signals only. For this purpose, a real-life acoustical dataset of 555 hours was collected in an office environment for the evaluation of the on-edge machine learning framework. 
 Introduction Recent advances in the domain of 'Internet of Things' (IoT) have led to a wide range of off-the-shelf connected devices developed specifically for (indoor) monitoring applications. Today's IoT devices are known to be small, energy efficient and rather cheap allowing unobtrusive integrations in domestic and public environments at a low cost. As the amount of information an IoT device captures is increasing, shifting data processing closer to the sensor becomes more important and is known by 'on-edge processing'. On-edge processing reduces the communication bandwidth and related power consumption, and comes with the advantage that no privacy sensitive data must be transmitted. This work evaluates a machine learning framework based on a Least-Squares Support Vector Machine (LS-SVM) that enables both inference and learning on the network edge where typically only a limited amount of resources are available. For learning, a time-recursive LS-SVM strategy is adopted. This implies that all model parameters are updated in a stepwise manner from small batches of newly collected samples only and thereby reducing the required memory footprint of the embedded platform. The use of IoT-enabled devices to obtain an intelligent behaviour and to facilitate home automation gained a lot of research interest in recent years and is known by 'smart homes'  [1] . Research has shown that residential, public and commercial buildings account for 20% to 40% of the total energy demand in the developed countries  [2] . The main energy consumers are the so-called lighting, heating, ventilation and air conditioning (L-HVAC) systems and are accountable for up to 70% of the total energy consumption  [2] . Reliable presence detection could dynamically control the L-HVAC devices resulting in an overall reduced energy consumption and an improved user comfort."
Random Projection in supervised non-stationary environments,"Moritz Heusinger, Frank-Michael Schleif",1 - Department of Computer Science UAS Würzburg-Schweinfurt Sanderheinrichsleitenweg 20 Würzburg Germany,"Random Projection (RP) is a popular and efficient technique to preprocess high-dimensional data and to reduce its dimensionality. While RP has been widely used and evaluated in stationary data analysis scenarios, non-stationary environments are not well analyzed. In this paper we provide a profound evaluation of RP on streaming data. We discuss how RP can be bounded for streaming data using the Johnson-Lindenstrauss (JL) lemma. In particular we analyze the effect of concept drift, as a key challenge for streaming data. We also provide experiments with RP on streaming data, using state-of-the-art streaming classifiers like Adaptive Hoeffding Tree, to evaluate its efficiency.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-13.pdf,2020,100.0,"Random Projection in supervised non-stationary environments Random Projection (RP) is a popular and efficient technique to preprocess high-dimensional data and to reduce its dimensionality. While RP has been widely used and evaluated in stationary data analysis scenarios, non-stationary environments are not well analyzed. In this paper we provide a profound evaluation of RP on streaming data. We discuss how RP can be bounded for streaming data using the Johnson-Lindenstrauss (JL) lemma. In particular we analyze the effect of concept drift, as a key challenge for streaming data. We also provide experiments with RP on streaming data, using state-of-the-art streaming classifiers like Adaptive Hoeffding Tree, to evaluate its efficiency."
Visualization of the Feature Space of Neural Networks,"Carlos Alaíz, Ángela Fernández, José Dorronsoro",1 - Dpto. de Ingeniería Informática & Instituto de Ingeniería del Conocimiento Universidad Autónoma de Madrid 28049 Madrid Spain,"Visualization of a learning machine can be crucial to understand its behaviour, specially in the case of (deep) neural networks, since they are quite difficult to interpret. An approach for visualizing the feature space of a neural network is presented, trying to answer to the question ""what representation of the data is the network using to make its decision?"" The proposed method gives a representation of the space where the network is tackling the problem, reducing it while respecting the linearity of the model. As shown experimentally, this technique allows to study the evolution of the model with respect to the training epochs, to have a representation of the data similar to the one used by the neural network, and even to detect groups of patterns that behave differently. * With partial support from the European Regional Development Fund and from the Spanish Ministry of Economy, Industry, and Competitiveness, project TIN2016-76406-P (AEI/FEDER, UE). Work supported also by UAM-ADIC Chair for Data Science and Machine Learning. We also acknowledge the use of the facilities of Centro de Computación Científica (CCC) at UAM.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-130.pdf,2020,100.0,"Visualization of the Feature Space of Neural Networks Visualization of a learning machine can be crucial to understand its behaviour, specially in the case of (deep) neural networks, since they are quite difficult to interpret. An approach for visualizing the feature space of a neural network is presented, trying to answer to the question ""what representation of the data is the network using to make its decision?"" The proposed method gives a representation of the space where the network is tackling the problem, reducing it while respecting the linearity of the model. As shown experimentally, this technique allows to study the evolution of the model with respect to the training epochs, to have a representation of the data similar to the one used by the neural network, and even to detect groups of patterns that behave differently. * With partial support from the European Regional Development Fund and from the Spanish Ministry of Economy, Industry, and Competitiveness, project TIN2016-76406-P (AEI/FEDER, UE). Work supported also by UAM-ADIC Chair for Data Science and Machine Learning. We also acknowledge the use of the facilities of Centro de Computación Científica (CCC) at UAM."
Theoretically Expressive and Edge-aware Graph Learning,"Federico Errica, Davide Bacciu, Alessio Micheli","1 - Department of Computer Science University of Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","We propose a new Graph Neural Network that combines recent advancements in the field. We give theoretical contributions by proving that the model is strictly more general than the Graph Isomorphism Network and the Gated Graph Neural Network, as it can approximate the same functions and deal with arbitrary edge values. Then, we show how a single node information can flow through the graph unchanged.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-132.pdf,2020,100.0,"Theoretically Expressive and Edge-aware Graph Learning We propose a new Graph Neural Network that combines recent advancements in the field. We give theoretical contributions by proving that the model is strictly more general than the Graph Isomorphism Network and the Gated Graph Neural Network, as it can approximate the same functions and deal with arbitrary edge values. Then, we show how a single node information can flow through the graph unchanged."
Sparse Metric Learning in Prototype-based Classification,"Johannes Brinkrolf, Barbara Hammer",1 - Machine Learning Group Bielefeld University Germany,"Metric learning schemes can greatly enhance distance-based classifiers, and provide additional model functionality such as interpretability in terms of feature relevance weights. In particular for high dimensional data, it is desirable to obtain sparse feature relevance weights for higher efficiency and interpretability. In this contribution, a new feature selection scheme is proposed for prototype-based classification models with adaptive metric learning. More precisely, we integrate the group lasso penalty and a subsequent optimization of sparsity while leaving the mapping invariant. We evaluate the performance on a variety of benchmarks.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-138.pdf,2020,100.0,"Sparse Metric Learning in Prototype-based Classification Metric learning schemes can greatly enhance distance-based classifiers, and provide additional model functionality such as interpretability in terms of feature relevance weights. In particular for high dimensional data, it is desirable to obtain sparse feature relevance weights for higher efficiency and interpretability. In this contribution, a new feature selection scheme is proposed for prototype-based classification models with adaptive metric learning. More precisely, we integrate the group lasso penalty and a subsequent optimization of sparsity while leaving the mapping invariant. We evaluate the performance on a variety of benchmarks."
Invariant Integration in Deep Convolutional Feature Space,"Matthias Rath, Alexandru Condurache","1 - University of Lübeck -Institute for Signal Processing
2 - Robert Bosch GmbH -Automated Driving","In this contribution, we show how to incorporate prior knowledge to a deep neural network architecture in a principled manner. We enforce feature space invariances using a novel layer based on invariant integration. This allows us to construct a complete feature space invariant to finite transformation groups. We apply our proposed layer to explicitly insert invariance properties for vision-related classification tasks, demonstrate our approach for the case of rotation invariance and report state-of-the-art performance on the Rotated-MNIST dataset. Our method is especially beneficial when training with limited data.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-140.pdf,2020,100.0,"Invariant Integration in Deep Convolutional Feature Space In this contribution, we show how to incorporate prior knowledge to a deep neural network architecture in a principled manner. We enforce feature space invariances using a novel layer based on invariant integration. This allows us to construct a complete feature space invariant to finite transformation groups. We apply our proposed layer to explicitly insert invariance properties for vision-related classification tasks, demonstrate our approach for the case of rotation invariance and report state-of-the-art performance on the Rotated-MNIST dataset. Our method is especially beneficial when training with limited data."
A Systematic Assessment of Deep Learning Models for Molecule Generation,"Davide Rigoni, Nicolò Navarin, Alessandro Sperduti","1 - University of Padua -Department of Mathematics ""Tullio Levi-Civita"" via Trieste 63 35121 Padua -Italy
2 - Fondazione Bruno Kessler via Sommarive 18 38123 Trento Italy
5 - Department of Mathematics University of Padua","In recent years the scientific community has devoted much effort in the development of deep learning models for the generation of new molecules with desirable properties (i.e. drugs). This has produced many proposals in literature. However, a systematic comparison among the different VAE methods is still missing. For this reason, we propose an extensive testbed for the evaluation of generative models for drug discovery, and we present the results obtained by many of the models proposed in literature.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-141.pdf,2020,100.0,"A Systematic Assessment of Deep Learning Models for Molecule Generation In recent years the scientific community has devoted much effort in the development of deep learning models for the generation of new molecules with desirable properties (i.e. drugs). This has produced many proposals in literature. However, a systematic comparison among the different VAE methods is still missing. For this reason, we propose an extensive testbed for the evaluation of generative models for drug discovery, and we present the results obtained by many of the models proposed in literature."
SDOstream: Low-Density Models for Streaming Outlier Detection,"Alexander Hartl, Tanja Zseby",1 - TU Wien -Institute of Telecommunications Gußhausstraße 25 1040 Vienna Austria,"Data commonly changes over time. Algorithms for anomaly detection must therefore be adapted to overcome the challenges of evolving data. We present SDOstream, a distance-based outlier detection algorithm for stream data that uses low-density models, therefore operating in linear time and avoiding the limitations of sliding windows and instance-based methods. SDOstream is designed to ensure a good integration in applications, hence the definition of ""outlier"" is not predetermined, but can be decided by the application based on distances to representative point locations. We describe the algorithm and evaluate algorithm performance with several datasets.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-143.pdf,2020,100.0,"SDOstream: Low-Density Models for Streaming Outlier Detection Data commonly changes over time. Algorithms for anomaly detection must therefore be adapted to overcome the challenges of evolving data. We present SDOstream, a distance-based outlier detection algorithm for stream data that uses low-density models, therefore operating in linear time and avoiding the limitations of sliding windows and instance-based methods. SDOstream is designed to ensure a good integration in applications, hence the definition of ""outlier"" is not predetermined, but can be decided by the application based on distances to representative point locations. We describe the algorithm and evaluate algorithm performance with several datasets."
Tensor Decompositions in Recursive Neural Networks for Tree-Structured Data,"Daniele Castellana, Davide Bacciu",1 - Dipartimento di Informatica Università di Pisa Italy,"The paper introduces two new aggregation functions to encode structural knowledge from tree-structured data. They leverage the Canonical and Tensor-Train decompositions to yield expressive context aggregation while limiting the number of model parameters. Finally, we define two novel neural recursive models for trees leveraging such aggregation functions, and we test them on two tree classification tasks, showing the advantage of proposed models when tree outdegree increases. * This work has been supported by MIUR under project SIR 2014 LIST-IT (RBSI14STDE).","Tensor Decompositions in Deep Learning - organized by Davide Bacciu (Università di Pisa, Italy), Danilo Mandic (Imperial College, United Kingdom)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-144.pdf,2020,100.0,"Tensor Decompositions in Recursive Neural Networks for Tree-Structured Data The paper introduces two new aggregation functions to encode structural knowledge from tree-structured data. They leverage the Canonical and Tensor-Train decompositions to yield expressive context aggregation while limiting the number of model parameters. Finally, we define two novel neural recursive models for trees leveraging such aggregation functions, and we test them on two tree classification tasks, showing the advantage of proposed models when tree outdegree increases. * This work has been supported by MIUR under project SIR 2014 LIST-IT (RBSI14STDE)."
ASAP -A Sub-sampling Approach for Preserving Topological Structures,"Abolfazl Taghribi, Kerstin Bunte, Michele Mastropietro, Sven De Rijcke, Peter Tino","1 - Faculty of Science and Engineering University of Groningen The Netherlands
3 - Department of Physics & Astronomy Ghent University Belgium
5 - School of Computer Science University of Birmingham UK","Topological data analysis tools enjoy increasing popularity in a wide range of applications. However, due to computational complexity, processing large number of samples of higher dimensionality quickly becomes infeasible. We propose a novel sub-sampling strategy inspired by Coulomb's law to decrease the number of data points in d-dimensional point clouds while preserving its Homology. The method is not only capable of reducing the memory and computation time needed for the construction of different types of simplicial complexes but also preserves the size of the voids in d-dimensions, which is crucial e.g. for astronomical applications. We demonstrate and compare the strategy in several synthetic scenarios and an astronomical particle simulation of a dwarf galaxy for the detection of superbubbles (supernova signatures).","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-147.pdf,2020,99.25925925925925,"ASAP -A Sub-sampling Approach for Preserving Topological Structures Topological data analysis tools enjoy increasing popularity in a wide range of applications. However, due to computational complexity, processing large number of samples of higher dimensionality quickly becomes infeasible. We propose a novel sub-sampling strategy inspired by Coulomb's law to decrease the number of data points in d-dimensional point clouds while preserving its Homology. The method is not only capable of reducing the memory and computation time needed for the construction of different types of simplicial complexes but also preserves the size of the voids in d-dimensions, which is crucial e.g. for astronomical applications. We demonstrate and compare the strategy in several synthetic scenarios and an astronomical particle simulation of a dwarf galaxy for the detection of superbubbles (supernova signatures)."
Predicting low gamma-from lower frequency band activity in electrocorticography,"Bob Dyck, Benjamin Wittevrongel, Flavio Camarrone, Ine Dauwe, Evelien Carrette, Alfred Meurs, Paul Boon, Dirk Roost, Marc Van Hulle","1 - -KU Leuven -Dept. of Computer Science Celestijnenlaan 200 A 2402 3001 LEUVEN Belgium
2 - -KU Leuven -Laboratory for Neuro-& Psychophysiology Herestraat 49 1021, 3000 Leuven Belgium
4 - -UZ Gent -Laboratory of Clinical and Experimental Neurophysiology C Heymanslaan 10 9000 Gent Belgium
8 - -UZ Gent -Dept. of Neurosurgery C Heymanslaan 10 9000 Gent Belgium","Electrocorticography (ECoG)   has witnessed increasing interest from brain modelers for spanning a broader spectral band than EEG. As human brain activity exhibits broadband modulations, we hypothesize that this should also be reflected by ECoG signal predictability across frequency bands. As a concrete case, we consider the prediction of low gamma-(40-70 Hz) from lower frequency band non-task related activity using the recently developed Block Term Tensor Regression (BTTR) algorithm. As a result, we achieved prediction accuracies up to 89% (Pearson correlation coefficient), providing evidence for a substantial degree of low gamma predictability. * Authors wish to thank the Flemish Supercomputer Center for their support and acknowledge funding from the European Union's Horizon 2020 (857375), KU Leuven (PFV/10/008, C24/18/098), and the Belgian Fund for Scientific Research -Flanders (G088314N, G0A0914N, G0A4118N, AKUL 043).","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-149.pdf,2020,94.33962264150944,"Predicting low gamma-from lower frequency band activity in electrocorticography Electrocorticography (ECoG)   has witnessed increasing interest from brain modelers for spanning a broader spectral band than EEG. As human brain activity exhibits broadband modulations, we hypothesize that this should also be reflected by ECoG signal predictability across frequency bands. As a concrete case, we consider the prediction of low gamma-(40-70 Hz) from lower frequency band non-task related activity using the recently developed Block Term Tensor Regression (BTTR) algorithm. As a result, we achieved prediction accuracies up to 89% (Pearson correlation coefficient), providing evidence for a substantial degree of low gamma predictability. * Authors wish to thank the Flemish Supercomputer Center for their support and acknowledge funding from the European Union's Horizon 2020 (857375), KU Leuven (PFV/10/008, C24/18/098), and the Belgian Fund for Scientific Research -Flanders (G088314N, G0A0914N, G0A4118N, AKUL 043)."
Model Variance for Extreme Learning Machine,"Fabian Guignard, Mohamed Laib, Mikhail Kanevski","1 - Surface Dynamics (IDYST) University of Lausanne -Institute of Earth
2 - UNIL-Mouline 1015 Lausanne Switzerland
3 - Institute for Science and Technology (LIST) IT for Innovative Services L-4362 Esch-sur-Alzette -Luxembourg Luxembourg","We derived theoretical formulas for the variance of extreme learning machine ensemble in a general case of a heteroskedastic noise. They provide a decomposition of the variance, which helps in the understanding of how the different sources of randomness contribute. The application of the proposed method to simulated datasets shows the effectiveness of the newly introduced estimations in replicating the expected variance behaviours.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-15.pdf,2020,100.0,"Model Variance for Extreme Learning Machine We derived theoretical formulas for the variance of extreme learning machine ensemble in a general case of a heteroskedastic noise. They provide a decomposition of the variance, which helps in the understanding of how the different sources of randomness contribute. The application of the proposed method to simulated datasets shows the effectiveness of the newly introduced estimations in replicating the expected variance behaviours."
Random Signal Cut for Improving Multimodal CNN Robustness of 2D Road Object Detection,"Robin Condat, Alexandrina Rogozan, Abdelaziz Bensrhair",1 - Normandie Univ -INSA Rouen LITIS Rouen France,"Given the large number of deep neural network proposals using only RGB images for 2D object detection for Advanced Driver-Assistance Systems, we propose MMRetina, a CNN taking multimodal data (RGB, Depth from Stereo, Optical Flow, LIDAR) as input for detecting road objects and their 2D localization. We introduce a new data augmentation method, we called Random Signal Cut, to make our multimodal CNN more robust to sensor malfunctions or breakdowns. The experiments show on KITTI dataset that using multimodal data with Random Signal Cut improves significantly CNN robustness without lowering its overall performances when all sensors are well functioning.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-153.pdf,2020,100.0,"Random Signal Cut for Improving Multimodal CNN Robustness of 2D Road Object Detection Given the large number of deep neural network proposals using only RGB images for 2D object detection for Advanced Driver-Assistance Systems, we propose MMRetina, a CNN taking multimodal data (RGB, Depth from Stereo, Optical Flow, LIDAR) as input for detecting road objects and their 2D localization. We introduce a new data augmentation method, we called Random Signal Cut, to make our multimodal CNN more robust to sensor malfunctions or breakdowns. The experiments show on KITTI dataset that using multimodal data with Random Signal Cut improves significantly CNN robustness without lowering its overall performances when all sensors are well functioning."
New Results on Sparse Autoencoders for Posture Classification and Segmentation,"Doreen Jirak, Stefan Wermter",1 - University of Hamburg -Knowledge Technology Vogt Kölln-Str. 30 22527 Hamburg Germany,"This paper is a sequel on posture recognition using sparse autoencoders. We conduct experiments on a posture dataset and show that shallow sparse autoencoders achieve even better performance compared to a convolutional neural network, state-of-the-art model for recognition tasks. Also, our results support robust image representation from the autoencoder model rendering further finetuning unnecessary. Finally, we suggest using sparse autoencoders for image segmentation.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-156.pdf,2020,100.0,"New Results on Sparse Autoencoders for Posture Classification and Segmentation This paper is a sequel on posture recognition using sparse autoencoders. We conduct experiments on a posture dataset and show that shallow sparse autoencoders achieve even better performance compared to a convolutional neural network, state-of-the-art model for recognition tasks. Also, our results support robust image representation from the autoencoder model rendering further finetuning unnecessary. Finally, we suggest using sparse autoencoders for image segmentation."
Lower bounds on the nonnegative rank using a nested polytopes formulation,"Julien Dewez, François Glineur",1 - ICTEAM/INMA UCLouvain CORE Avenue Georges Lemaître Louvain-la-Neuve Belgium,"Computing the nonnegative rank of a nonnegative matrix has been proven to be, in general, NP-hard  [1] . However, this quantity has many interesting applications, e.g., it can be used to compute the extension complexity of polytopes  [2] . Therefore researchers have been trying to approximate this quantity as closely as possible with strong lower and upper bounds. In this work, we introduce a new lower bound on the nonnegative rank based on a representation of the matrix as a pair of nested polytopes. The nonnegative rank then corresponds to the minimum number of vertices of any polytope nested between these two polytopes. Using the geometric concept of supporting corner, we introduce a parametrized family of computable lower bounds and present preliminary numerical results on slack matrices of regular polygons.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-157.pdf,2020,100.0,"Lower bounds on the nonnegative rank using a nested polytopes formulation Computing the nonnegative rank of a nonnegative matrix has been proven to be, in general, NP-hard  [1] . However, this quantity has many interesting applications, e.g., it can be used to compute the extension complexity of polytopes  [2] . Therefore researchers have been trying to approximate this quantity as closely as possible with strong lower and upper bounds. In this work, we introduce a new lower bound on the nonnegative rank based on a representation of the matrix as a pair of nested polytopes. The nonnegative rank then corresponds to the minimum number of vertices of any polytope nested between these two polytopes. Using the geometric concept of supporting corner, we introduce a parametrized family of computable lower bounds and present preliminary numerical results on slack matrices of regular polygons."
Resume: A Robust Framework for Professional Profile Learning & Evaluation,"Clara Gainon De Forsan De Gabriac, Amina Djelloul, Constance Scherer, Vincent Guigue, Patrick Gallinari","1 - Sorbonne Université CNRS LIP6, F-75005 Paris France","Professional Profile Extraction is a crucial challenge for any HR department. In this paper, we propose an approach to learn and evaluate professional embeddings. We first highlight the technical issues associated with this specific data; then, we propose an architecture that compares different language models to encode the textual information; finally, we learn user profiles and propose three original evaluation tasks to illustrate the strengths and weaknesses of our approach.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-158.pdf,2020,100.0,"Resume: A Robust Framework for Professional Profile Learning & Evaluation Professional Profile Extraction is a crucial challenge for any HR department. In this paper, we propose an approach to learn and evaluate professional embeddings. We first highlight the technical issues associated with this specific data; then, we propose an architecture that compares different language models to encode the textual information; finally, we learn user profiles and propose three original evaluation tasks to illustrate the strengths and weaknesses of our approach."
GraN: An Efficient Gradient-Norm Based Detector for Adversarial and Misclassified Examples,"Julia Lust, Alexandru Condurache","1 - University of Lübeck -Institute for Signal Processing
2 - Robert Bosch GmbH -Automated Driving","Deep neural networks (DNNs) are vulnerable to adversarial examples and other data perturbations. Especially in safety critical applications of DNNs, it is therefore crucial to detect misclassified samples. The current state-of-the-art detection methods require either significantly more runtime or more parameters than the original network itself. This paper therefore proposes GraN, a time-and parameter-efficient method that is easily adaptable to any DNN. GraN is based on the layer-wise norm of the DNN's gradient regarding the loss of the current input-output combination, which can be computed via backpropagation. GraN achieves state-of-the-art performance on numerous problem set-ups.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-159.pdf,2020,100.0,"GraN: An Efficient Gradient-Norm Based Detector for Adversarial and Misclassified Examples Deep neural networks (DNNs) are vulnerable to adversarial examples and other data perturbations. Especially in safety critical applications of DNNs, it is therefore crucial to detect misclassified samples. The current state-of-the-art detection methods require either significantly more runtime or more parameters than the original network itself. This paper therefore proposes GraN, a time-and parameter-efficient method that is easily adaptable to any DNN. GraN is based on the layer-wise norm of the DNN's gradient regarding the loss of the current input-output combination, which can be computed via backpropagation. GraN achieves state-of-the-art performance on numerous problem set-ups."
On Feature Selection Using Anisotropic General Regression Neural Network,"Federico Amato, Fabian Guignard, Philippe Jacquet, Mikhail Kanevski","1 - Faculty of Geosciences and Environment University of Lausanne IDYST UNIL 1015 Lausanne Switzerland
3 - Computer Center -Scientific Computing and Research Support Unit UNIL 1015 Lausanne Switzerland","The presence of irrelevant features in the input dataset tends to reduce the interpretability and predictive quality of machine learning models. Therefore, the development of feature selection methods to recognize irrelevant features is a crucial topic in machine learning. Here we show how the General Regression Neural Network used with an anisotropic Gaussian Kernel can be used to perform feature selection. A number of numerical experiments are conducted using simulated data to study the robustness of the proposed methodology and its sensitivity to sample size. Finally, a comparison with four other feature selection methods is performed on several real world datasets.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-16.pdf,2020,100.0,"On Feature Selection Using Anisotropic General Regression Neural Network The presence of irrelevant features in the input dataset tends to reduce the interpretability and predictive quality of machine learning models. Therefore, the development of feature selection methods to recognize irrelevant features is a crucial topic in machine learning. Here we show how the General Regression Neural Network used with an anisotropic Gaussian Kernel can be used to perform feature selection. A number of numerical experiments are conducted using simulated data to study the robustness of the proposed methodology and its sensitivity to sample size. Finally, a comparison with four other feature selection methods is performed on several real world datasets."
Time Series Prediction from Multiple Factors,"Perrine Cribier-Delande, Raphael Puget, Vincent Guigue, Ludovic Denoyer","1 - MLIA Sorbonne Université CNRS LIP6, F-75005 Paris France
2 - DEA-IR 1 avenue du Golf 78084 Renault, Technocentre, Guyancourt France","We propose a new neural architecture to predict time series, each depending on multiple underlying factors. Our method typically applies to spatio-temporal prediction of missing series where only certain locations and times are observed. The model is based on an encoderdecoder structure where the multiple factors are projected into a latent space which is learned by combining the latent factors coming from multiple observed series. We show on several spatio-temporal datasets that our method is able to predict missing series, not only for observed factors values, but also for new ones (e.g new locations or times).",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-160.pdf,2020,68.0,"Time Series Prediction from Multiple Factors We propose a new neural architecture to predict time series, each depending on multiple underlying factors. Our method typically applies to spatio-temporal prediction of missing series where only certain locations and times are observed. The model is based on an encoderdecoder structure where the multiple factors are projected into a latent space which is learned by combining the latent factors coming from multiple observed series. We show on several spatio-temporal datasets that our method is able to predict missing series, not only for observed factors values, but also for new ones (e.g new locations or times)."
A Distributed Neural Network Architecture for Robust Non-Linear Spatio-Temporal Prediction,"Matthias Karlbauer, Sebastian Otte, Hendrik Lensch, Thomas Scholten, Volker Wulfmeyer, Martin Butz","1 - University of Tübingen -Neuro-Cognitive Modeling Group Sand 14 72076 Tübingen Germany
3 - University of Tübingen -Computer Graphics Maria-von-Linden-Straße 6 72076 Tübingen -Germany
4 - University of Tübingen -Soil Science and Geomorphology Rümelinstraße 19-23 72070 Tübingen -Germany
5 - Institute for Physics and Meteorology Garbenstraße 30 University of Hohenheim 70599 Stuttgart Germany","DISTANA -a distributed spatio-temporal artificial neural network architecture -learns to model and predict spatio-temporal time series dynamics. It learns in a parallel, spatially distributed manner while employing a mesh of recurrent, neural prediction kernels (PKs). Individual PKs predict the local data stream and exchange information laterally. DISTANA essentially assumes that generally applicable causes, which may be locally modified, generate the observed data. We show that DISTANA scales and generalizes to large problem spaces, can approximate complex dynamics, and is robust to overfitting, outperforming other competitive ANNs.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-161.pdf,2020,100.0,"A Distributed Neural Network Architecture for Robust Non-Linear Spatio-Temporal Prediction DISTANA -a distributed spatio-temporal artificial neural network architecture -learns to model and predict spatio-temporal time series dynamics. It learns in a parallel, spatially distributed manner while employing a mesh of recurrent, neural prediction kernels (PKs). Individual PKs predict the local data stream and exchange information laterally. DISTANA essentially assumes that generally applicable causes, which may be locally modified, generate the observed data. We show that DISTANA scales and generalizes to large problem spaces, can approximate complex dynamics, and is robust to overfitting, outperforming other competitive ANNs."
Do we need hundreds of classifiers or a good feature selection?,"Laura Morán-Fernández, Verónica Bolón-Canedo, Amparo Alonso-Betanzos",1 - CITIC Universidade da Coruña Coruña Spain,"The task of choosing the appropriate classifier for a problem is not an easy-tosolve question due to the high number of algorithms available belonging to different families. Most of these classification algorithms exhibit a degradation in the performance when faced with many irrelevant and/or redundant features. Thus, in this work we analyze the impact of feature selection in classification. Experimental results over ten synthetic datasets show that the significance of selecting a classifier decreases after applying an appropriate preprocessing step and, not only this alleviates the choice, but it also improves the results in almost all classifiers tested.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-167.pdf,2020,100.0,"Do we need hundreds of classifiers or a good feature selection? The task of choosing the appropriate classifier for a problem is not an easy-tosolve question due to the high number of algorithms available belonging to different families. Most of these classification algorithms exhibit a degradation in the performance when faced with many irrelevant and/or redundant features. Thus, in this work we analyze the impact of feature selection in classification. Experimental results over ten synthetic datasets show that the significance of selecting a classifier decreases after applying an appropriate preprocessing step and, not only this alleviates the choice, but it also improves the results in almost all classifiers tested."
Detection of elementary particles with the WiSARD n-tuple classifier,"Pedro Xavier, Massimo De Gregorio, Felipe França, Priscila Lima","1 - ISASI/CNR NA Italy
2 - Universidade Federal do Rio de Janeiro 1-POLI 2-NCE 3-PESC RJ COPPE, Brazil","This work presents a weightless neural network model that learns multiple elementary particle collision phenomena. Having the AT-LAS Higgs Boson Machine Learning Challenge as the target dataset, a couple of abstractions were developed in order to achieve a fast and simple algorithm that would otherwise require much more sophisticated tools. Experimental results over the Higgs Boson τ -τ decay and the B + meson decay shows that the WiSARD n-tuple classifier provide a generic and lightweight method for studying a broad range of particle decay modes.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-170.pdf,2020,100.0,"Detection of elementary particles with the WiSARD n-tuple classifier This work presents a weightless neural network model that learns multiple elementary particle collision phenomena. Having the AT-LAS Higgs Boson Machine Learning Challenge as the target dataset, a couple of abstractions were developed in order to achieve a fast and simple algorithm that would otherwise require much more sophisticated tools. Experimental results over the Higgs Boson τ -τ decay and the B + meson decay shows that the WiSARD n-tuple classifier provide a generic and lightweight method for studying a broad range of particle decay modes."
Automatic Pain Intensity Recognition: Training Set Selection based on Outliers and Centroids,"Peter Bellmann, Patrick Thiam, Friedhelm Schwenker","1 - Ulm University -Institute of Neural Information Processing James-Franck-Ring 89081 Ulm Germany
3 - Institute of Medical Systems Biology Ulm University Albert-Einstein-Allee 11 89081 Ulm Germany","In this study, we evaluate a person independent pain intensity recognition task, based on the BioVid Heat Pain Database. Previous works show that for such classification tasks, the overall performance can be increased by reducing the training data, based on certain criteria, such as different distance measures. This results in considering only a certain amount of participants from the training set, whose data distributions are defined to be the most similar to the data distribution of the participant from the test set. Counterintuitively, we propose to remove participants, which are identified as central points, from the training set, completely independent from the test set. Our evaluations show that this approach can lead to significant improvement of classification accuracy. * We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research. The work of Peter Bellmann and Friedhelm Schwenker is supported by the project Multimodal recognition of affect over the course of a tutorial learning experiment (SCHW623/7-1) funded by the German Research Foundation (DFG).",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-171.pdf,2020,100.0,"Automatic Pain Intensity Recognition: Training Set Selection based on Outliers and Centroids In this study, we evaluate a person independent pain intensity recognition task, based on the BioVid Heat Pain Database. Previous works show that for such classification tasks, the overall performance can be increased by reducing the training data, based on certain criteria, such as different distance measures. This results in considering only a certain amount of participants from the training set, whose data distributions are defined to be the most similar to the data distribution of the participant from the test set. Counterintuitively, we propose to remove participants, which are identified as central points, from the training set, completely independent from the test set. Our evaluations show that this approach can lead to significant improvement of classification accuracy. * We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research. The work of Peter Bellmann and Friedhelm Schwenker is supported by the project Multimodal recognition of affect over the course of a tutorial learning experiment (SCHW623/7-1) funded by the German Research Foundation (DFG)."
Fréchet Mean Computation in Graph Space through Projected Block Gradient Descent,"Nicolas Boria, Benjamin Negrevergne, Florian Yger",1 - LAMSADE CNRS PSL-Université Paris Dauphine Place du Marécal de Lattre de Tassigny Paris France,"A fundamental concept in statistics is the concept of Fréchet sample mean. While its computation is a simple task in Euclidian space, the same does not hold for less structured spaces such as the space of graphs, where concepts of distance or mid-point can be hard to compute. We present some work in progress regarding new distance measures and new algorithms to compute the Fréchet mean in the space of Graphs.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-172.pdf,2020,100.0,"Fréchet Mean Computation in Graph Space through Projected Block Gradient Descent A fundamental concept in statistics is the concept of Fréchet sample mean. While its computation is a simple task in Euclidian space, the same does not hold for less structured spaces such as the space of graphs, where concepts of distance or mid-point can be hard to compute. We present some work in progress regarding new distance measures and new algorithms to compute the Fréchet mean in the space of Graphs."
Sequence Classification using Ensembles of Recurrent Generative Expert Modules,"Marius Hobbhahn, Martin Butz, Sarah Fabi, Sebastian Otte",1 - University of Tübingen -Neuro-Cognitive Modeling Group Sand 14 72076 Tübingen Germany,"Successful discriminative deep learning relies on large amounts of data and proper domain coverage. We introduce an ensemble of recurrent generative modules, achieving robust and effective sequence classification facing sparse data. Each module is an expert for only a few variations of a certain class. Given an input trajectory, the latent codes of the experts are adapted via back-propagation of the reconstruction error and the most accurate expert yields the class. In comparison with direct discriminative models, our approach achieves better classification rates with fewer training examples, can be easily extended, and provides fully transparent decisions.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-174.pdf,2020,100.0,"Sequence Classification using Ensembles of Recurrent Generative Expert Modules Successful discriminative deep learning relies on large amounts of data and proper domain coverage. We introduce an ensemble of recurrent generative modules, achieving robust and effective sequence classification facing sparse data. Each module is an expert for only a few variations of a certain class. Given an input trajectory, the latent codes of the experts are adapted via back-propagation of the reconstruction error and the most accurate expert yields the class. In comparison with direct discriminative models, our approach achieves better classification rates with fewer training examples, can be easily extended, and provides fully transparent decisions."
Attacking Model Sets with Adversarial Examples,"István Megyeri, István Hegedűs, Márk Jelasity","1 - University of Szeged Hungary
4 - -MTA-SZTE Research Group on Artificial Intelligence Hungary","Adversarial input perturbation is a well-studied problem in machine learning. Here, we introduce a generalized variant of this problem, where we look for adversarial examples that satisfy multiple constraints simultaneously over a set of multi-class models. For example, we might want to force an entire set of models to make the same mistake over the same example, in order to create transferable attacks. Or we might want to fool just a single model, without fooling the rest of the models, in order to target only a specific manufacturer. Known attacks are not directly suitable for addressing this problem. The generated example has to satisfy multiple constraints and no feasible solution may exist for any amount of perturbation. We introduce an iterative heuristic algorithm inspired by the DeepFool attack. We evaluate our method over the MNIST and CIFAR-10 data sets. We show that it can find feasible multi-model adversarial perturbations, and that the magnitude of these perturbations is similar to the single model case.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-175.pdf,2020,100.0,"Attacking Model Sets with Adversarial Examples Adversarial input perturbation is a well-studied problem in machine learning. Here, we introduce a generalized variant of this problem, where we look for adversarial examples that satisfy multiple constraints simultaneously over a set of multi-class models. For example, we might want to force an entire set of models to make the same mistake over the same example, in order to create transferable attacks. Or we might want to fool just a single model, without fooling the rest of the models, in order to target only a specific manufacturer. Known attacks are not directly suitable for addressing this problem. The generated example has to satisfy multiple constraints and no feasible solution may exist for any amount of perturbation. We introduce an iterative heuristic algorithm inspired by the DeepFool attack. We evaluate our method over the MNIST and CIFAR-10 data sets. We show that it can find feasible multi-model adversarial perturbations, and that the magnitude of these perturbations is similar to the single model case."
Compressive Learning of Generative Networks,"Vincent Schellekens, Laurent Jacques",1 - ISPGroup ICTEAM Louvain-La-Neuve UCLouvain Belgium,"Generative networks implicitly approximate complex densities from their sampling with impressive accuracy. However, because of the enormous scale of modern datasets, this training process is often computationally expensive. We cast generative network training into the recent framework of compressive learning: we reduce the computational burden of large-scale datasets by first harshly compressing them in a single pass as a single sketch vector. We then propose a cost function, which approximates the Maximum Mean Discrepancy metric, but requires only this sketch, which makes it time-and memory-efficient to optimize.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-176.pdf,2020,100.0,"Compressive Learning of Generative Networks Generative networks implicitly approximate complex densities from their sampling with impressive accuracy. However, because of the enormous scale of modern datasets, this training process is often computationally expensive. We cast generative network training into the recent framework of compressive learning: we reduce the computational burden of large-scale datasets by first harshly compressing them in a single pass as a single sketch vector. We then propose a cost function, which approximates the Maximum Mean Discrepancy metric, but requires only this sketch, which makes it time-and memory-efficient to optimize."
An agile machine learning project in pharmadeveloping a Mask R-CNN-based web application for bacterial colony counting,"Tanguy Naets, Maarten Huijsmans, Laurent Sorber, Paul Smyth, Gaël De Lannoy","1 - GSK Vaccines Rixensart Belgium
3 - 1-Radix.ai Brussels Belgium","We present a web application to assist lab technicians with the counting of different types of bacteria colonies. We use a Mask R-CNN model trained and tuned specifically to detect the number of BVG+ (virulent) and BVG-(avirulent) colonies. We achieve a mAPIoU=.5 of 94 %. With these encouraging results, we see opportunities to bring the benefits of improved accuracy and time saved to nearby problems and labs such as generalising to other bacteria types and viral foci counting.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-178.pdf,2020,90.3765690376569,"An agile machine learning project in pharmadeveloping a Mask R-CNN-based web application for bacterial colony counting We present a web application to assist lab technicians with the counting of different types of bacteria colonies. We use a Mask R-CNN model trained and tuned specifically to detect the number of BVG+ (virulent) and BVG-(avirulent) colonies. We achieve a mAPIoU=.5 of 94 %. With these encouraging results, we see opportunities to bring the benefits of improved accuracy and time saved to nearby problems and labs such as generalising to other bacteria types and viral foci counting."
Understanding and improving unsupervised training of Boltzmann machines,"Gorka Muñoz-Gil, Alejandro Pozas-Kerstjens, Miguel Angel Garcia-March, Maciej Lewenstein, Przemys Law, R Grzybowski","1 - ICFO-Institut de Ciencies Fotoniques
2 - The Barcelona Institute of Science and Technology 08860 Castelldefels Barcelona Spain
9 - ICREA Passeig Lluis Companys 23 08010 Barcelona Spain
10 - Faculty of Physics Adam Mickiewicz University Umultowska 85 61-614 Poznań Poland","We have analyzed the training of Boltzmann machines under the perspective of statistical physics. We argue that training models in spin-glass regime is highly inefficient and unnecessary. To that end, previously we have presented RAPID, a method to control the frustration of spin models and to train them without the need of expensive sampling methods. In this contribution we study effects of initialising Boltzmann machines in easily sampling regime and training with standard methods.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-180.pdf,2020,99.29078014184397,"Understanding and improving unsupervised training of Boltzmann machines We have analyzed the training of Boltzmann machines under the perspective of statistical physics. We argue that training models in spin-glass regime is highly inefficient and unnecessary. To that end, previously we have presented RAPID, a method to control the frustration of spin models and to train them without the need of expensive sampling methods. In this contribution we study effects of initialising Boltzmann machines in easily sampling regime and training with standard methods."
Problem Transformation Methods with Distance-Based Learning for Multi-Target Regression,"Joonas Hämäläinen, Tommi Kärkkäinen",1 - Faculty of Information Technology University of Jyvaskyla University of Jyvaskyla P.O. Box 35 FI-40014 Finland,"Multi-target regression is a special subset of supervised machine learning problems. Problem transformation methods are used in the field to improve the performance of basic methods. The purpose of this article is to test the use of recently popularized distance-based methods, the minimal learning machine (MLM) and the extreme minimal learning machine (EMLM), in problem transformation. The main advantage of the full data variants of these methods is the lack of any meta-parameter. The experimental results for the MLM and EMLM show promising potential, emphasizing the utility of the problem transformation especially with the EMLM.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-181.pdf,2020,100.0,"Problem Transformation Methods with Distance-Based Learning for Multi-Target Regression Multi-target regression is a special subset of supervised machine learning problems. Problem transformation methods are used in the field to improve the performance of basic methods. The purpose of this article is to test the use of recently popularized distance-based methods, the minimal learning machine (MLM) and the extreme minimal learning machine (EMLM), in problem transformation. The main advantage of the full data variants of these methods is the lack of any meta-parameter. The experimental results for the MLM and EMLM show promising potential, emphasizing the utility of the problem transformation especially with the EMLM."
Respiratory Pattern Recognition from Low-Resolution Thermal Imaging,"Salla Aario, Ajinkya Gorad, Miika Arvonen, Simo Särkkä","1 - Aalto University -Dept. of Electrical Engineering and Automation Otakaari 3 Espoo Finland
3 - Kuopio University Hospital -Dept. of Paediatrics Puijonlaaksontie 2 Kuopio Finland","Remote monitoring of vital signs has a wide range of applications. In this paper we propose a method to identify respiratory patterns from low-resolution thermal video data using a nearest neighbor data association (NNDA) and nearest neighbor Kalman filter (NNKF) based algorithms along with multi-class support vector machine (SVM). The method in this work is evaluated against breathing belt data as a reference, collected from healthy volunteers. Correlation of the proposed method with airflow derived from the breathing belt was found to be 0.7. The SVM classifier is able to distinguish between the breathing patterns from derived airflow with 60% accuracy.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-182.pdf,2020,100.0,"Respiratory Pattern Recognition from Low-Resolution Thermal Imaging Remote monitoring of vital signs has a wide range of applications. In this paper we propose a method to identify respiratory patterns from low-resolution thermal video data using a nearest neighbor data association (NNDA) and nearest neighbor Kalman filter (NNKF) based algorithms along with multi-class support vector machine (SVM). The method in this work is evaluated against breathing belt data as a reference, collected from healthy volunteers. Correlation of the proposed method with airflow derived from the breathing belt was found to be 0.7. The SVM classifier is able to distinguish between the breathing patterns from derived airflow with 60% accuracy."
Improving Light-weight Convolutional Neural Networks for Face Recognition Targeting Resource Constrained Platforms,"Iulian Felea, Radu Dogaru","1 - University ""Politehnica"" of Bucharest Dept. of Applied Electronics and Information Engineering Splaiul Independenței 313 Romania","A thorough investigation of the possibility to optimize deep convolutional neural network architectures for face recognition problems is considered, from the perspective of training very compact models to be further deployed on resource-constrained systems. Latencies in recognition phase and memory usage are minimized while recognition accuracies are maintained close to state of the art performance of more complicated deep neural networks. Using two widely used datasets, namely VGG-Face and YouTube Faces, several modifications of a recent light-weight CNN model are proposed, and for a reasonable accuracy the most compact solutions were identified. Experiments on VGG-Face show that our proposed models achieves 95.5% accuracy, with 5.6 times less memory storage when compared to the reference slim model.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-185.pdf,2020,100.0,"Improving Light-weight Convolutional Neural Networks for Face Recognition Targeting Resource Constrained Platforms A thorough investigation of the possibility to optimize deep convolutional neural network architectures for face recognition problems is considered, from the perspective of training very compact models to be further deployed on resource-constrained systems. Latencies in recognition phase and memory usage are minimized while recognition accuracies are maintained close to state of the art performance of more complicated deep neural networks. Using two widely used datasets, namely VGG-Face and YouTube Faces, several modifications of a recent light-weight CNN model are proposed, and for a reasonable accuracy the most compact solutions were identified. Experiments on VGG-Face show that our proposed models achieves 95.5% accuracy, with 5.6 times less memory storage when compared to the reference slim model."
Softmax Recurrent Unit: A new type of RNN cell,"Lucas Vos, Twan Van Laarhoven","1 - Faculty of Management, Science and Technology Heerlen Open University of the Netherlands The Netherlands
3 - Radboud University -Institute for Computing and Information Science Nijmegen The Netherlands","Recurrent Neural Networks (RNNs) have been very successful in many state-of-the-art solutions for natural language tasks like machine translation. However, LSTM, the most common RNN cell, is complex and utilizes a lot of components. We present the Softmax Recurrent Unit (SMRU), a novel and elegant design of a new type of RNN cell. The SMRU has a simple structure, which is solely based around the softmax function. We present four different variants of the SMRU and compare them to both the LSTM and GRU on various tasks and datasets. These experiments show that the SMRU achieves competitive performance, surpassing either the LSTM or the GRU on any the given task, while having a much simpler design.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-187.pdf,2020,100.0,"Softmax Recurrent Unit: A new type of RNN cell Recurrent Neural Networks (RNNs) have been very successful in many state-of-the-art solutions for natural language tasks like machine translation. However, LSTM, the most common RNN cell, is complex and utilizes a lot of components. We present the Softmax Recurrent Unit (SMRU), a novel and elegant design of a new type of RNN cell. The SMRU has a simple structure, which is solely based around the softmax function. We present four different variants of the SMRU and compare them to both the LSTM and GRU on various tasks and datasets. These experiments show that the SMRU achieves competitive performance, surpassing either the LSTM or the GRU on any the given task, while having a much simpler design."
Variational Mixture of Normalizing Flows,"Guilherme Freitas, Mário Figueiredo",1 - Instituto de Telecomunicações and Instituto Superior Técnico University of Lisbon Portugal,"In the past few years, deep generative models, such as generative adversarial networks, variational autoencoders, and their variants, have seen wide adoption for the task of modelling complex data distributions. In spite of the outstanding sample quality achieved by those methods, they model the target distributions implicitly, in the sense that the probability density functions approximated by them are not explicitly accessible. This fact renders those methods unfit for tasks that require, for example, scoring new instances of data with the learned distributions. Normalizing flows overcome this limitation by leveraging the change-ofvariables formula for probability density functions, and by using transformations designed to have tractable and cheaply computable Jacobians. Although flexible, this framework lacked (until the publication of recent work) a way to introduce discrete structure (such as the one found in mixtures) in the models it allows to construct, in an unsupervised scenario. The present work overcomes this by using normalizing flows as components in a mixture model, and devising a training procedure for such a model. This procedure is based on variational inference, and uses a variational posterior parameterized by a neural network. As will become clear, this model naturally lends itself to (multimodal) density estimation, semisupervised learning, and clustering. The proposed model is evaluated on two synthetic datasets, as well as on a real-world dataset.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-188.pdf,2020,97.5,"Variational Mixture of Normalizing Flows In the past few years, deep generative models, such as generative adversarial networks, variational autoencoders, and their variants, have seen wide adoption for the task of modelling complex data distributions. In spite of the outstanding sample quality achieved by those methods, they model the target distributions implicitly, in the sense that the probability density functions approximated by them are not explicitly accessible. This fact renders those methods unfit for tasks that require, for example, scoring new instances of data with the learned distributions. Normalizing flows overcome this limitation by leveraging the change-ofvariables formula for probability density functions, and by using transformations designed to have tractable and cheaply computable Jacobians. Although flexible, this framework lacked (until the publication of recent work) a way to introduce discrete structure (such as the one found in mixtures) in the models it allows to construct, in an unsupervised scenario. The present work overcomes this by using normalizing flows as components in a mixture model, and devising a training procedure for such a model. This procedure is based on variational inference, and uses a variational posterior parameterized by a neural network. As will become clear, this model naturally lends itself to (multimodal) density estimation, semisupervised learning, and clustering. The proposed model is evaluated on two synthetic datasets, as well as on a real-world dataset."
Adversarials −1 in Speech Recognition: Detection and Defence,"Nils Worzyk, Stefan Niewerth, Oliver Kramer","1 - University of Oldenburg -Dept. of Computing Science 26129 Oldenburg Germany
2 - https://github.com/mozilla/DeepSpeech","Systems that accept voice commands have become established in our daily lives. To process those commands, modern systems usually use neural networks, which have been shown to be very successful. Nevertheless, they are vulnerable against adversarial attacks-slightly perturbed inputs, to fool the system, but are not recognizable by humans. In this work we extend the adversarial −1 concept, introduced in the image domain, to the speech recognition domain. By adapting the methodology we are able to identify adversarial inputs, in certain cases, with an accuracy of 99.9%, while still detecting benign inputs with an accuracy of 99.8%, for the investigated attacks. Furthermore, we present a technique to restore the correct label of an adversarial input, with up to 67.6% accuracy. All program code for this work can be found on https://github.com/OLStefan/Adversarials-1Speech-Recognition.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-190.pdf,2020,95.7983193277311,"Adversarials −1 in Speech Recognition: Detection and Defence Systems that accept voice commands have become established in our daily lives. To process those commands, modern systems usually use neural networks, which have been shown to be very successful. Nevertheless, they are vulnerable against adversarial attacks-slightly perturbed inputs, to fool the system, but are not recognizable by humans. In this work we extend the adversarial −1 concept, introduced in the image domain, to the speech recognition domain. By adapting the methodology we are able to identify adversarial inputs, in certain cases, with an accuracy of 99.9%, while still detecting benign inputs with an accuracy of 99.8%, for the investigated attacks. Furthermore, we present a technique to restore the correct label of an adversarial input, with up to 67.6% accuracy. All program code for this work can be found on https://github.com/OLStefan/Adversarials-1Speech-Recognition."
Anomaly Detection Approach in Cyber Security for User and Entity Behavior Analytics System,"Vladimir Uliukha, Alexey Lukashin, Lev Utkin, M Ikhail Popov, Anna Eldo",1 - Peter the Great St. Petersburg Polytechnic University Research Laboratory of Neural Network Technologies and Artificial Intelligence Saint Petersburg Russia,"This paper presents a prototype of an intelligent system for advanced analytics for integrated security of complex information and cyberphysical systems with the implementation of analytical models and software developed in Peter the Great St. Petersburg Polytechnic University . The article discusses the practical aspects of the application of unsupervised machine learning methods to the tasks of identifying abnormal objects in the field of information security in computer networks. The format of presenting initial data on various events in computer networks is described, as well as the process of preparing a training set for machine learning. The results of detecting anomalies by the Isolation Forest and Local Outlier Factor methods are presented, as well as an analysis of the results. * The reported study was funded by RFBR, project number 19-29-01004.","Machine Learning Applied to Computer Networks - organized by Alexander Gepperth (University of Applied Sciences Fulda, Germany), Sebastian Rieger (University of Applied Sciences Fulda, Deutschland)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-191.pdf,2020,100.0,"Anomaly Detection Approach in Cyber Security for User and Entity Behavior Analytics System This paper presents a prototype of an intelligent system for advanced analytics for integrated security of complex information and cyberphysical systems with the implementation of analytical models and software developed in Peter the Great St. Petersburg Polytechnic University . The article discusses the practical aspects of the application of unsupervised machine learning methods to the tasks of identifying abnormal objects in the field of information security in computer networks. The format of presenting initial data on various events in computer networks is described, as well as the process of preparing a training set for machine learning. The results of detecting anomalies by the Isolation Forest and Local Outlier Factor methods are presented, as well as an analysis of the results. * The reported study was funded by RFBR, project number 19-29-01004."
Missing Image Data Imputation using Variational Autoencoders with Weighted Loss,"Ricardo Pereira, Joana Santos, José Amorim, Pedro Rodrigues, Pedro Abreu, Alameda Hernâni, Porto","1 - Centre for Informatics and Systems University of Coimbra
2 - Department of Informatics Engineering Pólo II Pinhal de Marrocos 3030-290 Coimbra Portugal
7 - IPO-Porto Research Centre -CI-IPOP Rua Dr. António Bernardino de Almeida 4200-072 Porto Portugal
8 - Center for Health Technology and Services Research Faculty of Medicine University of Porto","Missing data is an issue often addressed with imputation strategies that replace the missing values with plausible ones. A trend in these strategies is the use of generative models, one being Variational Autoencoders. However, the default loss function of this method gives the same importance to all data, while a more suitable solution should focus on the missing values. In this work an extension of this method with a custom loss function is introduced (Variational Autoencoder with Weighted Loss). The method was compared with state-of-the-art generative models and the results showed improvements higher than 40% in several settings.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-193.pdf,2020,100.0,"Missing Image Data Imputation using Variational Autoencoders with Weighted Loss Missing data is an issue often addressed with imputation strategies that replace the missing values with plausible ones. A trend in these strategies is the use of generative models, one being Variational Autoencoders. However, the default loss function of this method gives the same importance to all data, while a more suitable solution should focus on the missing values. In this work an extension of this method with a custom loss function is introduced (Variational Autoencoder with Weighted Loss). The method was compared with state-of-the-art generative models and the results showed improvements higher than 40% in several settings."
Binary and Multi-label Defect Classification of Printed Circuit Boards based on Transfer Learning,"Leandro De, S Silva, Agostinho Júnior, Bruno Fernandes, George Azevedo, Sergio Oliveira","1 - Universidade de Pernambuco -Escola Politécnica de Pernambuco Rua Benfica 455 Recife PE, Brazil
2 - Instituto Federal de Educação Ciência e Tecnologia da Paraíba (IFPB) Rua José Antônio da Silva 300 Cajazeiras PB, Brazil","Automatic optical inspection for printed circuit boards (PCB) is an important step to assure quality control in electronic manufacturing. Recently deep learning models have been used to detect and classify PCB defects. Since public PCB datasets usually are not large enough to train deep models from scratch, transfer learning has proved to be an effective strategy to overcome this limitation. In this paper we evaluate the influence of input image size for non-referential binary classification of PCB images from the DeepPCB dataset and moving further we evaluated a multi-label classification, both based on transfer learning. The best models achieved 99.5% accuracy for binary classification and mean accuracy of 95.16% for multi-label classification.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-194.pdf,2020,99.48186528497409,"Binary and Multi-label Defect Classification of Printed Circuit Boards based on Transfer Learning Automatic optical inspection for printed circuit boards (PCB) is an important step to assure quality control in electronic manufacturing. Recently deep learning models have been used to detect and classify PCB defects. Since public PCB datasets usually are not large enough to train deep models from scratch, transfer learning has proved to be an effective strategy to overcome this limitation. In this paper we evaluate the influence of input image size for non-referential binary classification of PCB images from the DeepPCB dataset and moving further we evaluated a multi-label classification, both based on transfer learning. The best models achieved 99.5% accuracy for binary classification and mean accuracy of 95.16% for multi-label classification."
Approximating Archetypal Analysis Using Quantum Annealing,"Sebastian Feld, Christoph Roch, Katja Geirhos, Thomas Gabor",1 - LMU Munich -Mobile and Distributed Systems Group Oettingenstr. 67 80538 Munich Germany,"Archetypes are those extreme values of a data set that can jointly represent all other data points. They often have descriptive meanings and can thus contribute to the understanding of the data. Such archetypes are identified using archetypal analysis and all data points are represented as convex combinations thereof. In this work, archetypal analysis is linked with quantum annealing. For both steps, i.e. the determination of archetypes and the assignment of data points, we derive a QUBO formulation which is solved on D-Wave's 2000Q Quantum Annealer. For selected data sets, called toy and iris, our quantum annealing-based approach can achieve similar results to the original R-package ""archetypes"".","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-195.pdf,2020,100.0,"Approximating Archetypal Analysis Using Quantum Annealing Archetypes are those extreme values of a data set that can jointly represent all other data points. They often have descriptive meanings and can thus contribute to the understanding of the data. Such archetypes are identified using archetypal analysis and all data points are represented as convex combinations thereof. In this work, archetypal analysis is linked with quantum annealing. For both steps, i.e. the determination of archetypes and the assignment of data points, we derive a QUBO formulation which is solved on D-Wave's 2000Q Quantum Annealer. For selected data sets, called toy and iris, our quantum annealing-based approach can achieve similar results to the original R-package ""archetypes""."
CNN Encoder to Reduce the Dimensionality of Data Image for Motion Planning,"Janderson Ferreira, Agostinho Júnior, Yves Galvão, Bruno Fernandes, Pablo Barros","1 - Universidade de Pernambuco -Escola Politécnica de Pernambuco Rua Benfica 455 Recife PE, Brazil
6 - Cognitive Architecture for Collaborative Technologies (CONTACT) Unit Istituto Italiano di Tecnologia Genova Italy","Many real-world applications need path planning algorithms to solve tasks in different areas, such as social applications, autonomous cars, and tracking activities. And most importantly motion planning. Although the use of path planning is sufficient in most motion planning scenarios, they represent potential bottlenecks in large environments with dynamic changes. To tackle this problem, the number of possible routes could be reduced to make it easier for path planning algorithms to find the shortest path with less efforts. An traditional algorithm for path planning is the A*, it uses an heuristic to work faster than other solutions. In this work, we propose a CNN encoder capable of eliminating useless routes for motion planning problems, then we combine the proposed neural network output with A*. To measure the efficiency of our solution, we propose a database with different scenarios of motion planning problems. The evaluated metric is the number of the iterations to find the shortest path. The A* was compared with the CNN Encoder (proposal) with A*. In all evaluated scenarios, our solution reduced the number of iterations by more than 60%.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-196.pdf,2020,100.0,"CNN Encoder to Reduce the Dimensionality of Data Image for Motion Planning Many real-world applications need path planning algorithms to solve tasks in different areas, such as social applications, autonomous cars, and tracking activities. And most importantly motion planning. Although the use of path planning is sufficient in most motion planning scenarios, they represent potential bottlenecks in large environments with dynamic changes. To tackle this problem, the number of possible routes could be reduced to make it easier for path planning algorithms to find the shortest path with less efforts. An traditional algorithm for path planning is the A*, it uses an heuristic to work faster than other solutions. In this work, we propose a CNN encoder capable of eliminating useless routes for motion planning problems, then we combine the proposed neural network output with A*. To measure the efficiency of our solution, we propose a database with different scenarios of motion planning problems. The evaluated metric is the number of the iterations to find the shortest path. The A* was compared with the CNN Encoder (proposal) with A*. In all evaluated scenarios, our solution reduced the number of iterations by more than 60%."
Explorations in Quantum Neural Networks with Intermediate Measurements,"Lukas Franken, Bogdan Georgiev","1 - Fraunhofer IAIS -Research Center for ML ML2R, Birlinghoven -53757 Schloss, Sankt Augustin","In this short note we explore a few quantum circuits with the particular goal of basic image recognition. The models we study are inspired by recent progress in Quantum Convolution Neural Networks (QCNN)  [12] . We present a few experimental results, where we attempt to learn basic image patterns motivated by scaling down the MNIST dataset. * We would like to thank the Fraunhofer IAIS, the Research Center for Machine Learning IAIS, and the Competence Center for Machine Learning Rhine-Ruhr ML2R, for the excellent working conditions. We would also like to thank Prof.C. Bauckhage for the encouragement and fruitful discussions","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-197.pdf,2020,100.0,"Explorations in Quantum Neural Networks with Intermediate Measurements In this short note we explore a few quantum circuits with the particular goal of basic image recognition. The models we study are inspired by recent progress in Quantum Convolution Neural Networks (QCNN)  [12] . We present a few experimental results, where we attempt to learn basic image patterns motivated by scaling down the MNIST dataset. * We would like to thank the Fraunhofer IAIS, the Research Center for Machine Learning IAIS, and the Competence Center for Machine Learning Rhine-Ruhr ML2R, for the excellent working conditions. We would also like to thank Prof.C. Bauckhage for the encouragement and fruitful discussions"
A survey of Machine Learning applied to Computer Networks,"Alexander Gepperth, Sebastian Rieger",1 - Fulda University of Applied Sciences -Applied Computer Science Leipziger Straße 123 36037 Fulda Germany,"We review the current state of the art in the domain of machine learning applied to computer networks. First of all, we describe recent developments in computer networking and outline the potential fields for machine learning that arise from these developments. We discuss challenges for machine learning in this particular field, namely the inherent big data aspect of computer networks, and the fact that learning very often needs to be conducted in a streaming setting with non-stationary data distributions. We discuss practical issues like privacy protection and computing resources before finally outlining potential technological benefits of this emerging scientific field.","Machine Learning Applied to Computer Networks - organized by Alexander Gepperth (University of Applied Sciences Fulda, Germany), Sebastian Rieger (University of Applied Sciences Fulda, Deutschland)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-2.pdf,2020,87.71929824561404,"A survey of Machine Learning applied to Computer Networks We review the current state of the art in the domain of machine learning applied to computer networks. First of all, we describe recent developments in computer networking and outline the potential fields for machine learning that arise from these developments. We discuss challenges for machine learning in this particular field, namely the inherent big data aspect of computer networks, and the fact that learning very often needs to be conducted in a streaming setting with non-stationary data distributions. We discuss practical issues like privacy protection and computing resources before finally outlining potential technological benefits of this emerging scientific field."
Fast Deep Neural Networks Convergence using a Weightless Neural Model,"Alan Bacellar, Brunno Goldstein, Victor Ferreira, Leandro Santiago, Priscila Lima, Felipe França",1 - Federal University of Rio de Janeiro (UFRJ) Rio de Janeiro Brazil,"Deep Neural Networks (DNNs) have surged as a promising technique for AI applications combining a huge parametric space with efficient learning algorithms. The efficiency of the training procedure relies on some optimization algorithms which adjust the initial weights to minimize the loss of the model. Such strategies are essential to speed up the convergence of the optimization steps. Nonetheless, a general initialization procedure is still an open problem since the proposed techniques either require a long processing time or take a considerable number of iterations to figure out an acceptable model. This work presents a weight initialization strategy using transfer learning via Weightless Neural Network (WNN). This WNN initialization strategy reaches up to 5.5× accuracy and 15× loss reduction at the first iterations when compared against well-known techniques such as Xavier and He.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-200.pdf,2020,100.0,"Fast Deep Neural Networks Convergence using a Weightless Neural Model Deep Neural Networks (DNNs) have surged as a promising technique for AI applications combining a huge parametric space with efficient learning algorithms. The efficiency of the training procedure relies on some optimization algorithms which adjust the initial weights to minimize the loss of the model. Such strategies are essential to speed up the convergence of the optimization steps. Nonetheless, a general initialization procedure is still an open problem since the proposed techniques either require a long processing time or take a considerable number of iterations to figure out an acceptable model. This work presents a weight initialization strategy using transfer learning via Weightless Neural Network (WNN). This WNN initialization strategy reaches up to 5.5× accuracy and 15× loss reduction at the first iterations when compared against well-known techniques such as Xavier and He."
Mining Temporal Changes in Strengths and Weaknesses of Cricket Players Using Tensor Decomposition,"Swarup Ranjan, Vijaya Saradhi",1 - Department of Computer Science and Engineering Indian Institute of Technology Guwahati India,"In this work, we present an application of tensor decomposition for discrete random variable tensor. In particular, we construct a tensor using cricket short text commentary data by employing domain-specific features. The aim is to understand the temporal changes in the strength rules and weakness rules of a player. Three-way correspondence analysis (TWCA) is employed to obtain the factors that show dependency between batting features, bowling features, and time respectively. Change in strength rules and weakness rules for Australian batsman Steve Smith (Test Rank #1 ICC player) are presented.","Tensor Decompositions in Deep Learning - organized by Davide Bacciu (Università di Pisa, Italy), Danilo Mandic (Imperial College, United Kingdom)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-202.pdf,2020,100.0,"Mining Temporal Changes in Strengths and Weaknesses of Cricket Players Using Tensor Decomposition In this work, we present an application of tensor decomposition for discrete random variable tensor. In particular, we construct a tensor using cricket short text commentary data by employing domain-specific features. The aim is to understand the temporal changes in the strength rules and weakness rules of a player. Three-way correspondence analysis (TWCA) is employed to obtain the factors that show dependency between batting features, bowling features, and time respectively. Change in strength rules and weakness rules for Australian batsman Steve Smith (Test Rank #1 ICC player) are presented."
Machine learning framework for control in classical and quantum domains,"Archismita Dalal, Eduardo Páez, Shakib Vedaie, Barry Sanders",1 - Institute for Quantum Science and Technology University of Calgary T2N 1N4 Alberta Canada,"Our aim is to construct a framework that relates learning and control for both classical and quantum domains. We claim to enhance the control toolkit and help un-confuse the interdisciplinary field of machine learning for control. Our framework highlights new research directions in areas connecting learning and control. The novelty of our work lies in unifying quantum and classical control and learning theories, aided by pictorial representations of current knowledge of these disparate areas. As an application of our proposed framework, we cast the quantum-control problem of adaptive phase estimation as a learning problem.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-203.pdf,2020,100.0,"Machine learning framework for control in classical and quantum domains Our aim is to construct a framework that relates learning and control for both classical and quantum domains. We claim to enhance the control toolkit and help un-confuse the interdisciplinary field of machine learning for control. Our framework highlights new research directions in areas connecting learning and control. The novelty of our work lies in unifying quantum and classical control and learning theories, aided by pictorial representations of current knowledge of these disparate areas. As an application of our proposed framework, we cast the quantum-control problem of adaptive phase estimation as a learning problem."
Tournament Selection Improves Cartesian Genetic Programming for Atari Games,"Tim Cofala, Lars Elend, Oliver Kramer",1 - Computational Intelligence Group Department of Computing Science University of Oldenburg 26122 Oldenburg Germany,"The objective of this paper is to extend Cartesian Genetic Programming (CGP) for the evolution of Atari game agents in the Arcade Learning Environment. Based upon preliminary work on the use of CGP playing Atari games, we propose extensions like the repeated evaluation of elite solutions. Furthermore, we improve the CGP optimization process by increasing the diversity in the population with tournament selection. Experimental studies on four exemplary Atari games show that the modifications decrease premature stagnation during the evolutionary optimization process and result in more robust agent strategies.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-204.pdf,2020,100.0,"Tournament Selection Improves Cartesian Genetic Programming for Atari Games The objective of this paper is to extend Cartesian Genetic Programming (CGP) for the evolution of Atari game agents in the Arcade Learning Environment. Based upon preliminary work on the use of CGP playing Atari games, we propose extensions like the repeated evaluation of elite solutions. Furthermore, we improve the CGP optimization process by increasing the diversity in the population with tournament selection. Experimental studies on four exemplary Atari games show that the modifications decrease premature stagnation during the evolutionary optimization process and result in more robust agent strategies."
An Empirical Study of Iterative Knowledge Distillation for Neural Network Compression,"Sharan Yalburgi, Tirtharaj Dash, Ramya Hebbalaguppe, Srinidhi Hegde, Ashwin Srinivasan","1 - K.K. Birla Goa Campus Pilani India
3 - TCS Research India","In this paper we introduce Iterative Knowledge Distillation (IKD), the process of successively minimizing models based on the Knowledge Distillation (KD) approach in  [1] . We study two variations of IKD, called parental-and ancestral-training. Both use a single-teacher, and result in a single-student model: the differences arise from which model is used as a teacher. Our results provide support for the utility of the IKD procedure, in the form of increased model compression, without significant losses in predictive accuracy. An important task in IKD is choosing the right model(s) to act as a teacher for a subsequent iteration. Across the variations of IKD studied, our results suggest that the most recent model constructed (parental-training) is the best single teacher for the model in the next iteration. This result suggests that training in IKD can proceed without requiring us to keep all models in the sequence.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-205.pdf,2020,100.0,"An Empirical Study of Iterative Knowledge Distillation for Neural Network Compression In this paper we introduce Iterative Knowledge Distillation (IKD), the process of successively minimizing models based on the Knowledge Distillation (KD) approach in  [1] . We study two variations of IKD, called parental-and ancestral-training. Both use a single-teacher, and result in a single-student model: the differences arise from which model is used as a teacher. Our results provide support for the utility of the IKD procedure, in the form of increased model compression, without significant losses in predictive accuracy. An important task in IKD is choosing the right model(s) to act as a teacher for a subsequent iteration. Across the variations of IKD studied, our results suggest that the most recent model constructed (parental-training) is the best single teacher for the model in the next iteration. This result suggests that training in IKD can proceed without requiring us to keep all models in the sequence."
Why state-of-the-art deep learning barely works as good as a linear classifier in extreme multi-label text classification,"Mohammadreza Qaraei, Sujay Khandagale, Rohit Babbar","1 - CS Department Helsinki Aalto University Finland
2 - Department New York Columbia University CS, USA","Extreme Multi-label Text Classification (XMTC) refers to supervised learning of a classifier which can predict a small subset of relevant labels for a document from an extremely large set. Even though deep learning algorithms have surpassed linear and kernel methods for most natural language processing tasks over the last decade; recent works show that state-of-the-art deep learning methods can only barely manage to work as well as a linear classifier for the XMTC task. The goal of this work is twofold : (i) to investigate the reasons for the comparable performance of these two strands of methods for XMTC, and (ii) to document this observation explicitly, as the efficacy of linear classifiers in this regime, has been ignored in many relevant recent works.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-207.pdf,2020,100.0,"Why state-of-the-art deep learning barely works as good as a linear classifier in extreme multi-label text classification Extreme Multi-label Text Classification (XMTC) refers to supervised learning of a classifier which can predict a small subset of relevant labels for a document from an extremely large set. Even though deep learning algorithms have surpassed linear and kernel methods for most natural language processing tasks over the last decade; recent works show that state-of-the-art deep learning methods can only barely manage to work as well as a linear classifier for the XMTC task. The goal of this work is twofold : (i) to investigate the reasons for the comparable performance of these two strands of methods for XMTC, and (ii) to document this observation explicitly, as the efficacy of linear classifiers in this regime, has been ignored in many relevant recent works."
Joint optimization of predictive performance and selection stability,"Victor Hamer, Pierre Dupont",1 - ICTEAM/INGI/Machine Learning Group UCLouvain Place Sainte-Barbe 2 B-1348 Louvain-la-Neuve Belgium,"Current feature selection methods, especially applied to high dimensional data, tend to suffer from instability since marginal modifications in the data may result in largely distinct selected feature sets. Such instability strongly limits a sound interpretation of the selected variables by domain experts. We address this issue by optimizing jointly the predictive accuracy and selection stability and by deriving Pareto-optimal trajectories. Our approach extends the Recursive Feature Elimination algorithm by enforcing the selection of some features based on a stable, univariate criterion. Experiments conducted on several high dimensional microarray datasets illustrate that large stability gains are obtained with no significant drop of accuracy.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-21.pdf,2020,100.0,"Joint optimization of predictive performance and selection stability Current feature selection methods, especially applied to high dimensional data, tend to suffer from instability since marginal modifications in the data may result in largely distinct selected feature sets. Such instability strongly limits a sound interpretation of the selected variables by domain experts. We address this issue by optimizing jointly the predictive accuracy and selection stability and by deriving Pareto-optimal trajectories. Our approach extends the Recursive Feature Elimination algorithm by enforcing the selection of some features based on a stable, univariate criterion. Experiments conducted on several high dimensional microarray datasets illustrate that large stability gains are obtained with no significant drop of accuracy."
Handling missing data in recurrent neural networks for air quality forecasting,"Michel Tokic, Anja Von Beuningen, Christoph Tietz, Hans-Georg Zimmermann","1 - Siemens AG -Otto-Hahn-Ring 6 81379 München Germany
4 - Fraunhofer IIS -Nordostpark 93 90411 Nürnberg Germany","Practical applications of air quality forecasting, which typically provide predictions over a horizon of hours and days, often require the handling of missing data due to unobserved relevant variables, sensor defects or communication outages. In this paper we discuss two aspects being important when building air quality forecasting models for essential air pollution parameters such as particular matter and nitrogen dioxides. Using a specialized architecture of a recurrent neural network, we can build models even if (1) unobserved variables or (2) missing data are present.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-23.pdf,2020,100.0,"Handling missing data in recurrent neural networks for air quality forecasting Practical applications of air quality forecasting, which typically provide predictions over a horizon of hours and days, often require the handling of missing data due to unobserved relevant variables, sensor defects or communication outages. In this paper we discuss two aspects being important when building air quality forecasting models for essential air pollution parameters such as particular matter and nitrogen dioxides. Using a specialized architecture of a recurrent neural network, we can build models even if (1) unobserved variables or (2) missing data are present."
Motion Segmentation using Frequency Domain Transformer Networks,"Hafez Farazi, Sven Behnke",1 - University of Bonn Computer Science Institute VI Autonomous Intelligent Systems Endenicher Allee 19a 53115 Bonn Germany,"Self-supervised prediction is a powerful mechanism to learn representations that capture the underlying structure of the data. Despite recent progress, the self-supervised video prediction task is still challenging. One of the critical factors that make the task hard is motion segmentation, which is segmenting individual objects and the background and estimating their motion separately. In video prediction, the shape, appearance, and transformation of each object should be understood only by predicting the next frame in pixel space. To address this task, we propose a novel end-to-end learnable architecture that predicts the next frame by modeling foreground and background separately while simultaneously estimating and predicting the foreground motion using Frequency Domain Transformer Networks. Experimental evaluations show that this yields interpretable representations and that our approach can outperform some widely used video prediction methods like Video Ladder Network and Predictive Gated Pyramids on synthetic data.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-24.pdf,2020,100.0,"Motion Segmentation using Frequency Domain Transformer Networks Self-supervised prediction is a powerful mechanism to learn representations that capture the underlying structure of the data. Despite recent progress, the self-supervised video prediction task is still challenging. One of the critical factors that make the task hard is motion segmentation, which is segmenting individual objects and the background and estimating their motion separately. In video prediction, the shape, appearance, and transformation of each object should be understood only by predicting the next frame in pixel space. To address this task, we propose a novel end-to-end learnable architecture that predicts the next frame by modeling foreground and background separately while simultaneously estimating and predicting the foreground motion using Frequency Domain Transformer Networks. Experimental evaluations show that this yields interpretable representations and that our approach can outperform some widely used video prediction methods like Video Ladder Network and Predictive Gated Pyramids on synthetic data."
Tensor Decompositions in Deep Learning,"Davide Bacciu, Danilo Mandic","1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 56127 Pisa -Italy
2 - Department of Electrical and Electronic Engineering Imperial College Exhibition Road London United Kingdom","The paper surveys the topic of tensor decompositions in modern machine learning applications. It focuses on three active research topics of significant relevance for the community. After a brief review of consolidated works on multi-way data analysis, we consider the use of tensor decompositions in compressing the parameter space of deep learning models. Lastly, we discuss how tensor methods can be leveraged to yield richer adaptive representations of complex data, including structured information. The paper concludes with a discussion on interesting open research challenges. * This work has been supported by MIUR under project SIR 2014 LIST-IT (RBSI14STDE).","Tensor Decompositions in Deep Learning - organized by Davide Bacciu (Università di Pisa, Italy), Danilo Mandic (Imperial College, United Kingdom)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-3.pdf,2020,100.0,"Tensor Decompositions in Deep Learning The paper surveys the topic of tensor decompositions in modern machine learning applications. It focuses on three active research topics of significant relevance for the community. After a brief review of consolidated works on multi-way data analysis, we consider the use of tensor decompositions in compressing the parameter space of deep learning models. Lastly, we discuss how tensor methods can be leveraged to yield richer adaptive representations of complex data, including structured information. The paper concludes with a discussion on interesting open research challenges. * This work has been supported by MIUR under project SIR 2014 LIST-IT (RBSI14STDE)."
An quantum algorithm for feedforward neural networks tested on existing quantum hardware,"Francesco Tacchino, Dario Gerace, Chiara Macchiavello, Panagiotis Barkoutsos, Ivano Tavernelli, Daniele Bajoni","1 - Università di Pavia Italy
4 - IBM Research Zurich Rüschlikon Switzerland
7 - University of Pavia
8 - Department of Physics University of Pavia PRIN Project INPhoPOL","We present a memory-efficient quantum algorithm implementing the action of an artificial neuron according to a binary-valued model of the classical perceptron. The algorithm, tested on noisy IBM-Q superconducting real quantum processors, succeeds in elementary classification and image-recognition tasks through a hybrid quantum-classical training procedure. Here we also show that this model is amenable to be extended to a multilayered artificial neural network, which is able to solve a task that would be impossible to a single one of its constituent artificial neurons, thus laying the basis for a fully quantum artificial intelligence algorithm run on noisy intermediate-scale quantum hardware.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-30.pdf,2020,100.0,"An quantum algorithm for feedforward neural networks tested on existing quantum hardware We present a memory-efficient quantum algorithm implementing the action of an artificial neuron according to a binary-valued model of the classical perceptron. The algorithm, tested on noisy IBM-Q superconducting real quantum processors, succeeds in elementary classification and image-recognition tasks through a hybrid quantum-classical training procedure. Here we also show that this model is amenable to be extended to a multilayered artificial neural network, which is able to solve a task that would be impossible to a single one of its constituent artificial neurons, thus laying the basis for a fully quantum artificial intelligence algorithm run on noisy intermediate-scale quantum hardware."
Domain Invariant Representations with Deep Spectral Alignment,"Christoph Raab, Peter Meier, Frank-Michael Schleif",1 - Department of Computer Science University of Applied Science Würzburg-Schweinfurt Sanderheinrichsleitenweg 20 Würzburg Germany,"Similar as traditional algorithms, deep learning networks struggle in generalizing across domain boundaries. A current solution is the simultaneous training of the classification model and the minimization of domain differences in the deep network. In this work, we propose a new unsupervised deep domain adaptation architecture, which trains a classifier and minimizes the difference of spectral properties of the covariance matrix of the data. Evaluated against standard architectures and datasets, the approach shows an alignment with respect to the data variance between related domains. * We are thankful for support in the FuE program Informations-und Kommunikationstechnik of the StMWi, project OBerA, grant number IUK-1709-0011// IUK530/010.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-31.pdf,2020,100.0,"Domain Invariant Representations with Deep Spectral Alignment Similar as traditional algorithms, deep learning networks struggle in generalizing across domain boundaries. A current solution is the simultaneous training of the classification model and the minimization of domain differences in the deep network. In this work, we propose a new unsupervised deep domain adaptation architecture, which trains a classifier and minimizes the difference of spectral properties of the covariance matrix of the data. Evaluated against standard architectures and datasets, the approach shows an alignment with respect to the data variance between related domains. * We are thankful for support in the FuE program Informations-und Kommunikationstechnik of the StMWi, project OBerA, grant number IUK-1709-0011// IUK530/010."
Incorporating Human Priors into Deep Reinforcement Learning for Robotic Control,"Manon Flageat, Kai Arulkumaran, Anil Bharath",1 - Imperial College London -Dept. of Bioengineering Exhibition Road London UK,"Deep reinforcement learning (DRL) shows promise for robotic control, as it scales to high-dimensional observations and does not require a model of the robot or environment. However, properties such as control continuity or movement smoothness, which are desirable for application in the real world, will not necessarily emerge from training on reward functions based purely on task success. Inspired by human neuromotor control and movement analysis literature, we define a modular set of costs that promote more efficient, human-like movement policies. Using a simulated 3-DoF manipulator robot, we demonstrate the benefits of these costs by incorporating them into the training of a model-free DRL algorithm and decision-time planning of a trained model-based DRL algorithm. We also quantify these benefits through metrics based on the same literature, which allows for greater interpretability of learned policies-a common concern when learning policies with powerful and complex function approximators.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-32.pdf,2020,100.0,"Incorporating Human Priors into Deep Reinforcement Learning for Robotic Control Deep reinforcement learning (DRL) shows promise for robotic control, as it scales to high-dimensional observations and does not require a model of the robot or environment. However, properties such as control continuity or movement smoothness, which are desirable for application in the real world, will not necessarily emerge from training on reward functions based purely on task success. Inspired by human neuromotor control and movement analysis literature, we define a modular set of costs that promote more efficient, human-like movement policies. Using a simulated 3-DoF manipulator robot, we demonstrate the benefits of these costs by incorporating them into the training of a model-free DRL algorithm and decision-time planning of a trained model-based DRL algorithm. We also quantify these benefits through metrics based on the same literature, which allows for greater interpretability of learned policies-a common concern when learning policies with powerful and complex function approximators."
A Real-time PCB Defect Detector Based on Supervised and Semi-supervised Learning,"Fan He, Sanli Tang, Siamak Mehrkanoon, Xiaolin Huang, Jie Yang","1 - Shanghai Jiao Tong University China
3 - Hikvision Research Institute China
4 - Maastricht University The Netherlands
7 - Research and Demonstration Application of Monitoring and Management Technology of City Energy System Based on Large Data and Artificial Intelligence (SGIT0000YXJS1800395)","This paper designs a deep model to detect PCB defects from an input pair of a detect-free template and a defective tested image. A novel group pyramid pooling module is proposed to efficiently extract features in various resolutions to predict defects in different scales. To train the deep model, a dataset including 6 common types of PCB defects is established, namely DeepPCB, which contains 1,500 image pairs with annotations. Besides, a semi-supervised learning manner is examined to effectively utilize the unlabelled images for training the PCB defect detector. Experiment results validate the effectiveness and efficiency of the proposed model by achieving 98.6% mAP @ 62 FPS on DeepPCB dataset. Deep-PCB is now available at: https://github.com/tangsanli5201/DeepPCB.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-33.pdf,2020,100.0,"A Real-time PCB Defect Detector Based on Supervised and Semi-supervised Learning This paper designs a deep model to detect PCB defects from an input pair of a detect-free template and a defective tested image. A novel group pyramid pooling module is proposed to efficiently extract features in various resolutions to predict defects in different scales. To train the deep model, a dataset including 6 common types of PCB defects is established, namely DeepPCB, which contains 1,500 image pairs with annotations. Besides, a semi-supervised learning manner is examined to effectively utilize the unlabelled images for training the PCB defect detector. Experiment results validate the effectiveness and efficiency of the proposed model by achieving 98.6% mAP @ 62 FPS on DeepPCB dataset. Deep-PCB is now available at: https://github.com/tangsanli5201/DeepPCB."
Similarities between policy gradient methods in reinforcement and supervised learning,"Eric Benhamou, David Saltiel","1 - ULCO LISIC
2 - 1-Lamsade Dauphine, 2-AI Square Connect","Reinforcement learning (RL) is about sequential decision making and is traditionally opposed to supervised learning (SL) and unsupervised learning (USL). In RL, given the current state, the agent makes a decision that may influence the next state as opposed to SL where the next state remains the same, regardless of decisions taken. Although this difference is fundamental, SL and RL are not so different. In particular, we emphasize in this paper that gradient policy methods can be cast as a SL problem where true label are replaced with discounted rewards. We provide a simple experiment where we interchange label and pseudo rewards to show that SL techniques can be directly translated into RL methods.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-34.pdf,2020,100.0,"Similarities between policy gradient methods in reinforcement and supervised learning Reinforcement learning (RL) is about sequential decision making and is traditionally opposed to supervised learning (SL) and unsupervised learning (USL). In RL, given the current state, the agent makes a decision that may influence the next state as opposed to SL where the next state remains the same, regardless of decisions taken. Although this difference is fundamental, SL and RL are not so different. In particular, we emphasize in this paper that gradient policy methods can be cast as a SL problem where true label are replaced with discounted rewards. We provide a simple experiment where we interchange label and pseudo rewards to show that SL techniques can be directly translated into RL methods."
On the long-term learning ability of LSTM LMs,"Wim Boes, Robbe Van Rompaey, Lyan Verwimp, Joris Pelemans, Hugo Van Hamme, Patrick Wambacq","1 - -KU Leuven -ESAT Leuven Belgium
3 - Apple Inc. Cupertino USA","We inspect the long-term learning ability of Long Short-Term Memory language models (LSTM LMs) by evaluating a contextual extension based on the Continuous Bag-of-Words (CBOW) model for both sentence-and discourse-level LSTM LMs and by analyzing its performance. We evaluate on text and speech. Sentence-level models using the longterm contextual module perform comparably to vanilla discourse-level LSTM LMs. On the other hand, the extension does not provide gains for discourse-level models. These findings indicate that discourse-level LSTM LMs already rely on contextual information to perform long-term learning.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-35.pdf,2020,100.0,"On the long-term learning ability of LSTM LMs We inspect the long-term learning ability of Long Short-Term Memory language models (LSTM LMs) by evaluating a contextual extension based on the Continuous Bag-of-Words (CBOW) model for both sentence-and discourse-level LSTM LMs and by analyzing its performance. We evaluate on text and speech. Sentence-level models using the longterm contextual module perform comparably to vanilla discourse-level LSTM LMs. On the other hand, the extension does not provide gains for discourse-level models. These findings indicate that discourse-level LSTM LMs already rely on contextual information to perform long-term learning."
Cross-Encoded Meta Embedding towards Transfer Learning,"Rickard Brännvall, Johan Öhman, György Kovács, Marcus Liwicki","1 - Experimental Mechanics -Luleå University of Technology Sweden
2 - EISLAB Machine Learning -Luleå University of Technology Sweden
4 - RISE ICE -Research Institutes of Sweden Sweden","In this paper we generate word meta-embeddings from already existing embeddings using cross-encoding. Previous approaches can only work with words that exist in each source embedding, while the architecture presented here drops this requirement. We demonstrate the method using two pre-trained embeddings, namely GloVE and FastText. Furthermore, we propose additional improvements to the training process of the metaembedding. Results on six standard tests for word similarity show that the meta-embedding trained outperforms the original embeddings. Moreover, this performance can be further increased with the proposed improvements, resulting in a competitive performance with those reported earlier.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-36.pdf,2020,100.0,"Cross-Encoded Meta Embedding towards Transfer Learning In this paper we generate word meta-embeddings from already existing embeddings using cross-encoding. Previous approaches can only work with words that exist in each source embedding, while the architecture presented here drops this requirement. We demonstrate the method using two pre-trained embeddings, namely GloVE and FastText. Furthermore, we propose additional improvements to the training process of the metaembedding. Results on six standard tests for word similarity show that the meta-embedding trained outperforms the original embeddings. Moreover, this performance can be further increased with the proposed improvements, resulting in a competitive performance with those reported earlier."
Seq-to-NSeq model for multi-summary generation,"Guillaume Le Berre, Christophe Cerisara",1 - University of Lorraine -LORIA France,"Summaries of texts and documents written by people present a high variability, depending on the information they want to focus on and their writing style. Despite recent progress in generative models and controllable text generation, automatic summarization systems are still relatively limited in their capacity to both generate various types of summaries and capture this variability from a corpus. We propose to address this challenge with a multi-decoder model for abstractive sentence summarization that generates several summaries from a single input text. This model is an extension of a sequence-to-sequence model in which multiple concurrent decoders with shared attention and embeddings are trained to generate different summaries that capture the variability of styles present in the corpus. The full model is trained jointly with an Expectation-Maximization algorithm. A first qualitative analysis of the resulting decoders reveals clusters that tend to be consistent with respect to a given style, e.g., passive vs. active voice.",Image and text analysis,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-37.pdf,2020,100.0,"Seq-to-NSeq model for multi-summary generation Summaries of texts and documents written by people present a high variability, depending on the information they want to focus on and their writing style. Despite recent progress in generative models and controllable text generation, automatic summarization systems are still relatively limited in their capacity to both generate various types of summaries and capture this variability from a corpus. We propose to address this challenge with a multi-decoder model for abstractive sentence summarization that generates several summaries from a single input text. This model is an extension of a sequence-to-sequence model in which multiple concurrent decoders with shared attention and embeddings are trained to generate different summaries that capture the variability of styles present in the corpus. The full model is trained jointly with an Expectation-Maximization algorithm. A first qualitative analysis of the resulting decoders reveals clusters that tend to be consistent with respect to a given style, e.g., passive vs. active voice."
Language processing in the era of deep learning,"Ivano Lauriola, Alberto Lavelli, Fabio Aiolli","1 - University of Padova -Dept of Mathematics Via Trieste 63 35121 Padova Italy
2 - Fondazione Bruno Kessler Via Sommarive 18 38123 Trento Italy","Natural Language Processing is a branch of artificial intelligence brimful of intricate, sophisticated, and challenging tasks, such as machine translation, question answering, summarization, and so on. Thanks to the recent advances of deep learning, NLP applications have received an unprecedented boost in performance, generating growing interest from the Machine Learning community. However, even if recent techniques are starting to reach excellent performance on various tasks, there are still several problems that need to be solved, such as the computational cost, the reproducibility of results, and the lack of interpretability. In this contribution, we provide a high-level overview of recent advances in NLP, the role of Machine Learning, and current research directions.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-4.pdf,2020,100.0,"Language processing in the era of deep learning Natural Language Processing is a branch of artificial intelligence brimful of intricate, sophisticated, and challenging tasks, such as machine translation, question answering, summarization, and so on. Thanks to the recent advances of deep learning, NLP applications have received an unprecedented boost in performance, generating growing interest from the Machine Learning community. However, even if recent techniques are starting to reach excellent performance on various tasks, there are still several problems that need to be solved, such as the computational cost, the reproducibility of results, and the lack of interpretability. In this contribution, we provide a high-level overview of recent advances in NLP, the role of Machine Learning, and current research directions."
Self-organizing maps in manifolds with complex topologies: An application to the planning of closed path for indoor UAV patrols,Hervé Frezza-Buet,"1 - Université de Lorraine, CentraleSupélec CNRS F-57000 Metz LORIA France","In this paper, the ability of 1D-SOMs to address the Euclidian Travelling Salesperson problem is extended to more irregular topologies, in order to compute short closed paths covering an indoor environment. In such environments, wall constraints makes the topology of the area to be visited by a patroller very irregular. An application to indoor unmanned aerial vehicule (UAV) security patrols is considered.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-40.pdf,2020,100.0,"Self-organizing maps in manifolds with complex topologies: An application to the planning of closed path for indoor UAV patrols In this paper, the ability of 1D-SOMs to address the Euclidian Travelling Salesperson problem is extended to more irregular topologies, in order to compute short closed paths covering an indoor environment. In such environments, wall constraints makes the topology of the area to be visited by a patroller very irregular. An application to indoor unmanned aerial vehicule (UAV) security patrols is considered."
Biochemical Pathway Robustness Prediction with Graph Neural Networks,"Marco Podda, Davide Bacciu, Alessio Micheli, Paolo Milazzo",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 56127 Pisa Italy,"The robustness property of a biochemical pathway refers to maintaining stable levels of molecular concentration against the perturbation of parameters governing the underlying chemical reactions. Its computation requires an expensive integration in parameter space. We present a novel application of Graph Neural Networks (GNN) to predict robustness indicators on pathways represented as Petri nets, without the need of performing costly simulations. Our assumption is that pathway structure alone is sufficient to be effective in this task. We show experimentally for the first time that this is indeed possible to a good extent, and investigate how different architectural choices influence performances.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-41.pdf,2020,100.0,"Biochemical Pathway Robustness Prediction with Graph Neural Networks The robustness property of a biochemical pathway refers to maintaining stable levels of molecular concentration against the perturbation of parameters governing the underlying chemical reactions. Its computation requires an expensive integration in parameter space. We present a novel application of Graph Neural Networks (GNN) to predict robustness indicators on pathways represented as Petri nets, without the need of performing costly simulations. Our assumption is that pathway structure alone is sufficient to be effective in this task. We show experimentally for the first time that this is indeed possible to a good extent, and investigate how different architectural choices influence performances."
Embedding of FRPN in CNN architecture,"Alberto Rossi, Markus Hagenbuchner, Franco Scarselli, Ah Tsoi","1 - Department of Information Engineering University of Florence Via di S. Marta 3 50139 Firenze Italy
2 - School of Computing and Information Technology University of Wollongong Northfields Avenue 2522 Wollongong Australia
3 - Department of Information Engineering University of Siena Via Roma 56 53100 Siena Italy","This paper extends the fully recursive perceptron network (FRPN) model for vectorial inputs to include deep convolutional neural networks (CNNs) which can accept multi-dimensional inputs. A FRPN consists of a recursive layer, which, given a fixed input, iteratively computes an equilibrium state. The unfolding realized with this kind of iterative mechanism allows to simulate a deep neural network with any number of layers. The extension of the FRPN to CNN results in an architecture, which we call convolutional-FRPN (C-FRPN), where the convolutional layers are recursive. The method is evaluated on several image classification benchmarks. It is shown that the C-FRPN consistently outperforms standard CNNs having the same number of parameters. The gap in performance is particularly large for small networks, showing that the C-FRPN is a very powerful architecture, since it allows to obtain equivalent performance with fewer parameters when compared with deep CNNs.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-46.pdf,2020,100.0,"Embedding of FRPN in CNN architecture This paper extends the fully recursive perceptron network (FRPN) model for vectorial inputs to include deep convolutional neural networks (CNNs) which can accept multi-dimensional inputs. A FRPN consists of a recursive layer, which, given a fixed input, iteratively computes an equilibrium state. The unfolding realized with this kind of iterative mechanism allows to simulate a deep neural network with any number of layers. The extension of the FRPN to CNN results in an architecture, which we call convolutional-FRPN (C-FRPN), where the convolutional layers are recursive. The method is evaluated on several image classification benchmarks. It is shown that the C-FRPN consistently outperforms standard CNNs having the same number of parameters. The gap in performance is particularly large for small networks, showing that the C-FRPN is a very powerful architecture, since it allows to obtain equivalent performance with fewer parameters when compared with deep CNNs."
Comparison of Cluster Validity Indices and Decision Rules for Different Degrees of Cluster Separation,"Sara Kaczyńska, Rebecca Marion, Rainer Von Sachs",1 - Université catholique de Louvain -ISBA LIDAM Voie du Roman Pays 20 1348 Louvain-la-Neuve Belgium,"Clustering algorithms are powerful tools for data exploration but often require the a priori choice of the number of clusters. In practice, cluster validity indices (CVIs) are used to quantify the clustering structure of candidate partitions, then decision rules are applied to the indices to choose the best number of clusters. This study analyzes how dimensionality and the degree of cluster separation impact the choice of the number of clusters according to 7 different indices and various decision rules. In contrast to previous studies, the degree of cluster separation is controlled by a single parameter and several decision rules are tested for each CVI.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-48.pdf,2020,100.0,"Comparison of Cluster Validity Indices and Decision Rules for Different Degrees of Cluster Separation Clustering algorithms are powerful tools for data exploration but often require the a priori choice of the number of clusters. In practice, cluster validity indices (CVIs) are used to quantify the clustering structure of candidate partitions, then decision rules are applied to the indices to choose the best number of clusters. This study analyzes how dimensionality and the degree of cluster separation impact the choice of the number of clusters according to 7 different indices and various decision rules. In contrast to previous studies, the degree of cluster separation is controlled by a single parameter and several decision rules are tested for each CVI."
Verifying Deep Learning-based Decisions for Facial Expression Recognition,"Ines Rieger, René Kollmann, Bettina Finzel, Dominik Seuss, Ute Schmid","1 - Fraunhofer Institute for Integrated Circuits Erlangen Germany
2 - University of Bamberg -Cognitive Systems Bamberg Germany","Neural networks with high performance can still be biased towards non-relevant features. However, reliability and robustness is especially important for high-risk fields such as clinical pain treatment. We therefore propose a verification pipeline, which consists of three steps. First, we classify facial expressions with a neural network. Next, we apply layer-wise relevance propagation to create pixel-based explanations. Finally, we quantify these visual explanations based on a bounding-box method with respect to facial regions. Although our results show that the neural network achieves state-of-the-art results, the evaluation of the visual explanations reveals that relevant facial regions may not be considered. * This project is funded by the Federal Ministry of Education and Research, grant no. 01IS18056A and 01IS18056B (TraMeExCo). We thank Sebastian Lapuschkin and Jaspar Pahl for their support.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-49.pdf,2020,100.0,"Verifying Deep Learning-based Decisions for Facial Expression Recognition Neural networks with high performance can still be biased towards non-relevant features. However, reliability and robustness is especially important for high-risk fields such as clinical pain treatment. We therefore propose a verification pipeline, which consists of three steps. First, we classify facial expressions with a neural network. Next, we apply layer-wise relevance propagation to create pixel-based explanations. Finally, we quantify these visual explanations based on a bounding-box method with respect to facial regions. Although our results show that the neural network achieves state-of-the-art results, the evaluation of the visual explanations reveals that relevant facial regions may not be considered. * This project is funded by the Federal Ministry of Education and Research, grant no. 01IS18056A and 01IS18056B (TraMeExCo). We thank Sebastian Lapuschkin and Jaspar Pahl for their support."
Machine Learning in the biopharma industry,"Thibault Helleputte, Gaël De Lannoy, Paul Smyth","1 - GSK Vaccines -Research & Development Rue de l'institut 89 1330 Rixensart
3 - 1-DNAlytics Chemin du Cyclotron 6 1348 Louvain-la-Neuve Belgium","Modern high-throughput technologies deployed in R&D for new health products have opened the door to Machine Learning applications that allow the automation of tasks and support for data-driven risk-based decision making. Appealing opportunities of applying Machine Learning appear for the development of modern complex drugs, for biomanufacturing production lines optimization, or even for elaborating product portfolio strategies. Nevertheless, many practical challenges make it difficult to apply Machine Learning models in the biopharmaceutical field. Innovative approaches must thus be considered in many of these practical cases. This tutorial paper is an attempt to describe the landscape of Machine Learning application to the biopharmaceutical industry along three dimensions: opportunities, specificities or constraints and methods.","Machine learning in the pharmaceutical industry - organized by Paul Smyth (GlaxoSmithKline Tech Data & Analytics, Belgium), Thibault Helleputte (DNAlytics, Belgium), Gael de Lannoy (GlaxoSmithKline, CMC Statistical Sciences, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-5.pdf,2020,78.57142857142857,"Machine Learning in the biopharma industry Modern high-throughput technologies deployed in R&D for new health products have opened the door to Machine Learning applications that allow the automation of tasks and support for data-driven risk-based decision making. Appealing opportunities of applying Machine Learning appear for the development of modern complex drugs, for biomanufacturing production lines optimization, or even for elaborating product portfolio strategies. Nevertheless, many practical challenges make it difficult to apply Machine Learning models in the biopharmaceutical field. Innovative approaches must thus be considered in many of these practical cases. This tutorial paper is an attempt to describe the landscape of Machine Learning application to the biopharmaceutical industry along three dimensions: opportunities, specificities or constraints and methods."
Cost-free resolution enhancement in Convolutional Neural Networks for medical image segmentation,"Oscar Pellicer-Valero, María Rupérez-Moreno, José Martín-Guerrero","1 - Department of Electronic Engineering Intelligent Data Analysis Laboratory
2 - ETSE (Engineering School) Universitat de València (UV) Spain
3 - Centro de Investigación en Ingeniería Mecánica (CIIM) Universitat Politècnica de València (UPV) Spain","High-resolution segmentations of medical images are imperative for applications such as treatment planning, image fusion or computeraided surgery. Nevertheless, these are often hard and time-consuming to produce. This paper presents a method for improving the output resolution of Convolutional Neural Networks (CNNs) for medical image segmentation. It is straightforward to implement and works with any already trained CNN with no modification nor retraining required. It is able to produce better results than binary interpolation methods since it exploits all the contextual information to predict the sought values.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-51.pdf,2020,100.0,"Cost-free resolution enhancement in Convolutional Neural Networks for medical image segmentation High-resolution segmentations of medical images are imperative for applications such as treatment planning, image fusion or computeraided surgery. Nevertheless, these are often hard and time-consuming to produce. This paper presents a method for improving the output resolution of Convolutional Neural Networks (CNNs) for medical image segmentation. It is straightforward to implement and works with any already trained CNN with no modification nor retraining required. It is able to produce better results than binary interpolation methods since it exploits all the contextual information to predict the sought values."
Modular Length Control for Sentence Generation,"Katya Kudashkina, Peter Wittek, Jamie Kiros, Graham Taylor","1 - Engineering Dept University of Guelph 50 Stone Rd E N1G 2W1 Guelph ON Canada
2 - University of Toronto 105 St George St., 4-Google Brain 111 Richmond St. W. #12 M5S 3E6, M5H 2G4 Toronto, Toronto ON, ON Canada, Canada
4 - 661 University Ave., Suite 710 M5G 1M1 Toronto ON Canada","Generating summary-sentences with preserved meaning is important for the summarization of longer documents. Length control of summary-sentences is challenging as sentences cannot simply be cut at the desired length; they must be complete and preserve input meaning. We propose a modular framework for length control of generated sentences: based on sequence-to-sequence models, powered by a two-stage training process involving a summarizer that is trained without explicit length control and a stylizer that is fine-tuned on the output of the summarizer. Our solution achieves the performance of existing models for controlling generated sentence length but light in implementation and model complexity.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-53.pdf,2020,100.0,"Modular Length Control for Sentence Generation Generating summary-sentences with preserved meaning is important for the summarization of longer documents. Length control of summary-sentences is challenging as sentences cannot simply be cut at the desired length; they must be complete and preserve input meaning. We propose a modular framework for length control of generated sentences: based on sequence-to-sequence models, powered by a two-stage training process involving a summarizer that is trained without explicit length control and a stylizer that is fine-tuned on the output of the summarizer. Our solution achieves the performance of existing models for controlling generated sentence length but light in implementation and model complexity."
Pyramidal Graph Echo State Networks,"Filippo Bianchi, Claudio Gallicchio, Alessio Micheli","1 - NORCE -the Norwegian Research Center
2 - University of Pisa","We analyze graph neural network models that combine iterative message-passing implemented by a function with untrained weights and graph pooling operations. In particular, we alternate randomized neural message passing with graph coarsening operations, which provide multiple views of the underlying graph. Each view is concatenated to build a graph embedding for graph-level classification. The main advantage of the proposed architecture is its speed, further improved by the pooling, in computing graph-level representations. Results obtained on popular graph classification benchmarks, comparing different topological pooling techniques, support our claim.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-54.pdf,2020,100.0,"Pyramidal Graph Echo State Networks We analyze graph neural network models that combine iterative message-passing implemented by a function with untrained weights and graph pooling operations. In particular, we alternate randomized neural message passing with graph coarsening operations, which provide multiple views of the underlying graph. Each view is concatenated to build a graph embedding for graph-level classification. The main advantage of the proposed architecture is its speed, further improved by the pooling, in computing graph-level representations. Results obtained on popular graph classification benchmarks, comparing different topological pooling techniques, support our claim."
Efficient computation of counterfactual explanations of LVQ models,"André Artelt, Barbara Hammer",1 - Faculty of Technology Inspiration 1 CITEC -Cognitive Interaction Technology Bielefeld University 33619 Bielefeld Germany,"The increasing use of machine learning in practice and legal regulations like EU's GDPR cause the necessity to be able to explain the prediction and behavior of machine learning models. A prominent example of particularly intuitive explanations of AI models in the context of decision making are counterfactual explanations. Yet, it is still an open research problem how to efficiently compute counterfactual explanations for many models. We investigate how to efficiently compute counterfactual explanations for an important class of models, prototype-based classifiers such as learning vector quantization models. In particular, we derive specific convex and non-convex programs depending on the used metric.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-55.pdf,2020,100.0,"Efficient computation of counterfactual explanations of LVQ models The increasing use of machine learning in practice and legal regulations like EU's GDPR cause the necessity to be able to explain the prediction and behavior of machine learning models. A prominent example of particularly intuitive explanations of AI models in the context of decision making are counterfactual explanations. Yet, it is still an open research problem how to efficiently compute counterfactual explanations for many models. We investigate how to efficiently compute counterfactual explanations for an important class of models, prototype-based classifiers such as learning vector quantization models. In particular, we derive specific convex and non-convex programs depending on the used metric."
Entity-Pair Embeddings for Improving Relation Extraction in the Biomedical Domain,"Farrokh Mehryary, Hans Moen, Tapio Salakoski, Filip Ginter","1 - Department of Future Technologies Turku NLP Group University of Turku Turku Finland
2 - University of Turku Graduate School (UTUGS) Turku Finland","We introduce a new approach for training named-entity pair embeddings to improve relation extraction performance in the biomedical domain. These embeddings are trained in an unsupervised manner, based on the principles of distributional semantics. By adding them to neural network architectures, we show that improved F-Scores are achieved. Our best performing neural model which utilizes entity-pair embeddings along with a pre-trained BERT encoder, achieves an F-score of 77.19 on CHEMPROT (Chemical-Protein) relation extraction corpus, setting a new state-of-the-art result for the task.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-56.pdf,2020,100.0,"Entity-Pair Embeddings for Improving Relation Extraction in the Biomedical Domain We introduce a new approach for training named-entity pair embeddings to improve relation extraction performance in the biomedical domain. These embeddings are trained in an unsupervised manner, based on the principles of distributional semantics. By adding them to neural network architectures, we show that improved F-Scores are achieved. Our best performing neural model which utilizes entity-pair embeddings along with a pre-trained BERT encoder, achieves an F-score of 77.19 on CHEMPROT (Chemical-Protein) relation extraction corpus, setting a new state-of-the-art result for the task."
Fast and Stable Interval Bounds Propagation for Training Verifiably Robust Models,"Paweł Morawiecki, Przemysław Spurek, Marek Śmieja, Jacek Tabor","1 - Institute of Computer Science Polish Academy of Sciences
2 - Institute of Computer Science and Computational Mathematics Jagiellonian University Poland","We present an efficient technique to train classification networks which are verifiably robust against norm-bounded adversarial attacks. This framework is built upon interval bounds propagation (IBP), which applies the interval arithmetic to bound the activations at each layer and keeps the prediction invariant to the input perturbation. To speed up and stabilize training of IBP, we supply its cost function with an additional term, which encourages the model to keep the interval bounds at hidden layers small. Experimental results demonstrate that the training of our model is faster, more stable and less sensitive to the exact specification of the training process than original IBP. 1","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-57.pdf,2020,100.0,"Fast and Stable Interval Bounds Propagation for Training Verifiably Robust Models We present an efficient technique to train classification networks which are verifiably robust against norm-bounded adversarial attacks. This framework is built upon interval bounds propagation (IBP), which applies the interval arithmetic to bound the activations at each layer and keeps the prediction invariant to the input perturbation. To speed up and stabilize training of IBP, we supply its cost function with an additional term, which encourages the model to keep the interval bounds at hidden layers small. Experimental results demonstrate that the training of our model is faster, more stable and less sensitive to the exact specification of the training process than original IBP. 1"
Modelling human sound localization with deep neural networks,"Kiki Van Der Heijden, Siamak Mehrkanoon","1 - Maastricht Centre for Systems Biology (MaCSBio) Maastricht University -School for Mental Health and Neuroscience (MHeNs) Universiteitssingel 40-60 6229 ER Maastricht Netherlands
2 - Maastricht University -Department of Knowledge Engineering. Paul-Henri Spaaklaan 1 6229 EN Maastricht Netherlands","How the brain transforms binaural, real-life sounds into a neural representation of sound location is unclear. This paper introduces a deep learning approach to address these neurocomputational mechanisms: We develop a biological-inspired deep neural network model of sound azimuth encoding operating on auditory nerve representations of real-life sounds. We explore two types of loss functions: Euclidean distance and angular distance. Our results show that a network resembling the early stages of the human auditory pathway can predict sound azimuth location. The type of loss function modulates spatial acuity in different ways. Finally, learning is independent of environment-specific acoustic properties.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-59.pdf,2020,99.17355371900827,"Modelling human sound localization with deep neural networks How the brain transforms binaural, real-life sounds into a neural representation of sound location is unclear. This paper introduces a deep learning approach to address these neurocomputational mechanisms: We develop a biological-inspired deep neural network model of sound azimuth encoding operating on auditory nerve representations of real-life sounds. We explore two types of loss functions: Euclidean distance and angular distance. Our results show that a network resembling the early stages of the human auditory pathway can predict sound azimuth location. The type of loss function modulates spatial acuity in different ways. Finally, learning is independent of environment-specific acoustic properties."
Quantum Machine Learning,"José Martín-Guerrero, Lucas Lamata","1 - Departament d'Enginyeria Electrònica ETSE-UV Universitat de València Spain
2 - Departamento de Física Atómica, Molecular y Nuclear Universidad de Sevilla Spain","Machine Learning (ML) is becoming a more and more popular field of knowledge, being a term known not only in the academic field due to its successful applications to many real-world problems. The advent of Deep Learning and Big Data in the last decade has contributed to make it even more popular. Many companies, both large ones and SMEs, have created specific departments for ML and data analysis, being in fact their main activity in many cases. This current exploitation of ML should not mislead us; while it is a mature field of knowledge, there is still room for many novel contributions, namely, a better understanding of the underlying Mathematics, proposal and tuning of algorithms suitable for new problems (e.g., Natural Language Processing), automation and optimization of the search of parameters, etc. Within this framework of new contributions to ML, Quantum Machine Learning (QML) has emerged strongly lately, speeding up ML calculations and providing alternative representations to existing approaches. This special session includes six high-quality papers dealing with some of the most relevant aspects of QML, including analysis of learning in quantum computing and quantum annealers, quantum versions of classical ML models -like neural networks or learning vector quantization-, and quantum learning approaches for measurement and control.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-6.pdf,2020,100.0,"Quantum Machine Learning Machine Learning (ML) is becoming a more and more popular field of knowledge, being a term known not only in the academic field due to its successful applications to many real-world problems. The advent of Deep Learning and Big Data in the last decade has contributed to make it even more popular. Many companies, both large ones and SMEs, have created specific departments for ML and data analysis, being in fact their main activity in many cases. This current exploitation of ML should not mislead us; while it is a mature field of knowledge, there is still room for many novel contributions, namely, a better understanding of the underlying Mathematics, proposal and tuning of algorithms suitable for new problems (e.g., Natural Language Processing), automation and optimization of the search of parameters, etc. Within this framework of new contributions to ML, Quantum Machine Learning (QML) has emerged strongly lately, speeding up ML calculations and providing alternative representations to existing approaches. This special session includes six high-quality papers dealing with some of the most relevant aspects of QML, including analysis of learning in quantum computing and quantum annealers, quantum versions of classical ML models -like neural networks or learning vector quantization-, and quantum learning approaches for measurement and control."
Navigational Freespace Detection for Autonomous Driving in Fixed Routes,"Aparajit Narayan, Elio Tuci, William Sachiti, Aaron Parsons","1 - Academy of Robotics 33 Cathedral Road CF11 9HB Cardiff Wales (UK
2 - Faculty of Computer Science University of Namur Rue Grandgagnage 21 5000 Namur Belgium","Vision-based modules are largely exploited by autonomous driving vehicles to identify the road area and to avoid collisions with other vehicles, pedestrians and obstacles. This paper illustrates the results of a comparative study in which eight different vision-based modules are evaluated for detecting free navigational space in urban environments. All modules are implemented using Convolutions Neural Networks. The distinctive and innovative feature of these modules is the manner via which navigational freespace is identified from image inputs. The modules generate the coordinates of a triangle, whose area represents the navigation freespace. The relative position of the triangle top corner with respect to the image centre points toward the vehicle direction of motion. Thus, when trained on a fixed route, these modules are able to successfully detect the road-freepsace and to make appropriate decisions concerning where to go at roundabouts, intersections etc., in order to reach the final destination.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-61.pdf,2020,100.0,"Navigational Freespace Detection for Autonomous Driving in Fixed Routes Vision-based modules are largely exploited by autonomous driving vehicles to identify the road area and to avoid collisions with other vehicles, pedestrians and obstacles. This paper illustrates the results of a comparative study in which eight different vision-based modules are evaluated for detecting free navigational space in urban environments. All modules are implemented using Convolutions Neural Networks. The distinctive and innovative feature of these modules is the manner via which navigational freespace is identified from image inputs. The modules generate the coordinates of a triangle, whose area represents the navigation freespace. The relative position of the triangle top corner with respect to the image centre points toward the vehicle direction of motion. Thus, when trained on a fixed route, these modules are able to successfully detect the road-freepsace and to make appropriate decisions concerning where to go at roundabouts, intersections etc., in order to reach the final destination."
Unsupervised Latent Space Translation Network,"Magda Friedjungová, Daniel Vašata, Tomáš Chobola, Marcel Jiřina",1 - Faculty of Information Technology Prague Czech Technical University Prague Czech Republic,"One task that is often discussed in a computer vision is the mapping of an image from one domain to a corresponding image in another domain known as image-to-image translation. Currently there are several approaches solving this task. In this paper, we present an enhancement of the UNIT framework that aids in removing its main drawbacks. More specifically, we introduce an additional adversarial discriminator on the latent representation used instead of VAE, which enforces the latent space distributions of both domains to be similar. On MNIST and USPS domain adaptation tasks, this approach greatly outperforms competing approaches.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-64.pdf,2020,100.0,"Unsupervised Latent Space Translation Network One task that is often discussed in a computer vision is the mapping of an image from one domain to a corresponding image in another domain known as image-to-image translation. Currently there are several approaches solving this task. In this paper, we present an enhancement of the UNIT framework that aids in removing its main drawbacks. More specifically, we introduce an additional adversarial discriminator on the latent representation used instead of VAE, which enforces the latent space distributions of both domains to be similar. On MNIST and USPS domain adaptation tasks, this approach greatly outperforms competing approaches."
Frontiers in Reservoir Computing,"Claudio Gallicchio, Mantas Lukoševičius, Simone Scardapane","1 - University of Pisa Italy
2 - Kaunas University of Technology Lithuania
3 - Sapienza University of Rome Italy","Reservoir computing (RC) studies the properties of large recurrent networks of artificial neurons, with either fixed or random connectivity. Over the last years, reservoirs have become a key tool for pattern recognition and neuroscience problems, being able to develop a rich representation of the temporal information even if left untrained. The common paradigm has been instantiated into several models, among which the Echo State Network and the Liquid State Machine represent the most widely known ones. Nowadays, RC represents the de facto state-of-the-art approach for efficient learning in the temporal domain. Besides, theoretical studies in RC area can contribute to the broader field of Recurrent Neural Networks research by enabling a deeper understanding of the fundamental capabilities of dynamical recurrent models, even in the absence of training of the recurrent connections. RC paradigm also allows using different dynamical systems, including hardware, for computation. This paper is intended to give an overview on the RC research field, highlighting major frontiers in its development and finally introducing the contributed papers to the ESANN 2020 special session.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-7.pdf,2020,100.0,"Frontiers in Reservoir Computing Reservoir computing (RC) studies the properties of large recurrent networks of artificial neurons, with either fixed or random connectivity. Over the last years, reservoirs have become a key tool for pattern recognition and neuroscience problems, being able to develop a rich representation of the temporal information even if left untrained. The common paradigm has been instantiated into several models, among which the Echo State Network and the Liquid State Machine represent the most widely known ones. Nowadays, RC represents the de facto state-of-the-art approach for efficient learning in the temporal domain. Besides, theoretical studies in RC area can contribute to the broader field of Recurrent Neural Networks research by enabling a deeper understanding of the fundamental capabilities of dynamical recurrent models, even in the absence of training of the recurrent connections. RC paradigm also allows using different dynamical systems, including hardware, for computation. This paper is intended to give an overview on the RC research field, highlighting major frontiers in its development and finally introducing the contributed papers to the ESANN 2020 special session."
Zero-shot and few-shot time series forecasting with ordinal regression recurrent neural networks,"Bernardo Orozco, Stephen Roberts","1 - Information Engineering University of Oxford
2 - Mind Foundry Ltd","Recurrent neural networks (RNNs) are state-of-the-art in several sequential learning tasks, but they often require considerable amounts of data to generalise well. For many time series forecasting (TSF) tasks, only a few dozens of observations may be available at training time, which restricts use of this class of models. We propose a novel RNN-based model that directly addresses this problem by learning a shared feature embedding over the space of many quantised time series. We show how this enables our RNN framework to accurately and reliably forecast unseen time series, even when there is little to no training data available. * We acknowledge the support provided by CONACYT (CVU #598304) and the UK Royal Academy of Engineering.","Learning from partially labeled data - organized by Siamak Mehrkanoon (Maastricht University, The Netherlands), Xiaolin Huang (Shanghai Jiao Tong University, China), Johan Suykens (KU Leuven, Belgium)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-71.pdf,2020,100.0,"Zero-shot and few-shot time series forecasting with ordinal regression recurrent neural networks Recurrent neural networks (RNNs) are state-of-the-art in several sequential learning tasks, but they often require considerable amounts of data to generalise well. For many time series forecasting (TSF) tasks, only a few dozens of observations may be available at training time, which restricts use of this class of models. We propose a novel RNN-based model that directly addresses this problem by learning a shared feature embedding over the space of many quantised time series. We show how this enables our RNN framework to accurately and reliably forecast unseen time series, even when there is little to no training data available. * We acknowledge the support provided by CONACYT (CVU #598304) and the UK Royal Academy of Engineering."
Multi-Directional Laplacian Pyramids for Completion of Missing Data Entries,Neta Rabin,1 - Department of Industrial Engineering Tel-Aviv University Israel,"A common pre-processing task in machine learning is handling missing data entries, also known as imputation. Standard techniques use mean values, regression or optimization based techniques for predicting the missing data values. In this paper, a kernel based technique is utilized for imputing data in a multi-scale manner. The construction is based on Laplacian pyramids, which operate on the row and column spaces of the data in several scales. Experimental results demonstrate the approach on publicly available datasets, and highlight its simple computational construction and convergence stability.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-72.pdf,2020,100.0,"Multi-Directional Laplacian Pyramids for Completion of Missing Data Entries A common pre-processing task in machine learning is handling missing data entries, also known as imputation. Standard techniques use mean values, regression or optimization based techniques for predicting the missing data values. In this paper, a kernel based technique is utilized for imputing data in a multi-scale manner. The construction is based on Laplacian pyramids, which operate on the row and column spaces of the data in several scales. Experimental results demonstrate the approach on publicly available datasets, and highlight its simple computational construction and convergence stability."
Improving the Union Bound: a Distribution Dependent Approach,"Luca Oneto, Sandro Ridella, Davide Anguita",1 - DIBRIS -University of Genoa Via Opera Pia 11a 16145 Genoa Italy,"Statistical Learning Theory deals with the problem of estimating the performance of a learning procedure. Any learning procedure implies making choices and this choices imply a risk. When the number of choices is finite, the state-of-the-art tool for evaluating the total risk of all the choice made is the Union Bound. The problem of the Union Bound is that it is very loose in practice if no a-priori information is available. In fact, the Union Bound considers all choices equally plausible while, as a matter of fact, a learning procedure targets just particular choices disregarding the others. In this work we will show that it is possible to improve the Union Bound based results using a distribution dependent weighting strategy of the true risks associated to each choice. Then we will prove that our proposal outperforms or, in the worst case, it degenerate in the Union Bound.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-74.pdf,2020,100.0,"Improving the Union Bound: a Distribution Dependent Approach Statistical Learning Theory deals with the problem of estimating the performance of a learning procedure. Any learning procedure implies making choices and this choices imply a risk. When the number of choices is finite, the state-of-the-art tool for evaluating the total risk of all the choice made is the Union Bound. The problem of the Union Bound is that it is very loose in practice if no a-priori information is available. In fact, the Union Bound considers all choices equally plausible while, as a matter of fact, a learning procedure targets just particular choices disregarding the others. In this work we will show that it is possible to improve the Union Bound based results using a distribution dependent weighting strategy of the true risks associated to each choice. Then we will prove that our proposal outperforms or, in the worst case, it degenerate in the Union Bound."
Learning Deep Fair Graph Neural Networks,"Nicolò Navarin, Luca Oneto, Michele Donini","1 - University of Padua -Via Trieste 63 35121 Padova Italy
2 - University of Genoa Via Opera Pia 11a 16145 Genova Italy
3 - Amazon -9th Ave Seattle 98101 WA USA","Developing learning methods which do not discriminate subgroups in the population is the central goal of algorithmic fairness. One way to reach this goal is to learn a data representation that is expressive enough to describe the data and fair enough to remove the possibility to discriminate subgroups when a model is learned leveraging on the learned representation. This problem is even more challenging when our data are graphs, which nowadays are ubiquitous and allow to model entities and relationships between them. In this work we measure fairness according to demographic parity, requiring the probability of the possible model decisions to be independent of the sensitive information. We investigate how to impose this constraint in the different layers of a deep graph neural network through the use of two different regularizers. The first one is based on a simple convex relaxation, and the second one inspired by a Wasserstein distance formulation of demographic parity. We present experiments on a real world dataset, showing the effectiveness of our proposal.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-75.pdf,2020,100.0,"Learning Deep Fair Graph Neural Networks Developing learning methods which do not discriminate subgroups in the population is the central goal of algorithmic fairness. One way to reach this goal is to learn a data representation that is expressive enough to describe the data and fair enough to remove the possibility to discriminate subgroups when a model is learned leveraging on the learned representation. This problem is even more challenging when our data are graphs, which nowadays are ubiquitous and allow to model entities and relationships between them. In this work we measure fairness according to demographic parity, requiring the probability of the possible model decisions to be independent of the sensitive information. We investigate how to impose this constraint in the different layers of a deep graph neural network through the use of two different regularizers. The first one is based on a simple convex relaxation, and the second one inspired by a Wasserstein distance formulation of demographic parity. We present experiments on a real world dataset, showing the effectiveness of our proposal."
Graph Neural Networks for the Prediction of Protein-Protein Interfaces,"Niccolò Pancino, Alberto Rossi, Giorgio Ciano, Giorgia Giacomini, Simone Bonechi, Paolo Andreini, Franco Scarselli, Monica Bianchini, Pietro Bongini","1 - SAILAB -University of Siena -via Roma 56 53100 Siena Italy
2 - DINFO -University of Florence -via di Santa Marta 3 50139 Florence Italy","Binding site identification allows to determine the functionality and the quaternary structure of protein-protein complexes. Various approaches to this problem have been proposed without reaching a viable solution. Representing the interacting peptides as graphs, a correspondence graph describing their interaction can be built. Finding the maximum clique in the correspondence graph allows to identify the secondary structure elements belonging to the interaction site. Although the maximum clique problem is NP-complete, Graph Neural Networks make for an approximation tool that can solve the problem in affordable time. Our experimental results are promising and suggest that this direction should be explored further.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-76.pdf,2020,100.0,"Graph Neural Networks for the Prediction of Protein-Protein Interfaces Binding site identification allows to determine the functionality and the quaternary structure of protein-protein complexes. Various approaches to this problem have been proposed without reaching a viable solution. Representing the interacting peptides as graphs, a correspondence graph describing their interaction can be built. Finding the maximum clique in the correspondence graph allows to identify the secondary structure elements belonging to the interaction site. Although the maximum clique problem is NP-complete, Graph Neural Networks make for an approximation tool that can solve the problem in affordable time. Our experimental results are promising and suggest that this direction should be explored further."
Learning Step Size Adaptation in Evolution Strategies,Oliver Kramer,1 - Computational Intelligence Group Department of Computing Science University of Oldenburg 26122 Oldenburg Germany,"Step size adaptation is an essential part of successful evolution strategies in continuous solution spaces as they moderate between exploration and exploitation. We propose to learn step sizes evolved with a σ-self-adaptive (1 + λ)-ES using LSTMs. Based on input sequences of multi-variate distances between best solutions of successive generations and their step sizes a long short-term memory network (LSTM) is trained. The learned distances-step size pairs guide the search of the LSTM-ES, which is a (1 + λ)-ES with LSTM step size predictions. An experimental analysis illustrates the behavior of the LSTM-ES on the Sphere function with different parameter settings and problem dimensionalities.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-8.pdf,2020,100.0,"Learning Step Size Adaptation in Evolution Strategies Step size adaptation is an essential part of successful evolution strategies in continuous solution spaces as they moderate between exploration and exploitation. We propose to learn step sizes evolved with a σ-self-adaptive (1 + λ)-ES using LSTMs. Based on input sequences of multi-variate distances between best solutions of successive generations and their step sizes a long short-term memory network (LSTM) is trained. The learned distances-step size pairs guide the search of the LSTM-ES, which is a (1 + λ)-ES with LSTM step size predictions. An experimental analysis illustrates the behavior of the LSTM-ES on the Sphere function with different parameter settings and problem dimensionalities."
A preconditioned accelerated stochastic gradient descent algorithm,"Alexandru Onose, Iman Mossavat, Henk-Jan Smilde",1 - ASML Netherlands B.V. De Run 6501 5504DR Veldhoven The Netherlands,"We propose a preconditioned accelerated stochastic gradient method suitable for large scale optimization. Inspired by recent popular adaptive per-feature algorithms, we propose a specic preconditioner based on the second moment of the gradient. We derive sucient convergence conditions for the minimization of convex functions using a generic class of diagonal preconditioners and provide a formal convergence proof based on a framework originally used for on-line learning. We show empirical results for the minimization of convex and non-convex cost functions, in the context of neural network training. The method compares favorably with respect to current, rst order, stochastic optimization methods.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-80.pdf,2020,100.0,"A preconditioned accelerated stochastic gradient descent algorithm We propose a preconditioned accelerated stochastic gradient method suitable for large scale optimization. Inspired by recent popular adaptive per-feature algorithms, we propose a specic preconditioner based on the second moment of the gradient. We derive sucient convergence conditions for the minimization of convex functions using a generic class of diagonal preconditioners and provide a formal convergence proof based on a framework originally used for on-line learning. We show empirical results for the minimization of convex and non-convex cost functions, in the context of neural network training. The method compares favorably with respect to current, rst order, stochastic optimization methods."
Detection of abnormal driving situations using distributed representations and unsupervised learning,"Florian Mirus, Terrence Stewart, Jörg Conradt","1 - -BMW Group -Research New Technologies, Innovations Garching Germany
2 - Department of Electrical and Computer Engineering Technical University of Munich Munich Germany
3 - -Applied Brain Research Inc Waterloo Ontario Canada
4 - Department of Computational Science and Technology KTH Royal Institute of Technology Stockholm Sweden","In this paper, we present an anomaly detection system employing an unsupervised learning model trained on the information encapsulated within distributed vector representations of automotive scenes. Our representations allows us to encode automotive scenes with a varying number of traffic participants in a vector of fixed length. We train a neural network autoencoder in unsupervised fashion to detect anomalies based on this representation. We demonstrate the usefulness of our approach through a quantitative analysis on two real-world data-sets.",Unsupervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-81.pdf,2020,100.0,"Detection of abnormal driving situations using distributed representations and unsupervised learning In this paper, we present an anomaly detection system employing an unsupervised learning model trained on the information encapsulated within distributed vector representations of automotive scenes. Our representations allows us to encode automotive scenes with a varying number of traffic participants in a vector of fixed length. We train a neural network autoencoder in unsupervised fashion to detect anomalies based on this representation. We demonstrate the usefulness of our approach through a quantitative analysis on two real-world data-sets."
Reservoir memory machines,"Benjamin Paaßen, Alexander Schulz","1 - Machine Learning Group Bielefeld University Germany Inspiration
2 - 33619 Bielefeld Germany","In recent years, Neural Turing Machines have gathered attention by joining the flexibility of neural networks with the computational capabilities of Turing machines. However, Neural Turing Machines are notoriously hard to train, which limits their applicability. We propose reservoir memory machines, which are still able to solve some of the benchmark tests for Neural Turing Machines, but are much faster to train, requiring only an alignment algorithm and linear regression. Our model can also be seen as an extension of echo state networks with an external memory, enabling arbitrarily long storage without interference. * Funding by the Bielefeld Young Researchers' Fund and from BMBF within the project MechML under grant number 01IS18053E is gratefully acknowledged. We also thank Barbara Hammer for brilliant theoretical insights.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-82.pdf,2020,100.0,"Reservoir memory machines In recent years, Neural Turing Machines have gathered attention by joining the flexibility of neural networks with the computational capabilities of Turing machines. However, Neural Turing Machines are notoriously hard to train, which limits their applicability. We propose reservoir memory machines, which are still able to solve some of the benchmark tests for Neural Turing Machines, but are much faster to train, requiring only an alignment algorithm and linear regression. Our model can also be seen as an extension of echo state networks with an external memory, enabling arbitrarily long storage without interference. * Funding by the Bielefeld Young Researchers' Fund and from BMBF within the project MechML under grant number 01IS18053E is gratefully acknowledged. We also thank Barbara Hammer for brilliant theoretical insights."
Epistemic Risk-Sensitive Reinforcement Learning,"Hannes Eriksson, Christos Dimitrakakis","1 - Chalmers University of Technology Gothenburg Sweden
2 - Zenuity AB Gothenburg Sweden
4 - University of Oslo Oslo Norway","We develop a framework for risk-sensitive behaviour in reinforcement learning (RL) due to uncertainty about the environment dynamics by leveraging utility-based definitions of risk sensitivity. In this framework, the preference for risk can be tuned by varying the utility function, for which we develop dynamic programming (DP) and policy gradient-based algorithms. The risk-averse behavior is compared with the behavior of risk-neutral policy in environments with epistemic risk.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-84.pdf,2020,100.0,"Epistemic Risk-Sensitive Reinforcement Learning We develop a framework for risk-sensitive behaviour in reinforcement learning (RL) due to uncertainty about the environment dynamics by leveraging utility-based definitions of risk sensitivity. In this framework, the preference for risk can be tuned by varying the utility function, for which we develop dynamic programming (DP) and policy gradient-based algorithms. The risk-averse behavior is compared with the behavior of risk-neutral policy in environments with epistemic risk."
Perplexity-free Parametric t-SNE,"Francesco Crecchi, Cyril De Bodt, Michel Verleysen, John Lee, Davide Bacciu","1 - Dipartimento di Informatica Largo Bruno Pontecorvo Universitá di Pisa 56127 Pisa Italy
2 - Université catholique de Louvain -ICTEAM Place du Levant L5.03.02, 1348 Louvain-la-Neuve Belgium","The t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm is a ubiquitously employed dimensionality reduction (DR) method. Its non-parametric nature and impressive efficacy motivated its parametric extension. It is however bounded to a user-defined perplexity parameter, restricting its DR quality compared to recently developed multi-scale perplexity-free approaches. This paper hence proposes a multi-scale parametric t-SNE scheme, relieved from the perplexity tuning and with a deep neural network implementing the mapping. It produces reliable embeddings with out-of-sample extensions, competitive with the best perplexity adjustments in terms of neighborhood preservation on multiple data sets.",Feature selection and dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-85.pdf,2020,100.0,"Perplexity-free Parametric t-SNE The t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm is a ubiquitously employed dimensionality reduction (DR) method. Its non-parametric nature and impressive efficacy motivated its parametric extension. It is however bounded to a user-defined perplexity parameter, restricting its DR quality compared to recently developed multi-scale perplexity-free approaches. This paper hence proposes a multi-scale parametric t-SNE scheme, relieved from the perplexity tuning and with a deep neural network implementing the mapping. It produces reliable embeddings with out-of-sample extensions, competitive with the best perplexity adjustments in terms of neighborhood preservation on multiple data sets."
Locally Adaptive Nearest Neighbors,"Jan Göpfert, Heiko Wersing, Barbara Hammer","1 - Bielefeld University Germany
2 - Honda Research Institute Europe GmbH Offenbach Germany
4 - We gratefully acknowledge support by Honda Research Institute Europe GmbH Offenbach am Main Germany","When training automated systems, it has been shown to be beneficial to adapt the representation of data by learning a problem-specific metric. This metric is global. We extend this idea and, for the widely used family of k nearest neighbors algorithms, develop a method that allows learning locally adaptive metrics. To demonstrate important aspects of how our approach works, we conduct a number of experiments on synthetic data sets, and we show its usefulness on real-world benchmark data sets.",Supervised learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-89.pdf,2020,100.0,"Locally Adaptive Nearest Neighbors When training automated systems, it has been shown to be beneficial to adapt the representation of data by learning a problem-specific metric. This metric is global. We extend this idea and, for the widely used family of k nearest neighbors algorithms, develop a method that allows learning locally adaptive metrics. To demonstrate important aspects of how our approach works, we conduct a number of experiments on synthetic data sets, and we show its usefulness on real-world benchmark data sets."
Quantum-Inspired Learning Vector Quantization for Classification Learning,"T Villmann, J Ravichandran, A Engelsberger, A Villmann, M Kaden","1 - University of Applied Sciences Mittweida
2 - Saxony Institute for Comp. Intelligence and Machine Learning Mittweida Germany
7 - Berufliches Schulzentrum Döbeln-Mittweida Germany","This paper introduces a variant of the prototype-based generalized learning vector quantization algorithm (GLVQ) for classification learning, which is inspired by quantum computing. Starting from the motivation of kernelized GLVQ, the nonlinear transformation of real data and prototypes into quantum bit vectors allows to formulate a GLVQ variant in a (n-dimensional) quantum bit vector space H n . A key feature for this approach is that H n is an Hilbert space with particular inner product properties, which finally restrict the prototype adaptation to be unitary transformations. The resulting approach is denoted as Qu-GLVQ. We provide the mathematical framework and give exemplary numerical results. * M.K. was supported by grants of the European Social Fund (ESF) for a Young Researcher Group 'MACS' in cooperation with the TU Bergakademie Freiberg (Germany) and for the project titled 'Digitale Produkt-und Prozessinovationen' at the UAS Mittweida. J.R. and A.E. are supported by a PhD-grant of ESF.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-90.pdf,2020,100.0,"Quantum-Inspired Learning Vector Quantization for Classification Learning This paper introduces a variant of the prototype-based generalized learning vector quantization algorithm (GLVQ) for classification learning, which is inspired by quantum computing. Starting from the motivation of kernelized GLVQ, the nonlinear transformation of real data and prototypes into quantum bit vectors allows to formulate a GLVQ variant in a (n-dimensional) quantum bit vector space H n . A key feature for this approach is that H n is an Hilbert space with particular inner product properties, which finally restrict the prototype adaptation to be unitary transformations. The resulting approach is denoted as Qu-GLVQ. We provide the mathematical framework and give exemplary numerical results. * M.K. was supported by grants of the European Social Fund (ESF) for a Young Researcher Group 'MACS' in cooperation with the TU Bergakademie Freiberg (Germany) and for the project titled 'Digitale Produkt-und Prozessinovationen' at the UAS Mittweida. J.R. and A.E. are supported by a PhD-grant of ESF."
On Learning a Control System without Continuous Feedback,"Georgi Angelov, Bogdan Georgiev","1 - Sofia University
2 - Research Center for ML Fraunhofer IAIS. ‡ Equal Contribution","We discuss a class of control problems by means of deep neural networks (DNN). Our goal is to develop DNN models that, once trained, are able to produce solutions of such problems at an acceptable error-rate and much faster computation time than an ordinary numerical solver. In the present note we study two such models for the Brockett integrator control problem.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-92.pdf,2020,100.0,"On Learning a Control System without Continuous Feedback We discuss a class of control problems by means of deep neural networks (DNN). Our goal is to develop DNN models that, once trained, are able to produce solutions of such problems at an acceptable error-rate and much faster computation time than an ordinary numerical solver. In the present note we study two such models for the Brockett integrator control problem."
Self-organized dynamic attractors in recurrent neural networks,"Benedikt Vettelschoss, Matthias Freiberger, Joni Dambre",1 - Ghent University -imec -IDLab Technologiepark-Zwijnaarde 126 B-9052 Ghent Belgium,"Recurrent neural networks usually rely on either transient or attractor dynamics to implement working memory, and some studies suggest that it requires a combination of the two. These studies introduce attractor states by the supervised training of a network's feedback weights. In this work we report the creation of comparable memory states through unsupervised learning. We introduce attractor dynamics into an echo state network in a self-organized way by applying a differential Hebbian rule to it's feedback weights. We find that this yields periodic and quasiperiodic attractors in most cases. We analyse the linearized system after the learning phase to understand the origin of these attractors, and connect these findings to other results concerning the dynamical changes induced by neural plasticity.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-95.pdf,2020,100.0,"Self-organized dynamic attractors in recurrent neural networks Recurrent neural networks usually rely on either transient or attractor dynamics to implement working memory, and some studies suggest that it requires a combination of the two. These studies introduce attractor states by the supervised training of a network's feedback weights. In this work we report the creation of comparable memory states through unsupervised learning. We introduce attractor dynamics into an echo state network in a self-organized way by applying a differential Hebbian rule to it's feedback weights. We find that this yields periodic and quasiperiodic attractors in most cases. We analyse the linearized system after the learning phase to understand the origin of these attractors, and connect these findings to other results concerning the dynamical changes induced by neural plasticity."
Linear Graph Convolutional Networks,"Nicolò Navarin, Wolfgang Erb, Luca Pasa, Alessandro Sperduti","1 - University of Padua -Department of Mathematics ""Tullio Levi-Civita"" via Trieste 63 35121 Padua Italy
2 - Department of Mathematics University of Padova
3 - DEEPer project","Many neural networks for graphs are based on the graph convolution operator, proposed more than a decade ago. Since then, many alternative definitions have been proposed, that tend to add complexity (and non-linearity) to the model. In this paper, we follow the opposite direction by proposing a linear graph convolution operator. Despite its simplicity, we show that our convolution operator is more theoretically grounded than many proposals in literature, and shows improved predictive performance.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-96.pdf,2020,100.0,"Linear Graph Convolutional Networks Many neural networks for graphs are based on the graph convolution operator, proposed more than a decade ago. Since then, many alternative definitions have been proposed, that tend to add complexity (and non-linearity) to the model. In this paper, we follow the opposite direction by proposing a linear graph convolution operator. Despite its simplicity, we show that our convolution operator is more theoretically grounded than many proposals in literature, and shows improved predictive performance."
Interpretation of Model Agnostic Classifiers via Local Mental Images,"Aluizio Filho, Gabriel Guarisa, Leopoldo Lusquino Filho, Luiz Oliveira, Carlos Cosenza, Felipe França, Priscila Lima","1 - PESC/COPPE Universidade Federal do Rio de Janeiro 2-NCE, 3-PEP RJ COPPE, Brazil","Although successful black-box learning models have been created, understanding what happens when a machine produces a classification response is still a challenge. This work introduces FRWI -Fuzzy Regression WiSARD Interpreter, a novel fuzzy rules-based algorithm that is capable of interpreting the responses of black-box classifiers via the production of local mental images from a WiSARD n-tuple classifier. FRWI is compared with LIME -Local Interpretable Model-Agnostic Explanations, a pioneering agnostic classification interpreter model. To make a quantitative evaluation of interpretable models, a new metric -Interpretation Capacity Score -is proposed. Using this metric, it is shown that FRWI surpasses LIME in producing coherent interpretations.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-97.pdf,2020,100.0,"Interpretation of Model Agnostic Classifiers via Local Mental Images Although successful black-box learning models have been created, understanding what happens when a machine produces a classification response is still a challenge. This work introduces FRWI -Fuzzy Regression WiSARD Interpreter, a novel fuzzy rules-based algorithm that is capable of interpreting the responses of black-box classifiers via the production of local mental images from a WiSARD n-tuple classifier. FRWI is compared with LIME -Local Interpretable Model-Agnostic Explanations, a pioneering agnostic classification interpreter model. To make a quantitative evaluation of interpretable models, a new metric -Interpretation Capacity Score -is proposed. Using this metric, it is shown that FRWI surpasses LIME in producing coherent interpretations."
Self-Organizing Kernel-based Convolutional Echo State Network for Human Actions Recognition,"Gin Lee, Chu Kiong Loo, Wei Liew, Stefan Wermter","1 - Multimedia University -Faculty of Engineering and Technology Jalan Ayer Keroh Lama 75450 Melaka Malaysia
2 - Faculty of Computer Science and Information Technology University of Malaya 50603 Lembah Pantai
3 - Kuala Lumpur Malaysia
6 - Department of Informatics University of Hamburg Vogt-Koelln-Str.30 22527 Hamburg Germany",We propose a deterministic initialization of the Echo State Network reservoirs to ensure that the activation of its internal echo state representations reflects similar topological qualities of the input signal which should lead to a self-organizing reservoir. Human actions encoded as a multivariate time series signal are clustered before using the clustered nodes and interconnectivity matrices for initializing the S-ConvESN reservoirs. The capability of S-ConvESN is evaluated using several 3Dskeleton-based action recognition datasets.,"Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-99.pdf,2020,100.0,Self-Organizing Kernel-based Convolutional Echo State Network for Human Actions Recognition We propose a deterministic initialization of the Echo State Network reservoirs to ensure that the activation of its internal echo state representations reflects similar topological qualities of the input signal which should lead to a self-organizing reservoir. Human actions encoded as a multivariate time series signal are clustered before using the clustered nodes and interconnectivity matrices for initializing the S-ConvESN reservoirs. The capability of S-ConvESN is evaluated using several 3Dskeleton-based action recognition datasets.
Reservoir Computing by Discretizing ODEs,Claudio Gallicchio,1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"We draw connections between Reservoir Computing (RC) and Ordinary Differential Equations, introducing a novel class of models called Euler State Networks (EuSNs). The proposed approach is featured by system dynamics that are both stable and non-dissipative, hence enabling an effective transmission of input signals over time. At the same time, EuSN is featured by untrained recurrent dynamics, preserving all the computational advantages of RC models. Through experiments on several benchmarks for time-series classification, we empirically show that EuSN can substantially narrow the performance gap between RC and fully trainable recurrent neural networks.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-101,2021,100.0,"Reservoir Computing by Discretizing ODEs We draw connections between Reservoir Computing (RC) and Ordinary Differential Equations, introducing a novel class of models called Euler State Networks (EuSNs). The proposed approach is featured by system dynamics that are both stable and non-dissipative, hence enabling an effective transmission of input signals over time. At the same time, EuSN is featured by untrained recurrent dynamics, preserving all the computational advantages of RC models. Through experiments on several benchmarks for time-series classification, we empirically show that EuSN can substantially narrow the performance gap between RC and fully trainable recurrent neural networks."
Domain Adversarial Tangent Learning Towards Interpretable Domain Adaptation,"Christoph Raab, Sascha Saralajew, Frank-Michael Schleif","1 - Department of Computer Science University of Applied Science Würzburg-Schweinfurt Würzburg Germany
2 - Bosch Center for Artificial Intelligence Renningen Germany","Deep learning struggles to generalize well to an unseen target domain of interest. Current domain adaptation methods simultaneously learn a classifier and an adversarial game for invariant representations but inadequately align local structures, while the underlying process is hard to interpret. We propose a new interpretable adversarial domain architecture, matching local manifold approximations across domains. Evaluated against related networks, the approach is competitive, while the adaptation process can be visually verified.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-103,2021,100.0,"Domain Adversarial Tangent Learning Towards Interpretable Domain Adaptation Deep learning struggles to generalize well to an unseen target domain of interest. Current domain adaptation methods simultaneously learn a classifier and an adversarial game for invariant representations but inadequately align local structures, while the underlying process is hard to interpret. We propose a new interpretable adversarial domain architecture, matching local manifold approximations across domains. Evaluated against related networks, the approach is competitive, while the adaptation process can be visually verified."
Geometric Probing of Word Vectors,Madina Babazhanova,1 - Maxat Tezekbayev Zhenisbek Assylbekov School of Sciences and Humanities -Nazarbayev University Kazakhstan,"This paper studies the informativeness of linguistic properties such as part-of-speech and named entities encoded in word representations. First, we find directions that correspond to these properties using the method of  Elazar et al. (2020) . Then such directions are compared with the principal vectors obtained from application of PCA to word embeddings. As a result, we find that the part-of-speech information is more important for word embeddings than the named entity property.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-105,2021,100.0,"Geometric Probing of Word Vectors This paper studies the informativeness of linguistic properties such as part-of-speech and named entities encoded in word representations. First, we find directions that correspond to these properties using the method of  Elazar et al. (2020) . Then such directions are compared with the principal vectors obtained from application of PCA to word embeddings. As a result, we find that the part-of-speech information is more important for word embeddings than the named entity property."
Decay Momentum for Improving Federated Learning,"Miguel Fernandes, Catarina Silva, Joel Arrais, Alberto Cardoso, Bernardete Ribeiro",1 - Department of Informatics Engineering Polo II Pinhal de Marrocos University of Coimbra Coimbra Portugal,"We propose two novel Federated Learning (FL) algorithms based on decaying momentum (Demon): Federated Demon (FedDemon) and Federated Demon Adam (FedDemonAdam). In particular, we apply Demon to Momentum Stochastic Gradient Descent (SGD) and Adam in a Federated setting, which has shown to improve results in a centralized environment. We empirically show that FedDemon and FedDemonAdam have a faster convergence rate and performance improvements compared to state-of-the-art algorithms including FedAvg, FedAvgM and FedAdam.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-106,2021,100.0,"Decay Momentum for Improving Federated Learning We propose two novel Federated Learning (FL) algorithms based on decaying momentum (Demon): Federated Demon (FedDemon) and Federated Demon Adam (FedDemonAdam). In particular, we apply Demon to Momentum Stochastic Gradient Descent (SGD) and Adam in a Federated setting, which has shown to improve results in a centralized environment. We empirically show that FedDemon and FedDemonAdam have a faster convergence rate and performance improvements compared to state-of-the-art algorithms including FedAvg, FedAvgM and FedAdam."
A bag of nodes primer on weightless graph classification *,"Raul Barbosa, Diego Carvalho, Priscila Lima, Felipe França","1 - Centro de Tecnologia Federal University of Rio de Janeiro (UFRJ) -PESC/COPPE Cidade Universitária Bloco H 319 -21941-972 Sala Brazil
2 - Federal Centre for Technological Education of Rio de Janeiro (CEFET/RJ) Av. Maracanã 229, 20271-110 Brazil","This paper proposes a weightless architecture for graph classification scenarios. This architecture is a three-headed arrangement composed of graph hand-picked features, a quantization method and a final classifier. Although multiple new strategies for graph classification have been proposed in recent years, it is still necessary to settle comparable studies with respect to weightless neural networks. The proposed architecture is evaluated along with other baseline classifiers and independent strategies, showing that weightless architectures are able to compete with other well-established methods such as graph kernels.",Classification,https://doi.org/10.14428/esann/2021.ES2021-107,2021,98.24561403508771,"A bag of nodes primer on weightless graph classification * This paper proposes a weightless architecture for graph classification scenarios. This architecture is a three-headed arrangement composed of graph hand-picked features, a quantization method and a final classifier. Although multiple new strategies for graph classification have been proposed in recent years, it is still necessary to settle comparable studies with respect to weightless neural networks. The proposed architecture is evaluated along with other baseline classifiers and independent strategies, showing that weightless architectures are able to compete with other well-established methods such as graph kernels."
Quantifying Resemblance of Synthetic Medical Time-Series,"Karan Bhanot, Saloni Dash, Joe Pedersen, Isabelle Guyon, Kristin Bennett","1 - Department of Computer Science Rensselaer Polytechnic Institute New York USA
2 - OptumLabs Visiting Fellow
3 - -BITS Pilani Department of CSIS -Goa Campus India
4 - Rensselaer Polytechnic Institute -Department of ISE -New York USA
5 - LISN CNRS INRIA Université Paris-Saclay France
6 - Department of Mathematics -New York Rensselaer Polytechnic Institute USA","Access to medical data is often restricted due to privacy laws e.g. HIPAA and GDPR. We address the viability of substituting real data with synthetic data to protect privacy while maintaining utility. Medical data records are fundamentally longitudinal, with one patient having multiple health events influenced by covariates like gender, age etc. Synthesis of medical data, hence, falls under time-series generative modeling. We demonstrate methods to measure synthetic medical time-series quality on datasets from previously published synthetic data research. We deploy four time-series metrics to quantify resemblance in synthetic and real covariate plots while comparing baseline data generation methods.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-108,2021,100.0,"Quantifying Resemblance of Synthetic Medical Time-Series Access to medical data is often restricted due to privacy laws e.g. HIPAA and GDPR. We address the viability of substituting real data with synthetic data to protect privacy while maintaining utility. Medical data records are fundamentally longitudinal, with one patient having multiple health events influenced by covariates like gender, age etc. Synthesis of medical data, hence, falls under time-series generative modeling. We demonstrate methods to measure synthetic medical time-series quality on datasets from previously published synthetic data research. We deploy four time-series metrics to quantify resemblance in synthetic and real covariate plots while comparing baseline data generation methods."
TSR-DSAW: Table Structure Recognition via Deep Spatial Association of Words,"Arushi Jain, Shubham Paliwal, Monika Sharma, Lovekesh Vig",1 - TCS Research Delhi India,"Existing methods for Table  Structure  Recognition (TSR) from camera-captured or scanned documents perform poorly on complextables consisting of nested rows / columns, multi-line texts and missing cell data. This is because current data-driven methods work by simply training deep models on large volumes of data and fail to generalize when an unseen table structure is encountered. In this paper, we propose to train a deep network to capture the spatial associations between different word pairs present in the table image for unravelling the table structure. We present an end-to-end pipeline, named TSR-DSAW: TSR via Deep Spatial Association of Words, which outputs a digital representation of a table image in a structured format such as HTML. Given a table image as input, the proposed method begins with the detection of all the words present in the image using a text-detection network like CRAFT which is followed by the generation of word-pairs using dynamic programming. These word-pairs are highlighted in individual images and subsequently, fed into a DenseNet-121 classifier trained to capture spatial associations such as same-row, same-column, same-cell or none. Finally, we perform post-processing on the classifier output to generate the table structure in HTML format. We evaluate our TSR-DSAW pipeline on two public table-image datasets -PubTabNet and ICDAR 2013, and demonstrate improvement over previous methods such as TableNet and DeepDeSRT.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-109,2021,100.0,"TSR-DSAW: Table Structure Recognition via Deep Spatial Association of Words Existing methods for Table  Structure  Recognition (TSR) from camera-captured or scanned documents perform poorly on complextables consisting of nested rows / columns, multi-line texts and missing cell data. This is because current data-driven methods work by simply training deep models on large volumes of data and fail to generalize when an unseen table structure is encountered. In this paper, we propose to train a deep network to capture the spatial associations between different word pairs present in the table image for unravelling the table structure. We present an end-to-end pipeline, named TSR-DSAW: TSR via Deep Spatial Association of Words, which outputs a digital representation of a table image in a structured format such as HTML. Given a table image as input, the proposed method begins with the detection of all the words present in the image using a text-detection network like CRAFT which is followed by the generation of word-pairs using dynamic programming. These word-pairs are highlighted in individual images and subsequently, fed into a DenseNet-121 classifier trained to capture spatial associations such as same-row, same-column, same-cell or none. Finally, we perform post-processing on the classifier output to generate the table structure in HTML format. We evaluate our TSR-DSAW pipeline on two public table-image datasets -PubTabNet and ICDAR 2013, and demonstrate improvement over previous methods such as TableNet and DeepDeSRT."
Predicting employee attrition with a more effective use of historical events,"Abdel-Rahmen Korichi, Hamamache Kheddouci, Daniel West","1 - UMR 5205 Université de Lyon -LIRIS Bâtiment Nautibus 43, bd du 11 novembre 1918 69622 Villeurbanne France","Attrition prediction research typically focuses on constructing models that involves one observation per employee over a limited time period, while the rest of the employees are discarded. Time-series attributes are transformed to non-time-series ones by applying statistical operations (e.g. sum, max, etc.). Such methods result in information loss and therefore less effective predictions. In this paper, we introduce a dynamic approach to employee attrition prediction, leveraging the longitudinal nature of the data, and allowing the models to generalize across behaviors and providing a closer estimate of the employee risk of leaving.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-110,2021,100.0,"Predicting employee attrition with a more effective use of historical events Attrition prediction research typically focuses on constructing models that involves one observation per employee over a limited time period, while the rest of the employees are discarded. Time-series attributes are transformed to non-time-series ones by applying statistical operations (e.g. sum, max, etc.). Such methods result in information loss and therefore less effective predictions. In this paper, we introduce a dynamic approach to employee attrition prediction, leveraging the longitudinal nature of the data, and allowing the models to generalize across behaviors and providing a closer estimate of the employee risk of leaving."
Transformers for Molecular Graph Generation,"Tim Cofala, Oliver Kramer",1 - Department of Computing Science University of Oldenburg 26129 Oldenburg Germany,"This work introduces an autoregressive generative model for graphs which is based on the transformer architecture and applied to the domain of molecular graph generation. Utilizing the multi-head self-attention mechanism to directly model distributions over atoms and bonds, it can sample new molecular graphs in an autoregressive manner. The benchmark framework MOSES is used to compare the proposed approach to other state-of-the-art molecule generation models. It is shown that the model is capable of generalizing from the training data to generate novel and realistic molecules.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-112,2021,100.0,"Transformers for Molecular Graph Generation This work introduces an autoregressive generative model for graphs which is based on the transformer architecture and applied to the domain of molecular graph generation. Utilizing the multi-head self-attention mechanism to directly model distributions over atoms and bonds, it can sample new molecular graphs in an autoregressive manner. The benchmark framework MOSES is used to compare the proposed approach to other state-of-the-art molecule generation models. It is shown that the model is capable of generalizing from the training data to generate novel and realistic molecules."
Unsupervised Real-time Anomaly Detection for Multivariate Mobile Phone Traffic Series,"Evelyne Akopyan, Angelo Furno, Nour-Eddin El, Eric Gaume","1 - Univ. Gustave Eiffel Univ. Lyon ENTPE F-69518 Lyon LICIT France
4 - Univ. Gustave Eiffel GERS F-44344 Bouguenais LEE France",Real-time anomaly detection in urban areas from massive data is a recent research field with challenging requirements. This paper presents a lightweight framework for real-time anomaly detection in multivariate time-series extracted from large-scale Mobile-phone Network Data (MND). Our solution relies on unsupervised machine learning applied to MND collected at individual antennas of a nation-wide French mobile phone network operator. The proposed framework is based on a two-step approach: (i) the offline stage aims at assessing the typical behaviour of the antennas; (ii) the online stage performs real-time comparison of incoming data with respect to the detected typical behaviour. Results related to a real case-study of terrorist attack in the city of Lyon show that our framework can successfully detect an emergency event almost instantaneously and locate the anomalous area with high precision.,Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-113,2021,100.0,Unsupervised Real-time Anomaly Detection for Multivariate Mobile Phone Traffic Series Real-time anomaly detection in urban areas from massive data is a recent research field with challenging requirements. This paper presents a lightweight framework for real-time anomaly detection in multivariate time-series extracted from large-scale Mobile-phone Network Data (MND). Our solution relies on unsupervised machine learning applied to MND collected at individual antennas of a nation-wide French mobile phone network operator. The proposed framework is based on a two-step approach: (i) the offline stage aims at assessing the typical behaviour of the antennas; (ii) the online stage performs real-time comparison of incoming data with respect to the detected typical behaviour. Results related to a real case-study of terrorist attack in the city of Lyon show that our framework can successfully detect an emergency event almost instantaneously and locate the anomalous area with high precision.
Multi-perspective embedding for non-metric time series classification,"Maximilian Münch, Simon Heilig, Frank-Michael Schleif","1 - Faculty of Computer Science and Business Information Systems Würzburg University of Applied Sciences Würzburg-Schweinfurt Germany
2 - Computer Science and Artificial Intelligence Bernoulli Institute for Mathematics University of Groningen Groningen The Netherlands","The interest in time series analysis is rapidly increasing, providing new challenges for machine learning. Over many decades, Dynamic Time Warping (DTW) is referred to as the de facto standard distance measure for time series and the tool of choice when analyzing such data. Nevertheless, DTW has two major drawbacks: (a) it is non-metric and therefore hard to handle by standard machine learning techniques, and (b) it is not well suited for multi-dimensional time series. For this purpose, we propose a multi-perspective embedding of the time series into a complex-valued vector space and the evaluation by a model that is able to handle complex-valued data. The approach is evaluated on various multi-dimensional time series data and with different classifier techniques.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-114,2021,100.0,"Multi-perspective embedding for non-metric time series classification The interest in time series analysis is rapidly increasing, providing new challenges for machine learning. Over many decades, Dynamic Time Warping (DTW) is referred to as the de facto standard distance measure for time series and the tool of choice when analyzing such data. Nevertheless, DTW has two major drawbacks: (a) it is non-metric and therefore hard to handle by standard machine learning techniques, and (b) it is not well suited for multi-dimensional time series. For this purpose, we propose a multi-perspective embedding of the time series into a complex-valued vector space and the evaluation by a model that is able to handle complex-valued data. The approach is evaluated on various multi-dimensional time series data and with different classifier techniques."
Sparse mixture of von Mises-Fisher distribution,"Florian Barbaro, Fabrice Rossi","1 - Université Paris 1 Panthéon-Sorbonne -Laboratoire SAMM EA 4543 France
2 - UMR 7534 Université Paris Dauphine-PSL -CEREMADE France",Mixtures of von Mises-Fisher distributions can be used to cluster data on the unit hypersphere. This is particularly adapted for high-dimensional directional data such as texts. We propose in this article to estimate a von Mises mixture using a l1 penalized likelihood. This leads to sparse prototypes that improve both clustering quality and interpretability. We introduce an expectation-maximisation (EM) algorithm for this estimation and show the advantages of the approach on real data benchmark. We propose to explore the trade-off between the sparsity term and the likelihood one with a simple path following algorithm. k h=1 z ih = 1.,Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-115,2021,100.0,Sparse mixture of von Mises-Fisher distribution Mixtures of von Mises-Fisher distributions can be used to cluster data on the unit hypersphere. This is particularly adapted for high-dimensional directional data such as texts. We propose in this article to estimate a von Mises mixture using a l1 penalized likelihood. This leads to sparse prototypes that improve both clustering quality and interpretability. We introduce an expectation-maximisation (EM) algorithm for this estimation and show the advantages of the approach on real data benchmark. We propose to explore the trade-off between the sparsity term and the likelihood one with a simple path following algorithm. k h=1 z ih = 1.
Estimating uncertainty in radiation oncology dose prediction with dropout and bootstrap in U-Net models,"Alyssa Vanginderdeuren, Margerie Huet-Dastarac, Ana Barragan-Montero, John Lee","1 - UCLouvain.be -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium
4 - 1-UCLouvain.be -ICTEAM Place du Levant 3 1348 Louvain-la-Neuve Belgium","Deep learning models, such as U-Net, can be used to efficiently predict the optimal dose distribution in radiotherapy treatment planning. In this work, we want to supplement the prediction model with a measurement of its uncertainty at each voxel. For this purpose, a full Bayesian approach would, however, be too costly. Instead, we compare, based on their correlation with the actual error, three simpler methods, namely, the dropout, the bootstrap and a modification of the U-Net. These methods can be easily adapted to other architectures. 200 patients with head and neck cancer were used in this work.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-117,2021,100.0,"Estimating uncertainty in radiation oncology dose prediction with dropout and bootstrap in U-Net models Deep learning models, such as U-Net, can be used to efficiently predict the optimal dose distribution in radiotherapy treatment planning. In this work, we want to supplement the prediction model with a measurement of its uncertainty at each voxel. For this purpose, a full Bayesian approach would, however, be too costly. Instead, we compare, based on their correlation with the actual error, three simpler methods, namely, the dropout, the bootstrap and a modification of the U-Net. These methods can be easily adapted to other architectures. 200 patients with head and neck cancer were used in this work."
Emotional Intensity Level Analysis of Speech Emotional Intensity Estimation,"Megumi Kawase, Minoru Nakayama",1 - Tokyo Institute of Technology -School of Engineering Meguro Tokyo Japan,"An estimation procedure using three models to determine the appropriate emotional intensity from the 10 listed emotional intensity classes for utterances has been developed in order to support better communication between humans and machines. In order to improve estimation performance, utterances were divided into segments and an estimated emotional intensity and its probability were produced as outputs. Two feature vectors were produced from the outputs and these features were used for the utterance-level classification using Support Vector Machine and Random Forest techniques. In the results, the accuracy of emotional intensity estimation in two out of three models was improved using the procedure proposed. In addition, features which contributed to the estimations were analyzed.",Machine Learning for Measuring and Analyzing Online Social Communications,https://doi.org/10.14428/esann/2021.ES2021-118,2021,100.0,"Emotional Intensity Level Analysis of Speech Emotional Intensity Estimation An estimation procedure using three models to determine the appropriate emotional intensity from the 10 listed emotional intensity classes for utterances has been developed in order to support better communication between humans and machines. In order to improve estimation performance, utterances were divided into segments and an estimated emotional intensity and its probability were produced as outputs. Two feature vectors were produced from the outputs and these features were used for the utterance-level classification using Support Vector Machine and Random Forest techniques. In the results, the accuracy of emotional intensity estimation in two out of three models was improved using the procedure proposed. In addition, features which contributed to the estimations were analyzed."
Multivariate Time Series Multi-Coclustering. Application to Advanced Driving Assistance System Validation,"Etienne Goffinet, Mustapha Lebbah, Hanane Azzag, Loïc Giraldi, Anthony Coutant","1 - LIPN-UMR 7030 Sorbonne Paris-Nord University Villetaneuse France
2 - Groupe Renault SAS Avenue du Golf Guyancourt France
5 - CEA, DES IRESNE 4-HephIA, 30, rue de Gramont 13108 Saint-Paul-Lez-Durance, Paris DEC France, France","Driver assistance systems development remains a technical challenge for car manufacturers. Validating these systems requires to assess the assistance systems performances in a considerable number of driving contexts. Groupe Renault uses massive simulation for this task, which allows reproducing the complexity of physical driving conditions precisely and produces large volumes of multivariate time series. We present the operational constraints and scientific challenges related to these datasets and our proposal of an adapted model-based multiple coclustering approach, which creates several independent partitions by grouping redundant variables. This method natively performs model selection, missing values inference, noisy samples handling, confidence interval production, while keeping a sparse parameter numbers. The proposed model is evaluated on a synthetic dataset, and applied to a driver assistance system validation use-case.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-119,2021,100.0,"Multivariate Time Series Multi-Coclustering. Application to Advanced Driving Assistance System Validation Driver assistance systems development remains a technical challenge for car manufacturers. Validating these systems requires to assess the assistance systems performances in a considerable number of driving contexts. Groupe Renault uses massive simulation for this task, which allows reproducing the complexity of physical driving conditions precisely and produces large volumes of multivariate time series. We present the operational constraints and scientific challenges related to these datasets and our proposal of an adapted model-based multiple coclustering approach, which creates several independent partitions by grouping redundant variables. This method natively performs model selection, missing values inference, noisy samples handling, confidence interval production, while keeping a sparse parameter numbers. The proposed model is evaluated on a synthetic dataset, and applied to a driver assistance system validation use-case."
Dynamic clustering and modeling of temporal data subject to common regressive effects,"Louise Bonfils, Allou Samé, Latifa Oukhellou",1 - Université Gustave Eiffel COSYS-GRETTIA Champs-sur-Marne France,"Clustering is used in many applicative fields to summarize information into a small number of groups. Motivated by behavioral extraction issues from urban data, the interest of this paper is to propose a classification method that allows modeling the evolution of cluster profiles over time while considering common regressive effects. The parameters of the proposed model are estimated using variational approximation because maximum likelihood estimation is not suitable in this case. The ability of the model to estimate parameters is evaluated using various simulated data and compared with two other models.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-121,2021,100.0,"Dynamic clustering and modeling of temporal data subject to common regressive effects Clustering is used in many applicative fields to summarize information into a small number of groups. Motivated by behavioral extraction issues from urban data, the interest of this paper is to propose a classification method that allows modeling the evolution of cluster profiles over time while considering common regressive effects. The parameters of the proposed model are estimated using variational approximation because maximum likelihood estimation is not suitable in this case. The ability of the model to estimate parameters is evaluated using various simulated data and compared with two other models."
Judging competitions and benchmarks: a candidate election approach,"Adrien Pavao, Michael Vaccaro, Isabelle Guyon",1 - LISN/CNRS INRIA Université Paris-Saclay France,"Machine learning progress relies on algorithm benchmarks. We study the problem of declaring a winner, or ranking ""candidate"" algorithms, based on results obtained by ""judges"" (scores on various tasks). Inspired by social science and game theory on fair elections, we compare various ranking functions, ranging from simple score averaging to Condorcet methods. We devise novel empirical criteria to assess the quality of ranking functions, including the generalization to new tasks and the stability under judge or candidate perturbation. We conduct an empirical comparison on the results of 5 competitions and benchmarks (one artificially generated). While prior theoretical analyses indicate that no single ranking function satisfies all desired properties, our empirical study reveals that the classical ""average rank"" method fares well. However, some pairwise comparison methods can get better empirical results.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-122,2021,100.0,"Judging competitions and benchmarks: a candidate election approach Machine learning progress relies on algorithm benchmarks. We study the problem of declaring a winner, or ranking ""candidate"" algorithms, based on results obtained by ""judges"" (scores on various tasks). Inspired by social science and game theory on fair elections, we compare various ranking functions, ranging from simple score averaging to Condorcet methods. We devise novel empirical criteria to assess the quality of ranking functions, including the generalization to new tasks and the stability under judge or candidate perturbation. We conduct an empirical comparison on the results of 5 competitions and benchmarks (one artificially generated). While prior theoretical analyses indicate that no single ranking function satisfies all desired properties, our empirical study reveals that the classical ""average rank"" method fares well. However, some pairwise comparison methods can get better empirical results."
Context-specific sampling method for contextual explanations,"Manik Madhikermi, Avleen Malhi, Kary Främling","1 - Department of computing science Umeå Umeå University Sweden
2 - Computer science Department Aalto University Espoo Finland
4 - Department of computing and informatics Bournemouth Bournemouth University United Kingdom","Explaining the result of machine learning models is an active research topic in Artificial Intelligence (AI) domain with an objective to provide mechanisms to understand and interpret the results of the underlying black-box model in a human-understandable form. With this objective, several eXplainable Artificial Intelligence (XAI) methods have been designed and developed based on varied fundamental principles. Some methods such as Local interpretable model agnostic explanations (LIME), SHAP (SHapley Additive exPlanations) are based on the surrogate model while others such as Contextual Importance and Utility (CIU) do not create or rely on the surrogate model to generate its explanation. Despite the difference in underlying principles, these methods use different sampling techniques such as uniform sampling, weighted sampling for generating explanations. CIU, which emphasizes a context-aware decision explanation, employs a uniform sampling method for the generation of representative samples. In this research, we target uniform sampling methods which generate representative samples that do not guarantee to be representative in the presence of strong non-linearities or exceptional input feature value combinations. The objective of this research is to develop a sampling method that addresses these concerns. To address this need, a new adaptive weighted sampling method has been proposed. In order to verify its efficacy in generating explanations, the proposed method has been integrated with CIU, and tested by deploying the special test case.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-124,2021,100.0,"Context-specific sampling method for contextual explanations Explaining the result of machine learning models is an active research topic in Artificial Intelligence (AI) domain with an objective to provide mechanisms to understand and interpret the results of the underlying black-box model in a human-understandable form. With this objective, several eXplainable Artificial Intelligence (XAI) methods have been designed and developed based on varied fundamental principles. Some methods such as Local interpretable model agnostic explanations (LIME), SHAP (SHapley Additive exPlanations) are based on the surrogate model while others such as Contextual Importance and Utility (CIU) do not create or rely on the surrogate model to generate its explanation. Despite the difference in underlying principles, these methods use different sampling techniques such as uniform sampling, weighted sampling for generating explanations. CIU, which emphasizes a context-aware decision explanation, employs a uniform sampling method for the generation of representative samples. In this research, we target uniform sampling methods which generate representative samples that do not guarantee to be representative in the presence of strong non-linearities or exceptional input feature value combinations. The objective of this research is to develop a sampling method that addresses these concerns. To address this need, a new adaptive weighted sampling method has been proposed. In order to verify its efficacy in generating explanations, the proposed method has been integrated with CIU, and tested by deploying the special test case."
Fourier-based Video Prediction through Relational Object Motion,"Malte Mosbach, Sven Behnke",1 - University of Bonn Computer Science Institute VI Autonomous Intelligent Systems Friedrich-Hirzebruch-Allee 5 53115 Bonn Germany,"The ability to predict future outcomes conditioned on observed video frames is crucial for intelligent decision-making in autonomous systems. Recently, deep recurrent architectures have been applied to the task of video prediction. However, this often results in blurry predictions and requires tedious training on large datasets. Here, we explore a different approach by (1) using frequency-domain approaches for video prediction and (2) explicitly inferring object-motion relationships in the observed scene. The resulting predictions are consistent with the observed dynamics in a scene and do not suffer from blur.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-125,2021,100.0,"Fourier-based Video Prediction through Relational Object Motion The ability to predict future outcomes conditioned on observed video frames is crucial for intelligent decision-making in autonomous systems. Recently, deep recurrent architectures have been applied to the task of video prediction. However, this often results in blurry predictions and requires tedious training on large datasets. Here, we explore a different approach by (1) using frequency-domain approaches for video prediction and (2) explicitly inferring object-motion relationships in the observed scene. The resulting predictions are consistent with the observed dynamics in a scene and do not suffer from blur."
Pruning Neural Networks with Supermasks,"Vincent Rolfs, Matthias Kerzel, Stefan Wermter",1 - Department of Informatics University of Hamburg Vogt-Koelln-Str.30 22527 Hamburg Germany,"The Lottery Ticket hypothesis by Frankle and Carbin states that a randomly initialized dense network contains a smaller subnetwork that, when trained in isolation, will match the performance of the original network. However, identifying this pruned subnetwork usually requires repeated training to determine optimal pruning thresholds. We present a novel approach to accelerate the pruning: By methodically evaluating different Supermasks, the threshold for selecting neurons as part of a pruned Lottery Ticket network can be determined without additional training. We evaluate the method on the MNIST dataset and achieve a size reduction of over 60% without a drop in performance. * The authors gratefully acknowledge partial support from the German Research Foundation DFG under project CML (TRR 169).",Model selection,https://doi.org/10.14428/esann/2021.ES2021-126,2021,100.0,"Pruning Neural Networks with Supermasks The Lottery Ticket hypothesis by Frankle and Carbin states that a randomly initialized dense network contains a smaller subnetwork that, when trained in isolation, will match the performance of the original network. However, identifying this pruned subnetwork usually requires repeated training to determine optimal pruning thresholds. We present a novel approach to accelerate the pruning: By methodically evaluating different Supermasks, the threshold for selecting neurons as part of a pruned Lottery Ticket network can be determined without additional training. We evaluate the method on the MNIST dataset and achieve a size reduction of over 60% without a drop in performance. * The authors gratefully acknowledge partial support from the German Research Foundation DFG under project CML (TRR 169)."
Object Detection on Thermal Images: Performance of YOLOv4 Trained on Small Datasets,"Maxence Chaverot, Maxime Carré, Michel Jourlin, Abdelaziz Bensrhair, Richard Grisel","1 - INSA Rouen LITIS 685 Avenue
2 - Université 76800 SaintÉtienneduRouvray France 2 NT2I 10 Rue Jean Servanton 42000 SaintÉtienne France
3 - Hubert Curien Laboratory 18 Rue Professeur Benoît Lauras 42000 SaintÉtienne France
6 - INSA Rouen 685 Avenue de l'Université 76800 SaintÉtienneduRouvray France","Thermal sensors are underrepresented in the field of Advanced Driver Assistance Systems whereas their capabilities to acquire images independently of weather or daytime can be very helpful to achieve optimal pedestrian and vehicle detection. This underrepresentation is due to the small amount of available public datasets. This lack of training samples and the difficulties of building such datasets are a real hurdle to the development of an object detector dedicated to thermal images. Thanks to YOLOv4 and its detection performance, we show in this paper that finetuning this neural network requires few samples to achieve satisfying performance, outperforming the results of stateoftheart detectors.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-130,2021,100.0,"Object Detection on Thermal Images: Performance of YOLOv4 Trained on Small Datasets Thermal sensors are underrepresented in the field of Advanced Driver Assistance Systems whereas their capabilities to acquire images independently of weather or daytime can be very helpful to achieve optimal pedestrian and vehicle detection. This underrepresentation is due to the small amount of available public datasets. This lack of training samples and the difficulties of building such datasets are a real hurdle to the development of an object detector dedicated to thermal images. Thanks to YOLOv4 and its detection performance, we show in this paper that finetuning this neural network requires few samples to achieve satisfying performance, outperforming the results of stateoftheart detectors."
IF: Iterative Fractional Optimization,"Sarthak Chatterjee, Subhro Das, Sérgio Pequito","1 - Department of Electrical Computer, and Systems Engineering Rensselaer Polytechnic Institute Troy NY USA
2 - MIT-IBM Watson AI Lab IBM Research Cambridge MA USA
3 - Delft Center for Systems and Control Delft University of Technology The Netherlands","Most optimization problems lack closed-form solutions of the argument that minimizes a given function, and even if these were available it might be prohibitive to compute it. As such, we rely on iterative numerical algorithms to find an approximate solution. In this paper, we propose to leverage fractional calculus in the context of time series analysis methods to devise a new iterative algorithm. Specifically, we propose to leverage autoregressive fractional-order integrative moving average time series, whose coefficients encode a proxy for local spatial information. We provide evidence that our algorithm is efficient and particularly suitable for cases where the Hessian is ill-conditioned.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-133,2021,100.0,"IF: Iterative Fractional Optimization Most optimization problems lack closed-form solutions of the argument that minimizes a given function, and even if these were available it might be prohibitive to compute it. As such, we rely on iterative numerical algorithms to find an approximate solution. In this paper, we propose to leverage fractional calculus in the context of time series analysis methods to devise a new iterative algorithm. Specifically, we propose to leverage autoregressive fractional-order integrative moving average time series, whose coefficients encode a proxy for local spatial information. We provide evidence that our algorithm is efficient and particularly suitable for cases where the Hessian is ill-conditioned."
Towards Robust Auxiliary Tasks for Language Adaptation,"Gil Rocha, Henrique Lopes Cardoso",1 - Faculdade de Engenharia Laboratório de Inteligência Artificial e Ciência de Computadores (LIACC) Universidade do Porto Porto Portugal,"To overcome the lack of annotated resources in less-resourced languages, unsupervised language adaptation methods have been explored. Based on multilingual word embeddings, Adversarial Training has been successfully employed in a variety of tasks and languages. With recent neural language models, empirical analysis on the task of natural language inference suggests that more challenging auxiliary tasks for Adversarial Training should be formulated to further improve language adaptation. We propose rethinking such auxiliary tasks for language adaptation.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-134,2021,100.0,"Towards Robust Auxiliary Tasks for Language Adaptation To overcome the lack of annotated resources in less-resourced languages, unsupervised language adaptation methods have been explored. Based on multilingual word embeddings, Adversarial Training has been successfully employed in a variety of tasks and languages. With recent neural language models, empirical analysis on the task of natural language inference suggests that more challenging auxiliary tasks for Adversarial Training should be formulated to further improve language adaptation. We propose rethinking such auxiliary tasks for language adaptation."
Constraint optimization for Echo State Networks applied to satellite image forecasting,"Yannic Lieder, Jochen Steil",1 - Technische Universität Braunschweig -Institut für Robotik und Prozessinformatik,"The paper proposes to deal with noisy, sparse or short training data sequences by adding domain knowledge to the learning process of Echo State Networks (ESNs). Known constraints like monotony in the output, periodicity or bounds on output values are encoded as inequality constraints on the output weights to be learned. Exploiting that the output of an ESN is linear in the weights, Quadratic Programming is then used to obtain and optimize these. The method is applied to the prediction of pixel values from monthly, noisy satellite images of a short history of five years, thereby enabling the cleaning of images from clouds or snow.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-135,2021,100.0,"Constraint optimization for Echo State Networks applied to satellite image forecasting The paper proposes to deal with noisy, sparse or short training data sequences by adding domain knowledge to the learning process of Echo State Networks (ESNs). Known constraints like monotony in the output, periodicity or bounds on output values are encoded as inequality constraints on the output weights to be learned. Exploiting that the output of an ESN is linear in the weights, Quadratic Programming is then used to obtain and optimize these. The method is applied to the prediction of pixel values from monthly, noisy satellite images of a short history of five years, thereby enabling the cleaning of images from clouds or snow."
Continual Learning at the Edge: Real-Time Training on Smartphone Devices,"Lorenzo Pellegrini, Vincenzo Lomonaco, Gabriele Graffieti, Davide Maltoni","1 - University of Bologna -Computer Science Department Via Cesare Pavese 50 47521 Cesena Italy
2 - University of Pisa -Computer Science Department Largo B. Pontecorvo 56127 Pisa Italy","On-device training for personalized learning is a challenging research problem. Being able to quickly adapt deep prediction models at the edge is necessary to better suit personal user needs. However, adaptation on the edge poses some questions on both the efficiency and sustainability of the learning process and on the ability to work under shifting data distributions. Indeed, naively fine-tuning a prediction model only on the newly available data results in catastrophic forgetting, a sudden erasure of previously acquired knowledge. In this paper, we detail the implementation and deployment of a hybrid continual learning strategy (AR1*) on a native Android application for real-time on-device personalization without forgetting. Our benchmark, based on an extension of the CORe50 dataset, shows the efficiency and effectiveness of our solution.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-136,2021,100.0,"Continual Learning at the Edge: Real-Time Training on Smartphone Devices On-device training for personalized learning is a challenging research problem. Being able to quickly adapt deep prediction models at the edge is necessary to better suit personal user needs. However, adaptation on the edge poses some questions on both the efficiency and sustainability of the learning process and on the ability to work under shifting data distributions. Indeed, naively fine-tuning a prediction model only on the newly available data results in catastrophic forgetting, a sudden erasure of previously acquired knowledge. In this paper, we detail the implementation and deployment of a hybrid continual learning strategy (AR1*) on a native Android application for real-time on-device personalization without forgetting. Our benchmark, based on an extension of the CORe50 dataset, shows the efficiency and effectiveness of our solution."
A Parameterless t-SNE for Faithful Cluster Embeddings from Prototype-based Learning and CONN Similarity,"Josh Taylor, Erzsébet Merényi","1 - Department of Statistics -Rice University 6100 Main St Houston Texas USA
2 - Departments of Statistics & Electrical and Computer Engineering Rice University","We propose an improvement to t-SNE which allows automated specification of its perplexity parameter using topological information about a data manifold revealed through neural prototype-based learning. This information is contained in the CONN (CONNectivity) similarity of neural prototypes, which expresses the strength (weakness) of topological connectivity at various points within the manifold. Experiments show that improvements, collectively called CONNt-SNE, are capable of producing meaningful and trustworthy low-dimensional embeddings without the need to heuristically optimize over (i.e., grid search) t-SNE's perplexity space. Data-driven perplexity determination improves our confidence that any structure appearing in the embeddings is valid and not merely an artifact of spurious parameterization.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-138,2021,100.0,"A Parameterless t-SNE for Faithful Cluster Embeddings from Prototype-based Learning and CONN Similarity We propose an improvement to t-SNE which allows automated specification of its perplexity parameter using topological information about a data manifold revealed through neural prototype-based learning. This information is contained in the CONN (CONNectivity) similarity of neural prototypes, which expresses the strength (weakness) of topological connectivity at various points within the manifold. Experiments show that improvements, collectively called CONNt-SNE, are capable of producing meaningful and trustworthy low-dimensional embeddings without the need to heuristically optimize over (i.e., grid search) t-SNE's perplexity space. Data-driven perplexity determination improves our confidence that any structure appearing in the embeddings is valid and not merely an artifact of spurious parameterization."
SmoothLRP: Smoothing LRP by Averaging over Stochastic Input Variations,"Arne Raulf, Sina Däubener, Ben Luis Hack, Axel Mosig, Asja Fischer","1 - Department of Bioinformatics Ruhr University Bochum Germany
2 - Department of Mathematics Ruhr University Bochum Germany","Explanations of neural networks predictions are a necessity for deploying neural networks in safety critical domains. Several methods were developed which identify most relevant input features, such as sensitivity analysis and layer-wise relevance propagation (LRP). It has been shown that the noise in the explanations from the sensitivity analysis can be reduced by averaging over noisy input images, a method referred to as SmoothGrad. We investigate the application of the same principle to LRP and find that it smooths the resulting relevance function leading to improved explanations. Moreover, it can be applied for restoring the correct label of adversarial examples. * Equal contribution.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-139,2021,100.0,"SmoothLRP: Smoothing LRP by Averaging over Stochastic Input Variations Explanations of neural networks predictions are a necessity for deploying neural networks in safety critical domains. Several methods were developed which identify most relevant input features, such as sensitivity analysis and layer-wise relevance propagation (LRP). It has been shown that the noise in the explanations from the sensitivity analysis can be reduced by averaging over noisy input images, a method referred to as SmoothGrad. We investigate the application of the same principle to LRP and find that it smooths the resulting relevance function leading to improved explanations. Moreover, it can be applied for restoring the correct label of adversarial examples. * Equal contribution."
Evolutionary Deep Multi-Task Learning,"Patrick Burke, Jonas Prellberg, Oliver Kramer",1 - Department of Computer Science University of Oldenburg 26122 Oldenburg Germany,"Multi-task learning is an approach to reduce the amount of required training data by learning multiple tasks at the same time. In the context of neural networks, multi-task learning is performed by sharing weights or creating dependencies between weights of task-specific networks. In this work, we propose an algorithm that uses a simple evolutionary algorithm, which is able to match and also surpass learned weight sharing. We evaluate the performance of this method on CIFAR-100, cast as a multi-tasking problem, using an 18-layer residual network, and compare our results to literature.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-14,2021,100.0,"Evolutionary Deep Multi-Task Learning Multi-task learning is an approach to reduce the amount of required training data by learning multiple tasks at the same time. In the context of neural networks, multi-task learning is performed by sharing weights or creating dependencies between weights of task-specific networks. In this work, we propose an algorithm that uses a simple evolutionary algorithm, which is able to match and also surpass learned weight sharing. We evaluate the performance of this method on CIFAR-100, cast as a multi-tasking problem, using an 18-layer residual network, and compare our results to literature."
Tangent Graph Convolutional Network,"Luca Pasa, Nicolò Navarin, Alessandro Sperduti","1 - University of Padua Department of Mathematics ""Tullio Levi-Civita"" Human Inspired Technology Research Centre (HIT) via Trieste 63 35121 Padua Italy","Most Graph Convolutions (GCs)   proposed in the Graph Neural Networks (GNNs) literature share the principle of computing topologically enriched node representations based on the ones of their neighbors. In this paper, we propose a novel GNN named Tangent Graph Convolutional Network (TGCN) that, in addition to the traditional GC approach, exploits a novel GC that computes node embeddings based on the differences between the attributes of a vertex and the attributes of its neighbors. This allows the GC to characterize each node's neighbor by computing its tangent space representation with respect to the considered vertex.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-143,2021,100.0,"Tangent Graph Convolutional Network Most Graph Convolutions (GCs)   proposed in the Graph Neural Networks (GNNs) literature share the principle of computing topologically enriched node representations based on the ones of their neighbors. In this paper, we propose a novel GNN named Tangent Graph Convolutional Network (TGCN) that, in addition to the traditional GC approach, exploits a novel GC that computes node embeddings based on the differences between the attributes of a vertex and the attributes of its neighbors. This allows the GC to characterize each node's neighbor by computing its tangent space representation with respect to the considered vertex."
Application of Graph Convolutions in a Lightweight Model for Skeletal Human Motion Forecasting,"Luca Hermes, Barbara Hammer, Malte Schilling",1 - Machine Learning Group Bielefeld University 33501 Bielefeld Germany,Prediction of movements is essential for successful cooperation with intelligent systems. We propose a model that integrates organized spatial information as given through the moving body's skeletal structure. This inherent structure is exploited in our model through application of Graph Convolutions and we demonstrate how this allows leveraging the structured spatial information into competitive predictions that are based on a lightweight model that requires a comparatively small number of parameters.,Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-145,2021,100.0,Application of Graph Convolutions in a Lightweight Model for Skeletal Human Motion Forecasting Prediction of movements is essential for successful cooperation with intelligent systems. We propose a model that integrates organized spatial information as given through the moving body's skeletal structure. This inherent structure is exploited in our model through application of Graph Convolutions and we demonstrate how this allows leveraging the structured spatial information into competitive predictions that are based on a lightweight model that requires a comparatively small number of parameters.
Lifelong Learning from Event-based Data,"Vadym Gryshchuk, Cornelius Weber, Chu Kiong Loo, Stefan Wermter","1 - Department of Informatics University of Hamburg Vogt-Koelln-Strasse 30 22527 Hamburg Germany
3 - Department of Artificial Intelligence Lembah Pantai University of Malaya 50603 Kuala Lumpur Malaysia","Lifelong learning is a long-standing aim for artificial agents that act in dynamic environments, in which an agent needs to accumulate knowledge incrementally without forgetting previously learned representations. We investigate methods for learning from data produced by event cameras and compare techniques to mitigate forgetting while learning incrementally. We propose a model that is composed of both, feature extraction and continuous learning. Furthermore, we introduce a habituationbased method to mitigate forgetting. Our experimental results show that the combination of different techniques can help to avoid catastrophic forgetting while learning incrementally from the features provided by the extraction module.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-146,2021,100.0,"Lifelong Learning from Event-based Data Lifelong learning is a long-standing aim for artificial agents that act in dynamic environments, in which an agent needs to accumulate knowledge incrementally without forgetting previously learned representations. We investigate methods for learning from data produced by event cameras and compare techniques to mitigate forgetting while learning incrementally. We propose a model that is composed of both, feature extraction and continuous learning. Furthermore, we introduce a habituationbased method to mitigate forgetting. Our experimental results show that the combination of different techniques can help to avoid catastrophic forgetting while learning incrementally from the features provided by the extraction module."
Improving Graph Variational Autoencoders with Multi-Hop Simple Convolutions,"Erik Jhones, F Do Nascimento, Amauri Souza, Diego Mesquita","1 - Department of Computer Science Fortaleza Federal Institute of Ceará Brazil
3 - Department of Computer Science Espoo Aalto University Finland","Variational auto-encoding architectures represent one of the most popular approaches to graph generative modeling. These models comprise encoder and a decoder networks, which map back and forth between the input and latent spaces. Notably, most of the literature in variational autoencoders (VAEs) for graphs focuses on developing more efficient architectures at the expense of increased complexity. In this work, we pursue an orthogonal direction and leverage multi-hop linear graph convolutional layers to create efficient yet simple encoders, boosting the performance of graph autoencoders. Our results demonstrate that our approach outperforms popular graph VAE baselines in link prediction tasks.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-147,2021,100.0,"Improving Graph Variational Autoencoders with Multi-Hop Simple Convolutions Variational auto-encoding architectures represent one of the most popular approaches to graph generative modeling. These models comprise encoder and a decoder networks, which map back and forth between the input and latent spaces. Notably, most of the literature in variational autoencoders (VAEs) for graphs focuses on developing more efficient architectures at the expense of increased complexity. In this work, we pursue an orthogonal direction and leverage multi-hop linear graph convolutional layers to create efficient yet simple encoders, boosting the performance of graph autoencoders. Our results demonstrate that our approach outperforms popular graph VAE baselines in link prediction tasks."
Deep Echo State Networks for Functional Ambulation Categories Estimation,"L Pedrelli, E Bergamini, M Tramontano, G Vannozzi, A Mannini","1 - The BioRobotics Institute
2 - Scuola Superiore Sant'Anna Pisa Italy
3 - Fondazione Santa Lucia IRCCS Rome Italy
5 - Dept. of Movement, Human and Health Sciences University of Rome Foro Italico Rome Italy
9 - IRCCS Fondazione Don Carlo Gnocchi Firenze Italy","In this work, we introduce a novel application for the automatic estimation of Functional Ambulatory Category (FAC) based on deep Echo State Networks (ESNs). FAC is a clinical scale for assessing the gait ability used in post-stroke rehabilitation and, in general, for disease monitoring. In this application, the estimation is performed automatically by analyzing signals gathered from wearable sensors (located on both tibiae, pelvis, trunk and head) during the execution of a walking test. This is performed by analysing the whole time-series through the DeepESN model without preprocessing. The experimental results show that the use of a deep recurrent neural network allows the model to exploit the richness contained in the whole raw temporal signal improving the performance w.r.t. the shallow recurrent model. Overall, our approach obtained 0.37 of mean absolute error with a maximum error of 0.78 resulting very accurate in the classification of the gait ability through the estimation of the FAC value. Considering the experimental results obtained, the proposed approach represents a good baseline for medical applications based on the automatic estimation of the FAC scale.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-149,2021,100.0,"Deep Echo State Networks for Functional Ambulation Categories Estimation In this work, we introduce a novel application for the automatic estimation of Functional Ambulatory Category (FAC) based on deep Echo State Networks (ESNs). FAC is a clinical scale for assessing the gait ability used in post-stroke rehabilitation and, in general, for disease monitoring. In this application, the estimation is performed automatically by analyzing signals gathered from wearable sensors (located on both tibiae, pelvis, trunk and head) during the execution of a walking test. This is performed by analysing the whole time-series through the DeepESN model without preprocessing. The experimental results show that the use of a deep recurrent neural network allows the model to exploit the richness contained in the whole raw temporal signal improving the performance w.r.t. the shallow recurrent model. Overall, our approach obtained 0.37 of mean absolute error with a maximum error of 0.78 resulting very accurate in the classification of the gait ability through the estimation of the FAC value. Considering the experimental results obtained, the proposed approach represents a good baseline for medical applications based on the automatic estimation of the FAC scale."
Privacy-Preserving Kernel Computation For Vertically Partitioned Data,"Mirko Polato, Alberto Gallinaro, Fabio Aiolli",1 - Department of Mathematics University of Padova Italy,"In this paper, we propose a secure and privacy-preserving technique for computing dot-product kernels on vertically distributed data. Our proposal is based on secure multi-party computation which provides theoretical guarantees on both security and privacy. We also provide a practical application of the method by adapting a kernel-based collaborative filtering technique to the federated setting. An extensive experimental evaluation shows the effectiveness of the proposed approach.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-152,2021,100.0,"Privacy-Preserving Kernel Computation For Vertically Partitioned Data In this paper, we propose a secure and privacy-preserving technique for computing dot-product kernels on vertically distributed data. Our proposal is based on secure multi-party computation which provides theoretical guarantees on both security and privacy. We also provide a practical application of the method by adapting a kernel-based collaborative filtering technique to the federated setting. An extensive experimental evaluation shows the effectiveness of the proposed approach."
Gradient representations in ReLU networks as similarity functions,"Dániel Rácz, Bálint Daróczy","1 - Institute of Mathematics Pázmány Eötvos Loránd University Péter sétány 1/C H-1117 Budapest Hungary
2 - Institute for Computer Science and Control SZTAKI Kende utca 13-17 H-1111 Budapest ELKH, Hungary
3 - Université catholique de Louvain INMA/ICTEAM Avenue Georges Lemaître 4 B-1348 Louvain-la-Neuve Belgium",Feed-forward networks can be interpreted as mappings with linear decision surfaces at the level of the last layer. We investigate how the tangent space of the network can be exploited to refine the decision in case of ReLU (Rectified Linear Unit) activations. We show that a simple Riemannian metric parametrized on the parameters of the network forms a similarity function at least as good as the original network and we suggest a sparse metric to increase the similarity gap.,Classification,https://doi.org/10.14428/esann/2021.ES2021-153,2021,100.0,Gradient representations in ReLU networks as similarity functions Feed-forward networks can be interpreted as mappings with linear decision surfaces at the level of the last layer. We investigate how the tangent space of the network can be exploited to refine the decision in case of ReLU (Rectified Linear Unit) activations. We show that a simple Riemannian metric parametrized on the parameters of the network forms a similarity function at least as good as the original network and we suggest a sparse metric to increase the similarity gap.
Handling Correlations in Random Forests: which Impacts on Variable Importance and Model Interpretability?,"Marie Chavent, Jerome Lacaille, Alex Mourer, Madalina Olteanu","1 - UMR CNRS 5251 Inria bdx sud ouest, équipe ASTRAL -IMB
3 - UMR 7534 CEREMADE Université Paris Dauphine PSL France
4 - Université Pantheon Sorbonne 4543 France","The present manuscript tackles the issues of model interpretability and variable importance in random forests, in the presence of correlated input variables. Variable importance criteria based on random permutations are known to be sensitive when input variables are correlated, and may lead for instance to unreliability in the importance ranking. In order to overcome some of the problems raised by correlation, an original variable importance measure is introduced. The proposed measure builds upon an algorithm which clusters the input variables based on their correlations, and summarises each such cluster by a synthetic variable. The effectiveness of the proposed criterion is illustrated through simulations in a regression context, and compared with several existing variable importance measures.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-155,2021,100.0,"Handling Correlations in Random Forests: which Impacts on Variable Importance and Model Interpretability? The present manuscript tackles the issues of model interpretability and variable importance in random forests, in the presence of correlated input variables. Variable importance criteria based on random permutations are known to be sensitive when input variables are correlated, and may lead for instance to unreliability in the importance ranking. In order to overcome some of the problems raised by correlation, an original variable importance measure is introduced. The proposed measure builds upon an algorithm which clusters the input variables based on their correlations, and summarises each such cluster by a synthetic variable. The effectiveness of the proposed criterion is illustrated through simulations in a regression context, and compared with several existing variable importance measures."
Semi-supervised learning with Bayesian Confidence Propagation Neural Network,"Naresh Ravichandran, Anders Lansner, Pawel Herman","1 - Computational Brain Science Lab KTH Royal Institute of Technology 10044 Stockholm Sweden
3 - Department of Mathematics Stockholm University 10691 Stockholm Sweden","Learning internal representations from data using no or few labels is useful for machine learning research, as it allows using massive amounts of unlabeled data. In this work, we use the Bayesian Confidence Propagation Neural Network (BCPNN) model developed as a biologically plausible model of the cortex. Recent work has demonstrated that these networks can learn useful internal representations from data using local Bayesian-Hebbian learning rules. In this work, we show how such representations can be leveraged in a semi-supervised setting by introducing and comparing different classifiers. We also evaluate and compare such networks with other popular semi-supervised classifiers.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-156,2021,100.0,"Semi-supervised learning with Bayesian Confidence Propagation Neural Network Learning internal representations from data using no or few labels is useful for machine learning research, as it allows using massive amounts of unlabeled data. In this work, we use the Bayesian Confidence Propagation Neural Network (BCPNN) model developed as a biologically plausible model of the cortex. Recent work has demonstrated that these networks can learn useful internal representations from data using local Bayesian-Hebbian learning rules. In this work, we show how such representations can be leveraged in a semi-supervised setting by introducing and comparing different classifiers. We also evaluate and compare such networks with other popular semi-supervised classifiers."
CAS-Net: A Novel Coronary Artery Segmentation Neural Network,"Rawaa Hamdi, Asma Kerkeni, Mohamed Bedoui, Asma Abdallah","1 - Faculty of Medicine Laboratory of Technology and Medical Imaging University of Monastir Tunisia
2 - Faculty of Sciences of Monastir University of Monastir Tunisia
4 - Higher Institute of Computer Sciences and Mathematics University of Monastir Tunisia","In conventional X-ray coronary angiography, accurate coronary artery segmentation is a crucial and challenging step in the assessment of coronary artery disease. In this paper, we propose a new architecture (CAS-Net) for coronary artery segmentation. It is based on Residual U-Net and it includes both channel and spatial attention mechanism in the center part to generate hierarchical rich features of coronary arteries. Experiments are conducted on a private dataset of 150 images. The results show that CAS-Net outperforms the state-of-the-art methods achieving the highest accuracy of 96.91% and Dice of 82.70%.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-157,2021,100.0,"CAS-Net: A Novel Coronary Artery Segmentation Neural Network In conventional X-ray coronary angiography, accurate coronary artery segmentation is a crucial and challenging step in the assessment of coronary artery disease. In this paper, we propose a new architecture (CAS-Net) for coronary artery segmentation. It is based on Residual U-Net and it includes both channel and spatial attention mechanism in the center part to generate hierarchical rich features of coronary arteries. Experiments are conducted on a private dataset of 150 images. The results show that CAS-Net outperforms the state-of-the-art methods achieving the highest accuracy of 96.91% and Dice of 82.70%."
Temperature as a Regularizer for Semantic Segmentation,"Chanho Kim, Won-Sook Lee",1 - School of Electrical Engineering and Computer Science (EECS) University of Ottawa 800 King Edward Ave Ottawa ON CANADA,"A data-oriented approach including all deep learning methods is usually suffered by overfitting. A regularizer has been, from the beginning, introduced to resolve this problem. Inspired by Generative Adversarial Network (GAN), our framework generates the adversarial loss to penalize a segmentation model like a regularizer. We introduce temperature as a regularizer when calculating Least-Square losses. Temperature affects losses in both a discriminator and a generator in our DCGAN framework. Our experiment suggests L2 losses on top of the original LSGAN losses for optimization. This new regularizer using temperature improves semantic Segmentation accuracy both in Pixel accuracy and mean Intersection-of Union. 
 Related Works Generative Adversarial Network: Started from the first GAN paper  [6]  which introduces the adversarial network design between a generator and a discriminator, various GAN loss functions are introduced such as minimax loss strategy used in DCGAN [7], Least-Square loss from LSGAN [8], or Wasserstein",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-158,2021,100.0,"Temperature as a Regularizer for Semantic Segmentation A data-oriented approach including all deep learning methods is usually suffered by overfitting. A regularizer has been, from the beginning, introduced to resolve this problem. Inspired by Generative Adversarial Network (GAN), our framework generates the adversarial loss to penalize a segmentation model like a regularizer. We introduce temperature as a regularizer when calculating Least-Square losses. Temperature affects losses in both a discriminator and a generator in our DCGAN framework. Our experiment suggests L2 losses on top of the original LSGAN losses for optimization. This new regularizer using temperature improves semantic Segmentation accuracy both in Pixel accuracy and mean Intersection-of Union. 
 Related Works Generative Adversarial Network: Started from the first GAN paper  [6]  which introduces the adversarial network design between a generator and a discriminator, various GAN loss functions are introduced such as minimax loss strategy used in DCGAN [7], Least-Square loss from LSGAN [8], or Wasserstein"
Distribution Preserving Multiple Hypotheses Prediction for Uncertainty Modeling,"Tobias Leemann, Moritz Sackmann, Jörn Thielecke, Ulrich Hofmann","1 - University of Erlangen-Nürnberg Institute of Information Technology (Communication Electronics 91058 Erlangen Germany
4 - AUDI AG -Predevelopment of Automated Driving 85045 Ingolstadt Germany","Many supervised machine learning tasks, such as future state prediction in dynamical systems, require precise modeling of a forecast's uncertainty. The Multiple Hypotheses Prediction (MHP) approach addresses this problem by providing several hypotheses that represent possible outcomes. Unfortunately, with the common l2 loss function, these hypotheses do not preserve the data distribution's characteristics. We propose an alternative loss for distribution preserving MHP and review relevant theorems supporting our claims. Furthermore, we empirically show that our approach yields more representative hypotheses on a synthetic and a real-world motion prediction data set. The outputs of the proposed method can directly be used in sampling-based Monte-Carlo methods.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-16,2021,100.0,"Distribution Preserving Multiple Hypotheses Prediction for Uncertainty Modeling Many supervised machine learning tasks, such as future state prediction in dynamical systems, require precise modeling of a forecast's uncertainty. The Multiple Hypotheses Prediction (MHP) approach addresses this problem by providing several hypotheses that represent possible outcomes. Unfortunately, with the common l2 loss function, these hypotheses do not preserve the data distribution's characteristics. We propose an alternative loss for distribution preserving MHP and review relevant theorems supporting our claims. Furthermore, we empirically show that our approach yields more representative hypotheses on a synthetic and a real-world motion prediction data set. The outputs of the proposed method can directly be used in sampling-based Monte-Carlo methods."
Combining Attack Success Rate and Detection Rate for effective Universal Adversarial Attacks,"Alina Baia, Alfredo Milani, Valentina Poggioni",1 - University of Perugia Italy,"In the framework of Adversarial Machine Learning, several detection and protection techniques are used to characterize specific attack-defense scenarios. In this paper, we present universal, unrestricted black-box adversarial attacks based on a multi-objective nested evolutionary algorithm able to incorporate the detection rate and a measure of image quality into the attack building phase.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-160,2021,99.4535519125683,"Combining Attack Success Rate and Detection Rate for effective Universal Adversarial Attacks In the framework of Adversarial Machine Learning, several detection and protection techniques are used to characterize specific attack-defense scenarios. In this paper, we present universal, unrestricted black-box adversarial attacks based on a multi-objective nested evolutionary algorithm able to incorporate the detection rate and a measure of image quality into the attack building phase."
A Multi-ELM Model for Incomplete Data,"Baichuan Chi, Amaury Lendasse, Edward Ratner, Renjie Hu","1 - ILT Department University of Houston Houston USA
3 - Edammo Inc. Iowa City USA","This paper presents a novel model of Extreme Learning Machines (ELMs) for incomplete data. ELMs are fast accurate randomized neural networks. Nevertheless ELM can only be applied on the complete dataset. Therefore, a novel Multi-ELM Model for incomplete data is proposed, consisting of multiple secondary ELMs and one primary ELM. The secondary ELMs are approximating the primary ELM's hidden neurons' outputs for the data with missing values. As summarized in the experimental Section, this model can be applied on data with any missing patterns, without using imputations and can outperform the traditional imputation methods within a reasonable fraction of missing values, as it avoids the noises introduced by imputations.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-162,2021,100.0,"A Multi-ELM Model for Incomplete Data This paper presents a novel model of Extreme Learning Machines (ELMs) for incomplete data. ELMs are fast accurate randomized neural networks. Nevertheless ELM can only be applied on the complete dataset. Therefore, a novel Multi-ELM Model for incomplete data is proposed, consisting of multiple secondary ELMs and one primary ELM. The secondary ELMs are approximating the primary ELM's hidden neurons' outputs for the data with missing values. As summarized in the experimental Section, this model can be applied on data with any missing patterns, without using imputations and can outperform the traditional imputation methods within a reasonable fraction of missing values, as it avoids the noises introduced by imputations."
A Baseline for Shapley Values in MLPs: from Missingness to Neutrality,"Cosimo Izzo, Aldo Lipani, Ramin Okhrati, Francesca Medda",1 - University College London London United Kingdom,"Deep neural networks have gained momentum based on their accuracy, but their interpretability is often criticised. As a result, they are labelled as black boxes. In response, several methods have been proposed in the literature to explain their predictions. Among the explanatory methods, Shapley values is a feature attribution method favoured for its robust theoretical foundation. However, the analysis of feature attributions using Shapley values requires choosing a baseline that represents the concept of missingness. An arbitrary choice of baseline could negatively impact the explanatory power of the method and possibly lead to incorrect interpretations. In this paper, we present a method for choosing a baseline according to a neutrality value: as a parameter selected by decision-makers, the point at which their choices are determined by the model predictions being either above or below it. Hence, the proposed baseline is set based on a parameter that depends on the actual use of the model. This procedure stands in contrast to how other baselines are set, i.e. without accounting for how the model is used. We empirically validate our choice of baseline in the context of binary classification tasks, using two datasets: a synthetic dataset and a dataset derived from the financial domain.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-18,2021,100.0,"A Baseline for Shapley Values in MLPs: from Missingness to Neutrality Deep neural networks have gained momentum based on their accuracy, but their interpretability is often criticised. As a result, they are labelled as black boxes. In response, several methods have been proposed in the literature to explain their predictions. Among the explanatory methods, Shapley values is a feature attribution method favoured for its robust theoretical foundation. However, the analysis of feature attributions using Shapley values requires choosing a baseline that represents the concept of missingness. An arbitrary choice of baseline could negatively impact the explanatory power of the method and possibly lead to incorrect interpretations. In this paper, we present a method for choosing a baseline according to a neutrality value: as a parameter selected by decision-makers, the point at which their choices are determined by the model predictions being either above or below it. Hence, the proposed baseline is set based on a parameter that depends on the actual use of the model. This procedure stands in contrast to how other baselines are set, i.e. without accounting for how the model is used. We empirically validate our choice of baseline in the context of binary classification tasks, using two datasets: a synthetic dataset and a dataset derived from the financial domain."
The Coming of Age of Interpretable and Explainable Machine Learning Models,"P Lisboa, S Saralajew, A Vellido, T Villmann","1 - Liverpool John Moores University Liverpool United Kingdom
2 - Bosch Center for Artificial Intelligence Renningen Germany
3 - Universitat Politècnica de Catalunya and IDEAI-UPC Research Center Barcelona Spain
4 - University of Applied Sciences Mittweida
5 - Saxon Institute for Comp. Intelligence and Machine Learning Mittweida Germany","Machine learning-based systems are now part of a wide array of real-world applications seamlessly embedded in the social realm. In the wake of this realisation, strict legal regulations for these systems are currently being developed, addressing some of the risks they may pose. This is the coming of age of the interpretability and explainability problems in machine learning-based data analysis, which can no longer be seen just as an academic research problem. In this tutorial, associated to ESANN 2021 special session on ""Interpretable Models in Machine Learning and Explainable Artificial Intelligence"", we discuss explainable and interpretable machine learning as post-hoc and ante-hoc strategies to address these problems and highlight several aspects related to them, including their assessment. The contributions accepted for the session are then presented in this context.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-2,2021,100.0,"The Coming of Age of Interpretable and Explainable Machine Learning Models Machine learning-based systems are now part of a wide array of real-world applications seamlessly embedded in the social realm. In the wake of this realisation, strict legal regulations for these systems are currently being developed, addressing some of the risks they may pose. This is the coming of age of the interpretability and explainability problems in machine learning-based data analysis, which can no longer be seen just as an academic research problem. In this tutorial, associated to ESANN 2021 special session on ""Interpretable Models in Machine Learning and Explainable Artificial Intelligence"", we discuss explainable and interpretable machine learning as post-hoc and ante-hoc strategies to address these problems and highlight several aspects related to them, including their assessment. The contributions accepted for the session are then presented in this context."
Differentially Private Time Series Generation,"Hiba Arnout, Johanna Bronner, Thomas Runkler","1 - Siemens AG -Corporate Technology Otto-Hahn-Ring 6 81739 Munich Germany
2 - Department of Computer Science Boltzmannstraße 3 Technical University of Munich 85748 Garching Germany","Privacy issues prevent data owner from improving Machine Learning (ML) performance as it makes external collaborations binding. To allow data sharing without confidentiality concerns, we propose in this work methods to generate time series in a privacy preserving manner. We combine the existing Generative Adversarial Networks (GAN) models for time series namely TimeGAN [1], ClaRe-GAN [2] and C-RNN-GAN [3] with differential privacy. This is achieved by changing their original discriminator with a private discriminator that relies on the differentially private stochastic gradient method (DPSGD)  [4] . Our experiments show that the developed methods -in particular TimeGAN and ClaRe-GANoutperform the existing and unique differentially private model for time series of RCGAN [5]  in terms of privacy and accuracy.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-20,2021,100.0,"Differentially Private Time Series Generation Privacy issues prevent data owner from improving Machine Learning (ML) performance as it makes external collaborations binding. To allow data sharing without confidentiality concerns, we propose in this work methods to generate time series in a privacy preserving manner. We combine the existing Generative Adversarial Networks (GAN) models for time series namely TimeGAN [1], ClaRe-GAN [2] and C-RNN-GAN [3] with differential privacy. This is achieved by changing their original discriminator with a private discriminator that relies on the differentially private stochastic gradient method (DPSGD)  [4] . Our experiments show that the developed methods -in particular TimeGAN and ClaRe-GANoutperform the existing and unique differentially private model for time series of RCGAN [5]  in terms of privacy and accuracy."
End-to-end Keyword Spotting using Xception-1d,"Iván Vallés-Pérez, Juan Gómez-Sanchis, Marcelino Martínez-Sober, Joan Vila-Francés, Antonio Serrano-López, Emilio Soria-Olivas","1 - Intelligent Data Analysis Laboratory (IDAL) University of Valencia
2 - Avenida de la Universitat s/n 46100 Burjassot, Valencia Spain","The field of conversational agents is growing fast and there is an increasing need for algorithms that enhance natural interaction. In this work we show how we achieved state of the art results in the Keyword Spotting field by adapting and tweaking the Xception algorithm, which achieved outstanding results in several computer vision tasks. We obtained about 96% accuracy when classifying audio clips belonging to 35 different categories, beating human annotation at the most complex tasks proposed.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-21,2021,100.0,"End-to-end Keyword Spotting using Xception-1d The field of conversational agents is growing fast and there is an increasing need for algorithms that enhance natural interaction. In this work we show how we achieved state of the art results in the Keyword Spotting field by adapting and tweaking the Xception algorithm, which achieved outstanding results in several computer vision tasks. We obtained about 96% accuracy when classifying audio clips belonging to 35 different categories, beating human annotation at the most complex tasks proposed."
"Semantic Prediction: Which One Should Come First, Recognition or Prediction?","Hafez Farazi, Jan Nogga, Sven Behnke",1 - University of Bonn Computer Science Institute VI Autonomous Intelligent Systems Friedrich-Hirzebruch-Allee 5 53115 Bonn Germany,"The ultimate goal of video prediction is not forecasting future pixel-values given some previous frames. Rather, the end goal of video prediction is to discover valuable internal representations from the vast amount of available unlabeled video data in a self-supervised fashion for downstream tasks. One of the primary downstream tasks is interpreting the scene's semantic composition and using it for decision-making. For example, by predicting human movements, an observer can anticipate human activities and collaborate in a shared workspace. There are two main ways to achieve the same outcome, given a pre-trained video prediction and pre-trained semantic extraction model; one can first apply predictions and then extract semantics or first extract semantics and then predict. We investigate these configurations using the Local Frequency Domain Transformer Network (LFDTN) as the video prediction model and U-Net as the semantic extraction model on synthetic and real datasets.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-23,2021,100.0,"Semantic Prediction: Which One Should Come First, Recognition or Prediction? The ultimate goal of video prediction is not forecasting future pixel-values given some previous frames. Rather, the end goal of video prediction is to discover valuable internal representations from the vast amount of available unlabeled video data in a self-supervised fashion for downstream tasks. One of the primary downstream tasks is interpreting the scene's semantic composition and using it for decision-making. For example, by predicting human movements, an observer can anticipate human activities and collaborate in a shared workspace. There are two main ways to achieve the same outcome, given a pre-trained video prediction and pre-trained semantic extraction model; one can first apply predictions and then extract semantics or first extract semantics and then predict. We investigate these configurations using the Local Frequency Domain Transformer Network (LFDTN) as the video prediction model and U-Net as the semantic extraction model on synthetic and real datasets."
Sample efficient localization and stage prediction with autoencoders,"Sebastian Hoch, Sascha Lange, Janis Keuper","1 - Offenburg University -Institute for Machine Learning and Analytics Germany
2 - PSIORI GmbH Germany","Engineering, construction and operation of complex machines involves a wide range of complicated, simultaneous tasks, which potentially could be automated. In this work, we focus on perception tasks in such systems, investigating deep learning approaches for multi-task transfer learning with limited training data. We show an approach that takes advantage of a technical systems' focus on selected objects and their properties. We create focused representations and simultaneously solve joint objectives in a system through multi-task learning with convolutional autoencoders. The focused representations are used as a starting point for the data-saving solution of the additional tasks. The efficiency of this approach is demonstrated using images and tasks of an autonomous circular crane with a grapple.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-24,2021,100.0,"Sample efficient localization and stage prediction with autoencoders Engineering, construction and operation of complex machines involves a wide range of complicated, simultaneous tasks, which potentially could be automated. In this work, we focus on perception tasks in such systems, investigating deep learning approaches for multi-task transfer learning with limited training data. We show an approach that takes advantage of a technical systems' focus on selected objects and their properties. We create focused representations and simultaneously solve joint objectives in a system through multi-task learning with convolutional autoencoders. The focused representations are used as a starting point for the data-saving solution of the additional tasks. The efficiency of this approach is demonstrated using images and tasks of an autonomous circular crane with a grapple."
Deep Graph Convolutional Networks for Wind Speed Prediction,"Tomasz Stańczyk, Siamak Mehrkanoon",1 - Department of Data Science and Knowledge Engineering Maastricht University Paul-Henri Spaaklaan 1 6229 EN Maastricht The Netherlands,"In this paper, we introduce a new model for wind speed prediction based on spatio-temporal graph convolutional networks. Here, weather stations are treated as nodes of a graph with a learnable adjacency matrix, which determines the strength of relations between the stations based on the historical weather data. The self-loop connection is added to the learnt adjacency matrix and its strength is controlled by additional learnable parameter. Experiments performed on real datasets collected from weather stations located in Denmark and the Netherlands show that our proposed model outperforms previously developed baseline models on the referenced datasets.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-25,2021,100.0,"Deep Graph Convolutional Networks for Wind Speed Prediction In this paper, we introduce a new model for wind speed prediction based on spatio-temporal graph convolutional networks. Here, weather stations are treated as nodes of a graph with a learnable adjacency matrix, which determines the strength of relations between the stations based on the historical weather data. The self-loop connection is added to the learnt adjacency matrix and its strength is controlled by additional learnable parameter. Experiments performed on real datasets collected from weather stations located in Denmark and the Netherlands show that our proposed model outperforms previously developed baseline models on the referenced datasets."
Correlated Weights Neural Layer with external control,Slawomir Golak,"1 - Department of Industrial Informatics Silesian University of Technology Gliwice Poland
2 - grants Silesian University of Technology","The correlated weights neural layer is a generalization of the convolutional layer constituting the core of CNN networks. The CWNL layer takes advantage of weights correlated with coordinates of a neuron and its inputs, calculated by a dedicated neural subnet. In this work, a modified CWNL layer is proposed, which allows the parameterized spatial manipulation (and any other global transformation) of a pattern. The externally controlled CWNL layer can be used in existing neural network architectures, giving them the ability of internal pattern transformation without any modification of the training process.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-26,2021,100.0,"Correlated Weights Neural Layer with external control The correlated weights neural layer is a generalization of the convolutional layer constituting the core of CNN networks. The CWNL layer takes advantage of weights correlated with coordinates of a neuron and its inputs, calculated by a dedicated neural subnet. In this work, a modified CWNL layer is proposed, which allows the parameterized spatial manipulation (and any other global transformation) of a pattern. The externally controlled CWNL layer can be used in existing neural network architectures, giving them the ability of internal pattern transformation without any modification of the training process."
Validating static call graph-based malware signatures using community detection methods,"Attila Mester, Zalán Bodó","1 - Faculty of Mathematics and Computer Science Babeş-Bolyai University
2 - Cluj-Napoca Romania
3 - Bitdefender Cluj-Napoca Romania","Due to the increasing number of new malware appearing daily, it is impossible to manually inspect each sample. By applying data mining techniques to analyze the program code, we can help manual processing. In this paper we propose a method to extract signatures from the executable binary of a malware, in order to query the local neighborhood in real time. The method is validated by applying community detection algorithms on the common fingerprint-based malware graph to identify families, and assessing these with evaluation metrics used in the field (e.g. modularity, family majority, etc.). The signatures are obtained via static code analysis, using function call n-grams and applying locality-sensitive hashing techniques to enable the match between functions with highly similar instruction lists.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-27,2021,100.0,"Validating static call graph-based malware signatures using community detection methods Due to the increasing number of new malware appearing daily, it is impossible to manually inspect each sample. By applying data mining techniques to analyze the program code, we can help manual processing. In this paper we propose a method to extract signatures from the executable binary of a malware, in order to query the local neighborhood in real time. The method is validated by applying community detection algorithms on the common fingerprint-based malware graph to identify families, and assessing these with evaluation metrics used in the field (e.g. modularity, family majority, etc.). The signatures are obtained via static code analysis, using function call n-grams and applying locality-sensitive hashing techniques to enable the match between functions with highly similar instruction lists."
The Benefits of Adversarial Defence in Generalisation,"Luca Oneto, Sandro Ridella, Davide Anguita",1 - University of Genoa Via Opera Pia 11a 16145 Genova Italy,"Recent researches have been shown that models induced by machine learning, in particular by deep learning, can be easily fooled by an adversary who carefully crafts imperceptible, at least from the human perspective, or physically plausible modifications of the input data. This discovery gave birth to a new field of research, the adversarial machine learning, where new methods of attacks and defence are developed continuously, mimicking what is happening from a long time in cybersecurity. In this paper we will show that the drawbacks of inducing models from data less prone to be misled actually provides some benefits when it comes to assess their generalisation abilities.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-28,2021,100.0,"The Benefits of Adversarial Defence in Generalisation Recent researches have been shown that models induced by machine learning, in particular by deep learning, can be easily fooled by an adversary who carefully crafts imperceptible, at least from the human perspective, or physically plausible modifications of the input data. This discovery gave birth to a new field of research, the adversarial machine learning, where new methods of attacks and defence are developed continuously, mimicking what is happening from a long time in cybersecurity. In this paper we will show that the drawbacks of inducing models from data less prone to be misled actually provides some benefits when it comes to assess their generalisation abilities."
In-Station Train Movements Prediction: from Shallow to Deep Multi Scale Models *,"Gianluca Boleto, Luca Oneto, Matteo Cardellini, Marco Maratea, Mauro Vallati, Renzo Canepa, Davide Anguita","1 - University of Genoa Via Opera Pia 11a 16145 Genova Italy
5 - University of Huddersfield -Huddersfield West Yorkshire HD1 3DH UK
6 - Rete Ferroviaria Italiana -Via Don Vincenzo Minetti 6/5 16126 Genova Italy","Public railway transport systems play a crucial role in servicing the global society and are the transport backbone of a sustainable economy. While a significant effort has been devoted to predict inter-station trains movements to support stakeholders (i.e., infrastructure managers, train operators, and travellers) decisions, the problem of predicting instation movements, while being crucial to improve train dispatching (i.e., empowering human or automatic dispatchers), has been far more less investigated. In fact, stations are the most critical points in a railway network: even small improvements in the estimation of the duration of trains movements can remarkably enhance the dispatching efficiency in coping with the increase in capacity demand and with delays. In this work we will first leverage on state of the art shallow models, fed by domain experts with domain specific features, to improve the current predictive systems. Then, we will leverage on a customised deep multi scale model able to automatically learn the representation and improve the accuracy of the shallow models. Results on real-world data coming from the Italian railway network will support our proposal. * This work has been partially funded by Hitachi Rail STS through the RAIDLab (Railway Artificial Intelligence and Data Analysis Laboratory), a joint laboratory between Hitachi Rail STS and University of Genoa. 1 https://ec.europa.eu/transport/themes/infrastructure en 2 https://shift2rail.org/ 475",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-29,2021,98.73417721518987,"In-Station Train Movements Prediction: from Shallow to Deep Multi Scale Models * Public railway transport systems play a crucial role in servicing the global society and are the transport backbone of a sustainable economy. While a significant effort has been devoted to predict inter-station trains movements to support stakeholders (i.e., infrastructure managers, train operators, and travellers) decisions, the problem of predicting instation movements, while being crucial to improve train dispatching (i.e., empowering human or automatic dispatchers), has been far more less investigated. In fact, stations are the most critical points in a railway network: even small improvements in the estimation of the duration of trains movements can remarkably enhance the dispatching efficiency in coping with the increase in capacity demand and with delays. In this work we will first leverage on state of the art shallow models, fed by domain experts with domain specific features, to improve the current predictive systems. Then, we will leverage on a customised deep multi scale model able to automatically learn the representation and improve the accuracy of the shallow models. Results on real-world data coming from the Italian railway network will support our proposal. * This work has been partially funded by Hitachi Rail STS through the RAIDLab (Railway Artificial Intelligence and Data Analysis Laboratory), a joint laboratory between Hitachi Rail STS and University of Genoa. 1 https://ec.europa.eu/transport/themes/infrastructure en 2 https://shift2rail.org/ 475"
Machine Learning for Measuring and Analyzing Online Social Communications,"Chris Bronk, Amaury Lendasse, Peggy Lindner, Dan Wallach, Barbara Hammer","1 - Department of Information and Logistics Technology Houston University of Houston USA
2 - Department of Computer Science Houston -Rice University USA
4 - Arcada University of Applied Sciences -Risklab Helsinki Finland
7 - Bielefeld University -CITEC -Cognitive Interaction Technology Germany","In this paper, we propose a framework for application of a novel machine learning-based system for analyzing online social communications. As a example, we are targeting anti-Semitic graphical memes posted to social media. We presented very promising preliminary results on a Facebook dataset that consists of a total of 10000 labeled memes. We can conclude that machine learning will soon be able to successfully analyze and monitor complex social communications.",Machine Learning for Measuring and Analyzing Online Social Communications,https://doi.org/10.14428/esann/2021.ES2021-3,2021,100.0,"Machine Learning for Measuring and Analyzing Online Social Communications In this paper, we propose a framework for application of a novel machine learning-based system for analyzing online social communications. As a example, we are targeting anti-Semitic graphical memes posted to social media. We presented very promising preliminary results on a Facebook dataset that consists of a total of 10000 labeled memes. We can conclude that machine learning will soon be able to successfully analyze and monitor complex social communications."
Comprehensive Analysis of the Screening of COVID-19 Approaches in Chest X-ray Images from Portable Devices,"Daniel Morís, J De Moura, J Novo, M Ortega","1 - Centro de Investigación CITIC Universidade da Coruña 15071 A Coruña Spain
2 - -Grupo VARPA Instituto de Investigación Biomédica de A Coruña (INIBIC)
3 - Universidade da Coruña 15006 A Coruña Spain
13 - Ministerio de Ciencia e Innovación
14 - Government of Spain Universidades RTI2018-095894-B-I00","Computer-aided diagnosis plays an important role in the COVID-19 pandemic. Currently, it is recommended to use X-ray imaging to diagnose and assess the evolution in patients. Particularly, radiologists are asked to use portable acquisition devices to minimize the risk of cross-infection, facilitating an effective separation of suspected patients with other low-risk cases. In this work, we present an automatic COVID-19 screening, considering 6 representative state-of-the-art deep network architectures on a portable chest X-ray dataset that was specifically designed for this proposal. Exhaustive experimentation demonstrates that the models can separate COVID-19 cases from NON-COVID-19 cases, achieving a 97.68% of global accuracy.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-31,2021,100.0,"Comprehensive Analysis of the Screening of COVID-19 Approaches in Chest X-ray Images from Portable Devices Computer-aided diagnosis plays an important role in the COVID-19 pandemic. Currently, it is recommended to use X-ray imaging to diagnose and assess the evolution in patients. Particularly, radiologists are asked to use portable acquisition devices to minimize the risk of cross-infection, facilitating an effective separation of suspected patients with other low-risk cases. In this work, we present an automatic COVID-19 screening, considering 6 representative state-of-the-art deep network architectures on a portable chest X-ray dataset that was specifically designed for this proposal. Exhaustive experimentation demonstrates that the models can separate COVID-19 cases from NON-COVID-19 cases, achieving a 97.68% of global accuracy."
Anomalous Cluster Detection in Large Networks with Diffusion-Percolation Testing,"Corentin Larroche, Johan Mazel, Stephan Clémençon","1 - French National Cybersecurity Agency (ANSSI 51 boulevard de La Tour-Maubourg 75700, 07 SP Paris France
2 - Télécom Paris Institut Polytechnique de Paris -LTCI 19 place Marguerite Perey 91120 Palaiseau France","We propose a computationally efficient procedure for elevated mean detection on a connected subgraph of a network with node-related scalar observations. Our approach relies on two intuitions: first, a significant concentration of high observations in a connected subgraph implies that the subgraph induced by the nodes associated with the highest observations has a large connected component. Secondly, a greater detection power can be obtained in certain cases by denoising the observations using the network structure. Numerical experiments show that our procedure's detection performance and computational efficiency are both competitive.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-32,2021,100.0,"Anomalous Cluster Detection in Large Networks with Diffusion-Percolation Testing We propose a computationally efficient procedure for elevated mean detection on a connected subgraph of a network with node-related scalar observations. Our approach relies on two intuitions: first, a significant concentration of high observations in a connected subgraph implies that the subgraph induced by the nodes associated with the highest observations has a large connected component. Secondly, a greater detection power can be obtained in certain cases by denoising the observations using the network structure. Numerical experiments show that our procedure's detection performance and computational efficiency are both competitive."
An Algorithmic Approach to Establish a Lower Bound for the Size of Semiring Neural Networks,"Martin Böhm, Thomas Schmid","1 - Universität Leipzig -Algebraische und logische Grundlagen der Informatik Augustusplatz 10 Leipzig Germany
2 - Universität Leipzig -Machine Learning Group Augustusplatz 10 Leipzig Germany
3 - Lancaster University in Leipzig Nikolaistrasse 10 Leipzig Germany","Semiring neural networks have been introduced as a recurrent neural network-type representation of weighted automata with the potential to learn a recognizable series. Whether a given semiring neural network actually can or cannot compute a recognizable series, however, depends on the size of the network. Therefore, it is desirable to determine whether a proposed size is too small before initiation of the training procedure. Here, we present an algorithm that achieves this in polynomial time. As there is a one-to-one correspondence between semiring neural networks and weighted automata, our algorithm can also be used to derive lower bounds for the size of a recognizing automaton. Our algorithm complements previous work in this area as it works over commutative zero-sum-free semirings.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-33,2021,100.0,"An Algorithmic Approach to Establish a Lower Bound for the Size of Semiring Neural Networks Semiring neural networks have been introduced as a recurrent neural network-type representation of weighted automata with the potential to learn a recognizable series. Whether a given semiring neural network actually can or cannot compute a recognizable series, however, depends on the size of the network. Therefore, it is desirable to determine whether a proposed size is too small before initiation of the training procedure. Here, we present an algorithm that achieves this in polynomial time. As there is a one-to-one correspondence between semiring neural networks and weighted automata, our algorithm can also be used to derive lower bounds for the size of a recognizing automaton. Our algorithm complements previous work in this area as it works over commutative zero-sum-free semirings."
Orientation Adaptive Minimal Learning Machine for Directions of Atomic Forces,"Antti Pihlajamäki, Joakim Linja, Joonas Hämäläinen, Sami Malola, Paavo Nieminen, Tommi Kärkkäinen, Hannu Häkkinen","1 - Department of Physics University of Jyväskylä Nanoscience Center FI-40014 Jyväskylä Finland
2 - Faculty of Information Technology University of Jyväskylä FI-40014 Jyväskylä Finland
8 - Department of Chemistry University of Jyväskylä Nanoscience Center FI-40014 Jyväskylä Finland","Machine learning (ML) force fields are one of the most common applications of ML in nanoscience. However, commonly these methods are trained on potential energies of atomic systems and force vectors are omitted. Here we present a ML framework, which tackles the greatest difficulty on using forces in ML: accurate prediction of force direction. We use the idea of Minimal Learning Machine to device a method which can adapt to the orientation of an atomic environment to estimate the directions of force vectors. The method was tested with linear alkane molecules.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-34,2021,100.0,"Orientation Adaptive Minimal Learning Machine for Directions of Atomic Forces Machine learning (ML) force fields are one of the most common applications of ML in nanoscience. However, commonly these methods are trained on potential energies of atomic systems and force vectors are omitted. Here we present a ML framework, which tackles the greatest difficulty on using forces in ML: accurate prediction of force direction. We use the idea of Minimal Learning Machine to device a method which can adapt to the orientation of an atomic environment to estimate the directions of force vectors. The method was tested with linear alkane molecules."
Functional Gradient Descent for n-Tuple Regression,"Rafael Katopodis, Priscila Lima, Felipe França",1 - COPPE Universidade Federal do Rio de Janeiro 2-NCE Brazil,"n-tuple neural networks have been in the past applied to a wide range of learning domains. However, for the particular area of regression, existing systems have displayed two shortcomings: little flexibility in the objective function being optimized and an inability to handle nonstationarity in an online learning setting. A novel n-tuple system is proposed to address these issues. The new architecture leverages the idea of functional gradient descent, drawing inspiration from its use in kernel methods. Furthermore, its capabilities are showcased in two reinforcement learning tasks, which involves both nonstationary online learning and task-specific objective functions.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-35,2021,100.0,"Functional Gradient Descent for n-Tuple Regression n-tuple neural networks have been in the past applied to a wide range of learning domains. However, for the particular area of regression, existing systems have displayed two shortcomings: little flexibility in the objective function being optimized and an inability to handle nonstationarity in an online learning setting. A novel n-tuple system is proposed to address these issues. The new architecture leverages the idea of functional gradient descent, drawing inspiration from its use in kernel methods. Furthermore, its capabilities are showcased in two reinforcement learning tasks, which involves both nonstationary online learning and task-specific objective functions."
The partial response SVM,"B Walters, S Ortega-Martorell, I Olier, P Lisboa",1 - Data Science Research Centre School of Computer Science and Mathematics Liverpool John Moores University Byrom Street L3 3AF Liverpool UK,We introduce a probabilistic algorithm for binary classification based on the SVM through the application of the ANOVA decomposition for multivariate functions to express the logit of the Platt estimate of the posterior probability as a non-redundant sum of functions of fewer variables (partial responses) followed by feature selection with the Lasso. The partial response SVM (prSVM) is compared with previous interpretable models of the SVM. Its accuracy and stability are demonstrated with real-world data sets.,Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-36,2021,100.0,The partial response SVM We introduce a probabilistic algorithm for binary classification based on the SVM through the application of the ANOVA decomposition for multivariate functions to express the logit of the Platt estimate of the posterior probability as a non-redundant sum of functions of fewer variables (partial responses) followed by feature selection with the Lasso. The partial response SVM (prSVM) is compared with previous interpretable models of the SVM. Its accuracy and stability are demonstrated with real-world data sets.
Benign overfitting of fully connected Deep Nets: A Sobolev space viewpoint,"Emmanuel Caron, Stéphane Chrétien","1 - Laboratoire de Mathématiques d'Avignon Université d'Avignon Avignon France
2 - Université Lumière-Lyon-II 69676 Bron Cedex France","Deep neural nets have undergone tremendous improvements in the last decade, which revolutionised the field of machine learning in a broad and lasting manner, achieving unprecedented performance in such diverse fields as image analysis, point cloud registration, natural language processing and model free control. On the theoretical side, understanding the underpinnings of deep learning remains a formidable challenge, despite impressive breakthroughs in the last decade. One particularly interesting new prospect is the analysis of the double descent phenomenon described in  Belkin et al. [2019] , a counter-intuitive theory bringing new insight on the performance of learning systems in the greatly over-parametrised regime.The list of contribution to the understanding of the double descent paradigm has grown substantially in the last two years, but all available results in the literature mainly focus on the linear and the kernel setups. In the present paper, we study the overparametrised part of the double descent curve introduced in Belkin et al. [2019]  and propose a new approach to the study of benign overfitting in the setting of learning Sobolev maps.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-37,2021,97.95918367346938,"Benign overfitting of fully connected Deep Nets: A Sobolev space viewpoint Deep neural nets have undergone tremendous improvements in the last decade, which revolutionised the field of machine learning in a broad and lasting manner, achieving unprecedented performance in such diverse fields as image analysis, point cloud registration, natural language processing and model free control. On the theoretical side, understanding the underpinnings of deep learning remains a formidable challenge, despite impressive breakthroughs in the last decade. One particularly interesting new prospect is the analysis of the double descent phenomenon described in  Belkin et al. [2019] , a counter-intuitive theory bringing new insight on the performance of learning systems in the greatly over-parametrised regime.The list of contribution to the understanding of the double descent paradigm has grown substantially in the last two years, but all available results in the literature mainly focus on the linear and the kernel setups. In the present paper, we study the overparametrised part of the double descent curve introduced in Belkin et al. [2019]  and propose a new approach to the study of benign overfitting in the setting of learning Sobolev maps."
Unsupervised Word Representations Learning with Bilinear Convolutional Network on Characters,"Thomas Luka, Laure Soulier, David Picard","1 - LIGM, École des Ponts Univ Gustave Eiffel CNRS Marne-la-Vallée France
2 - Sorbonne Université CNRS LIP6 F-75005 Paris France
4 - Agence Innovation Défense (AID) and École Ponts Paris-Tech","In this paper, we propose a new unsupervised method for learning word embedding with raw characters as input representations, bypassing the problems arising from the use of a dictionary. To achieve this purpose, we translate the distributional hypothesis into a unsupervised metric learning objective, which allows to consider only an encoder instead of an encoder-decoder architecture. We propose to use a convolutional neural network with bilinear product blocks and residual connections to encode co-occurrences patterns. We show the effectiveness of our approach by comparing it with classical word embedding methods such as fastText and GloVe on several benchmarks.",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-38,2021,100.0,"Unsupervised Word Representations Learning with Bilinear Convolutional Network on Characters In this paper, we propose a new unsupervised method for learning word embedding with raw characters as input representations, bypassing the problems arising from the use of a dictionary. To achieve this purpose, we translate the distributional hypothesis into a unsupervised metric learning objective, which allows to consider only an encoder instead of an encoder-decoder architecture. We propose to use a convolutional neural network with bilinear product blocks and residual connections to encode co-occurrences patterns. We show the effectiveness of our approach by comparing it with classical word embedding methods such as fastText and GloVe on several benchmarks."
"Federated Learning Methods, Applications and Beyond","Moritz Heusinger, Christoph Raab, Fabrice Rossi, Frank-Michael Schleif","1 - Department of Computer Science University of Applied Science Würzburg-Schweinfurt Würzburg Germany
3 - CEREMADE University Paris Dauphine PSL France","In recent years the applications of machine learning models have increased rapidly, due to the large amount of available data and technological progress. While some domains like web analysis can benefit from this with only minor restrictions, other fields like medicine with patient data are stronger regulated. In particular data privacy plays an important role as recently highlighted by the trustworthy AI initiative of the EU or general privacy regulations in legislation. Another major challenge is, that the required training data is often distributed in terms of features or samples and unavailable for classical batch learning approaches. In 2016 Google came up with a framework, called Federated Learning to solve both of these problems. We provide a brief overview on existing Methods and Applications in the field of vertical and horizontal Federated Learning, as well as Federated Transfer Learning.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-4,2021,84.61538461538461,"Federated Learning Methods, Applications and Beyond In recent years the applications of machine learning models have increased rapidly, due to the large amount of available data and technological progress. While some domains like web analysis can benefit from this with only minor restrictions, other fields like medicine with patient data are stronger regulated. In particular data privacy plays an important role as recently highlighted by the trustworthy AI initiative of the EU or general privacy regulations in legislation. Another major challenge is, that the required training data is often distributed in terms of features or samples and unavailable for classical batch learning approaches. In 2016 Google came up with a framework, called Federated Learning to solve both of these problems. We provide a brief overview on existing Methods and Applications in the field of vertical and horizontal Federated Learning, as well as Federated Transfer Learning."
AGLVQ -Making Generalized Learning Vector Quantization Aware of Context,"Torben Graeber, Sebastian Vetter, Sascha Saralajew, Michael Unterreiner, Dieter Schramm","1 - University of Duisburg-Essen -Chair of Mechatronics Lotharstraße 1 2 -Dr. Ing. h.c. F. Porsche AG Porschestrasse 911 222-230, 47057, 71287 Duisburg, Weissach MD Germany, Germany","Generalized Learning Vector Quantization methods are a powerful and robust approach for classification tasks. They compare incoming samples with representative prototypes for each target class. While prototypes are physically interpretable, they do not account for changes in the environment. We propose a novel framework for the incorporation of context information into prototype generation. We can model dependencies in a modular way ranging from polynomials to neural networks. Evaluations on artificial and real-world datasets show an increase in performance and meaningful prototype adaptations.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-40,2021,84.13793103448276,"AGLVQ -Making Generalized Learning Vector Quantization Aware of Context Generalized Learning Vector Quantization methods are a powerful and robust approach for classification tasks. They compare incoming samples with representative prototypes for each target class. While prototypes are physically interpretable, they do not account for changes in the environment. We propose a novel framework for the incorporation of context information into prototype generation. We can model dependencies in a modular way ranging from polynomials to neural networks. Evaluations on artificial and real-world datasets show an increase in performance and meaningful prototype adaptations."
Echo-state neural networks forecasting steelworks off-gases for their dispatching in CH4 and CH3OH syntheses reactors,"Ismael Matino, Stefano Dettori, Valentina Colla, Katharina Rechberger, Nina Kieberger","1 - Scuola Superiore Sant'Anna -TeCIP Institute ICT-COISP Via Moruzzi 1 Pisa Italy
4 - K1-MET GmbH Stahlstraße 14 Linz Austria
5 - Research and Development Ironmaking Technical Department -voestalpine Stahl GmdH
6 - Business Unit Slab voestalpine-Strasse 3 Linz Austria","In the era of European Green Deal, steelworks are committed to reduce their CO2 emissions by preserving their competitiveness. One of the options to achieve such aim is the valorization of process off-gases. Methane and Methanol production can be obtained by coupling novel reactors with an advanced control system that dispatches these gases after enrichment with green hydrogen. Knowing in advance the gases availability and composition is fundamental. The paper present Echo State Networks based-models that are applied to this aim and achieve adequate forecasting accuracy also in case of highly dynamic processes.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-41,2021,100.0,"Echo-state neural networks forecasting steelworks off-gases for their dispatching in CH4 and CH3OH syntheses reactors In the era of European Green Deal, steelworks are committed to reduce their CO2 emissions by preserving their competitiveness. One of the options to achieve such aim is the valorization of process off-gases. Methane and Methanol production can be obtained by coupling novel reactors with an advanced control system that dispatches these gases after enrichment with green hydrogen. Knowing in advance the gases availability and composition is fundamental. The paper present Echo State Networks based-models that are applied to this aim and achieve adequate forecasting accuracy also in case of highly dynamic processes."
Enhash: A Fast Streaming Algorithm For Concept Drift Detection,"Aashi Jindal, Prashant Gupta, Debarka Sengupta","1 - Department of Electrical Engineering Hauz Khas Indian Institute of Technology Delhi 110016 Delhi India
4 - Department of Computer Science and Engineering Indraprastha Institute of Information Technology 110020 Delhi India
5 - Queensland University of Technology -Institute of Health and Biomedical Innovation Brisbane 4000 QLD Australia","We propose Enhash, a fast ensemble learner that detects concept drift in a data stream. A stream may consist of abrupt, gradual, virtual, or recurring events, or a mixture of various types of drift. Enhash employs projection hash to insert an incoming sample. Benchmark tests on 6 artificial and 4 real data sets consisting of various types of drift show that Enhash is competitive with stateof-the-art ensemble learners while being significantly faster. It also has moderate resource requirements.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-43,2021,100.0,"Enhash: A Fast Streaming Algorithm For Concept Drift Detection We propose Enhash, a fast ensemble learner that detects concept drift in a data stream. A stream may consist of abrupt, gradual, virtual, or recurring events, or a mixture of various types of drift. Enhash employs projection hash to insert an incoming sample. Benchmark tests on 6 artificial and 4 real data sets consisting of various types of drift show that Enhash is competitive with stateof-the-art ensemble learners while being significantly faster. It also has moderate resource requirements."
Hierarchical Planning in Multilayered State-Action Networks,"Matthias Brucklacher, Hanspeter Mallot, Tristan Baumann","1 - University of Tübingen -Cognitive Neuroscience Auf der Morgenstelle 28 72076 Tübingen Germany
2 - University of Amsterdam -Cognitive Systems Neuroscience Group Science Park 904 1090 GE Amsterdam Netherlands","The ability to decompose large tasks into smaller subtasks allows humans to solve complex problems step-by-step. To transfer this ability to an automated system, we propose a spiking neural network inspired by the neurobiological mechanics of spatial cognition to represent space on multiple levels of abstraction. As behavioral experiments suggest that humans integrate spatial knowledge in a graph of places, neurons in the state-action network encode locations while connections between them represent transition actions. In a series of simulation experiments, the influence of hierarchy on planning speed and on the resulting route choice in comparison to single-level models is investigated. We find that the model chooses biased subgoals in line with experiments on human navigation.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-45,2021,100.0,"Hierarchical Planning in Multilayered State-Action Networks The ability to decompose large tasks into smaller subtasks allows humans to solve complex problems step-by-step. To transfer this ability to an automated system, we propose a spiking neural network inspired by the neurobiological mechanics of spatial cognition to represent space on multiple levels of abstraction. As behavioral experiments suggest that humans integrate spatial knowledge in a graph of places, neurons in the state-action network encode locations while connections between them represent transition actions. In a series of simulation experiments, the influence of hierarchy on planning speed and on the resulting route choice in comparison to single-level models is investigated. We find that the model chooses biased subgoals in line with experiments on human navigation."
Toxicity Detection in Online Comments with Limited Data: A Comparative Analysis,"Max Lübbering, Maren Pielka, Kajaree Das, Michael Gebauer, Rajkumar Ramamurthy, Christian Bauckhage, Rafet Sifa","1 - Department for Computer Science Universität Bonn
2 - Department Media Engineering Fraunhofer IAIS
5 - Technische Universität Berlin -ISE","We present a comparative study on toxicity detection, focusing on the problem of identifying toxicity types of low prevalence and possibly even unobserved at training time. For this purpose, we train our models on a dataset that contains only a weak type of toxicity, and test whether they are able to generalize to more severe toxicity types. We find that representation learning and ensembling exceed the classification performance of simple classifiers on toxicity detection, while also providing significantly better generalization and robustness. All models benefit from a larger training set size, which even extends to the toxicity types unseen during training.",Machine Learning for Measuring and Analyzing Online Social Communications,https://doi.org/10.14428/esann/2021.ES2021-48,2021,100.0,"Toxicity Detection in Online Comments with Limited Data: A Comparative Analysis We present a comparative study on toxicity detection, focusing on the problem of identifying toxicity types of low prevalence and possibly even unobserved at training time. For this purpose, we train our models on a dataset that contains only a weak type of toxicity, and test whether they are able to generalize to more severe toxicity types. We find that representation learning and ensembling exceed the classification performance of simple classifiers on toxicity detection, while also providing significantly better generalization and robustness. All models benefit from a larger training set size, which even extends to the toxicity types unseen during training."
Deep Learning Model for Context-Dependent Survival Analysis,"Raphaël Langhendries, Jérôme Lacaille","1 - Safran Aircraft Engines -DataLab Villaroche France
2 - SAMM -EA 4543
3 - Université Panthéon Sorbonne France","In this article, we introduce a deep learning model (denoted thereafter DCM: Deep Contextual Model ) for survival analysis able of predicting the probability that a subject meets an event of interest according to its past life. The subject and the event of interest can be diverse depending on the field of application, thus the model can be applied in various contexts. We present an application in the aerospace field that consists in forecasting hot corrosion in turbofan. 
 Framework 
 Background on survival analysis Like all statistical models, survival models need to be fitted on data. Survival data can be represented by a tuple (t, c) where t is a time and c a label. Survival data can be 323","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-49,2021,100.0,"Deep Learning Model for Context-Dependent Survival Analysis In this article, we introduce a deep learning model (denoted thereafter DCM: Deep Contextual Model ) for survival analysis able of predicting the probability that a subject meets an event of interest according to its past life. The subject and the event of interest can be diverse depending on the field of application, thus the model can be applied in various contexts. We present an application in the aerospace field that consists in forecasting hot corrosion in turbofan. 
 Framework 
 Background on survival analysis Like all statistical models, survival models need to be fitted on data. Survival data can be represented by a tuple (t, c) where t is a time and c a label. Survival data can be 323"
Deep learning for graphs,"Davide Bacciu, Filippo Bianchi, Benjamin Paassen, Cesare Alippi","1 - Department of Computer Science University of Pisa Italy
2 - Arctic University of Norway
3 - NORCE The Norwegian Research Centre AS Norway
4 - Humboldt-University of Berlin Germany
5 - Università della Svizzera italiana Switzerland
6 - Politecnico di Milano Italy","Deep learning for graphs encompasses all those neural models endowed with multiple layers of computation operating on data represented as graphs. The most common building blocks of these models are graph encoding layers, which compute a vector embedding for each node in a graph using message-passing operators. In this paper, we provide an overview of the key concepts in the field, point towards open questions, and frame the contributions of the ESANN 2021 special session into the broader context of deep learning for graphs. * Funding by the German Research Foundation (DFG) under grant number PA 3460/2-1 is gratefully acknowledged.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-5,2021,100.0,"Deep learning for graphs Deep learning for graphs encompasses all those neural models endowed with multiple layers of computation operating on data represented as graphs. The most common building blocks of these models are graph encoding layers, which compute a vector embedding for each node in a graph using message-passing operators. In this paper, we provide an overview of the key concepts in the field, point towards open questions, and frame the contributions of the ESANN 2021 special session into the broader context of deep learning for graphs. * Funding by the German Research Foundation (DFG) under grant number PA 3460/2-1 is gratefully acknowledged."
Deep Neural Networks for Classification of Riding Patterns: with a focus on explainability,"Milad Leyli Abadi, Abderrahmane Boubezoul","1 - -IRT SystemX Saclay France
2 - Gustave Eiffel University -TS2 Simu&Moto France","The powered two-wheelers (PTW) are among the most vulnerable transport users. It is crucial to identify the appropriate action that should be undertaken during a specific situation to reduce the risk. In this article, the aim is to improve the current state of the art in identification of riding patterns through neural network architectures and to explain how a decision is made by a model which is considered as a black box. In this regard, a new visualization tool specific to time series is suggested to help identify the most influential factors and hopefully to develop appropriate risk mitigation strategies.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-51,2021,100.0,"Deep Neural Networks for Classification of Riding Patterns: with a focus on explainability The powered two-wheelers (PTW) are among the most vulnerable transport users. It is crucial to identify the appropriate action that should be undertaken during a specific situation to reduce the risk. In this article, the aim is to improve the current state of the art in identification of riding patterns through neural network architectures and to explain how a decision is made by a model which is considered as a black box. In this regard, a new visualization tool specific to time series is suggested to help identify the most influential factors and hopefully to develop appropriate risk mitigation strategies."
Compact Neural Architecture Search for Local Climate Zones Classification,"Kalifou Traore, Andrés Camero, Xiao Zhu","1 - Data Science in Earth Observation Technical University of Munich
2 - German Aerospace Center (DLR) Remote Sensing Technology Institute (IMF)","State-of-the-art Computer Vision models achieve impressive performance but with an increasing complexity. Great advances have been made towards automatic model design, but accounting for model performance and low complexity is still an open challenge. In this study, we propose a neural architecture search strategy for high performance low complexity classification models, that combines an efficient search algorithm with mechanisms for reducing complexity. We tested our proposal on a real World remote sensing problem, the Local Climate Zone classification. The results show that our proposal achieves state-of-the-art performance, while being at least 91.8% more compact in terms of size and FLOPs.",Model selection,https://doi.org/10.14428/esann/2021.ES2021-55,2021,100.0,"Compact Neural Architecture Search for Local Climate Zones Classification State-of-the-art Computer Vision models achieve impressive performance but with an increasing complexity. Great advances have been made towards automatic model design, but accounting for model performance and low complexity is still an open challenge. In this study, we propose a neural architecture search strategy for high performance low complexity classification models, that combines an efficient search algorithm with mechanisms for reducing complexity. We tested our proposal on a real World remote sensing problem, the Local Climate Zone classification. The results show that our proposal achieves state-of-the-art performance, while being at least 91.8% more compact in terms of size and FLOPs."
A Lightweight Approach for Origin-Destination Matrix Anonymization,"Benoît Matet, Etienne Côme, Angelo Furno, Loïc Bonnetain, Latifa Oukhellou, Nour-Eddin El","1 - Univ. Gustave Eiffel COSYS F-77447 Marne-la-Vallée GRETTIA France
2 - Univ. Gustave Eiffel Univ. Lyon ENTPE F-69518 Lyon LICIT France","Personal trajectory data are becoming more and more accessible and have a high value in transport planning and mobility characterisation, at the cost of a risk for user's privacy. Addressing this risk is usually computationally expensive and can lead to losing most of the data utility. We explore a new, light-weight approach to Origin/Destinationmatrix anonymization that is easily scalable. We apply it to trip records from New York City Taxi and Limousine Commission (TLC) to illustrate how it can combine foolproof anonymity with a good spatial precision for a reasonable computational cost.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-56,2021,100.0,"A Lightweight Approach for Origin-Destination Matrix Anonymization Personal trajectory data are becoming more and more accessible and have a high value in transport planning and mobility characterisation, at the cost of a risk for user's privacy. Addressing this risk is usually computationally expensive and can lead to losing most of the data utility. We explore a new, light-weight approach to Origin/Destinationmatrix anonymization that is easily scalable. We apply it to trip records from New York City Taxi and Limousine Commission (TLC) to illustrate how it can combine foolproof anonymity with a good spatial precision for a reasonable computational cost."
Data-Efficient Training of High-Resolution Images in Medical Domain,"Amey Pandit, Kushagra Mahajan, Shruti Kunde, Monika Sharma",1 - Rekha Singhal and Lovekesh Vig TCS Research India,"The ability of Graphical Processor Units (GPUs) to quickly train dataand compute-intensive deep networks has led to rapid advancements across diverse domains such as robotics, medical imaging and autonomous driving. However, memory constraints with GPU-based training for memory-intensive deep networks have forced researchers to adopt various workarounds: 1) resize the input image, 2) divide input image into smaller patches, or use smaller batch-sizes in order to fit both the model and batch training data into GPU memory.While these alternatives perform well when dealing with natural images, they suffer from 1) loss of highresolution information, 2) loss of global context and 3) sub-optimal batch sizes. Such issues will likely to become more pressing for domains like medical imaging, where data is scarce and images are often of very high resolution with subtle features. Therefore, in this paper, we demonstrate that training can be made more data-efficient by using a distributed training setup with high-resolution images and larger effective batch sizes, with batches being distributed across multiple nodes. The distributed GPU training framework, which partitions the data and only shares model parameters across different GPUs, gets around the memory constraints of single GPU training. We conduct a study in which experiments are performed for different image resolutions (ranging from 112 × 112 to 1024 × 1024) and different number of images per class to determine the effect of image resolutions on network performance. We illustrate our findings on two medical imaging datasets namely, SD-198 skin-lesion and NIH Chest X-rays.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-57,2021,100.0,"Data-Efficient Training of High-Resolution Images in Medical Domain The ability of Graphical Processor Units (GPUs) to quickly train dataand compute-intensive deep networks has led to rapid advancements across diverse domains such as robotics, medical imaging and autonomous driving. However, memory constraints with GPU-based training for memory-intensive deep networks have forced researchers to adopt various workarounds: 1) resize the input image, 2) divide input image into smaller patches, or use smaller batch-sizes in order to fit both the model and batch training data into GPU memory.While these alternatives perform well when dealing with natural images, they suffer from 1) loss of highresolution information, 2) loss of global context and 3) sub-optimal batch sizes. Such issues will likely to become more pressing for domains like medical imaging, where data is scarce and images are often of very high resolution with subtle features. Therefore, in this paper, we demonstrate that training can be made more data-efficient by using a distributed training setup with high-resolution images and larger effective batch sizes, with batches being distributed across multiple nodes. The distributed GPU training framework, which partitions the data and only shares model parameters across different GPUs, gets around the memory constraints of single GPU training. We conduct a study in which experiments are performed for different image resolutions (ranging from 112 × 112 to 1024 × 1024) and different number of images per class to determine the effect of image resolutions on network performance. We illustrate our findings on two medical imaging datasets namely, SD-198 skin-lesion and NIH Chest X-rays."
Weightless Neural Networks for text classification using tf-idf,"Massimo De Gregorio, Antonio Sorgente, Giuseppe Vettigli","1 - Istituto di Scienze Applicate e Sistemi Intelligenti -CNR Italy
3 - Centrica plc -United Kingdom","While Weightless Neural Networks (WNN) have been proven effective in Natural Language Processing (NLP) applications, they require the use of highly customized features as they work on binary inputs. However, recent advancements have brought methodologies able to adapt WNN to real numbers showing competitive results on many classification tasks, but they often struggle on sparse data. In this paper, we show that WNN can successfully use sparse linguistic features, like tf-idf, using appropriate transformations. We also show that WNN can be used to improve the performances of existing models for Mixed Language Sentiment Analysis and that it has competitive performances for news categorization. 
 The WiSARD Classifier The WiSARD, originally conceived as a pattern recognition device mainly focusing on binary image processing [6], belongs to the class of weightless neu-239",Natural language processing,https://doi.org/10.14428/esann/2021.ES2021-58,2021,100.0,"Weightless Neural Networks for text classification using tf-idf While Weightless Neural Networks (WNN) have been proven effective in Natural Language Processing (NLP) applications, they require the use of highly customized features as they work on binary inputs. However, recent advancements have brought methodologies able to adapt WNN to real numbers showing competitive results on many classification tasks, but they often struggle on sparse data. In this paper, we show that WNN can successfully use sparse linguistic features, like tf-idf, using appropriate transformations. We also show that WNN can be used to improve the performances of existing models for Mixed Language Sentiment Analysis and that it has competitive performances for news categorization. 
 The WiSARD Classifier The WiSARD, originally conceived as a pattern recognition device mainly focusing on binary image processing [6], belongs to the class of weightless neu-239"
Stochastic quartet approach for fast multidimensional scaling,"Pierre Lambert, Cyril De Bodt, Michel Verleysen, John Lee","1 - -UCLouvain.be -ICTEAM/ELEN Place du Levant 3 L5.03.02, 1348 Louvain-la-Neuve Belgium
5 - UCLouvain.be -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium","Multidimensional scaling is a statistical process that aims to embed high-dimensional data into a lower-dimensional, more manageable space. Common MDS algorithms tend to have some limitations when facing large data sets due to their high time and spatial complexities. This paper attempts to tackle the problem by using a stochastic approach to MDS which uses gradient descent to optimise a loss function defined on randomly designated quartets of points. This method mitigates the quadratic memory usage by computing distances on the fly, and has iterations in O(N ) time complexity, with N samples. Experiments show that the proposed method provides competitive results in reasonable time. Public codes are available at https://github.com/PierreLambert3/SQuaD-MDS.git. 
 Multidimensional scaling and its limitations Dimensionality reduction (DR) is the process of mapping high-dimensional (HD) observations into a lower-dimensional (LD) space such that the LD embedding is a faithful representation of the HD data. The main DR uses are in machine learning, to curb the curse of dimensionality, and in visualisation. Mapped data can reveal structures that would lay hidden from the human perception if left in HD. Typically, some information is lost by the DR and, therefore, each DR method has a take on what kind of information should be preserved and what can be lost. Used frequently in visualisation, t-SNE [1] aims at retaining the neighbourhood of each point according to a distance metric and a perplexity, which reflects the size of the neighbourhood to preserve. While t-SNE excels at retaining local structures, sufficiently remote points tend to be considered equally distant by the algorithm and, therefore, the larger-scale structures can be distorted. Such distortions can lead to erroneous conclusions by the human user, who might overestimate the dissimilarity between two clusters that are distant in the LD embedding. For this reason, using multiple DR paradigms in conjunction is a good practice in visualisation: another embedding that preserves distances instead of neighbourhoods would have prevented this erroneous conclusion. This paper considers metric multidimensional scaling (MDS): a DR technique that produces a LD embedding such that the pairwise distances in LD reflect those in HD. MDS minimises a cost function which, in its simplest form, is the sum of the squared differences between distances in HD and the Euclidean distances in LD. A common strategy to optimize this cost function is based on 417",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-59,2021,100.0,"Stochastic quartet approach for fast multidimensional scaling Multidimensional scaling is a statistical process that aims to embed high-dimensional data into a lower-dimensional, more manageable space. Common MDS algorithms tend to have some limitations when facing large data sets due to their high time and spatial complexities. This paper attempts to tackle the problem by using a stochastic approach to MDS which uses gradient descent to optimise a loss function defined on randomly designated quartets of points. This method mitigates the quadratic memory usage by computing distances on the fly, and has iterations in O(N ) time complexity, with N samples. Experiments show that the proposed method provides competitive results in reasonable time. Public codes are available at https://github.com/PierreLambert3/SQuaD-MDS.git. 
 Multidimensional scaling and its limitations Dimensionality reduction (DR) is the process of mapping high-dimensional (HD) observations into a lower-dimensional (LD) space such that the LD embedding is a faithful representation of the HD data. The main DR uses are in machine learning, to curb the curse of dimensionality, and in visualisation. Mapped data can reveal structures that would lay hidden from the human perception if left in HD. Typically, some information is lost by the DR and, therefore, each DR method has a take on what kind of information should be preserved and what can be lost. Used frequently in visualisation, t-SNE [1] aims at retaining the neighbourhood of each point according to a distance metric and a perplexity, which reflects the size of the neighbourhood to preserve. While t-SNE excels at retaining local structures, sufficiently remote points tend to be considered equally distant by the algorithm and, therefore, the larger-scale structures can be distorted. Such distortions can lead to erroneous conclusions by the human user, who might overestimate the dissimilarity between two clusters that are distant in the LD embedding. For this reason, using multiple DR paradigms in conjunction is a good practice in visualisation: another embedding that preserves distances instead of neighbourhoods would have prevented this erroneous conclusion. This paper considers metric multidimensional scaling (MDS): a DR technique that produces a LD embedding such that the pairwise distances in LD reflect those in HD. MDS minimises a cost function which, in its simplest form, is the sum of the squared differences between distances in HD and the Euclidean distances in LD. A common strategy to optimize this cost function is based on 417"
"Complex Data: Learning Trustworthily, Automatically, and with Guarantees","Luca Oneto, Nicolò Navarin, Battista Biggio, Federico Errica, Alessio Micheli, Franco Scarselli, Monica Bianchini, Alessandro Sperduti","1 - Università di Genova Via Opera Pia 11a 16145 Genova Italy
2 - Università di Padova -Via Trieste 63 35121 Padova Italy
3 - Università di Cagliari -Piazza d'Armi 09123 Cagliari Italy
4 - Università di Pisa -Largo Bruno Pontecorvo 3 56127 Pisa Italy
6 - Università di Siena Via Roma 56 53100 Siena Italy","Machine Learning (ML) achievements enabled automatic extraction of actionable information from data in a wide range of decisionmaking scenarios. This demands for improving both ML technical aspects (e.g., design and automation) and human-related metrics (e.g., fairness, robustness, privacy, and explainability), with performance guarantees at both levels. The aforementioned scenario posed three main challenges: (i) Learning from Complex Data (i.e., sequence, tree, and graph data), (ii) Learning Trustworthily, and (iii) Learning Automatically with Guarantees. The focus of this special session is on addressing one or more of these challenges with the final goal of Learning Trustworthily, Automatically, and with Guarantees from Complex Data.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-6,2021,100.0,"Complex Data: Learning Trustworthily, Automatically, and with Guarantees Machine Learning (ML) achievements enabled automatic extraction of actionable information from data in a wide range of decisionmaking scenarios. This demands for improving both ML technical aspects (e.g., design and automation) and human-related metrics (e.g., fairness, robustness, privacy, and explainability), with performance guarantees at both levels. The aforementioned scenario posed three main challenges: (i) Learning from Complex Data (i.e., sequence, tree, and graph data), (ii) Learning Trustworthily, and (iii) Learning Automatically with Guarantees. The focus of this special session is on addressing one or more of these challenges with the final goal of Learning Trustworthily, Automatically, and with Guarantees from Complex Data."
Impact of data subsamplings in Fast Multi-Scale Neighbor Embedding,"Pierre Lambert, John Lee, Michel Verleysen, Cyril De Bodt","1 - -UCLouvain.be -ICTEAM/ELEN Place du Levant 3 L5.03.02, 1348 Louvain-la-Neuve Belgium
3 - UCLouvain.be -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium","Fast multi-scale neighbor embedding (f-ms-NE) is an algorithm that maps high-dimensional data to a low-dimensional space by preserving the multi-scale data neighborhoods. To lower its time complexity, f-ms-NE uses random subsamplings to estimate the data properties at multiple scales. To improve this estimation and study the f-ms-NE sensitivity to randomness, this paper generalizes the f-ms-NE cost function by averaging several subsamplings. Experiments reveal that this can slightly improve the quality of the embeddings while maintaining reasonable computation times. Codes are available at https://github.com/cdebodt/ Fast_Multi-scale_NE.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-60,2021,99.24812030075188,"Impact of data subsamplings in Fast Multi-Scale Neighbor Embedding Fast multi-scale neighbor embedding (f-ms-NE) is an algorithm that maps high-dimensional data to a low-dimensional space by preserving the multi-scale data neighborhoods. To lower its time complexity, f-ms-NE uses random subsamplings to estimate the data properties at multiple scales. To improve this estimation and study the f-ms-NE sensitivity to randomness, this paper generalizes the f-ms-NE cost function by averaging several subsamplings. Experiments reveal that this can slightly improve the quality of the embeddings while maintaining reasonable computation times. Codes are available at https://github.com/cdebodt/ Fast_Multi-scale_NE."
Fusion of estimations from two modalities using the Viterbi's algorithm: application to fetal heart rate monitoring,"Rémi Souriau, Julie Fontecave-Jallon, Bertrand Rivet","1 - UMR 5525 Univ. Grenoble Alpes CNRS VetAgro Sup
2 - Grenoble INP TIMC 38000 Grenoble France
3 - UMR 5216 GIPSA-lab Univ. Grenoble Alpes CNRS Grenoble INP 38000 Grenoble France","The Viterbi's algorithm allows to estimate latent time series according to observations in a hidden Markov model. This algorithm can be used to merge estimations from different modalities as proposed in this paper. Such a multi-modal estimation is more efficient than monomodal estimations when the modalities are subject to independent noises. In this paper, this improvement is evaluated in function of noise level of modalities. Experiences on toy data and actual signals to estimate the fetal heart rate show that merging modalities will provide better estimations on average than using the modalities separately.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-61,2021,100.0,"Fusion of estimations from two modalities using the Viterbi's algorithm: application to fetal heart rate monitoring The Viterbi's algorithm allows to estimate latent time series according to observations in a hidden Markov model. This algorithm can be used to merge estimations from different modalities as proposed in this paper. Such a multi-modal estimation is more efficient than monomodal estimations when the modalities are subject to independent noises. In this paper, this improvement is evaluated in function of noise level of modalities. Experiences on toy data and actual signals to estimate the fetal heart rate show that merging modalities will provide better estimations on average than using the modalities separately."
Density Independent Self-organized Support for Q-Value Function Interpolation in Reinforcement Learning,"Antonin Calba, Alain Dutech, Jérémy Fix","1 - Université de Lorraine Nancy -France. 2-Loria, Nancy -France ; 3-INRIA, Nancy -France 4-CentraleSupelec Metz France","In this paper, we propose a contribution in the field of Reinforcement Learning (RL) with continuous state space. Our work is along the line of previous works involving a vector quantization algorithm for learning the state space representation on top of which a function approximation takes place. In particular, our contribution compares the performances of the Kohonen SOM and the Rougier DSOM with the Göppert function approximation scheme on both the mountain car problem. We give a particular focus to DSOM as it is less sensitive to the density of inputs and opens interesting perspectives in RL.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-62,2021,100.0,"Density Independent Self-organized Support for Q-Value Function Interpolation in Reinforcement Learning In this paper, we propose a contribution in the field of Reinforcement Learning (RL) with continuous state space. Our work is along the line of previous works involving a vector quantization algorithm for learning the state space representation on top of which a function approximation takes place. In particular, our contribution compares the performances of the Kohonen SOM and the Rougier DSOM with the Göppert function approximation scheme on both the mountain car problem. We give a particular focus to DSOM as it is less sensitive to the density of inputs and opens interesting perspectives in RL."
Calliope -A Polyphonic Music Transformer,"Andrea Valenti, Stefano Berti, Davide Bacciu",1 - University of Pisa -Dept. of Computer Science Largo B. Pontecorvo 56127 Pisa Italy,"The polyphonic nature of music makes the application of deep learning to music modelling a challenging task. On the other hand, the Transformer architecture seems to be a good fit for this kind of data. In this work, we present Calliope, a novel autoencoder model based on Transformers for the efficient modelling of multi-track sequences of polyphonic music. The experiments show that our model is able to improve the state of the art on musical sequence reconstruction and generation, with remarkably good results especially on long sequences.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-63,2021,98.76543209876543,"Calliope -A Polyphonic Music Transformer The polyphonic nature of music makes the application of deep learning to music modelling a challenging task. On the other hand, the Transformer architecture seems to be a good fit for this kind of data. In this work, we present Calliope, a novel autoencoder model based on Transformers for the efficient modelling of multi-track sequences of polyphonic music. The experiments show that our model is able to improve the state of the art on musical sequence reconstruction and generation, with remarkably good results especially on long sequences."
Investigating Intensity and Transversal Drift in Hyperspectral Imaging Data,"Valerie Vaquet, Patrick Menz, Udo Seiffert, Barbara Hammer","1 - Machine Learning Group Bielefeld University Bielefeld Germany
2 - Fraunhofer Institute of Factory Operation and Automation (IFF) Cognitive Processes and Systems Magdeburg Germany","When measuring data with hyperspectral cameras drift in the data distribution occurs over time and when the sensing device is changed. Frequently, this drift is a combination of intensity and wavelength shifts. In this contribution, we demonstrate that transfer component analysis together with subsampling constitutes a particular efficient and simple technology for spectral offset elimination which is applied to avoid the negative impact of drift on the classification performance. We demonstrate that this approach performs on par or better in comparison to established methods, and we also provide a theoretical motivation why this technology can deal with both, intensity as well as wavelength shift provided bounds on the smoothness of the functional data are given.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-64,2021,100.0,"Investigating Intensity and Transversal Drift in Hyperspectral Imaging Data When measuring data with hyperspectral cameras drift in the data distribution occurs over time and when the sensing device is changed. Frequently, this drift is a combination of intensity and wavelength shifts. In this contribution, we demonstrate that transfer component analysis together with subsampling constitutes a particular efficient and simple technology for spectral offset elimination which is applied to avoid the negative impact of drift on the classification performance. We demonstrate that this approach performs on par or better in comparison to established methods, and we also provide a theoretical motivation why this technology can deal with both, intensity as well as wavelength shift provided bounds on the smoothness of the functional data are given."
Estimating Formulas for Model Performance Under Noisy Labels Using Symbolic Regression,"Scen Fech, Dawei Khoo, Michael Zhu, Dietrich Hedderich, Klakow",1 - Saarland University Saarland Informatics Campus Germany,"We present a generic formula characterizing the learning of our model under a variety of label-noise settings. This is achieved by using the symbolic regressor model, a genetic programming algorithm, from which we learn functions based on a large set of performance evaluations. Equipped with the knowledge from the regressor, we find a universal formula governing the model performance with respect to noise. This result from our empirical approach could have qualitative applications in mitigating the performance of real-world noisy data and could complement certain noise-robust models.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-65,2021,100.0,"Estimating Formulas for Model Performance Under Noisy Labels Using Symbolic Regression We present a generic formula characterizing the learning of our model under a variety of label-noise settings. This is achieved by using the symbolic regressor model, a genetic programming algorithm, from which we learn functions based on a large set of performance evaluations. Equipped with the knowledge from the regressor, we find a universal formula governing the model performance with respect to noise. This result from our empirical approach could have qualitative applications in mitigating the performance of real-world noisy data and could complement certain noise-robust models."
Enhancing brain decoding using attention augmented deep neural networks,"Ismail Abdellaoui, García Jesús, Caner Fernández, Siamak Sahinli, Mehrkanoon",1 - Department of Data Science and Knowledge Engineering Maastricht University The Netherlands,"Neuroimaging techniques have shown to be valuable when studying brain activity. This paper uses Magnetoencephalography (MEG) data, provided by the Human Connectome Project (HCP), and different deep learning models to perform brain decoding. Specifically, we investigate to which extent one can infer the task performed by a subject based on its MEG data. In order to capture the most relevant features of the signals, self and global attention are incorporated into our models. The obtained results show that the inclusion of attention improves the performance and generalization of the models across subjects. 
 Preliminaries Attention mechanisms allow the models to capture long-range dependencies, and highlight/suppress relevant/irrelevant parts of the input. The models used in this paper are equipped with two types of attention: self and global.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-67,2021,100.0,"Enhancing brain decoding using attention augmented deep neural networks Neuroimaging techniques have shown to be valuable when studying brain activity. This paper uses Magnetoencephalography (MEG) data, provided by the Human Connectome Project (HCP), and different deep learning models to perform brain decoding. Specifically, we investigate to which extent one can infer the task performed by a subject based on its MEG data. In order to capture the most relevant features of the signals, self and global attention are incorporated into our models. The obtained results show that the inclusion of attention improves the performance and generalization of the models across subjects. 
 Preliminaries Attention mechanisms allow the models to capture long-range dependencies, and highlight/suppress relevant/irrelevant parts of the input. The models used in this paper are equipped with two types of attention: self and global."
Improved and Generalized Vine Line Detection on Aerial Images Using Asymmetrical Neural Networks and ML Subclassifiers,"Jérôme Treboux, Rolf Ingold, Dominique Genoud","1 - University of Applied Sciences and Arts Western Switzerland (HES-SO) Sierre Switzerland
2 - Department of Informatics Fribourg University of Fribourg Switzerland","It is widely accepted that deep neural networks are very efficient for detecting objects in images. They reach their limit when detecting multiple instances of long lines in low-resolution images. We present an original methodology for the recognition of vine lines in low-resolution satellite images. The method consists in combining an asymmetrical neural network with a sub-classifier. We first compare a traditional U-Net architecture with an asymmetrical U-Net architecture designed for precision agriculture. We then highlight the significant improvement in vine line detection when a Random Forest is added after the customized U-Net. This methodology addresses the complex task of dissociating vine lines from other agricultural objects. As a result, our experiments improve the precision from 0.83 to 0.94 over our optimized neural network.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-68,2021,100.0,"Improved and Generalized Vine Line Detection on Aerial Images Using Asymmetrical Neural Networks and ML Subclassifiers It is widely accepted that deep neural networks are very efficient for detecting objects in images. They reach their limit when detecting multiple instances of long lines in low-resolution images. We present an original methodology for the recognition of vine lines in low-resolution satellite images. The method consists in combining an asymmetrical neural network with a sub-classifier. We first compare a traditional U-Net architecture with an asymmetrical U-Net architecture designed for precision agriculture. We then highlight the significant improvement in vine line detection when a Random Forest is added after the customized U-Net. This methodology addresses the complex task of dissociating vine lines from other agricultural objects. As a result, our experiments improve the precision from 0.83 to 0.94 over our optimized neural network."
Boundary-Based Fairness Constraints in Decision Trees and Random Forests,"Géraldin Nanfack, Valentin Delchevalerie, Benoît Frénay",1 - Faculty of Computer Science PReCISE Rue Grandgagnage 21 University of Namur -NaDI/naXys 5000 Namur Belgium,"Decision Trees (DTs) and Random Forests (RFs) are popular models in Machine Learning (ML) thanks to their interpretability and efficiency to solve real-world problems. However, DTs may sometimes learn rules that treat different groups of people unfairly, by paying attention to sensitive features like for example gender, age, income, language, etc. Even if several solutions have been proposed to reduce the unfairness for different ML algorithms, few of them apply to DTs. This work aims to transpose a successful method proposed by Zafar et al.  [1]  to reduce the unfairness in boundary based ML models to DTs.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-69,2021,100.0,"Boundary-Based Fairness Constraints in Decision Trees and Random Forests Decision Trees (DTs) and Random Forests (RFs) are popular models in Machine Learning (ML) thanks to their interpretability and efficiency to solve real-world problems. However, DTs may sometimes learn rules that treat different groups of people unfairly, by paying attention to sensitive features like for example gender, age, income, language, etc. Even if several solutions have been proposed to reduce the unfairness for different ML algorithms, few of them apply to DTs. This work aims to transpose a successful method proposed by Zafar et al.  [1]  to reduce the unfairness in boundary based ML models to DTs."
Machine learning and data mining for urban mobility intelligence,"Etienne Côme, Latifa Oukhellou, Allou Samé, Lijun Sun","1 - Univ. Gustave Eiffel COSYS F-77447 Marne-la-Vallée GRETTIA France
4 - McGill University 817 Sherbrooke St. W. Montreal H3A 0C3 QC Canada","The last few decades have seen a faster development of digital systems for observing the mobility of people and goods. Various sensing systems -such as radio communication, Wi-Fi, Bluetooth, validation of smart cards, mobile phone, and road traffic monitoring systems -have enabled researchers and practitioners to acquire large amounts of data, which generally refer to individual and collective trajectories. The mobility data can be further enriched with side information, such as text corpora from social media, survey data, and weather information. These massive data, temporally and spatially structured, can benefit from advanced machine learning and data mining methods, providing decision aid tools, and contributing to the development of safer, cleaner, and more efficient transportation systems. They can also help to implement new mobility services for the user. This article provides an overview of methodological advances in temporal and spatial mobility data processing. 
 Structural time series decomposition applied to mobility data Considering mobility data as time series, structural models [1] have been used to extract from them multiple latent components, each representing an aspect of 453",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-7,2021,100.0,"Machine learning and data mining for urban mobility intelligence The last few decades have seen a faster development of digital systems for observing the mobility of people and goods. Various sensing systems -such as radio communication, Wi-Fi, Bluetooth, validation of smart cards, mobile phone, and road traffic monitoring systems -have enabled researchers and practitioners to acquire large amounts of data, which generally refer to individual and collective trajectories. The mobility data can be further enriched with side information, such as text corpora from social media, survey data, and weather information. These massive data, temporally and spatially structured, can benefit from advanced machine learning and data mining methods, providing decision aid tools, and contributing to the development of safer, cleaner, and more efficient transportation systems. They can also help to implement new mobility services for the user. This article provides an overview of methodological advances in temporal and spatial mobility data processing. 
 Structural time series decomposition applied to mobility data Considering mobility data as time series, structural models [1] have been used to extract from them multiple latent components, each representing an aspect of 453"
Dynamic Graph Echo State Networks,"Domenico Tortorella, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy,"Dynamic temporal graphs represent evolving relations between entities, e.g. interactions between social network users or infection spreading. We propose an extension of graph echo state networks for the efficient processing of dynamic temporal graphs, with a sufficient condition for their echo state property, and an experimental analysis of reservoir layout impact. Compared to temporal graph kernels that need to hold the entire history of vertex interactions, our model provides a vector encoding for the dynamic graph that is updated at each time-step without requiring training. Experiments show accuracy comparable to approximate temporal graph kernels on twelve dissemination process classification tasks.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-70,2021,100.0,"Dynamic Graph Echo State Networks Dynamic temporal graphs represent evolving relations between entities, e.g. interactions between social network users or infection spreading. We propose an extension of graph echo state networks for the efficient processing of dynamic temporal graphs, with a sufficient condition for their echo state property, and an experimental analysis of reservoir layout impact. Compared to temporal graph kernels that need to hold the entire history of vertex interactions, our model provides a vector encoding for the dynamic graph that is updated at each time-step without requiring training. Experiments show accuracy comparable to approximate temporal graph kernels on twelve dissemination process classification tasks."
Inductive learning for product assortment graph completion,"H Dukić, G Deligiorgis, P Sepe, D Bacciu, M Trincavelli","1 - Dipartimento di Informatica Largo B. Pontecorvo 3 Universitá di Pisa 56127 Pisa Italy
2 - -H&M Group -Business Tech Mäster Samuelsgatan 46A AI, Analytics and Data, Sweden","Global retailers have assortments that contain hundreds of thousands of products that can be linked by several types of relationships like style compatibility, ""bought together"", ""watched together"", etc. Graphs are a natural representation for assortments, where products are nodes and relations are edges. Relations like style compatibility are often produced by a manual process and therefore do not cover uniformly the whole graph. We propose to use inductive learning to enhance a graph encoding style compatibility of a fashion assortment, leveraging rich node information comprising textual descriptions and visual data. Then, we show how the proposed graph enhancement improves substantially the performance on transductive tasks with a minor impact on graph sparsity.",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-73,2021,100.0,"Inductive learning for product assortment graph completion Global retailers have assortments that contain hundreds of thousands of products that can be linked by several types of relationships like style compatibility, ""bought together"", ""watched together"", etc. Graphs are a natural representation for assortments, where products are nodes and relations are edges. Relations like style compatibility are often produced by a manual process and therefore do not cover uniformly the whole graph. We propose to use inductive learning to enhance a graph encoding style compatibility of a fashion assortment, leveraging rich node information comprising textual descriptions and visual data. Then, we show how the proposed graph enhancement improves substantially the performance on transductive tasks with a minor impact on graph sparsity."
Supervised learning of convex piecewise linear approximations of optimization problems,"Laurine Duchesne, Quentin Louveaux, Louis Wehenkel",1 - University of Liege -Dept of EE&CS Liege Belgium,"We propose to use input convex neural networks (ICNN) to build convex approximations of non-convex feasible sets of optimization problems, in the form of a set of linear equalities and inequalities in a lifted space. Our approach may be tailored to yield both inner-and outer-approximations, or to maximize its accuracy in regions closer to the minimum of a given objective function. We illustrate the method on twodimensional toy problems and motivate it by various instances of reliability management problems of large-scale electric power systems.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-74,2021,100.0,"Supervised learning of convex piecewise linear approximations of optimization problems We propose to use input convex neural networks (ICNN) to build convex approximations of non-convex feasible sets of optimization problems, in the form of a set of linear equalities and inequalities in a lifted space. Our approach may be tailored to yield both inner-and outer-approximations, or to maximize its accuracy in regions closer to the minimum of a given objective function. We illustrate the method on twodimensional toy problems and motivate it by various instances of reliability management problems of large-scale electric power systems."
A Relational Model for One-Shot Classification,"Arturs Polis, Alexander Ilin",1 - Aalto University Espoo Finland,"We show that a deep learning model with built-in relational inductive bias can bring benefits to sample-efficient learning, without relying on extensive data augmentation. The proposed one-shot classification model performs relational matching of a pair of inputs in the form of local and pairwise attention. Our approach solves perfectly the one-shot image classification Omniglot challenge. Our model exceeds human level accuracy, as well as the previous state of the art, with no data augmentation.",Classification,https://doi.org/10.14428/esann/2021.ES2021-75,2021,100.0,"A Relational Model for One-Shot Classification We show that a deep learning model with built-in relational inductive bias can bring benefits to sample-efficient learning, without relying on extensive data augmentation. The proposed one-shot classification model performs relational matching of a pair of inputs in the form of local and pairwise attention. Our approach solves perfectly the one-shot image classification Omniglot challenge. Our model exceeds human level accuracy, as well as the previous state of the art, with no data augmentation."
Transfer learning in Bayesian optimization for the calibration of a beam line in proton therapy,"Valentin Hamaide, François Glineur",1 - UCLouvain -ICTEAM & CORE Louvain-la-Neuve Belgium,"Bayesian optimization (BO) is a type of black-box method used to optimize a costly objective function for which we have no access to derivatives. In practice, it is frequent that a series of similar problems has to be solved, with the problem data changing moderately between instances. We investigate a transfer learning approach based on BO that reuses information from a previous configuration in order to speed up subsequent optimizations. Our approach involves learning the noise variance to apply to the function values of the previous configuration and adapting the exploration-exploitation trade-off of the acquisition function from the previous configuration. We apply those ideas to the calibration of a beam line in proton therapy where the goal is to find magnet currents to obtain a desired shape for the beam of protons, and for which the calibration has to be repeated for several configurations. We show that reusing information from a previous configuration allows a reduction in the number of iterations by more than 80%, and that using BO is superior to the conventional Nelder-Mead algorithm for black box optimization and transfer learning.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-79,2021,100.0,"Transfer learning in Bayesian optimization for the calibration of a beam line in proton therapy Bayesian optimization (BO) is a type of black-box method used to optimize a costly objective function for which we have no access to derivatives. In practice, it is frequent that a series of similar problems has to be solved, with the problem data changing moderately between instances. We investigate a transfer learning approach based on BO that reuses information from a previous configuration in order to speed up subsequent optimizations. Our approach involves learning the noise variance to apply to the function values of the previous configuration and adapting the exploration-exploitation trade-off of the acquisition function from the previous configuration. We apply those ideas to the calibration of a beam line in proton therapy where the goal is to find magnet currents to obtain a desired shape for the beam of protons, and for which the calibration has to be repeated for several configurations. We show that reusing information from a previous configuration allows a reduction in the number of iterations by more than 80%, and that using BO is superior to the conventional Nelder-Mead algorithm for black box optimization and transfer learning."
Continual Learning with Echo State Networks,"Andrea Cossu, Davide Bacciu, Antonio Carta, Claudio Gallicchio, Vincenzo Lomonaco","1 - Department of Computer Science Largo B. Pontecorvo University of Pisa 56127 Pisa -Italy
2 - Scuola Normale Superiore Piazza dei Cavalieri 56126 Pisa Italy","Continual Learning (CL) refers to a learning setup where data is non stationary and the model has to learn without forgetting existing knowledge. The study of CL for sequential patterns revolves around trained recurrent networks. In this work, instead, we introduce CL in the context of Echo State Networks (ESNs), where the recurrent component is kept fixed. We provide the first evaluation of catastrophic forgetting in ESNs and we highlight the benefits in using CL strategies which are not applicable to trained recurrent models. Our results confirm the ESN as a promising model for CL and open to its use in streaming scenarios.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-80,2021,100.0,"Continual Learning with Echo State Networks Continual Learning (CL) refers to a learning setup where data is non stationary and the model has to learn without forgetting existing knowledge. The study of CL for sequential patterns revolves around trained recurrent networks. In this work, instead, we introduce CL in the context of Echo State Networks (ESNs), where the recurrent component is kept fixed. We provide the first evaluation of catastrophic forgetting in ESNs and we highlight the benefits in using CL strategies which are not applicable to trained recurrent models. Our results confirm the ESN as a promising model for CL and open to its use in streaming scenarios."
Robust Malware Classification via Deep Graph Networks on Call Graph Topologies,"Federico Errica, Giacomo Iadarola, Fabio Martinelli, Francesco Mercaldo, Alessio Micheli","1 - Department of Computer Science University of Pisa
2 - Institute of Informatics and Telematics Department of Medicine and Health Sciences National Research Council of Italy 3-University of Molise","We propose a malware classification system that is shown to be robust to some common intra-procedural obfuscation techniques. Indeed, by training the Contextual Graph Markov Model on the call graph representation of a program, we classify it using only topological information, which is unaffected by such obfuscations. In particular, we show that the structure of the call graph is sufficient to achieve good accuracy on a multi-class classification benchmark.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-82,2021,100.0,"Robust Malware Classification via Deep Graph Networks on Call Graph Topologies We propose a malware classification system that is shown to be robust to some common intra-procedural obfuscation techniques. Indeed, by training the Contextual Graph Markov Model on the call graph representation of a program, we classify it using only topological information, which is unaffected by such obfuscations. In particular, we show that the structure of the call graph is sufficient to achieve good accuracy on a multi-class classification benchmark."
Behavior Constraining in Weight Space for Offline Reinforcement Learning,"Phillip Swazinna, Steffen Udluft, Daniel Hein, Thomas Runkler","1 - Siemens Technology -Learning Systems Germany
3 - Technical University of Munich -Dept. of Informatics Germany","In offline reinforcement learning, a policy needs to be learned from a single pre-collected dataset. Typically, policies are thus regularized during training to behave similarly to the data generating policy, by adding a penalty based on a divergence between action distributions of generating and trained policy. We propose a new algorithm, which constrains the policy directly in its weight space instead, and demonstrate its effectiveness in experiments. * The project this paper is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01IS18049A.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-83,2021,100.0,"Behavior Constraining in Weight Space for Offline Reinforcement Learning In offline reinforcement learning, a policy needs to be learned from a single pre-collected dataset. Typically, policies are thus regularized during training to behave similarly to the data generating policy, by adding a penalty based on a divergence between action distributions of generating and trained policy. We propose a new algorithm, which constrains the policy directly in its weight space instead, and demonstrate its effectiveness in experiments. * The project this paper is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01IS18049A."
Real-time On-edge Classification: an Application to Domestic Acoustic Event Recognition,"Lode Vuegen, Peter Karsmakers",1 - Department of Computer Science Declarative Languages and Artificial Intelligence (DTAI) KU Leuven Kleinhoefstraat 4 B-2440 Geel Belgium,"In this paper two different convolutional neural network (CNN) architectures are investigated for the purpose of real-time on-edge domestic acoustic event classification. For training and evaluation of the models, a real-life acoustical dataset was recorded in 72 different home environments. A quantization-aware training scheme was applied that takes into account that the models need to run on 8-bit fixed-point processing hardware. Once trained, the models were successfully deployed on an ARM cortex-M7 microcontroller unit (i.MX RT1064). This study indicates that the used procedure can lead to an efficient and real-time embedded on-edge implementation of a domestic sound event classifier that does not sacrifice classification performance compared to its floating-point counterpart.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-84,2021,100.0,"Real-time On-edge Classification: an Application to Domestic Acoustic Event Recognition In this paper two different convolutional neural network (CNN) architectures are investigated for the purpose of real-time on-edge domestic acoustic event classification. For training and evaluation of the models, a real-life acoustical dataset was recorded in 72 different home environments. A quantization-aware training scheme was applied that takes into account that the models need to run on 8-bit fixed-point processing hardware. Once trained, the models were successfully deployed on an ARM cortex-M7 microcontroller unit (i.MX RT1064). This study indicates that the used procedure can lead to an efficient and real-time embedded on-edge implementation of a domestic sound event classifier that does not sacrifice classification performance compared to its floating-point counterpart."
Multiobjective Reinforcement Learning in Optimized Drug Design,"Maryam Abbasi, Tiago Pereira, Beatriz Santos, Bernardete Ribeiro, Joel Arrais",1 - Department of Informatics Engineering (DEI) Center for Informatics and Systems University of Coimbra (CISUC) University of Coimbra Coimbra Portugal,"Machine learning has been increasingly applied with success in generating synthetically reasonable molecules. However, a complete system capable of both producing valid molecules and optimizing multiple traits has remained elusive. This paper employs multiobjective reinforcement learning to draw a framework to design compounds. Different multiobjective techniques have been evaluated, such as weighted sum and Chebyshev. The results show that the implemented model can be effectively optimized towards different and competing molecular properties. Nonetheless, the model implemented with the weighted sum scalarization technique with a weight of 0.55 for biological affinity is the one with the most appropriate trade-off for the different evaluated properties.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-87,2021,100.0,"Multiobjective Reinforcement Learning in Optimized Drug Design Machine learning has been increasingly applied with success in generating synthetically reasonable molecules. However, a complete system capable of both producing valid molecules and optimizing multiple traits has remained elusive. This paper employs multiobjective reinforcement learning to draw a framework to design compounds. Different multiobjective techniques have been evaluated, such as weighted sum and Chebyshev. The results show that the implemented model can be effectively optimized towards different and competing molecular properties. Nonetheless, the model implemented with the weighted sum scalarization technique with a weight of 0.55 for biological affinity is the one with the most appropriate trade-off for the different evaluated properties."
The LVQ-based Counter Propagation Networkan Interpretable Information Bottleneck Approach,"M Kaden, R Schubert, M Bakhtiari, L Schwarz, T Villmann","1 - University of Applied Sciences Mittweida
2 - Saxon Institute for Comp. Intelligence and Machine Learning Mittweida Germany","In this paper we present a realization of the informationbottleneck-paradigm by means of an improved counter propagation network. It combines an unsupervised vector quantizer for data compression with a subsequent supervised learning vector quantization model. The approach is mathematically justified and yields an interpretable model for classification under the constraint of data compression, which is not longer independently learned from the classification task. * M.K., M.M.B. and D.S. were supported by grants of the European Social Fund (ESF) for a Young Researcher Group 'MaLeKITA' and a PhD grant.",Interpretable Models in Machine Learning and Explainable Artificial Intelligence,https://doi.org/10.14428/esann/2021.ES2021-88,2021,95.6043956043956,"The LVQ-based Counter Propagation Networkan Interpretable Information Bottleneck Approach In this paper we present a realization of the informationbottleneck-paradigm by means of an improved counter propagation network. It combines an unsupervised vector quantizer for data compression with a subsequent supervised learning vector quantization model. The approach is mathematically justified and yields an interpretable model for classification under the constraint of data compression, which is not longer independently learned from the classification task. * M.K., M.M.B. and D.S. were supported by grants of the European Social Fund (ESF) for a Young Researcher Group 'MaLeKITA' and a PhD grant."
NNBMSS: a Novel and Fast Method for Model Structure Selection,"Amaury Lendasse, Kallin Khan, Edward Ratner","1 - Department of Information and Logistics Technology Houston University of Houston USA
2 - Arcada University of Applied Sciences -Risklab Helsinki Finland
3 - Edammo Inc. Iowa City USA","In this paper, we present a new method to perform model structure selection. This proposed method can be used to select the complexity of any continuous regression method. We also present an asymptotic mathematical proof of the proposed method and the new method is illustrated on a benchmark. Compared to the well-known 10-fold Cross-Validation, the computational time associated to our new method is approximately divided by a factor 8 as illustrated on the benchmark.",Model selection,https://doi.org/10.14428/esann/2021.ES2021-9,2021,100.0,"NNBMSS: a Novel and Fast Method for Model Structure Selection In this paper, we present a new method to perform model structure selection. This proposed method can be used to select the complexity of any continuous regression method. We also present an asymptotic mathematical proof of the proposed method and the new method is illustrated on a benchmark. Compared to the well-known 10-fold Cross-Validation, the computational time associated to our new method is approximately divided by a factor 8 as illustrated on the benchmark."
RecLVQ: Recurrent Learning Vector Quantization,"Jensun Ravichandran, Marika Kaden, Thomas Villmann","1 - University of Applied Sciences Mittweida
2 - Saxon Institute for Comp. Intelligence and Machine Learning Mittweida Germany","Learning Vector Quantizers (LVQ) and its cost-functionbased variant called Generalized Learning Vector Quanitzation (GLVQ) are powerful, yet simple and interpretable classification models. Even though GLVQ is an effective tool for classifying vectorial data, it cannot handle raw sequence data of potentially different lengths. Usually, this problem is solved by manually engineering fixed-length features or by employing recurrent networks. Therefore, a natural idea is to incorporate recurrent units for data processing into the GLVQ network structure. The processed data can then be compared in a latent space for classification decisions. We demonstrate the ability of this approach on illustrative classification problems. * M.K. and J.R. are supported by grants of the European Social Fund (ESF).","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-90,2021,100.0,"RecLVQ: Recurrent Learning Vector Quantization Learning Vector Quantizers (LVQ) and its cost-functionbased variant called Generalized Learning Vector Quanitzation (GLVQ) are powerful, yet simple and interpretable classification models. Even though GLVQ is an effective tool for classifying vectorial data, it cannot handle raw sequence data of potentially different lengths. Usually, this problem is solved by manually engineering fixed-length features or by employing recurrent networks. Therefore, a natural idea is to incorporate recurrent units for data processing into the GLVQ network structure. The processed data can then be compared in a latent space for classification decisions. We demonstrate the ability of this approach on illustrative classification problems. * M.K. and J.R. are supported by grants of the European Social Fund (ESF)."
Convolutional Neural Network Architecture for Classification of Aircraft Engines Flight Time Series,"Delphine Bay, Clémence Bisot",1 - Safran Aircraft Engines 2 chemin de Viercy 77019 Montereau-sur-le-Jard France,"During each flight, an aircraft engine sends data to a ground system. This data corresponds to different sensors measurements (temperatures, pressures, vibrations...) collected at key moments of the flight. It constitutes rich multivariate time series used to monitor the engine's health. In this article, we used flight data to predict the main removal cause of the engine. The problem falls within the framework of time series classification. This article proposes an interpretable neural network architecture which fits with the physical understanding of the modeled phenomenon in order to address the problem on a real-world, industrial dataset.",Time series and signal processing,https://doi.org/10.14428/esann/2021.ES2021-91,2021,100.0,"Convolutional Neural Network Architecture for Classification of Aircraft Engines Flight Time Series During each flight, an aircraft engine sends data to a ground system. This data corresponds to different sensors measurements (temperatures, pressures, vibrations...) collected at key moments of the flight. It constitutes rich multivariate time series used to monitor the engine's health. In this article, we used flight data to predict the main removal cause of the engine. The problem falls within the framework of time series classification. This article proposes an interpretable neural network architecture which fits with the physical understanding of the modeled phenomenon in order to address the problem on a real-world, industrial dataset."
Concept Drift Segmentation via Kolmogorov-Trees,"Fabian Hinder, Barbara Hammer",1 - Bielefeld University -Cognitive Interaction Technology (CITEC) Inspiration 1 33619 Bielefeld Germany,"The notion of concept drift refers to the phenomenon that the data distribution changes over time. If drift occurs, machine learning models need adjustment. Since drift can be inhomogeneous, suitable actions depending on the location in data space. In this paper we address the challenge to partition the data space into segments with homogeneous drift characteristics. We formalize this objective as an independence criterion, and derive a robust and efficient training algorithm based thereon. We evaluate the efficiency of the method in comparison to existing technologies: the identification of drifting clusters, and the estimation of a conditional density distribution. * Funding in the frame of the BMBF project ITS.ML, 01IS18041A is gratefully acknowledged.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-93,2021,100.0,"Concept Drift Segmentation via Kolmogorov-Trees The notion of concept drift refers to the phenomenon that the data distribution changes over time. If drift occurs, machine learning models need adjustment. Since drift can be inhomogeneous, suitable actions depending on the location in data space. In this paper we address the challenge to partition the data space into segments with homogeneous drift characteristics. We formalize this objective as an independence criterion, and derive a robust and efficient training algorithm based thereon. We evaluate the efficiency of the method in comparison to existing technologies: the identification of drifting clusters, and the estimation of a conditional density distribution. * Funding in the frame of the BMBF project ITS.ML, 01IS18041A is gratefully acknowledged."
Federated Learning approach for Spectral Clustering,"Elena Hernández-Pereira, Oscar Fontenla-Romero, Bertha Guijarro-Berdiñas, Beatriz Pérez-Sánchez","1 - CITIC and Facultad de Informática Universidade da Coruña Campus de Elviña, A Coruña Spain
2 - Consellería de Cultura Educación
3 - Universidades from Xunta de Galicia""","Spectral clustering is a clustering paradigm that has been shown to be more effective in finding clusters with non-convex shapes than some traditional algorithms such as k-means. However, this algorithm is not directly applicable when the data is naturally distributed in different locations, as it happens in many Internet of Things scenarios. In this work, we propose a distributed spectral clustering to create a cooperative federated model to deal with those cases in which the data is distributed in different sites and with data privacy concerns. We demonstrate that sharing a minimal amount of information allows this distributed version of the spectral clustering to achieve good behavior for clustering several synthetic data sets.",Unsupervised learning,https://doi.org/10.14428/esann/2021.ES2021-95,2021,79.20792079207921,"Federated Learning approach for Spectral Clustering Spectral clustering is a clustering paradigm that has been shown to be more effective in finding clusters with non-convex shapes than some traditional algorithms such as k-means. However, this algorithm is not directly applicable when the data is naturally distributed in different locations, as it happens in many Internet of Things scenarios. In this work, we propose a distributed spectral clustering to create a cooperative federated model to deal with those cases in which the data is distributed in different sites and with data privacy concerns. We demonstrate that sharing a minimal amount of information allows this distributed version of the spectral clustering to achieve good behavior for clustering several synthetic data sets."
Improvement on Generative Adversarial Network for Targeted Drug Design,"Beatriz Santos, Maryam Abbasi, Tiago Pereira, Bernardete Ribeiro, Joel Arrais",1 - Department of Informatics Engineering (DEI) Center for Informatics and Systems University of Coimbra (CISUC) University of Coimbra Coimbra Portugal,"This paper provides a generative network framework that can replicate the molecular space distribution to satisfy a set of desirable features. The approach incorporates two effective machine learning techniques: an Encoder-Decoder architecture that converts the string notations of molecules into latent space and a generative adversarial network to learn the data distribution and generate new compounds. We train this joint model on a dataset that includes stereo-chemical information. The results show an improvement in the Encoder-Decoder performance, reaching 89% of correctly reconstructed molecules. The framework can generate a wide variety of compounds biased towards specific molecular properties using Transfer Learning.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-96,2021,100.0,"Improvement on Generative Adversarial Network for Targeted Drug Design This paper provides a generative network framework that can replicate the molecular space distribution to satisfy a set of desirable features. The approach incorporates two effective machine learning techniques: an Encoder-Decoder architecture that converts the string notations of molecules into latent space and a generative adversarial network to learn the data distribution and generate new compounds. We train this joint model on a dataset that includes stereo-chemical information. The results show an improvement in the Encoder-Decoder performance, reaching 89% of correctly reconstructed molecules. The framework can generate a wide variety of compounds biased towards specific molecular properties using Transfer Learning."
Cross-modal verification for 3D object detection,"Haodi Zhang, Alexandrina Rogozan, Abdelaziz Bensrhair",1 - LITIS LAB -INSA de ROUEN -Normandie Universite 786 Avenue de l'Universite 76000 Rouen France,"To overcome the deficiency in the single modality of LiDAR point cloud, we propose a cross-modal verification (CMV) model for reducing 3D object detection false positives. The abundant color and texture information in image modality allow the classification of the projection region of 3D bounding box proposal in the image plane. Three 3D object detectors are adopted as backbone and eight evaluation metrics are used to fully investigate the proposed model. The experiment results show that the proposed CMV model removes more than 50% of false positives in 3D object detection proposals and significantly improves the performance of 3D object detection.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-97,2021,100.0,"Cross-modal verification for 3D object detection To overcome the deficiency in the single modality of LiDAR point cloud, we propose a cross-modal verification (CMV) model for reducing 3D object detection false positives. The abundant color and texture information in image modality allow the classification of the projection region of 3D bounding box proposal in the image plane. Three 3D object detectors are adopted as backbone and eight evaluation metrics are used to fully investigate the proposed model. The experiment results show that the proposed CMV model removes more than 50% of false positives in 3D object detection proposals and significantly improves the performance of 3D object detection."
Slope: A First-order Approach for Measuring Gradient Obfuscation,"Maura Pintor, Luca Demetrio, Giovanni Manca, Battista Biggio, Fabio Roli",1 - University of Cagliari Italy,"Evaluating adversarial robustness is a challenging problem. Many defenses have been shown to provide a false sense of security by unintentionally obfuscating gradients, hindering the optimization process of gradient-based attacks. Such defenses have been subsequently shown to fail against adaptive attacks crafted to circumvent gradient obfuscation. In this work, we present Slope, a metric that detects obfuscated gradients by comparing the expected and the actual increase of the attack loss after one iteration. We show that our metric can detect the presence of obfuscated gradients in many documented cases, providing a useful debugging tool towards improving adversarial robustness evaluations.","Complex Data: Learning Trustworthily, Automatically, and with Guarantees",https://doi.org/10.14428/esann/2021.ES2021-99,2021,100.0,"Slope: A First-order Approach for Measuring Gradient Obfuscation Evaluating adversarial robustness is a challenging problem. Many defenses have been shown to provide a false sense of security by unintentionally obfuscating gradients, hindering the optimization process of gradient-based attacks. Such defenses have been subsequently shown to fail against adaptive attacks crafted to circumvent gradient obfuscation. In this work, we present Slope, a metric that detects obfuscated gradients by comparing the expected and the actual increase of the attack loss after one iteration. We show that our metric can detect the presence of obfuscated gradients in many documented cases, providing a useful debugging tool towards improving adversarial robustness evaluations."
Attention-based Ingredient Phrase Parser,"Zhengxiang Shi, Pin Ni, Meihui Wang, Eun Kim, Aldo Lipani",1 - University College London Gower St London United Kingdom,"As virtual personal assistants have now penetrated the consumer market, with products such as Siri and Alexa, the research community has produced several works on task-oriented dialogue tasks such as hotel booking, restaurant booking, and movie recommendation. Assisting users to cook is one of these tasks that are expected to be solved by intelligent assistants, where ingredients and their corresponding attributes, such as name, unit, and quantity, should be provided to users precisely and promptly. However, existing ingredient information scraped from the cooking website is in the unstructured form with huge variation in the lexical structure, for example, ""1 garlic clove, crushed"", and ""1 (8 ounce) package cream cheese, softened"", making it difficult to extract information exactly. To provide an engaged and successful conversational service to users for cooking tasks, we propose a new ingredient parsing model that can parse an ingredient phrase of recipes into the structure form with its corresponding attributes with over 0.93 F1-score. Experimental results show that our model achieves state-of-the-art performance on AllRecipes and Food.com datasets.","Natural language processing, and recommender systems",https://doi.org/10.14428/esann/2022.ES2022-10,2022,100.0,"Attention-based Ingredient Phrase Parser As virtual personal assistants have now penetrated the consumer market, with products such as Siri and Alexa, the research community has produced several works on task-oriented dialogue tasks such as hotel booking, restaurant booking, and movie recommendation. Assisting users to cook is one of these tasks that are expected to be solved by intelligent assistants, where ingredients and their corresponding attributes, such as name, unit, and quantity, should be provided to users precisely and promptly. However, existing ingredient information scraped from the cooking website is in the unstructured form with huge variation in the lexical structure, for example, ""1 garlic clove, crushed"", and ""1 (8 ounce) package cream cheese, softened"", making it difficult to extract information exactly. To provide an engaged and successful conversational service to users for cooking tasks, we propose a new ingredient parsing model that can parse an ingredient phrase of recipes into the structure form with its corresponding attributes with over 0.93 F1-score. Experimental results show that our model achieves state-of-the-art performance on AllRecipes and Food.com datasets."
Hyperspectral Wavelength Analysis with U-Net for Larynx Cancer Detection,"Felix Meyer-Veit, Rania Rayyes, Andreas Gerstner, Jochen Steil",1 - Technische Universität Braunschweig -Inst. für Robotik und Prozessinformatik 2-Klinikum Braunschweig -ENT -Holwedestr. 16 38118 Braunschweig Germany,"Early detection of laryngeal tumors is critical for their successful therapy. In this paper, we investigate how hyperspectral (HS) imaging can contribute to this aim based on an in-vivo data set of 13 HS image cubes recorded in clinical practice. We perform semantic segmentation with a tailored U-Net trained on labels provided by the clinicians. We specifically investigate the influence of exposure time during image acquisition, the suitable wavelengths to determine the most informative image channels, and present quantitative results on accuracy and the AUC measure. * The data set collection was funded by the German Cancer Aid within the project framework ""Early detection of laryngeal cancer by means of Hyperspectral Imaging (109825110275)"".","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-100,2022,100.0,"Hyperspectral Wavelength Analysis with U-Net for Larynx Cancer Detection Early detection of laryngeal tumors is critical for their successful therapy. In this paper, we investigate how hyperspectral (HS) imaging can contribute to this aim based on an in-vivo data set of 13 HS image cubes recorded in clinical practice. We perform semantic segmentation with a tailored U-Net trained on labels provided by the clinicians. We specifically investigate the influence of exposure time during image acquisition, the suitable wavelengths to determine the most informative image channels, and present quantitative results on accuracy and the AUC measure. * The data set collection was funded by the German Cancer Aid within the project framework ""Early detection of laryngeal cancer by means of Hyperspectral Imaging (109825110275)""."
Sliced-Wasserstein normalizing flows: beyond maximum likelihood training,"Florentin Coeurdoux, Nicolas Dobigeon, Pierre Chainais","1 - University of Toulouse IRIT/INP ENSEEIHT F-31071 Toulouse France
3 - Institut Universitaire de France (IUF) France
4 - UMR 9189 CRIStAL Univ. Lille CNRS Centrale Lille F-59000 Lille France","Despite their advantages, normalizing flows generally suffer from several shortcomings including their tendency to generate unrealistic data (e.g., images) and their failing to detect out-of-distribution data. One reason for these deficiencies lies in the training strategy which traditionally exploits a maximum likelihood principle only. This paper proposes a new training paradigm based on a hybrid objective function combining the maximum likelihood principle (MLE) and a sliced-Wasserstein distance. Results obtained on synthetic toy examples and real image data sets show better generative abilities in terms of both likelihood and visual aspects of the generated samples. Reciprocally, the proposed approach leads to a lower likelihood of out-of-distribution data, demonstrating a greater data fidelity of the resulting flows.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-101,2022,100.0,"Sliced-Wasserstein normalizing flows: beyond maximum likelihood training Despite their advantages, normalizing flows generally suffer from several shortcomings including their tendency to generate unrealistic data (e.g., images) and their failing to detect out-of-distribution data. One reason for these deficiencies lies in the training strategy which traditionally exploits a maximum likelihood principle only. This paper proposes a new training paradigm based on a hybrid objective function combining the maximum likelihood principle (MLE) and a sliced-Wasserstein distance. Results obtained on synthetic toy examples and real image data sets show better generative abilities in terms of both likelihood and visual aspects of the generated samples. Reciprocally, the proposed approach leads to a lower likelihood of out-of-distribution data, demonstrating a greater data fidelity of the resulting flows."
Lightening CNN architectures by regularization driven weights' pruning,"Giovanni Bonetta, Rossella Cancelliere",1 - Department of Computer Science University of Turin 12 -10149 Turin Italy,"Deep learning models are getting increasingly big, leading towards overparametrized architectures with high computational and storage requirements. This hinders the possibility to train/deploy them on IoT or mobile devices, while also creating concerns about their environmental fingerprint. We propose a regularization technique which allows to selectively shrink the norm of non significant weights in order to subsequently prune them, generating highly compressed models. We tested the proposed technique on three well known image classification tasks, obtaining results on par or better than competitors in terms of sparsity and metrics.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-102,2022,100.0,"Lightening CNN architectures by regularization driven weights' pruning Deep learning models are getting increasingly big, leading towards overparametrized architectures with high computational and storage requirements. This hinders the possibility to train/deploy them on IoT or mobile devices, while also creating concerns about their environmental fingerprint. We propose a regularization technique which allows to selectively shrink the norm of non significant weights in order to subsequently prune them, generating highly compressed models. We tested the proposed technique on three well known image classification tasks, obtaining results on par or better than competitors in terms of sparsity and metrics."
Constraint Guided Gradient Descent: Guided Training with Inequality Constraints,"Quinten Van Baelen, Peter Karsmakers","1 - Leuven.AI -KU Leuven institute for AI
3 - Dept. of Computer Science ADVISE-DTAI Kleinhoefstraat 4 1-KU, B-2440 Leuven, Geel Belgium","Deep learning is typically performed by learning a neural network solely from data in the form of input-output pairs ignoring available domain knowledge. In this work, the Constraint Guided Gradient Descent (CGGD) framework is proposed that enables the injection of domain knowledge into the training procedure. The domain knowledge is assumed to be described as a conjunction of hard inequality constraints which appears to be a natural choice for several applications. Compared to other neuro-symbolic approaches, the proposed method converges to a model that satisfies any inequality constraint on the training data and does not require to first transform the constraints into some ad-hoc term that is added to the learning (optimisation) objective. Under certain conditions, it is shown that CGGD can converge to a model that satisfies the constraints on the training set, while prior work does not necessarily converge to such a model. It is empirically shown on two independent and small data sets that CGGD makes training less dependent on the initialisation of the network and improves the constraint satisfiability on all data.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-105,2022,100.0,"Constraint Guided Gradient Descent: Guided Training with Inequality Constraints Deep learning is typically performed by learning a neural network solely from data in the form of input-output pairs ignoring available domain knowledge. In this work, the Constraint Guided Gradient Descent (CGGD) framework is proposed that enables the injection of domain knowledge into the training procedure. The domain knowledge is assumed to be described as a conjunction of hard inequality constraints which appears to be a natural choice for several applications. Compared to other neuro-symbolic approaches, the proposed method converges to a model that satisfies any inequality constraint on the training data and does not require to first transform the constraints into some ad-hoc term that is added to the learning (optimisation) objective. Under certain conditions, it is shown that CGGD can converge to a model that satisfies the constraints on the training set, while prior work does not necessarily converge to such a model. It is empirically shown on two independent and small data sets that CGGD makes training less dependent on the initialisation of the network and improves the constraint satisfiability on all data."
Improving Laplacian Pyramids Regression with Localization in Frequency and Time,"Ben Hen, Ángela Fernández, Neta Rabin","1 - Department of Industrial Engineering Tel-Aviv University Israel
2 - Dpto de Ingeniería Informática Universidad Autónoma de Madrid Spain","Auto-Adaptive Laplacian Pyramids (ALP) is an iterative kernel-based regression model. It constructs a multi-scale representation of the train data, where the multi-scale modes are average residuals. In this work, we propose two extensions of the model. The first is a hybrid approach that combines ALP with Empirical Mode Decomposition to provide localization in the frequency domain. The second modifies ALP to fit datasets with non-uniform noise, which is achieved by computing the optimal stopping criterion in a point-dependent manner. Experimental results demonstrate these models for solar energy prediction and for forecasting epidemiology infections.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-106,2022,100.0,"Improving Laplacian Pyramids Regression with Localization in Frequency and Time Auto-Adaptive Laplacian Pyramids (ALP) is an iterative kernel-based regression model. It constructs a multi-scale representation of the train data, where the multi-scale modes are average residuals. In this work, we propose two extensions of the model. The first is a hybrid approach that combines ALP with Empirical Mode Decomposition to provide localization in the frequency domain. The second modifies ALP to fit datasets with non-uniform noise, which is achieved by computing the optimal stopping criterion in a point-dependent manner. Experimental results demonstrate these models for solar energy prediction and for forecasting epidemiology infections."
Deep learning for Parkinson's disease symptom detection and severity evaluation using accelerometer signal,Tomasz Gutowski,1 - Cybernetics Faculty gen. Sylwestra Military University of Technology Kaliskiego 2 00 - 908 Warsaw Poland,"This paper presents a neural network for predicting the severity/presence of Parkinson's disease motor symptomstremor, bradykinesia and dyskinesia, based on accelerometer signals collected while the patient is executing selected tasks. The suggested network uses accelerometer signals as input along with the type of completed task and the side the device is worn on. The data was collected in the Levodopa Response Study funded by MJFF. The model has been trained for every symptom separately and the results have helped to identify the tasks that result in the best accuracy of symptom detection and evaluation.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-107,2022,99.05660377358491,"Deep learning for Parkinson's disease symptom detection and severity evaluation using accelerometer signal This paper presents a neural network for predicting the severity/presence of Parkinson's disease motor symptomstremor, bradykinesia and dyskinesia, based on accelerometer signals collected while the patient is executing selected tasks. The suggested network uses accelerometer signals as input along with the type of completed task and the side the device is worn on. The data was collected in the Levodopa Response Study funded by MJFF. The model has been trained for every symptom separately and the results have helped to identify the tasks that result in the best accuracy of symptom detection and evaluation."
Bayes Point Rule Set Learning,"Fabio Aiolli, Luca Bergamin, Tommaso Carraro, Mirko Polato","1 - Department of Mathematics University of Padova Padova Italy
4 - Fondazione Bruno Kessler Trento Italy
5 - Department of Computer Science University of Turin Turin Italy","This paper proposes an effective bottom-up extension of the popular FIND-S algorithm to learn (monotone) DNF-type rulesets. The algorithm greedily finds a partition of the positive examples. The produced monotone DNF is a set of conjunctive rules, each corresponding to the most specific rule consistent with a part of positive and all negative examples. We also propose two principled extensions of this method, approximating the Bayes Optimal Classifier by aggregating monotone DNF decision rules. Finally, we provide a methodology to improve the explainability of the learned rules while retaining their generalization capabilities. An extensive comparison with state-of-the-art symbolic and statistical methods on several benchmark data sets shows that our proposal provides an excellent balance between explainability and accuracy.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-108,2022,100.0,"Bayes Point Rule Set Learning This paper proposes an effective bottom-up extension of the popular FIND-S algorithm to learn (monotone) DNF-type rulesets. The algorithm greedily finds a partition of the positive examples. The produced monotone DNF is a set of conjunctive rules, each corresponding to the most specific rule consistent with a part of positive and all negative examples. We also propose two principled extensions of this method, approximating the Bayes Optimal Classifier by aggregating monotone DNF decision rules. Finally, we provide a methodology to improve the explainability of the learned rules while retaining their generalization capabilities. An extensive comparison with state-of-the-art symbolic and statistical methods on several benchmark data sets shows that our proposal provides an excellent balance between explainability and accuracy."
A Bayesian Variational Principle for Dynamic Self Organizing Maps,"Anthony Fillion, Thibaut Kulak, François Blayo",1 - 1-NeoInstinct -NeoLab 3 rue Traversière Lausanne Switzerland,We propose organisation conditions that yield a method for training SOM with adaptative neighborhood radius in a variational Bayesian framework. This method is validated on a non-stationary setting and compared in an high-dimensional setting with an other adaptative method.,Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-11,2022,83.07692307692307,A Bayesian Variational Principle for Dynamic Self Organizing Maps We propose organisation conditions that yield a method for training SOM with adaptative neighborhood radius in a variational Bayesian framework. This method is validated on a non-stationary setting and compared in an high-dimensional setting with an other adaptative method.
Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning,"Yi Zhao, Rinu Boney, Alexander Ilin, Juho Kannala, Joni Pajarinen","1 - Department of Electrical Engineering and Automation Aalto University
2 - Department of Computer Science Aalto Universiity Finland
6 - Department of Computer Science Technical University Darmstadt Germany","Offline reinforcement learning, by learning from a fixed dataset, makes it possible to learn agent behaviors without interacting with the environment. However, depending on the quality of the offline dataset, such pre-trained agents may have limited performance and would further need to be fine-tuned online by interacting with the environment. During online fine-tuning, the performance of the pre-trained agent may collapse quickly due to the sudden distribution shift from offline to online data. We propose to adaptively weigh the behavior cloning loss during online fine-tuning based on the agent's performance and training stability. Moreover, we use a randomized ensemble of Q functions to further increase the sample efficiency of online fine-tuning by performing a large number of learning updates. Experiments show that the proposed method yields state-of-the-art offline-to-online reinforcement learning performance on the popular D4RL benchmark.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-110,2022,100.0,"Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning Offline reinforcement learning, by learning from a fixed dataset, makes it possible to learn agent behaviors without interacting with the environment. However, depending on the quality of the offline dataset, such pre-trained agents may have limited performance and would further need to be fine-tuned online by interacting with the environment. During online fine-tuning, the performance of the pre-trained agent may collapse quickly due to the sudden distribution shift from offline to online data. We propose to adaptively weigh the behavior cloning loss during online fine-tuning based on the agent's performance and training stability. Moreover, we use a randomized ensemble of Q functions to further increase the sample efficiency of online fine-tuning by performing a large number of learning updates. Experiments show that the proposed method yields state-of-the-art offline-to-online reinforcement learning performance on the popular D4RL benchmark."
An empirical comparison of generators in replay-based continual learning,"Nadzeya Dzemidovich, Alexander Gepperth",1 - University of Applied Sciences Fulda -Applied Computer Science Leipzigerstr. 123 36037 Fulda Germany,"This study is in the context of continual learning (CL) with DNNs. It compares several types of generators when performing replay, i.e., the generation of previously seen samples, to avoid catastrophic forgetting. Principal generators are generative adversarial networks (GANs) and variational autoencoders (VAEs). We evaluate these generators in various flavors (conditional, Wasserstein etc.) w.r.t. CL performance on a variety of CL tasks generated from the MNIST benchmark. Concerning generators, we find that VAEs are generally more compatible with CL than GANs. More generally, we find that replay-based CL faces counterintuitive issues for seemingly simple problems: first, that performance degrades more strongly as less information is added, and, furthermore, that performance degrades even when only known information is added.",Classification,https://doi.org/10.14428/esann/2022.ES2022-111,2022,100.0,"An empirical comparison of generators in replay-based continual learning This study is in the context of continual learning (CL) with DNNs. It compares several types of generators when performing replay, i.e., the generation of previously seen samples, to avoid catastrophic forgetting. Principal generators are generative adversarial networks (GANs) and variational autoencoders (VAEs). We evaluate these generators in various flavors (conditional, Wasserstein etc.) w.r.t. CL performance on a variety of CL tasks generated from the MNIST benchmark. Concerning generators, we find that VAEs are generally more compatible with CL than GANs. More generally, we find that replay-based CL faces counterintuitive issues for seemingly simple problems: first, that performance degrades more strongly as less information is added, and, furthermore, that performance degrades even when only known information is added."
A Fast and Simple Evolution Strategy with Covariance Matrix Estimation,Oliver Kramer,1 - Computational Intelligence Lab Department of Computer Science Carl-von-Ossietzky University of Oldenburg 26111 Oldenburg Germany,With the rise of A.I. methods the demand for efficient optimization methods that are easy to implement and use increases. This paper introduces a simple optimization method for numerical blackbox optimization. It proposes to apply covariance matrix estimation for the (1+1)-ES with Rechenberg's step size control. Experiments on a small set of benchmark functions demonstrate that the approach outperforms its isotropic variant allowing competitive convergence on problems with scaled and correlated dimensions.,Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-112,2022,100.0,A Fast and Simple Evolution Strategy with Covariance Matrix Estimation With the rise of A.I. methods the demand for efficient optimization methods that are easy to implement and use increases. This paper introduces a simple optimization method for numerical blackbox optimization. It proposes to apply covariance matrix estimation for the (1+1)-ES with Rechenberg's step size control. Experiments on a small set of benchmark functions demonstrate that the approach outperforms its isotropic variant allowing competitive convergence on problems with scaled and correlated dimensions.
Neural-Network-Based Estimation of Normal Distributions in Black-Box Optimization,"Jiří Tumpach, Jan Koza, Zbyněk Pitra, Martin Holeňa","1 - Charles University Prague Czech Republic
2 - Czech Technical University Prague Czech Republic
6 - Czech Academy of Sciences Prague Czech Republic","The paper presents a novel application of artificial neural networks (ANNs) in the context of surrogate models for black-box optimization, i.e. optimization of objective functions that are accessed through empirical evaluation. For active learning of surrogate models, a very important role plays learning of multidimensional normal distributions, for which Gaussian processes (GPs) have been traditionally used. On the other hand, the research reported in this paper evaluated the applicability of two ANN-based methods to this end: combining GPs with ANNs and learning normal distributions with evidential ANNs. After methods sketch, the paper brings their comparison on a large collection of data from surrogate-assisted black-box optimization. It shows that combining GPs using linear covariance functions with ANNs yields lower errors than the investigated methods of evidential learning.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-113,2022,60.49382716049383,"Neural-Network-Based Estimation of Normal Distributions in Black-Box Optimization The paper presents a novel application of artificial neural networks (ANNs) in the context of surrogate models for black-box optimization, i.e. optimization of objective functions that are accessed through empirical evaluation. For active learning of surrogate models, a very important role plays learning of multidimensional normal distributions, for which Gaussian processes (GPs) have been traditionally used. On the other hand, the research reported in this paper evaluated the applicability of two ANN-based methods to this end: combining GPs with ANNs and learning normal distributions with evidential ANNs. After methods sketch, the paper brings their comparison on a large collection of data from surrogate-assisted black-box optimization. It shows that combining GPs using linear covariance functions with ANNs yields lower errors than the investigated methods of evidential learning."
Predicting Test Execution Times with Asymmetric Random Forests,"Francisco Pereira, Hélio Silva, João Gomes, Javam Machado",1 - Department of Computer Science Federal University of Ceará Brazil,"Being able to estimate a test execution time is of fundamental importance when you need to prioritize tests. Furthermore, it is also important that an estimation algorithm do not underestimate the execution time, since time can be a hard constraint in many problems. If a test take longer than expected, some test that is planned to be executed in the future may have to be cancelled. Under such scenario, in this paper, we developed two simple variants of the Random Forest regression algorithm to predict test execution times in storage diagnostics tests. The proposed methods are compared to a baseline time estimation method (already available in a commercial product) and other machine learning based models. On the basis of our experiments we can state that the proposed variants achieved promising results when considering an asymmetric error metric. * This research was partially funded by Lenovo, as part of its R&D investment under Brazilian Informatics Law, and by CAPES under the grant #88887.609134/2021-00.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-114,2022,100.0,"Predicting Test Execution Times with Asymmetric Random Forests Being able to estimate a test execution time is of fundamental importance when you need to prioritize tests. Furthermore, it is also important that an estimation algorithm do not underestimate the execution time, since time can be a hard constraint in many problems. If a test take longer than expected, some test that is planned to be executed in the future may have to be cancelled. Under such scenario, in this paper, we developed two simple variants of the Random Forest regression algorithm to predict test execution times in storage diagnostics tests. The proposed methods are compared to a baseline time estimation method (already available in a commercial product) and other machine learning based models. On the basis of our experiments we can state that the proposed variants achieved promising results when considering an asymmetric error metric. * This research was partially funded by Lenovo, as part of its R&D investment under Brazilian Informatics Law, and by CAPES under the grant #88887.609134/2021-00."
"Price direction prediction in financial markets, using Random Forest and Adaboost","Mohammadmahdi Ghahramani, Fabio Aiolli",1 - Department of Mathematics -Padova Università di Padova Italy,"Experience shows trading in financial markets can be highly profitable. In this light, a great deal of effort has been devoted to using machine learning to predict market behavior. By using Random Forest and Adaboost models, we present a novel method for modeling candlestick patterns in financial markets. Our first contribution in the preprocessing part is to prepare data, develop additional features, and modify data. Our second contribution is introducing a novel prediction approach, named dataset ensembling to predict daily prices. Using three-year daily Bitcoin prices, the models are trained, tuned and then tested on one year of unseen data, showing the feasibility of the approach in terms of accuracy.",Classification,https://doi.org/10.14428/esann/2022.ES2022-115,2022,100.0,"Price direction prediction in financial markets, using Random Forest and Adaboost Experience shows trading in financial markets can be highly profitable. In this light, a great deal of effort has been devoted to using machine learning to predict market behavior. By using Random Forest and Adaboost models, we present a novel method for modeling candlestick patterns in financial markets. Our first contribution in the preprocessing part is to prepare data, develop additional features, and modify data. Our second contribution is introducing a novel prediction approach, named dataset ensembling to predict daily prices. Using three-year daily Bitcoin prices, the models are trained, tuned and then tested on one year of unseen data, showing the feasibility of the approach in terms of accuracy."
Wind power forecasting based on bagging extreme learning machine ensemble model,"Henrique Matheus, Molin Dal, Ribeiro, Sinvaldo Rodrigues Moreno, Ramon Gomes Da Silva, José Kleinubing Larcher, Cristiane Canton, Viviana Cocco Mariani, Leandro Dos, Santos Coelho","1 - Federal University of Technology -Parana (UTFPR). Industrial and Systems Engineering Graduate Program (PPGEPS) -Pato Branco PR Brazil
2 - Pontifical Catholic University of Parana (PUCPR). Mechanical Engineering Graduate Program (PPGEM) -Curitiba PR Brazil
3 - Pontifical Catholic University of Parana (PUCPR). Industrial and Systems Engineering Graduate Program (PPGEPS). -Curitiba PR Brazil
5 - -University Center of Pato Branco (UNIDEP) Pato Branco PR Brazil
7 - Department of Electrical Engineering. -Curitiba Federal University of Parana (UFPR) PR Brazil
10 - Coordenação de Aperfeiçoamento de Pessoal de Nível Superior Brasil","The wind energy forecast is an useful tool for wind farm production planning, and operation, facilitating decision making in terms of maintenance, electricity market clearing, and load sharing. This study proposes a cooperative ensemble learning model, using time series preprocessing, multi-objective optimization, and artificial intelligence to forecast wind energy generation in two wind farms in Brazil. Multi-objective optimization is employed to combine variational mode decompositionbased components of a model with bootstrap aggregation (bagging) and extreme learning machine models. Forecasting accuracy is evaluated through the root mean squared error, mean absolute error, mean absolute percentage error, and Diebold-Mariano hypothesis test. The empirical results suggest that proposed ensemble learning model achieved better forecasting performance than bootstrap stacking, machine learning, artificial neural networks, and statistical models, with values of approximately 12.76%, 25.25%, 31.91%, and 34.76%, respectively, in terms of root mean squared errors reduction for out-of-sample forecasting.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-117,2022,100.0,"Wind power forecasting based on bagging extreme learning machine ensemble model The wind energy forecast is an useful tool for wind farm production planning, and operation, facilitating decision making in terms of maintenance, electricity market clearing, and load sharing. This study proposes a cooperative ensemble learning model, using time series preprocessing, multi-objective optimization, and artificial intelligence to forecast wind energy generation in two wind farms in Brazil. Multi-objective optimization is employed to combine variational mode decompositionbased components of a model with bootstrap aggregation (bagging) and extreme learning machine models. Forecasting accuracy is evaluated through the root mean squared error, mean absolute error, mean absolute percentage error, and Diebold-Mariano hypothesis test. The empirical results suggest that proposed ensemble learning model achieved better forecasting performance than bootstrap stacking, machine learning, artificial neural networks, and statistical models, with values of approximately 12.76%, 25.25%, 31.91%, and 34.76%, respectively, in terms of root mean squared errors reduction for out-of-sample forecasting."
Dynamics-aware Representation Learning via Multivariate Time Series Transformers,"Michael Potter, Yıldız İlkay, Potter, Octavia Camps, Mario Sznaier","1 - Naval Surface Warfare Center Corona Norco CA USA
2 - BioSensics LLC Newton MA USA
3 - Electrical and Computer Engineering Northeastern University Boston MA USA","We propose a novel multivariate time series autoencoder, which produces interpretable linear-dynamical latent features that govern the predictions for several downstream tasks. To this end, we combine a transformer autoencoder with a dynamical atoms-based autoencoder to mimic Koopman operators in the latent space. We demonstrate that our approach significantly outperforms deep Koopman operator learning baselines for time series forecasting on chaotic systems such as the lorenz Attractor. Furthermore, the dynamics-aware representations, combined with a transformer classifier, lead to state-of-the-art classification accuracy on benchmark multivariate time series datasets. Our code is publicly available at https://github.com/mlpotter/T-DYAN-T.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-12,2022,100.0,"Dynamics-aware Representation Learning via Multivariate Time Series Transformers We propose a novel multivariate time series autoencoder, which produces interpretable linear-dynamical latent features that govern the predictions for several downstream tasks. To this end, we combine a transformer autoencoder with a dynamical atoms-based autoencoder to mimic Koopman operators in the latent space. We demonstrate that our approach significantly outperforms deep Koopman operator learning baselines for time series forecasting on chaotic systems such as the lorenz Attractor. Furthermore, the dynamics-aware representations, combined with a transformer classifier, lead to state-of-the-art classification accuracy on benchmark multivariate time series datasets. Our code is publicly available at https://github.com/mlpotter/T-DYAN-T."
Recurrent Restricted Kernel Machines for Time-series Forecasting,"Arun Pandey, Hannes De Meulemeester, Henri De Plaen, Bart De Moor, Johan Suykens",1 - ESAT-STADIUS KU Leuven Kasteelpark Arenberg 10 B-3001 Leuven Belgium,"In this paper, we propose a novel method for time-series modeling and forecasting. It is based on the temporal formulation of Restricted Kernel Machines leading to a dynamical equation in the latent-variables. Forecasting involves finding the next latent variable and then solving a pre-image problem to predict a new-point in the input space. Further, we benchmark our model on several standard data sets against other well-known time-series models. * European Research Council under the European Union's Horizon 2020 research and innovation programme: ERC Advanced Grants agreements E-DUALITY(No 787960) and Back to the Roots (No 885682). This paper reflects only the authors' views and the Union is not liable for any use that may be made of the contained information. Research Council KUL: Optimization frameworks for deep kernel machines C14/18/068; Research Fund (projects C16/15/059, C3/19/053, C24/18/022, C3/20/117, C3I-21-00316); Industrial Research Fund (Fellowships 13-0260, IOFm/16/004, IOFm/20/002) and several Leuven Research and Development bilateral industrial projects.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-120,2022,100.0,"Recurrent Restricted Kernel Machines for Time-series Forecasting In this paper, we propose a novel method for time-series modeling and forecasting. It is based on the temporal formulation of Restricted Kernel Machines leading to a dynamical equation in the latent-variables. Forecasting involves finding the next latent variable and then solving a pre-image problem to predict a new-point in the input space. Further, we benchmark our model on several standard data sets against other well-known time-series models. * European Research Council under the European Union's Horizon 2020 research and innovation programme: ERC Advanced Grants agreements E-DUALITY(No 787960) and Back to the Roots (No 885682). This paper reflects only the authors' views and the Union is not liable for any use that may be made of the contained information. Research Council KUL: Optimization frameworks for deep kernel machines C14/18/068; Research Fund (projects C16/15/059, C3/19/053, C24/18/022, C3/20/117, C3I-21-00316); Industrial Research Fund (Fellowships 13-0260, IOFm/16/004, IOFm/20/002) and several Leuven Research and Development bilateral industrial projects."
Do We Really Need a New Theory to Understand the Double-Descent?,"Luca Oneto, Sandro Ridella, Davide Anguita",1 - University of Genoa Via Opera Pia 11a 16145 Genova Italy,"This century saw an unprecedented increase of public and private investments in Artificial Intelligence (AI) and especially in Machine Learning (ML). This led to breakthroughs in their practical ability to solve complex real world problems impacting research and society at large. Instead, our ability to understand the fundamental mechanism behind these breakthroughs has slowed down because of their increased complexity. This questioned researchers about the necessity for a new theoretical framework able to help researchers catch up on this lag. One of the still not well understood mechanisms is the so called over-parametrization, namely the ability of certain models to increasing their generalization performance (reduce test error) when the number of parameters is above the interpolating threshold (zero training error), and the associated doubledescent curve. In this paper we will show that this phenomena can be better understood using both known theories, i.e., the algorithmic stability theory, and empirical evidence. 1 https://ai-watch.ec.europa.eu/publications/ai-watch-index-2021_en",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-13,2022,100.0,"Do We Really Need a New Theory to Understand the Double-Descent? This century saw an unprecedented increase of public and private investments in Artificial Intelligence (AI) and especially in Machine Learning (ML). This led to breakthroughs in their practical ability to solve complex real world problems impacting research and society at large. Instead, our ability to understand the fundamental mechanism behind these breakthroughs has slowed down because of their increased complexity. This questioned researchers about the necessity for a new theoretical framework able to help researchers catch up on this lag. One of the still not well understood mechanisms is the so called over-parametrization, namely the ability of certain models to increasing their generalization performance (reduce test error) when the number of parameters is above the interpolating threshold (zero training error), and the associated doubledescent curve. In this paper we will show that this phenomena can be better understood using both known theories, i.e., the algorithmic stability theory, and empirical evidence. 1 https://ai-watch.ec.europa.eu/publications/ai-watch-index-2021_en"
Graph-Induced Geodesics Approximation for Non-Euclidian K-Means,Hervé Frezza-Buet,"1 - Université de Lorraine, CentraleSupélec CNRS F-57000 Metz LORIA France","In this paper, an adaptation of the k-means algorithm and related methods to non-Euclidian topology is presented. The paper introduces a rationale for approximating the geodesics of that topology, as well as a learning rule that is robust to noise. The first results on artificial but very noisy distributions presented here are promising for further experimentation on real cases.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-14,2022,100.0,"Graph-Induced Geodesics Approximation for Non-Euclidian K-Means In this paper, an adaptation of the k-means algorithm and related methods to non-Euclidian topology is presented. The paper introduces a rationale for approximating the geodesics of that topology, as well as a learning rule that is robust to noise. The first results on artificial but very noisy distributions presented here are promising for further experimentation on real cases."
A Machine Learning Approach for School Dropout Prediction in Brazil,"João Gabriel, Corrêa Krüger, Jean Paul Barddal, Alceu De Souza, Britto Junior","1 - Graduate Program in Informatics (PPGIa) Pontifícia Universidade Católica do Paraná (PUCPR) R. Imaculada Conceição 1155, 80215-901 Curitiba PR Brazil","School dropout is a problem that impacts many socioeconomic aspects, including inequality. Dropout prediction algorithms can help remediate this problem, although several past attempts in the literature did so using small datasets. This paper brings forward an experimental approach of machine learning for school dropout prediction in Brazilian schools. The data used for this study was first retrieved from the academic systems of a group of Brazilian private schools, which was later enriched with socio-economic data extracted from governmental sources. Using the dataset to train different types of classifiers, we obtained up to 95.2% precision rates when predicting dropout at different year and educational stages, thus allowing schools to plan and apply retention strategies.",Classification,https://doi.org/10.14428/esann/2022.ES2022-15,2022,100.0,"A Machine Learning Approach for School Dropout Prediction in Brazil School dropout is a problem that impacts many socioeconomic aspects, including inequality. Dropout prediction algorithms can help remediate this problem, although several past attempts in the literature did so using small datasets. This paper brings forward an experimental approach of machine learning for school dropout prediction in Brazilian schools. The data used for this study was first retrieved from the academic systems of a group of Brazilian private schools, which was later enriched with socio-economic data extracted from governmental sources. Using the dataset to train different types of classifiers, we obtained up to 95.2% precision rates when predicting dropout at different year and educational stages, thus allowing schools to plan and apply retention strategies."
Minkowski logarithmic error: A physics-informed neural network approach for wind turbine lifetime assessment,"Francisco Santos, Pietro Antuono, Nymfa Noppe, Wout Weijtjens, Christof Devriendt",1 - Vrije Universiteit Brussel OWI-Lab Pleinlaan 2 1050 Brussels Belgium,"In this contribution we present a physics-informed neural network (PINN) approach for wind turbine fatigue estimation. This PINN incorporates physical information of the structure's fatigue profile in its loss function, referred to as Minkowski logarithmic error (MLE) -an extension of the log loss for any given L p space. The function is mathematically analysed and differentiated in order to better understand its behaviour. The results obtained using the MLE are favourably compared with previous efforts using the mean squared logarithmic error. Finally, the long-term error is evaluated based on the effect of p.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-16,2022,100.0,"Minkowski logarithmic error: A physics-informed neural network approach for wind turbine lifetime assessment In this contribution we present a physics-informed neural network (PINN) approach for wind turbine fatigue estimation. This PINN incorporates physical information of the structure's fatigue profile in its loss function, referred to as Minkowski logarithmic error (MLE) -an extension of the log loss for any given L p space. The function is mathematically analysed and differentiated in order to better understand its behaviour. The results obtained using the MLE are favourably compared with previous efforts using the mean squared logarithmic error. Finally, the long-term error is evaluated based on the effect of p."
A Kernel Based Multilinear SVD Approach for Multiple Sclerosis Profiles Classification,"Berardino Barile, Pooya Ashtari, Francoise Durand-Dubief, Frederik Maes, Dominique Sappey-Marinier, Sabine Van Huffel","1 - Department of Electrical Engineering (ESAT) UMR 5220 CNRS & U1294 INSERM) CREATIS ( Universite Claude Bernard Lyon 1, Division Stadius 2-KU Leuven, Leuven France, Belgium
4 - Service de Neurologie A Hospices Civils de Lyon France
6 - CERMEP Imagerie du Vivant Bron France","In machine learning, kernel data analysis represents a new approach to the study of neurological diseases such as Multiple Sclerosis (MS). In this work, a kernelization technique was combined with a tensor factorization method based on Multilinear Singular Value Decomposition (MLSVD) for MS profile classification. Our simple, yet effective, approach generates a meaningful feature embedding of multi-view data, allowing good classification performance. The results presented in this work define an interesting approach, given that only the anatomical T1-weighted image was used, which represents the most important modality in clinical applications.",Classification,https://doi.org/10.14428/esann/2022.ES2022-17,2022,100.0,"A Kernel Based Multilinear SVD Approach for Multiple Sclerosis Profiles Classification In machine learning, kernel data analysis represents a new approach to the study of neurological diseases such as Multiple Sclerosis (MS). In this work, a kernelization technique was combined with a tensor factorization method based on Multilinear Singular Value Decomposition (MLSVD) for MS profile classification. Our simple, yet effective, approach generates a meaningful feature embedding of multi-view data, allowing good classification performance. The results presented in this work define an interesting approach, given that only the anatomical T1-weighted image was used, which represents the most important modality in clinical applications."
Feature Compression Using Dynamic Switches in Multi-split CNNs,"Suresh Kumaraswamy, Alexey Ozerov, Ngoc Duong, Anne Lambert, François Schnitzler, Patrick Fontaine","1 - InterDigital, Inc. -Rennes France
3 - Ava -Paris France
5 - Lacroix Impulse -Rennes France","Convolutional neural networks (CNN) are often computationally demanding for mobile devices. Offloading some computation lowers this burden: initial convolutional layers are processed on a smartphone, the resulting high dimensional features are transmitted, and latter layers are processed in the cloud/edge/another device. To improve this process, we propose Dynamic Switch, a convolutional subnetwork enabling anywhere splittable CNNs with multirate feature compression using a single set of network parameters. We achieve 90% feature compression with at most 3% accuracy loss for MobileNet and MSDNet on ImageNet dataset and at most 4.58% on CIFAR100 dataset with MSDNet, ResNet-18, Mo-bileNet/MobileNetv2 and ShuffleNet/ShuffleNetv2.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-18,2022,100.0,"Feature Compression Using Dynamic Switches in Multi-split CNNs Convolutional neural networks (CNN) are often computationally demanding for mobile devices. Offloading some computation lowers this burden: initial convolutional layers are processed on a smartphone, the resulting high dimensional features are transmitted, and latter layers are processed in the cloud/edge/another device. To improve this process, we propose Dynamic Switch, a convolutional subnetwork enabling anywhere splittable CNNs with multirate feature compression using a single set of network parameters. We achieve 90% feature compression with at most 3% accuracy loss for MobileNet and MSDNet on ImageNet dataset and at most 4.58% on CIFAR100 dataset with MSDNet, ResNet-18, Mo-bileNet/MobileNetv2 and ShuffleNet/ShuffleNetv2."
Developmental Modular Reinforcement Learning,"Jianyong Xue, Frédéric Alexandre","1 - Inria Bordeaux Sud-Ouest -Talence France
2 - LaBRI -Universite de Bordeaux -Talence France
3 - Institut des Maladies Neurodégénératives -Bordeaux France","In this article, we propose a modular reinforcement learning (MRL) architecture that coordinates the competition and the cooperation between modules, and inspires, in a developmental approach, the generation of new modules in cases where new goals have been detected. We evaluate the effectiveness of our approach in a multiple-goal torus grid world. Results show that our approach has better performance than previous MRL methods in learning separate strategies for sub-goals, and reusing them for solving task-specific or unseen multi-goal problems, as well as maintaining the independence of the learning in each module.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-19,2022,100.0,"Developmental Modular Reinforcement Learning In this article, we propose a modular reinforcement learning (MRL) architecture that coordinates the competition and the cooperation between modules, and inspires, in a developmental approach, the generation of new modules in cases where new goals have been detected. We evaluate the effectiveness of our approach in a multiple-goal torus grid world. Results show that our approach has better performance than previous MRL methods in learning separate strategies for sub-goals, and reusing them for solving task-specific or unseen multi-goal problems, as well as maintaining the independence of the learning in each module."
Deep networks with ReLU activation functions can be smooth statistical models,Joseph Rynkiewicz,1 - Universté de Paris 1 -SAMM 90 rue de Tolbiac France,"Most Deep neural networks use ReLU activation functions. Since these functions are not differentiable in 0, we may believe that such models may have irregular behavior. In this paper, we will show that the issue is more in the data than in the model, and if the data are ""smooth"", the model will be differentiable in a suitable sense. We give a striking illustration of this fact with the example of adversarial attacks.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-20,2022,100.0,"Deep networks with ReLU activation functions can be smooth statistical models Most Deep neural networks use ReLU activation functions. Since these functions are not differentiable in 0, we may believe that such models may have irregular behavior. In this paper, we will show that the issue is more in the data than in the model, and if the data are ""smooth"", the model will be differentiable in a suitable sense. We give a striking illustration of this fact with the example of adversarial attacks."
Deep Convolutional Neural Networks with Sequentially Semiseparable Weight Matrices,"Matthias Kissel, Klaus Diepold",1 - Technical University of Munich -Chair of Data Processing Arcisstr 21 -80333 Munich Germany,"Modern Convolutional Neural Networks (CNNs) comprise millions of parameters. Therefore, the use of these networks requires high computing and memory resources. We propose to reduce these resource requirements by using structured matrices. For that, we replace weight matrices of the fully connected classifier part of several pre-trained CNNs by Sequentially Semiseparable (SSS) Matrices. By that, the number of parameters in these layers can be reduced drastically, as well as the number of operations required for evaluating the layer. We show that the combination of approximating the original weight matrices with SSS matrices followed by gradient-descent based training leads to the best prediction results (compared to just approximating or training from scratch).","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-21,2022,100.0,"Deep Convolutional Neural Networks with Sequentially Semiseparable Weight Matrices Modern Convolutional Neural Networks (CNNs) comprise millions of parameters. Therefore, the use of these networks requires high computing and memory resources. We propose to reduce these resource requirements by using structured matrices. For that, we replace weight matrices of the fully connected classifier part of several pre-trained CNNs by Sequentially Semiseparable (SSS) Matrices. By that, the number of parameters in these layers can be reduced drastically, as well as the number of operations required for evaluating the layer. We show that the combination of approximating the original weight matrices with SSS matrices followed by gradient-descent based training leads to the best prediction results (compared to just approximating or training from scratch)."
Interactive dual projections for gene expression analysis,"Ignacio Díaz, José Enguita, Diego García, Ana González, Abel Cuadrado, María Chiara, Nuria Valdés","1 - University of Oviedo -Dept of Electrical Engineering Edificio Torres Quevedo módulo 2, Campus de 33204 Gijón SPAIN
6 - Institute of Sanitary Research Principado de Asturias Hospital Universitario Central de Asturias 33011 Oviedo SPAIN
7 - -Department of Internal Medicine Section of Endocrinology Nutrition Hospital Universitario de Cabueñes 33204 Gijón SPAIN","We present an application of interactive dimensionality reduction (DR) for exploratory analysis of gene expression data that produces two lively updated projections, a sample map and a gene map, by rendering intermediate results of a t-SNE. The user can condition the projections ""on the fly"" by subsets of genes or samples, so updated views reveal coexpression patterns for different cancer types or gene groups. * This work is part of Grant PID2020-115401GB-I00 funded by MCIN/AEI/ 10.13039/501100011033. The results shown here are based upon data generated by the TCGA Research Network: https://www.cancer.gov/tcga.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-22,2022,100.0,"Interactive dual projections for gene expression analysis We present an application of interactive dimensionality reduction (DR) for exploratory analysis of gene expression data that produces two lively updated projections, a sample map and a gene map, by rendering intermediate results of a t-SNE. The user can condition the projections ""on the fly"" by subsets of genes or samples, so updated views reveal coexpression patterns for different cancer types or gene groups. * This work is part of Grant PID2020-115401GB-I00 funded by MCIN/AEI/ 10.13039/501100011033. The results shown here are based upon data generated by the TCGA Research Network: https://www.cancer.gov/tcga."
Anomaly detections on the oil system of a turbofan engine by a neural autoencoder,"Jean Coussirou, Thomas Vanaret, Jérôme Lacaille",1 - DataLab Safran Aircraft Engines Rond-Point René Ravaud 77550 Moissy-Cramayel France,"The turbofan engine uses oil to lubricate and cool its components. This extremely sensitive system can cause in-flight engine shutdowns in the event of a failure. This article presents the implementation of a fully automatic anomaly detection system capable of detecting both known phenomena and exceptional cases using weak signals. 
 Collected data CEOD data is made up of hundreds of measurements and calculations performed by the on-board computers and retrieved on the ground after each flight. To address the oil management system, we are only interested in 10 parameters, including 4 oil data parameters (quantity, temperature, main pressure, and pressure difference around the 287",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-24,2022,100.0,"Anomaly detections on the oil system of a turbofan engine by a neural autoencoder The turbofan engine uses oil to lubricate and cool its components. This extremely sensitive system can cause in-flight engine shutdowns in the event of a failure. This article presents the implementation of a fully automatic anomaly detection system capable of detecting both known phenomena and exceptional cases using weak signals. 
 Collected data CEOD data is made up of hundreds of measurements and calculations performed by the on-board computers and retrieved on the ground after each flight. To address the oil management system, we are only interested in 10 parameters, including 4 oil data parameters (quantity, temperature, main pressure, and pressure difference around the 287"
Reinforcement learning for constructing low density sign representations of Boolean functions,"Oytun Yapar, Erhan Oztop","1 - Computer Science Department Ozyegin University Istanbul Turkey
3 - SISReC OTRI Osaka University Osaka Japan","Boolean functions (BFs) can be uniquely represented with polynomial functions by representing True and False with ±1. With the 'sign-representation' framework, i.e., when the sign of the polynomials is used instead of the exact ±1, the representation is not unique anymore, and several measures of sign-representation become the target of research. One such measure is the polynomial threshold function density (PTF density), i.e., the minimum number of monomials that suffices to sign-represent a given BF. Several algorithms can find sign-representations with a low number of monomials; however, to find a representation with the minimum number of monomials possible is a combinatorial search problem. The recent success of reinforcement learning (RL) algorithms in solving combinatorial search problems poses the question of whether RL can perform well in finding sign-representations with a low number of monomials. To address this question, we focused on Deep Q-Networks (DQN) and explored its applicability to the sign-representation problem. To be concrete, we present our work on modeling RL agents for solving the signrepresentation problem and give our results on the application of DQN to BFs with a low number of variables (n = 4). Our results indicate that the trained DQN agent generalizes well and exploits intrinsic structure of BFs, such as their equivalence in terms of certain equivalence relations.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-25,2022,100.0,"Reinforcement learning for constructing low density sign representations of Boolean functions Boolean functions (BFs) can be uniquely represented with polynomial functions by representing True and False with ±1. With the 'sign-representation' framework, i.e., when the sign of the polynomials is used instead of the exact ±1, the representation is not unique anymore, and several measures of sign-representation become the target of research. One such measure is the polynomial threshold function density (PTF density), i.e., the minimum number of monomials that suffices to sign-represent a given BF. Several algorithms can find sign-representations with a low number of monomials; however, to find a representation with the minimum number of monomials possible is a combinatorial search problem. The recent success of reinforcement learning (RL) algorithms in solving combinatorial search problems poses the question of whether RL can perform well in finding sign-representations with a low number of monomials. To address this question, we focused on Deep Q-Networks (DQN) and explored its applicability to the sign-representation problem. To be concrete, we present our work on modeling RL agents for solving the signrepresentation problem and give our results on the application of DQN to BFs with a low number of variables (n = 4). Our results indicate that the trained DQN agent generalizes well and exploits intrinsic structure of BFs, such as their equivalence in terms of certain equivalence relations."
Supervised dimensionality reduction technique accounting for soft classes,"Sorina Mustatea, Michaël Aupetit, Jaakko Peltonen, Sylvain Lespinats, Denys Dutykh","1 - Univ. Grenoble Alpes INES Le Bourget du Lac F-73375 France
2 - LAMA Univ. Grenoble Alpes Univ. Savoie Mont Blanc CNRS 73000 Chambéry France
3 - Computing Research Institute Qatar
4 - HBKU Doha Qatar
5 - Faculty of Information Technology and Communication Sciences Tampere University Finland","Exploratory visual analysis of multidimensional labeled data is challenging. Multidimensional Projections for labeled data attempt to separate classes while preserving neighborhoods. In this work, we consider the case where instances are assigned multiple labels with probabilities or weights: for example, the output of a probabilistic classifier, fuzzy membership functions in fuzzy logic, or the share of votes for each candidate in an election. We propose a new technique to better preserve neighborhoods of such data. Our experiments show improved qualitative results compared to unsupervised, and existing dimensionality reduction techniques.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-26,2022,100.0,"Supervised dimensionality reduction technique accounting for soft classes Exploratory visual analysis of multidimensional labeled data is challenging. Multidimensional Projections for labeled data attempt to separate classes while preserving neighborhoods. In this work, we consider the case where instances are assigned multiple labels with probabilities or weights: for example, the output of a probabilistic classifier, fuzzy membership functions in fuzzy logic, or the share of votes for each candidate in an election. We propose a new technique to better preserve neighborhoods of such data. Our experiments show improved qualitative results compared to unsupervised, and existing dimensionality reduction techniques."
Improving Zorro Explanations for Sparse Observations with Dense Proxy Data,"Andreas Mazur, André Artelt, Barbara Hammer","1 - University of Cyprus
2 - Faculty of Technology Inspiration 1 CITEC -Cognitive Interaction Technology Bielefeld University 33619 Bielefeld Germany","Explanation methods are considered the most prominent way of achieving the ubiquitous requirement of transparency. Ideally, in order to be useful, explanations should be ""easy to understand"" -i.e. being of low complexity. In this work, we empirically study explanations generated by Zorro, an explanation method for Graph Neural Networks. In the context of a standard reinforcement learning scenario, we propose a methodology to improve the quality of generated explanations in case of sparse observations.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-27,2022,100.0,"Improving Zorro Explanations for Sparse Observations with Dense Proxy Data Explanation methods are considered the most prominent way of achieving the ubiquitous requirement of transparency. Ideally, in order to be useful, explanations should be ""easy to understand"" -i.e. being of low complexity. In this work, we empirically study explanations generated by Zorro, an explanation method for Graph Neural Networks. In the context of a standard reinforcement learning scenario, we propose a methodology to improve the quality of generated explanations in case of sparse observations."
Embedding-based next song recommendation for playlists,"Raphaël Romero, Tijl De Bie",1 - Department of Electrical Engineering Technologiepark-Zwijnaarde 126 Ghent University 9052 Gent Belgium,"In recent years, music storage and consumption has shifted massively to digital platforms, where large-scale libraries of songs are stored along with their metadata. As a byproduct of this transformation, music is increasingly being organized and accessed in the form of playlists. User-curated playlists have become massively available online, and the challenge of automatically generating playlists has gained popularity in the music information retrieval community. In this paper, we build on link prediction for graphs to propose a flexible music playlist generation method. We transform a playlist dataset into a weighted graph of songs and posit a Poisson model on the count of transitions between songs, where the rate is modulated by the euclidean distance between song embeddings. Our method yields prediction results superior to common deterministic baselines, suggesting that the learned embeddings can be used to derive a meaningful notion of song similarity.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-28,2022,100.0,"Embedding-based next song recommendation for playlists In recent years, music storage and consumption has shifted massively to digital platforms, where large-scale libraries of songs are stored along with their metadata. As a byproduct of this transformation, music is increasingly being organized and accessed in the form of playlists. User-curated playlists have become massively available online, and the challenge of automatically generating playlists has gained popularity in the music information retrieval community. In this paper, we build on link prediction for graphs to propose a flexible music playlist generation method. We transform a playlist dataset into a weighted graph of songs and posit a Poisson model on the count of transitions between songs, where the rate is modulated by the euclidean distance between song embeddings. Our method yields prediction results superior to common deterministic baselines, suggesting that the learned embeddings can be used to derive a meaningful notion of song similarity."
Anomaly detection and representation learning in an instrumented railway bridge,"Yacine Bel-Hadj, Francisco Santos, Wout Weijtjens","1 - Vrije Universiteit Brussel OWI-Lab Pleinlaan 2 1050 Brussels, Brussels Belgium","In this contribution, the strain measurements of a railway bridge are used for anomaly detection, in the context of Structural Health Monitoring (SHM). The methodology used is a combination of a sparse convolutional autoencoder (CSAE) and a Mahalanobis distance. Due to the lack of labeled anomalous data, a simulated fault is used to evaluate the performance of the algorithm. The proposed approach far outperforms the classical feature-based approach. Finally, the latent dimension of the autoencoder is studied and shown to be structured and representative of the underlying physics of the problem.",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-29,2022,100.0,"Anomaly detection and representation learning in an instrumented railway bridge In this contribution, the strain measurements of a railway bridge are used for anomaly detection, in the context of Structural Health Monitoring (SHM). The methodology used is a combination of a sparse convolutional autoencoder (CSAE) and a Mahalanobis distance. Due to the lack of labeled anomalous data, a simulated fault is used to evaluate the performance of the algorithm. The proposed approach far outperforms the classical feature-based approach. Finally, the latent dimension of the autoencoder is studied and shown to be structured and representative of the underlying physics of the problem."
Machine Learning and Information Theoretic Methods for Molecular Biology and Medicine,"T Villmann, J Almeida, J Lee, S Vinga","1 - University of Applied Sciences Mittweida
2 - Saxon Institute for Comp. Intelligence and Machine Learning Mittweida Germany
3 - Division of Cancer Epidemiology and Genetics National Institutes of Health National Cancer Institute Maryland USA
4 - UC Louvain IREC & ICTEAM Brussels & Louvain-la-Neuve -Belgium
5 - Universidade de Lisboa
6 - Dept. Computer Science and Engineering / Dept Instituto Superior Técnico Bioengineering Lisboa Portugal","A short introduction to the application of informationtheoretic and machine learning methods to biomolecular and medical data is provided as the motivating material that supports special session dedicated to this topic at ESANN 2022. In particular, we highlight current developments of foundation such as interpretability and model certainty. Further, we emphasize how theoretic models provide a natural framework to deal with heterogeneous and complex data structures as frequently occurring in biomedical research.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-3,2022,93.92265193370166,"Machine Learning and Information Theoretic Methods for Molecular Biology and Medicine A short introduction to the application of informationtheoretic and machine learning methods to biomolecular and medical data is provided as the motivating material that supports special session dedicated to this topic at ESANN 2022. In particular, we highlight current developments of foundation such as interpretability and model certainty. Further, we emphasize how theoretic models provide a natural framework to deal with heterogeneous and complex data structures as frequently occurring in biomedical research."
Deep latent position model for node clustering in graphs,"Dingge Liang, Marco Corneli, Charles Bouveyron, Pierre Latouche","1 - Laboratoire J.A.Dieudonné Université Côte d'Azur INRIA CNRS France
4 - Laboratoire MAP5 UMR 8145 Université Paris Cité CNRS France","With the significant increase of interactions between individuals through numeric means, the clustering of vertex in graphs has become a fundamental approach for analysing large and complex networks. We propose here the deep latent position model (DeepLPM), an end-to-end clustering approach which combines the widely used latent position model (LPM) for network analysis with a graph convolutional network (GCN) encoding strategy. Thus, DeepLPM can automatically assign each node to its group without using any additional algorithms and better preserves the network topology. Numerical experiments on simulated data and an application on the Cora citation network are conducted to demonstrate its effectiveness and interest in performing unsupervised clustering tasks.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-30,2022,100.0,"Deep latent position model for node clustering in graphs With the significant increase of interactions between individuals through numeric means, the clustering of vertex in graphs has become a fundamental approach for analysing large and complex networks. We propose here the deep latent position model (DeepLPM), an end-to-end clustering approach which combines the widely used latent position model (LPM) for network analysis with a graph convolutional network (GCN) encoding strategy. Thus, DeepLPM can automatically assign each node to its group without using any additional algorithms and better preserves the network topology. Numerical experiments on simulated data and an application on the Cora citation network are conducted to demonstrate its effectiveness and interest in performing unsupervised clustering tasks."
Interactive visual analytics for medical data: application to COVID-19 clinical information during the first wave,"José Enguita, Diego García, María Chiara, Nuria Valdés, Ana González, Abel Cuadrado, Ignacio Díaz","1 - University of Oviedo -Dept of Electrical Engineering Edificio Torres Quevedo módulo 2, Campus de 33204 Gijón SPAIN
3 - Institute of Sanitary Research Principado de Asturias Hospital Universitario Central de Asturias 33011 Oviedo SPAIN
4 - -Department of Internal Medicine Section of Endocrinology Nutrition Hospital Universitario de Cabueñes 33204 Gijón SPAIN","Biomedical data recorded as a result of clinical practice are often multi-domain -involving lab measurements, medication, patient attributes, logistic information-, and also highly unstructured, with high rates of missing data and asynchronously sampled measurements. In this scenario, we need tools capable of providing a broad picture prior to more detailed analyses. We present here a visual analytics approach that uses the morphing projections technique to combine the visualization of a t-SNE projection of clinical time series, with views of other clinical or patient's information. The proposed approach is demonstrated on an application case study of COVID-19 clinical information taken during the first wave.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-31,2022,100.0,"Interactive visual analytics for medical data: application to COVID-19 clinical information during the first wave Biomedical data recorded as a result of clinical practice are often multi-domain -involving lab measurements, medication, patient attributes, logistic information-, and also highly unstructured, with high rates of missing data and asynchronously sampled measurements. In this scenario, we need tools capable of providing a broad picture prior to more detailed analyses. We present here a visual analytics approach that uses the morphing projections technique to combine the visualization of a t-SNE projection of clinical time series, with views of other clinical or patient's information. The proposed approach is demonstrated on an application case study of COVID-19 clinical information taken during the first wave."
Model Agnostic Local Explanations of Reject,"André Artelt, Roel Visser, Barbara Hammer","1 - University of Cyprus
2 - Faculty of Technology Inspiration 1 CITEC -Cognitive Interaction Technology Bielefeld University 33619 Bielefeld Germany","The application of machine learning based decision making systems in safety critical areas requires reliable high certainty predictions. Reject options are a common way of ensuring a sufficiently high certainty of predictions. While being able to reject uncertain samples is important, it is also of importance to be able to explain why a particular sample was rejected. However, explaining reject options is still an open problem. We propose a model-agnostic method for locally explaining reject options by means of interpretable models and counterfactual explanations.",Classification,https://doi.org/10.14428/esann/2022.ES2022-34,2022,100.0,"Model Agnostic Local Explanations of Reject The application of machine learning based decision making systems in safety critical areas requires reliable high certainty predictions. Reject options are a common way of ensuring a sufficiently high certainty of predictions. While being able to reject uncertain samples is important, it is also of importance to be able to explain why a particular sample was rejected. However, explaining reject options is still an open problem. We propose a model-agnostic method for locally explaining reject options by means of interpretable models and counterfactual explanations."
Deep Semantic Segmentation in Skin Detection,"Daniela Cuza, Andrea Loreggia, Alessandra Lumini, Loris Nanni","1 - University of Padova -Dept of Information Engineering Padova Italy
2 - Dept of Information Engineering Brescia University of Brescia Italy
3 - Dept of Computer Science and Engineering Bologna University of Bologna Italy","Deep semantic segmentation is a task that identifies objects and their boundaries in images, to do that a classification task is performed at the pixel level to tag whether a pixel belongs to an object. In skin detection, areas of images are classified as skin or non-skin regions. In this work, we report a short survey of the recent literature covering the task to help researchers in selecting the most suitable method for their application and to expand the knowledge about the available datasets for this topic. A compact empirical evaluation comparing recent models and a new ensemble model is reported.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-35,2022,100.0,"Deep Semantic Segmentation in Skin Detection Deep semantic segmentation is a task that identifies objects and their boundaries in images, to do that a classification task is performed at the pixel level to tag whether a pixel belongs to an object. In skin detection, areas of images are classified as skin or non-skin regions. In this work, we report a short survey of the recent literature covering the task to help researchers in selecting the most suitable method for their application and to expand the knowledge about the available datasets for this topic. A compact empirical evaluation comparing recent models and a new ensemble model is reported."
Efficient classification learning of biochemical structured data by means of relevance weighting for sensoric response features,"Sophie Katrin, Marika Bohnsack, Julius Kaden, Thomas Voigt, Villmann","1 - University of Applied Sciences Mittweida
2 - Saxon Institute for Computational Intelligence and Machine Learning Mittweida Germany","We present an approach for generating vectorial representations of graphs for machine learning applications based on a sensoric response principle and multiple graph kernels. The sensor perspective reduces the graph kernel computations significantly. Thus, multiple kernel (relevance) learning can be realized using the interpretable generalized matrix learning vector quantization (GMLVQ) classifier. Results obtained in small molecule classification serve as proof of concept. * K.S.B and M.K. are supported by a grant of the European Social Fund (ESF).",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-36,2022,100.0,"Efficient classification learning of biochemical structured data by means of relevance weighting for sensoric response features We present an approach for generating vectorial representations of graphs for machine learning applications based on a sensoric response principle and multiple graph kernels. The sensor perspective reduces the graph kernel computations significantly. Thus, multiple kernel (relevance) learning can be realized using the interpretable generalized matrix learning vector quantization (GMLVQ) classifier. Results obtained in small molecule classification serve as proof of concept. * K.S.B and M.K. are supported by a grant of the European Social Fund (ESF)."
Continual Learning for Human State Monitoring,"Federico Matteoni, Andrea Cossu, Claudio Gallicchio, Vincenzo Lomonaco, Davide Bacciu","1 - University of Pisa -Computer Science Department Largo B. Pontecorvo 3 -56127 Pisa Italy
3 - Scuola Normale Superiore Piazza dei Cavalieri 7 -56126 Pisa Italy","Continual Learning (CL) on time series data represents a promising but under-studied avenue for real-world applications. We propose two new CL benchmarks for Human State Monitoring. We carefully designed the benchmarks to mirror real-world environments in which new subjects are continuously added. We conducted an empirical evaluation to assess the ability of popular CL strategies to mitigate forgetting in our benchmarks. Our results show that, possibly due to the domainincremental properties of our benchmarks, forgetting can be easily tackled even with a simple finetuning and that existing strategies struggle in accumulating knowledge over a fixed, held-out, test subject.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-38,2022,100.0,"Continual Learning for Human State Monitoring Continual Learning (CL) on time series data represents a promising but under-studied avenue for real-world applications. We propose two new CL benchmarks for Human State Monitoring. We carefully designed the benchmarks to mirror real-world environments in which new subjects are continuously added. We conducted an empirical evaluation to assess the ability of popular CL strategies to mitigate forgetting in our benchmarks. Our results show that, possibly due to the domainincremental properties of our benchmarks, forgetting can be easily tackled even with a simple finetuning and that existing strategies struggle in accumulating knowledge over a fixed, held-out, test subject."
Detection and Localization of GAN Manipulated Multi-spectral Satellite Images,"Lydia Abady, Giovanna Dimitri, Mauro Barni",1 - Department of Information Engineering and Mathematics Siena University of Siena Italy,"Owing to their realistic features and continuous improvements, images manipulated by Generative Adversarial Network (GAN) have become a compelling research topic. In this paper, we apply detection and localization to GAN manipulated images by means of models, based on EfficientNet-B4 architectures. Detection is tested on multiple generated multi-spectral datasets from several world regions and different GAN architectures, whereas localization is tested on an inpainted images dataset of sizes 2048×2048×13. The results obtained for both detection and localization are shown to be promising.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-39,2022,100.0,"Detection and Localization of GAN Manipulated Multi-spectral Satellite Images Owing to their realistic features and continuous improvements, images manipulated by Generative Adversarial Network (GAN) have become a compelling research topic. In this paper, we apply detection and localization to GAN manipulated images by means of models, based on EfficientNet-B4 architectures. Detection is tested on multiple generated multi-spectral datasets from several world regions and different GAN architectures, whereas localization is tested on an inpainted images dataset of sizes 2048×2048×13. The results obtained for both detection and localization are shown to be promising."
Beyond Supervised Continual Learning: a Review,"Benedikt Bagus, Alexander Gepperth, Timothée Lesort","1 - Department of Computer Science Leipzigerstraße 123 University of Applied Sciences Fulda 36037 Fulda Germany
3 - Montréal University (UdeM) Mila 6666 St-Urbain Street Montréal QC Canada","Continual Learning (CL, sometimes also termed incremental learning) is a flavor of machine learning where the usual assumption of stationary data distribution is relaxed or omitted. When naively applying, e.g., DNNs in CL problems, changes in the data distribution can cause the so-called catastrophic forgetting (CF) effect: an abrupt loss of previous knowledge. Although many significant contributions to enabling CL have been made in recent years, most works address supervised (classification) problems. This article reviews literature that study CL in other settings, such as learning with reduced supervision, fully unsupervised learning, and reinforcement learning. Besides proposing a simple schema for classifying CL approaches w.r.t. their level of autonomy and supervision, we discuss the specific challenges associated with each setting and the potential contributions to the field of CL in general. 
 Framework and Goals of Continual Learning Continual learning (CL) is a machine learning sub-field that studies learning under time-varying data distributions. This relaxes one of the fundamental assumptions of statistical learning theory ([1]), which states that the data follows 67",Unsupervised nonlinear dimensionality reduction,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-134.pdf,2022,59.04761904761905,"Beyond Supervised Continual Learning: a Review Continual Learning (CL, sometimes also termed incremental learning) is a flavor of machine learning where the usual assumption of stationary data distribution is relaxed or omitted. When naively applying, e.g., DNNs in CL problems, changes in the data distribution can cause the so-called catastrophic forgetting (CF) effect: an abrupt loss of previous knowledge. Although many significant contributions to enabling CL have been made in recent years, most works address supervised (classification) problems. This article reviews literature that study CL in other settings, such as learning with reduced supervision, fully unsupervised learning, and reinforcement learning. Besides proposing a simple schema for classifying CL approaches w.r.t. their level of autonomy and supervision, we discuss the specific challenges associated with each setting and the potential contributions to the field of CL in general. 
 Framework and Goals of Continual Learning Continual learning (CL) is a machine learning sub-field that studies learning under time-varying data distributions. This relaxes one of the fundamental assumptions of statistical learning theory ([1]), which states that the data follows 67"
Deep learning approaches for mice glomeruli segmentation,"Duccio Meconcelli, Simone Bonechi, Giovanna Dimitri","1 - DIISM Department of Information Engineering and Mathematics University of Siena Siena Italy
2 - DISPOC, Department of Social, Political and Cognitive Sciences University of Siena Siena Italy","Deep learning (DL) is widely applied in biomedical image processing nowadays. In this paper, we propose the use of DL architectures for glomerulus segmentation in histopathological images of mouse kidneys. Indeed, in humans, the analysis of the glomeruli is fundamental to decide on the transplantability of the organ. However, no datasets with human samples are publicly available. Therefore, obtaining good segmentation performance on the kidneys of mice could be the first step for a transfer learning approach to humans. We compared the use of two well-known architectures for image segmentation, namely MobileNet and DeepLab V2. Both models showed very promising results.",Image processing and transfer learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-169.pdf,2022,74.50980392156863,"Deep learning approaches for mice glomeruli segmentation Deep learning (DL) is widely applied in biomedical image processing nowadays. In this paper, we propose the use of DL architectures for glomerulus segmentation in histopathological images of mouse kidneys. Indeed, in humans, the analysis of the glomeruli is fundamental to decide on the transplantability of the organ. However, no datasets with human samples are publicly available. Therefore, obtaining good segmentation performance on the kidneys of mice could be the first step for a transfer learning approach to humans. We compared the use of two well-known architectures for image segmentation, namely MobileNet and DeepLab V2. Both models showed very promising results."
Real-time capable Ensemble Estimation for 2D Object Detection,"Lukas Enderich, Simon Heming",1 - Robert Bosch GmbH -Computer Vision Research Robert-Bosch-Straße 200 31139 Hildesheim Germany,"Deep neural networks tend to make overconfident predictions. Although ensemble methods improve the predictive performance by producing better calibrated confidences, they are computationally expensive. Thus, we propose a real-time capable ensemble method for object detection that significantly improves the performance with only a minor increase in runtime. Our method diversifies the prediction of the class probabilities on the anchor space using multiple classification heads. A regularization further increases the diversity of the heads, making ensemble distillation unnecessary. On the KITTI benchmark dataset, our approach increases the mean average precision of an SSD based network from 0.58 to 0.71. 
 Introduction Deep neural networks (DNNs) are state-of-the-art in many machine learning challenges, outperforming classical methods in computer vision, object detection, and speech recognition  [1, 2] . However, there are still a number of problems when DNNs are used in real-time and safety-critical systems. This includes, for instance, their ability to generalize, as DNNs poorly quantify uncertainty and tend to make overconfident predictions  [3, 4] . Ensemble methods improve the predictive performance of DNNs, providing better calibrated confidences by averaging over the ensemble output  [4] . Ensemble methods can for example be based on a certain number of independently trained networks [5] or a monte-carlo dropout model  [6] . However, these methods significantly increase the computational complexity during inference since multiple forward passes need to be calculated. Therefore, recent work has focused on distilling both the diversity and the knowledge of an ensemble into a single network  [3] . The model used in [3] consists of one network body and multiple networks heads. Thus, it is trained to approximate the predictions of each ensemble member with its corresponding network head. Since the body is shared among all heads, the computational complexity is significantly lower compared to the distilled ensemble. However, the setup used in [3] only works for image classification. Furthermore, training and distilling an ensemble is time-consuming, especially for more complex tasks such as object detection. Therefore, we transfer the multi-head approach to object detection by making two major contributions: We show how to efficiently diversify an anchor-based object detector by using multiple classification heads. In this way, different class probabilities are predicted for each anchor that can be averaged during inference.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-41,2022,100.0,"Real-time capable Ensemble Estimation for 2D Object Detection Deep neural networks tend to make overconfident predictions. Although ensemble methods improve the predictive performance by producing better calibrated confidences, they are computationally expensive. Thus, we propose a real-time capable ensemble method for object detection that significantly improves the performance with only a minor increase in runtime. Our method diversifies the prediction of the class probabilities on the anchor space using multiple classification heads. A regularization further increases the diversity of the heads, making ensemble distillation unnecessary. On the KITTI benchmark dataset, our approach increases the mean average precision of an SSD based network from 0.58 to 0.71. 
 Introduction Deep neural networks (DNNs) are state-of-the-art in many machine learning challenges, outperforming classical methods in computer vision, object detection, and speech recognition  [1, 2] . However, there are still a number of problems when DNNs are used in real-time and safety-critical systems. This includes, for instance, their ability to generalize, as DNNs poorly quantify uncertainty and tend to make overconfident predictions  [3, 4] . Ensemble methods improve the predictive performance of DNNs, providing better calibrated confidences by averaging over the ensemble output  [4] . Ensemble methods can for example be based on a certain number of independently trained networks [5] or a monte-carlo dropout model  [6] . However, these methods significantly increase the computational complexity during inference since multiple forward passes need to be calculated. Therefore, recent work has focused on distilling both the diversity and the knowledge of an ensemble into a single network  [3] . The model used in [3] consists of one network body and multiple networks heads. Thus, it is trained to approximate the predictions of each ensemble member with its corresponding network head. Since the body is shared among all heads, the computational complexity is significantly lower compared to the distilled ensemble. However, the setup used in [3] only works for image classification. Furthermore, training and distilling an ensemble is time-consuming, especially for more complex tasks such as object detection. Therefore, we transfer the multi-head approach to object detection by making two major contributions: We show how to efficiently diversify an anchor-based object detector by using multiple classification heads. In this way, different class probabilities are predicted for each anchor that can be averaged during inference."
The role of feature selection in personalized recommender systems,"Roger Bagué-Masanés, Verónica Bolón-Canedo, Beatriz Remeseiro","1 - CITIC Universidade da Coruña, A Coruña Spain
3 - Universidad de Oviedo Gijón Spain","Recommender systems suggest products to users, based on their popularity or the users' preferences. This paper proposes a hybrid personalized recommender system based on users' tastes and also on information available about items. We used a dataset downloaded from Tri-pAdvisor, which contains some information from restaurants (items), such as price range or special diets. Feature selection techniques are employed to analyze the impact that each variable has on personalized recommendations, allowing us to understand not only the process underlying the recommendation to favor the transparency of the system, but also what users value the most when choosing a restaurant.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-43,2022,100.0,"The role of feature selection in personalized recommender systems Recommender systems suggest products to users, based on their popularity or the users' preferences. This paper proposes a hybrid personalized recommender system based on users' tastes and also on information available about items. We used a dataset downloaded from Tri-pAdvisor, which contains some information from restaurants (items), such as price range or special diets. Feature selection techniques are employed to analyze the impact that each variable has on personalized recommendations, allowing us to understand not only the process underlying the recommendation to favor the transparency of the system, but also what users value the most when choosing a restaurant."
A Deep Learning approach for oocytes segmentation and analysis,"Paolo Andreini, Niccolò Pancino, Filippo Costanti, Gabriele Eusepi, Barbara Corradini","1 - Department of Information Engineering and Mathematics University of Siena Siena Italy
2 - Department of Information Engineering University of Florence Florence Italy
4 - SILOG Sistemi Logici s.r.l Siena Italy","Medical Assisted Procreation (MAP) has seen a sharp increase in demand over the past decade, due to a variety of reasons, including genetic factors, health conditions altered by stress and pollution, as well as delayed pregnancy and age-related loss of fertility. The success of MAP techniques is strongly correlated to the dexterity of a human operator, who is asked to classify and select healthy oocytes to fertilize and return to the uterus. This work describes a deep learning approach to the segmentation of oocyte images, to support operators in their selection, to improve the success probability of MAP.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-44,2022,100.0,"A Deep Learning approach for oocytes segmentation and analysis Medical Assisted Procreation (MAP) has seen a sharp increase in demand over the past decade, due to a variety of reasons, including genetic factors, health conditions altered by stress and pollution, as well as delayed pregnancy and age-related loss of fertility. The success of MAP techniques is strongly correlated to the dexterity of a human operator, who is asked to classify and select healthy oocytes to fertilize and return to the uterus. This work describes a deep learning approach to the segmentation of oocyte images, to support operators in their selection, to improve the success probability of MAP."
Neural Architecture Search for Sentence Classification with BERT,"Philip Kenneweg, Sarah Schröder, Barbara Hammer",1 - Faculty of Technology Inspiration 1 Bielefeld University 33615 Bielefeld Germany,"Pre training of language models on large text corpora is common practice in Natural Language Processing. Following, fine tuning of these models is performed to achieve the best results on a variety of tasks. In this paper we question the common practice of only adding a single output layer as a classification head on top of the network. We perform an AutoML search to find architectures that outperform the current single layer at only a small compute cost. We validate our classification architecture on a variety of NLP benchmarks from the GLUE dataset. The source code is open-source and free (MIT licensed) software, available at https://github.com/TheMody/NASforSentenceEmbeddingHeads. * We gratefully acknowledge funding by the BMWi (01MK20007E), from the MKW NRW in the project Bias aus KI-Modellen and by the BMBF (01IS19080 A).","Natural language processing, and recommender systems",https://doi.org/10.14428/esann/2022.ES2022-45,2022,100.0,"Neural Architecture Search for Sentence Classification with BERT Pre training of language models on large text corpora is common practice in Natural Language Processing. Following, fine tuning of these models is performed to achieve the best results on a variety of tasks. In this paper we question the common practice of only adding a single output layer as a classification head on top of the network. We perform an AutoML search to find architectures that outperform the current single layer at only a small compute cost. We validate our classification architecture on a variety of NLP benchmarks from the GLUE dataset. The source code is open-source and free (MIT licensed) software, available at https://github.com/TheMody/NASforSentenceEmbeddingHeads. * We gratefully acknowledge funding by the BMWi (01MK20007E), from the MKW NRW in the project Bias aus KI-Modellen and by the BMBF (01IS19080 A)."
A weakly supervised approach to skin lesion segmentation,Simone Bonechi,"1 - Department of Social, Political and Cognitive Sciences University of Siena Siena Italy
2 - Department of Information Engineering and Mathematics University of Siena Siena Italy","Early detection of skin cancers greatly increases patients' chances of recovery. To support dermatologists in this diagnosis, many decision support systems based on Convolutional Neural Networks have recently been proposed to segment the lesion and classify it. The use of the information coming from the segmentation, as an additional input to the classifier, proved to be fundamental to increase its performance and, in fact, the shape of the lesion is of diagnostic importance unanimously recognized by clinicians. However, in the ISIC database, the public reference dataset that collects a huge number of skin lesion images, all samples are labeled for classification but only a very small fraction of them are also labeled for segmentation. To overcome this limitation, the present paper proposes a weakly supervised approach to extract the segmentation label maps of approximately 43,000 ISIC images, used to train a segmentation network, with very promising performance.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-46,2022,100.0,"A weakly supervised approach to skin lesion segmentation Early detection of skin cancers greatly increases patients' chances of recovery. To support dermatologists in this diagnosis, many decision support systems based on Convolutional Neural Networks have recently been proposed to segment the lesion and classify it. The use of the information coming from the segmentation, as an additional input to the classifier, proved to be fundamental to increase its performance and, in fact, the shape of the lesion is of diagnostic importance unanimously recognized by clinicians. However, in the ISIC database, the public reference dataset that collects a huge number of skin lesion images, all samples are labeled for classification but only a very small fraction of them are also labeled for segmentation. To overcome this limitation, the present paper proposes a weakly supervised approach to extract the segmentation label maps of approximately 43,000 ISIC images, used to train a segmentation network, with very promising performance."
Orthogonality in Additive Reservoir Computing,"Andrea Ceni, Claudio Gallicchio",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"Reservoir computing (RC) is a state-of-the-art approach for efficient training in temporal domains. In this paper, we explore new RC architectures that generalise the popular leaky echo state network model (leaky-ESN) introducing an additive orthogonal term outside the nonlinear part of the ESN equation. We investigate the benefits of employing orthogonal matrices in ESNs both inside the nonlinearity and outside of it. We show empirically how to boost the memory capacity towards the theoretical maximum value while still preserving the power of nonlinear computations. Ergo, we optimise the compromise between computing with memory and computing with nonlinearity. The proposed model demonstrates to outperform both leaky-ESN and orthogonal reservoir ESN models on tasks requiring nonlinear computations with memory.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-7.pdf,2022,70.12987012987013,"Orthogonality in Additive Reservoir Computing Reservoir computing (RC) is a state-of-the-art approach for efficient training in temporal domains. In this paper, we explore new RC architectures that generalise the popular leaky echo state network model (leaky-ESN) introducing an additive orthogonal term outside the nonlinear part of the ESN equation. We investigate the benefits of employing orthogonal matrices in ESNs both inside the nonlinearity and outside of it. We show empirically how to boost the memory capacity towards the theoretical maximum value while still preserving the power of nonlinear computations. Ergo, we optimise the compromise between computing with memory and computing with nonlinearity. The proposed model demonstrates to outperform both leaky-ESN and orthogonal reservoir ESN models on tasks requiring nonlinear computations with memory."
Machine learning for automated quality control in injection moulding manufacturing,"Steven Michiels, Cédric De Schryver, Lynn Houthuys, Frederik Vogeler, Frederik Desplentere","1 - Thomas More University of Applied Sciences Belgium
2 - Dept. of Smart Technology & Design KU Leuven -University of Leuven Campus De Nayer 2 Belgium
3 - Dept. of Materials Engineering ProPoliS Research Group Campus Bruges","Machine learning (ML) may improve and automate quality control (QC) in injection moulding manufacturing. As the labelling of extensive, real-world process data is costly, however, the use of simulated process data may offer a first step towards a successful implementation. In this study, simulated data was used to develop a predictive model for the product quality of an injection moulded sorting container. The achieved accuracy, specificity and sensitivity on the test set was 99.4%, 99.7% and 94.7%, respectively. This study thus shows the potential of ML towards automated QC in injection moulding and encourages the extension to ML models trained on real-world data. The research leading to these results has received funding from VLAIO (TETRA project 'AI4IM ', project number HBC.2020', project number HBC. .2556)   )",Classification,https://doi.org/10.14428/esann/2022.ES2022-48,2022,100.0,"Machine learning for automated quality control in injection moulding manufacturing Machine learning (ML) may improve and automate quality control (QC) in injection moulding manufacturing. As the labelling of extensive, real-world process data is costly, however, the use of simulated process data may offer a first step towards a successful implementation. In this study, simulated data was used to develop a predictive model for the product quality of an injection moulded sorting container. The achieved accuracy, specificity and sensitivity on the test set was 99.4%, 99.7% and 94.7%, respectively. This study thus shows the potential of ML towards automated QC in injection moulding and encourages the extension to ML models trained on real-world data. The research leading to these results has received funding from VLAIO (TETRA project 'AI4IM ', project number HBC.2020', project number HBC. .2556)   )"
Data stream generation through real concept's interpolation,"Joanna Komorniczak, Pawel Ksieniewicz",1 - Department of Systems and Computer Networks Wroclaw University of Science and Technology Wroclaw Poland,Among the recently published works in the field of data stream analysis -both in the context of classification task and concept drift detection -the deficit of real-world data streams is a recurring problem. This article proposes a method for generating data streams with given parameters based on real-world static data. The method uses onedimensional interpolation to generate sudden or incremental concept drifts. The generated streams were subjected to an exemplary analysis in the concept drift detection task with a detector ensemble. The method can potentially contribute to the development of methods focused on data stream processing.,Concept drift,https://doi.org/10.14428/esann/2022.ES2022-49,2022,100.0,Data stream generation through real concept's interpolation Among the recently published works in the field of data stream analysis -both in the context of classification task and concept drift detection -the deficit of real-world data streams is a recurring problem. This article proposes a method for generating data streams with given parameters based on real-world static data. The method uses onedimensional interpolation to generate sudden or incremental concept drifts. The generated streams were subjected to an exemplary analysis in the concept drift detection task with a detector ensemble. The method can potentially contribute to the development of methods focused on data stream processing.
Deep Semantic Segmentation Models in Computer Vision,"Paolo Andreini, Giovanna Dimitri",1 - DIISM -Universitá degli Studi di Siena Via Roma 56 Siena Italy,"Recently, deep learning models have had a huge impact on computer vision applications, in particular in semantic segmentation, in which many challenges are open. As an example, the lack of large annotated datasets implies the need for new semi-supervised and unsupervised techniques. This problem is particularly relevant in the medical field due to privacy issues and high costs of image tagging by medical experts. The aim of this tutorial overview paper is to provide a short overview of the recent results and advances regarding deep learning applications in computer vision particularly for what concerns semantic segmentation.",Deep Semantic Segmentation Models in Computer Vision,https://doi.org/10.14428/esann/2022.ES2022-5,2022,100.0,"Deep Semantic Segmentation Models in Computer Vision Recently, deep learning models have had a huge impact on computer vision applications, in particular in semantic segmentation, in which many challenges are open. As an example, the lack of large annotated datasets implies the need for new semi-supervised and unsupervised techniques. This problem is particularly relevant in the medical field due to privacy issues and high costs of image tagging by medical experts. The aim of this tutorial overview paper is to provide a short overview of the recent results and advances regarding deep learning applications in computer vision particularly for what concerns semantic segmentation."
Towards Better Transition Modeling in Recurrent Neural Networks: the Case of Sign Language Tokenization,"Pierre Poitier, Jérôme Fink, Benoît Frénay",1 - Faculty of Computer Science -PReCISE rue Grandgagnage 21 University of Namur -NaDI B-5000 Namur Belgium,"Recurrent neural networks can be used to segment sequences such as videos, where transitions can be challenging to detect. This paper benchmarks strategies to better model the transition between states. The specific task of SL video tokenization is chosen for the evaluation, as it remains challenging. Tokenizers are the cornerstone of natural language processing pipelines. There exist powerful tokenizers for text data, but sign language (SL) video tokenizers are still under development. Benchmarked strategies prove to be useful to improve SL videos tokenization, but there is still room for improvement to better model state transitions.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-50,2022,100.0,"Towards Better Transition Modeling in Recurrent Neural Networks: the Case of Sign Language Tokenization Recurrent neural networks can be used to segment sequences such as videos, where transitions can be challenging to detect. This paper benchmarks strategies to better model the transition between states. The specific task of SL video tokenization is chosen for the evaluation, as it remains challenging. Tokenizers are the cornerstone of natural language processing pipelines. There exist powerful tokenizers for text data, but sign language (SL) video tokenizers are still under development. Benchmarked strategies prove to be useful to improve SL videos tokenization, but there is still room for improvement to better model state transitions."
Modular Representations for Weak Disentanglement,"Andrea Valenti, Davide Bacciu",1 - Department of Computer Science Largo B. Pontecorvo University of Pisa 56127 Pisa Italy,"The recently introduced weakly disentangled representations proposed to relax some constraints of the previous definitions of disentanglement, in exchange for more flexibility. However, at the moment, weak disentanglement can only be achieved by increasing the amount of supervision as the number of factors of variations of the data increase. In this paper, we introduce modular representations for weak disentanglement, a novel method that allows to keep the amount of supervised information constant with respect the number of generative factors. The experiments shows that models using modular representations can increase their performance with respect to previous work without the need of additional supervision. * The work has been partially supported by the EU H2020 TAILOR project (n.952215).",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-52,2022,100.0,"Modular Representations for Weak Disentanglement The recently introduced weakly disentangled representations proposed to relax some constraints of the previous definitions of disentanglement, in exchange for more flexibility. However, at the moment, weak disentanglement can only be achieved by increasing the amount of supervision as the number of factors of variations of the data increase. In this paper, we introduce modular representations for weak disentanglement, a novel method that allows to keep the amount of supervised information constant with respect the number of generative factors. The experiments shows that models using modular representations can increase their performance with respect to previous work without the need of additional supervision. * The work has been partially supported by the EU H2020 TAILOR project (n.952215)."
Size Scaling in Self-Play Reinforcement Learning,"Oren Neumann, Claudius Gros",1 - Institute for Theoretical Physics Goethe University Frankfurt Frankfurt am Main Germany,"Performance scaling laws with resources are heavily studied in supervised deep learning models but not in reinforcement learning. We examine the scaling of the AlphaZero [1] algorithm's performance with model size by training agents on three competitive two-player games, Connect Four, Oware and Pentago. We find that performance, in the form of the Elo rating, scales logarithmically with the number of free neural network parameters, a trend consistent across games and when using deeper neural networks. This leads to a universal expression for the average match outcome which depends only on the ratio of sizes between opponents, which is supported by an agnostic rating method.",Reinforcement learning,https://doi.org/10.14428/esann/2022.ES2022-53,2022,100.0,"Size Scaling in Self-Play Reinforcement Learning Performance scaling laws with resources are heavily studied in supervised deep learning models but not in reinforcement learning. We examine the scaling of the AlphaZero [1] algorithm's performance with model size by training agents on three competitive two-player games, Connect Four, Oware and Pentago. We find that performance, in the form of the Elo rating, scales logarithmically with the number of free neural network parameters, a trend consistent across games and when using deeper neural networks. This leads to a universal expression for the average match outcome which depends only on the ratio of sizes between opponents, which is supported by an agnostic rating method."
Pruning Weightless Neural Networks,"Zachary Susskind, Alan Bacellar, Aman Arora, Luis Villon, Renan Mendanha, Leandro De Araújo, Diego Dutra, Priscila Lima, Felipe França, Igor Miranda, et al.","1 - UFRJ 3-UFF, 4-IT-Porto Rio de Janeiro, Niterói Brazil, Brazil, Portugal
7 - UFRB 6-ISCTE Cruz das Almas, Lisbon Brazil, Portugal
8 - 1-UT Austin, Austin USA","Weightless neural networks (WNNs) are a type of machine learning model which perform prediction using lookup tables (LUTs) instead of arithmetic operations. Recent advancements in WNNs have reduced model sizes and improved accuracies, reducing the gap in accuracy with deep neural networks (DNNs). Modern DNNs leverage ""pruning"" techniques to reduce model size, but this has not previously been explored for WNNs. We propose a WNN pruning strategy based on identifying and culling the LUTs which contribute least to overall model accuracy. We demonstrate an average 40% reduction in model size with at most 1% reduction in accuracy.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-55,2022,100.0,"Pruning Weightless Neural Networks Weightless neural networks (WNNs) are a type of machine learning model which perform prediction using lookup tables (LUTs) instead of arithmetic operations. Recent advancements in WNNs have reduced model sizes and improved accuracies, reducing the gap in accuracy with deep neural networks (DNNs). Modern DNNs leverage ""pruning"" techniques to reduce model size, but this has not previously been explored for WNNs. We propose a WNN pruning strategy based on identifying and culling the LUTs which contribute least to overall model accuracy. We demonstrate an average 40% reduction in model size with at most 1% reduction in accuracy."
From Hyperspectral to Multispectral Sensing and from Simulation to Reality: A Comprehensive Approach to Calibration Model Transfer,"Patrick Menz, Valerie Vaquet, Barbara Hammer, Udo Seiffert","1 - Cognitive Processes and Systems Fraunhofer Institute for Factory Operation and Automation IFF Magdeburg Germany
2 - Machine Learning Group Bielefeld University Bielefeld Germany
5 - Compolytics GmbH Barleben Germany","High-resolution hyperspectral sensors provide precise but expensive information on an object's chemical composition in various industries. We present a method for transferring this capability to customized low-cost multispectral solutions. Taking a relevance analysis of spectra for a given problem as our starting point, we simulated and designed a multispectral sensor based on inverse spectroscopy. The corresponding calibration model, which was derived from the simulation of such a multispectral sensor and connected with its hardware, may not drop in precision significantly. Different methods of calibration model transfer capable of handling a limited subset of the data were tested for this purpose. The latent space transformation with Chebyshev polynomials outperformed all other methods by yielding the fewest labeled data.",Concept drift,https://doi.org/10.14428/esann/2022.ES2022-56,2022,78.76447876447877,"From Hyperspectral to Multispectral Sensing and from Simulation to Reality: A Comprehensive Approach to Calibration Model Transfer High-resolution hyperspectral sensors provide precise but expensive information on an object's chemical composition in various industries. We present a method for transferring this capability to customized low-cost multispectral solutions. Taking a relevance analysis of spectra for a given problem as our starting point, we simulated and designed a multispectral sensor based on inverse spectroscopy. The corresponding calibration model, which was derived from the simulation of such a multispectral sensor and connected with its hardware, may not drop in precision significantly. Different methods of calibration model transfer capable of handling a limited subset of the data were tested for this purpose. The latent space transformation with Chebyshev polynomials outperformed all other methods by yielding the fewest labeled data."
Feature selection for transfer learning using particle swarm optimization and complexity measures,"Guillermo Castillo-García, Laura Morán-Fernández, Verónica Bolón-Canedo","1 - Universidad Internacional Menéndez Pelayo Spain
2 - CITIC Universidade da Coruña Coruña Spain","Particle Swarm Optimization is an optimization algorithm that explores a search space guided by a fitness function in order to find a good solution. We apply it to perform feature selection for domain adaptation. Usually, classification error is used in the fitness function to evaluate the goodness of subsets of features. In this paper, we propose to employ complexity metrics instead, as we assume that reducing the complexity of the problem will lead to good results while being less computationally demanding and independent from the classifier used for testing. We found out that our method is indeed faster and selects fewer features, obtaining competitive classification accuracy results.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-57,2022,100.0,"Feature selection for transfer learning using particle swarm optimization and complexity measures Particle Swarm Optimization is an optimization algorithm that explores a search space guided by a fitness function in order to find a good solution. We apply it to perform feature selection for domain adaptation. Usually, classification error is used in the fitness function to evaluate the goodness of subsets of features. In this paper, we propose to employ complexity metrics instead, as we assume that reducing the complexity of the problem will lead to good results while being less computationally demanding and independent from the classifier used for testing. We found out that our method is indeed faster and selects fewer features, obtaining competitive classification accuracy results."
Beyond Homophily with Graph Echo State Networks,"Domenico Tortorella, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy,"Graph Echo State Networks (GESN) have already demonstrated their efficacy and efficiency in graph classification tasks. However, semi-supervised node classification brought out the problem of oversmoothing in end-to-end trained deep models, which causes a bias towards high homophily graphs. We evaluate for the first time GESN on node classification tasks with different degrees of homophily, analyzing also the impact of the reservoir radius. Our experiments show that reservoir models are able to achieve better or comparable accuracy with respect to fully trained deep models that implement ad hoc variations in the architectural bias, with a gain in terms of efficiency.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-58,2022,100.0,"Beyond Homophily with Graph Echo State Networks Graph Echo State Networks (GESN) have already demonstrated their efficacy and efficiency in graph classification tasks. However, semi-supervised node classification brought out the problem of oversmoothing in end-to-end trained deep models, which causes a bias towards high homophily graphs. We evaluate for the first time GESN on node classification tasks with different degrees of homophily, analyzing also the impact of the reservoir radius. Our experiments show that reservoir models are able to achieve better or comparable accuracy with respect to fully trained deep models that implement ad hoc variations in the architectural bias, with a gain in terms of efficiency."
Simple Non Regressive Informed Machine Learning Model for Predictive Maintenance of Railway Critical Assets *,"Simone Minisi, Andrea Garrone, Luca Oneto, Renzo Canepa, Carlo Dambra, Davide Anguita","1 - ZenaByte s.r.l Via Cesarea 2 16121 Genova Italy
2 - University of Genoa Via Opera Pia 11a 16145 Genova Italy
4 - Rete Ferroviaria Italiana Via Don Vincenzo Minetti 6/5 16126 Genova Italy","Signals, track circuits, switches, and relay rooms are simultaneously the most critical and most maintained railway assets. A fault of one of these assets may strongly reduce the railway network capacity or even disrupt the circulation. Effectively predicting what assets may need maintenance allows to anticipate the intervention thus avoiding a failure. Currently, this problem is tackled by infrastructure managers mostly relying on operators' experience and with limited support of decision supporting tools. In this paper, we propose a Simple Informed Machine Learning (ML) based model able to automatically predict what asset need to be maintained fully leveraging on the operator experience. However, ML models in modern industrial MLOps pipelines demand continuous data collection, model re-training, testing, and monitoring, creating a large technical debt. In fact, one of the main requirements of these pipelines is to not be regressive, i.e., not simply improve average performances but also not incorrectly predicting an output that was correctly classified by the reference model (negative flips). In this work we face this problem by empowering the proposed ML with Non Regressive properties. Results on real data coming from a portion of an Italian Railway Network managed by Rete Ferroviaria Italiana, the Italian Infrastructure Manager, will support our proposal.",Classification,https://doi.org/10.14428/esann/2022.ES2022-59,2022,99.07407407407408,"Simple Non Regressive Informed Machine Learning Model for Predictive Maintenance of Railway Critical Assets * Signals, track circuits, switches, and relay rooms are simultaneously the most critical and most maintained railway assets. A fault of one of these assets may strongly reduce the railway network capacity or even disrupt the circulation. Effectively predicting what assets may need maintenance allows to anticipate the intervention thus avoiding a failure. Currently, this problem is tackled by infrastructure managers mostly relying on operators' experience and with limited support of decision supporting tools. In this paper, we propose a Simple Informed Machine Learning (ML) based model able to automatically predict what asset need to be maintained fully leveraging on the operator experience. However, ML models in modern industrial MLOps pipelines demand continuous data collection, model re-training, testing, and monitoring, creating a large technical debt. In fact, one of the main requirements of these pipelines is to not be regressive, i.e., not simply improve average performances but also not incorrectly predicting an output that was correctly classified by the reference model (negative flips). In this work we face this problem by empowering the proposed ML with Non Regressive properties. Results on real data coming from a portion of an Italian Railway Network managed by Rete Ferroviaria Italiana, the Italian Infrastructure Manager, will support our proposal."
Challenges in anomaly and change point detection,"Madalina Olteanu, Fabrice Rossi, Florian Yger","1 - UMR 7534 CEREMADE CNRS Université Paris-Dauphine
2 - PSL University 75016 Paris France
5 - LAMSADE UMR 7243 CNRS Université Paris-Dauphine","This paper presents an introduction to the state-of-the-art in anomaly and change-point detection. On the one hand, the main concepts needed to understand the vast scientific literature on those subjects are introduced. On the other, a selection of important surveys and books, as well as two selected active research topics in the field, are presented.",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-6,2022,100.0,"Challenges in anomaly and change point detection This paper presents an introduction to the state-of-the-art in anomaly and change-point detection. On the one hand, the main concepts needed to understand the vast scientific literature on those subjects are introduced. On the other, a selection of important surveys and books, as well as two selected active research topics in the field, are presented."
Battery detection of XRay images using transfer learning,"Nermeen Abou Baker, David Rohrschneider, Uwe Handmann",1 - Dept of Computer Science Ruhr West University of Applied Sciences Lutzowstrassse 5 46236 Bottrop Germany,"The need for detecting and sorting batteries is drastically increasing for many applications. This study proves the potential of transfer learning in predicting whether the image contains a battery or not, the location and identifying three types of batteries, namely: prismatic, pouch, and cylindrical Lithium-Ion Batteries (LIB). Particularly, it focuses on the transfer learning method in two applications: Training a large-scale dataset to detect electronic devices using a pre-trained YOLOv5m, then using these latter trained weights to detect and classify the batteries. The precision of battery detection achieves 94%, which outperforms the pretrained YOLOv5m weights with 5%, in 22 ms inference time.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-60,2022,100.0,"Battery detection of XRay images using transfer learning The need for detecting and sorting batteries is drastically increasing for many applications. This study proves the potential of transfer learning in predicting whether the image contains a battery or not, the location and identifying three types of batteries, namely: prismatic, pouch, and cylindrical Lithium-Ion Batteries (LIB). Particularly, it focuses on the transfer learning method in two applications: Training a large-scale dataset to detect electronic devices using a pre-trained YOLOv5m, then using these latter trained weights to detect and classify the batteries. The precision of battery detection achieves 94%, which outperforms the pretrained YOLOv5m weights with 5%, in 22 ms inference time."
Classification of preclinical markers in Alzheimer's disease via WiSARD classifier,"M De Gregorio, A Di Costanzo, A Motta, D Paris, A Sorgente","1 - Istituto di Scienze Applicate e Sistemi Intelligenti ""Eduardo Caianiello"" -CNR Italy
2 - Centre for Research and Training in Medicine for Aging Dept. of Medicine Health Sciences ""Vincenzo Tiberio"" University of Molise Italy
3 - Istituto di Chimica Biomolecolare -CNR Italy","Weightless Neural Networks (WNN) showed good results in various classification problems in different domains where a significant number of instances for each class was available. In this work, we present different WiSARD classifiers facing a quite difficult problem from both the clinical and the machine learning point of views: the classification of preclinical markers in Alzheimer's disease continuum patients. The four domain classes show overlapping molecular features and each has few instances (around 40). Together with improved class separation, the confirmation of the goodness of the results is given by a series of experiments that have compared the WiSARD classifiers to many state-of-the-art classifiers, even those ensembles, showing that the obtained results are very close to the top best models.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-63,2022,100.0,"Classification of preclinical markers in Alzheimer's disease via WiSARD classifier Weightless Neural Networks (WNN) showed good results in various classification problems in different domains where a significant number of instances for each class was available. In this work, we present different WiSARD classifiers facing a quite difficult problem from both the clinical and the machine learning point of views: the classification of preclinical markers in Alzheimer's disease continuum patients. The four domain classes show overlapping molecular features and each has few instances (around 40). Together with improved class separation, the confirmation of the goodness of the results is given by a series of experiments that have compared the WiSARD classifiers to many state-of-the-art classifiers, even those ensembles, showing that the obtained results are very close to the top best models."
Gap filling in air temperature series by matrix completion methods,"Benoît Loucheur, P.-A Absil, Michel Journée","1 - ICTEAM Institute 1348 Louvain-la-Neuve UCLouvain, Belgium
3 - Royal Meteorological Institute 1180 Uccle Belgium, Belgium","Quality control of meteorological data is an important part of atmospheric analysis and prediction, as missing or erroneous values can degrade the quality of weather and climate information derived from these data. In practice, the presence of missing data in the weather series is quite common and problematic for many uses. We compare the performance of matrix completion methods with the state of the art to solve this missing data problem. The experimental results are carried out using the daily minimum and maximum temperature measurements of the network of weather stations operated by the Royal Meteorological Institute (RMI) of Belgium.",Regression and forecasting,https://doi.org/10.14428/esann/2022.ES2022-67,2022,100.0,"Gap filling in air temperature series by matrix completion methods Quality control of meteorological data is an important part of atmospheric analysis and prediction, as missing or erroneous values can degrade the quality of weather and climate information derived from these data. In practice, the presence of missing data in the weather series is quite common and problematic for many uses. We compare the performance of matrix completion methods with the state of the art to solve this missing data problem. The experimental results are carried out using the daily minimum and maximum temperature measurements of the network of weather stations operated by the Royal Meteorological Institute (RMI) of Belgium."
Deep Learning for Graphs,"Davide Bacciu, Federico Errica, Nicolò Navarin, Luca Pasa, Daniele Zambon","1 - Department of Computer Science University of Pisa Italy
2 - -NEC Laboratories Europe Germany
3 - Department of Mathematics University of Padova Italy
5 - The Swiss AI Lab IDSIA Università della Svizzera italiana Switzerland","The flourishing field of deep learning for graphs relies on the layered computation of representations from graph-structured input data. Message passing is the most common strategy for such processing of graphs, based on an efficient information exchange among the connected nodes via a local and iterative procedure. Representations learned in this way can be used to address different tasks related to nodes, edges, or even entire graphs. This tutorial paper reviews fundamental concepts and open challenges of deep learning for graphs and summarizes the contributions that have been accepted for publication to the ESANN 2022 special session on the topic.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-7,2022,100.0,"Deep Learning for Graphs The flourishing field of deep learning for graphs relies on the layered computation of representations from graph-structured input data. Message passing is the most common strategy for such processing of graphs, based on an efficient information exchange among the connected nodes via a local and iterative procedure. Representations learned in this way can be used to address different tasks related to nodes, edges, or even entire graphs. This tutorial paper reviews fundamental concepts and open challenges of deep learning for graphs and summarizes the contributions that have been accepted for publication to the ESANN 2022 special session on the topic."
Adaptive multi-modal positive semi-definite and indefinite kernel fusion for binary classification,"Maximilian Münch, Christoph Raab, Simon Heilig, Manuel Röder, Frank-Michael Schleif","1 - Center for Artificial Intelligence and Robotics (CAIRO) University of Applied Sciences Würzburg-Schweinfurt Würzburg Germany
2 - Computer Science and Artificial Intelligence Bernoulli Institute for Mathematics
3 - University of Groningen Groningen The Netherlands","Data and information are nowadays frequently available in multiple modalities like different sensor signals, textual descriptions, graph structures, and other formats. The maximum information from these heterogeneous representations can be obtained by fusing the various modalities by specific embeddings or proximity measures. Current approaches are widely limited in the fusion model and the applied measures, especially when the given data is non-vectorial. We propose a model to learn the spectral properties of the different inner product representations in a joined optimization problem. The approach is evaluated on various multimodal data and compared to modern multiple-kernel learning and baseline techniques. * MM and MR are supported by the Bavarian HighTech agenda and the Würzburg Center for Artificial Intelligence and Robotics (CAIRO). Additionally, we thank Dr. Benjamin Paaßen for the invaluable discussions about this research topic during a fantastic boating trip.",Classification,https://doi.org/10.14428/esann/2022.ES2022-70,2022,100.0,"Adaptive multi-modal positive semi-definite and indefinite kernel fusion for binary classification Data and information are nowadays frequently available in multiple modalities like different sensor signals, textual descriptions, graph structures, and other formats. The maximum information from these heterogeneous representations can be obtained by fusing the various modalities by specific embeddings or proximity measures. Current approaches are widely limited in the fusion model and the applied measures, especially when the given data is non-vectorial. We propose a model to learn the spectral properties of the different inner product representations in a joined optimization problem. The approach is evaluated on various multimodal data and compared to modern multiple-kernel learning and baseline techniques. * MM and MR are supported by the Bavarian HighTech agenda and the Würzburg Center for Artificial Intelligence and Robotics (CAIRO). Additionally, we thank Dr. Benjamin Paaßen for the invaluable discussions about this research topic during a fantastic boating trip."
Contrasting Explanation of Concept Drift *,"Fabian Hinder, André Artelt, Valerie Vaquet, Barbara Hammer","1 - Bielefeld University -Cognitive Interaction Technology (CITEC) Inspiration 1 33619 Bielefeld Germany
3 - University of Cyprus","The notion of concept drift refers to the phenomenon that the distribution, which is underlying the observed data, changes over time. As a consequence machine learning models may become inaccurate and need adjustment. While there do exist methods to detect concept drift or to adjust models in the presence of observed drift, the question of explaining drift is still widely unsolved. This problem is of importance, since it enables an understanding of the most prominent drift characteristics. In this work we propose to explain concept drift by means of contrasting explanations describing characteristic changes of spatial features. We demonstrate the usefulness of the explanation in several examples.",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-71,2022,97.5609756097561,"Contrasting Explanation of Concept Drift * The notion of concept drift refers to the phenomenon that the distribution, which is underlying the observed data, changes over time. As a consequence machine learning models may become inaccurate and need adjustment. While there do exist methods to detect concept drift or to adjust models in the presence of observed drift, the question of explaining drift is still widely unsolved. This problem is of importance, since it enables an understanding of the most prominent drift characteristics. In this work we propose to explain concept drift by means of contrasting explanations describing characteristic changes of spatial features. We demonstrate the usefulness of the explanation in several examples."
Filtering participants improves generalization in competitions and benchmarks,"Adrien Pavao, Zhengying Liu, Isabelle Guyon",1 - LISN/CNRS INRIA Université Paris-Saclay France,"We address the problem of selecting a winning algorithm in a challenge or benchmark. While evaluations of algorithms carried out by third party organizers eliminate the inventor-evaluator bias, little attention has been paid to the risk of over-fitting the winner's selection by the organizers. In this paper, we carry out an empirical evaluation using the results of several challenges and benchmarks, evidencing this phenomenon. We show that a heuristic commonly used by organizers consisting of pre-filtering participants using a trial run, reduces over-fitting. We formalize this method and derive a semi-empirical formula to determine the optimal number of top k participants to retain from the trial run.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-72,2022,100.0,"Filtering participants improves generalization in competitions and benchmarks We address the problem of selecting a winning algorithm in a challenge or benchmark. While evaluations of algorithms carried out by third party organizers eliminate the inventor-evaluator bias, little attention has been paid to the risk of over-fitting the winner's selection by the organizers. In this paper, we carry out an empirical evaluation using the results of several challenges and benchmarks, evidencing this phenomenon. We show that a heuristic commonly used by organizers consisting of pre-filtering participants using a trial run, reduces over-fitting. We formalize this method and derive a semi-empirical formula to determine the optimal number of top k participants to retain from the trial run."
Appearance-Context aware Axial Attention for Fashion Landmark Detection,"Nikhil Kilari, Gaurab Bhattacharya, Kumar Reddy, J Gubbi, Arpan Pal",1 - Embedded Devices and Intelligent Systems TCS Research India,"Fashion landmark detection is a fundamental task in several fashion image analysis problems. The associated challenges involving non-rigid structures and variations in style and orientation makes it extremely hard to accurately detect the landmarks. In this paper, we propose Appearance-Context network (ACNet), which encapsulates both global and local contextual information extending the axial attention mechanism. We design axial attention augmented local appearance network and introduce a novel Global-Context aware axial attention module which aggregates the global features attending discriminatory cues across height, width and channel axes. The proposed ACNet architecture outperforms existing methods on two large-scale fashion landmark datasets.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-74,2022,100.0,"Appearance-Context aware Axial Attention for Fashion Landmark Detection Fashion landmark detection is a fundamental task in several fashion image analysis problems. The associated challenges involving non-rigid structures and variations in style and orientation makes it extremely hard to accurately detect the landmarks. In this paper, we propose Appearance-Context network (ACNet), which encapsulates both global and local contextual information extending the axial attention mechanism. We design axial attention augmented local appearance network and introduce a novel Global-Context aware axial attention module which aggregates the global features attending discriminatory cues across height, width and channel axes. The proposed ACNet architecture outperforms existing methods on two large-scale fashion landmark datasets."
High Accuracy and Low Regret for User-Cold-Start Using Latent Bandits,"David Young, Douglas Leith",1 - School of Computer Science and Statistics Trinity College Dublin Ireland,"We develop a novel latent-bandit algorithm for tackling the cold-start problem for new users joining a recommender system. This new algorithm significantly outperforms the state of the art, simultaneously achieving both higher accuracy and lower regret.","Natural language processing, and recommender systems",https://doi.org/10.14428/esann/2022.ES2022-79,2022,100.0,"High Accuracy and Low Regret for User-Cold-Start Using Latent Bandits We develop a novel latent-bandit algorithm for tackling the cold-start problem for new users joining a recommender system. This new algorithm significantly outperforms the state of the art, simultaneously achieving both higher accuracy and lower regret."
Continual Incremental Language Learning for Neural Machine Translation,"Michele Resta, Davide Bacciu",1 - University of Pisa -Computer Science Department Largo Bruno Pontecorvo 56127 Pisa Italy,"The paper provides an experimental investigation of the phenomena of catastrophic forgetting for Neural Machine Translation systems. We introduce and describe the continual incremental language learning setting and its analogy with the classical continual learning scenario. The experiments measure the performance loss of a naive incremental training strategy against a jointly trained baseline, and we show the mitigating effect of the replay strategy. To this end, we also introduce a prioritized replay buffer strategy informed by the specific application domain.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-80,2022,100.0,"Continual Incremental Language Learning for Neural Machine Translation The paper provides an experimental investigation of the phenomena of catastrophic forgetting for Neural Machine Translation systems. We introduce and describe the continual incremental language learning setting and its analogy with the classical continual learning scenario. The experiments measure the performance loss of a naive incremental training strategy against a jointly trained baseline, and we show the mitigating effect of the replay strategy. To this end, we also introduce a prioritized replay buffer strategy informed by the specific application domain."
Semi-synthetic Data for Automatic Drone Shadow Detection,"Mohammed El, Amine Mokhtari, Virginie Vandenbulcke, Sohaib Laraba, Matei Mancas, Elias Ennadifi, Mohamed Tazir, Bernard Gosselin",1 - University of Mons -Numediart Boulevard Dolez 31 -7000 Mons Belgium,"In this paper, we deal with the problem of shadow detection of UAVs, which impacts their navigation. We propose to generate synthetic images containing shadows in random locations, backgrounds, sizes, and opacities in order to augment our dataset. The generated data is used to train and compare several models to effectively detect, in real-time, UAVs shadows which will help to stabilize their localization and navigation. Deep learning models such as SSD, YOLOv3, and YOLOv5 are tested for the detection part. With our approach, we achieved 99% of the mean average precision when using the YOLOv5.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-82,2022,100.0,"Semi-synthetic Data for Automatic Drone Shadow Detection In this paper, we deal with the problem of shadow detection of UAVs, which impacts their navigation. We propose to generate synthetic images containing shadows in random locations, backgrounds, sizes, and opacities in order to augment our dataset. The generated data is used to train and compare several models to effectively detect, in real-time, UAVs shadows which will help to stabilize their localization and navigation. Deep learning models such as SSD, YOLOv3, and YOLOv5 are tested for the detection part. With our approach, we achieved 99% of the mean average precision when using the YOLOv5."
Diverse Memory for Experience Replay in Continual Learning,"Andrii Krutsylo, Pawe Morawiecki",1 - Institute of Computer Science Polish Academy of Sciences Jana Kazimierza 5 01-248 Warsaw Poland,"Neural networks trained on data whose distribution is shifted in time suffer greatly from performance degradation. This problem is known as catastrophic forgetting, i.e. learning new classes leads to loss of accuracy on previously seen ones. A replay buffer can mitigate this problem by storing and reusing some of the data. In this paper, we propose a modification of sampling to the memory buffer using deep features extracted from the classifier itself to increase the diversity of stored samples. Our method demonstrates a consistent reduction in forgetting verified on different settings for MNIST, SVHN and CIFAR-10 datasets.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-83,2022,100.0,"Diverse Memory for Experience Replay in Continual Learning Neural networks trained on data whose distribution is shifted in time suffer greatly from performance degradation. This problem is known as catastrophic forgetting, i.e. learning new classes leads to loss of accuracy on previously seen ones. A replay buffer can mitigate this problem by storing and reusing some of the data. In this paper, we propose a modification of sampling to the memory buffer using deep features extracted from the classifier itself to increase the diversity of stored samples. Our method demonstrates a consistent reduction in forgetting verified on different settings for MNIST, SVHN and CIFAR-10 datasets."
D vs 2D convolutional neural networks for scalp high frequency oscillations identification,"Gaëlle Milon-Harnois, Nisrine Jrad, Daniel Schang, Patrick Bogaert, Pierre Chauvet","1 - -UCO -Laboratoire Angevin de Recherche en Ingénierie des Systèmes
3 - ESEO-Tech -Laboratoire d'Etude et de Recherche en Informatique d'Angers (LERIA) -Angers France
4 - Centre Hospitalier Universitaire -Neuropediatric department Angers France","Scalp High Frequency Oscillations (HFOs) are promising biomarkers of epileptogenic zones. Since HFOs visual detection is strenuous, there is a real need to develop accurate HFOs automatic detectors. In this paper, we present a comparative study of two detectors: onedimensional (1D) Convolutional Neural Networks (CNN) running on High-Density Electroencephalograms signals and two dimensional (2D) CNN on time-frequency maps of those signals. Experimental results show that 1D-CNN enables easy end-to-end learning of preprocessing, feature extraction and classification modules while achieving competitive performance.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-84,2022,98.34254143646409,"D vs 2D convolutional neural networks for scalp high frequency oscillations identification Scalp High Frequency Oscillations (HFOs) are promising biomarkers of epileptogenic zones. Since HFOs visual detection is strenuous, there is a real need to develop accurate HFOs automatic detectors. In this paper, we present a comparative study of two detectors: onedimensional (1D) Convolutional Neural Networks (CNN) running on High-Density Electroencephalograms signals and two dimensional (2D) CNN on time-frequency maps of those signals. Experimental results show that 1D-CNN enables easy end-to-end learning of preprocessing, feature extraction and classification modules while achieving competitive performance."
Improving Intensive Care Chest X-Ray Classification by Transfer Learning and Automatic Label Generation,"Helen Schneider, David Biesner, Sebastian Nowak, Yannik Layer, Maike Theis, Wolfgang Block, Benjamin Wulff, Alois Sprinkart, Ulrike Attenberger, Rafet Sifa","1 - Department Media Engineering Fraunhofer IAIS
3 - Department of Computerscience University of Bonn
4 - Department of Diagnostic and Interventional Radiology University Hospital Bonn","Radiologists commonly conduct chest X-rays for the diagnosis of pathologies or the evaluation of extrathoracic material positions in intensive care unit (ICU) patients. Automated assessments of radiographs have the potential to assist physicians by detecting pathologies that pose an emergency, leading to faster initiation of treatment and optimization of clinical workflows. The amount and quality of training data is a key aspect for developing deep learning models with reliable performance. This work investigates the effects of transfer learning on public data, automatically generated data labels and manual data annotation on the classification of ICU chest X-rays of the University Hospital Bonn.",Machine Learning and Information Theoretic Methods  for Molecular Biology and Medicine,https://doi.org/10.14428/esann/2022.ES2022-85,2022,100.0,"Improving Intensive Care Chest X-Ray Classification by Transfer Learning and Automatic Label Generation Radiologists commonly conduct chest X-rays for the diagnosis of pathologies or the evaluation of extrathoracic material positions in intensive care unit (ICU) patients. Automated assessments of radiographs have the potential to assist physicians by detecting pathologies that pose an emergency, leading to faster initiation of treatment and optimization of clinical workflows. The amount and quality of training data is a key aspect for developing deep learning models with reliable performance. This work investigates the effects of transfer learning on public data, automatically generated data labels and manual data annotation on the classification of ICU chest X-rays of the University Hospital Bonn."
Adaptive Gabor Filters for Interpretable Color Texture Classification,"Gerrit Luimstra, Kerstin Bunte",1 - University of Groningen -Science and Engineering Nijenborgh 9 Groningen Netherlands,"We introduce the use of trainable feature extractors, based on the Gabor function, into the interpretable machine learning domain. The use of adaptive Gabor filters allows for interpretable feature extraction to be learned automatically in a domain agnostic way, and comes with the benefit of a large reduction in trainable parameters. We implemented the filters into an image classification variant of learning vector quantization We extend and compare the image classification variant of learning vector quantization with adaptive Gabor filters and demonstrate the proposed technique on VisTex color texture images. The adaptive Gabor filters show promising results for interpretable and efficient color texture classification.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-87,2022,100.0,"Adaptive Gabor Filters for Interpretable Color Texture Classification We introduce the use of trainable feature extractors, based on the Gabor function, into the interpretable machine learning domain. The use of adaptive Gabor filters allows for interpretable feature extraction to be learned automatically in a domain agnostic way, and comes with the benefit of a large reduction in trainable parameters. We implemented the filters into an image classification variant of learning vector quantization We extend and compare the image classification variant of learning vector quantization with adaptive Gabor filters and demonstrate the proposed technique on VisTex color texture images. The adaptive Gabor filters show promising results for interpretable and efficient color texture classification."
Graph Neural Networks for Propositional Model Counting,"Gaia Saveri, Luca Bortolussi","1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy
2 - Department of Mathematics and Geoscience University of Trieste Via A. Valerio 12 34127 Trieste Italy","Graph Neural Networks (GNNs) have been recently leveraged to solve several logical reasoning tasks. Nevertheless, counting problems such as propositional model counting (#SAT) are still mostly approached with traditional solvers. Here we tackle this gap by presenting an architecture based on the GNN framework for belief propagation (BP) of [1], extended with self-attentive GNN and trained to approximately solve the #SAT problem. We experimentally show that our model, trained on a small set of random Boolean formulae, is able to scale effectively to much larger problem sizes, outperforming state of the art approximate solvers. Moreover, we show that it can be efficiently fine-tuned to provide good generalization results on different formulae distributions, such as those coming from SATencoded combinatorial problems. Related Work. In [5] a graph neural network model is proposed to solve the weighted disjunctive normal form counting problem (weighted #DNF). Moreover, a significant",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-88,2022,100.0,"Graph Neural Networks for Propositional Model Counting Graph Neural Networks (GNNs) have been recently leveraged to solve several logical reasoning tasks. Nevertheless, counting problems such as propositional model counting (#SAT) are still mostly approached with traditional solvers. Here we tackle this gap by presenting an architecture based on the GNN framework for belief propagation (BP) of [1], extended with self-attentive GNN and trained to approximately solve the #SAT problem. We experimentally show that our model, trained on a small set of random Boolean formulae, is able to scale effectively to much larger problem sizes, outperforming state of the art approximate solvers. Moreover, we show that it can be efficiently fine-tuned to provide good generalization results on different formulae distributions, such as those coming from SATencoded combinatorial problems. Related Work. In [5] a graph neural network model is proposed to solve the weighted disjunctive normal form counting problem (weighted #DNF). Moreover, a significant"
Federated learning vector quantization for dealing with drift between nodes,"Valerie Vaquet, Fabian Hinder, Johannes Brinkrolf, Patrick Menz, Udo Seiffert, Barbara Hammer","1 - Machine Learning Group Bielefeld University Bielefeld Germany
4 - Fraunhofer Institute of Factory Operation and Automation (IFF) Cognitive Processes and Systems Magdeburg Germany
5 - -Compolytics GmbH Barleben Germany","Federated learning is an efficient methodology to reduce the data transmissions to the server when working with large amounts of (sensor) data from diverse physical locations. When using data from different sensor devices concept drift between the single sensors poses an additional challenge. In this contribution we define a formal framework for federated learning with concept drift and propose a version of federated LVQ dealing with concept drift induced by different hyperspectral cameras. We evaluate this approach experimentally and demonstrate its robustness to class imbalance and missing classes. * Authors contributed equally. † Funding in the frame of the BMBF project TiM, 05M20PBA and 05M20AFA, and BMWi project KI-Marktplatz, 01MK20007E is gratefully acknowledged.",Concept drift,https://doi.org/10.14428/esann/2022.ES2022-89,2022,100.0,"Federated learning vector quantization for dealing with drift between nodes Federated learning is an efficient methodology to reduce the data transmissions to the server when working with large amounts of (sensor) data from diverse physical locations. When using data from different sensor devices concept drift between the single sensors poses an additional challenge. In this contribution we define a formal framework for federated learning with concept drift and propose a version of federated LVQ dealing with concept drift induced by different hyperspectral cameras. We evaluate this approach experimentally and demonstrate its robustness to class imbalance and missing classes. * Authors contributed equally. † Funding in the frame of the BMBF project TiM, 05M20PBA and 05M20AFA, and BMWi project KI-Marktplatz, 01MK20007E is gratefully acknowledged."
Input Routed Echo State Networks,"Luca Argentieri, Claudio Gallicchio, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"We introduce a novel Reservoir Computing (RC) approach for multi-dimensional temporal signals. Our proposal is based on routing the different dimensions of the driving input towards different dynamical sub-modules in a multi-reservoir architecture. At the same time, controllable interconnections among the sub-modules allow modeling the interplay between the different dynamics that might be required by the task. Experiments on synthetic and real-world time-series classification problems clearly show the advantages of the proposed approach in dealing with multi-dimensional signals in comparison to standard RC neural networks.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-90,2022,100.0,"Input Routed Echo State Networks We introduce a novel Reservoir Computing (RC) approach for multi-dimensional temporal signals. Our proposal is based on routing the different dimensions of the driving input towards different dynamical sub-modules in a multi-reservoir architecture. At the same time, controllable interconnections among the sub-modules allow modeling the interplay between the different dynamics that might be required by the task. Experiments on synthetic and real-world time-series classification problems clearly show the advantages of the proposed approach in dealing with multi-dimensional signals in comparison to standard RC neural networks."
Revisiting Edge Pooling in Graph Neural Networks,Francesco Landolfi,"1 - Department of Computer Science Università di Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","Sparse pooling methods for graph neural networks typically perform graph reduction by keeping only the top-k vertices according to an adaptive scoring function. Although fast and scalable, these methods destroy the relational information of the graph and possibly make it disconnected. EdgePool is one of the few sparse alternatives that preserve the connectivity of the input graph by performing a series of edge contractions according to an adaptive scoring of the edges, but it has the drawback of being sequential and not scalable on large scale graphs. In this paper we show that EdgePool can be efficiently computed adapting a well-known parallel algorithm from literature, and we also propose a novel, parallel alternative that leverages on an adaptive scoring function of the nodes. We test both methods on standard benchmark datasets, showing that they generally outperform other sparse pooling methods from the literature. * I would like to thank Davide Bacciu and Alessio Conte for their useful suggestions.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-92,2022,100.0,"Revisiting Edge Pooling in Graph Neural Networks Sparse pooling methods for graph neural networks typically perform graph reduction by keeping only the top-k vertices according to an adaptive scoring function. Although fast and scalable, these methods destroy the relational information of the graph and possibly make it disconnected. EdgePool is one of the few sparse alternatives that preserve the connectivity of the input graph by performing a series of edge contractions according to an adaptive scoring of the edges, but it has the drawback of being sequential and not scalable on large scale graphs. In this paper we show that EdgePool can be efficiently computed adapting a well-known parallel algorithm from literature, and we also propose a novel, parallel alternative that leverages on an adaptive scoring function of the nodes. We test both methods on standard benchmark datasets, showing that they generally outperform other sparse pooling methods from the literature. * I would like to thank Davide Bacciu and Alessio Conte for their useful suggestions."
Distributive Thermometer: A New Unary Encoding for Weightless Neural Networks,"Alan Bacellar, Zachary Susskind, Luis Villon, Igor Miranda, Leandro De Araújo, Diego Dutra, Mauricio Breternitz, Lizy John, Priscila Lima, Felipe França","1 - UFRJ 2-UT Rio de Janeiro, Austin, Austin Brazil, USA
3 - UFRB 4-UFF Cruz das Almas, Niterói Brazil, Brazil
5 - ISTAR/ISCTE-IUL 6-Instituto de Telecomunicações Lisbon Portugal, Portugal","The binary encoding of real valued inputs is a crucial part of Weightless Neural Networks. The Linear Thermometer and its variations are the most prominent methods to determine binary encoding for input data but, as they make assumptions about the input distribution, the resulting encoding is sub-optimal and possibly wasteful when the assumption is incorrect. We propose a new thermometer approach that doesn't require such assumptions. Our results show that it achieves similar or better accuracy when compared to a thermometer that correctly assumes the distribution, and accuracy gains up to 26.3% when other thermometer representations assume an unsound distribution.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-94,2022,100.0,"Distributive Thermometer: A New Unary Encoding for Weightless Neural Networks The binary encoding of real valued inputs is a crucial part of Weightless Neural Networks. The Linear Thermometer and its variations are the most prominent methods to determine binary encoding for input data but, as they make assumptions about the input distribution, the resulting encoding is sub-optimal and possibly wasteful when the assumption is incorrect. We propose a new thermometer approach that doesn't require such assumptions. Our results show that it achieves similar or better accuracy when compared to a thermometer that correctly assumes the distribution, and accuracy gains up to 26.3% when other thermometer representations assume an unsound distribution."
Multioutput Regression Neural Network Training via Gradient Boosting *,"Seyedsaman Emami, Gonzalo Martínez-Muñoz",1 - Universidad Autónoma de Madrid -Escuela Politéctica Superior Francisco Tomás y Valiente 11 28049 Madrid Spain,"A novel sequential procedure to train the final layers of a multi-output regression neural network (NN) based on Gradient Boosting is proposed, where the NN is an additive expansion of the Gradient Boosting. The method works by training portions of the network in an iterative manner in such a way that each new portion of the NN is learnt to compensate for the errors of the already trained portions, and the final result of the network forms by provided weight and the last hidden layer output. This is in contrast to the standard training of NNs in which the whole network is trained to learn the concept at hand. Extensive experiments show the good performance of the proposed method with respect to NN.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-95,2022,98.55072463768117,"Multioutput Regression Neural Network Training via Gradient Boosting * A novel sequential procedure to train the final layers of a multi-output regression neural network (NN) based on Gradient Boosting is proposed, where the NN is an additive expansion of the Gradient Boosting. The method works by training portions of the network in an iterative manner in such a way that each new portion of the NN is learnt to compensate for the errors of the already trained portions, and the final result of the network forms by provided weight and the last hidden layer output. This is in contrast to the standard training of NNs in which the whole network is trained to learn the concept at hand. Extensive experiments show the good performance of the proposed method with respect to NN."
PCA improves the adversarial robustness of neural networks,"Ammar Al-Najjar, István Megyeri",1 - University of Szeged Hungary,"Deep neural networks perform well in many visual recognition tasks, but they are sensitive to adversarial input perturbation. More robust models can be learned when attacks are applied to the training data or preprocessing is used. However, the effect of preprocessing is frequently underestimated and it has not received sufficient attention as it usually does not affect the network's clean accuracy. Here, we seek to demonstrate that preprocessing can play a role in improving adversarial robustness. Our empirical results show that principal component analysis, a simple yet effective preprocessing method, can significantly improve neural networks' robustness for both regular and adversarial training.","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-96,2022,100.0,"PCA improves the adversarial robustness of neural networks Deep neural networks perform well in many visual recognition tasks, but they are sensitive to adversarial input perturbation. More robust models can be learned when attacks are applied to the training data or preprocessing is used. However, the effect of preprocessing is frequently underestimated and it has not received sufficient attention as it usually does not affect the network's clean accuracy. Here, we seek to demonstrate that preprocessing can play a role in improving adversarial robustness. Our empirical results show that principal component analysis, a simple yet effective preprocessing method, can significantly improve neural networks' robustness for both regular and adversarial training."
ROP inception: signal estimation with quadratic random sketching,"Rémi Delogne, Vincent Schellekens, Laurent Jacques",1 - ISPGroup INMA ICTEAM UCLouvain Belgium,"Rank-one projections (ROP) of matrices and quadratic random sketching of signals support several data processing and machine learning methods, as well as recent imaging applications, such as phase retrieval or optical processing units. In this paper, we demonstrate how signal estimation can be operated directly through such quadratic sketchesequivalent to the ROPs of the ""lifted signal"" obtained as its outer product with itself-without explicitly reconstructing that signal. Our analysis relies on showing that, up to a minor debiasing trick, the ROP measurement operator satisfies a generalised sign product embedding (SPE) property. In a nutshell, the SPE shows that the scalar product of a signal sketch with the sign of the sketch of a given pattern approximates the square of the projection of that signal on this pattern. This thus amounts to an insertion (an inception) of a ROP model inside a ROP sketch. The effectiveness of our approach is evaluated in several synthetic experiments. * LJ is funded by the Belgian FNRS. Part of this work is funded by the FNRS under Grant n• T.0136.20 (Learn2Sense).","Deep learning, signal, image",https://doi.org/10.14428/esann/2022.ES2022-97,2022,100.0,"ROP inception: signal estimation with quadratic random sketching Rank-one projections (ROP) of matrices and quadratic random sketching of signals support several data processing and machine learning methods, as well as recent imaging applications, such as phase retrieval or optical processing units. In this paper, we demonstrate how signal estimation can be operated directly through such quadratic sketchesequivalent to the ROPs of the ""lifted signal"" obtained as its outer product with itself-without explicitly reconstructing that signal. Our analysis relies on showing that, up to a minor debiasing trick, the ROP measurement operator satisfies a generalised sign product embedding (SPE) property. In a nutshell, the SPE shows that the scalar product of a signal sketch with the sign of the sketch of a given pattern approximates the square of the projection of that signal on this pattern. This thus amounts to an insertion (an inception) of a ROP model inside a ROP sketch. The effectiveness of our approach is evaluated in several synthetic experiments. * LJ is funded by the Belgian FNRS. Part of this work is funded by the FNRS under Grant n• T.0136.20 (Learn2Sense)."
Federated Adaptation of Reservoirs via Intrinsic Plasticity,"Valerio De Caro, Claudio Gallicchio, Davide Bacciu","1 - Department of Computer Science University of Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","We propose a novel algorithm for performing federated learning with Echo State Networks (ESNs) in a client-server scenario. In particular, our proposal focuses on the adaptation of reservoirs by combining Intrinsic Plasticity with Federated Averaging. The former is a gradientbased method for adapting the reservoir's non-linearity in a local and unsupervised manner, while the latter provides the framework for learning in the federated scenario. We evaluate our approach on real-world datasets from human monitoring, in comparison with the previous approach for federated ESNs existing in literature. Results show that adapting the reservoir with our algorithm provides a significant improvement on the performance of the global model.",Recurrent learning and reservoir computing,https://doi.org/10.14428/esann/2022.ES2022-98,2022,100.0,"Federated Adaptation of Reservoirs via Intrinsic Plasticity We propose a novel algorithm for performing federated learning with Echo State Networks (ESNs) in a client-server scenario. In particular, our proposal focuses on the adaptation of reservoirs by combining Intrinsic Plasticity with Federated Averaging. The former is a gradientbased method for adapting the reservoir's non-linearity in a local and unsupervised manner, while the latter provides the framework for learning in the federated scenario. We evaluate our approach on real-world datasets from human monitoring, in comparison with the previous approach for federated ESNs existing in literature. Results show that adapting the reservoir with our algorithm provides a significant improvement on the performance of the global model."
Biased Edge Dropout in NIFTY for Fair Graph Representation Learning,"Federico Caldart, Luca Pasa, Luca Oneto, Alessandro Sperduti, Nicolò Navarin","1 - University of Padua Via Trieste 63 35121 Padua Italy
3 - University of Genoa Via Opera Pia 11a 16145 Genova Italy
6 - Department of Mathematics University of Padua","Graph Neural Networks (GNNs) are nowadays widely used in many real-world applications. Nonetheless, the data relationships can be a source of biases based on sensitive attributes (e.g., gender or ethnicity). Several methods have been proposed to learn fair graph node representations. In this work we extend NIFTY, an approach that exploits additional terms in the loss function based on perturbing the input data to enforce the fairness of the GNNs. In particular, we exploit a biased perturbation of the adjacency matrix of the graph able to reduce the edge homophily. We show the effectiveness of our approach in four real-world graph datasets.",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-99,2022,100.0,"Biased Edge Dropout in NIFTY for Fair Graph Representation Learning Graph Neural Networks (GNNs) are nowadays widely used in many real-world applications. Nonetheless, the data relationships can be a source of biases based on sensitive attributes (e.g., gender or ethnicity). Several methods have been proposed to learn fair graph node representations. In this work we extend NIFTY, an approach that exploits additional terms in the loss function based on perturbing the input data to enforce the fairness of the GNNs. In particular, we exploit a biased perturbation of the adjacency matrix of the graph able to reduce the edge homophily. We show the effectiveness of our approach in four real-world graph datasets."
Efficient Learning in Spiking Models,"Alexander Rast, Mario Aoun, Eleni Elia, Nigel Crook","1 - Oxford Brookes University -School of Engineering Computing, & Mathematics Wheatley Campus OX33 1HX Wheatley Oxford United Kingdom
2 - Montreal QC Canada","Spiking neural networks (SNNs) form a large class of neural models distinct from 'classical' continuous-valued networks such as multilayer perceptrons (MLPs). With event-driven dynamics and a continuoustime model, in contrast to the discrete-time model of their classical counterparts, they offer interesting advantages in representational capacity and energy consumption. However, developing models of learning for SNNs has historically proven challenging: as continuous-time systems, their dynamics are much more complex and they cannot benefit from the strong theoretical developments in MLPs such as convergence proofs and optimal gradient descent. Nor do they gain automatically from algorithmic improvements that have produced efficient matrix inversion and batch training methods. Research has focussed largely on the most extensively studied learning mechanisms in SNNs: spike-timing-dependent plasticity (STDP). Although there has been progress here, there are also notable pathologies that have often been solved with a variety of ad-hoc techniques. A relatively recent interesting development is attempts to map classical convolutional neural networks to spiking implementations, but these may not leverage all the claimed advantages of spiking. This tutorial overview looks at existing techniques for learning in SNNs and offers some thoughts for future directions.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-1,2023,100.0,"Efficient Learning in Spiking Models Spiking neural networks (SNNs) form a large class of neural models distinct from 'classical' continuous-valued networks such as multilayer perceptrons (MLPs). With event-driven dynamics and a continuoustime model, in contrast to the discrete-time model of their classical counterparts, they offer interesting advantages in representational capacity and energy consumption. However, developing models of learning for SNNs has historically proven challenging: as continuous-time systems, their dynamics are much more complex and they cannot benefit from the strong theoretical developments in MLPs such as convergence proofs and optimal gradient descent. Nor do they gain automatically from algorithmic improvements that have produced efficient matrix inversion and batch training methods. Research has focussed largely on the most extensively studied learning mechanisms in SNNs: spike-timing-dependent plasticity (STDP). Although there has been progress here, there are also notable pathologies that have often been solved with a variety of ad-hoc techniques. A relatively recent interesting development is attempts to map classical convolutional neural networks to spiking implementations, but these may not leverage all the claimed advantages of spiking. This tutorial overview looks at existing techniques for learning in SNNs and offers some thoughts for future directions."
Sun Tracking using a Weightless Q-Learning Neural Network,"Guilherme Santos Souza, Felipe França, Priscila Lima","1 - PESC/COPPE Universidade Federal do Rio de Janeiro
4 - NCE -Universidade Federal do Rio de Janeiro 3-Instituto de Telecomunicações Portugal","Photovoltaic(PV) systems are one of the leading technologies to address climate change. Tracking systems improve energy generation by moving the surface to follow the sun's position however, these methods do not ensure optimal results in cloudy environments. This article proposes a closed-loop control algorithm for tracking based on reinforcement learning and weightless neural networks, compared to an astrological model. The method was applied in a single PV array on a single-axis tracking system, simulated with PVLib. Results showed that the architecture could improve results in cloudy environments but not in a clear-sky situation, as expected for a first approach.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-100,2023,100.0,"Sun Tracking using a Weightless Q-Learning Neural Network Photovoltaic(PV) systems are one of the leading technologies to address climate change. Tracking systems improve energy generation by moving the surface to follow the sun's position however, these methods do not ensure optimal results in cloudy environments. This article proposes a closed-loop control algorithm for tracking based on reinforcement learning and weightless neural networks, compared to an astrological model. The method was applied in a single PV array on a single-axis tracking system, simulated with PVLib. Results showed that the architecture could improve results in cloudy environments but not in a clear-sky situation, as expected for a first approach."
Real-time Detection of Evoked Potentials by Deep Learning: a Case Study,"Leonardo Amato, Marta Maschietto, Alessandro Leparulo, Mattia Tambaro, Stefano Vassanelli, Alessandro Sperduti","1 - Department of Mathematics Tullio Levi-Civita""
2 - Department of Biomedical Sciences University of Padua Italy","In Local Field Potential (LFP) recordings it is hard to distinguish Evoked Potentials (EPs) from spontaneous activity. Automatic real-time detection of all EPs in a recording would enable the deployment of neuromorphic prostheses. In this paper, we present a case study involving EPs induced by stimulation of a whisker in rats. We compare the detection performance of three deep learning models: a Temporal Convolutional Network, a Recurrent Neural Network, and a Mixed model. A data augmentation technique for LFP data and a technique to learn the delay of causal models are proposed. Experimental results show that the three deep learning models are capable of detecting most EPs with few false positives, a delay of less than 100ms, and for a pruned TCN, using only 1,282 parameters.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-101,2023,100.0,"Real-time Detection of Evoked Potentials by Deep Learning: a Case Study In Local Field Potential (LFP) recordings it is hard to distinguish Evoked Potentials (EPs) from spontaneous activity. Automatic real-time detection of all EPs in a recording would enable the deployment of neuromorphic prostheses. In this paper, we present a case study involving EPs induced by stimulation of a whisker in rats. We compare the detection performance of three deep learning models: a Temporal Convolutional Network, a Recurrent Neural Network, and a Mixed model. A data augmentation technique for LFP data and a technique to learn the delay of causal models are proposed. Experimental results show that the three deep learning models are capable of detecting most EPs with few false positives, a delay of less than 100ms, and for a pruned TCN, using only 1,282 parameters."
Quantum-ready vector quantization: Prototype learning as a binary optimization problem,"Alexander Engelsberger, Thomas Villmann","1 - Mittweida University of Applied Sciences Saxon Institute for Computational Intelligence and Machine Learning Mittweida Germany
2 - Computer Science and Artificial Intelligence Bernoulli Institute for Mathematics
3 - University of Groningen Groningen The Netherlands","Quantum Computing Research proposed strategies to solve binary optimization problems. Application on current and near-term generation Hardware is possible. Even if computational benefits of the strategies are yet to be shown, we want to explore connections to prototype learning schemes. We examine cost functions for vector quantization based on data point selection and how they can be transformed into a common quadratic unconstrained binary optimization formulation (QUBO). There are different approaches for solving QUBO problems using quantum computer or quantum annealer hardware. We look at their current limits and how they might change.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-108,2023,100.0,"Quantum-ready vector quantization: Prototype learning as a binary optimization problem Quantum Computing Research proposed strategies to solve binary optimization problems. Application on current and near-term generation Hardware is possible. Even if computational benefits of the strategies are yet to be shown, we want to explore connections to prototype learning schemes. We examine cost functions for vector quantization based on data point selection and how they can be transformed into a common quadratic unconstrained binary optimization formulation (QUBO). There are different approaches for solving QUBO problems using quantum computer or quantum annealer hardware. We look at their current limits and how they might change."
Multispectral Texture Classification in Agriculture,"Mariya Shumska, Kerstin Bunte",1 - University of Groningen -Johann Bernoulli Institute for Mathematics and Computer Science Groningen the Netherlands,"Texture classification plays an important role in different domains including agricultural applications, where unmanned vehicles such as drones equipped with multispectral sensors are gaining more attention. Hence, a solution which does not require substantial computational resources is desired for real-time monitoring. In this contribution, we propose an efficient and interpretable Generalized Matrix Learning Vector Quantization based framework to classify multispectral images. We demonstrate the performance of different model designs and compare them to other benchmarks for the classification of a soil data set. Our framework yields comparable accuracy while providing interpretable results.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-110,2023,100.0,"Multispectral Texture Classification in Agriculture Texture classification plays an important role in different domains including agricultural applications, where unmanned vehicles such as drones equipped with multispectral sensors are gaining more attention. Hence, a solution which does not require substantial computational resources is desired for real-time monitoring. In this contribution, we propose an efficient and interpretable Generalized Matrix Learning Vector Quantization based framework to classify multispectral images. We demonstrate the performance of different model designs and compare them to other benchmarks for the classification of a soil data set. Our framework yields comparable accuracy while providing interpretable results."
Residual Reservoir Computing Neural Networks for Time-series Classification,"Andrea Ceni, Claudio Gallicchio",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"We introduce a novel class of Reservoir Computing (RC) models, a family of efficiently trainable Recurrent Neural Networks based on untrained connections. Aiming to improve the forward propagation of input information through time, we augment standard Echo State Networks (ESNs) with linear reservoir-skip connections modulated by an untrained orthogonal weight matrix. We analyze the mathematical properties of the resulting reservoir systems and show that the dynamical regime of the proposed class of models is controllably close to the edge of stability. Experiments on several time-series classification tasks highlight the striking performance advantage of the proposed approach over standard ESNs.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-112,2023,100.0,"Residual Reservoir Computing Neural Networks for Time-series Classification We introduce a novel class of Reservoir Computing (RC) models, a family of efficiently trainable Recurrent Neural Networks based on untrained connections. Aiming to improve the forward propagation of input information through time, we augment standard Echo State Networks (ESNs) with linear reservoir-skip connections modulated by an untrained orthogonal weight matrix. We analyze the mathematical properties of the resulting reservoir systems and show that the dynamical regime of the proposed class of models is controllably close to the edge of stability. Experiments on several time-series classification tasks highlight the striking performance advantage of the proposed approach over standard ESNs."
Single-pass uncertainty estimation with layer ensembling for regression: application to proton therapy dose prediction for head and neck cancer,"Robin Tilman, Margerie Huet-Dastarac, Ana Barragan-Montero, John Lee","1 - UCLouvain.be -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium
4 - 1-UCLouvain.be -ICTEAM Place du Levant 3 1348 Louvain-la-Neuve Belgium","We developed a new uncertainty quantification method for deep learning regression models, based on Layer Ensembles [1], which is competitive with state-of-the-art ensembling and Monte Carlo (MC) dropout techniques. The method was implemented in a UNet-like architecture and applied to predicting 3D dose maps for head and neck cancer patients who are treated with proton therapy. The new approach runs approximately 8 times faster than MC Dropout. Our statistical analysis showed no significant difference in prediction accuracy between the two different methods (p-value = 0.09). Moreover, the correlation uncertainty/error in the body is only -3%. These findings demonstrate the potential of the new method in enabling fast and accurate uncertainty quantification for regression problems and, in particular, for proton therapy dose prediction.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-115,2023,100.0,"Single-pass uncertainty estimation with layer ensembling for regression: application to proton therapy dose prediction for head and neck cancer We developed a new uncertainty quantification method for deep learning regression models, based on Layer Ensembles [1], which is competitive with state-of-the-art ensembling and Monte Carlo (MC) dropout techniques. The method was implemented in a UNet-like architecture and applied to predicting 3D dose maps for head and neck cancer patients who are treated with proton therapy. The new approach runs approximately 8 times faster than MC Dropout. Our statistical analysis showed no significant difference in prediction accuracy between the two different methods (p-value = 0.09). Moreover, the correlation uncertainty/error in the body is only -3%. These findings demonstrate the potential of the new method in enabling fast and accurate uncertainty quantification for regression problems and, in particular, for proton therapy dose prediction."
Don't waste SAM,"Nermeen Abou Baker, Uwe Handmann",1 - Dept of Computer Science Ruhr West University of Applied Sciences Lutzowstrassse 5 46236 Bottrop Germany,"Meta AI has recently released the Segment Anything Model (SAM), which demonstrates exceptional zero-shot image segmentation performance across various tasks with remarkable accuracy. Despite its inability to provide accurate segmentation across multiple research fields, SAM still serves as a valuable starting point for supporting the segmentation pipeline process, particularly for tasks that require extensive and senior skills annotations. This study aims to evaluate the generalization of SAM and fine-tuning SAM models using three waste segmentation datasets. Although they are captured from real scenes as SAM was pretrained on, these datasets present several challenges, including occlusions, deformable objects, transparency, and objects easily confused with backgrounds. In our findings, the fine-tuned SAM-ViT-H model outperforms the state-ofthe-art Zerowaste, and TACO datasets with a significant increase of +30 in IoU, and it closely approaches performance levels of TrashCan 1.0, with only a −1.44 difference. After evaluating these popular waste datasets, it became evident that fine-tuning SAM as a foundational model is a crucial step for providing better generalization for downstream waste segmentation tasks. Therefore, SAM should not be disregarded or wasted.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-116,2023,93.33333333333333,"Don't waste SAM Meta AI has recently released the Segment Anything Model (SAM), which demonstrates exceptional zero-shot image segmentation performance across various tasks with remarkable accuracy. Despite its inability to provide accurate segmentation across multiple research fields, SAM still serves as a valuable starting point for supporting the segmentation pipeline process, particularly for tasks that require extensive and senior skills annotations. This study aims to evaluate the generalization of SAM and fine-tuning SAM models using three waste segmentation datasets. Although they are captured from real scenes as SAM was pretrained on, these datasets present several challenges, including occlusions, deformable objects, transparency, and objects easily confused with backgrounds. In our findings, the fine-tuned SAM-ViT-H model outperforms the state-ofthe-art Zerowaste, and TACO datasets with a significant increase of +30 in IoU, and it closely approaches performance levels of TrashCan 1.0, with only a −1.44 difference. After evaluating these popular waste datasets, it became evident that fine-tuning SAM as a foundational model is a crucial step for providing better generalization for downstream waste segmentation tasks. Therefore, SAM should not be disregarded or wasted."
A model-based approach to meta-Reinforcement Learning: Transformers and tree search,"Brieuc Pinon, Raphaël Jungers, Jean-Charles Delvenne",1 - Department of Mathematical engineering UCLouvain Louvain-la-Neuve Belgium,"Meta-learning is a line of research that develops the ability to leverage past experiences to efficiently solve new learning problems. In the context of Reinforcement Learning (RL), meta-RL methods demonstrate a capability to learn behaviors that efficiently acquire and exploit information on a set of related tasks. The Alchemy benchmark has been proposed in  [1]  to test such methods. Alchemy features a rich structured latent space that is challenging for state-of-the-art model-free RL methods. These methods fail to learn to properly explore then exploit. We develop a model-based algorithm. We train a model whose principal block is a Transformer Decoder to fit the symbolic Alchemy environment dynamics. Then we define an online planner with the learned model using a tree search method. This algorithm significantly outperforms previously applied methods on the symbolic Alchemy problem. Our results reveal the relevance of model-based approaches with online planning to perform exploration and exploitation successfully in meta-RL.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-117,2023,100.0,"A model-based approach to meta-Reinforcement Learning: Transformers and tree search Meta-learning is a line of research that develops the ability to leverage past experiences to efficiently solve new learning problems. In the context of Reinforcement Learning (RL), meta-RL methods demonstrate a capability to learn behaviors that efficiently acquire and exploit information on a set of related tasks. The Alchemy benchmark has been proposed in  [1]  to test such methods. Alchemy features a rich structured latent space that is challenging for state-of-the-art model-free RL methods. These methods fail to learn to properly explore then exploit. We develop a model-based algorithm. We train a model whose principal block is a Transformer Decoder to fit the symbolic Alchemy environment dynamics. Then we define an online planner with the learned model using a tree search method. This algorithm significantly outperforms previously applied methods on the symbolic Alchemy problem. Our results reveal the relevance of model-based approaches with online planning to perform exploration and exploitation successfully in meta-RL."
Comparative study of synfire chain and ring attractor model for timing in the premotor nucleus in male Zebra Finches,"Fjola Hyseni, Nicolas Rougier, Arthur Leblois","1 - UMR 5293 CNRS IMN F-33000 Bordeaux France
2 - LaBRI Universite de Bordeaux Talence France
4 - Inria Bordeaux Sud-Ouest Talence France","Timing is crucial for the generation of a wide range of sensorimotor tasks. However, the underlying mechanisms remain unclear. In the order of milliseconds, premotor nucleus HV C (proper name) in male zebra finches is an outstanding model in studying the sequential neuronal activity encoding action timing. Current computational models of HV C rely on the synfire chains, which are not robust to noise and function for a narrow range of weights. An alternative with robust functional properties  [11] [5] are attractors. Here, we compare the two models and show that not only the ring attractor is more robust, but can also reproduce the brief activity bursts of HV C neurons.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-120,2023,98.30508474576271,"Comparative study of synfire chain and ring attractor model for timing in the premotor nucleus in male Zebra Finches Timing is crucial for the generation of a wide range of sensorimotor tasks. However, the underlying mechanisms remain unclear. In the order of milliseconds, premotor nucleus HV C (proper name) in male zebra finches is an outstanding model in studying the sequential neuronal activity encoding action timing. Current computational models of HV C rely on the synfire chains, which are not robust to noise and function for a narrow range of weights. An alternative with robust functional properties  [11] [5] are attractors. Here, we compare the two models and show that not only the ring attractor is more robust, but can also reproduce the brief activity bursts of HV C neurons."
Introducing Convolutional Channel-wise Goodness in Forward-Forward Learning,"Andreas Papachristodoulou, Christos Kyrkou, Stelios Timotheou, Theocharis Theocharides",1 - KIOS Research and Innovation Center of Excellence Dept of Electrical and Computer Engineering Nicosia University of Cyprus Cyprus,"This paper introduces a Channel-wise Goodness Function (CWG) that enhances the Forward-Forward through the use of Convolutional Neural Networks. The CWG function facilitates simultaneous feature extraction and separation, eliminating the requirement for constructing negative data and leading to faster convergence rates. The approach employs a two-component loss function that maximizes positive goodness and minimizes negative goodness. This enables the model to learn class-specific features to outperform recent non-backpropagation approaches on basic image classification datasets and shorten the gap with the well-established backpropagation methods.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-121,2023,100.0,"Introducing Convolutional Channel-wise Goodness in Forward-Forward Learning This paper introduces a Channel-wise Goodness Function (CWG) that enhances the Forward-Forward through the use of Convolutional Neural Networks. The CWG function facilitates simultaneous feature extraction and separation, eliminating the requirement for constructing negative data and leading to faster convergence rates. The approach employs a two-component loss function that maximizes positive goodness and minimizes negative goodness. This enables the model to learn class-specific features to outperform recent non-backpropagation approaches on basic image classification datasets and shorten the gap with the well-established backpropagation methods."
Derivative-Free Optimization Approaches for Force Polytopes Prediction,"G Laisné, J-M Salotti, N Rezzoug","1 - INRIA Center at University of Bordeaux Talence France
3 - UMR 5218 University of Bordeaux CNRS Bordeaux INP IMS F-33400 Talence France
5 - PPrime Institute CNRS University of Poitiers ENSMA 3346 Poitiers UPR, France
6 - LABRI IMB CNRS Université de Bordeaux Bordeaux INP and Conseil Régional d'Aquitaine Inria","Hand force capacities reflect an individual's ability to generate forces in all directions, considering a given upper-limb posture. These capacities are described as polytopes by means of an upper-limb musculoskeletal model. However, such a model needs to be adapted to an individual for more accuracy. The model parameter space is investigated using derivative-free algorithms which do not require the optimization function to be differentiable: genetic algorithms and SRACOS, a classificationbased algorithm. Results demonstrate that employing a genetic algorithm with a polytope representation in 26 vertices yields the most accurate prediction of force capacities in a validation posture. * The simulations in this paper were carried out using the PlaFRIM experimental testbed",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-122,2023,100.0,"Derivative-Free Optimization Approaches for Force Polytopes Prediction Hand force capacities reflect an individual's ability to generate forces in all directions, considering a given upper-limb posture. These capacities are described as polytopes by means of an upper-limb musculoskeletal model. However, such a model needs to be adapted to an individual for more accuracy. The model parameter space is investigated using derivative-free algorithms which do not require the optimization function to be differentiable: genetic algorithms and SRACOS, a classificationbased algorithm. Results demonstrate that employing a genetic algorithm with a polytope representation in 26 vertices yields the most accurate prediction of force capacities in a validation posture. * The simulations in this paper were carried out using the PlaFRIM experimental testbed"
Efficient Knowledge Aggregation Methods for Weightless Neural Networks,"Otávio Oliveira, Ana Maria De Almeida, José Sales Dias, Luís Rosário, Edson Borin, Mauricio Breternitz","1 - Instituto Universitário de Lisboa (ISCTE-IUL) ISTAR Lisbon Portugal
2 - Institute of Computing -UNICAMP Campinas, São Paulo Brazil
5 - Faculty of Medicine Lisbon University Lisbon Portugal","Weightless Neural Networks (WNN) are good candidates for Federated Learning scenarios due to their robustness and computational lightness. In this work, we show that it is possible to aggregate the knowledge of multiple WNNs using more compact data structures, such as Bloom Filters, to reduce the amount of data transferred between devices. Finally, we explore variations of Bloom Filters and found that a particular data-structure, the Count-Min Sketch (CMS), is a good candidate for aggregation. Costing at most 3% of accuracy, CMS can be up to 3x smaller when compared to previous approaches, specially for large datasets.",Classification,https://doi.org/10.14428/esann/2023.ES2023-123,2023,100.0,"Efficient Knowledge Aggregation Methods for Weightless Neural Networks Weightless Neural Networks (WNN) are good candidates for Federated Learning scenarios due to their robustness and computational lightness. In this work, we show that it is possible to aggregate the knowledge of multiple WNNs using more compact data structures, such as Bloom Filters, to reduce the amount of data transferred between devices. Finally, we explore variations of Bloom Filters and found that a particular data-structure, the Count-Min Sketch (CMS), is a good candidate for aggregation. Costing at most 3% of accuracy, CMS can be up to 3x smaller when compared to previous approaches, specially for large datasets."
On the Limitations of Model Stealing with Uncertainty Quantification Models,"David Pape, Sina Däubener, Thorsten Eisenhofer, Antonio Cinà, Lea Schönherr","1 - CISPA Helmholtz Center for Information Security
2 - Ruhr University Bochum","Model stealing aims at inferring a victim model's functionality at a fraction of the original training cost. While the goal is clear, in practice the model's architecture, weight dimension, and original training data can not be determined exactly, leading to mutual uncertainty during stealing. In this work, we explicitly tackle this uncertainty by generating multiple possible networks and combining their predictions to improve the quality of the stolen model. For this, we compare five popular uncertainty quantification models in a model stealing task. Surprisingly, our results indicate that the considered models only lead to marginal improvements in terms of label agreement (i.e., fidelity) to the stolen model. To find the cause of this, we inspect the diversity of the model's prediction by looking at the prediction variance as a function of training iterations. We realize that during training, the models tend to have similar predictions, indicating that the network diversity we wanted to leverage using uncertainty quantification models is not (high) enough for improvements on the model stealing task.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-125,2023,100.0,"On the Limitations of Model Stealing with Uncertainty Quantification Models Model stealing aims at inferring a victim model's functionality at a fraction of the original training cost. While the goal is clear, in practice the model's architecture, weight dimension, and original training data can not be determined exactly, leading to mutual uncertainty during stealing. In this work, we explicitly tackle this uncertainty by generating multiple possible networks and combining their predictions to improve the quality of the stolen model. For this, we compare five popular uncertainty quantification models in a model stealing task. Surprisingly, our results indicate that the considered models only lead to marginal improvements in terms of label agreement (i.e., fidelity) to the stolen model. To find the cause of this, we inspect the diversity of the model's prediction by looking at the prediction variance as a function of training iterations. We realize that during training, the models tend to have similar predictions, indicating that the network diversity we wanted to leverage using uncertainty quantification models is not (high) enough for improvements on the model stealing task."
Improved Interpretation of Feature Relevances: Iterated Relevance Matrix Analysis (IRMA),"Sofie Lövdal, Michael Biehl","1 - Computer Science and Artificial Intelligence Univ. of Groningen -Bernoulli Inst. for Mathematics Nijenborgh 9 9747 AG Groningen The Netherlands
2 - Dept. of Nuclear Medicine and Molecular Imaging -University Medical Center Groningen (UMCG) Hanzeplein 1 9713 GZ Groningen The Netherlands","We introduce and investigate the iterated application of Generalized Matrix Relevance Learning for the analysis of feature relevances in classification problems. The suggested Iterated Relevance Matrix Analysis (IRMA), identifies a linear subspace representing the classification specific information of the considered data sets in feature space using Generalized Matrix Learning Vector Quantization. By iteratively determining a new discriminative direction while projecting out all previously identified ones, all features carrying relevant information about the classification can be found, facilitating a detailed analysis of feature relevances. Moreover, IRMA can be used to generate improved low-dimensional representations and visualizations of labeled data sets. * S.L. acknowledges support by Stichting ParkinsonFonds.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-127,2023,100.0,"Improved Interpretation of Feature Relevances: Iterated Relevance Matrix Analysis (IRMA) We introduce and investigate the iterated application of Generalized Matrix Relevance Learning for the analysis of feature relevances in classification problems. The suggested Iterated Relevance Matrix Analysis (IRMA), identifies a linear subspace representing the classification specific information of the considered data sets in feature space using Generalized Matrix Learning Vector Quantization. By iteratively determining a new discriminative direction while projecting out all previously identified ones, all features carrying relevant information about the classification can be found, facilitating a detailed analysis of feature relevances. Moreover, IRMA can be used to generate improved low-dimensional representations and visualizations of labeled data sets. * S.L. acknowledges support by Stichting ParkinsonFonds."
"Multimodal Recognition of Valence, Arousal and Dominance via Late-Fusion of Text, Audio and Facial Expressions","Annette Rios, Uwe Reichel, Chirag Bhuvaneshwara, Panagiotis Filntisis, Petros Maragos, Felix Burkhardt, Florian Eyben, Björn Schuller, Fabrizio Nunnari, Sarah Ebling","1 - Department of Computational Linguistics University of Zurich Switzerland
2 - Germany
3 - German Research Center for Artificial Intelligence (DFKI) Saarland Informatics Campus D3
4 - ATHENA Research Center Greece","We present an approach for the prediction of valence, arousal, and dominance of people communicating via text/audio/video streams for a translation from and to sign languages. The approach consists of the fusion of the output of three CNN-based models dedicated to the analysis of text, audio, and facial expressions. Our experiments show that any combination of two or three modalities increases prediction performance for valence and arousal.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-128,2023,100.0,"Multimodal Recognition of Valence, Arousal and Dominance via Late-Fusion of Text, Audio and Facial Expressions We present an approach for the prediction of valence, arousal, and dominance of people communicating via text/audio/video streams for a translation from and to sign languages. The approach consists of the fusion of the output of three CNN-based models dedicated to the analysis of text, audio, and facial expressions. Our experiments show that any combination of two or three modalities increases prediction performance for valence and arousal."
Simultaneous failures classification in a predictive maintenance case,"Antoine Hubermont, Elio Tuci, Nicola De Quattro","1 - UNamur -Computer Science faculty Rue Grandgagnage 21 5000 Namur Belgium
2 - les Hêtres 2 6890 Libin Telespazio Belgium, Belgium","In industry 4.0, Machine Learning coupled with sensors monitoring leverages new ways to optimise maintenance strategies. In a predictive maintenance case, failure diagnoses are an excellent way to prevent any breakdowns. Up to now, failure diagnoses are focused on the classification of only one failure among many (multi-label classification), even if multiple failures can occur simultaneously. This study proposes an extension to classify simultaneous failures with the most popular classification methods such as random forests or artificial neural networks. Validated on a public predictive maintenance dataset, our methodology achieved classification with equal or best accuracy compared to multi-label classification.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-129,2023,100.0,"Simultaneous failures classification in a predictive maintenance case In industry 4.0, Machine Learning coupled with sensors monitoring leverages new ways to optimise maintenance strategies. In a predictive maintenance case, failure diagnoses are an excellent way to prevent any breakdowns. Up to now, failure diagnoses are focused on the classification of only one failure among many (multi-label classification), even if multiple failures can occur simultaneously. This study proposes an extension to classify simultaneous failures with the most popular classification methods such as random forests or artificial neural networks. Validated on a public predictive maintenance dataset, our methodology achieved classification with equal or best accuracy compared to multi-label classification."
Combining Stochastic Explainers and Subgraph Neural Networks can Increase Expressivity and Interpretability,"Indro Spinelli, Michele Guerra, Filippo Bianchi, Simone Scardapane","1 - Sapienza University of Rome a -DI Dept Via Salaria 113 00198 Rome Italy
2 - Dept. of Mathematics and Statistics Hansine Hansens veg 18 UiT the Arctic University of Norway 9019 Tromsø Norway
5 - DIET Dept Via Eudossiana 18 00184 Rome Italy","Subgraph-enhanced graph neural networks (SGNN) can increase the expressive power of the standard message-passing framework. This model family represents each graph as a collection of subgraphs, generally extracted by random sampling or with hand-crafted heuristics. Our key observation is that by selecting ""meaningful"" subgraphs, besides improving the expressivity of a GNN, it is also possible to obtain interpretable results. For this purpose, we introduce a novel framework that jointly predicts the class of the graph and a set of explanatory sparse subgraphs, which can be analyzed to understand the decision process of the classifier. The subgraphs produced by our framework allow to achieve comparable performance in terms of accuracy, with the additional benefit of providing explanations.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-13,2023,100.0,"Combining Stochastic Explainers and Subgraph Neural Networks can Increase Expressivity and Interpretability Subgraph-enhanced graph neural networks (SGNN) can increase the expressive power of the standard message-passing framework. This model family represents each graph as a collection of subgraphs, generally extracted by random sampling or with hand-crafted heuristics. Our key observation is that by selecting ""meaningful"" subgraphs, besides improving the expressivity of a GNN, it is also possible to obtain interpretable results. For this purpose, we introduce a novel framework that jointly predicts the class of the graph and a set of explanatory sparse subgraphs, which can be analyzed to understand the decision process of the classifier. The subgraphs produced by our framework allow to achieve comparable performance in terms of accuracy, with the additional benefit of providing explanations."
Hybrid modelling of dynamic anaerobic digestion process in full-scale with LSTM NN and BMP measurements,"Alberto Meola, Sören Weinrich","1 - Faculty of Mathematics and Computer Science Leipzig University Augustusplatz 10 04109 Leipzig Germany
2 - Faculty of Energy • Building Servi-ces • Environmental Engineering Münster University of Applied Sciences Stegerwaldstraße 39 48565 Steinfurt Germany
3 - Bio-chemical Conversion Department Deutsches Biomasseforschungszentrum gemeinnützige GmbH 1 -DBFZ, Torgauer Straße 116 04347 Leipzig Germany","Machine learning algorithms allow an accurate description of the anaerobic digestion process, but they are not applied in full-scale reactors due to the lack of physicochemical reliabilty. A hybrid model combining biomethane potential (BMP) tests data and a long short-term memory (LSTM) neural network was developed for providing previous knowledge to the neural network and improving performances. Results show that the best model configuration can predict the methane yield with a 6-hours resolution 1 day in advance with a Root Mean Square Scaled Error (RMSSE) of 36%, compared to an RMSSE of 41% obtained by the pure LSTM model configuration.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-133,2023,100.0,"Hybrid modelling of dynamic anaerobic digestion process in full-scale with LSTM NN and BMP measurements Machine learning algorithms allow an accurate description of the anaerobic digestion process, but they are not applied in full-scale reactors due to the lack of physicochemical reliabilty. A hybrid model combining biomethane potential (BMP) tests data and a long short-term memory (LSTM) neural network was developed for providing previous knowledge to the neural network and improving performances. Results show that the best model configuration can predict the methane yield with a 6-hours resolution 1 day in advance with a Root Mean Square Scaled Error (RMSSE) of 36%, compared to an RMSSE of 41% obtained by the pure LSTM model configuration."
Feature Selection for Multi-label Classification with Minimal Learning Machine,"Joakim Linja, Joonas Hämäläinen, Tommi Kärkkäinen",1 - Faculty of Information Technology University of Jyväskylä University of Jyväskylä P.O. Box 35 FI-40014 Finland,"Multi-label classification problems, where more than one class can be active in a single instance, generalize the conventional single-label cases. In this article, we continue the research track documented in  [1, 2] , where the Minimal Learning Machine (MLM) was generalized into multilabel problems with competitive results compared to other state-of-the-art techniques. Our current interest is to consider whether we can reduce the complexity of the distance-based regression model in the MLM by performing feature selection. For this purpose, an existing feature selection filter technique is generalized to multi-label problems. Experimental results confirm that the proposed technique provides a useful ranking, which allows one to reduce the number of active features without jeopardizing the quality of the multi-label MLM classifier.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-134,2023,100.0,"Feature Selection for Multi-label Classification with Minimal Learning Machine Multi-label classification problems, where more than one class can be active in a single instance, generalize the conventional single-label cases. In this article, we continue the research track documented in  [1, 2] , where the Minimal Learning Machine (MLM) was generalized into multilabel problems with competitive results compared to other state-of-the-art techniques. Our current interest is to consider whether we can reduce the complexity of the distance-based regression model in the MLM by performing feature selection. For this purpose, an existing feature selection filter technique is generalized to multi-label problems. Experimental results confirm that the proposed technique provides a useful ranking, which allows one to reduce the number of active features without jeopardizing the quality of the multi-label MLM classifier."
Sparse Nyström Approximation for Non-Vectorial Data Using Class-informed Landmark Selection,"Maximilian Münch, Katrin Bohnsack, Alexander Engelsberger, Frank-Michael Schleif, Thomas Villmann","1 - Center for Artificial Intelligence and Robotics (CAIRO) University of Applied Sciences Würzburg-Schweinfurt Würzburg Germany
2 - Computer Science and Artificial Intelligence Bernoulli Institute for Mathematics
3 - University of Groningen Groningen The Netherlands
6 - Saxon Institute for Computational Intelligence and Machine Learning Mittweida University of Applied Sciences Mittweida Germany","We introduce an efficient approach for supervised landmark selection in sparse Nyström approximation of kernel matrices. Our method converts structured non-vectorial input data such as graphs or text into a vectorial dissimilarity representation, enabling class-informed landmark identification through prototype-based learning. Experimental results show competitive approximation quality compared to existing strategies and demonstrate the positive effect of integrating class information into the selection process of Nyström landmarks making our approach an efficient and versatile solution for large-scale kernel learning.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-136,2023,100.0,"Sparse Nyström Approximation for Non-Vectorial Data Using Class-informed Landmark Selection We introduce an efficient approach for supervised landmark selection in sparse Nyström approximation of kernel matrices. Our method converts structured non-vectorial input data such as graphs or text into a vectorial dissimilarity representation, enabling class-informed landmark identification through prototype-based learning. Experimental results show competitive approximation quality compared to existing strategies and demonstrate the positive effect of integrating class information into the selection process of Nyström landmarks making our approach an efficient and versatile solution for large-scale kernel learning."
An Alternating Minimization Algorithm with Trajectory for Direct Exoplanet Detection,"Hazan Daglayan, Simon Vary, P.-A Absil",1 - ICTEAM Institute UCLouvain 1348 Louvain-la-Neuve Belgium,"Effective image post-processing algorithms are vital for the successful direct imaging of exoplanets. Existing algorithms use techniques based on a low-rank approximation to separate the rotating planet signal from the quasi-static speckles. In this paper, we present a novel approach that iteratively finds the planet's flux and the low-rank approximation of quasi-static signals, strengthening the existing model based on lowrank approximations. We implement the algorithm with two different norms and test it on data, showing improvement over classical low-rank approaches. Our results highlight the benefits of iterative refinement of low-rank approximation to enhance planet detection.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-137,2023,100.0,"An Alternating Minimization Algorithm with Trajectory for Direct Exoplanet Detection Effective image post-processing algorithms are vital for the successful direct imaging of exoplanets. Existing algorithms use techniques based on a low-rank approximation to separate the rotating planet signal from the quasi-static speckles. In this paper, we present a novel approach that iteratively finds the planet's flux and the low-rank approximation of quasi-static signals, strengthening the existing model based on lowrank approximations. We implement the algorithm with two different norms and test it on data, showing improvement over classical low-rank approaches. Our results highlight the benefits of iterative refinement of low-rank approximation to enhance planet detection."
Exploring the Importance of Sign Language Phonology for a Deep Neural Network,"Javier Martínez Rodríguez, Martha Larson, Louis Ten Bosch","1 - Center for Language Studies Radboud University Netherlands
2 - https://github.com/JavierMartnz MindTheLinguisticGap","We conduct an initial investigation to gain insight into whether a deep neural network learns phonological aspects of sign language when classifying video recordings of isolated signs from a continuous signing scenario. We train a series of neural networks to distinguish pairs of signs in Dutch Sign Language, controlling the phonological difference between the signs in each pair. Our results suggest that the intrinsic dimension of the final hidden layer of a network is surprisingly insensitive to the phonological difference between the signs in a pair. However, the ability of the network to discriminate two signs shows a clear trend towards increasing with increasing phonological distinctiveness. 
 Related Work Isolated sign language recognition. Sign language recognition (SLR) is the problem of recognizing and identifying a particular sign in a video clip. In this paper, we study isolated SLR, also known as word-level SLR, which",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-138,2023,100.0,"Exploring the Importance of Sign Language Phonology for a Deep Neural Network We conduct an initial investigation to gain insight into whether a deep neural network learns phonological aspects of sign language when classifying video recordings of isolated signs from a continuous signing scenario. We train a series of neural networks to distinguish pairs of signs in Dutch Sign Language, controlling the phonological difference between the signs in each pair. Our results suggest that the intrinsic dimension of the final hidden layer of a network is surprisingly insensitive to the phonological difference between the signs in a pair. However, the ability of the network to discriminate two signs shows a clear trend towards increasing with increasing phonological distinctiveness. 
 Related Work Isolated sign language recognition. Sign language recognition (SLR) is the problem of recognizing and identifying a particular sign in a video clip. In this paper, we study isolated SLR, also known as word-level SLR, which"
Don't skip the skips: autoencoder skip connections improve latent representation discrepancy for anomaly detection,"Anne-Sophie Collin, Cyril De Bodt, Dounia Mulders, Christophe De Vleeschouwer",1 - UCLouvain -ICTEAM/ELEN,"Reconstruction-based anomaly detection typically relies on the reconstruction of a defect-free output from an input image. Such reconstruction can be obtained by training an autoencoder to reconstruct clean images from inputs corrupted with a synthetic defect. Previous works have shown that adopting an autoencoder with skip connections improves reconstruction sharpness. However, it remains unclear how skip connections aect the latent representations learned during training. Here, we compare internal representations of autoencoders with and without skip connections. Experiments over the MVTec AD dataset reveal that skip connections enable the autoencoder latent representations to intrinsically discriminate between clean and defective images.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-139,2023,100.0,"Don't skip the skips: autoencoder skip connections improve latent representation discrepancy for anomaly detection Reconstruction-based anomaly detection typically relies on the reconstruction of a defect-free output from an input image. Such reconstruction can be obtained by training an autoencoder to reconstruct clean images from inputs corrupted with a synthetic defect. Previous works have shown that adopting an autoencoder with skip connections improves reconstruction sharpness. However, it remains unclear how skip connections aect the latent representations learned during training. Here, we compare internal representations of autoencoders with and without skip connections. Experiments over the MVTec AD dataset reveal that skip connections enable the autoencoder latent representations to intrinsically discriminate between clean and defective images."
Graph for Transformer Feature: A New Approach for Face Anti-Spoofing,"Quoc-Huy Trinh, Trong-Hieu Nguyen Mau, Xuan-Mao Nguyen, Minh-Van Nguyen, Hai-Dang Nguyen","1 - University of Science VNU-HCM Ho Chi Minh city Vietnam
2 - VNG Corporation Ho Chi Minh city Vietnam
3 - Software Engineering Laboratory","Face recognition is popular nowadays, however, Face antispoofing (FAS) poses a significant challenge for recognition systems due to the threat of external attacks. While many deep learning methods have been proposed to address this issue, they often face challenges in industry settings. Experiments found that patch extraction modules, such as the Vision Transformer and Swin Transformer, are effective for FAS in single images and perform well in industrial environments. From this point, we propose a model that leverages Transformer features and Graph Neural Networks to learn global information and identify correlations between patch features, which are critical for FAS.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-14,2023,100.0,"Graph for Transformer Feature: A New Approach for Face Anti-Spoofing Face recognition is popular nowadays, however, Face antispoofing (FAS) poses a significant challenge for recognition systems due to the threat of external attacks. While many deep learning methods have been proposed to address this issue, they often face challenges in industry settings. Experiments found that patch extraction modules, such as the Vision Transformer and Swin Transformer, are effective for FAS in single images and perform well in industrial environments. From this point, we propose a model that leverages Transformer features and Graph Neural Networks to learn global information and identify correlations between patch features, which are critical for FAS."
Evaluating Curriculum Learning Strategies for Pancreatic Cancer Prediction,"David Vázquez-Lema, Elena Hernández-Pereira, Eduardo Mosqueira-Rey",1 - Universidade da Coruña (CITIC) Campus de Elviña 15071 A Coruña Spain,"In this work we applied Curriculum Learning (CL) to evaluate the performance of a machine learning (ML) model for pancreatic cancer prediction. As the dataset required it, we applied missing value imputation and data augmentation techniques. We compare different curriculum configurations in terms of pacing functions and we perform different experiments concluding that CL helps to train the ML model. Nevertheless, not all the configurations behave in the same way, and the best results were obtained when organising the curriculum in increasing levels of difficulty following exponential pacing.",Classification,https://doi.org/10.14428/esann/2023.ES2023-141,2023,100.0,"Evaluating Curriculum Learning Strategies for Pancreatic Cancer Prediction In this work we applied Curriculum Learning (CL) to evaluate the performance of a machine learning (ML) model for pancreatic cancer prediction. As the dataset required it, we applied missing value imputation and data augmentation techniques. We compare different curriculum configurations in terms of pacing functions and we perform different experiments concluding that CL helps to train the ML model. Nevertheless, not all the configurations behave in the same way, and the best results were obtained when organising the curriculum in increasing levels of difficulty following exponential pacing."
Functional Resonant Synaptic Clusters for Decoding Time-Structured Spike Trains,"Nigel Crook, Alex Rast, Eleni Elia, Mario Aoun","1 - Oxford Brookes University UK
4 - Montreal QC Canada","Biological neurons communicate with each other using two broad categories of spike event coding: rate-based and temporal. Rate-based coding communicates analog information on a continuous scale through the intensity of bursts of spikes while temporal coding relies on the timing of spike events. It has been shown that temporal coding has higher information capacity than rate based coding, but is much more challenging to model due to difficulties estimating spike-time statistics. In this paper we demonstrate how history dependent NMDA-modulated 'resonant' synapses organised in 'functional synaptic clusters' provide a robust mechanism for decoding temporally structured spike trains.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-142,2023,100.0,"Functional Resonant Synaptic Clusters for Decoding Time-Structured Spike Trains Biological neurons communicate with each other using two broad categories of spike event coding: rate-based and temporal. Rate-based coding communicates analog information on a continuous scale through the intensity of bursts of spikes while temporal coding relies on the timing of spike events. It has been shown that temporal coding has higher information capacity than rate based coding, but is much more challenging to model due to difficulties estimating spike-time statistics. In this paper we demonstrate how history dependent NMDA-modulated 'resonant' synapses organised in 'functional synaptic clusters' provide a robust mechanism for decoding temporally structured spike trains."
Coordinate descent on the Stiefel manifold for deep neural network training,"Estelle Massart, Vinayak Abrol","1 - IIIT Delhi -CSE Department Infosys Centre for AI R&D Block IIIT Delhi India
2 - 1-UCLouvain -ICTEAM Avenue Georges Lemaître 4 B-1348 Louvain-la-Neuve Belgium","To alleviate the cost incurred by orthogonality constraints in optimization and model training, we propose a stochastic coordinate descent algorithm on the Stiefel manifold. We compute expressions for geodesics on the Stiefel manifold with initial velocity aligned with coordinates of the tangent space and show that, analogously to the orthogonal group, iterate updates of coordinate descent methods can be efficiently implemented in terms of multiplications by Givens matrices. We illustrate our proposed algorithm on deep neural network training.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-143,2023,100.0,"Coordinate descent on the Stiefel manifold for deep neural network training To alleviate the cost incurred by orthogonality constraints in optimization and model training, we propose a stochastic coordinate descent algorithm on the Stiefel manifold. We compute expressions for geodesics on the Stiefel manifold with initial velocity aligned with coordinates of the tangent space and show that, analogously to the orthogonal group, iterate updates of coordinate descent methods can be efficiently implemented in terms of multiplications by Givens matrices. We illustrate our proposed algorithm on deep neural network training."
Temporal Ensembling-based Deep k-Nearest Neighbours for Learning with Noisy Labels,Alexandra-Ioana Albu,1 - Department of Computer Science Babeş-Bolyai University 1 M. Kogalniceanu Street -Cluj-Napoca Romania,"Label noise can significantly affect the generalization of deep neural networks. Nevertheless, it is omnipresent in real world applications. This paper introduces an approach for identifying the samples from a dataset which are likely to have correct annotations. The proposed method computes the agreement of a sample with its nearest neighbours retrieved from the feature space provided by a neural network. We introduce a temporal ensembling strategy which takes into account the agreement scores obtained by a sample during previous training epochs. The superiority of our approach over several baselines is shown on image classification datasets.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-144,2023,100.0,"Temporal Ensembling-based Deep k-Nearest Neighbours for Learning with Noisy Labels Label noise can significantly affect the generalization of deep neural networks. Nevertheless, it is omnipresent in real world applications. This paper introduces an approach for identifying the samples from a dataset which are likely to have correct annotations. The proposed method computes the agreement of a sample with its nearest neighbours retrieved from the feature space provided by a neural network. We introduce a temporal ensembling strategy which takes into account the agreement scores obtained by a sample during previous training epochs. The superiority of our approach over several baselines is shown on image classification datasets."
An Empirical Study of Over-Parameterized Neural Models based on Graph Random Features,"Nicolò Navarin, Luca Pasa, Luca Oneto, Alessandro Sperduti","1 - University of Padua -Via Trieste 63 35121 Padua -Italy
3 - University of Genoa Via Opera Pia 11a 16145 Genoa Italy
5 - University of Trento -Via Sommarive 9 I-38123 Povo Italy","In this paper, we investigate neural models based on graph random features. In particular, we aim to understand when over-parameterization, namely generating more features than the ones necessary to interpolate, may be beneficial for the generalization of the resulting models. Exploiting the algorithmic stability framework and based on empirical evidences from several commonly adopted graph datasets, we will shed some light on this issue.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-145,2023,100.0,"An Empirical Study of Over-Parameterized Neural Models based on Graph Random Features In this paper, we investigate neural models based on graph random features. In particular, we aim to understand when over-parameterization, namely generating more features than the ones necessary to interpolate, may be beneficial for the generalization of the resulting models. Exploiting the algorithmic stability framework and based on empirical evidences from several commonly adopted graph datasets, we will shed some light on this issue."
"Nesterov momentum and gradient normalization to improve t-SNE convergence and neighborhood preservation, without early exaggeration","Pierre Lambert, John Lee, Edouard Couplet, Cyril De Bodt","1 - ICTEAM/ELEN Place du Levant Université catholique de Louvain
3 - Université catholique de Louvain -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium
6 - L5.03.02, 1348 Louvain-la-Neuve Belgium",Student t-distributed stochastic neighbor embedding (t-SNE) finds low-dimensional data representations allowing visual exploration of data sets. t-SNE minimises a cost function with a custom two-phase gradient descent. The first phase is called early exaggeration and involves a hyper-parameter whose value can be tricky and time-consuming to set. This paper proposes another way to optimise the cost function without early exaggeration. Empirical evaluation shows that the proposed method of optimization converges faster and yields competitive results in terms of neighborhood preservation.,Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-147,2023,100.0,"Nesterov momentum and gradient normalization to improve t-SNE convergence and neighborhood preservation, without early exaggeration Student t-distributed stochastic neighbor embedding (t-SNE) finds low-dimensional data representations allowing visual exploration of data sets. t-SNE minimises a cost function with a custom two-phase gradient descent. The first phase is called early exaggeration and involves a hyper-parameter whose value can be tricky and time-consuming to set. This paper proposes another way to optimise the cost function without early exaggeration. Empirical evaluation shows that the proposed method of optimization converges faster and yields competitive results in terms of neighborhood preservation."
On Feature Removal for Explainability in Dynamic Environments,"Fabian Fumagalli, Maximilian Muschalik, Eyke Hüllermeier, Barbara Hammer","1 - Bielefeld University D-33615 Bielefeld Germany
2 - -LMU Munich D-80539 Munich Germany","Removal-based explanations are a general framework to provide feature importance scores, where feature removal, i.e. restricting a model on a subset of features, is a central component. While many machine learning applications require dynamic modeling environments, where distributions and models change over time, removal-based explanations and feature removal have mainly been considered in a static batch learning environment. Recently, an interventional and observational perturbation method was presented that allows to remove features efficiently in dynamic learning environments with concept drift. In this paper, we compare these two algorithms on two synthetic data streams. We showcase how both yield substantially different explanations when features are correlated and provide guidance on the choice based on the application.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-148,2023,100.0,"On Feature Removal for Explainability in Dynamic Environments Removal-based explanations are a general framework to provide feature importance scores, where feature removal, i.e. restricting a model on a subset of features, is a central component. While many machine learning applications require dynamic modeling environments, where distributions and models change over time, removal-based explanations and feature removal have mainly been considered in a static batch learning environment. Recently, an interventional and observational perturbation method was presented that allows to remove features efficiently in dynamic learning environments with concept drift. In this paper, we compare these two algorithms on two synthetic data streams. We showcase how both yield substantially different explanations when features are correlated and provide guidance on the choice based on the application."
Enhancing Evolution Strategies with Evolution Path Bias,Oliver Kramer,1 - Computational Intelligence Lab Department of Computer Science Carl-von-Ossietzky University of Oldenburg 26111 Oldenburg Germany,"Evolution Strategies (ES) have emerged as a powerful and effective method for optimization and reinforcement learning tasks, largely due to their simplicity and scalability. However, current ES techniques can be limited in their capacity to quickly converge on the optimal solution. In this paper, we propose a novel approach to enhance ES by incorporating an evolution path-informed bias in the Gaussian mutation operator. This bias is designed to facilitate faster descent on decreasing functions. Our method leverages the evolution path, which represents the historical search directions, to intelligently bias the Gaussian mutation. By doing so, it enables the algorithm to be more sensitive to the underlying function's structure and adaptively exploit this information for more efficient exploration. We validate our approach through experiments on three benchmark functions: a linear function, we call Downhill function here, a Parabolic ridge, and a Sphere function. The results demonstrate that our evolution path-informed bias significantly accelerates convergence on in most of the cases.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-15,2023,100.0,"Enhancing Evolution Strategies with Evolution Path Bias Evolution Strategies (ES) have emerged as a powerful and effective method for optimization and reinforcement learning tasks, largely due to their simplicity and scalability. However, current ES techniques can be limited in their capacity to quickly converge on the optimal solution. In this paper, we propose a novel approach to enhance ES by incorporating an evolution path-informed bias in the Gaussian mutation operator. This bias is designed to facilitate faster descent on decreasing functions. Our method leverages the evolution path, which represents the historical search directions, to intelligently bias the Gaussian mutation. By doing so, it enables the algorithm to be more sensitive to the underlying function's structure and adaptively exploit this information for more efficient exploration. We validate our approach through experiments on three benchmark functions: a linear function, we call Downhill function here, a Parabolic ridge, and a Sphere function. The results demonstrate that our evolution path-informed bias significantly accelerates convergence on in most of the cases."
Improved the locally aligned ant technique (LAAT) strategy to recover manifolds embedded in strong noise,"Felipe Contreras, Reynier Peletier, Kerstin Bunte","1 - University of Groningen -Kapteyn Astronomical Institute Broerstraat 5 9712 CP Groningen Netherlands
2 - Computer Science and Artificial Intelligence Broerstraat 5 University of Groningen -Bernoulli Institute for Mathematics 9712 CP Groningen Netherlands","The automatic detection, extraction, and modeling of manifold structures from large data-sets are of great interest, especially in Astronomy. Existing manifold learning techniques for feature extraction in Computer Vision, Bioinformatics and signal denoising typically fail in astronomical scenarios, since they mostly assume low levels of noise and one manifold of fixed dimension. Therefore, the Locally Aligned Ant Technique (LAAT) was recently proposed to discover multiple faint and noisy structures of varying dimensionality embedded in large amounts of background noise. Although it demonstrates excellent results in multiple scenarios, its performance depends on global thresholding and user tuning. Here, we improve LAAT and replace the global threshold by a flexible local strategy.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-151,2023,100.0,"Improved the locally aligned ant technique (LAAT) strategy to recover manifolds embedded in strong noise The automatic detection, extraction, and modeling of manifold structures from large data-sets are of great interest, especially in Astronomy. Existing manifold learning techniques for feature extraction in Computer Vision, Bioinformatics and signal denoising typically fail in astronomical scenarios, since they mostly assume low levels of noise and one manifold of fixed dimension. Therefore, the Locally Aligned Ant Technique (LAAT) was recently proposed to discover multiple faint and noisy structures of varying dimensionality embedded in large amounts of background noise. Although it demonstrates excellent results in multiple scenarios, its performance depends on global thresholding and user tuning. Here, we improve LAAT and replace the global threshold by a flexible local strategy."
Fine-Tuning is not (Always) Overfitting Artifacts *,"Jeremie Bogaert, Emmanuel Jean, Cyril De Bodt, François-Xavier Standaert, Icteam Uclouvain -Belgium, Multitel -Belgium",Unknown,"Since their release, transformers, and in particular fine-tuned transformers are widely used for text-related classification tasks. However, only a few studies try to understand how fine-tuning actually works and existing alternatives, such as feature-based transformers, are often overlooked. In this work, we study a French transformer model, Camem-BERT, to compare the fine-tuned and feature-based approaches in terms of their performances, interpretability and embedding space. We observe that while fine-tuning has a limited impact on performances in our case study, it significantly affects the intepretability (by better isolating words that are intuitively connected to the classification task) and embedding space (by summarizing the majority of the relevant information into a fewer dimensions) of the results. We conclude by highlighting open questions regarding the generalization potential of fine-tuned embeddings.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-152,2023,62.0,"Fine-Tuning is not (Always) Overfitting Artifacts * Since their release, transformers, and in particular fine-tuned transformers are widely used for text-related classification tasks. However, only a few studies try to understand how fine-tuning actually works and existing alternatives, such as feature-based transformers, are often overlooked. In this work, we study a French transformer model, Camem-BERT, to compare the fine-tuned and feature-based approaches in terms of their performances, interpretability and embedding space. We observe that while fine-tuning has a limited impact on performances in our case study, it significantly affects the intepretability (by better isolating words that are intuitively connected to the classification task) and embedding space (by summarizing the majority of the relevant information into a fewer dimensions) of the results. We conclude by highlighting open questions regarding the generalization potential of fine-tuned embeddings."
On the number of latent representations in deep neural networks for tabular data,"Edouard Couplet, Pierre Lambert, Michel Verleysen, John Lee, Cyril De Bodt","1 - UCLouvain -ICTEAM ELEN
5 - UCLouvain -IREC/MIRO","Most recent deep neural network architectures for tabular data operate at the feature level and process multiple latent representations simultaneously. While the dimension of these representations is set through hyper-parameter tuning, their number is typically fixed and equal to the number of features in the original data. In this paper, we explore the impact of varying the number of latent representations on model performance. Our results suggest that increasing the number of representations beyond the number of features can help capture more complex interactions, whereas reducing their number can improve performance in cases where there are many uninformative features.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-156,2023,100.0,"On the number of latent representations in deep neural networks for tabular data Most recent deep neural network architectures for tabular data operate at the feature level and process multiple latent representations simultaneously. While the dimension of these representations is set through hyper-parameter tuning, their number is typically fixed and equal to the number of features in the original data. In this paper, we explore the impact of varying the number of latent representations on model performance. Our results suggest that increasing the number of representations beyond the number of features can help capture more complex interactions, whereas reducing their number can improve performance in cases where there are many uninformative features."
Robust Feature Selection and Robust Training to Cope with Hyperspectral Sensor Shifts,"Valerie Vaquet, Johannes Brinkrolf, Barbara Hammer",1 - Machine Learning Group Bielefeld University Bielefeld Germany,"Hyperspectral imaging is a suitable measurement tool across domains. However, when combined with machine learning techniques, frequently intensity and transversal shifts hinder the transfer between different sensors and settings. Established approaches focus on eliminating sensor shifts in the data or recalibrating sensors. In this contribution, we target the training procedure, propose robust training, and derive a robust feature selection strategy that can cope with multiple shift dynamics at the same time. We evaluate our approaches experimentally on artificial and real-world datasets.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-158,2023,100.0,"Robust Feature Selection and Robust Training to Cope with Hyperspectral Sensor Shifts Hyperspectral imaging is a suitable measurement tool across domains. However, when combined with machine learning techniques, frequently intensity and transversal shifts hinder the transfer between different sensors and settings. Established approaches focus on eliminating sensor shifts in the data or recalibrating sensors. In this contribution, we target the training procedure, propose robust training, and derive a robust feature selection strategy that can cope with multiple shift dynamics at the same time. We evaluate our approaches experimentally on artificial and real-world datasets."
Knowledge Distillation for Anomaly Detection,"Adrian Pol, Ekaterina Govorkova, Sonja Grönroos, Nadezda Chernyavskaya, Philip Harris, Maurizio Pierini, Isobel Ojalvo, Peter Elmer","1 - Princeton University USA
2 - Massachusetts Inst. of Technology USA
3 - University of Helsinki Finland
4 - European Organization for Nuclear Research (CERN) Switzerland","Unsupervised deep learning techniques are widely used to identify anomalous behaviour. The performance of such methods is a product of the amount of training data and the model size. However, the size is often a limiting factor for the deployment on resource-constrained devices. We present a novel procedure based on knowledge distillation for compressing an unsupervised anomaly detection model into a supervised deployable one and we suggest a set of techniques to improve the detection sensitivity. Compressed models perform comparably to their larger counterparts while significantly reducing the size and memory footprint.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-159,2023,100.0,"Knowledge Distillation for Anomaly Detection Unsupervised deep learning techniques are widely used to identify anomalous behaviour. The performance of such methods is a product of the amount of training data and the model size. However, the size is often a limiting factor for the deployment on resource-constrained devices. We present a novel procedure based on knowledge distillation for compressing an unsupervised anomaly detection model into a supervised deployable one and we suggest a set of techniques to improve the detection sensitivity. Compressed models perform comparably to their larger counterparts while significantly reducing the size and memory footprint."
Learning with Boosting Decision Stumps for Feature Selection in Evolving Data Streams,Daniel Assis,Unknown,"Feature selection plays an important role in Machine Learning pipelines, and many challenges emerge for feature selection when data arrives continuously as a stream. In this paper, we extend the Adaptive Boosting for Feature Selection (ABFS) algorithm by (i) using a different Online Boosting strategy and (ii) changing the Boosting scaling factor of instances weighting. Results show that our extended ABFS leveraged the predictive performance of classifiers more than the standard ABFS in the most used monolithic classifiers for stream mining.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-16,2023,100.0,"Learning with Boosting Decision Stumps for Feature Selection in Evolving Data Streams Feature selection plays an important role in Machine Learning pipelines, and many challenges emerge for feature selection when data arrives continuously as a stream. In this paper, we extend the Adaptive Boosting for Feature Selection (ABFS) algorithm by (i) using a different Online Boosting strategy and (ii) changing the Boosting scaling factor of instances weighting. Results show that our extended ABFS leveraged the predictive performance of classifiers more than the standard ABFS in the most used monolithic classifiers for stream mining."
Similarity versus Supervision: Best Approaches for HS Code Prediction,"Sédrick Stassin, Otmane Amel, Ahmed Sidi, Mahmoudi, Xavier Siebert",1 - University of Mons -ILIA Unit Mons Belgium,"With growing e-commerce flows and new legislative rules, customs representatives confront serious liabilities when completing customs declarations for their clients. In the latter, the Harmonized System (HS) code is a crucial component using 10 digits (HS10) to classify products and define national tax rates. In this paper, we first compare the performance of sentence embedding models using semantic similarity, and second, we assess the effectiveness of supervised models, both aimed at predicting up to the HS10 code. To the best of our knowledge, there is currently little research being conducted on this topic. We demonstrate the differences and respective strengths of each approach. Our results show the outstanding performance of the semantic similarity approach with a top-3 and top-5 accuracy of 89% and 94.8% respectively for HS10 prediction.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-163,2023,100.0,"Similarity versus Supervision: Best Approaches for HS Code Prediction With growing e-commerce flows and new legislative rules, customs representatives confront serious liabilities when completing customs declarations for their clients. In the latter, the Harmonized System (HS) code is a crucial component using 10 digits (HS10) to classify products and define national tax rates. In this paper, we first compare the performance of sentence embedding models using semantic similarity, and second, we assess the effectiveness of supervised models, both aimed at predicting up to the HS10 code. To the best of our knowledge, there is currently little research being conducted on this topic. We demonstrate the differences and respective strengths of each approach. Our results show the outstanding performance of the semantic similarity approach with a top-3 and top-5 accuracy of 89% and 94.8% respectively for HS10 prediction."
Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization,"Giuseppe Floris, Raffaele Mura, Luca Scionis, Giorgio Piras, Maura Pintor, Ambra Demontis, Battista Biggio","1 - Department of Electrical and Electronic Engineering University of Cagliari
5 - Department of Computer Engineering Sapienza University of Rome","Evaluating the adversarial robustness of machine-learning models using gradient-based attacks is challenging. In this work, we show that hyperparameter optimization can improve fast minimum-norm attacks by automating the selection of the loss function, the optimizer, and the step-size scheduler, along with the corresponding hyperparameters. Our extensive evaluation involving several robust models demonstrates the improved efficacy of fast minimum-norm attacks when hyped up with hyperparameter optimization. We release our open-source code at https://github.com/pralab/HO-FMN.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-164,2023,100.0,"Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization Evaluating the adversarial robustness of machine-learning models using gradient-based attacks is challenging. In this work, we show that hyperparameter optimization can improve fast minimum-norm attacks by automating the selection of the loss function, the optimizer, and the step-size scheduler, along with the corresponding hyperparameters. Our extensive evaluation involving several robust models demonstrates the improved efficacy of fast minimum-norm attacks when hyped up with hyperparameter optimization. We release our open-source code at https://github.com/pralab/HO-FMN."
Multimodal Approach for Harmonized System Code Prediction,"Otmane Amel, Sédrick Stassin, Ahmed Sidi, Mahmoudi, Xavier Siebert",1 - University of Mons -ILIA Unit Mons Belgium,"The rapid growth of e-commerce has placed considerable pressure on customs representatives, prompting advanced methods. In tackling this, Artificial intelligence (AI) systems have emerged as a promising approach to minimize the risks faced. Given that the Harmonized System (HS) code is a crucial element for an accurate customs declaration, we propose a novel multimodal HS code prediction approach using deep learning models exploiting both image and text features obtained through the customs declaration combined with e-commerce platform information. We evaluated two early fusion methods and introduced our MultConcat fusion method. To the best of our knowledge, few studies analyze the featurelevel combination of text and image in the state-of-the-art for HS code prediction, which heightens interest in our paper and its findings. The experimental results prove the effectiveness of our approach and fusion method with a top-3 and top-5 accuracy of 93.5% and 98.2% respectively.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-165,2023,100.0,"Multimodal Approach for Harmonized System Code Prediction The rapid growth of e-commerce has placed considerable pressure on customs representatives, prompting advanced methods. In tackling this, Artificial intelligence (AI) systems have emerged as a promising approach to minimize the risks faced. Given that the Harmonized System (HS) code is a crucial element for an accurate customs declaration, we propose a novel multimodal HS code prediction approach using deep learning models exploiting both image and text features obtained through the customs declaration combined with e-commerce platform information. We evaluated two early fusion methods and introduced our MultConcat fusion method. To the best of our knowledge, few studies analyze the featurelevel combination of text and image in the state-of-the-art for HS code prediction, which heightens interest in our paper and its findings. The experimental results prove the effectiveness of our approach and fusion method with a top-3 and top-5 accuracy of 93.5% and 98.2% respectively."
Evaluation of Contrastive Learning for Electronic Component Detection,"Leandro De, S Silva, Agostinho Freire, Bruno Fernandes, George Azevedo, Sergio Oliveira","1 - Universidade de Pernambuco -Escola Politécnica de Pernambuco Rua Benfica 455 Recife PE, Brazil
2 - Instituto Federal de Educação Ciência e Tecnologia da Paraíba (IFPB) Rua José Antônio da Silva 300 Cajazeiras PB, Brazil","The rapid growth of electronic waste (e-waste) has led to an urgent need for efficient recycling processes to recover valuable materials and reduce environmental impact. Waste Printed Circuit Boards (WPCBs) constitute significant e-waste and contain valuable components and precious metals. Computer vision systems can automate the classification, disassembly, and recycling of WPCBs. However, obtaining large annotated datasets for machine learning in this domain is costly and often unavailable. This paper investigates using few-shot and supervised contrastive learning in electronic component detection. We propose a model incorporating contrastive learning components for detecting electronic components in scenarios with limited training data or annotated labels. Our experimental results show that, in limited-data scenarios, contrastive learning outperforms the original versions of Faster R-CNN object detector. This study contributes to developing efficient recycling solutions for e-waste management and resource recovery.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-167,2023,100.0,"Evaluation of Contrastive Learning for Electronic Component Detection The rapid growth of electronic waste (e-waste) has led to an urgent need for efficient recycling processes to recover valuable materials and reduce environmental impact. Waste Printed Circuit Boards (WPCBs) constitute significant e-waste and contain valuable components and precious metals. Computer vision systems can automate the classification, disassembly, and recycling of WPCBs. However, obtaining large annotated datasets for machine learning in this domain is costly and often unavailable. This paper investigates using few-shot and supervised contrastive learning in electronic component detection. We propose a model incorporating contrastive learning components for detecting electronic components in scenarios with limited training data or annotated labels. Our experimental results show that, in limited-data scenarios, contrastive learning outperforms the original versions of Faster R-CNN object detector. This study contributes to developing efficient recycling solutions for e-waste management and resource recovery."
Disambiguating Signs: Deep Learning-based Gloss-level Classification for German Sign Language by Utilizing Mouth Actions,"Nam Dinh, Vera Pham, Eleftherios Czehmann, Avramidis",1 - German Research Center for Artificial Intelligence (DFKI) Speech and Language Technology Lab Alt-Moabit 91c 10559 Berlin Germany,"Despite the importance of mouth actions in Sign Languages, previous work on Automatic Sign Language Recognition (ASLR) has limited use of the mouth area. Disambiguation of homonyms is one of the functions of mouth actions, making them essential for tasks involving ambiguous hand signs. To measure their importance for ASLR, we trained a classifier to recognize ambiguous hand signs. We compared three models which use the upper body/hands area, the mouth, and both combined as input. We found that the addition of the mouth area in the model resulted in the best accuracy, giving an improvement of 7.2% and 4.7% on the validation and test set, while allowing disambiguation of the hand signs for most of the cases. In cases where the disambiguation failed, it was observed that the signers in the video samples occasionally didn't perform mouthings. In a few cases, the mouthing was enough to achieve full disambiguation of the signs. We conclude that further investigation on the modelling of the mouth region can be beneficial of future ASLR systems.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-168,2023,100.0,"Disambiguating Signs: Deep Learning-based Gloss-level Classification for German Sign Language by Utilizing Mouth Actions Despite the importance of mouth actions in Sign Languages, previous work on Automatic Sign Language Recognition (ASLR) has limited use of the mouth area. Disambiguation of homonyms is one of the functions of mouth actions, making them essential for tasks involving ambiguous hand signs. To measure their importance for ASLR, we trained a classifier to recognize ambiguous hand signs. We compared three models which use the upper body/hands area, the mouth, and both combined as input. We found that the addition of the mouth area in the model resulted in the best accuracy, giving an improvement of 7.2% and 4.7% on the validation and test set, while allowing disambiguation of the hand signs for most of the cases. In cases where the disambiguation failed, it was observed that the signers in the video samples occasionally didn't perform mouthings. In a few cases, the mouthing was enough to achieve full disambiguation of the signs. We conclude that further investigation on the modelling of the mouth region can be beneficial of future ASLR systems."
Spiking neural networks with Hebbian plasticity for unsupervised representation learning,"Naresh Ravichandran, Anders Lansner, Pawel Herman","1 - Division of Computational Science and Technology School of Electrical Engineering and Computer Science KTH Royal Institute of Technology Sweden
3 - Department of Mathematics Stockholm University Sweden
5 - Digital Futures KTH Royal Institute of Technology Sweden","We introduce a novel spiking neural network model for learning distributed internal representations from data in an unsupervised procedure. We achieved this by transforming the non-spiking feedforward Bayesian Confidence Propagation Neural Network (BCPNN) model, employing an online correlation-based Hebbian-Bayesian learning and rewiring mechanism, shown previously to perform representation learning, into a spiking neural network with Poisson statistics and low firing rate comparable to in vivo cortical pyramidal neurons. We evaluated the representations learned by our spiking model using a linear classifier and show performance close to the nonspiking BCPNN, and competitive with other Hebbian-based spiking networks when trained on MNIST and F-MNIST machine learning benchmarks.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-169,2023,100.0,"Spiking neural networks with Hebbian plasticity for unsupervised representation learning We introduce a novel spiking neural network model for learning distributed internal representations from data in an unsupervised procedure. We achieved this by transforming the non-spiking feedforward Bayesian Confidence Propagation Neural Network (BCPNN) model, employing an online correlation-based Hebbian-Bayesian learning and rewiring mechanism, shown previously to perform representation learning, into a spiking neural network with Poisson statistics and low firing rate comparable to in vivo cortical pyramidal neurons. We evaluated the representations learned by our spiking model using a linear classifier and show performance close to the nonspiking BCPNN, and competitive with other Hebbian-based spiking networks when trained on MNIST and F-MNIST machine learning benchmarks."
Action-Based ADHD Diagnosis in Video,"Yichun Li, Yuxing Yang, Rajesh Nair, Syed Naqvi","1 - Intelligent Sensing and Communications Research Group Newcastle University UK
3 - Tyne and Wear (CNTW) NHS Foundation Trust Cumbria, Northumberland UK","Attention Deficit Hyperactivity Disorder (ADHD) causes significant impairment in various domains. Early diagnosis of ADHD and treatment could significantly improve the quality of life and functioning. Recently, machine learning methods have improved the accuracy and efficiency of the ADHD diagnosis process. However, the cost of the equipment and trained staff required by the existing methods are generally huge. Therefore, we introduce the video-based frame-level action recognition network to ADHD diagnosis for the first time. We also record a real multi-modal ADHD dataset and extract three action classes from the video modality for ADHD diagnosis. The whole process data have been reported to CNTW-NHS Foundation Trust, which would be reviewed by medical consultants/professionals and will be made public in due course.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-17,2023,100.0,"Action-Based ADHD Diagnosis in Video Attention Deficit Hyperactivity Disorder (ADHD) causes significant impairment in various domains. Early diagnosis of ADHD and treatment could significantly improve the quality of life and functioning. Recently, machine learning methods have improved the accuracy and efficiency of the ADHD diagnosis process. However, the cost of the equipment and trained staff required by the existing methods are generally huge. Therefore, we introduce the video-based frame-level action recognition network to ADHD diagnosis for the first time. We also record a real multi-modal ADHD dataset and extract three action classes from the video modality for ADHD diagnosis. The whole process data have been reported to CNTW-NHS Foundation Trust, which would be reviewed by medical consultants/professionals and will be made public in due course."
On Transformer Autoregressive Decoding for Multivariate Time Series Forecasting,"Mohammed Aldosari, John Miller",1 - School of Computing University of Georgia 415 Boyd Research and Education Center 30602 Athens GA,"The success of the Transformer model has promoted recent advances in time series forecasting. This adoption sparked an interest in developing efficient Transformer models that scale well for forecasting long sequences. This involves maintaining non-autoregressive one-time decoding. However, the role of autoregressive decoding is less explored. To address this gap, we revisit an essential idea of the vanilla Transformer model and show that autoregressive decoding works well compared to non-autoregressive decoding. It also becomes vital for critical forecasting tasks, such as pandemic forecasting, where the stakes are high. Our code and data are publicly available at https://github.com/maldosari1/ar_transformer_tf.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-171,2023,100.0,"On Transformer Autoregressive Decoding for Multivariate Time Series Forecasting The success of the Transformer model has promoted recent advances in time series forecasting. This adoption sparked an interest in developing efficient Transformer models that scale well for forecasting long sequences. This involves maintaining non-autoregressive one-time decoding. However, the role of autoregressive decoding is less explored. To address this gap, we revisit an essential idea of the vanilla Transformer model and show that autoregressive decoding works well compared to non-autoregressive decoding. It also becomes vital for critical forecasting tasks, such as pandemic forecasting, where the stakes are high. Our code and data are publicly available at https://github.com/maldosari1/ar_transformer_tf."
Wind Power Prediction with ETSformer,"Jill Baumann, Oliver Kramer",1 - Computational Intelligence Lab Department of Computer Science Carl-von-Ossietzky University of Oldenburg 26111 Oldenburg Germany,"With growing environmental awareness, power generation from wind and other renewable sources is becoming increasingly important. Accurate short-term predictions of wind turbine power are needed to keep the grid stable and secure. This paper investigates the use of ETSformer, a time series approach based on the transformer architecture, for wind power prediction. ETSformer incorporates exponential smoothing principles and introduces mechanisms such as exponential smoothing attention and frequency attention to improve accuracy, efficiency and interpretability. This study compares ETSformer and LSTM on a sample dataset of a wind farm and its surrounding sites within a three kilometer radius from the Wind Integration National Dataset Toolkit with five minute interval measurements. The investigation shows promising results and improvements of ETSformer in ultra-short and short-term wind power prediction.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-173,2023,100.0,"Wind Power Prediction with ETSformer With growing environmental awareness, power generation from wind and other renewable sources is becoming increasingly important. Accurate short-term predictions of wind turbine power are needed to keep the grid stable and secure. This paper investigates the use of ETSformer, a time series approach based on the transformer architecture, for wind power prediction. ETSformer incorporates exponential smoothing principles and introduces mechanisms such as exponential smoothing attention and frequency attention to improve accuracy, efficiency and interpretability. This study compares ETSformer and LSTM on a sample dataset of a wind farm and its surrounding sites within a three kilometer radius from the Wind Integration National Dataset Toolkit with five minute interval measurements. The investigation shows promising results and improvements of ETSformer in ultra-short and short-term wind power prediction."
Pattern Recognition Spiking Neural Network for Classification of Chinese Characters,"Nicola Russo, Wan Yuzhong, Thomas Madsen, Konstantin Nikolic","1 - University of West London -School of Computing and Engineering St Mary's road W5 5RF London UK
2 - Imperial College London -Institute of Biomedical Engineering South Kensington Campus London SW7 2AZ UK","The Spiking Neural Networks (SNNs) are biologically more realistic than other types of Artificial Neural Networks (ANNs), but they have been much less utilised in applications. When comparing the two types of NNs, the SNNs are considered to be of lower latency, more hardware-friendly and energy-efficient, and suitable for running on portable devices with weak computing performance. In this paper we aim to use an SNN for the task of classifying Chinese character images, and test its performance. The network utilises inhibitory synapses for the purpose of using unsupervised learning. The learning algorithm is a derivative of the traditional Spike-timing-dependent Plasticity (STDP) learning rule. The input images are first pre-processed by traditional methods (OpenCV). Different hyperparameters configurations are tested reaching an optimal configuration and a classification accuracy rate of 93%.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-174,2023,100.0,"Pattern Recognition Spiking Neural Network for Classification of Chinese Characters The Spiking Neural Networks (SNNs) are biologically more realistic than other types of Artificial Neural Networks (ANNs), but they have been much less utilised in applications. When comparing the two types of NNs, the SNNs are considered to be of lower latency, more hardware-friendly and energy-efficient, and suitable for running on portable devices with weak computing performance. In this paper we aim to use an SNN for the task of classifying Chinese character images, and test its performance. The network utilises inhibitory synapses for the purpose of using unsupervised learning. The learning algorithm is a derivative of the traditional Spike-timing-dependent Plasticity (STDP) learning rule. The input images are first pre-processed by traditional methods (OpenCV). Different hyperparameters configurations are tested reaching an optimal configuration and a classification accuracy rate of 93%."
SOM-based Classification and a Novel Stopping Criterion for Astroparticle Applications,"Luis Sanchez, Erzsébet Merényi, Christopher Tunnell","1 - Department of Physics and Astronomy -Rice University
2 - Departments of Statistics & Electrical and Computer Engineering Rice University 6100 Main Street Houston Texas U.S.A","Classification of detector signals is vital in particle physics experiments. However, the intricate spatio-temporal nature of the data and instrumentation effects make highly accurate classification challenging. In this study we use a Conscience Self-Organizing Map to aid in the classification of particle signals from a dark matter experiment. We evaluate clusters extracted from the SOM for physics interpretation, label them and, by using the cluster labels, we demonstrate an improvement of accuracy over the currently used method. We also introduce a stopping criterion based on map quality to help shorten long SOM training.",Classification,https://doi.org/10.14428/esann/2023.ES2023-177,2023,100.0,"SOM-based Classification and a Novel Stopping Criterion for Astroparticle Applications Classification of detector signals is vital in particle physics experiments. However, the intricate spatio-temporal nature of the data and instrumentation effects make highly accurate classification challenging. In this study we use a Conscience Self-Organizing Map to aid in the classification of particle signals from a dark matter experiment. We evaluate clusters extracted from the SOM for physics interpretation, label them and, by using the cluster labels, we demonstrate an improvement of accuracy over the currently used method. We also introduce a stopping criterion based on map quality to help shorten long SOM training."
Anomaly detection in irregular image sequences for concentrated solar power plants,"Sukanya Patra, Thi Le, Hien Khanh, Souhaib Taieb",1 - Faculty of Science University of Mons Belgium,"Operations at extremely high temperatures can lead to various malfunctions in Concentrated Solar Power (CSP) plants, emphasizing the need for predictive maintenance (PdM). We study PdM as an anomaly detection (AD) problem from irregular image sequences, which represent the minute-by-minute solar receiver's surface temperature from a CSP plant. Contrary to standard benchmark image datasets in AD research, our data shows distinct characteristics such as non-stationarity, temporal dependence, and irregular sampling, which are unaddressed by current image-based AD techniques. Therefore, we introduce a forecast-based AD method to address these characteristics, drawing inspiration from irregular sequence modelling. The results show that the proposed method outperforms classical image-based AD methods on our dataset.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-178,2023,100.0,"Anomaly detection in irregular image sequences for concentrated solar power plants Operations at extremely high temperatures can lead to various malfunctions in Concentrated Solar Power (CSP) plants, emphasizing the need for predictive maintenance (PdM). We study PdM as an anomaly detection (AD) problem from irregular image sequences, which represent the minute-by-minute solar receiver's surface temperature from a CSP plant. Contrary to standard benchmark image datasets in AD research, our data shows distinct characteristics such as non-stationarity, temporal dependence, and irregular sampling, which are unaddressed by current image-based AD techniques. Therefore, we introduce a forecast-based AD method to address these characteristics, drawing inspiration from irregular sequence modelling. The results show that the proposed method outperforms classical image-based AD methods on our dataset."
Energy-efficient detection of a spike sequence,"Louis Le Coeur, Nicholas Riedman, Saarthak Sarup, Kwabena Boahen",1 - Departments of Electrical Engineering and Bioengineering Stanford University 450 Jane Stanford Way 94305-2004 Stanford CA USA,We present a novel 3D spike sorting network (3DSS) that detects a spike sequence efficiently and memorizes it upon a single presentation without configuration. We analyze the wiring and switches of alternatives and show that 3DSS reduces energy per spike quadratically compared to existing 2D networks. Applications include large-scale document retrieval and self-configuring hardware.,Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-179,2023,100.0,Energy-efficient detection of a spike sequence We present a novel 3D spike sorting network (3DSS) that detects a spike sequence efficiently and memorizes it upon a single presentation without configuration. We analyze the wiring and switches of alternatives and show that 3DSS reduces energy per spike quadratically compared to existing 2D networks. Applications include large-scale document retrieval and self-configuring hardware.
A Counterexample to Ockham's Razor and the Curse of Dimensionality: Marginalising Complexity and Dimensionality for GMMs,Benoît Frénay,1 - Faculty of Computer Science University of Namur -NaDI PReCISE -HuMaLearn rue Grandgagnage 21 B-5000 Namur Belgium,"Ockham's razor and the curse of dimensionality are two founding principles in machine learning. First, simple models should be preferred to complex ones, in order to prevent overfitting. Second, highdimensional spaces should be avoided, whenever possible, because learning is easier in lower-dimensional spaces. These principles are often invoked to justify methodological choices or to preprocess data. However, this paper shows a counterexample where it is better to first learn a more complex model in a higher-dimensional space, and then to go back to the lowerdimensional space while dropping the additional complexity. Specifically, experiments demonstrate that Gaussian mixtures models can be learned in a higher-dimensional space and then marginalised to the target dimensionality to improve probability density estimation performances. The chosen problem is deliberately simple to facilitate the analysis, but it opens the way to similar work for more complex models and tasks.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-18,2023,100.0,"A Counterexample to Ockham's Razor and the Curse of Dimensionality: Marginalising Complexity and Dimensionality for GMMs Ockham's razor and the curse of dimensionality are two founding principles in machine learning. First, simple models should be preferred to complex ones, in order to prevent overfitting. Second, highdimensional spaces should be avoided, whenever possible, because learning is easier in lower-dimensional spaces. These principles are often invoked to justify methodological choices or to preprocess data. However, this paper shows a counterexample where it is better to first learn a more complex model in a higher-dimensional space, and then to go back to the lowerdimensional space while dropping the additional complexity. Specifically, experiments demonstrate that Gaussian mixtures models can be learned in a higher-dimensional space and then marginalised to the target dimensionality to improve probability density estimation performances. The chosen problem is deliberately simple to facilitate the analysis, but it opens the way to similar work for more complex models and tasks."
Retinal blood vessel segmentation from high resolution fundus image using deep learning architecture,"Henda Boudegga, Yaroub Elloumi, Asma Abdallah, Rostom Kachouri, Mohamed Bedoui","1 - Medical Technology and Image Processing Laboratory Univ. of Monastir Tunisia
2 - ISITCom Hammam-Sousse University of Sousse Tunisia
6 - LIGM Univ. Gustave Eiffel CNRS ESIEE Paris F-77454 Marne-la-Vallée France","The Retinal Vascular Tree (RVT) segmentation is required to diagnose various ocular pathologies. Recently, fundus images are acquired with higher resolution, which allows representing a large range of vessel thickness. However, standard Deep Learning (DL) architectures with static and small convolution size have failed to achieve higher segmentation performance. In this paper, we propose a novel DL architecture for RVT segmentation dedicated for high resolution fundus images. The idea consists at extending the U-net architecture by increasing (e.g. decreasing) convolution kernel size through convolution blocs, in correlation with downscale (e.g. upscale) of feature map dimensions. The proposed architecture is validated on HRF database, where average sensitivity is increased from 56% to 84%.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-180,2023,100.0,"Retinal blood vessel segmentation from high resolution fundus image using deep learning architecture The Retinal Vascular Tree (RVT) segmentation is required to diagnose various ocular pathologies. Recently, fundus images are acquired with higher resolution, which allows representing a large range of vessel thickness. However, standard Deep Learning (DL) architectures with static and small convolution size have failed to achieve higher segmentation performance. In this paper, we propose a novel DL architecture for RVT segmentation dedicated for high resolution fundus images. The idea consists at extending the U-net architecture by increasing (e.g. decreasing) convolution kernel size through convolution blocs, in correlation with downscale (e.g. upscale) of feature map dimensions. The proposed architecture is validated on HRF database, where average sensitivity is increased from 56% to 84%."
Multi-Fidelity Reinforcement Learning with Control Variates,"Sami Khairy, Prasanna Balaprakash","1 - Oak Ridge National Laboratory Oak Ridge TN United States
2 - 1-Microsoft Vancouver BC Canada","In this paper, we investigate reinforcement learning (RL) in multi-fidelity environments and enhance the performance of the agent using cross-correlated data. We introduce a multifidelity estimator based on control variates to reduce the variance in state-action value function estimation. By employing this estimator, we develop a multifidelity Monte Carlo RL (MFMCRL) algorithm that boosts agent learning in high-fidelity settings. Our experiments show that, given a finite highfidelity sample budget, the MFMCRL agent outperforms an RL agent relying solely on high-fidelity interactions for policy optimization.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-181,2023,100.0,"Multi-Fidelity Reinforcement Learning with Control Variates In this paper, we investigate reinforcement learning (RL) in multi-fidelity environments and enhance the performance of the agent using cross-correlated data. We introduce a multifidelity estimator based on control variates to reduce the variance in state-action value function estimation. By employing this estimator, we develop a multifidelity Monte Carlo RL (MFMCRL) algorithm that boosts agent learning in high-fidelity settings. Our experiments show that, given a finite highfidelity sample budget, the MFMCRL agent outperforms an RL agent relying solely on high-fidelity interactions for policy optimization."
Adversarial Auditing of Machine Learning Models under Compound Shift,"Karan Bhanot, Dennis Wei, Ioana Baldini, Kristin Bennett","1 - Department of Computer Science Rensselaer Polytechnic Institute New York USA
2 - IBM Research -Yorktown Heights New York USA
4 - Department of Mathematics -New York Rensselaer Polytechnic Institute USA","Machine learning (ML) models often perform differently under distribution shifts, in terms of utility, fairness, and other dimensions. We propose the Adversarial Auditor for measuring the utility and fairness performance of ML models under compound shifts of outcome and protected attributes. We use Multi-Objective Bayesian Optimization (MOBO) to account for multiple metrics and identify shifts where model performance is extreme, both good and bad. Using two case studies, we show that MOBO performed better than random and grid-based approaches in identifying scenarios by adversarially optimizing objectives, highlighting the value of such an auditor for developing fair, accurate and shift-robust models.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-182,2023,100.0,"Adversarial Auditing of Machine Learning Models under Compound Shift Machine learning (ML) models often perform differently under distribution shifts, in terms of utility, fairness, and other dimensions. We propose the Adversarial Auditor for measuring the utility and fairness performance of ML models under compound shifts of outcome and protected attributes. We use Multi-Objective Bayesian Optimization (MOBO) to account for multiple metrics and identify shifts where model performance is extreme, both good and bad. Using two case studies, we show that MOBO performed better than random and grid-based approaches in identifying scenarios by adversarially optimizing objectives, highlighting the value of such an auditor for developing fair, accurate and shift-robust models."
Large-scale dataset and benchmarking for hand and face detection focused on sign language,"Alvaro Leandro, Cavalcante Carneiro, Denis Henrique, Pinheiro Salvadeo, Lucas De Brito","1 - Institute of Geosciences and Exact Sciences São Paulo State University Rio Claro, São Paulo Brazil","Object detection is an important preprocessing technique for sign language recognition, allowing focus on the most important parts of the image. This paper introduces a new large-scale dataset for hand and face detection in sign language context, mitigating the lack of data for this problem. We evaluated different object detection architectures to find the best trade-off between computational cost and mean Average Precision (mAP). The proposed dataset contains 477,480 annotated images. The most accurate detector (CenterNet) achieved an mAP of 96.7%. Furthermore, the optimizations made to the models reduced the inference time up to 74% in the best scenario.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-185,2023,100.0,"Large-scale dataset and benchmarking for hand and face detection focused on sign language Object detection is an important preprocessing technique for sign language recognition, allowing focus on the most important parts of the image. This paper introduces a new large-scale dataset for hand and face detection in sign language context, mitigating the lack of data for this problem. We evaluated different object detection architectures to find the best trade-off between computational cost and mean Average Precision (mAP). The proposed dataset contains 477,480 annotated images. The most accurate detector (CenterNet) achieved an mAP of 96.7%. Furthermore, the optimizations made to the models reduced the inference time up to 74% in the best scenario."
Quantum Artificial Intelligence: A tutorial,"José Martín-Guerrero, Lucas Lamata, Thomas Villmann","1 - Dpt. Eng. Electrònica IDAL ETSE-UV Universitat de València Spain
2 - Valencian Graduate School and Research Network of AI (ValgrAI) Spain
3 - Dpto. de Física Atómica, Molecular y Nuclear Universidad de Sevilla Spain
4 - Instituto Carlos I de Física Teórica y Computacional Universidad de Granada Spain
5 - SICIM Mittweida University of Applied Sciences Mittweida Germany","Artificial Intelligence (AI), a discipline with decades of history, is living its golden era due to striking developments that solve problems that were unthinkable just a few years ago, like generative models of text, images and video. The broad range of AI applications has also arrived to Physics, providing solutions to bottleneck situations, e.g., numerical methods that could not solve certain problems or took an extremely long time, optimization of quantum experimentation, or qubit control. Besides, Quantum Computing has become extremely popular for speeding up AI calculations, especially in the case of data-driven AI, i.e., Machine Learning (ML). The term Quantum ML is already known and deals with learning in quantum computers or quantum annealers, quantum versions of classical ML models and different learning approaches for quantum measurement and control. Quantum AI (QAI) tries to take a step forward in order to come up with disruptive concepts, such as, human-quantum-computer interfaces, sentiment analysis in quantum computers or explainability of quantum computing calculations, to name a few. This special session includes five high-quality papers on relevant topics, like quantum reinforcement learning, parallelization of quantum calculations, quantum feature selection and quantum vector quantization, thus capturing the richness and variability of approaches within QAI.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-2,2023,100.0,"Quantum Artificial Intelligence: A tutorial Artificial Intelligence (AI), a discipline with decades of history, is living its golden era due to striking developments that solve problems that were unthinkable just a few years ago, like generative models of text, images and video. The broad range of AI applications has also arrived to Physics, providing solutions to bottleneck situations, e.g., numerical methods that could not solve certain problems or took an extremely long time, optimization of quantum experimentation, or qubit control. Besides, Quantum Computing has become extremely popular for speeding up AI calculations, especially in the case of data-driven AI, i.e., Machine Learning (ML). The term Quantum ML is already known and deals with learning in quantum computers or quantum annealers, quantum versions of classical ML models and different learning approaches for quantum measurement and control. Quantum AI (QAI) tries to take a step forward in order to come up with disruptive concepts, such as, human-quantum-computer interfaces, sentiment analysis in quantum computers or explainability of quantum computing calculations, to name a few. This special session includes five high-quality papers on relevant topics, like quantum reinforcement learning, parallelization of quantum calculations, quantum feature selection and quantum vector quantization, thus capturing the richness and variability of approaches within QAI."
Potential analysis of a Quantum RL controller in the context of autonomous driving,"M Lautaro Hickmann, Arne Raulf, Frank Köster, Friedhelm Schwenker, Hans-Martin Rieser","1 - German Aerospace Center (DLR) -Institute for AI Safety and Security Ulm and St. Augustin Germany
4 - University of Ulm -Institute of Neural Information Processing James-Franck-Ring 89081 Ulm Germany","The potential of quantum enhanced Q-learning with a focus on its applicability to a lane change manoeuvre is investigated. In this context we solve multiple simple reinforcement learning environments using variational quantum circuits. The achieved results were similar to or even better than those of a simple constrained classical agent. We could observe promising behaviour on the more complex lane change manoeuvre task, which has an environment with an observation vector size twice larger than commonly used ones. For the Frozen Lake environment we found indications of possible quantum advantages in convergence rate.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-22,2023,100.0,"Potential analysis of a Quantum RL controller in the context of autonomous driving The potential of quantum enhanced Q-learning with a focus on its applicability to a lane change manoeuvre is investigated. In this context we solve multiple simple reinforcement learning environments using variational quantum circuits. The achieved results were similar to or even better than those of a simple constrained classical agent. We could observe promising behaviour on the more complex lane change manoeuvre task, which has an environment with an observation vector size twice larger than commonly used ones. For the Frozen Lake environment we found indications of possible quantum advantages in convergence rate."
"Improving the DRASiW performance by exploiting its own ""Mental Images""","Gianluca Coda, Massimo De Gregorio, Antonio Sorgente, Paolo Vanacore",1 - Istituto di Scienze Applicate e Sistemi Intelligenti -CNR,"Several improvements have been proposed in the literature for the Weightless Neural Networks (WNNs), in particular the DRASiW extension of the WiSARD model with the introduction of mental imagery and bleaching procedure. We propose a new bleaching procedure called Dynamic Adaptive Bleaching (DAB) and its variant, refined Dynamic Adaptive Bleaching (r DAB), to improve the WNNs performance in terms of computational time and classification capabilities.",Classification,https://doi.org/10.14428/esann/2023.ES2023-25,2023,100.0,"Improving the DRASiW performance by exploiting its own ""Mental Images"" Several improvements have been proposed in the literature for the Weightless Neural Networks (WNNs), in particular the DRASiW extension of the WiSARD model with the introduction of mental imagery and bleaching procedure. We propose a new bleaching procedure called Dynamic Adaptive Bleaching (DAB) and its variant, refined Dynamic Adaptive Bleaching (r DAB), to improve the WNNs performance in terms of computational time and classification capabilities."
A Tropical View of Graph Neural Networks,"Davide Bacciu, Francesco Landolfi, Danilo Numeroso","1 - Department of Computer Science Università di Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","Learning dynamic programming algorithms with Graph Neural Networks (GNNs) is a research direction which is increasingly gaining popularity. Prior work has demonstrated that in order to learn such algorithms, it is necessary to have an ""alignment"" between the neural architecture and the dynamics of the target algorithms, and that GNNs align, in fact, with dynamic programming. Here, we provide a different view of this alignment, studying it through the lens of tropical algebra. We show that GNNs can approximate dynamic programming algorithms up to arbitrary precision, provided that their input and output are appropriately pre-and post-processed.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-27,2023,100.0,"A Tropical View of Graph Neural Networks Learning dynamic programming algorithms with Graph Neural Networks (GNNs) is a research direction which is increasingly gaining popularity. Prior work has demonstrated that in order to learn such algorithms, it is necessary to have an ""alignment"" between the neural architecture and the dynamics of the target algorithms, and that GNNs align, in fact, with dynamic programming. Here, we provide a different view of this alignment, studying it through the lens of tropical algebra. We show that GNNs can approximate dynamic programming algorithms up to arbitrary precision, provided that their input and output are appropriately pre-and post-processed."
Towards Randomized Algorithms and Models that We Can Trust: a Theoretical Perspective,"Luca Oneto, Sandro Ridella, Davide Anguita",1 - University of Genoa Via Opera Pia 11a 16145 Genova Italy,"In the last decade it became increasingly apparent the inability of technical metrics to well characterize the behavior of intelligent systems. In fact, they are nowadays requested to meet also ethical requirements such as explainability, fairness, robustness, and privacy increasing our trust in their use in the wild. The final goal is to be able to develop a new generation of more responsible and trustworthy machine learning. In this paper, we focus our attention on randomized machine learning algorithms and models questioning, from a theoretical perspective, if it is possible to simultaneously optimize multiple metrics that are in tension between each other towards randomized machine learning algorithms that we can trust. For this purpose we will leverage the most recent advances coming from the statistical learning theory: distribution stability and differential privacy.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-29,2023,100.0,"Towards Randomized Algorithms and Models that We Can Trust: a Theoretical Perspective In the last decade it became increasingly apparent the inability of technical metrics to well characterize the behavior of intelligent systems. In fact, they are nowadays requested to meet also ethical requirements such as explainability, fairness, robustness, and privacy increasing our trust in their use in the wild. The final goal is to be able to develop a new generation of more responsible and trustworthy machine learning. In this paper, we focus our attention on randomized machine learning algorithms and models questioning, from a theoretical perspective, if it is possible to simultaneously optimize multiple metrics that are in tension between each other towards randomized machine learning algorithms that we can trust. For this purpose we will leverage the most recent advances coming from the statistical learning theory: distribution stability and differential privacy."
Green Machine Learning,"Verónica Bolón-Canedo, Laura Morán-Fernández, Brais Cancela, Amparo Alonso-Betanzos",1 - CITIC Universidade da Coruña Coruña Spain,"Green machine learning refers to research that is more environmentally friendly and inclusive, not only by producing novel results without increasing the computational cost, but also by ensuring that any researcher with a laptop has the opportunity to perform high-quality research without the need to use expensive cloud servers. Efficient machine learning approaches (especially deep learning) are starting to receive some attention in the research community. This tutorial is concerned with the development of machine learning algorithms that optimize efficiency rather than only accuracy. We provide an overview of this recent field, together with a review of the novel contributions to the ESANN 2023 special session on Green Machine Learning.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-3,2023,100.0,"Green Machine Learning Green machine learning refers to research that is more environmentally friendly and inclusive, not only by producing novel results without increasing the computational cost, but also by ensuring that any researcher with a laptop has the opportunity to perform high-quality research without the need to use expensive cloud servers. Efficient machine learning approaches (especially deep learning) are starting to receive some attention in the research community. This tutorial is concerned with the development of machine learning algorithms that optimize efficiency rather than only accuracy. We provide an overview of this recent field, together with a review of the novel contributions to the ESANN 2023 special session on Green Machine Learning."
Mitigating Robustness Bias: Theoretical Results and Empirical Evidences,"Danilo Franco, Luca Oneto, Davide Anguita",1 - University of Genoa Via Opera Pia 11a 16145 Genova Italy,"Recent research has shown that some learned classifiers can be more easily fooled by an adversary who carefully crafts imperceptible or physically plausible modifications of the input data regarding particular subgroups of the population (e.g., people with particular gender, ethnicity, or skin color). This form of unfairness has been just recently studied, noting the fact that classical fairness metrics, which only observe the model outputs, are not enough but robustness biases need to be measured and mitigated as well. For this reason, in this paper, we will first develop a new metric of fairness which generalizes the current ones and degenerates in the classical ones and then we will develop a theoretical mitigation framework with consistency results able to generate a new empirical mitigation strategy and explain why the current ones actually work.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-30,2023,100.0,"Mitigating Robustness Bias: Theoretical Results and Empirical Evidences Recent research has shown that some learned classifiers can be more easily fooled by an adversary who carefully crafts imperceptible or physically plausible modifications of the input data regarding particular subgroups of the population (e.g., people with particular gender, ethnicity, or skin color). This form of unfairness has been just recently studied, noting the fact that classical fairness metrics, which only observe the model outputs, are not enough but robustness biases need to be measured and mitigated as well. For this reason, in this paper, we will first develop a new metric of fairness which generalizes the current ones and degenerates in the classical ones and then we will develop a theoretical mitigation framework with consistency results able to generate a new empirical mitigation strategy and explain why the current ones actually work."
Performance Evaluation of Activation Functions in Extreme Learning Machine,"Karol Struniawski, Aleksandra Konopka, Ryszard Kozera","1 - Warsaw University of Life Sciences -SGGW Institute of Information Technology ul. Nowoursynowska 159 Warsaw Poland
4 - The University of Western Australia
5 - School of Physics, Mathematics and Computing 35 Stirling Highway Crawley, Perth Australia","This study investigates the performance of 36 different activation functions applied in Extreme Learning Machine on 10 distinct datasets. Results show that Mish and Sexp activation functions exhibit outstanding generalization abilities and consistently perform well across most datasets, while other functions are more dependent on the characteristics of the task at hand. The selection of an activation function is intricately linked to the applied dataset and novel activation functions may possess superior generalization capabilities comparing to commonly employed alternatives. This study provides valuable insight for researchers and practitioners seeking to optimize Extreme Learning Machine performance for solving classification tasks.",Classification,https://doi.org/10.14428/esann/2023.ES2023-31,2023,100.0,"Performance Evaluation of Activation Functions in Extreme Learning Machine This study investigates the performance of 36 different activation functions applied in Extreme Learning Machine on 10 distinct datasets. Results show that Mish and Sexp activation functions exhibit outstanding generalization abilities and consistently perform well across most datasets, while other functions are more dependent on the characteristics of the task at hand. The selection of an activation function is intricately linked to the applied dataset and novel activation functions may possess superior generalization capabilities comparing to commonly employed alternatives. This study provides valuable insight for researchers and practitioners seeking to optimize Extreme Learning Machine performance for solving classification tasks."
Graph-based Categorical Embedding,"Weiwei Wang, Stefano Bromuri, Michel Dumontier","1 - Maastricht University -Institute of Data Science Paul-Henri Spaaklaan 1 6229 EN Maastricht The Netherlands
2 - Computer Science Department Open University Valkenburgerweg 177 6419 AT Heerlen The Netherlands","Categorical features are a challenge for most machine learning algorithms that only accept numerical vectors in input. However, the emergence of graph neural networks is revolutionizing the application of machine learning models to traditional data sets. This is thanks to the possibility of introducing graph relationships amongst features and samples. In this contribution, we describe an algorithm leveraging the assignment matrix of a DiffPool graph neural network to calculate embeddings for categorical features, using as an adjacency matrix the co-occurrence matrix between the categorical values and as nodes feature the one hot encoded categorical values. We show that the algorithm proposed is scalable and presents a competitive performance in three publicly available data sets presenting both numerical and categorical values.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-32,2023,100.0,"Graph-based Categorical Embedding Categorical features are a challenge for most machine learning algorithms that only accept numerical vectors in input. However, the emergence of graph neural networks is revolutionizing the application of machine learning models to traditional data sets. This is thanks to the possibility of introducing graph relationships amongst features and samples. In this contribution, we describe an algorithm leveraging the assignment matrix of a DiffPool graph neural network to calculate embeddings for categorical features, using as an adjacency matrix the co-occurrence matrix between the categorical values and as nodes feature the one hot encoded categorical values. We show that the algorithm proposed is scalable and presents a competitive performance in three publicly available data sets presenting both numerical and categorical values."
End-to-End Neural Network Training for Hyperbox-Based Classification,"Denis Mayr, Lima Martins, Christian Lülf, Fabian Gieseke","1 - ERCIS -Department of Information Systems University of Münster
2 - Leonardo Campus 3 48149 Münster Germany","Hyperbox-based classification has been seen as a promising technique in which decisions on the data are represented as a series of orthogonal, multidimensional boxes (i.e., hyperboxes) that are often interpretable and human-readable. However, existing methods are no longer capable of efficiently handling the increasing volume of data many application domains face nowadays. We address this gap by proposing a novel, fully differentiable framework for hyperbox-based classification via neural networks. In contrast to previous work, our hyperbox models can be efficiently trained in an end-to-end fashion, which leads to significantly reduced training times and superior classification results.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-33,2023,100.0,"End-to-End Neural Network Training for Hyperbox-Based Classification Hyperbox-based classification has been seen as a promising technique in which decisions on the data are represented as a series of orthogonal, multidimensional boxes (i.e., hyperboxes) that are often interpretable and human-readable. However, existing methods are no longer capable of efficiently handling the increasing volume of data many application domains face nowadays. We address this gap by proposing a novel, fully differentiable framework for hyperbox-based classification via neural networks. In contrast to previous work, our hyperbox models can be efficiently trained in an end-to-end fashion, which leads to significantly reduced training times and superior classification results."
Hidden Markov Models for Temporal Graph Representation Learning,"Federico Errica, Alessio Gravina, Davide Bacciu, Alessio Micheli","1 - NEC Laboratories Europe Kurfürsten-Anlage 36 69115 Heidelberg Germany
2 - Department of Computer Science University of Pisa
3 - Largo Bruno Pontecorvo 56127 Pisa Italy","We propose the Hidden Markov Model for temporal Graphs, a deep and fully probabilistic model for learning in the domain of dynamic time-varying graphs. We extend hidden Markov models for sequences to the graph domain by stacking probabilistic layers that perform efficient message passing and learn representations for the individual nodes. We evaluate the goodness of the learned representations on temporal node prediction tasks, and we observe promising results compared to neural approaches.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-35,2023,100.0,"Hidden Markov Models for Temporal Graph Representation Learning We propose the Hidden Markov Model for temporal Graphs, a deep and fully probabilistic model for learning in the domain of dynamic time-varying graphs. We extend hidden Markov models for sequences to the graph domain by stacking probabilistic layers that perform efficient message passing and learn representations for the individual nodes. We evaluate the goodness of the learned representations on temporal node prediction tasks, and we observe promising results compared to neural approaches."
TabSRA: An Attention based Self-Explainable Model for Tabular Learning,"Kodjo Amekoe, Mohamed Dilmi, Hanane Azzag, Mustapha Lebbah, Zaineb Dagdia, Gregoire Jaffre","1 - UMR CNRS 7030 Sorbonne Paris Nord University -LIPN Villetaneuse France
2 - Groupe BPCE 7 promenade Germaine Sablon 75013 Paris France
4 - Paris-Saclay University -DAVID Lab UVSQ Versailles France","We propose TabSRA, a novel self-explainable, and accurate model for tabular learning. TabSRA is based on SRA (Self-Reinforcement Attention), new attention mechanism that helps to learn an intelligible representation of the raw input data through element-wise vector multiplication. The learned representation is aggregated by a highly transparent function (e.g linear), which produces the final output. Experimental results on synthetic and real-world classification problems show that the proposed TabSRA solution outperforms existing widely used self-explainable models and performs comparably to full complexity state-of-the-art models in term of accuracy while providing a faithful feature attribution. Source code is available at https://github.com/anselmeamekoe/TabSRA.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-37,2023,100.0,"TabSRA: An Attention based Self-Explainable Model for Tabular Learning We propose TabSRA, a novel self-explainable, and accurate model for tabular learning. TabSRA is based on SRA (Self-Reinforcement Attention), new attention mechanism that helps to learn an intelligible representation of the raw input data through element-wise vector multiplication. The learned representation is aggregated by a highly transparent function (e.g linear), which produces the final output. Experimental results on synthetic and real-world classification problems show that the proposed TabSRA solution outperforms existing widely used self-explainable models and performs comparably to full complexity state-of-the-art models in term of accuracy while providing a faithful feature attribution. Source code is available at https://github.com/anselmeamekoe/TabSRA."
Graph Representation Learning,"Davide Bacciu, Federico Errica, Alessio Micheli, Nicolò Navarin, Luca Pasa, Marco Podda, Daniele Zambon","1 - Department of Computer Science University of Pisa Italy
2 - -NEC Laboratories Europe Germany
4 - Department of Mathematics University of Padova Italy
7 - The Swiss AI Lab IDSIA Università della Svizzera italiana Switzerland","In a broad range of real-world machine learning applications, representing examples as graphs is crucial to avoid a loss of information. For this reason, in the last few years, the definition of machine learning methods, particularly neural networks, for graph-structured inputs has been gaining increasing attention. In particular, Deep Graph Networks (DGNs) are nowadays the most commonly adopted models to learn a representation that can be used to address different tasks related to nodes, edges, or even entire graphs. This tutorial paper reviews fundamental concepts and open challenges of graph representation learning and summarizes the contributions that have been accepted for publication to the ESANN 2023 special session on the topic.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-4,2023,100.0,"Graph Representation Learning In a broad range of real-world machine learning applications, representing examples as graphs is crucial to avoid a loss of information. For this reason, in the last few years, the definition of machine learning methods, particularly neural networks, for graph-structured inputs has been gaining increasing attention. In particular, Deep Graph Networks (DGNs) are nowadays the most commonly adopted models to learn a representation that can be used to address different tasks related to nodes, edges, or even entire graphs. This tutorial paper reviews fundamental concepts and open challenges of graph representation learning and summarizes the contributions that have been accepted for publication to the ESANN 2023 special session on the topic."
Robust and Cheap Safety Measure for Exoskeletal Learning Control with Estimated Uniform PAC (EUPAC),"Felix Weiske, Jens Jäkel",1 - University of Applied Sciences Leipzig -Faculty of Engineering Karl-Liebknecht-Straße 132 04277 Leipzig Germany,"Although safe reinforcement learning control for exoskeletons shows great potential, established real-world applications seem rare. There is a dilemma: the safe RL agent is either robustly safe and computationally demanding or not robustly safe but computationally cheap. We propose Estimated Uniform PAC (EUPAC) as a new safety heuristic. We show that our EUPAC algorithm differentiates safe from unsafe system behaviour with high significance (p < 0.001) while having a linear worst time complexity.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-40,2023,100.0,"Robust and Cheap Safety Measure for Exoskeletal Learning Control with Estimated Uniform PAC (EUPAC) Although safe reinforcement learning control for exoskeletons shows great potential, established real-world applications seem rare. There is a dilemma: the safe RL agent is either robustly safe and computationally demanding or not robustly safe but computationally cheap. We propose Estimated Uniform PAC (EUPAC) as a new safety heuristic. We show that our EUPAC algorithm differentiates safe from unsafe system behaviour with high significance (p < 0.001) while having a linear worst time complexity."
A Protocol for Continual Explanation of SHAP,"Andrea Cossu, Francesco Spinnato, Riccardo Guidotti, Davide Bacciu","1 - University of Pisa
2 - Scuola Normale Superiore
4 - CNR. Pisa Italy","Continual Learning trains models on a stream of data, with the aim of learning new information without forgetting previous knowledge. Given the dynamic nature of such environments, explaining the predictions of these models can be challenging. We study the behavior of SHAP values explanations in Continual Learning and propose an evaluation protocol to robustly assess the change of explanations in Class-Incremental scenarios. We observed that, while Replay strategies enforce the stability of SHAP values in feedforward/convolutional models, they are not able to do the same with fully-trained recurrent models. We show that alternative recurrent approaches, like randomized recurrent models, are more effective in keeping the explanations stable over time.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-41,2023,100.0,"A Protocol for Continual Explanation of SHAP Continual Learning trains models on a stream of data, with the aim of learning new information without forgetting previous knowledge. Given the dynamic nature of such environments, explaining the predictions of these models can be challenging. We study the behavior of SHAP values explanations in Continual Learning and propose an evaluation protocol to robustly assess the change of explanations in Class-Incremental scenarios. We observed that, while Replay strategies enforce the stability of SHAP values in feedforward/convolutional models, they are not able to do the same with fully-trained recurrent models. We show that alternative recurrent approaches, like randomized recurrent models, are more effective in keeping the explanations stable over time."
Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis,"Zhengxiang Shi, Aldo Lipani",1 - University College London Gower St London United Kingdom,"In recent years, language models (LMs) have made remarkable progress in advancing the field of natural language processing (NLP). However, the impact of data augmentation (DA) techniques on the finetuning (FT) performance of these LMs has been a topic of ongoing debate. In this study, we evaluate the effectiveness of three different FT methods in conjugation with back-translation across an array of 7 diverse NLP tasks, including classification and regression types, covering single-sentence and sentence-pair tasks. Contrary to prior assumptions that DA does not contribute to the enhancement of LMs' FT performance, our findings reveal that continued pre-training on augmented data can effectively improve the FT performance of the downstream tasks. In the most favourable case, continued pre-training improves the performance of FT by more than 10% in the few-shot learning setting. Our finding highlights the potential of DA as a powerful tool for bolstering LMs' performance. 1","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-42,2023,100.0,"Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis In recent years, language models (LMs) have made remarkable progress in advancing the field of natural language processing (NLP). However, the impact of data augmentation (DA) techniques on the finetuning (FT) performance of these LMs has been a topic of ongoing debate. In this study, we evaluate the effectiveness of three different FT methods in conjugation with back-translation across an array of 7 diverse NLP tasks, including classification and regression types, covering single-sentence and sentence-pair tasks. Contrary to prior assumptions that DA does not contribute to the enhancement of LMs' FT performance, our findings reveal that continued pre-training on augmented data can effectively improve the FT performance of the downstream tasks. In the most favourable case, continued pre-training improves the performance of FT by more than 10% in the few-shot learning setting. Our finding highlights the potential of DA as a powerful tool for bolstering LMs' performance. 1"
Hybrid Deep Learning-Based Air and Water Quality Prediction Model,"Jungeun Yoon, Dasong Yu, Youngjae Lee","1 - Andong National University -Dept of ICT Convergence Engineering 1375 Gyeongdong-ro -Andong-si
2 - ETRI -Dept of Regional Industry IT Conversion Team 1 Techno sunhwan-ro 10-gil Dalseong-gun -Daegu","This paper analyzes the impact of surrounding data on predicting air and water pollution levels by incorporating relevant features and examining their influence. By doing so, we can confirm the relationship between air and water pollution. A hybrid deep learning-based model is trained and various datasets and models are compared and analyzed. The proposed GCN-GRU model achieved the best results not only for P M2.5 but also for Dissolved Oxygen. The hybrid model takes into account the spatial and temporal effects of data characteristics and provides more accurate environmental prediction information through correlation analysis.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-44,2023,100.0,"Hybrid Deep Learning-Based Air and Water Quality Prediction Model This paper analyzes the impact of surrounding data on predicting air and water pollution levels by incorporating relevant features and examining their influence. By doing so, we can confirm the relationship between air and water pollution. A hybrid deep learning-based model is trained and various datasets and models are compared and analyzed. The proposed GCN-GRU model achieved the best results not only for P M2.5 but also for Dissolved Oxygen. The hybrid model takes into account the spatial and temporal effects of data characteristics and provides more accurate environmental prediction information through correlation analysis."
Automatic Trade-off Adaptation in Offline RL,"Phillip Swazinna, Steffen Udluft, Thomas Runkler","1 - Siemens Technology -Data Analytics & Artificial Intelligence Otto-Hahn-Ring 6 Munich Germany
2 - School of Computation, Information, and Technology Boltzmannstrasse 3 TU Munich Garching Germany","Recently, offline RL algorithms have been proposed that remain adaptive at runtime. For example, the LION algorithm [1] provides the user with an interface to set the trade-off between behavior cloning and optimality w.r.t. the estimated return at runtime. Experts can then use this interface to adapt the policy behavior according to their preferences and find a good trade-off between conservatism and performance optimization. Since expert time is precious, we extend the methodology with an autopilot that automatically finds the best parameterization of the trade-off, yielding a new algorithm which we term AutoLION. Recently,  [4]  proposed that offline RL policies should be trained to be adaptive at runtime, i.e. remain adaptive after the training phase is over. The authors propose to maintain a distribution of possible MDPs, which can then at runtime be narrowed down to perform actions that are estimated to be optimal in the currently believed MDP.  [1, 5]  take this a step further and train policies 309",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-46,2023,100.0,"Automatic Trade-off Adaptation in Offline RL Recently, offline RL algorithms have been proposed that remain adaptive at runtime. For example, the LION algorithm [1] provides the user with an interface to set the trade-off between behavior cloning and optimality w.r.t. the estimated return at runtime. Experts can then use this interface to adapt the policy behavior according to their preferences and find a good trade-off between conservatism and performance optimization. Since expert time is precious, we extend the methodology with an autopilot that automatically finds the best parameterization of the trade-off, yielding a new algorithm which we term AutoLION. Recently,  [4]  proposed that offline RL policies should be trained to be adaptive at runtime, i.e. remain adaptive after the training phase is over. The authors propose to maintain a distribution of possible MDPs, which can then at runtime be narrowed down to perform actions that are estimated to be optimal in the currently believed MDP.  [1, 5]  take this a step further and train policies 309"
Probabilistic Adaptation for Meta-Learning,Tameem Adel,"1 - National Physical Laboratory -Data Science Department Hampton Rd Teddington United Kingdom
2 - Machine Learning Group (MLG) University of Cambridge UK","Meta-learning models learn to generalise to unseen tasks at test time. We introduce a meta-learning algorithm which balances (global) generalisation with a (local) adaptive mechanism allowing the meta-learner to deal with potentially substantial heterogeneity in the task distribution. The proposed meta-learner flexibly consolidates shared components (responsible for generalisation) with task-specific components. The latter components are adapted, in a data-driven manner, based on estimating the similarity between the meta-test task in hand and the training tasks. Experiments demonstrate improved performance on few-shot learning benchmarks, both general and others involving a more heterogeneous set of tasks.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-48,2023,100.0,"Probabilistic Adaptation for Meta-Learning Meta-learning models learn to generalise to unseen tasks at test time. We introduce a meta-learning algorithm which balances (global) generalisation with a (local) adaptive mechanism allowing the meta-learner to deal with potentially substantial heterogeneity in the task distribution. The proposed meta-learner flexibly consolidates shared components (responsible for generalisation) with task-specific components. The latter components are adapted, in a data-driven manner, based on estimating the similarity between the meta-test task in hand and the training tasks. Experiments demonstrate improved performance on few-shot learning benchmarks, both general and others involving a more heterogeneous set of tasks."
"Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness","Maura Pintor, Ambra Demontis, Battista Biggio",1 - University of Cagliari -Dept of Electrical and Electronic Engineering Cagliari Italy,"In recent years, machine learning has become the most effective way to analyze massive data streams. However, machine learning is also subject to security and reliability issues. These aspects require machine learning to be thoroughly tested before being deployed in unsupervised scenarios, such as services intended for consumers. The goal of this session is to discuss open challenges, both theoretical and practical, related to the security and safety of machine learning. The session will try to address the following challenges: (i) the implementation of efficient tests for Machine Learning in the context of robustness to attacks and natural drifts of data; and (ii) the design of robust and efficient models able to function in the wild and mitigate or detect adversarial attacks. 
 Context Machine learning (ML) has rapidly transformed various industries, from powering recommendation systems to driving autonomous vehicles. As ML adoption grows, so does the need for rigorous evaluation and trustworthiness of ML models. In the last years, these models have been rapidly increasing in size and complexity, as well as the amount of data used for their training. This demands for testing techniques able to effectively cover the attack surface of these systems and properly test the resilience of ML to unseen and undesirable attacks [1]. To address this open problem, we formulate the following research challenge: Research Challenge 1 Implementation of efficient tests for Machine Learning in the context of robustness to attacks and natural drifts of data.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-5,2023,100.0,"Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness In recent years, machine learning has become the most effective way to analyze massive data streams. However, machine learning is also subject to security and reliability issues. These aspects require machine learning to be thoroughly tested before being deployed in unsupervised scenarios, such as services intended for consumers. The goal of this session is to discuss open challenges, both theoretical and practical, related to the security and safety of machine learning. The session will try to address the following challenges: (i) the implementation of efficient tests for Machine Learning in the context of robustness to attacks and natural drifts of data; and (ii) the design of robust and efficient models able to function in the wild and mitigate or detect adversarial attacks. 
 Context Machine learning (ML) has rapidly transformed various industries, from powering recommendation systems to driving autonomous vehicles. As ML adoption grows, so does the need for rigorous evaluation and trustworthiness of ML models. In the last years, these models have been rapidly increasing in size and complexity, as well as the amount of data used for their training. This demands for testing techniques able to effectively cover the attack surface of these systems and properly test the resilience of ML to unseen and undesirable attacks [1]. To address this open problem, we formulate the following research challenge: Research Challenge 1 Implementation of efficient tests for Machine Learning in the context of robustness to attacks and natural drifts of data."
Richness of Node Embeddings in Graph Echo State Networks,"Domenico Tortorella, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy,"Graph Echo State Networks (GESN) have recently proved effective in node classification tasks, showing particularly able to address the issue of heterophily. While previous literature has analyzed the design of reservoirs for sequence ESN and GESN for graph-level tasks, the factors that contribute to rich node embeddings are so far unexplored. In this paper we analyze the impact of different reservoir designs on node classification accuracy and on the quality of node embeddings computed by GESN using tools from the areas of information theory and numerical analysis. In particular, we propose an entropy measure for quantifying information in node embeddings.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-51,2023,100.0,"Richness of Node Embeddings in Graph Echo State Networks Graph Echo State Networks (GESN) have recently proved effective in node classification tasks, showing particularly able to address the issue of heterophily. While previous literature has analyzed the design of reservoirs for sequence ESN and GESN for graph-level tasks, the factors that contribute to rich node embeddings are so far unexplored. In this paper we analyze the impact of different reservoir designs on node classification accuracy and on the quality of node embeddings computed by GESN using tools from the areas of information theory and numerical analysis. In particular, we propose an entropy measure for quantifying information in node embeddings."
Sleep analysis in a CLIS patient using soft-clustering: a case study,"Sophie Adama, Martin Bogdan",1 - Dept of Neuromorphic Information Processing Leipzig University Augustusplatz 10 Leipzig Germany,"The paper deals with the analysis of the sleep patterns of a patient with Completely Locked-In Syndrome (CLIS). The analysis was performed using an approach initially designed to detect consciousness in Disorders of Consciousness (DoC) and CLIS patients. The method extracts different features based on spectral, complexity and connectivity measures and performs soft-clustering analyses to determine the consciousness state. The results showed that it was able to discriminate between the (Non)-Rapid Eye Movement (NREM) and the Rapid Eye Movement (REM) sleep stages. Detecting normal Slow-Wave Sleep (SWS) and REM phases indicates better communication abilities for the patient.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-52,2023,100.0,"Sleep analysis in a CLIS patient using soft-clustering: a case study The paper deals with the analysis of the sleep patterns of a patient with Completely Locked-In Syndrome (CLIS). The analysis was performed using an approach initially designed to detect consciousness in Disorders of Consciousness (DoC) and CLIS patients. The method extracts different features based on spectral, complexity and connectivity measures and performs soft-clustering analyses to determine the consciousness state. The results showed that it was able to discriminate between the (Non)-Rapid Eye Movement (NREM) and the Rapid Eye Movement (REM) sleep stages. Detecting normal Slow-Wave Sleep (SWS) and REM phases indicates better communication abilities for the patient."
Mixture of stochastic block models for multiview clustering,"Kylliann De Santiago, Marie Szafranski, Christophe Ambroise","1 - Laboratoire de Mathématiques et Modélisation d'Évry Université Paris-Saclay CNRS Univ Évry 91037 Évry-Courcouronnes France
3 - ENSIIE 91025 Évry-Courcouronnes France","In this work, we propose an original method for aggregating multiple clustering coming from different sources of information. Each partition is encoded by a co-membership matrix between observations. Our approach uses a mixture of Stochastic Block Models (SBM) to group co-membership matrices with similar information into components and to partition observations into different clusters, taking into account their specificities within the components. The parameters are estimated using a Variational Bayesian EM algorithm. The Bayesian framework allows for selecting an optimal numbers of clusters and components.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-54,2023,100.0,"Mixture of stochastic block models for multiview clustering In this work, we propose an original method for aggregating multiple clustering coming from different sources of information. Each partition is encoded by a co-membership matrix between observations. Our approach uses a mixture of Stochastic Block Models (SBM) to group co-membership matrices with similar information into components and to partition observations into different clusters, taking into account their specificities within the components. The parameters are estimated using a Variational Bayesian EM algorithm. The Bayesian framework allows for selecting an optimal numbers of clusters and components."
Feature Selection for Concept Drift Detection,"Fabian Hinder, Barbara Hammer",1 - Bielefeld University -Cognitive Interaction Technology (CITEC) Inspiration 1 33619 Bielefeld Germany,"Feature selection is one of the most relevant preprocessing and analysis techniques in machine learning. It can dramatically increase the performance of learning algorithms and also provide relevant information on the data. In online and stream learning concept drift, i.e., the change of the underlying distribution over time, can cause tremendous problems for learning models and data analysis. While there do exist feature selection methods for online learning, to the best of our knowledge there do not exist methods to perform feature selection for drift detection, i.e., to increase the performance of drift detectors and to analyze the drift itself. In this work, we study feature selection for concept drift detection and provide a formal derivation and semantic interpretation thereof. We empirically show the relevance of our considerations on several benchmarks.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-55,2023,100.0,"Feature Selection for Concept Drift Detection Feature selection is one of the most relevant preprocessing and analysis techniques in machine learning. It can dramatically increase the performance of learning algorithms and also provide relevant information on the data. In online and stream learning concept drift, i.e., the change of the underlying distribution over time, can cause tremendous problems for learning models and data analysis. While there do exist feature selection methods for online learning, to the best of our knowledge there do not exist methods to perform feature selection for drift detection, i.e., to increase the performance of drift detectors and to analyze the drift itself. In this work, we study feature selection for concept drift detection and provide a formal derivation and semantic interpretation thereof. We empirically show the relevance of our considerations on several benchmarks."
Secure Federated Learning with Kernel Affine Hull Machines,"Mohit Kumar, Bernhard Moser, Lukas Fischer",1 - Software Competence Center Hagenberg GmbH A-4232 Hagenberg Austria,"The concept of Kernel Affine Hull Machine (KAHM) was recently introduced for representing data via learning in Reproducing Kernel Hilbert Spaces. KAHM defines a bounded geometric body in data space such that a distance measure from the geometric body can be used to aggregate local KAHM-based models to build a global model. This study leverages KAHMs for secure federated learning where data is protected from an aggressive aggregator by fully homomorphic encryption. An accurate and computationally efficient federated learning architecture, that combines local KAHMs-based classifiers in a robust and flexible manner such that the global model can be homomorphically evaluated in an efficient manner, is provided.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-56,2023,100.0,"Secure Federated Learning with Kernel Affine Hull Machines The concept of Kernel Affine Hull Machine (KAHM) was recently introduced for representing data via learning in Reproducing Kernel Hilbert Spaces. KAHM defines a bounded geometric body in data space such that a distance measure from the geometric body can be used to aggregate local KAHM-based models to build a global model. This study leverages KAHMs for secure federated learning where data is protected from an aggressive aggregator by fully homomorphic encryption. An accurate and computationally efficient federated learning architecture, that combines local KAHMs-based classifiers in a robust and flexible manner such that the global model can be homomorphically evaluated in an efficient manner, is provided."
A hidden Markov model with Hawkes process-derived contextual variables to improve time series prediction. Case study in medical simulation,"Fatoumata Dama, Christine Sinoquet, Corinne Lejus-Bourdeau","1 - CHU de Nantes Nantes Université 1 place Alexis-Ricordeau 44000 Nantes France
2 - UMR CNRS 6004 Nantes Université 1-LS2N, 2 rue de la Houssinière 44322 Nantes Cedex France
3 - Centre de Calcul Intensif des Pays de la Loire Nantes France","So far, models that take advantage of sequences of events to refine time series prediction have only been designed for specific applications. In this paper, we introduce the Non-Homogeneous Markov Chain AutoRegressive (NHMC-AR) model. In our model, the innovation arises from the synchronization of a multivariate Hawkes temporal point process with an autoregressive first-order hidden Markov model, through contextual variables. Experiments on anaesthesia data demonstrate that NHMC-AR has substantially better predictive performance compared to two competing methods.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-57,2023,99.63898916967509,"A hidden Markov model with Hawkes process-derived contextual variables to improve time series prediction. Case study in medical simulation So far, models that take advantage of sequences of events to refine time series prediction have only been designed for specific applications. In this paper, we introduce the Non-Homogeneous Markov Chain AutoRegressive (NHMC-AR) model. In our model, the innovation arises from the synchronization of a multivariate Hawkes temporal point process with an autoregressive first-order hidden Markov model, through contextual variables. Experiments on anaesthesia data demonstrate that NHMC-AR has substantially better predictive performance compared to two competing methods."
Efficient feature selection for domain adaptation using Mutual Information Maximization,"Guillermo Castillo-García, Laura Morán-Fernández, Verónica Bolón-Canedo",1 - CITIC Universidade da Coruña Coruña Spain,"Green AI, an emerging research field, focuses on improving the efficiency of machine learning models. In this paper, we introduce a novel and efficient method for feature selection in domain adaptation, a type of transfer learning where the source and target domains share the feature space and task but differ in their distributions. Instead of using evolutionary algorithms, a typical approach in this field, we propose the use of filter methods, which do not require an iterative search process and are less computationally expensive. Our proposed method is Mutual Information Maximization, and our experiments show that it outperforms Particle Swarm Optimization in terms of efficiency, speed, and the ability to select a reduced subset of features while achieving competitive classification accuracy results.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-61,2023,100.0,"Efficient feature selection for domain adaptation using Mutual Information Maximization Green AI, an emerging research field, focuses on improving the efficiency of machine learning models. In this paper, we introduce a novel and efficient method for feature selection in domain adaptation, a type of transfer learning where the source and target domains share the feature space and task but differ in their distributions. Instead of using evolutionary algorithms, a typical approach in this field, we propose the use of filter methods, which do not require an iterative search process and are less computationally expensive. Our proposed method is Mutual Information Maximization, and our experiments show that it outperforms Particle Swarm Optimization in terms of efficiency, speed, and the ability to select a reduced subset of features while achieving competitive classification accuracy results."
Revisiting the Mark Conditional Independence Assumption in Neural Marked Temporal Point Processes,"Tanguy Bosser, Souhaib Taieb",1 - Department of Computer Science Avenue Victor Maistriau University of Mons 15 Mons Belgium,"Learning marked temporal point process (TPP) models involves modeling both the event arrival times as well as their associated labels, referred to as marks. The recent introduction of deep learning techniques to the field led to better modeling of event sequences thanks to more flexible neural TPP models. However, some of these models make the assumption that event marks are independent of event times given the history of the process, which may not be valid in many applications. We relax this assumption and explicitly parametrize the mark distribution as a function of the current event time. We show that our approach achieves improved performance in predicting future marks compared to baselines on multiple real-world event sequence datasets, without affecting the performance on event time prediction.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-64,2023,100.0,"Revisiting the Mark Conditional Independence Assumption in Neural Marked Temporal Point Processes Learning marked temporal point process (TPP) models involves modeling both the event arrival times as well as their associated labels, referred to as marks. The recent introduction of deep learning techniques to the field led to better modeling of event sequences thanks to more flexible neural TPP models. However, some of these models make the assumption that event marks are independent of event times given the history of the process, which may not be valid in many applications. We relax this assumption and explicitly parametrize the mark distribution as a function of the current event time. We show that our approach achieves improved performance in predicting future marks compared to baselines on multiple real-world event sequence datasets, without affecting the performance on event time prediction."
Hierarchical priors for Hyperspherical Prototypical Networks,"Samuele Fonio, Lorenzo Paletto, Mattia Cerrato, Dino Ienco, Roberto Esposito","1 - University of Turin -Computer Science Department Corso Svizzera 185 Turin -Italy
3 - Johannes Gutenberg-Universität Mainz Saarstrasse 21 Mainz Germany
4 - INRAE UMR TETIS Rue Jean François Breton 500 Montpellier France","In this paper, we explore the usage of hierarchical priors to improve learning in contexts where the number of available examples is extremely low. Specifically, we consider a Prototype Learning setting where deep neural networks are used to embed data in hyperspherical geometries. In this scenario, we propose an innovative way to learn the prototypes by combining class separation and hierarchical information. In addition, we introduce a contrastive loss function capable of balancing the exploitation of prototypes through a prototype pruning mechanism. We compare the proposed method with state-of-the-art approaches on two public datasets.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-65,2023,100.0,"Hierarchical priors for Hyperspherical Prototypical Networks In this paper, we explore the usage of hierarchical priors to improve learning in contexts where the number of available examples is extremely low. Specifically, we consider a Prototype Learning setting where deep neural networks are used to embed data in hyperspherical geometries. In this scenario, we propose an innovative way to learn the prototypes by combining class separation and hierarchical information. In addition, we introduce a contrastive loss function capable of balancing the exploitation of prototypes through a prototype pruning mechanism. We compare the proposed method with state-of-the-art approaches on two public datasets."
Convolutional Transformer via Graph Embeddings for Few-shot Toxicity and Side Effect Prediction,"Luis Torres, Bernardete Ribeiro, Joel Arrais","1 - Centre for Informatics and Systems Univ Coimbra University of Coimbra
2 - Department of Informatics Engineering 3030-290 Coimbra Portugal","The prediction of chemical toxicity and adverse side effects is a crucial task in drug discovery. Graph neural networks (GNNs) have accelerated the discovery of compounds with improved molecular profiles for effective drug development. Recently, Transformer networks have also managed to capture the long-range dependence in molecules to preserve the global aspects of molecular embeddings for molecular property prediction. In this paper, we propose a few-shot GNN-Transformer, FS-GNNCvTR to face the challenge of low-data toxicity and side effect prediction. Specifically, we introduce a convolutional Transformer to model the local spatial context of molecular graph embeddings while preserving the global information of deep representations. Furthermore, a two-module meta-learning framework is proposed to iteratively update model parameters across fewshot tasks with limited available data. Experiments on small-sized biological datasets for toxicity and side effect prediction, Tox21 and SIDER, demonstrate a superior performance of FS-GNNCvTR compared to standard graph-based methods. The code and data underlying this article are available in the repository, https://github.com/larngroup/FS-GNNCvTR.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-66,2023,100.0,"Convolutional Transformer via Graph Embeddings for Few-shot Toxicity and Side Effect Prediction The prediction of chemical toxicity and adverse side effects is a crucial task in drug discovery. Graph neural networks (GNNs) have accelerated the discovery of compounds with improved molecular profiles for effective drug development. Recently, Transformer networks have also managed to capture the long-range dependence in molecules to preserve the global aspects of molecular embeddings for molecular property prediction. In this paper, we propose a few-shot GNN-Transformer, FS-GNNCvTR to face the challenge of low-data toxicity and side effect prediction. Specifically, we introduce a convolutional Transformer to model the local spatial context of molecular graph embeddings while preserving the global information of deep representations. Furthermore, a two-module meta-learning framework is proposed to iteratively update model parameters across fewshot tasks with limited available data. Experiments on small-sized biological datasets for toxicity and side effect prediction, Tox21 and SIDER, demonstrate a superior performance of FS-GNNCvTR compared to standard graph-based methods. The code and data underlying this article are available in the repository, https://github.com/larngroup/FS-GNNCvTR."
Trends and Challenges for Sign Language Recognition with Machine Learning,"Jérôme Fink, Mathieu De Coster, Joni Dambre, Benoît Frénay","1 - Faculty of Computer Science PReCISE Rue Grandgagnage 21 University of Namur -NaDI 5000 Namur Belgium
2 - IDLab-AIRO -Ghent University -imec Technologiepark-Zwijnaarde 126 9052 Ghent Belgium","Research in natural language processing has led to the creation of powerful tools for individuals, companies... However, these successes for written languages have not yet affected signed languages (SLs) to the same extent. The creation of similar tools for signed languages would benefit deaf, hard of hearing, and hearing people by making SL content, learning, and communication more accessible for everyone. SL recognition and translation are related to AI, but require collaboration with linguists and stakeholders. This paper describes related challenges from an AI researcher's point of view and summarizes the state of the art in these domains.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-7,2023,100.0,"Trends and Challenges for Sign Language Recognition with Machine Learning Research in natural language processing has led to the creation of powerful tools for individuals, companies... However, these successes for written languages have not yet affected signed languages (SLs) to the same extent. The creation of similar tools for signed languages would benefit deaf, hard of hearing, and hearing people by making SL content, learning, and communication more accessible for everyone. SL recognition and translation are related to AI, but require collaboration with linguists and stakeholders. This paper describes related challenges from an AI researcher's point of view and summarizes the state of the art in these domains."
"Layered Neural Networks with GELU Activation, a Statistical Mechanics Analysis","Frederieke Richert, Michiel Straat, Elisa Oostwal, Michael Biehl","1 - University of Groningen -Intelligent Systems Nijenborgh 9 9747 AG Groningen The Netherlands
2 - Bielefeld University -Center for Cognitive Interaction Technology Inspiration 1 33619 Bielefeld Germany","Understanding the influence of activation functions on the learning behaviour of neural networks is of great practical interest. The GELU, being similar to swish and ReLU, is analysed for soft committee machines in the statistical physics framework of off-line learning. We find phase transitions with respect to the relative training set size, which are always continuous. This result rules out the hypothesis that convexity is necessary for continuous phase transitions. Moreover, we show that even a small contribution of a sigmoidal function like erf in combination with GELU leads to a discontinuous transition.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-72,2023,100.0,"Layered Neural Networks with GELU Activation, a Statistical Mechanics Analysis Understanding the influence of activation functions on the learning behaviour of neural networks is of great practical interest. The GELU, being similar to swish and ReLU, is analysed for soft committee machines in the statistical physics framework of off-line learning. We find phase transitions with respect to the relative training set size, which are always continuous. This result rules out the hypothesis that convexity is necessary for continuous phase transitions. Moreover, we show that even a small contribution of a sigmoidal function like erf in combination with GELU leads to a discontinuous transition."
FouriER: Link Prediction by Mixing Tokens with Fourier-enhanced MetaFormer,"Thanh Vu, Huy Ngo, Bac Le, Thanh Le","1 - Faculty of Information Technology University of Science Ho Chi Minh City Vietnam
2 - National University Ho Chi Minh City Vietnam, Vietnam
9 - Faculty of Information Tech-nology University of Science Ho Chi Minh City Vietnam","Knowledge graph link prediction has been researched for many years. With the steady development of data, the demand for missing link prediction in knowledge bases is growing. In this study, we propose FouriER, a model using Fourier transforms integrated into MetaFormer architecture to learn features from embeddings better but more computationally cost-effective than the self-attention mechanism in Transformer models. Furthermore, we transform embeddings to a 2D form and stack them that benefit the model in learning interactions between entities and relations more efficiently. As a result, we found that our model outperformed baseline models on two benchmark datasets in our experiments.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-73,2023,100.0,"FouriER: Link Prediction by Mixing Tokens with Fourier-enhanced MetaFormer Knowledge graph link prediction has been researched for many years. With the steady development of data, the demand for missing link prediction in knowledge bases is growing. In this study, we propose FouriER, a model using Fourier transforms integrated into MetaFormer architecture to learn features from embeddings better but more computationally cost-effective than the self-attention mechanism in Transformer models. Furthermore, we transform embeddings to a 2D form and stack them that benefit the model in learning interactions between entities and relations more efficiently. As a result, we found that our model outperformed baseline models on two benchmark datasets in our experiments."
CRE: Circle relationship embedding of patches in vision transformer,"Zhengyang Yu, Jochen Triesch","1 - Frankfurt Institute for Advanced Studies Ruth Moufang-Straße 1 60438 Frankfurt am Main Germany
2 - Xidian-FIAS International Joint Research Center Ruth Moufang-Straße 1 60438 Frankfurt am Main Germany","The vision transformer (ViT) utilizes a learnable position embedding (PE) to encode the location of an image patch. However, it is unclear if this learnable PE is vital and what its benefits are. This paper explores an alternative way of encoding patch locations that exploits prior knowledge about their spatial arrangement called circle relationship embedding (CRE). CRE considers the distance of image patches from the central patch based on the four-neighborhood to simplify the PE. Our experiments show that combining CRE with PE achieves better performance than using PE alone. The code for this paper can be downloaded at: https://github.com/trieschlab/CRE.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-75,2023,100.0,"CRE: Circle relationship embedding of patches in vision transformer The vision transformer (ViT) utilizes a learnable position embedding (PE) to encode the location of an image patch. However, it is unclear if this learnable PE is vital and what its benefits are. This paper explores an alternative way of encoding patch locations that exploits prior knowledge about their spatial arrangement called circle relationship embedding (CRE). CRE considers the distance of image patches from the central patch based on the four-neighborhood to simplify the PE. Our experiments show that combining CRE with PE achieves better performance than using PE alone. The code for this paper can be downloaded at: https://github.com/trieschlab/CRE."
WiSARD-based Ensemble Learning,"Leopoldo Filho, Felipe França, Priscila Lima, Roberto Frias, -Pesc Coppe 4 -Nce","1 - Institute of Science and Technology São Paulo State University Sorocaba Av Três de Março 511 -Alto da Boa Vista Sorocaba -São Paulo Brazil
2 - Instituto de Telecomunicações -Porto
3 - Federal University of Rio de Janeiro Av Horácio Macedo 2030 -Cidade Universitária Rio de Janeiro -RJ -Brazil
4 - COPPE/Federal University of Rio de Janeiro","Weightless neural networks are recognized for their online learning capacity and competitive performance with the state-of-the-art in different scenarios. Despite this, the literature has not adequately explored the potential of classification ensembles based on these models and their unique characteristics. This study introduces three types of ensembles based on the WiSARD weightless model and evaluates their effectiveness. The results show that these ensembles significantly improve accuracy compared to the WiSARD model and its ClusWiSARD extension, with a reasonable increase in computational cost. Furthermore, using ensembles eliminates the need for time-consuming tie-break policies of traditional WiSARD models.",Classification,https://doi.org/10.14428/esann/2023.ES2023-76,2023,100.0,"WiSARD-based Ensemble Learning Weightless neural networks are recognized for their online learning capacity and competitive performance with the state-of-the-art in different scenarios. Despite this, the literature has not adequately explored the potential of classification ensembles based on these models and their unique characteristics. This study introduces three types of ensembles based on the WiSARD weightless model and evaluates their effectiveness. The results show that these ensembles significantly improve accuracy compared to the WiSARD model and its ClusWiSARD extension, with a reasonable increase in computational cost. Furthermore, using ensembles eliminates the need for time-consuming tie-break policies of traditional WiSARD models."
Logarithmic division for green feature selection: an information-theoretic approach,"Samuel Suárez-Marcote, Laura Morán-Fernández, Verónica Bolón-Canedo",1 - CITIC Universidade da Coruña Coruña Spain,"Feature selection is a popular preprocessing step to reduce the dimensionality of the data while preserving the important information. In this paper we propose an efficient and green feature selection method based on information theory, with the novelty of using the logarithmic division and resort to fixed-point precision. The results of experiments conducted on several datasets indicate the potential of our proposal, as it does not incur in significant information loss compared to the standard method, both in the features selected and in the subsequent classification step. This finding opens up possibilities for a new family of green feature selection methods, which would help to minimize energy consumption and carbon emissions.",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-77,2023,100.0,"Logarithmic division for green feature selection: an information-theoretic approach Feature selection is a popular preprocessing step to reduce the dimensionality of the data while preserving the important information. In this paper we propose an efficient and green feature selection method based on information theory, with the novelty of using the logarithmic division and resort to fixed-point precision. The results of experiments conducted on several datasets indicate the potential of our proposal, as it does not incur in significant information loss compared to the standard method, both in the features selected and in the subsequent classification step. This finding opens up possibilities for a new family of green feature selection methods, which would help to minimize energy consumption and carbon emissions."
Language Modeling in Logistics: Customer Calling Prediction,"Xi Chen, Giacomo Anerdi, Daniel Tan, Stefano Bromuri","1 - Department of Advanced Computing Sciences Maastricht University Minderbroedersberg 4-6 6211 LK Maastricht Netherlands
2 - Department of Computer Science Open University of the Netherlands Valkenburgerweg 177 6419 AT Heerlen Netherlands","Customer centers in logistics companies deal with many customer calls and requests daily. One of the most common calls is related to requesting an update on the shipment status. Proactively sending message updates to customers can reduce the number of calls. However, naively sending updates to everyone can cause unnecessary anxiety to people who do not want it, thus leading to customer dissatisfaction or even more calls. If a machine learning model could predict shipments leading to a customer call based on its journey, it could be possible to proactively send message updates only to customers likely to make a call. Therefore, reducing the workload in the customer center while increasing customer satisfaction. In large logistic companies where the volume of calls can reach a million calls per month, even 10% of the reduction of calls could already significantly reduce the additional expenses and workload associated with tracing a shipment. In this paper, we formulate the shipment journey as a variant of a language model. Specifically, we treat checkpoints (station, facility, time, event code) as tokens and predict the next checkpoint(station, facility, time delta, event code). Our core insight is that shipment checkpoints follow a set of rules that dictate the possible sequence of checkpoints. This is similar to how grammar rules dictate which words can follow another. Despite remaining a difficult problem, our experiments show that features learned by modeling shipment checkpoints as a language model can improve customer calling prediction.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-78,2023,100.0,"Language Modeling in Logistics: Customer Calling Prediction Customer centers in logistics companies deal with many customer calls and requests daily. One of the most common calls is related to requesting an update on the shipment status. Proactively sending message updates to customers can reduce the number of calls. However, naively sending updates to everyone can cause unnecessary anxiety to people who do not want it, thus leading to customer dissatisfaction or even more calls. If a machine learning model could predict shipments leading to a customer call based on its journey, it could be possible to proactively send message updates only to customers likely to make a call. Therefore, reducing the workload in the customer center while increasing customer satisfaction. In large logistic companies where the volume of calls can reach a million calls per month, even 10% of the reduction of calls could already significantly reduce the additional expenses and workload associated with tracing a shipment. In this paper, we formulate the shipment journey as a variant of a language model. Specifically, we treat checkpoints (station, facility, time, event code) as tokens and predict the next checkpoint(station, facility, time delta, event code). Our core insight is that shipment checkpoints follow a set of rules that dictate the possible sequence of checkpoints. This is similar to how grammar rules dictate which words can follow another. Despite remaining a difficult problem, our experiments show that features learned by modeling shipment checkpoints as a language model can improve customer calling prediction."
Entropy Based Regularization Improves Performance in the Forward-Forward Algorithm,"Matteo Pardi, Domenico Tortorella, Alessio Micheli","1 - Department of Physics 'E. Fermi' Largo B. Pontecorvo University of Pisa 56127 Pisa Italy
2 - Department of Computer Science Largo B. Pontecorvo University of Pisa 56127 Pisa Italy","The forward-forward algorithm (FFA) is a recently proposed alternative to end-to-end backpropagation in deep neural networks. FFA builds networks greedily layer by layer, thus being of particular interest in applications where memory and computational constraints are important. In order to boost layers' ability to transfer useful information to subsequent layers, in this paper we propose a novel regularization term for the layerwise loss function that is based on Renyi's quadratic entropy. Preliminary experiments show accuracy is generally significantly improved across all network architectures. In particular, smaller architectures become more effective in addressing our classification tasks compared to the original FFA.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-79,2023,100.0,"Entropy Based Regularization Improves Performance in the Forward-Forward Algorithm The forward-forward algorithm (FFA) is a recently proposed alternative to end-to-end backpropagation in deep neural networks. FFA builds networks greedily layer by layer, thus being of particular interest in applications where memory and computational constraints are important. In order to boost layers' ability to transfer useful information to subsequent layers, in this paper we propose a novel regularization term for the layerwise loss function that is based on Renyi's quadratic entropy. Preliminary experiments show accuracy is generally significantly improved across all network architectures. In particular, smaller architectures become more effective in addressing our classification tasks compared to the original FFA."
FairBayRank: A Fair Personalized Bayesian Ranker,"Armielle Ngaffo, Julien Albert, Benoît Frénay, Gilles Perrouin",1 - Faculty of Computer Science PReCISE Rue Grandgagnage 21 University of Namur -NaDI B-5000 Namur Belgium,"Recommender systems are data-driven models that successfully provide users with personalized rankings of items (movies, books...). Meanwhile, for user minority groups, those systems can be unfair in predicting users' expectations due to biased data. Consequently, fairness remains an open challenge in the ranking prediction task. To address this issue, we propose in this paper FairBayRank, a fair Bayesian personalized ranking algorithm that deals with both fairness and ranking performance requirements. FairBayRank evaluation on real-world datasets shows that it efficiently alleviates unfairness issues while ensuring high prediction performances.","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-81,2023,100.0,"FairBayRank: A Fair Personalized Bayesian Ranker Recommender systems are data-driven models that successfully provide users with personalized rankings of items (movies, books...). Meanwhile, for user minority groups, those systems can be unfair in predicting users' expectations due to biased data. Consequently, fairness remains an open challenge in the ranking prediction task. To address this issue, we propose in this paper FairBayRank, a fair Bayesian personalized ranking algorithm that deals with both fairness and ranking performance requirements. FairBayRank evaluation on real-world datasets shows that it efficiently alleviates unfairness issues while ensuring high prediction performances."
Exploring Strategies for Modeling Sign Language Phonology,"Lee Kezar, Riley Carlin, Tejas Srinivasan, Zed Sehyr, Naomi Caselli, Jesse Thomason","1 - University of Southern California Los Angeles California
4 - Chapman University Orange California
5 - Boston University Boston Massachusetts","Like speech, signs are composed of discrete, recombinable features called phonemes. Prior work shows that models which can recognize phonemes are better at sign recognition, motivating deeper exploration into strategies for modeling sign language phonemes. In this work, we learn graph convolution networks to recognize the sixteen phoneme ""types"" found in ASL-LEX 2.0. Specifically, we explore how learning strategies like multi-task and curriculum learning can leverage mutually useful information between phoneme types to facilitate better modeling of sign language phonemes. Results on the Sem-Lex Benchmark show that curriculum learning yields an average accuracy of 87% across all phoneme types, outperforming fine-tuning and multi-task strategies for most phoneme types.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-83,2023,100.0,"Exploring Strategies for Modeling Sign Language Phonology Like speech, signs are composed of discrete, recombinable features called phonemes. Prior work shows that models which can recognize phonemes are better at sign recognition, motivating deeper exploration into strategies for modeling sign language phonemes. In this work, we learn graph convolution networks to recognize the sixteen phoneme ""types"" found in ASL-LEX 2.0. Specifically, we explore how learning strategies like multi-task and curriculum learning can leverage mutually useful information between phoneme types to facilitate better modeling of sign language phonemes. Results on the Sem-Lex Benchmark show that curriculum learning yields an average accuracy of 87% across all phoneme types, outperforming fine-tuning and multi-task strategies for most phoneme types."
Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?,"Romain Egelé, Isabelle Guyon, Yixuan Sun, Prasanna Balaprakash","1 - LISN, U. Paris-Saclay France
2 - Argonne Ntl Lab MCS USA
4 - Google USA
6 - CCSD Oak Ridge Ntl Lab USA
7 - ChaLearn USA","Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models, but it can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We conducted a comparison of various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-84,2023,100.0,"Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization? Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models, but it can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We conducted a comparison of various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases."
Automated green machine learning for condition-based maintenance,"Afonso Lourenço, Carolina Ferraz, Jorge Meira, Goreti Marreiros, Verónica Bolón, Amparo Alonso-Betanzos","1 - GECAD* -Research Group on Intelligent Engineering and Computing for Advanced Innovation and Development Polytechnic of Porto Portugal
2 - CITIC ⸸ -University of Coruña 15071 Coruña Spain","Within the big data paradigm, there is an increasing demand for machine learning with automatic configuration of hyperparameters. Although several algorithms have been proposed for automatically learning time-changing concepts, they generally do not scale well to very large databases. In this context, this paper presents an automated green machine learning approach applied to condition-based maintenance with automatic data fusion and density-based anomaly detection based on locality sensitivity hashing. Experiments on numerical simulations of train-track dynamic interactions demonstrate the utility of the approach to detect railway wheel out-of-roundness. This unlocks the full potential of scalable machine learning, paving the way for environment-friendly systems and automated decision-making. * The present work has been developed under project FERROVIA 4.0 (POCI-01-0247-FEDER-046111) and WAY4SafeRail (NORTE-01-0247-FEDER-069595). It has been supported by Portuguese Foundation for Science and Technology under project UIDB-00760-2020 and Spain´s Ministerium of Science and Innovation MCIN-",Green Machine Learning,https://doi.org/10.14428/esann/2023.ES2023-85,2023,100.0,"Automated green machine learning for condition-based maintenance Within the big data paradigm, there is an increasing demand for machine learning with automatic configuration of hyperparameters. Although several algorithms have been proposed for automatically learning time-changing concepts, they generally do not scale well to very large databases. In this context, this paper presents an automated green machine learning approach applied to condition-based maintenance with automatic data fusion and density-based anomaly detection based on locality sensitivity hashing. Experiments on numerical simulations of train-track dynamic interactions demonstrate the utility of the approach to detect railway wheel out-of-roundness. This unlocks the full potential of scalable machine learning, paving the way for environment-friendly systems and automated decision-making. * The present work has been developed under project FERROVIA 4.0 (POCI-01-0247-FEDER-046111) and WAY4SafeRail (NORTE-01-0247-FEDER-069595). It has been supported by Portuguese Foundation for Science and Technology under project UIDB-00760-2020 and Spain´s Ministerium of Science and Innovation MCIN-"
Deep dynamic co-clustering of streams of count data: a new online Zip-dLBM,"Giulia Marchello, Marco Corneli, Charles Bouveyron","1 - Université Côte d'Azur Inria
2 - Laboratoire J.A.Dieudonné CNRS Maasai team Nice France
5 - Laboratoire CEPAM Université Côte d'Azur Nice France","Co-clustering is a technique used to analyze complex and high-dimensional data in various fields. However, traditional co-clustering methods are usually limited to dense data sets and require massive amount of memory, which can be limiting in some applications. To address this issue, we propose an online co-clustering model that processes the data incrementally and introduces a novel latent block model for sparse data matrices. The proposed model employs a LSTM neural network and a time and block dependent mixture of zero-inflated distributions to model sparsity and aims to detect real-time changes in dynamics through Bayesian online change point detection. An original variational procedure is proposed for inference. Simulations demonstrate the effectiveness of the methodology for count data.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-86,2023,100.0,"Deep dynamic co-clustering of streams of count data: a new online Zip-dLBM Co-clustering is a technique used to analyze complex and high-dimensional data in various fields. However, traditional co-clustering methods are usually limited to dense data sets and require massive amount of memory, which can be limiting in some applications. To address this issue, we propose an online co-clustering model that processes the data incrementally and introduces a novel latent block model for sparse data matrices. The proposed model employs a LSTM neural network and a time and block dependent mixture of zero-inflated distributions to model sparsity and aims to detect real-time changes in dynamics through Bayesian online change point detection. An original variational procedure is proposed for inference. Simulations demonstrate the effectiveness of the methodology for count data."
Communication-Efficient Ridge Regression in Federated Echo State Networks,"Valerio De Caro, Antonio Mauro, Davide Bacciu, Claudio Gallicchio","1 - Department of Computer Science University of Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","Federated Echo State Networks represent an efficient methodology for learning in pervasive environments with private temporal data due to the low computational cost required by the learning phase. In this paper, we propose Partial Federated Ridge Regression (pFedRR), an approximate, communication-efficient version of the exact method for learning the readout in a federated setting. Each client compresses the local statistics to be exchanged with the server via an importance-based method, which selects the most relevant neurons with respect to the local distribution. We evaluate the methodology on two Human State Monitoring benchmarks, and results show that the importance-based selection of the information significantly reduces the communication cost, while acting as a regularization method to improve the generalization capabilities.","Sequential data, and Meta-learning",https://doi.org/10.14428/esann/2023.ES2023-87,2023,100.0,"Communication-Efficient Ridge Regression in Federated Echo State Networks Federated Echo State Networks represent an efficient methodology for learning in pervasive environments with private temporal data due to the low computational cost required by the learning phase. In this paper, we propose Partial Federated Ridge Regression (pFedRR), an approximate, communication-efficient version of the exact method for learning the readout in a federated setting. Each client compresses the local statistics to be exchanged with the server via an importance-based method, which selects the most relevant neurons with respect to the local distribution. We evaluate the methodology on two Human State Monitoring benchmarks, and results show that the importance-based selection of the information significantly reduces the communication cost, while acting as a regularization method to improve the generalization capabilities."
Segmentation and Analysis of Lumbar Spine MRI Scans for Vertebral Body Measurements,"Helen Schneider, David Biesner, Akash Ashokan, Maximilian Broß, Rebecca Kador, Sandra Halscheidt, Gábor Bagyó, Peter Dankerl, Haissam Ragab, Jin Yamamura, et al.",1 - Fraunhofer IAIS Sankt Augustin 2-evidia GmbH Dortmund 3-Diagnostic and Interventional Radiology University Medical Center Hamburg-Eppendorf,"This paper investigates a data-and knowledge-driven approach to automatically analyze lumbar MRI scans. The dataset used is an in-house dataset of 142 sagital lumbar spine images from German radiology practices of the evidia GmbH. We implement state-of-the-art deep learning methods to segment the individual vertebral bodies. Overall, a very accurate segmentation performance of 97% Dice Score was achieved. Based on this segmentation, pathologically relevant distances are calculated using rule-based computer vision methods. We focus on the anterior, posterior and middle height of a vertebra and the anterior and posterior distances between two lumbar vertebrae. We demonstrate the clinical value of this approach through a quantitative and qualitative result analysis.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-88,2023,100.0,"Segmentation and Analysis of Lumbar Spine MRI Scans for Vertebral Body Measurements This paper investigates a data-and knowledge-driven approach to automatically analyze lumbar MRI scans. The dataset used is an in-house dataset of 142 sagital lumbar spine images from German radiology practices of the evidia GmbH. We implement state-of-the-art deep learning methods to segment the individual vertebral bodies. Overall, a very accurate segmentation performance of 97% Dice Score was achieved. Based on this segmentation, pathologically relevant distances are calculated using rule-based computer vision methods. We focus on the anterior, posterior and middle height of a vertebra and the anterior and posterior distances between two lumbar vertebrae. We demonstrate the clinical value of this approach through a quantitative and qualitative result analysis."
Is Boredom an Indicator on the way to Singularity of Artificial Intelligence? Hypotheses as Thought-Provoking Impulse,Martin Bogdan,1 - Leipzig University -Neuromorphic Information Processing Augustusplatz 10 04109 Leipzig Germany,"In the past, the question regarding the point of singularity in artificial intelligence -when machines become more intelligent than humans -has been raised again and again. In this publication, a crucial point of human intelligence and the impact on this discussion will be postulated in the form of 3 hypotheses as thought-provoking impulse based on the basic hypothesis, that only systems which can be bored are intelligent. First, boredom is discussed from the perspective of psychology with its influence on human intelligence before deductions are drawn from this to artificial intelligence resp. machine learning. Finally, the hypotheses are formulated and the resulting future investigations are outlined.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-89,2023,100.0,"Is Boredom an Indicator on the way to Singularity of Artificial Intelligence? Hypotheses as Thought-Provoking Impulse In the past, the question regarding the point of singularity in artificial intelligence -when machines become more intelligent than humans -has been raised again and again. In this publication, a crucial point of human intelligence and the impact on this discussion will be postulated in the form of 3 hypotheses as thought-provoking impulse based on the basic hypothesis, that only systems which can be bored are intelligent. First, boredom is discussed from the perspective of psychology with its influence on human intelligence before deductions are drawn from this to artificial intelligence resp. machine learning. Finally, the hypotheses are formulated and the resulting future investigations are outlined."
Improving Fairness via Intrinsic Plasticity in Echo State Networks,"Andrea Ceni, Davide Bacciu, Valerio De Caro, Claudio Gallicchio, Luca Oneto","1 - University of Pisa Largo Bruno Pontecorvo 3 56127 Pisa Italy
5 - University of Genoa Via Opera Pia 11a 16145 Genova Italy","Artificial Intelligence, and in particular Machine Learning, has become ubiquitous in today's society, both revolutionizing and impacting society as a whole. However, it can also lead to algorithmic bias and unfair results, especially when sensitive information is involved. This paper addresses the problem of algorithmic fairness in Machine Learning for temporal data, focusing on ensuring that sensitive time-dependent information does not unfairly influence the outcome of a classifier. In particular, we focus on a class of training-efficient recurrent neural models called Echo State Networks, and show, for the first time, how to leverage local unsupervised adaptation of the internal dynamics in order to build fairer classifiers. Experimental results on real-world problems from physiological sensor data demonstrate the potential of the proposal.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-90,2023,100.0,"Improving Fairness via Intrinsic Plasticity in Echo State Networks Artificial Intelligence, and in particular Machine Learning, has become ubiquitous in today's society, both revolutionizing and impacting society as a whole. However, it can also lead to algorithmic bias and unfair results, especially when sensitive information is involved. This paper addresses the problem of algorithmic fairness in Machine Learning for temporal data, focusing on ensuring that sensitive time-dependent information does not unfairly influence the outcome of a classifier. In particular, we focus on a class of training-efficient recurrent neural models called Echo State Networks, and show, for the first time, how to leverage local unsupervised adaptation of the internal dynamics in order to build fairer classifiers. Experimental results on real-world problems from physiological sensor data demonstrate the potential of the proposal."
On Instance Weighted Clustering Ensembles,"Paul Moggridge, Na Helian, Yi Sun, Mariana Lilley",1 - School of Physics Engineering and Computer Science Department of Computer Science University of Hertfordshire Hatfield UK,"Ensemble clustering is a technique which combines multiple clustering results, and instance weighting is a technique which highlights important instances in a dataset. Both techniques are known to enhance clustering performance and robustness. In this research, ensembles and instance weighting are integrated with the spectral clustering algorithm. We believe this is the first attempt at creating diversity in the generative mechanism using density based instance weighting for a spectral ensemble. The proposed approach is empirically validated using synthetic datasets comparing against spectral and a spectral ensemble with random instance weighting. Results show that using the instance weighted sub-sampling approach as the generative mechanism for an ensemble of spectral clustering leads to improved clustering performance on datasets with imbalanced clusters.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-91,2023,100.0,"On Instance Weighted Clustering Ensembles Ensemble clustering is a technique which combines multiple clustering results, and instance weighting is a technique which highlights important instances in a dataset. Both techniques are known to enhance clustering performance and robustness. In this research, ensembles and instance weighting are integrated with the spectral clustering algorithm. We believe this is the first attempt at creating diversity in the generative mechanism using density based instance weighting for a spectral ensemble. The proposed approach is empirically validated using synthetic datasets comparing against spectral and a spectral ensemble with random instance weighting. Results show that using the instance weighted sub-sampling approach as the generative mechanism for an ensemble of spectral clustering leads to improved clustering performance on datasets with imbalanced clusters."
Policy-Based Reinforcement Learning in the Generalized Rock-Paper-Scissors Game,"Mali Gergely, Gabriela Czibula",1 - Department of Computer Science Babeş-Bolyai University Romania,"The Rock-Paper-Scissors game is a popular zero-sum game of cyclic nature, with a mixed-strategy Nash-equilibrium that has been the subject of a large number of studies and is of particular interest for economy, sociology and artificial intelligence. While there are numerous studies exploring evolutionary dynamics and learning, the overwhelming majority of these consider the game in its classical form, and two important axes with potential relevance remain unexplored. First, studies with policy-based reinforcement algorithms are lacking, and second, few existing investigations attempted to study such cyclic games with more than two players. The present work aims to address both of these matters.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-92,2023,100.0,"Policy-Based Reinforcement Learning in the Generalized Rock-Paper-Scissors Game The Rock-Paper-Scissors game is a popular zero-sum game of cyclic nature, with a mixed-strategy Nash-equilibrium that has been the subject of a large number of studies and is of particular interest for economy, sociology and artificial intelligence. While there are numerous studies exploring evolutionary dynamics and learning, the overwhelming majority of these consider the game in its classical form, and two important axes with potential relevance remain unexplored. First, studies with policy-based reinforcement algorithms are lacking, and second, few existing investigations attempted to study such cyclic games with more than two players. The present work aims to address both of these matters."
Logarithmic Quantum Forking,"Alessandro Berti, Anna Bernasconi, Gianna Corso, Riccardo Guidotti","1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 56127 Pisa Italy
2 - University of Pisa","Quantum algorithms evolve an initial quantum state into another during computation to obtain meaningful results. However, this evolution introduces the cost of re-preparing the same initial quantum state for different tasks. Unfortunately, since quantum memory is not yet available, this cost cannot be ignored in Quantum Artificial Intelligence (QAI), where the initial quantum state typically coincides with a quantum dataset. Redundant state preparations for different tasks on the same dataset can reduce the advantages of quantum computation. To address this issue, this work proposes a new technique: the Logarithmic Quantum Forking (LQF). LQF performs state preparation for an initial quantum state once and employs additional qubits to compute an exponential number of tasks over the initial quantum state. LQF enables more efficient use of quantum computation in QAI by amortizing the cost of preparing the initial quantum state.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-93,2023,100.0,"Logarithmic Quantum Forking Quantum algorithms evolve an initial quantum state into another during computation to obtain meaningful results. However, this evolution introduces the cost of re-preparing the same initial quantum state for different tasks. Unfortunately, since quantum memory is not yet available, this cost cannot be ignored in Quantum Artificial Intelligence (QAI), where the initial quantum state typically coincides with a quantum dataset. Redundant state preparations for different tasks on the same dataset can reduce the advantages of quantum computation. To address this issue, this work proposes a new technique: the Logarithmic Quantum Forking (LQF). LQF performs state preparation for an initial quantum state once and employs additional qubits to compute an exponential number of tasks over the initial quantum state. LQF enables more efficient use of quantum computation in QAI by amortizing the cost of preparing the initial quantum state."
Variants of Neural Gas for Regression Learning,"Ronny Schubert, Marika Kaden, Thomas Villmann",1 - Mittweida University of Applied Sciences Saxon Institute for Computational Intelligence and Machine Learning Technikumplatz 17 09648 Mittweida,"Approximation problems, and thus regression problems, have been widely considered as machine learning problems. A popular model to tackle such tasks are radial-basis-function networks (RBFN) and variants thereof. However, due to the global approximation scheme, RBFN, when trained in a supervised manner without additional constraints, may lack local representation. To this end, we propose approaches that aim to preserve locality in terms of the regression problem by using the Neural Gas algorithm. The models are tested on different data sets and compared to the supervised RBFN approach. * R. S. is supported by grants of the Agriculture Ministry of Germany (28DK112A20).","Anomaly Detection, and Learning Algorithms",https://doi.org/10.14428/esann/2023.ES2023-94,2023,100.0,"Variants of Neural Gas for Regression Learning Approximation problems, and thus regression problems, have been widely considered as machine learning problems. A popular model to tackle such tasks are radial-basis-function networks (RBFN) and variants thereof. However, due to the global approximation scheme, RBFN, when trained in a supervised manner without additional constraints, may lack local representation. To this end, we propose approaches that aim to preserve locality in terms of the regression problem by using the Neural Gas algorithm. The models are tested on different data sets and compared to the supervised RBFN approach. * R. S. is supported by grants of the Agriculture Ministry of Germany (28DK112A20)."
Learning Vector Quantization in Context of Information Bottleneck Theory,"M Bakhtiari, D Staps, T Villmann",1 - Mittweida University of Applied Sciences -Dept. of Comp. Science & Bio-informatics -Mittweida Germany,"This paper is an effort to parameterize Information Bottle-neck Theory to become a supervised classifier. We introduce a parametrization by means of Learning Vector Quantization. With this new approach, one can find suitable components that are necessary for an accurate, yet efficient, classification. A balance between compression and representation is made by means of a specially designed objective function.",Classification,https://doi.org/10.14428/esann/2023.ES2023-95,2023,100.0,"Learning Vector Quantization in Context of Information Bottleneck Theory This paper is an effort to parameterize Information Bottle-neck Theory to become a supervised classifier. We introduce a parametrization by means of Learning Vector Quantization. With this new approach, one can find suitable components that are necessary for an accurate, yet efficient, classification. A balance between compression and representation is made by means of a specially designed objective function."
DEFENDER: DTW-Based Episode Filtering Using Demonstrations for Enhancing RL Safety,"André Correia, Luís Alexandre",1 - Universidade da Beira Interior NOVA LINCS Covilhã Portugal,"Deploying reinforcement learning agents in the real world can be challenging due to the risks associated with learning through trial and error. We propose a task-agnostic method that leverages small sets of safe and unsafe demonstrations to improve the safety of RL agents during learning. The method compares the current trajectory of the agent with both sets of demonstrations at every step, and filters the trajectory if it resembles the unsafe demonstrations. We perform ablation studies on different filtering strategies and investigate the impact of the number of demonstrations on performance. Our method is compatible with any stand-alone RL algorithm and can be applied to any task. We evaluate our method on three tasks from OpenAI Gym's Mujoco benchmark and two state-of-the-art RL algorithms. The results demonstrate that our method significantly reduces the crash rate of the agent while converging to, and in most cases even improving, the performance of the stand-alone agent.",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-97,2023,100.0,"DEFENDER: DTW-Based Episode Filtering Using Demonstrations for Enhancing RL Safety Deploying reinforcement learning agents in the real world can be challenging due to the risks associated with learning through trial and error. We propose a task-agnostic method that leverages small sets of safe and unsafe demonstrations to improve the safety of RL agents during learning. The method compares the current trajectory of the agent with both sets of demonstrations at every step, and filters the trajectory if it resembles the unsafe demonstrations. We perform ablation studies on different filtering strategies and investigate the impact of the number of demonstrations on performance. Our method is compatible with any stand-alone RL algorithm and can be applied to any task. We evaluate our method on three tasks from OpenAI Gym's Mujoco benchmark and two state-of-the-art RL algorithms. The results demonstrate that our method significantly reduces the crash rate of the agent while converging to, and in most cases even improving, the performance of the stand-alone agent."
Quantum Feature Selection with Variance Estimation,"Alessandro Poggiali, Anna Bernasconi, Alessandro Berti, Gianna Corso, Riccardo Guidotti",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 56127 Pisa Italy,"The promise of quantum computation to achieve a speedup over classical computation led to a surge of interest in exploring new quantum algorithms for data analysis problems. Feature Selection, a technique that selects the most relevant features from a dataset, is a critical step in data analysis. With several Quantum Feature Selection techniques proposed in the literature, this study exhibits the potential of quantum algorithms to enhance Feature Selection and other tasks that leverage the variance. This study proposes a novel quantum algorithm for estimating the variance over a set of real data. Importantly, after state preparation, the algorithm's complexity exhibits logarithmic characteristics in both its width and depth. The quantum algorithm applies to the Feature Selection problem by designing a Hybrid Quantum Feature Selection (HQFS) algorithm. This work showcases an implementation of HQFS and assesses it on two synthetic datasets and a real dataset.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-99,2023,100.0,"Quantum Feature Selection with Variance Estimation The promise of quantum computation to achieve a speedup over classical computation led to a surge of interest in exploring new quantum algorithms for data analysis problems. Feature Selection, a technique that selects the most relevant features from a dataset, is a critical step in data analysis. With several Quantum Feature Selection techniques proposed in the literature, this study exhibits the potential of quantum algorithms to enhance Feature Selection and other tasks that leverage the variance. This study proposes a novel quantum algorithm for estimating the variance over a set of real data. Importantly, after state preparation, the algorithm's complexity exhibits logarithmic characteristics in both its width and depth. The quantum algorithm applies to the Feature Selection problem by designing a Hybrid Quantum Feature Selection (HQFS) algorithm. This work showcases an implementation of HQFS and assesses it on two synthetic datasets and a real dataset."
Informed Machine Learning for Complex Data,"Luca Oneto, Nicolò Navarin, Alessio Micheli, Luca Pasa, Claudio Gallicchio, Davide Bacciu, Davide Anguita","1 - University of Genoa Via Opera Pia 11a 16145 Genova Italy
2 - University of Padua -Via Trieste 63 35121 Padua -Italy
3 - University of Pisa -Largo Bruno Pontecorvo 3 56127 Pisa Italy","In the contemporary era of data-driven decision-making, the application of Machine Learning (ML) on complex data (e.g., images, text, sequences, trees, and graphs) has become increasingly pivotal (e.g., Large Language Models and Graph Neural Networks). In this context, there is a gap between purely data-driven models and domain-specific knowledge, requirements, and expertise. In particular, this domain specificity needs to be integrated into the ML models to improve learning generalization, sustainability, trustworthiness, reliability, security, and safety. This additional knowledge can assume different forms, e.g.: software developers require ML to comply with many technical requirements, companies require ML to comply with economic and environmental sustainability, domain experts require ML to be aligned with physical and logical laws, and society requires ML to be aligned with ethical principles. This special session gathers valuable contributions and early findings in the field of Informed ML for Complex Data. Our main objective is to showcase the potential and limitations of new ideas, improvements, or the blending of ML and other research areas in solving real-world problems.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-1,2024,100.0,"Informed Machine Learning for Complex Data In the contemporary era of data-driven decision-making, the application of Machine Learning (ML) on complex data (e.g., images, text, sequences, trees, and graphs) has become increasingly pivotal (e.g., Large Language Models and Graph Neural Networks). In this context, there is a gap between purely data-driven models and domain-specific knowledge, requirements, and expertise. In particular, this domain specificity needs to be integrated into the ML models to improve learning generalization, sustainability, trustworthiness, reliability, security, and safety. This additional knowledge can assume different forms, e.g.: software developers require ML to comply with many technical requirements, companies require ML to comply with economic and environmental sustainability, domain experts require ML to be aligned with physical and logical laws, and society requires ML to be aligned with ethical principles. This special session gathers valuable contributions and early findings in the field of Informed ML for Complex Data. Our main objective is to showcase the potential and limitations of new ideas, improvements, or the blending of ML and other research areas in solving real-world problems."
Stable Diffusion Dataset Generation for Downstream Classification Tasks,"Eugenio Lomurno, Matteo D'oria, Matteo Matteucci","1 - Department of Electronics, Information, and Bioengineering Politecnico di Milano Milan Italy","Recent advances in generative artificial intelligence have enabled the creation of high-quality synthetic data that closely mimics real-world data. This paper explores the adaptation of the Stable Diffusion 2.0 model for generating synthetic datasets, using Transfer Learning, Fine-Tuning and generation parameter optimisation techniques to improve the utility of the dataset for downstream classification tasks. We present a class-conditional version of the model that exploits a Class-Encoder and optimisation of key generation parameters. Our methodology led to synthetic datasets that, in a third of cases, produced models that outperformed those trained on real datasets.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-100,2024,100.0,"Stable Diffusion Dataset Generation for Downstream Classification Tasks Recent advances in generative artificial intelligence have enabled the creation of high-quality synthetic data that closely mimics real-world data. This paper explores the adaptation of the Stable Diffusion 2.0 model for generating synthetic datasets, using Transfer Learning, Fine-Tuning and generation parameter optimisation techniques to improve the utility of the dataset for downstream classification tasks. We present a class-conditional version of the model that exploits a Class-Encoder and optimisation of key generation parameters. Our methodology led to synthetic datasets that, in a third of cases, produced models that outperformed those trained on real datasets."
LSTM encoder-decoder model for contextualized time series forecasting applied to the simulation of a digital patient's physiological variables,"J Paris, C Sinoquet, F Taia-Alaoui, C Lejus-Bourdeau","1 - Nantes University Hospital CR2TI / UMR 1064 Inserm France
2 - LS2N UMR CNRS 6004 Nantes University France
3 - GRICAD Grenoble France
4 - LE SiMU / Nantes University Hospital Nantes University France","This paper explores utilizing an encoder-decoder neural architecture for unsupervised representation learning of mixed asynchronous data, presenting the jmetts (Joint Modelling of Event Traces and Time Series) model. Our goal is to forecast short-term multivariate time series within event contexts. As a proof of concept, we examine a real-world case in digitally assisted training for anaesthesiology. jmetts demonstrates high predictive performance, with a maximum prediction error percentage of approximately 5.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-105,2024,99.64912280701755,"LSTM encoder-decoder model for contextualized time series forecasting applied to the simulation of a digital patient's physiological variables This paper explores utilizing an encoder-decoder neural architecture for unsupervised representation learning of mixed asynchronous data, presenting the jmetts (Joint Modelling of Event Traces and Time Series) model. Our goal is to forecast short-term multivariate time series within event contexts. As a proof of concept, we examine a real-world case in digitally assisted training for anaesthesiology. jmetts demonstrates high predictive performance, with a maximum prediction error percentage of approximately 5."
Multidimensional CDTW-based features for Parkinson's Disease classification,"Ferhat Attal, Nicolas Khoury, Yacine Amirat",1 - LISSI Laboratory Est Creteil University Paris France,"This paper presents an improvement of the Unidimensional Continuous Dynamic Time Warping (UCDTW) method for diagnosing Parkinson's Disease (PD) based on multidimensional time series data. These data include recordings of vertical Ground Reaction Forces (vGRFs) collected from eight force sensors per shoe sole during the walk. Leveraging gait cycle patterns, the proposed approach distinguishes between healthy and PD subjects by assessing gait cycle repetition through Multidimensional CDTW. Several classification methods, including supervised (K-NN, DT, RF, SVM) and unsupervised (GMM, K-means), are used to classify the healthy and PD subjects, using MCDTW distances extracted from the gait cycles. The obtained results show a significant improvement in terms of classification performances when using MCDTW-based features compared to unidimensional ones.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-106,2024,100.0,"Multidimensional CDTW-based features for Parkinson's Disease classification This paper presents an improvement of the Unidimensional Continuous Dynamic Time Warping (UCDTW) method for diagnosing Parkinson's Disease (PD) based on multidimensional time series data. These data include recordings of vertical Ground Reaction Forces (vGRFs) collected from eight force sensors per shoe sole during the walk. Leveraging gait cycle patterns, the proposed approach distinguishes between healthy and PD subjects by assessing gait cycle repetition through Multidimensional CDTW. Several classification methods, including supervised (K-NN, DT, RF, SVM) and unsupervised (GMM, K-means), are used to classify the healthy and PD subjects, using MCDTW distances extracted from the gait cycles. The obtained results show a significant improvement in terms of classification performances when using MCDTW-based features compared to unidimensional ones."
Influence of Data Characteristics on Machine Learning Classification Performance and Stability of SHapley Additive exPlanations,"Anusha Ihalapathirana, Gunjan Chandra, Piia Lavikainen, Pekka Siirtola, Satu Tamminen, Nirzor Talukder, Janne Martikainen, Juha Röning","1 - -Biomimetics and Intelligent Systems Group University of Oulu Finland
3 - School of Pharmacy University of Eastern Finland Kuopio Finland","This study explores the effects of different data sizes and data imbalance on model performance and the stability of SHapley Additive ex-Planations (SHAP). The study utilizes a Type 2 diabetes (T2D) dataset to train three machine learning (ML) models: linear discriminant analysis, XGBoost, and a neural network. It shows that adjusting the background dataset size leads to variations in the SHAP values, with decreased variance observed in larger and balanced datasets. Furthermore, the study highlights that the data characteristics leading to high model performance may not always produce reliable and stable SHAP explanations.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-107,2024,100.0,"Influence of Data Characteristics on Machine Learning Classification Performance and Stability of SHapley Additive exPlanations This study explores the effects of different data sizes and data imbalance on model performance and the stability of SHapley Additive ex-Planations (SHAP). The study utilizes a Type 2 diabetes (T2D) dataset to train three machine learning (ML) models: linear discriminant analysis, XGBoost, and a neural network. It shows that adjusting the background dataset size leads to variations in the SHAP values, with decreased variance observed in larger and balanced datasets. Furthermore, the study highlights that the data characteristics leading to high model performance may not always produce reliable and stable SHAP explanations."
Leveraging Physics-Informed Neural Networks as Solar Wind Forecasting Models,"Nuno Costa, Filipa Barros, J Lima, Rui Pinto, André Restivo","1 - LIACC / Faculdade Engenharia da Universidade do Porto Portugal
3 - Instituto de Astrofísica e Ciências do Espaço CAUP Porto Portugal
4 - Institut de Recherche and Astrophysique et Planétologie OMP/CNRS CNES University of Toulouse Toulouse France
6 - Departamento de Física e Astronomia FCUP Porto Portugal","Space weather refers to the dynamic conditions in the solar system, particularly the interactions between the solar wind -a stream of charged particles emitted by the Sun -and the Earth's magnetic field and atmosphere. Accurate space weather forecasting is crucial for mitigating potential impacts on satellite operations, communication systems, power grids, and astronaut safety. However, existing solar wind coronal models like MULTI-VP require substantial computational resources. This paper proposes a Physics-Informed Neural Network (PiNN) as a faster yet accurate alternative that respects physical laws. PiNNs blend physics and data-driven techniques for rapid and reliable forecasts. Our studies show that PiNNs can reduce computation times and deliver forecasts comparable to MULTI-VP, offering an expedited and dependable solar wind forecasting approach.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-110,2024,100.0,"Leveraging Physics-Informed Neural Networks as Solar Wind Forecasting Models Space weather refers to the dynamic conditions in the solar system, particularly the interactions between the solar wind -a stream of charged particles emitted by the Sun -and the Earth's magnetic field and atmosphere. Accurate space weather forecasting is crucial for mitigating potential impacts on satellite operations, communication systems, power grids, and astronaut safety. However, existing solar wind coronal models like MULTI-VP require substantial computational resources. This paper proposes a Physics-Informed Neural Network (PiNN) as a faster yet accurate alternative that respects physical laws. PiNNs blend physics and data-driven techniques for rapid and reliable forecasts. Our studies show that PiNNs can reduce computation times and deliver forecasts comparable to MULTI-VP, offering an expedited and dependable solar wind forecasting approach."
Investigating the Gestalt Principle of Closure in Deep Convolutional Neural Networks,"Yuyan Zhang, Derya Soydaner, Fatemeh Behrad, Lisa Koßmann, Johan Wagemans","1 - Department of Computer Science Department of Brain and Cognition -KU Leuven 2-KU Leuven, Leuven, Leuven Belgium, Belgium
2 - -Leuven.AI KU Leuven Institute for AI Leuven Belgium","Deep neural networks perform well in object recognition, but do they perceive objects like humans? This study investigates the Gestalt principle of closure in convolutional neural networks. We propose a protocol to identify closure and conduct experiments using simple visual stimuli with progressively removed edge sections. We evaluate well-known networks on their ability to classify incomplete polygons. Our findings reveal a performance degradation as the edge removal percentage increases, indicating that current models heavily rely on complete edge information for accurate classification. The data used in our study is available on Github.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-111,2024,100.0,"Investigating the Gestalt Principle of Closure in Deep Convolutional Neural Networks Deep neural networks perform well in object recognition, but do they perceive objects like humans? This study investigates the Gestalt principle of closure in convolutional neural networks. We propose a protocol to identify closure and conduct experiments using simple visual stimuli with progressively removed edge sections. We evaluate well-known networks on their ability to classify incomplete polygons. Our findings reveal a performance degradation as the edge removal percentage increases, indicating that current models heavily rely on complete edge information for accurate classification. The data used in our study is available on Github."
Deep Riemannian Neural Architectures for Domain Adaptation in Burst cVEP-based Brain Computer Interface,"Velut Sébastien, Chevallier Sylvain, Corsi Marie-Constance, Dehais Frédéric","1 - Fédération ENAC ISAE-SUPAERO ONERA Université de Toulouse 10 avenue Edouard Belin 31400 Toulouse France
2 - A&O -LISN Université Paris-Saclay 1 rue René Thom 91190 Gif-sur-Yvette France
4 - Institut du Cerveau Sorbonne Université Paris Brain Institute -ICM
5 - CNRS Hopital de la Pitié Salpetriere F-75013 Paris Inria, Inserm, AP-HP France","Code modulated Visually Evoked Potentials (cVEP) is an emerging paradigm for Brain-Computer Interfaces (BCIs) that offers reduced calibration times. However, cVEP-based BCIs still encounter challenges related to cross-session/subject variabilities. As Riemannian approaches have demonstrated good robustness to these variabilities, we propose the first study of deep Riemannian neural architectures, namely SPDNets, on cVEP-based BCIs. To evaluate their performance with respect to subject variabilities, we conduct classification tasks in a domain adaptation framework using a burst cVEP open dataset. This study demonstrates that SPDNet yields the best accuracy with single-subject calibration and promising results in domain adaptation.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-112,2024,100.0,"Deep Riemannian Neural Architectures for Domain Adaptation in Burst cVEP-based Brain Computer Interface Code modulated Visually Evoked Potentials (cVEP) is an emerging paradigm for Brain-Computer Interfaces (BCIs) that offers reduced calibration times. However, cVEP-based BCIs still encounter challenges related to cross-session/subject variabilities. As Riemannian approaches have demonstrated good robustness to these variabilities, we propose the first study of deep Riemannian neural architectures, namely SPDNets, on cVEP-based BCIs. To evaluate their performance with respect to subject variabilities, we conduct classification tasks in a domain adaptation framework using a burst cVEP open dataset. This study demonstrates that SPDNet yields the best accuracy with single-subject calibration and promising results in domain adaptation."
Exploring High-and Low-Density Electroencephalography for a Dream Decoding Brain-Computer Interface,"Mithila Packiyanathan, André Torvestad, Luis Moctezuma, Marta Molinas","1 - Department of Engineering Cybernetics Norwegian University of Science and Technology. Trondheim Norway
3 - International Institute for Integrative Sleep Medicine University of Tsukuba. Tsukuba Ibaraki Japan","A high-performance real-time brain-computer interface system capable of identifying dreams has potential for healthcare applications. To address this, we use electroencephalogram (EEG) data from non-rapid eye movement sleep to classify dream experience and noexperience. Using 58 EEG channels, we achieve an accuracy of 0.94, an AUROC of 0.91, and a kappa score of 0.84, accomplished by first filtering the data through multivariate empirical mode decomposition followed by a combination of principal component analysis and common spatial patterns for feature extraction and K-nearest neighbors classifier. Interestingly, comparable results are obtained using 29 or 10 EEG channels selected by permutation-based channel selection.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-115,2024,96.4824120603015,"Exploring High-and Low-Density Electroencephalography for a Dream Decoding Brain-Computer Interface A high-performance real-time brain-computer interface system capable of identifying dreams has potential for healthcare applications. To address this, we use electroencephalogram (EEG) data from non-rapid eye movement sleep to classify dream experience and noexperience. Using 58 EEG channels, we achieve an accuracy of 0.94, an AUROC of 0.91, and a kappa score of 0.84, accomplished by first filtering the data through multivariate empirical mode decomposition followed by a combination of principal component analysis and common spatial patterns for feature extraction and K-nearest neighbors classifier. Interestingly, comparable results are obtained using 29 or 10 EEG channels selected by permutation-based channel selection."
On-line Learning Dynamics in Layered Neural Networks with Arbitrary Activation Functions *,"Otavio Citton, Frederieke Richert, Michael Biehl","1 - Intelligent Systems -Bernoulli Institute University of Groningen Nijenborgh 9 9747 AG Groningen The Netherlands
2 - Groningen Cognitive Systems and Materials Center (CogniGron) University of Groningen Groningen The Netherlands","We revisit and extend the statistical physics based analysis of layered neural networks trained by online gradient descent. We focus on the influence of the hidden unit activation functions on the typical learning behavior in model scenarios. Expanding activation functions in terms of Hermite polynomials enables us to extend the formalism to the analysis of soft committee machines with arbitrary activation in student-teacher scenarios. This approach requires much lower computational effort than naive numerical integration, which is practically infeasible. Moreover, it now becomes possible to treat mismatched scenarios in which the student activation function differs from the one used in the target rule definition. This makes it possible to study realistic models of machine learning. * The code used for the analysis can be found in our GitHub repository. † This work is funded by NWO M1 grant OCENW.M20.287 and CogniGron.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-116,2024,98.87640449438202,"On-line Learning Dynamics in Layered Neural Networks with Arbitrary Activation Functions * We revisit and extend the statistical physics based analysis of layered neural networks trained by online gradient descent. We focus on the influence of the hidden unit activation functions on the typical learning behavior in model scenarios. Expanding activation functions in terms of Hermite polynomials enables us to extend the formalism to the analysis of soft committee machines with arbitrary activation in student-teacher scenarios. This approach requires much lower computational effort than naive numerical integration, which is practically infeasible. Moreover, it now becomes possible to treat mismatched scenarios in which the student activation function differs from the one used in the target rule definition. This makes it possible to study realistic models of machine learning. * The code used for the analysis can be found in our GitHub repository. † This work is funded by NWO M1 grant OCENW.M20.287 and CogniGron."
Reservoir Memory Networks,"Claudio Gallicchio, Andrea Ceni",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 -56127 Pisa Italy,"We introduce Reservoir Memory Networks (RMNs), a novel class of Reservoir Computing (RC) models that integrate a linear memory cell with a non-linear reservoir to enhance long-term information retention. We explore various configurations of the memory cell using orthogonal circular shift matrices and Legendre polynomials, alongside nonlinear reservoirs configured as in Echo State Networks and Euler State Networks. Experimental results demonstrate the substantial benefits of RMNs in time-series classification tasks, highlighting their potential for advancing RC applications in areas requiring robust temporal processing.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-117,2024,100.0,"Reservoir Memory Networks We introduce Reservoir Memory Networks (RMNs), a novel class of Reservoir Computing (RC) models that integrate a linear memory cell with a non-linear reservoir to enhance long-term information retention. We explore various configurations of the memory cell using orthogonal circular shift matrices and Legendre polynomials, alongside nonlinear reservoirs configured as in Echo State Networks and Euler State Networks. Experimental results demonstrate the substantial benefits of RMNs in time-series classification tasks, highlighting their potential for advancing RC applications in areas requiring robust temporal processing."
An Efficient Neural Architecture Search Model for Medical Image Classification,"Lunchen Xie, Eugenio Lomurno, Matteo Gambella, Danilo Ardagna, Manuel Roveri, Matteo Matteucci, Qingjiang Shi","1 - Tongji University Shanghai China
2 - School of Software Engineering
3 - Politecnico di Milano Milan Italy
4 - Department of Electronics, Information, and Bioengineering","Accurate classification of medical images is essential for modern diagnostics. Deep learning advancements led clinicians to increasingly use sophisticated models to make faster and more accurate decisions, sometimes replacing human judgment. However, model development is costly and repetitive. Neural Architecture Search (NAS) provides solutions by automating the design of deep learning architectures. This paper presents ZO-DARTS+, a differentiable NAS algorithm that improves search efficiency through a novel method of generating sparse probabilities by bilevel optimization. Experiments on five public medical datasets show that ZO-DARTS+ matches the accuracy of state-of-the-art solutions while reducing search times by up to three times.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-119,2024,100.0,"An Efficient Neural Architecture Search Model for Medical Image Classification Accurate classification of medical images is essential for modern diagnostics. Deep learning advancements led clinicians to increasingly use sophisticated models to make faster and more accurate decisions, sometimes replacing human judgment. However, model development is costly and repetitive. Neural Architecture Search (NAS) provides solutions by automating the design of deep learning architectures. This paper presents ZO-DARTS+, a differentiable NAS algorithm that improves search efficiency through a novel method of generating sparse probabilities by bilevel optimization. Experiments on five public medical datasets show that ZO-DARTS+ matches the accuracy of state-of-the-art solutions while reducing search times by up to three times."
Large-Scale Continuous Structure Learning from Time-Series Data,"Filippo Michelis, Riccardo Massidda, Davide Bacciu","1 - Department of Computer Science Università di Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","Structure learning is the problem of recovering from data a Directed Acyclic Graph (DAG) of the interactions among variables. By enforcing a differentiable acyclicity constraint on the adjacency matrix of the graph, existing methods solve this problem as an optimization problem and have been recently extended to time-series data. Due to the cubic computational complexity of existing acyclicity constraints, their application is limited to a few variables. In this paper, we introduce svarcosmo, an optimization-based structure learning method for time-series data that builds upon recent developments on unconstrained but provably acyclic models. We empirically show on both simulated and real data that svarcosmo correctly recovers the underlying DAG in significantly less time, enabling optimization-based structure learning on high-dimensional data.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-120,2024,100.0,"Large-Scale Continuous Structure Learning from Time-Series Data Structure learning is the problem of recovering from data a Directed Acyclic Graph (DAG) of the interactions among variables. By enforcing a differentiable acyclicity constraint on the adjacency matrix of the graph, existing methods solve this problem as an optimization problem and have been recently extended to time-series data. Due to the cubic computational complexity of existing acyclicity constraints, their application is limited to a few variables. In this paper, we introduce svarcosmo, an optimization-based structure learning method for time-series data that builds upon recent developments on unconstrained but provably acyclic models. We empirically show on both simulated and real data that svarcosmo correctly recovers the underlying DAG in significantly less time, enabling optimization-based structure learning on high-dimensional data."
Similarity-Based Zero-Shot Domain Adaptation for Wearables,"Markus Vieth, Nils Grimmelsmann, Axel Schneider, Barbara Hammer","1 - Machine Learning Group Inspiration 1 Bielefeld University 33619 Bielefeld Germany
2 - Hochschule Bielefeld -University of Applied Sciences and Arts Interaktion 1 33619 Bielefeld Germany","Biosensors measure signals from the human body, and usually process them with a small ML model on simple hardware. When a new person starts using such a device, a domain adaptation problem arises. We consider the case where no labels are known for the new person, but data (including labels) from several other people are available (unsupervised, multi-source). As an application scenario, we look at a shoe insole with 3-8 pressure sensors that estimates how much weight/force is put on the foot (regression problem). We propose a distance measure between a source and target domain, and a combination of all source models. Experiments on real world data from 13 persons show that our method outperforms all other tested methods by a good margin.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-123,2024,100.0,"Similarity-Based Zero-Shot Domain Adaptation for Wearables Biosensors measure signals from the human body, and usually process them with a small ML model on simple hardware. When a new person starts using such a device, a domain adaptation problem arises. We consider the case where no labels are known for the new person, but data (including labels) from several other people are available (unsupervised, multi-source). As an application scenario, we look at a shoe insole with 3-8 pressure sensors that estimates how much weight/force is put on the foot (regression problem). We propose a distance measure between a source and target domain, and a combination of all source models. Experiments on real world data from 13 persons show that our method outperforms all other tested methods by a good margin."
Noise Robust One-Class Intrusion Detection on Dynamic Graphs,"Aleksei Liuliakov, Alexander Schulz, Luca Hermes, Barbara Hammer",1 - Machine Learning Group CITEC building Bielefeld University Inspiration 1 33619 Bielefeld Germany,"In the domain of network intrusion detection, robustness against contaminated and noisy data inputs remains a critical challenge. This study introduces a probabilistic version of the Temporal Graph Network Support Vector Data Description (TGN-SVDD) model, designed to enhance detection accuracy in the presence of input noise. By predicting parameters of a Gaussian distribution for each network event, our model is able to naturally address noisy adversarials and improve robustness compared to a baseline model. Our experiments on a modified CIC-IDS2017 data set with synthetic noise demonstrate significant improvements in detection performance compared to the baseline TGN-SVDD model, especially as noise levels increase.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-124,2024,100.0,"Noise Robust One-Class Intrusion Detection on Dynamic Graphs In the domain of network intrusion detection, robustness against contaminated and noisy data inputs remains a critical challenge. This study introduces a probabilistic version of the Temporal Graph Network Support Vector Data Description (TGN-SVDD) model, designed to enhance detection accuracy in the presence of input noise. By predicting parameters of a Gaussian distribution for each network event, our model is able to naturally address noisy adversarials and improve robustness compared to a baseline model. Our experiments on a modified CIC-IDS2017 data set with synthetic noise demonstrate significant improvements in detection performance compared to the baseline TGN-SVDD model, especially as noise levels increase."
Influence of image encoders and image features transformations in emergent communication,"Bastien Vanderplaetse, Stéphane Dupont, Xavier Siebert","1 - Artificial Intelligence Lab University of Mons -MAIA Belgium
3 - University of Mons -Mathematics and Operational Research Belgium","Emergent communication in multi-agent systems is a research field exploring how autonomous agents can develop unique communication protocols without human programming, showing adaptability in various contexts. This study investigates the influence of image encoders and spatial information within image features on agent performance and the compositionality of emergent languages in multi-agent systems. By exploring various image encoding strategies, including the application of different processing methods to image features, we assess their impact on agents' abilities in a structured communication task. Our findings indicate that while certain encoding processes enhance overall task performance, they do not necessarily improve language compositionality.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-127,2024,100.0,"Influence of image encoders and image features transformations in emergent communication Emergent communication in multi-agent systems is a research field exploring how autonomous agents can develop unique communication protocols without human programming, showing adaptability in various contexts. This study investigates the influence of image encoders and spatial information within image features on agent performance and the compositionality of emergent languages in multi-agent systems. By exploring various image encoding strategies, including the application of different processing methods to image features, we assess their impact on agents' abilities in a structured communication task. Our findings indicate that while certain encoding processes enhance overall task performance, they do not necessarily improve language compositionality."
Towards Deep Continual Workspace Monitoring: Performance Evaluation of CL Strategies for Object Detection in Working Sites,"Aslı ¸elik, Oguzhan Urhan, Andrea Cossu, Vincenzo Lomonaco","1 - Kocaeli University
3 - University of Pisa","Object detection plays a crucial role in computer-based monitoring tasks, where the adaptability of object detection algorithms to complex and dynamic backgrounds is essential for achieving accurate and stable detection performance. Despite the effectiveness of state-of-the-art object detectors, continual object detection remains a significant challenge in real-world applications. In this study, we utilized a dataset tailored for continual object detection in diverse working environments. Using this dataset, a task-incremental and task-agnostic continual learning scenario was established in which each experience, corresponding to object detection sub-datasets collected from different work sites. Common baseline continual learning (CL) strategies were employed throughout the continual training process to evaluate their efficacy. Our findings, consistent with the CL literature, underscore replay-based strategies as the top performers, assessed across both task-aware and task-agnostic settings. Additionally, zero-shot object detection demonstrates notably lower performance compared to the best-performing CL strategies, emphasizing the critical importance of CL strategies in maintaining consistent detection performance and adapting to new environments and work sites.",Continual Improvement of Deep Neural Networks in The Age of Big Data,https://doi.org/10.14428/esann/2024.ES2024-128,2024,100.0,"Towards Deep Continual Workspace Monitoring: Performance Evaluation of CL Strategies for Object Detection in Working Sites Object detection plays a crucial role in computer-based monitoring tasks, where the adaptability of object detection algorithms to complex and dynamic backgrounds is essential for achieving accurate and stable detection performance. Despite the effectiveness of state-of-the-art object detectors, continual object detection remains a significant challenge in real-world applications. In this study, we utilized a dataset tailored for continual object detection in diverse working environments. Using this dataset, a task-incremental and task-agnostic continual learning scenario was established in which each experience, corresponding to object detection sub-datasets collected from different work sites. Common baseline continual learning (CL) strategies were employed throughout the continual training process to evaluate their efficacy. Our findings, consistent with the CL literature, underscore replay-based strategies as the top performers, assessed across both task-aware and task-agnostic settings. Additionally, zero-shot object detection demonstrates notably lower performance compared to the best-performing CL strategies, emphasizing the critical importance of CL strategies in maintaining consistent detection performance and adapting to new environments and work sites."
Towards Explainable Evolution Strategies with Large Language Models,"Jill Baumann, Oliver Kramer",1 - Department of Computing Science Carl von Ossietzky Universität Oldenburg 26111 Oldenburg Germany,"This paper introduces an approach that integrates selfadaptive Evolution Strategies (ES) with Large Language Models (LLMs) to enhance the explainability of complex optimization processes. By employing a self-adaptive ES equipped with a restart mechanism, we effectively navigate the challenging landscapes of benchmark functions, capturing detailed logs of the optimization journey. The logs include fitness evolution, step-size adjustments and restart events due to stagnation. An LLM is then utilized to process these logs, generating concise, user-friendly summaries that highlight key aspects such as convergence behavior, optimal fitness achievements, and encounters with local optima. Our case study on the Rastrigin function demonstrates how our approach makes the complexities of ES optimization transparent. Our findings highlight the potential of using LLMs to bridge the gap between advanced optimization algorithms and their interpretability.",Language models,https://doi.org/10.14428/esann/2024.ES2024-129,2024,100.0,"Towards Explainable Evolution Strategies with Large Language Models This paper introduces an approach that integrates selfadaptive Evolution Strategies (ES) with Large Language Models (LLMs) to enhance the explainability of complex optimization processes. By employing a self-adaptive ES equipped with a restart mechanism, we effectively navigate the challenging landscapes of benchmark functions, capturing detailed logs of the optimization journey. The logs include fitness evolution, step-size adjustments and restart events due to stagnation. An LLM is then utilized to process these logs, generating concise, user-friendly summaries that highlight key aspects such as convergence behavior, optimal fitness achievements, and encounters with local optima. Our case study on the Rastrigin function demonstrates how our approach makes the complexities of ES optimization transparent. Our findings highlight the potential of using LLMs to bridge the gap between advanced optimization algorithms and their interpretability."
Interactive Machine Learning-Powered Dashboard for Energy Analytics in Residential Buildings,"Diego García, Ignacio Díaz, José Enguita, Jorge Menéndez, Abel Cuadrado","1 - University of Oviedo -Dept. of Electrical Engineering Edificio Torres Quevedo módulo 2, Campus de 33204 Gijón SPAIN","Efforts to reduce energy consumption in buildings are crucial for climate change concerns. In this sense, energy monitoring increases energy awareness and mitigates energy wastes. This study integrates machine learning models, advanced visualisations, and interactive tools to create an insightful energy monitoring dashboard. Novel contributions include a 2D map of daily energy demand profiles combining spatial encodings based on t-SNE, fluid aggregation, and filter operations via a datacube framework, as well as visual encoding powered by morphing projections. This approach facilitates the decisions of end users regarding the optimisation of energy in residential facilities.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-130,2024,100.0,"Interactive Machine Learning-Powered Dashboard for Energy Analytics in Residential Buildings Efforts to reduce energy consumption in buildings are crucial for climate change concerns. In this sense, energy monitoring increases energy awareness and mitigates energy wastes. This study integrates machine learning models, advanced visualisations, and interactive tools to create an insightful energy monitoring dashboard. Novel contributions include a 2D map of daily energy demand profiles combining spatial encodings based on t-SNE, fluid aggregation, and filter operations via a datacube framework, as well as visual encoding powered by morphing projections. This approach facilitates the decisions of end users regarding the optimisation of energy in residential facilities."
Evaluating the Quality of Saliency Maps for Distilled Convolutional Neural Networks,"Jasper Wilfling, Matias Valdenegro-Toro, Marco Zullich",1 - Department of AI -Faculty of Science and Engineering University of Groningen Nijenborgh 9 9747AG Groningen the Netherlands,"Knowledge Distillation (KD) is a popular technique to compress Deep Neural Networks. Studies on KD often evaluate it on the basis of accuracy and time-complexity; however, there exist other facets of a model performance, like explainability and fairness. In the present work, we evaluate the quality of saliency maps in terms of faithfulness and coherence in the context of KD and compare the results obtained with the uncompressed model. Our findings indicate how KD is potentially decreasing the accuracy of the saliency maps, thus acting as a warning on the usage of KD when high-quality explanations are required.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-131,2024,100.0,"Evaluating the Quality of Saliency Maps for Distilled Convolutional Neural Networks Knowledge Distillation (KD) is a popular technique to compress Deep Neural Networks. Studies on KD often evaluate it on the basis of accuracy and time-complexity; however, there exist other facets of a model performance, like explainability and fairness. In the present work, we evaluate the quality of saliency maps in terms of faithfulness and coherence in the context of KD and compare the results obtained with the uncompressed model. Our findings indicate how KD is potentially decreasing the accuracy of the saliency maps, thus acting as a warning on the usage of KD when high-quality explanations are required."
ADLER -An efficient Hessian-based strategy for adaptive learning rate,"Dario Balboni, Davide Bacciu","1 - Scuola Normale Superiore -Data Science Department Piazza dei Cavalieri 1 Pisa -Italy
2 - Computer Science Department University of Pisa Largo Bruno Pontecorvo 3 Pisa Italy","We derive a sound positive semi-definite approximation of the Hessian of deep models for which Hessian-vector products are easily computable. This enables us to provide an adaptive SGD learning rate strategy based on the minimization of the local quadratic approximation, which requires just twice the computation of a single SGD run, but performs comparably with grid search on SGD learning rates on different model architectures (CNN with and without residual connections) on classification tasks, which makes the algorithm a promising first step toward obtaining hyperparameter-free optimization of deep learning models, and also reduces the energy impact of training. We also compare the novel approximation with the Gauss-Newton approximation. 12 The used networks are trained without momentum nor weight decay as this would prevent a proper comparison; this explains why the obtained results aren't SOTA. 13 The full code and the experiment data are available at gitlab.com/dbalboni/ADLER. 14 As our method does not have momentum terms, we only compare against naive SGD.",Optimization,https://doi.org/10.14428/esann/2024.ES2024-132,2024,96.40287769784173,"ADLER -An efficient Hessian-based strategy for adaptive learning rate We derive a sound positive semi-definite approximation of the Hessian of deep models for which Hessian-vector products are easily computable. This enables us to provide an adaptive SGD learning rate strategy based on the minimization of the local quadratic approximation, which requires just twice the computation of a single SGD run, but performs comparably with grid search on SGD learning rates on different model architectures (CNN with and without residual connections) on classification tasks, which makes the algorithm a promising first step toward obtaining hyperparameter-free optimization of deep learning models, and also reduces the energy impact of training. We also compare the novel approximation with the Gauss-Newton approximation. 12 The used networks are trained without momentum nor weight decay as this would prevent a proper comparison; this explains why the obtained results aren't SOTA. 13 The full code and the experiment data are available at gitlab.com/dbalboni/ADLER. 14 As our method does not have momentum terms, we only compare against naive SGD."
SDE U-Net: Disentangling Aleatoric and Epistemic Uncertainties in Medical Image Segmentation,"Chuxin Zhang, Ana Barragan-Montero, John Lee","1 - UCLouvain -ICTEAM Place du Levant 3 1348 Louvain-la-Neuve Belgium
2 - 1-UCLouvain -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium","Quantifying uncertainty is crucial in artifical intelligence (AI) applications, particularly in high-stakes healthcare settings. This paper introduces SDE U-Net, a novel architecture that integrates stochastic differential equations (SDEs) with the U-Net framework, effectively distinguishing between aleatoric and epistemic uncertainties. By incorporating a randomness component, SDE U-Net directly captures and quantifies aleatoric uncertainty, while epistemic uncertainty is assessed through multiple forward passes. Comparative results show that SDE U-Net not only matches but also exceeds benchmark performance, achieving similar results in just 500 epochs, half the epochs required by the benchmark. This approach enhances the reliability of AI in medical decision-making by providing a clear, comprehensive representation of uncertainty, marking a significant advancement in the field of medical image segmentation.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-133,2024,100.0,"SDE U-Net: Disentangling Aleatoric and Epistemic Uncertainties in Medical Image Segmentation Quantifying uncertainty is crucial in artifical intelligence (AI) applications, particularly in high-stakes healthcare settings. This paper introduces SDE U-Net, a novel architecture that integrates stochastic differential equations (SDEs) with the U-Net framework, effectively distinguishing between aleatoric and epistemic uncertainties. By incorporating a randomness component, SDE U-Net directly captures and quantifies aleatoric uncertainty, while epistemic uncertainty is assessed through multiple forward passes. Comparative results show that SDE U-Net not only matches but also exceeds benchmark performance, achieving similar results in just 500 epochs, half the epochs required by the benchmark. This approach enhances the reliability of AI in medical decision-making by providing a clear, comprehensive representation of uncertainty, marking a significant advancement in the field of medical image segmentation."
Generation of Simulated Dataset of Computed Tomography Images of Eggs and Extraction of Measurements Using Deep Learning,"Jean Pierre, B Vargas, Davi De Paula, Denis Salvadeo, Emílio Júnior",1 - São Paulo State University (UNESP) -Institute of Geosciences and Exact Sciences Rio Claro São Paulo Brazil,"This paper extracts morphometric measurements of the different volumes of chicken egg components (shell, yolk, albumen and air chamber) by evaluating the segmentation algorithms, U-Net and Fully Convolutional Network (FCN). It also presents a new data set of 3D CT images of chicken eggs, simulating the different densities of a real one in the Digital Imaging and Communications in Medicine (DICOM) format and its labeled masks. The 3D models trained end-to-end showed high generalization even in the presence of variations in egg size and internal structures, achieving state-of-the-art segmentation performance with 99.4% accuracy.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-134,2024,100.0,"Generation of Simulated Dataset of Computed Tomography Images of Eggs and Extraction of Measurements Using Deep Learning This paper extracts morphometric measurements of the different volumes of chicken egg components (shell, yolk, albumen and air chamber) by evaluating the segmentation algorithms, U-Net and Fully Convolutional Network (FCN). It also presents a new data set of 3D CT images of chicken eggs, simulating the different densities of a real one in the Digital Imaging and Communications in Medicine (DICOM) format and its labeled masks. The 3D models trained end-to-end showed high generalization even in the presence of variations in egg size and internal structures, achieving state-of-the-art segmentation performance with 99.4% accuracy."
Visualizing and Improving 3D Mesh Segmentation with DeepView,"Andreas Mazur, Isaac Roberts, David Leins, Alexander Schulz, Barbara Hammer",1 - CITEC -Center for Cognitive Interaction Technology Faculty of Technology Inspiration 1 Bielefeld University 33619 Bielefeld Germany,"While 3D data is rich in information, it often comes with the drawback of being tedious to handle. Recent work in the Geometric Deep Learning community focused on developing high quality 3D datasets for tasks like mesh segmentation. However, the label quality can never be assured to be perfect. To improve label quality in 3D datasets, we propose an interactive algorithm combining DeepView, a method to visualize the classification function of neural networks, with Intrinsic Mesh CNNs, which generalize the convolution to Riemannian manifolds, to smartly select adequate sets of vertices from triangle mesh data for label correction.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-135,2024,100.0,"Visualizing and Improving 3D Mesh Segmentation with DeepView While 3D data is rich in information, it often comes with the drawback of being tedious to handle. Recent work in the Geometric Deep Learning community focused on developing high quality 3D datasets for tasks like mesh segmentation. However, the label quality can never be assured to be perfect. To improve label quality in 3D datasets, we propose an interactive algorithm combining DeepView, a method to visualize the classification function of neural networks, with Intrinsic Mesh CNNs, which generalize the convolution to Riemannian manifolds, to smartly select adequate sets of vertices from triangle mesh data for label correction."
LLaMA Tunes CMA-ES,Oliver Kramer,1 - Department of Computing Science Carl von Ossietzky Universität Oldenburg 26111 Oldenburg Germany,"This paper introduces LLaMA-ES, an approach for tuning the hyperparameters of Evolution Strategies (ES), specifically the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), by leveraging a Large Language Model (LLM). The proposed method uses the LLM to iteratively suggest parameter adjustments based on the optimization history, enabling dynamic fine-tuning of the algorithm. We validate our approach through experiments on numerical benchmark optimization problems, employing the LLaMA3 model with 70 billion parameters. The results demonstrate that LLaMA-ES significantly enhances the performance of CMA-ES, achieving competitive results in parameter tuning and demonstrating the potential of LLMs in optimization tasks.",Language models,https://doi.org/10.14428/esann/2024.ES2024-136,2024,100.0,"LLaMA Tunes CMA-ES This paper introduces LLaMA-ES, an approach for tuning the hyperparameters of Evolution Strategies (ES), specifically the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), by leveraging a Large Language Model (LLM). The proposed method uses the LLM to iteratively suggest parameter adjustments based on the optimization history, enabling dynamic fine-tuning of the algorithm. We validate our approach through experiments on numerical benchmark optimization problems, employing the LLaMA3 model with 70 billion parameters. The results demonstrate that LLaMA-ES significantly enhances the performance of CMA-ES, achieving competitive results in parameter tuning and demonstrating the potential of LLMs in optimization tasks."
Enhanced Deep Reinforcement Learning based Group Recommendation System with Multi-head Attention for Varied Group Sizes,"Saba Izadkhah, Banafsheh Rekabdar",1 - Department of Computer Science Portland State University Oregon USA,"This paper introduces EnGRMA, an Enhanced deep reinforcement learning-based Group Recommendation system with Multi-head Attention for varied group sizes. EnGRMA adapts its recommendation strategy according to group sizes, using individual member preferences in smaller groups through a weighted average method, and leveraging multihead attention to aggregate diverse opinions effectively in larger groups. This method helps model dynamic member-item interactions, enhancing the system's ability to deliver personalized recommendations. Our evaluation of the MovieLens-Rand dataset shows that EnGRMA not only outperforms GRMA and DRGR in Recall, NDCG, Precision, and F1 scores but also demonstrates superior performance in NDCG against AGREE.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-138,2024,100.0,"Enhanced Deep Reinforcement Learning based Group Recommendation System with Multi-head Attention for Varied Group Sizes This paper introduces EnGRMA, an Enhanced deep reinforcement learning-based Group Recommendation system with Multi-head Attention for varied group sizes. EnGRMA adapts its recommendation strategy according to group sizes, using individual member preferences in smaller groups through a weighted average method, and leveraging multihead attention to aggregate diverse opinions effectively in larger groups. This method helps model dynamic member-item interactions, enhancing the system's ability to deliver personalized recommendations. Our evaluation of the MovieLens-Rand dataset shows that EnGRMA not only outperforms GRMA and DRGR in Recall, NDCG, Precision, and F1 scores but also demonstrates superior performance in NDCG against AGREE."
Link prediction heuristics for temporal graph benchmark,"Manuel Dileo, Matteo Zignani",1 - Department of Computer Science University of Milan Italy,"Link prediction is one of the most well-known and studied problems in graph machine learning, successfully applied in different settings, such as predicting network evolution in online social networks, protein-to-protein interactions, or completing links in knowledge graphs. In recent years, we have witnessed several solutions based on deep learning methods for solving this task in the context of temporal networks. However, despite their effectiveness on static graphs, traditional heuristic-based approaches from network science research have never been considered potential benchmarks' baselines. For this reason, in this work, we tested four of the most well-known and simple heuristics for link prediction on the most adopted temporal graph benchmark (TGB). Our results show that simple link prediction heuristics can reach comparable results with state-of-the-art deep learning techniques and, thanks to their interpretability, give insights into the network being studied. We believe considering heuristic-based baselines will push the temporal graph learning community toward better models for link prediction.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-141,2024,100.0,"Link prediction heuristics for temporal graph benchmark Link prediction is one of the most well-known and studied problems in graph machine learning, successfully applied in different settings, such as predicting network evolution in online social networks, protein-to-protein interactions, or completing links in knowledge graphs. In recent years, we have witnessed several solutions based on deep learning methods for solving this task in the context of temporal networks. However, despite their effectiveness on static graphs, traditional heuristic-based approaches from network science research have never been considered potential benchmarks' baselines. For this reason, in this work, we tested four of the most well-known and simple heuristics for link prediction on the most adopted temporal graph benchmark (TGB). Our results show that simple link prediction heuristics can reach comparable results with state-of-the-art deep learning techniques and, thanks to their interpretability, give insights into the network being studied. We believe considering heuristic-based baselines will push the temporal graph learning community toward better models for link prediction."
Extrapolating Venusian Atmospheric Profiles using MAGMA Gaussian Processes,"Simon Lejoly, Arianna Piccialli, Arnaud Mahieux, Ann Vandaele, Benoit Frénay","1 - Faculty of Computer Science University of Namur -NaDI Institute Rue Grandgagnage 21 5000 Namur Belgium
2 - Royal Belgian Institute for Space Aeronomy -Planetary Atmosphere Department Avenue Circulaire 3 1180 Brussels -Belgium
4 - The University of Texas at Austin -Department of Aerospace Engineering and Engineering Mechanics 2617 Wichita St C0600, 78712 Stop, Austin TX USA","In the field of spatial aeronomy, atmospheric profile datasets often contain partial data. Probabilistic models, particularly Gaussian processes (GPs), offer promising solutions for filling these data gaps. However, traditional GP algorithms encounter challenges when handling multiple sequences simultaneously, both in terms of performance and computational complexity. Recently, an algorithm named MAGMA was introduced to address these issues. This paper evaluates MAGMA's performance using the SOIR Venus atmosphere dataset, marking the first application of MAGMA to atmospheric profiles. Results indicate that MAGMA represents a significant advancement towards the efficient application of GPs for extrapolating atmospheric profiles.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-142,2024,100.0,"Extrapolating Venusian Atmospheric Profiles using MAGMA Gaussian Processes In the field of spatial aeronomy, atmospheric profile datasets often contain partial data. Probabilistic models, particularly Gaussian processes (GPs), offer promising solutions for filling these data gaps. However, traditional GP algorithms encounter challenges when handling multiple sequences simultaneously, both in terms of performance and computational complexity. Recently, an algorithm named MAGMA was introduced to address these issues. This paper evaluates MAGMA's performance using the SOIR Venus atmosphere dataset, marking the first application of MAGMA to atmospheric profiles. Results indicate that MAGMA represents a significant advancement towards the efficient application of GPs for extrapolating atmospheric profiles."
Embodying Language Models in Robot Action,"Connor Gäde, Ozan Özdemir, Cornelius Weber, Stefan Wermter",1 - University of Hamburg -Dept of Informatics Vogt-Kölln-Straße 30 22527 Hamburg Germany,"Large language models (LLMs) have achieved significant recent success in deep learning. The remaining challenges in robotics and human-robot interaction (HRI) still need to be tackled but off-the-shelf pre-trained LLMs with advanced language and reasoning capabilities can provide solutions to problems in the field. In this work, we realise an open-ended HRI scenario involving a humanoid robot communicating with a human while performing robotic object manipulation tasks at a table. To this end, we combine pre-trained general models of speech recognition, vision-language, text-to-speech and open-world object detection with robot-specific models of visuospatial coordinate transfer and inverse kinematics, as well as a task-specific motion model. Our experiments reveal robust performance by the language model in accurately selecting the task mode and by the whole model in correctly executing actions during openended dialogue. Our innovative architecture enables a seamless integration of open-ended dialogue, scene description, open-world object detection and action execution. It is promising as a modular solution for diverse robotic platforms and HRI scenarios. * This work was supported by the German Research Foundation (DFG) under Project TRR 169 Crossmodal Learning (CML) and LeCAREbot. Philipp Allgeuer contributed software. 1 Our project website with an exemplary video can be found at https://knowledgetechnologyuhh.github.io/ELMiRA",Language models,https://doi.org/10.14428/esann/2024.ES2024-143,2024,100.0,"Embodying Language Models in Robot Action Large language models (LLMs) have achieved significant recent success in deep learning. The remaining challenges in robotics and human-robot interaction (HRI) still need to be tackled but off-the-shelf pre-trained LLMs with advanced language and reasoning capabilities can provide solutions to problems in the field. In this work, we realise an open-ended HRI scenario involving a humanoid robot communicating with a human while performing robotic object manipulation tasks at a table. To this end, we combine pre-trained general models of speech recognition, vision-language, text-to-speech and open-world object detection with robot-specific models of visuospatial coordinate transfer and inverse kinematics, as well as a task-specific motion model. Our experiments reveal robust performance by the language model in accurately selecting the task mode and by the whole model in correctly executing actions during openended dialogue. Our innovative architecture enables a seamless integration of open-ended dialogue, scene description, open-world object detection and action execution. It is promising as a modular solution for diverse robotic platforms and HRI scenarios. * This work was supported by the German Research Foundation (DFG) under Project TRR 169 Crossmodal Learning (CML) and LeCAREbot. Philipp Allgeuer contributed software. 1 Our project website with an exemplary video can be found at https://knowledgetechnologyuhh.github.io/ELMiRA"
Generalizing Convolution to Point Clouds,"Davide Bacciu, Francesco Landolfi","1 - Department of Computer Science Università di Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","Convolution, a fundamental operation in deep learning for structured grid data like images, cannot be directly applied to point clouds due to their irregular and unordered nature. Many approaches in literature that perform convolution on point clouds achieve this by designing a convolutional operator from scratch, often with little resemblance to the one used on images. We present two point cloud convolutions that naturally follow from the convolution in its standard definition popular with images. We do so by relaxing the indexing of the kernel weights with a ""soft"" dictionary that resembles the attention mechanism of the transformers. Finally, experimental results demonstrate the effectiveness of the proposed relaxations on two benchmark point cloud classification tasks. Z i1,...,i d ,k = conv(X, K) i1,...,i d ,k = j1,...,j d ,h X i1+j1,...,i d +j d ,h • K j1,...,j d ,h,k , (1)",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-145,2024,100.0,"Generalizing Convolution to Point Clouds Convolution, a fundamental operation in deep learning for structured grid data like images, cannot be directly applied to point clouds due to their irregular and unordered nature. Many approaches in literature that perform convolution on point clouds achieve this by designing a convolutional operator from scratch, often with little resemblance to the one used on images. We present two point cloud convolutions that naturally follow from the convolution in its standard definition popular with images. We do so by relaxing the indexing of the kernel weights with a ""soft"" dictionary that resembles the attention mechanism of the transformers. Finally, experimental results demonstrate the effectiveness of the proposed relaxations on two benchmark point cloud classification tasks. Z i1,...,i d ,k = conv(X, K) i1,...,i d ,k = j1,...,j d ,h X i1+j1,...,i d +j d ,h • K j1,...,j d ,h,k , (1)"
Forget early exaggeration in t-SNE: early hierarchization preserves global structure,"John Lee, Edouard Couplet, Pierre Lambert, Ludovic Journaux, Dounia Mulders, Cyril De Bodt, Michel Verleysen","1 - Institut Agro Dijon -Laboratoire d'Informatique de Bourgogne Boulevard Docteur Petitjean 26 21079 Dijon France
2 - 1-UCLouvain -IREC/MIRO Avenue Hippocrate 55 1200 Brussels Belgium
3 - UCLouvain -ICTEAM/ELEN Place du Levant 3 1348 Louvain-la-Neuve Belgium","As a local method of dimensionality reduction, t-SNE requires careful initialization in order to preserve the data global structure to the best extent. In regular t-SNE, the low-dimensional embedding is initialized either randomly or with PCA; next, gradient descent refines the embedding coordinates in two phases. In the first one, called early exaggeration, attractive forces between points are artificially strengthened to delay any detrimental effect of repulsive forces while points are still poorly organized. In this paper, a novel initialization of t-SNE is proposed. It works by hierarchizing the data points into a space-partitioning binary tree and successive runs of t-SNE with 4, 8, 16, ..., N points. Between two runs, the prototypical point in each tree branch is split into its two children prototypes, with some little random noise, and the embedding is rescaled to account for the increased population. Experimental results show the effectiveness of the method. The proposed method is compatible with any method of neighbor embedding (t-SNE, UMAP, etc.) provided early exaggeration can be disabled and initial coordinates can be fed into.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-146,2024,100.0,"Forget early exaggeration in t-SNE: early hierarchization preserves global structure As a local method of dimensionality reduction, t-SNE requires careful initialization in order to preserve the data global structure to the best extent. In regular t-SNE, the low-dimensional embedding is initialized either randomly or with PCA; next, gradient descent refines the embedding coordinates in two phases. In the first one, called early exaggeration, attractive forces between points are artificially strengthened to delay any detrimental effect of repulsive forces while points are still poorly organized. In this paper, a novel initialization of t-SNE is proposed. It works by hierarchizing the data points into a space-partitioning binary tree and successive runs of t-SNE with 4, 8, 16, ..., N points. Between two runs, the prototypical point in each tree branch is split into its two children prototypes, with some little random noise, and the embedding is rescaled to account for the increased population. Experimental results show the effectiveness of the method. The proposed method is compatible with any method of neighbor embedding (t-SNE, UMAP, etc.) provided early exaggeration can be disabled and initial coordinates can be fed into."
AI-based Collimation Optimization for X-Ray Imaging using Time-of-Flight Cameras,"Dominik Mairhöfer, Manuel Laufer, Lennart Berkel, Arpad Bischof, Erhardt Barth, Jörg Barkhausen, Thomas Martinetz","1 - University of Lübeck -Institute for Neuro-and Bioinformatics Ratzeburger Allee 160 23562 Lübeck Germany
3 - University Medical Center Schleswig-Holstein Ratzeburger Allee 160 23562 Lübeck -Germany
5 - -IMAGE Information Systems Europe GmbH Lange Str. 16 18055 Rostock Germany","Collimation during radiography, which is the process of defining the area to be radiated, is a crucial factor for the protection of the patient and for the diagnostic quality of a radiograph. Moreover, incorrect collimation is one of the main causes for a retake and the associated costs. In this paper we propose a novel collimation optimization approach using Time-of-Flight cameras and deep Neural Networks trained end-to-end to increase the diagnostic quality of a radiograph. For this we acquired a new dataset in a clinical environment consisting of depth images of the lower leg and the abdomen. Using this dataset we are able to segment depth images for the optimal collimation with an average IoU of 83%. * Contributed equally. The order of author names was randomly determined. † We thank Celina Schubbe for her help and support in collecting the dataset. This work was funded by the Bundesministerium für Wirtschaft und Klimaschutz (BMWK) through the KI-SIGS project.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-147,2024,100.0,"AI-based Collimation Optimization for X-Ray Imaging using Time-of-Flight Cameras Collimation during radiography, which is the process of defining the area to be radiated, is a crucial factor for the protection of the patient and for the diagnostic quality of a radiograph. Moreover, incorrect collimation is one of the main causes for a retake and the associated costs. In this paper we propose a novel collimation optimization approach using Time-of-Flight cameras and deep Neural Networks trained end-to-end to increase the diagnostic quality of a radiograph. For this we acquired a new dataset in a clinical environment consisting of depth images of the lower leg and the abdomen. Using this dataset we are able to segment depth images for the optimal collimation with an average IoU of 83%. * Contributed equally. The order of author names was randomly determined. † We thank Celina Schubbe for her help and support in collecting the dataset. This work was funded by the Bundesministerium für Wirtschaft und Klimaschutz (BMWK) through the KI-SIGS project."
Automatic Miscalibration Diagnosis: Interpreting Probability Integral Transform (PIT) Histograms,"Ondřej Podsztavek, Alexander Jordan, Pavel Tvrdík, Kai Polsterer","1 - Faculty of Information Technology Czech Technical University Thákurova 9, 160 00 Prague 6 -Czechia 2-Heidelberg Institute for Theoretical Studies Schloss-Wolfsbrunnenweg 35 691 18 Prague, Heidelberg Germany","Quantifying the predictive uncertainty of a model is essential for risk assessment. We address the proper calibration of the predictive uncertainty in regression tasks by employing the probability integral transform (PIT) histogram to diagnose miscalibration. PIT histograms are often difficult to interpret, and therefore we present an approach to an automatic interpretation of PIT histograms based on an interpreter trained with a synthetic data set. Given a PIT histogram of a model and a data set, the interpreter can estimate the data-generating distribution of the data set with the main purpose of identifying the cause of miscalibration. * Ondřej Podsztavek, Alexander I. Jordan, and Kai L. Polsterer gratefully acknowledge the generous and invaluable support of the Klaus Tschira Foundation. Ondřej Podsztavek acknowledges the support of his co-supervisor Petr Škoda, and the Grant Agency of the Czech Technical University in Prague (No. SGS23/209/OHK3/3T/18). 1 These two tools are equivalent because both display an estimate of the PIT distribution: the PIT histogram shows a density estimate, whereas the calibration plot displays an estimate of the cumulative distribution function.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-15,2024,100.0,"Automatic Miscalibration Diagnosis: Interpreting Probability Integral Transform (PIT) Histograms Quantifying the predictive uncertainty of a model is essential for risk assessment. We address the proper calibration of the predictive uncertainty in regression tasks by employing the probability integral transform (PIT) histogram to diagnose miscalibration. PIT histograms are often difficult to interpret, and therefore we present an approach to an automatic interpretation of PIT histograms based on an interpreter trained with a synthetic data set. Given a PIT histogram of a model and a data set, the interpreter can estimate the data-generating distribution of the data set with the main purpose of identifying the cause of miscalibration. * Ondřej Podsztavek, Alexander I. Jordan, and Kai L. Polsterer gratefully acknowledge the generous and invaluable support of the Klaus Tschira Foundation. Ondřej Podsztavek acknowledges the support of his co-supervisor Petr Škoda, and the Grant Agency of the Czech Technical University in Prague (No. SGS23/209/OHK3/3T/18). 1 These two tools are equivalent because both display an estimate of the PIT distribution: the PIT histogram shows a density estimate, whereas the calibration plot displays an estimate of the cumulative distribution function."
Causes of Rejects in Prototype-based Classification Aleatoric vs. Epistemic Uncertainty,"Johannes Brinkrolf, Valerie Vaquet, Fabian Hinder, Barbara Hammer",1 - Faculty of Technology Universitätsstraße 25 Bielefeld University 33615 Bielefeld Germany,"Prototype-based methods constitute a robust and transparent family of machine-learning models. To increase robustness in real-world applications, they are frequently coupled with reject options. While the state-of-the-art method, relative similarity, couples the rejection of samples with high aleatoric and epistemic uncertainty, the technique lacks transparency, i.e., an explanation of why a sample has been rejected. In this work, we analyze the relative similarity analytically and derive an explanation scheme for reject options in prototype-based classification.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-156,2024,100.0,"Causes of Rejects in Prototype-based Classification Aleatoric vs. Epistemic Uncertainty Prototype-based methods constitute a robust and transparent family of machine-learning models. To increase robustness in real-world applications, they are frequently coupled with reject options. While the state-of-the-art method, relative similarity, couples the rejection of samples with high aleatoric and epistemic uncertainty, the technique lacks transparency, i.e., an explanation of why a sample has been rejected. In this work, we analyze the relative similarity analytically and derive an explanation scheme for reject options in prototype-based classification."
EEG Source Imaging Enhances Motor Imagery Classification,"Andres Soler, Viktor Naas, Amita Giri, Marta Molinas","1 - Department of Engineering Cybernetics Norwegian University of Science and Technology Trondheim Norway
3 - Department of Brain and Cognitive Sciences Massachusetts Institute of Technology Boston USA","Brain-computer Interfaces (BCIs)   have been developed towards enhancing communication and control in individuals with motor disabilities and assist in motor rehabilitation, where motor imagery (MI), the mental visualization of limb movement, has been broadly explored. Traditionally, MI-based BCIs utilize electroencephalographic (EEG) recordings to discriminate between limbs motor imagination. This involves applying feature extraction and classification, primarily analyzing signals recorded at the scalp. Despite the success of the traditional sensor space analysis, recent studies have demonstrated that incorporating EEG source imaging (ESI) has led to an improvement of the classification performance. This work studies pipelines on both sensor and source space for classifying upper limb MI. Here, we introduce the use of source average power for the integration of ESI into MI-based BCIs. Our results suggest a significant accuracy improvement of 10% when applying source space analysis with average power against traditional sensor space analysis. This demonstrates that a shift from sensor space analysis to source space analysis can be beneficial for MI classification.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-158,2024,100.0,"EEG Source Imaging Enhances Motor Imagery Classification Brain-computer Interfaces (BCIs)   have been developed towards enhancing communication and control in individuals with motor disabilities and assist in motor rehabilitation, where motor imagery (MI), the mental visualization of limb movement, has been broadly explored. Traditionally, MI-based BCIs utilize electroencephalographic (EEG) recordings to discriminate between limbs motor imagination. This involves applying feature extraction and classification, primarily analyzing signals recorded at the scalp. Despite the success of the traditional sensor space analysis, recent studies have demonstrated that incorporating EEG source imaging (ESI) has led to an improvement of the classification performance. This work studies pipelines on both sensor and source space for classifying upper limb MI. Here, we introduce the use of source average power for the integration of ESI into MI-based BCIs. Our results suggest a significant accuracy improvement of 10% when applying source space analysis with average power against traditional sensor space analysis. This demonstrates that a shift from sensor space analysis to source space analysis can be beneficial for MI classification."
Predicting the Closing Cross Auction Results at the NASDAQ Stock Exchange,"Manuel Hettich, Philipp Bielefeld, Crispin Schomers, Sarel Cohen, Tobias Friedrich","1 - Hasso Plattner Institute University of Potsdam Potsdam Germany
4 - School of Computer Science Tel-Aviv-Yaffo Academic College
5 - Tel-Aviv Israel","This paper aims to present the results and learnings from our work on the last year's Optiver -Trading at the Close Kaggle 2023 challenge. It not only touches the two most widely used approaches in the competition, deep learning models and support vector regression models, but also describes the provided dataset drawn from the NASDAQ stock exchange with many detailed attributes, like the imbalance size and far and near prices, recorded in an interval of one second for the last ten minutes of each trading day. It also describes the constraints of the competition. The presented machine learning model based on the LightGBM engine stood out from the competition by feeding back the revealed target data given for the previous day and was one of the top 5% of all models in the competition. 
 Introduction On the NASDAQ stock exchange thousands of orders are executed every second, which requires fast and reliable models for bringing buyer and seller together and giving both a competitive price with low spreads compared to other stock exchanges. Especially the last ten minutes of a trading day are characterized by an increased volatility and the closing courses serve as key indicators for many market participants  [1] . While predicting the stock market attracts many researchers, as it promises enormous financial gains, it is also one of the most challenging problems. With the increasing computational power over the lasts decade, researchers were especially successful with supervised learning approaches, like artificial neural networks (ANN) or Support Vector Machines (SVN). But most current models still only have an accuracy between 60% and 80% [2], showing that there is still potential for improvement. Therefore, trading companies and stock exchanges, which especially benefit from having the best predictions, sometimes open competitions for finding better models or new approaches. One of these contests is the Optiver -Trading at the Close challenge 2023  [1] , where we participated in and got in contact with many interesting approaches we want to present in the next chapters.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-159,2024,100.0,"Predicting the Closing Cross Auction Results at the NASDAQ Stock Exchange This paper aims to present the results and learnings from our work on the last year's Optiver -Trading at the Close Kaggle 2023 challenge. It not only touches the two most widely used approaches in the competition, deep learning models and support vector regression models, but also describes the provided dataset drawn from the NASDAQ stock exchange with many detailed attributes, like the imbalance size and far and near prices, recorded in an interval of one second for the last ten minutes of each trading day. It also describes the constraints of the competition. The presented machine learning model based on the LightGBM engine stood out from the competition by feeding back the revealed target data given for the previous day and was one of the top 5% of all models in the competition. 
 Introduction On the NASDAQ stock exchange thousands of orders are executed every second, which requires fast and reliable models for bringing buyer and seller together and giving both a competitive price with low spreads compared to other stock exchanges. Especially the last ten minutes of a trading day are characterized by an increased volatility and the closing courses serve as key indicators for many market participants  [1] . While predicting the stock market attracts many researchers, as it promises enormous financial gains, it is also one of the most challenging problems. With the increasing computational power over the lasts decade, researchers were especially successful with supervised learning approaches, like artificial neural networks (ANN) or Support Vector Machines (SVN). But most current models still only have an accuracy between 60% and 80% [2], showing that there is still potential for improvement. Therefore, trading companies and stock exchanges, which especially benefit from having the best predictions, sometimes open competitions for finding better models or new approaches. One of these contests is the Optiver -Trading at the Close challenge 2023  [1] , where we participated in and got in contact with many interesting approaches we want to present in the next chapters."
Unveiling Dreams: Moving Towards Automatic Dream Decoding via PSD-Based EEG Analysis and Machine Learning,"André Torvestad, Mithila Packiyanathan, Luis Moctezuma, Marta Molinas","1 - Department of Engineering Cybernetics Norwegian University of Science and Technology. Trondheim Norway
3 - International Institute for Integrative Sleep Medicine University of Tsukuba. Tsukuba Ibaraki Japan","Equipping brain-computer interfaces with dream decoding capabilities could be vital in healthcare applications. We used high-density electroencephalogram data from non-rapid eye movement sleep to conduct qualitative analysis employing multivariate empirical mode decomposition and power spectral density (PSD) for preprocessing and machine learning algorithms to distinguish between a dream experience and no experience. Qualitative analysis shows differences between the two classes, especially in the theta and beta bands. We achieve a classification performance of 0.915 in accuracy, 0.851 in AUROC, and 0.715 in kappa with PSD features and extreme gradient boosting classifier.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-164,2024,100.0,"Unveiling Dreams: Moving Towards Automatic Dream Decoding via PSD-Based EEG Analysis and Machine Learning Equipping brain-computer interfaces with dream decoding capabilities could be vital in healthcare applications. We used high-density electroencephalogram data from non-rapid eye movement sleep to conduct qualitative analysis employing multivariate empirical mode decomposition and power spectral density (PSD) for preprocessing and machine learning algorithms to distinguish between a dream experience and no experience. Qualitative analysis shows differences between the two classes, especially in the theta and beta bands. We achieve a classification performance of 0.915 in accuracy, 0.851 in AUROC, and 0.715 in kappa with PSD features and extreme gradient boosting classifier."
Sequential Continual Pre-Training for Neural Machine Translation,"Niko Dalla Noce, Michele Resta, Davide Bacciu",1 - University of Pisa -Computer Science Department Largo Bruno Pontecorvo 56127 Pisa Italy,We explore continual pre-training for Neural Machine Translation within a continual learning framework. We introduce a setting where new languages are gradually added to pre-trained models across multiple training experiences. These pre-trained models are subsequently fine-tuned on downstream translation tasks. We compare mBART and mT5 pre-training objectives using four European Languages. Our findings demonstrate that sequentially adding languages during pre-training effectively mitigates catastrophic forgetting and minimally impacts downstream task performance.,Continual Improvement of Deep Neural Networks in The Age of Big Data,https://doi.org/10.14428/esann/2024.ES2024-165,2024,100.0,Sequential Continual Pre-Training for Neural Machine Translation We explore continual pre-training for Neural Machine Translation within a continual learning framework. We introduce a setting where new languages are gradually added to pre-trained models across multiple training experiences. These pre-trained models are subsequently fine-tuned on downstream translation tasks. We compare mBART and mT5 pre-training objectives using four European Languages. Our findings demonstrate that sequentially adding languages during pre-training effectively mitigates catastrophic forgetting and minimally impacts downstream task performance.
T-WinG: Windowing for Temporal Knowledge Graph Completion,"Ngoc-Trung Nguyen, Thanh Vu, Thanh Le","1 - Faculty of Information Technology University of Science Ho Chi Minh City Vietnam
2 - National University Ho Chi Minh City Vietnam, Vietnam
3 - Faculty of Information Technology University of Education Ho Chi Minh City Vietnam","In the domain of Temporal Knowledge Graph Completion, existing models often struggle with efficiently capturing the intricate temporal dynamics and interactions within knowledge graphs. To address these challenges, this paper introduces T-WinG, a novel approach that incorporates the Swin Transformer architecture, renowned for its efficacy in hierarchical representation learning. By integrating SPLIME's preprocessing techniques and refining the Swin Transformer's token mixer, T-WinG substantially improves performance. Specifically, our model demonstrates a performance improvement of up to 20% in accuracy metrics such as Mean Reciprocal Rank (MRR) and Hits@K, across four benchmark datasets compared to the best-performing baseline models. These results not only underscore T-WinG's ability to handle dynamic temporal data but also highlight its potential to address the pressing needs of real-world applications requiring accurate and timely insights from knowledge graphs.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-166,2024,100.0,"T-WinG: Windowing for Temporal Knowledge Graph Completion In the domain of Temporal Knowledge Graph Completion, existing models often struggle with efficiently capturing the intricate temporal dynamics and interactions within knowledge graphs. To address these challenges, this paper introduces T-WinG, a novel approach that incorporates the Swin Transformer architecture, renowned for its efficacy in hierarchical representation learning. By integrating SPLIME's preprocessing techniques and refining the Swin Transformer's token mixer, T-WinG substantially improves performance. Specifically, our model demonstrates a performance improvement of up to 20% in accuracy metrics such as Mean Reciprocal Rank (MRR) and Hits@K, across four benchmark datasets compared to the best-performing baseline models. These results not only underscore T-WinG's ability to handle dynamic temporal data but also highlight its potential to address the pressing needs of real-world applications requiring accurate and timely insights from knowledge graphs."
Feature Learning using Multi-view Kernel Partial Least Squares,"Xinjie Zeng, Qinghua Tao, Johan Suykens",1 - KU Leuven -ESAT-STADIUS Kasteelpark Arenberg 10 B-3001 Heverlee Belgium,"The multi-view learning deals with data of multiple views, aiming to explore the underlying relations between different views and use them for various tasks. In this paper, we derive a multi-view extension of kernel partial least squares for unsupervised feature learning. We establish the optimization objective in the primal as the pairwise covariance between the projection scores and derive that this model can be trained in the dual form by solving an eigenvalue problem. Experiments are also conducted to verify the effectiveness of the method with real-life multi-view datasets, where the proposed method is adopted as a feature extractor and then the clustering task is conducted for performance comparisons.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-168,2024,100.0,"Feature Learning using Multi-view Kernel Partial Least Squares The multi-view learning deals with data of multiple views, aiming to explore the underlying relations between different views and use them for various tasks. In this paper, we derive a multi-view extension of kernel partial least squares for unsupervised feature learning. We establish the optimization objective in the primal as the pairwise covariance between the projection scores and derive that this model can be trained in the dual form by solving an eigenvalue problem. Experiments are also conducted to verify the effectiveness of the method with real-life multi-view datasets, where the proposed method is adopted as a feature extractor and then the clustering task is conducted for performance comparisons."
"""Mental Images"" driven classification","Gianluca Coda, Massimo De Gregorio, Antonio Sorgente, Paolo Vanacore",1 - Istituto di Scienze Applicate e Sistemi Intelligenti -CNR Italy,"Common sense rules are a form of implicit knowledge acquired through experience and observation of the world around us, and used by both humans and machines to reason and to make decisions about the surrounding environment. Artificial Intelligence systems can extract these rules by mining data and apply them to many predictive tasks. Herein, we first present a new method for extracting rules from DRASiW ""Mental Images"" (MI) and then how to exploit them to improve the classification performance of the system. The latter is confirmed by the obtained results.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-169,2024,92.10526315789474,"""Mental Images"" driven classification Common sense rules are a form of implicit knowledge acquired through experience and observation of the world around us, and used by both humans and machines to reason and to make decisions about the surrounding environment. Artificial Intelligence systems can extract these rules by mining data and apply them to many predictive tasks. Herein, we first present a new method for extracting rules from DRASiW ""Mental Images"" (MI) and then how to exploit them to improve the classification performance of the system. The latter is confirmed by the obtained results."
Interpreting Hybrid AI through Autodecoded Latent Space Entities,"Roland Veen, Christodoulos Hadjichristodoulou, Michael Biehl","1 - Computer Science and Artificial Intelligence Univ. of Groningen Bernoulli Institute for Mathematics Groningen The Netherlands
2 - Medical Research Council Laboratory of Medical Sciences (MRC LMS London United Kingdom","Explainable AI models and methods have seen a rise in interest in recent years as a reaction to the widespread use of neural networks and similar black-box models in machine learning. In this project, we combine explainable, prototype-based systems and neural networks in an effort to benefit from both approaches. Specifically, we employ Generalized Matrix Relevance Learning Vector Quantization in combination with autoencoder networks. This allows us to perform automated non-linear feature extraction from high-dimensional inputs before feeding them into LVQ for classification. Moreover, the approach enables the mapping of the low-dimensional representatives and relevances back to the original feature space for visual inspection and interpretation.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-170,2024,100.0,"Interpreting Hybrid AI through Autodecoded Latent Space Entities Explainable AI models and methods have seen a rise in interest in recent years as a reaction to the widespread use of neural networks and similar black-box models in machine learning. In this project, we combine explainable, prototype-based systems and neural networks in an effort to benefit from both approaches. Specifically, we employ Generalized Matrix Relevance Learning Vector Quantization in combination with autoencoder networks. This allows us to perform automated non-linear feature extraction from high-dimensional inputs before feeding them into LVQ for classification. Moreover, the approach enables the mapping of the low-dimensional representatives and relevances back to the original feature space for visual inspection and interpretation."
Convergence analysis of an inexact gradient method on smooth convex functions,"Pierre Vernimmen, François Glineur",1 - Université catholique de Louvain -ICTEAM institute B-1348 Louvain-la-Neuve Belgium,"We consider the classical gradient method with constant stepsizes where some error is introduced in the computation of each gradient. More specifically, we assume relative inexactness, in the sense that the norm of the difference between the true gradient and its approximate value is bounded by a certain fraction of the gradient norm. We establish a sublinear convergence rate for this inexact method when applied to smooth convex functions, and illustrate on a logistic regression example.",Optimization,https://doi.org/10.14428/esann/2024.ES2024-171,2024,100.0,"Convergence analysis of an inexact gradient method on smooth convex functions We consider the classical gradient method with constant stepsizes where some error is introduced in the computation of each gradient. More specifically, we assume relative inexactness, in the sense that the norm of the difference between the true gradient and its approximate value is bounded by a certain fraction of the gradient norm. We establish a sublinear convergence rate for this inexact method when applied to smooth convex functions, and illustrate on a logistic regression example."
On the Stability of Neural Segmentation in Radiology,"Moritz Wolter, Lokesh Veeramacheneni, Bettina Baeßler, Ulrike Attenberger, Barbara Wichtmann","1 - High-Performance Computing and Analytics Lab University of Bonn GER
3 - Inst. of Diagnostic and Interventional Radiology University Hospital Würzburg GER
4 - Dept. of Diagnostic and Interventional Radiology University Hospital Bonn GER
6 - Dept. of Neuroradiology University Hospital Bonn GER","Neural networks promise automated prostate segmentation for the development of precise and quantifiable image-based biomarkers in modern personalized oncology. Before clinical translation, however, their stability must be ensured. In this study, we train three-dimensional Ushaped convolutional neural networks to segment prostate magnetic resonance imaging (MRI) scans and evaluate different loss formulations to improve their performance. To evaluate generalizability and reproducibility of our networks, we compare their performance in a clinically acquired test/re-test MRI data set of 26 prostate cancer patients that was previously not seen by the networks. We find our networks to be generalizable with good reproducibility with a mean Intersection over Union of 0.88. While initial results are promising, anatomical accuracy remains to be evaluated in larger, multi-center data sets. To facilitate clinical applicability, we provide an easy to use toolbox online.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-172,2024,100.0,"On the Stability of Neural Segmentation in Radiology Neural networks promise automated prostate segmentation for the development of precise and quantifiable image-based biomarkers in modern personalized oncology. Before clinical translation, however, their stability must be ensured. In this study, we train three-dimensional Ushaped convolutional neural networks to segment prostate magnetic resonance imaging (MRI) scans and evaluate different loss formulations to improve their performance. To evaluate generalizability and reproducibility of our networks, we compare their performance in a clinically acquired test/re-test MRI data set of 26 prostate cancer patients that was previously not seen by the networks. We find our networks to be generalizable with good reproducibility with a mean Intersection over Union of 0.88. While initial results are promising, anatomical accuracy remains to be evaluated in larger, multi-center data sets. To facilitate clinical applicability, we provide an easy to use toolbox online."
Exploring Temporal Knowledge Graphs with Compositional Interactions and Diachronic Mechanisms,"Loc Tran, Bac Le, Thanh Le","1 - Faculty of Information Technology University of Science Ho Chi Minh City Vietnam
2 - National University Ho Chi Minh City Vietnam, Vietnam","Temporal Knowledge Graphs (TKGs) organize dynamic real-world facts, adding a time dimension to the multi-relational graph structure of Knowledge Graphs (KGs). We leverage the expressive power of graph convolutional networks (GCNs) for modeling TKGs, recognizing similarities with handling graph-structured data and utilizing complex geometry. Our approach emphasizes compositional interactions between relations and entities, integrating a diachronic mechanism to enhance representation with both graph structure and temporal dynamics. Experimental results on benchmark datasets, employing various composition operators, showcase the effectiveness of our model in link prediction tasks.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-173,2024,100.0,"Exploring Temporal Knowledge Graphs with Compositional Interactions and Diachronic Mechanisms Temporal Knowledge Graphs (TKGs) organize dynamic real-world facts, adding a time dimension to the multi-relational graph structure of Knowledge Graphs (KGs). We leverage the expressive power of graph convolutional networks (GCNs) for modeling TKGs, recognizing similarities with handling graph-structured data and utilizing complex geometry. Our approach emphasizes compositional interactions between relations and entities, integrating a diachronic mechanism to enhance representation with both graph structure and temporal dynamics. Experimental results on benchmark datasets, employing various composition operators, showcase the effectiveness of our model in link prediction tasks."
Physics-Aware Normalizing Flows: Leveraging Electric Circuit Models in Adversarial Learning,"Benjamin Schindler, Thomas Schmid","1 - Machine Learning Group Universität Leipzig Augustusplatz 10 Leipzig Germany
2 - Martin-Luther-Universität Halle-Wittenberg Magdeburger Str. 8
3 - Halle (Saale) Germany
4 - Lancaster University in Leipzig Nikolaistrasse 10 Leipzig Germany","We introduce Physics-Aware Normalizing Flows, a novel framework combining data-driven generative modeling with a physical layer based on an Electric Circuit Model, ensuring adherence to electricity laws, sample fidelity, and explainability. Four existing Normalizing Flow architectures, including Real-NVP and NSF, were adapted to our adversarial regime and evaluated with promising results for the ad hoc determination of value ranges of physical quantities and the generation of labeled measurements based on an unlabeled dataset. By extensive data generation according to our self-explainable approach, Random Forest regressions of underlying physical quantities could be improved significantly, compared to the original dataset including omitted ground truth labels.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-177,2024,100.0,"Physics-Aware Normalizing Flows: Leveraging Electric Circuit Models in Adversarial Learning We introduce Physics-Aware Normalizing Flows, a novel framework combining data-driven generative modeling with a physical layer based on an Electric Circuit Model, ensuring adherence to electricity laws, sample fidelity, and explainability. Four existing Normalizing Flow architectures, including Real-NVP and NSF, were adapted to our adversarial regime and evaluated with promising results for the ad hoc determination of value ranges of physical quantities and the generation of labeled measurements based on an unlabeled dataset. By extensive data generation according to our self-explainable approach, Random Forest regressions of underlying physical quantities could be improved significantly, compared to the original dataset including omitted ground truth labels."
Towards the Application of Backpropagation-Free Graph Convolutional Networks on Huge Datasets,"Nicolò Navarin, Luca Pasa, Alessandro Sperduti",1 - Department of Mathematics via Trieste 63 University of Padua 35121 Padua Italy,"Backpropagation-Free Graph Convolutional Networks (BF-GCN) are backpropagation-free neural models dealing with graph data based on Gated Linear Networks. Each neuron in a BF-GCN is defined as a set of graph convolution filters (weight vectors) and a gating mechanism that, given a node's context, selects the weight vector to use for processing the node's attributes based on its distance from a set of prototypes. Given the higher expressivity BF-GNN's neurons compared to the standard graph convolutional neural networks' ones, they show bigger memory footprint. In this paper, we explore how reducing the size of node contexts through randomization can reduce the memory occupancy of the method, enabling its application to huge datasets. We empirically show how working with very low dimensional contexts does not impact the resulting predictive performances.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-179,2024,87.09677419354838,"Towards the Application of Backpropagation-Free Graph Convolutional Networks on Huge Datasets Backpropagation-Free Graph Convolutional Networks (BF-GCN) are backpropagation-free neural models dealing with graph data based on Gated Linear Networks. Each neuron in a BF-GCN is defined as a set of graph convolution filters (weight vectors) and a gating mechanism that, given a node's context, selects the weight vector to use for processing the node's attributes based on its distance from a set of prototypes. Given the higher expressivity BF-GNN's neurons compared to the standard graph convolutional neural networks' ones, they show bigger memory footprint. In this paper, we explore how reducing the size of node contexts through randomization can reduce the memory occupancy of the method, enabling its application to huge datasets. We empirically show how working with very low dimensional contexts does not impact the resulting predictive performances."
Invariant Representation Learning for Generalizable Imitation,"Mohamed Khalil Jabri, Panagiotis Papadakis, Ehsan Abbasnejad, Gilles Coppin, Javen Shi","1 - Lab-STICC UMR CNRS 6285 IMT Atlantique F-29238 Brest France
2 - Australian Institute for Machine Learning The University of Adelaide Australia
3 - IRL CROSSING CNRS Adelaide Australia","We address the problem of learning imitation policies that generalize across environments sharing the same underlying causal structure between the system dynamics and the task. We introduce a novel loss for learning invariant state representations that draws inspiration from adversarial robustness. Our approach is algorithm-agnostic and does not require knowledge of domain labels. Yet, evaluation in visual and non-visual environments reveals improved zero-shot generalization in the presence of spurious features compared to previous works.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-18,2024,100.0,"Invariant Representation Learning for Generalizable Imitation We address the problem of learning imitation policies that generalize across environments sharing the same underlying causal structure between the system dynamics and the task. We introduce a novel loss for learning invariant state representations that draws inspiration from adversarial robustness. Our approach is algorithm-agnostic and does not require knowledge of domain labels. Yet, evaluation in visual and non-visual environments reveals improved zero-shot generalization in the presence of spurious features compared to previous works."
Vision Language Models as Policy Learners in Reinforcement Learning Environments,"Giovanni Bonetta, Davide Zago, Rossella Cancelliere, Mirko Polato, Bernardo Magnini","1 - Bruno Kessler Foundation via Sommarive, 18 -Povo 38123 Trento Italy
2 - Department of Computer Science University of Turin 12 -10149 Turin Italy","In various domains requiring general knowledge and agent reasoning, traditional reinforcement learning (RL) algorithms often start from scratch, lacking prior knowledge of the environment. This approach can lead to significant inefficiencies as agents sometimes undergo extensive exploration before optimizing their actions. Conversely, in this paper we assume that recent Vision Language Models (VLMs), integrating both visual and textual information, possess inherent knowledge and basic reasoning capabilities, offering potential solutions to the sample inefficiency problem in RL. The paper explores the integration of VLMs into RL by employing a robust VLM model, Idefics-9B, as a policy updated via Proximal Policy Optimization (PPO). Experimental results on simulated environments demonstrate that utilizing VLMs in RL significantly accelerates PPO convergence and improves rewards compared to traditional solutions. Additionally, we propose a streamlined modification to the model architecture for memory efficiency and lighter training, and we release a number of upgraded environments featuring both visual observations and textual descriptions, which, we hope, will facilitate research in VLM and RL applications. Code is available at: https://github.com/giobin/VlmPolicyEsann24 * We acknowledge ISCRA for awarding this project access to the LEONARDO supercomputer, owned by the EuroHPC Joint Undertaking, hosted by CINECA (Italy).","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-181,2024,100.0,"Vision Language Models as Policy Learners in Reinforcement Learning Environments In various domains requiring general knowledge and agent reasoning, traditional reinforcement learning (RL) algorithms often start from scratch, lacking prior knowledge of the environment. This approach can lead to significant inefficiencies as agents sometimes undergo extensive exploration before optimizing their actions. Conversely, in this paper we assume that recent Vision Language Models (VLMs), integrating both visual and textual information, possess inherent knowledge and basic reasoning capabilities, offering potential solutions to the sample inefficiency problem in RL. The paper explores the integration of VLMs into RL by employing a robust VLM model, Idefics-9B, as a policy updated via Proximal Policy Optimization (PPO). Experimental results on simulated environments demonstrate that utilizing VLMs in RL significantly accelerates PPO convergence and improves rewards compared to traditional solutions. Additionally, we propose a streamlined modification to the model architecture for memory efficiency and lighter training, and we release a number of upgraded environments featuring both visual observations and textual descriptions, which, we hope, will facilitate research in VLM and RL applications. Code is available at: https://github.com/giobin/VlmPolicyEsann24 * We acknowledge ISCRA for awarding this project access to the LEONARDO supercomputer, owned by the EuroHPC Joint Undertaking, hosted by CINECA (Italy)."
FedHP: Federated Learning with Hyperspherical Prototypical Regularization,"Samuele Fonio, Mirko Polato, Roberto Esposito",1 - Computer Science Department University of Turin Corso Svizzera 175 Turin Italy,"This paper presents FedHP, an algorithm that amalgamates federated learning, hyperspherical geometries, and prototype learning. Federated Learning (FL) has garnered attention as a privacy-preserving method for constructing robust models across distributed datasets. Traditionally, FL involves exchanging model parameters to uphold data privacy; however, in scenarios with costly data communication, exchanging large neural network models becomes impractical. In such instances, prototype learning provides a feasible solution by necessitating the exchange of a few class prototypes instead of entire deep learning models. Motivated by these considerations, our approach leverages recent advancements in prototype learning, particularly the benefits offered by non-Euclidean geometries. Alongside introducing FedHP, we provide empirical evidence demonstrating its comparable performance to other state-of-the-art approaches while significantly reducing communication costs.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-183,2024,100.0,"FedHP: Federated Learning with Hyperspherical Prototypical Regularization This paper presents FedHP, an algorithm that amalgamates federated learning, hyperspherical geometries, and prototype learning. Federated Learning (FL) has garnered attention as a privacy-preserving method for constructing robust models across distributed datasets. Traditionally, FL involves exchanging model parameters to uphold data privacy; however, in scenarios with costly data communication, exchanging large neural network models becomes impractical. In such instances, prototype learning provides a feasible solution by necessitating the exchange of a few class prototypes instead of entire deep learning models. Motivated by these considerations, our approach leverages recent advancements in prototype learning, particularly the benefits offered by non-Euclidean geometries. Alongside introducing FedHP, we provide empirical evidence demonstrating its comparable performance to other state-of-the-art approaches while significantly reducing communication costs."
On F β -score and Cost-Consistency in Evaluation of Imbalanced Classification,Aleksi Avela,1 - School of Science Department of Mathematics and Systems Analysis Aalto University P.O. Box 11100 FI-00076 Aalto Finland,"Among many other difficulties of imbalanced classification, evaluation of classifiers is rarely trivial. F β -score is often recommended as one of the go-to evaluation measures in imbalanced classification, but researchers have voiced their concerns on whether F β -score in fact is an appropriate measure. In this paper, we introduce a framework of costconsistency, i.e., whether an evaluation measure is consistent with total classification cost at least for some cost and class imbalance ratio, and show that, with a simple cost structure, F β -score is not cost-consistent.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-186,2024,89.47368421052632,"On F β -score and Cost-Consistency in Evaluation of Imbalanced Classification Among many other difficulties of imbalanced classification, evaluation of classifiers is rarely trivial. F β -score is often recommended as one of the go-to evaluation measures in imbalanced classification, but researchers have voiced their concerns on whether F β -score in fact is an appropriate measure. In this paper, we introduce a framework of costconsistency, i.e., whether an evaluation measure is consistent with total classification cost at least for some cost and class imbalance ratio, and show that, with a simple cost structure, F β -score is not cost-consistent."
Unsupervised Drift Detection Using Quadtree Spatial Mapping,"Bernardo Ramos, Cristiano Castro, Tiago Coelho, Plamen Angelov","1 - Graduate Program in Electrical Engineering Universidade Federal de Minas Gerais Belo Horizonte Brazil
3 - School of Computing Communications Lancaster University Lancaster United Kingdom
4 - Universidade Estadual de Feira de Santana Brazil",This paper presents an unsupervised and model-independent concept drift detector based on quadtree spatial analysis (QTS). We used a d-dimensional quadtree to map the feature space and tracked a univariate curve that mimics the spatial behavior of the data stream. This curve serves as a helpful visual tool for analyzing concept drifts. Drifts are identified when there is a significant change in the current spatial mapping. Experimental results show that the proposed outperformed well-known drift detectors in terms of average precision and F1-score.,Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-187,2024,100.0,Unsupervised Drift Detection Using Quadtree Spatial Mapping This paper presents an unsupervised and model-independent concept drift detector based on quadtree spatial analysis (QTS). We used a d-dimensional quadtree to map the feature space and tracked a univariate curve that mimics the spatial behavior of the data stream. This curve serves as a helpful visual tool for analyzing concept drifts. Drifts are identified when there is a significant change in the current spatial mapping. Experimental results show that the proposed outperformed well-known drift detectors in terms of average precision and F1-score.
Clarity: a Deep Ensemble for Visual Counterfactual Explanations,"Claire Theobald, Frédéric Pennerath, Brieuc Conan-Guez, Miguel Couceiro, Amedeo Napoli","1 - Université de Lorraine CNRS F-54000 Nancy LORIA France
2 - Université de Lorraine, CentraleSupélec CNRS F-57000 Metz LORIA France","Counterfactual visual explanations are aimed at identifying changes in an image that will modify the prediction of a classifier. Unlike adversarial images, counterfactuals are required to be realistic. For this reason generative models such as variational autoencoders (VAE) have been used to restrain the search of counterfactuals on the data manifold. However such gradient-based approaches remain limited even when they deal with simple datasets such as MNIST. Conjecturing that these limitations result from a plateau effect which makes the gradient noisy and less informative, we improve the gradient estimation by training an ensemble of classifiers directly in the latent space of VAEs. Several experiments show that the resulting method called Clarity delivers counterfactual images of high-quality, competitive with the state-of-the-art.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-188,2024,100.0,"Clarity: a Deep Ensemble for Visual Counterfactual Explanations Counterfactual visual explanations are aimed at identifying changes in an image that will modify the prediction of a classifier. Unlike adversarial images, counterfactuals are required to be realistic. For this reason generative models such as variational autoencoders (VAE) have been used to restrain the search of counterfactuals on the data manifold. However such gradient-based approaches remain limited even when they deal with simple datasets such as MNIST. Conjecturing that these limitations result from a plateau effect which makes the gradient noisy and less informative, we improve the gradient estimation by training an ensemble of classifiers directly in the latent space of VAEs. Several experiments show that the resulting method called Clarity delivers counterfactual images of high-quality, competitive with the state-of-the-art."
Inductive Lateral Movement Detection in Enterprise Computer Networks,Corentin Larroche,"1 - French Cybersecurity Agency (ANSSI) 51 boulevard de La Tour-Maubourg 75700, 07 SP Paris France","Lateral movement is a crucial phase of advanced cyberattacks, during which attackers propagate from host to host within the targeted network. State-of-the-art methods for detecting this behavior rely on graph-based learning algorithms, which typically leverage node embeddings to detect anomalous edges between hosts. Once trained, such models cannot easily generalize to new hosts joining the network or to a different network, which is impractical in real-world applications. We investigate the detection performance of an inductive link prediction model, which can generalize to graphs not seen during training, and find that it performs as well as state-of-the-art transductive methods in a zero-shot setting. This opens promising perspectives for practical lateral movement detection.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-19,2024,75.0,"Inductive Lateral Movement Detection in Enterprise Computer Networks Lateral movement is a crucial phase of advanced cyberattacks, during which attackers propagate from host to host within the targeted network. State-of-the-art methods for detecting this behavior rely on graph-based learning algorithms, which typically leverage node embeddings to detect anomalous edges between hosts. Once trained, such models cannot easily generalize to new hosts joining the network or to a different network, which is impractical in real-world applications. We investigate the detection performance of an inductive link prediction model, which can generalize to graphs not seen during training, and find that it performs as well as state-of-the-art transductive methods in a zero-shot setting. This opens promising perspectives for practical lateral movement detection."
Insight-SNE: Understanding t-SNE Embeddings through Interactive Explanation,"Sacha Corbugy, Thibaut Septon, Bruno Dumas, Benoit Frenay",1 - Faculty of Computer Science University of Namur -NaDI Grandgagnage 21 B-5000 Namur Belgium,"Non-linear dimensionality reduction techniques offer insights into complex datasets, yet interpreting them poses challenges. While some papers provide methods for explaining DR, and others focus on interactively exploring embeddings, there are currently no works that seamlessly combine both aspects. Our contributions, Insight-SNE, propose an interactive tool that allows exploring t-SNE embeddings and their related gradient-based explanations, as well as its evaluation with expert users. 1 Supported by the Walloon region, with a Ph.D. grant from FRIA (F.R.S.-FNRS). 2 Supported by the Walloon region through the Pole MecaTech fund OPTIMIS (nb. 8564).",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-190,2024,100.0,"Insight-SNE: Understanding t-SNE Embeddings through Interactive Explanation Non-linear dimensionality reduction techniques offer insights into complex datasets, yet interpreting them poses challenges. While some papers provide methods for explaining DR, and others focus on interactively exploring embeddings, there are currently no works that seamlessly combine both aspects. Our contributions, Insight-SNE, propose an interactive tool that allows exploring t-SNE embeddings and their related gradient-based explanations, as well as its evaluation with expert users. 1 Supported by the Walloon region, with a Ph.D. grant from FRIA (F.R.S.-FNRS). 2 Supported by the Walloon region through the Pole MecaTech fund OPTIMIS (nb. 8564)."
Does a Reduced Fine-Tuning Surface Impact the Stability of the Explanations of LLMs?,"Jeremie Bogaert, François-Xavier Standaert",1 - Crypto Group ICTEAM Institute UCLouvain; Louvain-la-Neuve Belgium,"Explainability is an increasingly demanded feature for the deployment of LLMs. In this context, it has been shown that the explanations of models that are equivalent from the accuracy viewpoint can differ due to their training randomness, leading to a need to characterize the explanations' distribution and to understand the origin of this sensitivity. In this paper, we investigate whether the fine-tuning surface, defined as the number of bits that are fine-tuned in a LLM, can serve as a good proxy for the stability of its explanations. We answer negatively and show that two different approaches for reducing the fine-tuning surface, namely quantizing and freezing (a part of) the models, lead to very different outcomes.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-194,2024,100.0,"Does a Reduced Fine-Tuning Surface Impact the Stability of the Explanations of LLMs? Explainability is an increasingly demanded feature for the deployment of LLMs. In this context, it has been shown that the explanations of models that are equivalent from the accuracy viewpoint can differ due to their training randomness, leading to a need to characterize the explanations' distribution and to understand the origin of this sensitivity. In this paper, we investigate whether the fine-tuning surface, defined as the number of bits that are fine-tuned in a LLM, can serve as a good proxy for the stability of its explanations. We answer negatively and show that two different approaches for reducing the fine-tuning surface, namely quantizing and freezing (a part of) the models, lead to very different outcomes."
Deep Temporal Consensus Clustering for Patient Stratification in Amyotrophic Lateral Sclerosis,"Miguel Roque, Andreia Martins, Marta Gromicho, Mamede De Carvalho, Sara Madeira, Pedro Tomás, Helena Aidos","1 - INESC-ID Instituto Superior Técnico Universidade de Lisboa Portugal
2 - Faculdade de Ciências LASIGE Universidade de Lisboa Portugal
3 - Instituto de Medicina Molecular and Faculdade de Medicina Universidade de Lisboa Portugal","Amyotrophic Lateral Sclerosis (ALS) is a fast-acting neurodegenerative disease, characterized by loss of muscle movement and heterogeneity in disease evolution. This poses a challenge in predicting the best time for therapy administration. Here, we propose Deep Temporal Consensus Clustering (DTCC), a stratification method to uncover patient groups with similar disease progression. Using only the initial 6-month follow-up period, DTCC uncovered five clusters that were evaluated in terms of disease evolution and time-to-event. For three critical events (non-invasive ventilation, gastrostomy and death) the attained groups show distinct 10year progressions, validating the approach.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-195,2024,100.0,"Deep Temporal Consensus Clustering for Patient Stratification in Amyotrophic Lateral Sclerosis Amyotrophic Lateral Sclerosis (ALS) is a fast-acting neurodegenerative disease, characterized by loss of muscle movement and heterogeneity in disease evolution. This poses a challenge in predicting the best time for therapy administration. Here, we propose Deep Temporal Consensus Clustering (DTCC), a stratification method to uncover patient groups with similar disease progression. Using only the initial 6-month follow-up period, DTCC uncovered five clusters that were evaluated in terms of disease evolution and time-to-event. For three critical events (non-invasive ventilation, gastrostomy and death) the attained groups show distinct 10year progressions, validating the approach."
HDBSCAN for 3rd-order tensors,"Dina Andriantsiory, Joseph Geloun, Mustapha Lebbah","1 - LIPN UMR CNRS 7030 Université Sorbonne Paris Nord Villetaneuse France
3 - Paris-Saclay University UVSQ David Lab Versailles France","Several methods for tensor clustering require hyperparameters such as the cluster size or the number of clusters per mode. These methods present a challenge because, for real datasets, such inputs cannot be determined without incurring significant costs. Recently, Multi-Slice Clustering (MSC) has addressed this issue by utilizing a threshold parameter to perform data clustering. MSC identifies signal slices that reside in a lower-dimensional subspace within a 3rd-order rank-1 tensor dataset. However, determining the tensor rank remains a complex task. The current work introduces a new approach to tensor clustering that can extract clusters of similar slices and is also capable of finding co-clustering and triclustering in 3rd-order tensors of any rank. Our algorithm is based on the density of the data.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-198,2024,79.3103448275862,"HDBSCAN for 3rd-order tensors Several methods for tensor clustering require hyperparameters such as the cluster size or the number of clusters per mode. These methods present a challenge because, for real datasets, such inputs cannot be determined without incurring significant costs. Recently, Multi-Slice Clustering (MSC) has addressed this issue by utilizing a threshold parameter to perform data clustering. MSC identifies signal slices that reside in a lower-dimensional subspace within a 3rd-order rank-1 tensor dataset. However, determining the tensor rank remains a complex task. The current work introduces a new approach to tensor clustering that can extract clusters of similar slices and is also capable of finding co-clustering and triclustering in 3rd-order tensors of any rank. Our algorithm is based on the density of the data."
Continual Improvement of Deep Neural Networks in The Age of Big Data,"Alexander Gepperth, Timothée Lesort","1 - Department of Applied Computer Science Leipzigerstraße 123 University of Applied Sciences Fulda 36093 Fulda Germany
2 - Aignostics GmbH Alt-Moabit 73/73a 10555 Berlin Germany","Many applications of deep learning are set in an environment with perpetual change or at least with an ever-growing amount of data. In practice, deep neural network (DNNs) and large language models (LLMs) are continually trained and evaluated. They need to incorporate new data or new annotations, where one typical issue is the extensive availability of unannotated or low-quality data, coupled with a bottleneck concerning annotations and/or curated samples. In such setups, the scaling behavior of continual learning (CL) algorithms w.r.t. training time becomes critical, which is in contrast to the standard CL setting operating on small databases like MNIST, CIFAR or ImageNet. Annotations or curated samples become available progressively, e.g., because they are created by humans, or due to an ongoing exploration of the environment, and need to be progressively incorporated into models. This article explores how advancement in continual learning can improve the scalability and performance of DNNs and LLMs in such setups. One interesting aspect is to leverage dedicated (small-scale) CL techniques to achieve advantageous trade-offs between computational cost and accuracy, or how such CL methods can maintain advantageous scaling behavior w.r.t. continuous re-training on all data.",Continual Improvement of Deep Neural Networks in The Age of Big Data,https://doi.org/10.14428/esann/2024.ES2024-2,2024,88.72180451127821,"Continual Improvement of Deep Neural Networks in The Age of Big Data Many applications of deep learning are set in an environment with perpetual change or at least with an ever-growing amount of data. In practice, deep neural network (DNNs) and large language models (LLMs) are continually trained and evaluated. They need to incorporate new data or new annotations, where one typical issue is the extensive availability of unannotated or low-quality data, coupled with a bottleneck concerning annotations and/or curated samples. In such setups, the scaling behavior of continual learning (CL) algorithms w.r.t. training time becomes critical, which is in contrast to the standard CL setting operating on small databases like MNIST, CIFAR or ImageNet. Annotations or curated samples become available progressively, e.g., because they are created by humans, or due to an ongoing exploration of the environment, and need to be progressively incorporated into models. This article explores how advancement in continual learning can improve the scalability and performance of DNNs and LLMs in such setups. One interesting aspect is to leverage dedicated (small-scale) CL techniques to achieve advantageous trade-offs between computational cost and accuracy, or how such CL methods can maintain advantageous scaling behavior w.r.t. continuous re-training on all data."
Informed Machine Learning: Excess Risk and Generalization,"Luca Oneto, Sandro Ridella, Davide Anguita",1 - University of Genoa Via Opera Pia 11a 16145 Genova Italy,"Machine Learning (ML) based predictive models are impacting research, industry, and society at large thanks to their ability to model or surrogate real systems. Two of the main current limitations of ML are the need for large amounts of high quality data and low performance far away from the observed data. For this reason, in certain applications where prior knowledge is available, researchers have developed Informed ML (IML) to decrease ML high quality data voracity and increase ML extrapolation abilities. In this work we study the differences between ML and IML excess risk and generalization using also some examples to elucidate the theoretical discussions. Our findings shed some light on the mechanisms and the conditions under which IML outperforms ML.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-20,2024,100.0,"Informed Machine Learning: Excess Risk and Generalization Machine Learning (ML) based predictive models are impacting research, industry, and society at large thanks to their ability to model or surrogate real systems. Two of the main current limitations of ML are the need for large amounts of high quality data and low performance far away from the observed data. For this reason, in certain applications where prior knowledge is available, researchers have developed Informed ML (IML) to decrease ML high quality data voracity and increase ML extrapolation abilities. In this work we study the differences between ML and IML excess risk and generalization using also some examples to elucidate the theoretical discussions. Our findings shed some light on the mechanisms and the conditions under which IML outperforms ML."
Estimated neighbour sets and smoothed sampled global interactions are sufficient for a fast approximate t-SNE,"Pierre Lambert, Edouard Couplet, Cyril De Bodt, John Lee","1 - ICTEAM/ELEN Place du Levant Université catholique de Louvain
4 - L5.03.02, 1348 Louvain-la-Neuve Belgium
5 - Université catholique de Louvain -IREC/MIRO Avenue Hippocrate 55 B1.54.07 1200 Brussels Belgium","To minimise its loss function, the popular method of nonlinear dimensionality reduction t-SNE requires O(N 2 ) computations. As its applications often involve large datasets, fast approximations have been developed, such as Barnes-Hut t-SNE and FIt-SNE. Most fast approximations to t-SNE require the embedding dimensionality to be small, typically 2 or 3, limiting the use of t-SNE to data visualisation. Additionally, the effective computation time of the current accelerated t-SNE algorithms stays too high for a comfortable interactive visual exploration of data. This paper proposes an accelerated approximation to t-SNE with iterations of complexity O(N K), which does not rely on the use of a model to capture information about the low-dimensional space, relieving the computational burden of high dimensionality of the embedding space. For this purpose, the proposed method approximates neighbour sets and keeps track of smoothed estimations of long-range interactions in O(N K) time. The method is qualitatively tested on a handful of datasets and shows comparable results to existing fast neighbour embedding methods in the context of data visualisation. Code is available at https://github.com/PierreLambert3/c_fast_hSNE.git.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-203,2024,99.08256880733946,"Estimated neighbour sets and smoothed sampled global interactions are sufficient for a fast approximate t-SNE To minimise its loss function, the popular method of nonlinear dimensionality reduction t-SNE requires O(N 2 ) computations. As its applications often involve large datasets, fast approximations have been developed, such as Barnes-Hut t-SNE and FIt-SNE. Most fast approximations to t-SNE require the embedding dimensionality to be small, typically 2 or 3, limiting the use of t-SNE to data visualisation. Additionally, the effective computation time of the current accelerated t-SNE algorithms stays too high for a comfortable interactive visual exploration of data. This paper proposes an accelerated approximation to t-SNE with iterations of complexity O(N K), which does not rely on the use of a model to capture information about the low-dimensional space, relieving the computational burden of high dimensionality of the embedding space. For this purpose, the proposed method approximates neighbour sets and keeps track of smoothed estimations of long-range interactions in O(N K) time. The method is qualitatively tested on a handful of datasets and shows comparable results to existing fast neighbour embedding methods in the context of data visualisation. Code is available at https://github.com/PierreLambert3/c_fast_hSNE.git."
AI-based algorithm for intrusion detection on a real dataset,"Alejandro Esteban Martínez, David Esteban Martínez, Bertha Guijarro-Berdiñas, Amparo Alonso-Betanzos, Elena Hernández-Pereira, Julio Hernández-Castro, A Coruña -Spain","1 - Universidade da Coruña
6 - Universidad Politécnica de Madrid Madrid Spain","In the realm of cybersecurity, the detection of network intrusions stands as a paramount challenge, with ever-evolving threats demanding innovative solutions. This study delves into the application of diverse machine learning algorithms on a contemporary dataset (UGR'16) comprising real-world instances of intrusion in software systems. Specifically, several Machine Learning models (Outlier Detectors, Ensemble Methods, Deep Learning, and Conventional Classifiers) were tested and compared with previously reported results using a standard methodology. The obtained results reveal that the Ensemble Methods have been capable of improving the results from prior research. Particularly, the Extreme Gradient Boosting (XGBoost) algorithm offers better results than the original solution with Random Forest, with an AUC of 0.9218 as opposed to 0.8977, and more than four times as fast for the problem to solve.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-204,2024,100.0,"AI-based algorithm for intrusion detection on a real dataset In the realm of cybersecurity, the detection of network intrusions stands as a paramount challenge, with ever-evolving threats demanding innovative solutions. This study delves into the application of diverse machine learning algorithms on a contemporary dataset (UGR'16) comprising real-world instances of intrusion in software systems. Specifically, several Machine Learning models (Outlier Detectors, Ensemble Methods, Deep Learning, and Conventional Classifiers) were tested and compared with previously reported results using a standard methodology. The obtained results reveal that the Ensemble Methods have been capable of improving the results from prior research. Particularly, the Extreme Gradient Boosting (XGBoost) algorithm offers better results than the original solution with Random Forest, with an AUC of 0.9218 as opposed to 0.8977, and more than four times as fast for the problem to solve."
A Two-Stage Approach for Implicit Bias Detection in Generative Language Models,"Jeremy Edwards, Renjie Hu, Amaury Lendasse, Alexander Schlager, Peggy Lindner","1 - Dept. of Information Science Technology University of Houston 14004 University Boulevard 77479 Sugar Land TX USA
3 - Systems Engineering 223 Engineering Management Missouri University of Science & Technology Dept. of Engineering Management 600 W. 14th St 65409 Rolla MO USA
4 - AIceberg Inc New York USA","Machine learning and AI are increasingly popular for their impressive task performance. Yet, Natural Language Processing (NLP) models often inadvertently learn harmful biases related to gender and race, leading to skewed predictions. Literature distinguishes between direct and indirect bias. Current research aims to detect and mitigate these biases in machine learning models. This study introduces a two-stage approach to identify both types of gender bias in generative large language models (LLMs), confirming that they can manifest both direct and indirect biases.",Language models,https://doi.org/10.14428/esann/2024.ES2024-206,2024,100.0,"A Two-Stage Approach for Implicit Bias Detection in Generative Language Models Machine learning and AI are increasingly popular for their impressive task performance. Yet, Natural Language Processing (NLP) models often inadvertently learn harmful biases related to gender and race, leading to skewed predictions. Literature distinguishes between direct and indirect bias. Current research aims to detect and mitigate these biases in machine learning models. This study introduces a two-stage approach to identify both types of gender bias in generative large language models (LLMs), confirming that they can manifest both direct and indirect biases."
Large Language Models as Tuning Agents of Metaheuristics,"Alicja Martinek, Szymon Lukasik, Amir Gandomi","1 - NASK -National Research Institute Warsaw Poland
2 - AGH University of Technology in Kraków Kraków Poland
5 - University of Technology Sydney Sydney Australia
6 - Obuda University Budapest Hungary","This study examines whether LLMs can be utilized in metaheuristic tuning through selection of appropriate parameters. Instances of two optimization problems, Travelling Salesman and Graph Coloring, were solved with GA, ACO, PSO, and SA. Experiment involved running these heuristic optimizers with parameter values advised by LLMs. A round of feedback was performed through feeding LLMs with prompts that included initial parameters, average performance, and population variance, where applicable. The results show LLMs exhibit the ability to comprehend the non-trivial task of tuning metaheuristics' parameters. Additionally, feedback runs often outperform results achieved by initial setups, yielding a new application of LLMs.",Language models,https://doi.org/10.14428/esann/2024.ES2024-209,2024,100.0,"Large Language Models as Tuning Agents of Metaheuristics This study examines whether LLMs can be utilized in metaheuristic tuning through selection of appropriate parameters. Instances of two optimization problems, Travelling Salesman and Graph Coloring, were solved with GA, ACO, PSO, and SA. Experiment involved running these heuristic optimizers with parameter values advised by LLMs. A round of feedback was performed through feeding LLMs with prompts that included initial parameters, average performance, and population variance, where applicable. The results show LLMs exhibit the ability to comprehend the non-trivial task of tuning metaheuristics' parameters. Additionally, feedback runs often outperform results achieved by initial setups, yielding a new application of LLMs."
Continual Learning with Graph Reservoirs: Preliminary experiments in graph classification,"Domenico Tortorella, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy,"Continual learning aims to address the challenge of catastrophic forgetting in training models where data patterns are non-stationary. Previous research has shown that fully-trained graph learning models are particularly affected by this issue. One approach to lifting part of the burden is to leverage the representations provided by a training-free reservoir computing model. In this work, we evaluate for the first time different continual learning strategies in conjunction with Graph Echo State Networks, which have already demonstrated their efficacy and efficiency in graph classification tasks.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-21,2024,100.0,"Continual Learning with Graph Reservoirs: Preliminary experiments in graph classification Continual learning aims to address the challenge of catastrophic forgetting in training models where data patterns are non-stationary. Previous research has shown that fully-trained graph learning models are particularly affected by this issue. One approach to lifting part of the burden is to leverage the representations provided by a training-free reservoir computing model. In this work, we evaluate for the first time different continual learning strategies in conjunction with Graph Echo State Networks, which have already demonstrated their efficacy and efficiency in graph classification tasks."
Recurrent Neural Network based Counter Automata,"Sergio Leal, Luis Lago-Fernández",1 - Departamento de Ingeniería Informática Universidad Autónoma de Madrid Ciudad Universitaria de Cantoblanco 28049 Madrid Spain,"This paper presents a neural network architecture that aims to merge RNNs and push-down automata in order to address the recognition of formal languages improving interpretability. The model manages to reproduce a behaviour equivalent to that of an automaton, making it more generalizable and interpretable. Validation has been carried out through several experiments, testing not only convergence but also adaptability and training speed, and comparing the results with similar existing models, as well as with an LSTM. The proposed model serves as a starting point with excellent results, and serves as a basis for future extensions to more sophisticated architectures. * This work has been partially funded by Spanish projects PID2020-114867RB-I00 and PID2023-149669NB-I00 (http://www.mineco.gob.es/).","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-211,2024,100.0,"Recurrent Neural Network based Counter Automata This paper presents a neural network architecture that aims to merge RNNs and push-down automata in order to address the recognition of formal languages improving interpretability. The model manages to reproduce a behaviour equivalent to that of an automaton, making it more generalizable and interpretable. Validation has been carried out through several experiments, testing not only convergence but also adaptability and training speed, and comparing the results with similar existing models, as well as with an LSTM. The proposed model serves as a starting point with excellent results, and serves as a basis for future extensions to more sophisticated architectures. * This work has been partially funded by Spanish projects PID2020-114867RB-I00 and PID2023-149669NB-I00 (http://www.mineco.gob.es/)."
Federated Learning in a Semi-Supervised Environment for Earth Observation Data,"Bruno Casella, Alessio Barbaro Chisari, Marco Aldinucci, Sebastiano Battiato, Mario Valerio Giuffrida","1 - Computer Science Department Alpha Research Group University of Turin C.so Svizzera 185 Turin Italy
2 - Department of Mathematics and Computer Science -Image Processing Laboratory University of Catania Viale Andrea Doria 6 Catania Italy
5 - School of Computer Science University of Nottingham Wollaton Road NG8 1BB Nottingham UK","We propose FedRec, a federated learning workflow taking advantage of unlabelled data in a semi-supervised environment to assist in the training of a supervised aggregated model. In our proposed method, an encoder architecture extracting features from unlabelled data is aggregated with the feature extractor of a classification model via weight averaging. The fully connected layers of the supervised models are also averaged in a federated fashion. We show the effectiveness of our approach by comparing it with the state-of-the-art federated algorithm, an isolated and a centralised baseline, on novel cloud detection datasets. Our code is available at https://github.com/CasellaJr/FedRec.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-214,2024,100.0,"Federated Learning in a Semi-Supervised Environment for Earth Observation Data We propose FedRec, a federated learning workflow taking advantage of unlabelled data in a semi-supervised environment to assist in the training of a supervised aggregated model. In our proposed method, an encoder architecture extracting features from unlabelled data is aggregated with the feature extractor of a classification model via weight averaging. The fully connected layers of the supervised models are also averaged in a federated fashion. We show the effectiveness of our approach by comparing it with the state-of-the-art federated algorithm, an isolated and a centralised baseline, on novel cloud detection datasets. Our code is available at https://github.com/CasellaJr/FedRec."
Exploring Self-Organizing Maps for Addressing Semantic Impairments,"Jorge Graneri, Sebastián Basterrech, Eduardo Mizraji, Gerardo Rubino","1 - Faculty of Engineering UDELAR Montevideo Uruguay
2 - DTU-Compute Technical University of Denmark Kongens Lyngby Denmark
3 - Faculty of Sciences UDELAR Montevideo Uruguay
4 - INRIA Rennes -Bretagne Atlantique Rennes France","Since the 1990s, Self-Organizing Maps (SOMs) have been instrumental in reducing dimensionality and visualizing high-dimensional data. This study adapts SOMs to explore the neural representation of human concepts, their neural 'word net' mapping, and the deterioration of these mappings in certain neurological disorders. Our model draws inspiration from semantic dementia, a severe condition that degrades semantic knowledge in the brain. Although our exploration utilizes a low-dimensional model -a rough simplification with respect of our brains -it successfully replicates observed clinical patterns. These promising results inspire further research to enhance our understanding of language pathophysiology in neurological disorders. * This paper has been partially supported by ECOS Project U17E03 ""MASC"".",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-215,2024,100.0,"Exploring Self-Organizing Maps for Addressing Semantic Impairments Since the 1990s, Self-Organizing Maps (SOMs) have been instrumental in reducing dimensionality and visualizing high-dimensional data. This study adapts SOMs to explore the neural representation of human concepts, their neural 'word net' mapping, and the deterioration of these mappings in certain neurological disorders. Our model draws inspiration from semantic dementia, a severe condition that degrades semantic knowledge in the brain. Although our exploration utilizes a low-dimensional model -a rough simplification with respect of our brains -it successfully replicates observed clinical patterns. These promising results inspire further research to enhance our understanding of language pathophysiology in neurological disorders. * This paper has been partially supported by ECOS Project U17E03 ""MASC""."
Decision fusion based multimodal hierarchical method for speech emotion recognition from audio and text,"Nawal Alqurashi, Yuhua Li, Kirill Sidorov, David Marshall",1 - School of computer Science and Informatics Cardiff University UK,"Expressing emotions is essential in human interaction. Often, individuals convey emotions through neutral speech, while the underlying meaning carries emotional weight. Conversely, tone can also convey emotion despite neutral words. Most Speech Emotion Recognition research overlooks this. We address this gap with a multimodal emotion recognition system using hierarchical classifiers and a novel decision fusion method. Our approach analyses emotional cues from speech and text, measuring their impact on predicted classes, considering emotional or neutral contributions for each instance. Results on the IEMOCAP dataset show our method's effectiveness: 69.45% and 65.26% weighted accuracy in speaker-dependent and speaker-independent settings, respectively.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-219,2024,100.0,"Decision fusion based multimodal hierarchical method for speech emotion recognition from audio and text Expressing emotions is essential in human interaction. Often, individuals convey emotions through neutral speech, while the underlying meaning carries emotional weight. Conversely, tone can also convey emotion despite neutral words. Most Speech Emotion Recognition research overlooks this. We address this gap with a multimodal emotion recognition system using hierarchical classifiers and a novel decision fusion method. Our approach analyses emotional cues from speech and text, measuring their impact on predicted classes, considering emotional or neutral contributions for each instance. Results on the IEMOCAP dataset show our method's effectiveness: 69.45% and 65.26% weighted accuracy in speaker-dependent and speaker-independent settings, respectively."
Robustness and Regularization in Hierarchical Re-Basin,"Benedikt Franke, Florian Heinrich, Markus Lange, Arne Raulf",1 - German Aerospace Center (DLR) -Institute for AI Safety and Security Wilhelm-Runge-Strasse 10 89081 Ulm Germany,"This paper takes a closer look at Git Re-Basin, an interesting new approach to merge trained models. We propose a hierarchical model merging scheme that significantly outperforms the standard MergeMany algorithm. With our new algorithm, we find that Re-Basin induces adversarial and perturbation robustness into the merged models, with the effect becoming stronger the more models participate in the hierarchical merging scheme. However, in our experiments Re-Basin induces a much bigger performance drop than reported by the original authors.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-22,2024,100.0,"Robustness and Regularization in Hierarchical Re-Basin This paper takes a closer look at Git Re-Basin, an interesting new approach to merge trained models. We propose a hierarchical model merging scheme that significantly outperforms the standard MergeMany algorithm. With our new algorithm, we find that Re-Basin induces adversarial and perturbation robustness into the merged models, with the effect becoming stronger the more models participate in the hierarchical merging scheme. However, in our experiments Re-Basin induces a much bigger performance drop than reported by the original authors."
Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts,"Thanh Nguyen, Campbell Wilson, Janis Dalins","1 - Faculty of Information Technology AiLECS Lab Monash University Melbourne Australia
3 - AiLECS Lab Australian Federal Police Melbourne Australia","This paper proposes an approach to detection of online harmful content using the open-source pretrained Llama 2 model, recently released by Meta GenAI. We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages. Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods. Experimental results show a strong performance of the proposed approach, which is proficient and consistent across three distinct datasets with five sets of experiments. This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, and hate speech in online discussions and comments to maintain respectful digital communities.",Language models,https://doi.org/10.14428/esann/2024.ES2024-222,2024,100.0,"Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts This paper proposes an approach to detection of online harmful content using the open-source pretrained Llama 2 model, recently released by Meta GenAI. We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages. Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods. Experimental results show a strong performance of the proposed approach, which is proficient and consistent across three distinct datasets with five sets of experiments. This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, and hate speech in online discussions and comments to maintain respectful digital communities."
SAT Instances Generation Using Graph Variational Autoencoders,"Daniel Crowley, Marco Dalla, Barry O'sullivan, Andrea Visentin","1 - School of Computer Science University College Cork Cork Ireland
3 - SFI Centre for Research Training in AI University College Cork Cork Ireland
5 - Insight SFI Research Centre for Data Analytics Cork Ireland","This paper presents a SAT instance generator using a Graph Variational Autoencoder (GVAE2SAT ) architecture that outperforms existing generative deep learning models in speed and requires minimal post-processing. Our computational analyses benchmark this model against current deep learning techniques, introducing advanced metrics for more accurate evaluation. This new model is unique in its ability to maintain partial satisfiability of SAT instances while significantly reducing computational time. Although no method perfectly addresses all challenges in generating SAT instances, our approach marks a significant step forward in the efficiency and effectiveness of SAT instance generation.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-223,2024,100.0,"SAT Instances Generation Using Graph Variational Autoencoders This paper presents a SAT instance generator using a Graph Variational Autoencoder (GVAE2SAT ) architecture that outperforms existing generative deep learning models in speed and requires minimal post-processing. Our computational analyses benchmark this model against current deep learning techniques, introducing advanced metrics for more accurate evaluation. This new model is unique in its ability to maintain partial satisfiability of SAT instances while significantly reducing computational time. Although no method perfectly addresses all challenges in generating SAT instances, our approach marks a significant step forward in the efficiency and effectiveness of SAT instance generation."
Dual Stream Graph Transformer Fusion Networks for Enhanced Brain Decoding,"Lucas Goené, Siamak Mehrkanoon",1 - Department of Information and Computing Sciences Utrecht University Utrecht The Netherlands,"This paper presents the novel Dual Stream Graph-Transformer Fusion (DS-GTF) architecture designed specifically for classifying task-based Magnetoencephalography (MEG) data. In the spatial stream, inputs are initially represented as graphs, which are then passed through graph attention networks (GAT) to extract spatial patterns. Two methods, TopK and Thresholded Adjacency are introduced for initializing the adjacency matrix used in the GAT. In the temporal stream, the Transformer Encoder receives concatenated windowed input MEG data and learns new temporal representations. The learned temporal and spatial representations from both streams are fused before reaching the output layer. Experimental results demonstrate an enhancement in classification performance and a reduction in standard deviation across multiple test subjects compared to other examined models.",Graph learning,https://doi.org/10.14428/esann/2024.ES2024-23,2024,100.0,"Dual Stream Graph Transformer Fusion Networks for Enhanced Brain Decoding This paper presents the novel Dual Stream Graph-Transformer Fusion (DS-GTF) architecture designed specifically for classifying task-based Magnetoencephalography (MEG) data. In the spatial stream, inputs are initially represented as graphs, which are then passed through graph attention networks (GAT) to extract spatial patterns. Two methods, TopK and Thresholded Adjacency are introduced for initializing the adjacency matrix used in the GAT. In the temporal stream, the Transformer Encoder receives concatenated windowed input MEG data and learns new temporal representations. The learned temporal and spatial representations from both streams are fused before reaching the output layer. Experimental results demonstrate an enhancement in classification performance and a reduction in standard deviation across multiple test subjects compared to other examined models."
Joint Entropy Search for Multi-objective Bayesian Optimization with Constraints and Multiple Fidelities,"Daniel Fernández-Sánchez, Daniel Hernández-Lobato","1 - Computer Science Department Universidad Autónoma de Madrid
2 - Francisco Tomás y Valiente 11 28049 Madrid Spain","Bayesian optimization (BO) methods solve problems with several black-box objectives and constraints. Each black-box is expensive to evaluate and lacks a closed-form. They use a model of each black-box to guide the search for the problem's solution. Sometimes, however, the black-boxes may be evaluated at different fidelity levels. A lower fidelity is simply a cheap proxy of the corresponding black-box. Thus, lower fidelities that correlate with the actual black-box can be used to reduce the optimization cost. We propose Joint Entropy Search for Multi-Fidelity and Multi-objective Bayesian Optimization with Constraints (MF-JESMOC), a BO method for solving the aforementioned problems. It chooses the next point and fidelity level at which to evaluate the black-boxes as the one that is expected to reduce the most the joint entropy of the Pareto set and the Pareto front, normalized by the fidelity's cost. Deep Gaussian processes are used to model each black-box and dependencies between fidelities. In our experiments, MF-JESMOC outperforms other state-of-the-art methods for multi-objective BO with constraints and different fidelity levels. † The authors acknowledge financial support from projects PID2019-106827GB-I00 and PID2022-139856NB-I00, funded by MCIN and from the Autonomous Community of Madrid (ELLIS Unit Madrid). They also acknowledge the use of the facilities of Centro de Computación Científica, UAM.",Optimization,https://doi.org/10.14428/esann/2024.ES2024-24,2024,100.0,"Joint Entropy Search for Multi-objective Bayesian Optimization with Constraints and Multiple Fidelities Bayesian optimization (BO) methods solve problems with several black-box objectives and constraints. Each black-box is expensive to evaluate and lacks a closed-form. They use a model of each black-box to guide the search for the problem's solution. Sometimes, however, the black-boxes may be evaluated at different fidelity levels. A lower fidelity is simply a cheap proxy of the corresponding black-box. Thus, lower fidelities that correlate with the actual black-box can be used to reduce the optimization cost. We propose Joint Entropy Search for Multi-Fidelity and Multi-objective Bayesian Optimization with Constraints (MF-JESMOC), a BO method for solving the aforementioned problems. It chooses the next point and fidelity level at which to evaluate the black-boxes as the one that is expected to reduce the most the joint entropy of the Pareto set and the Pareto front, normalized by the fidelity's cost. Deep Gaussian processes are used to model each black-box and dependencies between fidelities. In our experiments, MF-JESMOC outperforms other state-of-the-art methods for multi-objective BO with constraints and different fidelity levels. † The authors acknowledge financial support from projects PID2019-106827GB-I00 and PID2022-139856NB-I00, funded by MCIN and from the Autonomous Community of Madrid (ELLIS Unit Madrid). They also acknowledge the use of the facilities of Centro de Computación Científica, UAM."
Transfer learning to minimize the predictive risk in clinical research,"Samuel Branders, Jérôme Paul, Arthur Ooghe, Alvaro Pereira",1 - Rue Granbonpre 11 bte 9 1435 Mont-Saint-Guibert Belgium,"The volume of data collected from patients enrolled in clinical trials is constantly on the rise. Classical linear and generalized linear models used in this context are unable to keep pace with this trend. Conversely, machine learning models have the potential to deal with such data, but cannot provide guarantees in terms of bias and interpretability. This paper explores a transfer learning approach that seeks to harmonize the strengths of both paradigms: providing unbiased and interpretable estimators while minimizing the expected predictive risk in finite samples. where Z = (Z 1 , . . . , Z d ) T is a vector of d variables of interest. γ is the vector of parameters we are looking to estimate, U is the error term, and µ is the 203",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-25,2024,100.0,"Transfer learning to minimize the predictive risk in clinical research The volume of data collected from patients enrolled in clinical trials is constantly on the rise. Classical linear and generalized linear models used in this context are unable to keep pace with this trend. Conversely, machine learning models have the potential to deal with such data, but cannot provide guarantees in terms of bias and interpretability. This paper explores a transfer learning approach that seeks to harmonize the strengths of both paradigms: providing unbiased and interpretable estimators while minimizing the expected predictive risk in finite samples. where Z = (Z 1 , . . . , Z d ) T is a vector of d variables of interest. γ is the vector of parameters we are looking to estimate, U is the error term, and µ is the 203"
Towards calibration-free online EEG motor imagery decoding using Deep Learning,"Martin Wimpff, Jan Zerfowski, Bin Yang","1 - Institute of Signal Processing and System Theory University of Stuttgart Germany
2 - Department of Psychiatry and Neurosciences Clinical Neurotechnology Laboratory Charité Campus Mitte (CCM) Charité -Universitätsmedizin Berlin Germany","The prevalence of stroke-induced disability drives research in motor imagery Brain-Computer Interfaces (BCIs) for rehabilitation. Closed-loop systems using traditional decoding models prevail but deep learning advances in single-trial offline decoding offer promises. However, transferring methods from offline to online decoding poses challenges. To address this, we propose a new approach to tune existing offline deep learning models towards online decoding, outperforming traditional pipelines without the need for subject-specific calibration data. Our proposed method is a step towards calibration-free BCIs that enable immediate feedback and user learning.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-26,2024,100.0,"Towards calibration-free online EEG motor imagery decoding using Deep Learning The prevalence of stroke-induced disability drives research in motor imagery Brain-Computer Interfaces (BCIs) for rehabilitation. Closed-loop systems using traditional decoding models prevail but deep learning advances in single-trial offline decoding offer promises. However, transferring methods from offline to online decoding poses challenges. To address this, we propose a new approach to tune existing offline deep learning models towards online decoding, outperforming traditional pipelines without the need for subject-specific calibration data. Our proposed method is a step towards calibration-free BCIs that enable immediate feedback and user learning."
Hyperbolic Metabolite-Disease Association Prediction,"Domonkos Pogány, Péter Antal",1 - Department of Artificial Intelligence and Systems Engineering Budapest University of Technology and Economics 1111 Budapest Hungary,"In biomarker research, there is a growing demand for computational methods to efficiently identify novel metabolite-disease associations (MDAs). Current approaches, however, do not take into account the underlying geometry of the MDA space. Here, we show that classifiers leveraging hyperbolic embeddings achieve comparable results to their Euclidean counterparts with significantly lower dimensionality, aligning better with the association network's scale-free nature. Finally, through a case study, we provide an interpretation of the model embeddings and investigate newly predicted associations. Our results demonstrate the intrinsic non-Euclidean geometry of the MDA space, providing direction for further research. A Pytorch-based implementation is available at https://github.com/PDomonkos/hyperbolic-MDA-prediction.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-29,2024,100.0,"Hyperbolic Metabolite-Disease Association Prediction In biomarker research, there is a growing demand for computational methods to efficiently identify novel metabolite-disease associations (MDAs). Current approaches, however, do not take into account the underlying geometry of the MDA space. Here, we show that classifiers leveraging hyperbolic embeddings achieve comparable results to their Euclidean counterparts with significantly lower dimensionality, aligning better with the association network's scale-free nature. Finally, through a case study, we provide an interpretation of the model embeddings and investigate newly predicted associations. Our results demonstrate the intrinsic non-Euclidean geometry of the MDA space, providing direction for further research. A Pytorch-based implementation is available at https://github.com/PDomonkos/hyperbolic-MDA-prediction."
"Machine learning in distributed, federated and non-stationary environments -recent trends","Mirko Polato, Barbara Hammer, Frank-Michael Schleif","1 - Department of Computer Science University of Turin Turin Italy
2 - Bielefeld University CITEC, Bielefeld Germany
3 - -Technical UAS Würzburg Schweinfurt
4 - Dept. of CS Würzburg Germany","This tutorial provides an overview of machine learning methodologies applied in distributed, federated, and non-stationary environments. We focus on recent advancements and novel research contributions of the field. Key topics include data analysis and pattern recognition for non-stationary environments, model compression, federated learning algorithms, and privacy preservation. This tutorial aims to equip researchers and practitioners with insights into current challenges and innovative solutions in this dynamic field.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-3,2024,92.73743016759776,"Machine learning in distributed, federated and non-stationary environments -recent trends This tutorial provides an overview of machine learning methodologies applied in distributed, federated, and non-stationary environments. We focus on recent advancements and novel research contributions of the field. Key topics include data analysis and pattern recognition for non-stationary environments, model compression, federated learning algorithms, and privacy preservation. This tutorial aims to equip researchers and practitioners with insights into current challenges and innovative solutions in this dynamic field."
A Deep Double Q-Learning as a SDLS support in solving LABS problem,"Dominik Żurek, Marcin Pietroń, Kamil Pietak, Kamil Faber",1 - AGH University of Krakow al Adama Mickiewicza 30 30-059 Krakow Poland,"Low Autocorrelation Binary Sequence (LABS) remains an open complex optimization problem with multiple applications. Existing studies rely primarily on advanced solvers based on local search heuristics, such as the steepest-descent local search algorithm (SDLS), Tabu search, or xLastovka algorithms. These approaches require searching through a large solution space, which is a computationally heavy and time-consuming process, leading to slower convergence. To improve convergence speed and allow for finding better solutions within a limited time, we propose the Deep Double Q-learning reinforcement learning algorithm for the LABS problem to support heuristic methods. The model aims to narrow down the search space without causing a drop in the final efficiency. Our experimental study showcases that the proposed approach is a promising direction for developing a highly efficient method for the LABS problem. * {dzurek, pietron, kpietak, kfaber}@agh.edu.pl. This paper was realized with funds of Polish Ministry of Science and Higher Education assigned to AGH University and it was supported by PLGrid Infrastructure.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-36,2024,100.0,"A Deep Double Q-Learning as a SDLS support in solving LABS problem Low Autocorrelation Binary Sequence (LABS) remains an open complex optimization problem with multiple applications. Existing studies rely primarily on advanced solvers based on local search heuristics, such as the steepest-descent local search algorithm (SDLS), Tabu search, or xLastovka algorithms. These approaches require searching through a large solution space, which is a computationally heavy and time-consuming process, leading to slower convergence. To improve convergence speed and allow for finding better solutions within a limited time, we propose the Deep Double Q-learning reinforcement learning algorithm for the LABS problem to support heuristic methods. The model aims to narrow down the search space without causing a drop in the final efficiency. Our experimental study showcases that the proposed approach is a promising direction for developing a highly efficient method for the LABS problem. * {dzurek, pietron, kpietak, kfaber}@agh.edu.pl. This paper was realized with funds of Polish Ministry of Science and Higher Education assigned to AGH University and it was supported by PLGrid Infrastructure."
Trustworthiness Score for Echo State Networks by Analysis of the Reservoir Dynamics,"José Enguita, Diego García, Abel Cuadrado, Daniel Peña, José Rodríguez, Ignacio Díaz","1 - Dept. of Electrical Engineering University of Oviedo 33204 Gijón Spain
5 - SUPPRESS Research Group University of León 24007 León Spain","Epistemic uncertainty arises from input data areas where models lack exposure during training and may result in significant performance degradation in deployment. Echo State Networks are often used as virtual sensors or digital twins processing temporal input data, so their robustness against this degradation is crucial. This paper addresses this challenge by proposing a score comparing the similarity between the dynamic evolution of the reservoir in training and in inference. This research aims to enhance model confidence and adaptability in evolving circumstances.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-38,2024,100.0,"Trustworthiness Score for Echo State Networks by Analysis of the Reservoir Dynamics Epistemic uncertainty arises from input data areas where models lack exposure during training and may result in significant performance degradation in deployment. Echo State Networks are often used as virtual sensors or digital twins processing temporal input data, so their robustness against this degradation is crucial. This paper addresses this challenge by proposing a score comparing the similarity between the dynamic evolution of the reservoir in training and in inference. This research aims to enhance model confidence and adaptability in evolving circumstances."
"Machine Learning Methods for BCI: challenges, pitfalls and promises","Jaime Salas, Marta Molina, Fabien Lotte","1 - Department of Engineering Cybernetics Inria Center NTNU 4-LaBRI Norway
2 - University of Bordeaux France
3 - Postdam University 1-PECoG Germany
4 - GITESI Institucion Universitaria de Envigado (IUE) Colombia","The development of Brain-Computer Interfaces (BCIs) has been constrained by a predominant focus on signal classification. This paper rather emphasizes the integration of neurophysiological principles, BCI paradigm selection, and rigorous experimental design. By addressing common pitfalls in Machine Learning implementation, we provide researchers with a tutorial and robust framework for BCI development, promoting reproducibility and rigor. Furthermore, by tackling challenges at the intersection of BCI and Machine Learning, this work contributes to the advancement of practical, real-time BCI applications.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-4,2024,100.0,"Machine Learning Methods for BCI: challenges, pitfalls and promises The development of Brain-Computer Interfaces (BCIs) has been constrained by a predominant focus on signal classification. This paper rather emphasizes the integration of neurophysiological principles, BCI paradigm selection, and rigorous experimental design. By addressing common pitfalls in Machine Learning implementation, we provide researchers with a tutorial and robust framework for BCI development, promoting reproducibility and rigor. Furthermore, by tackling challenges at the intersection of BCI and Machine Learning, this work contributes to the advancement of practical, real-time BCI applications."
Analysis of DNA methylation patterns in cancer samples using SOM,"Ignacio Díaz, José Enguita, Diego García, Abel Cuadrado, Nuria Valdés, María Chiara","1 - University of Oviedo -Dept. of Electrical Engineering Edificio Torres Quevedo módulo 2, Campus de 33204 Gijón SPAIN
5 - Department of Endocrinology and Nutrition Hospital Universitario Cruces Bilbao Bizkaia. Biobizkaia
6 - CIBERER CIBERDEM, EndoERN
7 - Institute of Sanitary Research Principado de Asturias Hospital Universitario Central de Asturias 33011 Oviedo SPAIN","By leveraging the SOM algorithm and the extensive epigenomic data from TCGA, this work aims to suggest a valid approach to explore the relationships between epigenetic alterations and PCPG pathogenesis. Additionally, the methodological approach presented here lays the foundation for a potentially valuable analysis tool that can be applied to other cancer types and epigenetic research.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-42,2024,100.0,"Analysis of DNA methylation patterns in cancer samples using SOM By leveraging the SOM algorithm and the extensive epigenomic data from TCGA, this work aims to suggest a valid approach to explore the relationships between epigenetic alterations and PCPG pathogenesis. Additionally, the methodological approach presented here lays the foundation for a potentially valuable analysis tool that can be applied to other cancer types and epigenetic research."
Few-shot similarity learning for motion classification via electromyography,"Rui Liu, Benjamin Paassen",1 - Faculty of Technology Bielefeld University Germany,"Accurate motion classification from surface electromyography signals is crucial for controlling bionic prostheses. Unfortunately, most state-of-the-art classifiers need to be re-trained with lots of data to recognize any new motion. Therefore, we propose a few-shot similarity learning approach that can be applied to new classes without any re-training, just using one to five reference points per new class. In experiments on two real-world data sets, we find that our proposed approach outperforms two state-of-the-art approaches for few-shot learning on sEMG signals, namely a transfer learning and a contrastive learning approach. Our experiments also reveal that the choice of loss function is crucial for performance whereas the choice of similarity function has less effect.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-43,2024,100.0,"Few-shot similarity learning for motion classification via electromyography Accurate motion classification from surface electromyography signals is crucial for controlling bionic prostheses. Unfortunately, most state-of-the-art classifiers need to be re-trained with lots of data to recognize any new motion. Therefore, we propose a few-shot similarity learning approach that can be applied to new classes without any re-training, just using one to five reference points per new class. In experiments on two real-world data sets, we find that our proposed approach outperforms two state-of-the-art approaches for few-shot learning on sEMG signals, namely a transfer learning and a contrastive learning approach. Our experiments also reveal that the choice of loss function is crucial for performance whereas the choice of similarity function has less effect."
Tumor Grading via Decorrelated Sparse Survival Regression,"Benjamin Paaßen, Nadine Gaisa, Michael Rose, Mark-Sebastian Bösherz","1 - Faculty of Technology Bielefeld University Bielefeld Germany
2 - Institute of Pathology University Hospital RWTH Aachen University Aachen Germany
3 - -Institute of Pathology University Hospital Ulm University of Ulm Ulm Germany","In medical pathology, tumor grading is concerned with estimating the risk posed by a tumor, based on its pathological features. One way to infer risk scores is survival regression, i.e. using machine learning to infer a score that predicts the remaining survival time of a patient. Unfortunately, if applied naively, such a score is a mix of the intrinsic risk posed by the tumor and other risk factors, like the progression of the tumor or patient gender and age. We provide the first survival regression model that disentangles tumor grading from undesired correlations, while retaining a high degree of model interpretability, thanks to convex optimization, nonnegativity constraints, sparsity, and linearity. We evaluate the proposed approach both on simulated and real-world data from N = 114 patients at the University Clinic Aachen.",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-44,2024,100.0,"Tumor Grading via Decorrelated Sparse Survival Regression In medical pathology, tumor grading is concerned with estimating the risk posed by a tumor, based on its pathological features. One way to infer risk scores is survival regression, i.e. using machine learning to infer a score that predicts the remaining survival time of a patient. Unfortunately, if applied naively, such a score is a mix of the intrinsic risk posed by the tumor and other risk factors, like the progression of the tumor or patient gender and age. We provide the first survival regression model that disentangles tumor grading from undesired correlations, while retaining a high degree of model interpretability, thanks to convex optimization, nonnegativity constraints, sparsity, and linearity. We evaluate the proposed approach both on simulated and real-world data from N = 114 patients at the University Clinic Aachen."
Graph-cut-assisted CNN training for pulmonary embolism segmentation,"Nana Yang, Robin Verschuren, C De Vleeschouwer",1 - ICTEAM -UCLouvain Louvain-la-Neuve 1348 Belgium,"We present a novel algorithm for pulmonary embolism segmentation, designed to alleviate the need for expert annotation. Our approach integrates deep learning with a conventional image segmentation techniques, operating in two distinct stages. Specifically, graph cut is used for initial segmentation, followed by manual refinement, to define the labels required to train a CNN. This CNN is then employed to generate pseudolabels on a large dataset, enabling the training of an improved CNN*. Our findings demonstrate enhanced performance of CNN* over CNN. Overall, the CNN* builds on a very limited amount of manual intervention. Moreover, the injection of expert knowledge in the graph-cut avoids the need for expert knowledge in this manual intervention.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-45,2024,100.0,"Graph-cut-assisted CNN training for pulmonary embolism segmentation We present a novel algorithm for pulmonary embolism segmentation, designed to alleviate the need for expert annotation. Our approach integrates deep learning with a conventional image segmentation techniques, operating in two distinct stages. Specifically, graph cut is used for initial segmentation, followed by manual refinement, to define the labels required to train a CNN. This CNN is then employed to generate pseudolabels on a large dataset, enabling the training of an improved CNN*. Our findings demonstrate enhanced performance of CNN* over CNN. Overall, the CNN* builds on a very limited amount of manual intervention. Moreover, the injection of expert knowledge in the graph-cut avoids the need for expert knowledge in this manual intervention."
Self-Supervised Learning from Incrementally Drifting Data Streams,"Valerie Vaquet, Jonas Vaquet, Fabian Hinder, Kleanthis Malialis, Christos Panayiotou, Marios Polycarpou, Barbara Hammer","1 - Machine Learning Group Bielefeld University Bielefeld Germany
2 - -KIOS Research and Innovation Center of Excellence University of Cyprus Nicosia -Cyprus
7 - Department of Electrical and Computer Engineering University of Cyprus Nicosia Cyprus","Supervised online learning relies on the assumption that ground truth information is available for model updates at each time step. As this is not realistic in every setting, alternatives such as active online learning, or online learning with verification latency have been proposed. In this work, we assume that no label information is available after intitial training. We argue that provided we can characterize the expected concept drift as incremental drift, we can rely on a self-labeling strategy to keep updated models. We derive a k-NN-based self-labeling online learner implementing the presented self-supervised scheme and experimentally show that this is an option for learning from incrementally drifting data streams in the absence of label information.",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-49,2024,100.0,"Self-Supervised Learning from Incrementally Drifting Data Streams Supervised online learning relies on the assumption that ground truth information is available for model updates at each time step. As this is not realistic in every setting, alternatives such as active online learning, or online learning with verification latency have been proposed. In this work, we assume that no label information is available after intitial training. We argue that provided we can characterize the expected concept drift as incremental drift, we can rely on a self-labeling strategy to keep updated models. We derive a k-NN-based self-labeling online learner implementing the presented self-supervised scheme and experimentally show that this is an option for learning from incrementally drifting data streams in the absence of label information."
Domain Knowledge Integration in Machine Learning Systems An Introduction,"Marika Kaden, Sascha Saralajew, Thomas Villmann","1 - Saxon Institute for Computational Intelligence and Machine Learning (SICIM) Mittweida University of Applied Sciences Mittweida Germany
2 - NEC Laboratories Europe GmbH Heidelberg Germany","Knowledge integration into machine learning systems is a promising and successful strategy to achieve more plausible and consistent results. The plausibility is accompanied by better model interpretability due to the adjustment of the machine learning system to the domain specic requirements and restrictions. Further, informed machine learning can be seen as a particular task specic regularization of the model leading to better learning convergence and frequently also requiring a lower amount of training data. This short introduction paper addresses some recent aspects, how domain knowledge can be integrated into learning systems on dierent levels ranging from informed feature extraction to domain adjusted structure and model architecture. * M.K. is supported by the IAI-XPRESS and the DAIMLER project which both are parts of the interdisciplinarry project Articial Intelligence Meets Space (AIMS, No. 50WK2270E) funded by the German Space Agency (DLR).",Domain Knowledge Integration in Machine Learning Systems,https://doi.org/10.14428/esann/2024.ES2024-5,2024,98.63013698630137,"Domain Knowledge Integration in Machine Learning Systems An Introduction Knowledge integration into machine learning systems is a promising and successful strategy to achieve more plausible and consistent results. The plausibility is accompanied by better model interpretability due to the adjustment of the machine learning system to the domain specic requirements and restrictions. Further, informed machine learning can be seen as a particular task specic regularization of the model leading to better learning convergence and frequently also requiring a lower amount of training data. This short introduction paper addresses some recent aspects, how domain knowledge can be integrated into learning systems on dierent levels ranging from informed feature extraction to domain adjusted structure and model architecture. * M.K. is supported by the IAI-XPRESS and the DAIMLER project which both are parts of the interdisciplinarry project Articial Intelligence Meets Space (AIMS, No. 50WK2270E) funded by the German Space Agency (DLR)."
Online Adaptation of Compressed Models by Pre-Training and Task-Relevant Pruning,"Thomas Avé, Matthias Hutsebaut-Buysse, Wei Wei, Kevin Mets","1 - University of Antwerp -imec Sint-Pietersvliet 7 2000 Antwerp Belgium
2 - IDLab -Department of Computer Science 1 Faculty of Applied Engineering","Neural networks are increasingly deployed on edge devices, where they must adapt to new data in dynamic environments. Here, model compression techniques like pruning are essential. This involves removing redundant neurons, increasing efficiency at the cost of accuracy, and creating a conflict between efficiency and adaptability. We propose a novel method for training and compressing models that maintains and extends their ability to generalize to new data, improving online adaptation without reducing compression rates. By pre-training the model on additional knowledge and identifying the parts of the deep neural network that actually encode task-relevant knowledge, we can effectively prune the model by 80% and achieve 16% higher accuracies when adapting to new domains. * This paper was supported by the OpenSwarm project and FWO [Grant 1SD9523N].",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-50,2024,100.0,"Online Adaptation of Compressed Models by Pre-Training and Task-Relevant Pruning Neural networks are increasingly deployed on edge devices, where they must adapt to new data in dynamic environments. Here, model compression techniques like pruning are essential. This involves removing redundant neurons, increasing efficiency at the cost of accuracy, and creating a conflict between efficiency and adaptability. We propose a novel method for training and compressing models that maintains and extends their ability to generalize to new data, improving online adaptation without reducing compression rates. By pre-training the model on additional knowledge and identifying the parts of the deep neural network that actually encode task-relevant knowledge, we can effectively prune the model by 80% and achieve 16% higher accuracies when adapting to new domains. * This paper was supported by the OpenSwarm project and FWO [Grant 1SD9523N]."
From Data to Simulation: Capturing Aircraft Engine Degradation Dynamics,"Abdellah Madane, Florent Forest, Hanane Azzag, Mustapha Lebbah, Jérôme Lacaille","1 - Paris-Saclay University -DAVID Lab UVSQ Versailles France
2 - Safran Airraft Engines -Moissy-Cramayel France
3 - EPFL -IMOS Lab Lausanne Switzerland
4 - UMR CNRS 7030 Sorbonne Paris Nord University -LIPN Villetaneuse France","The analysis and simulation of aircraft engine behavior have garnered significant attention in the aeronautical industry, primarily due to its implications for performance, maintenance, safety, and sustainability. Our work successfully showcases the efficacy of utilizing time series data collected from our aircraft engines to construct a digital twin capable of dynamically emulating their real-time behavior. We then introduce a new methodology to model the physical engine's degradation and meticulously monitor its evolution over time. By continuously analyzing the simulated data against real-world performance measurements, our approach offers valuable insights into the engine's long-term behavior and health trajectory.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-51,2024,100.0,"From Data to Simulation: Capturing Aircraft Engine Degradation Dynamics The analysis and simulation of aircraft engine behavior have garnered significant attention in the aeronautical industry, primarily due to its implications for performance, maintenance, safety, and sustainability. Our work successfully showcases the efficacy of utilizing time series data collected from our aircraft engines to construct a digital twin capable of dynamically emulating their real-time behavior. We then introduce a new methodology to model the physical engine's degradation and meticulously monitor its evolution over time. By continuously analyzing the simulated data against real-world performance measurements, our approach offers valuable insights into the engine's long-term behavior and health trajectory."
Leveraging endoscopic data with Contrastive Learning for Crohn's disease detection,"Robin Ghyselinck, Jérôme Fink, Bruno Dumas, Benoît Frenay",1 - University of Namur -NaDI Rue Grangagnage 21 5000 Namur Belgium,"This study contributes to the automatic detection of Crohn's Disease (CD), a gastrointestinal inflammatory condition. In particular, our approach deals with the challenge of data scarcity for CD by pretraining Vision Transformers (ViT) on Hyper-Kvasir and LDPolyp, two large colonscopic datasets that represent over one million images from a similar domain, using a Contrastive Loss (CL) mechanism. This approach significantly outperforms models pre-trained on ImageNet as well as models pre-trained with a Cross-Entropy Loss on the Crohn-IPI dataset.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-56,2024,98.78048780487805,"Leveraging endoscopic data with Contrastive Learning for Crohn's disease detection This study contributes to the automatic detection of Crohn's Disease (CD), a gastrointestinal inflammatory condition. In particular, our approach deals with the challenge of data scarcity for CD by pretraining Vision Transformers (ViT) on Hyper-Kvasir and LDPolyp, two large colonscopic datasets that represent over one million images from a similar domain, using a Contrastive Loss (CL) mechanism. This approach significantly outperforms models pre-trained on ImageNet as well as models pre-trained with a Cross-Entropy Loss on the Crohn-IPI dataset."
About Vector Quantization and its Privacy in Federated Learning,"Ronny Schubert, Thomas Villmann",1 - Mittweida University of Applied Sciences Saxon Institute for Computational Intelligence and Machine Learning Technikumplatz 17 09648 Mittweida,"In this work, we will consider how privacy for vector quantization models can be broken in a federated learning environment. We show how a potential attacker can expose data from the prototype updates without needing to know about the specific model used by exploiting the transparency of vector quantization. Finally, a 1-user environment example based on GLVQ will be shown. * R. S. is supported by grants of the Agriculture Ministry of Germany (28DK112A20).","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-57,2024,100.0,"About Vector Quantization and its Privacy in Federated Learning In this work, we will consider how privacy for vector quantization models can be broken in a federated learning environment. We show how a potential attacker can expose data from the prototype updates without needing to know about the specific model used by exploiting the transparency of vector quantization. Finally, a 1-user environment example based on GLVQ will be shown. * R. S. is supported by grants of the Agriculture Ministry of Germany (28DK112A20)."
Antagonism between Classification and Reconstruction Processes in Deep Predictive Coding Networks,"Jan Rathjens, Laurenz Wiskott",1 - Faculty of Computer Science Universitaetsstr Ruhr University Bochum 150 -44801 Bochum Germany,"Predictive coding-inspired deep networks for visual computing integrate classification and reconstruction processes in shared intermediate layers. Although synergy between these processes is commonly assumed, it has yet to be convincingly demonstrated. In this study, we utilize a purposefully designed family of autoencoder-like architectures with an added classification head to examine the consequences of combining classificationand reconstruction-driven information within the models' latent layers. Our findings underscore a significant challenge: Classification-driven information diminishes reconstruction-driven information in shared representations and vice versa. Our results challenge prevailing assumptions in predictive coding and offer guidance for future iterations of predictive coding concepts in deep networks.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-59,2024,100.0,"Antagonism between Classification and Reconstruction Processes in Deep Predictive Coding Networks Predictive coding-inspired deep networks for visual computing integrate classification and reconstruction processes in shared intermediate layers. Although synergy between these processes is commonly assumed, it has yet to be convincingly demonstrated. In this study, we utilize a purposefully designed family of autoencoder-like architectures with an added classification head to examine the consequences of combining classificationand reconstruction-driven information within the models' latent layers. Our findings underscore a significant challenge: Classification-driven information diminishes reconstruction-driven information in shared representations and vice versa. Our results challenge prevailing assumptions in predictive coding and offer guidance for future iterations of predictive coding concepts in deep networks."
Trust in Artificial Intelligence: Beyond Interpretability,"Tassadit Bouadi, Benoît Frénay, Luis Galárraga, Pierre Geurts, Barbara Hammer, Gilles Perrouin","1 - University of Rennes I -Campus de Beaulieu -IRISA Lab 35042 Rennes
2 - Faculty of Computer Science Rue Grangagnage University of Namur -NaDI 21 5000 Namur -Belgium
3 - Inria, Rennes Bretagne Atlantique -IRISA Lab 35042 Rennes
4 - University of Liège -Montefiore Institute -Liège Belgium
5 - Bielefeld University CITEC -33594 Bielefeld Germany","As artificial intelligence (AI) systems become increasingly integrated into everyday life, the need for trustworthiness in these systems has emerged as a critical challenge. This tutorial paper addresses the complexity of building trust in AI systems by exploring recent advances in explainable AI (XAI) and related areas that go beyond mere interpretability. After reviewing recent trends in XAI, we discuss how to control AI systems, align them with societal concerns, and address the robustness, reproducibility, and evaluation concerns inherent in these systems. This review highlights the multifaceted nature of the mechanisms for building trust in AI, and we hope it will pave the way for further research in this area.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-6,2024,100.0,"Trust in Artificial Intelligence: Beyond Interpretability As artificial intelligence (AI) systems become increasingly integrated into everyday life, the need for trustworthiness in these systems has emerged as a critical challenge. This tutorial paper addresses the complexity of building trust in AI systems by exploring recent advances in explainable AI (XAI) and related areas that go beyond mere interpretability. After reviewing recent trends in XAI, we discuss how to control AI systems, align them with societal concerns, and address the robustness, reproducibility, and evaluation concerns inherent in these systems. This review highlights the multifaceted nature of the mechanisms for building trust in AI, and we hope it will pave the way for further research in this area."
Federated Time Series Classification with ROCKET features,"Bruno Casella, Matthias Jakobs, Marco Aldinucci, Sebastian Buschjäger","1 - Computer Science Department Alpha Research Group University of Turin C.so Svizzera 185 Turin Italy
2 - Lamarr Institute for Machine Learning and Artificial Intelligence TU Dortmund University Dortmund Germany","This paper proposes FROCKS, a federated time series classification method using ROCKET features. Our approach dynamically adapts the models' features by selecting and exchanging the bestperforming ROCKET kernels from a federation of clients. Specifically, the server gathers the best-performing kernels of the clients together with the associated model parameters, and it performs a weighted average if a kernel is best-performing for more than one client. We compare the proposed method with state-of-the-art approaches on the UCR archive binary classification datasets and show superior performance on most datasets.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-61,2024,100.0,"Federated Time Series Classification with ROCKET features This paper proposes FROCKS, a federated time series classification method using ROCKET features. Our approach dynamically adapts the models' features by selecting and exchanging the bestperforming ROCKET kernels from a federation of clients. Specifically, the server gathers the best-performing kernels of the clients together with the associated model parameters, and it performs a weighted average if a kernel is best-performing for more than one client. We compare the proposed method with state-of-the-art approaches on the UCR archive binary classification datasets and show superior performance on most datasets."
Reconstruction of Mammography Projections using Image-to-Image Translation Techniques,"Joana Santos, Miriam Santos, Pedro Abreu","1 - Department of Informatics Engineering University of Coimbra CISUC 3030-290 Coimbra Portugal
2 - Laboratory of Artificial Intelligence and Decision Support (LIAAD -INESC TEC) Porto Portugal
3 - Department of Computer Sciences Faculty of Sciences University of Porto (FCUP) Porto Portugal","Mammography imaging is the gold standard for breast cancer detection and involves capturing two projections: mediolateral oblique and craniocaudal projections. The implementation of an approach that allows the acquisition of only one projection and reconstructs the other could mitigate patient burden, minimize radiation exposure, and reduce costs. Image-to-image translation has showcased the ability to generate realistic synthetic images in different medical imaging modalities which make these techniques a great candidate for the novel application in mammography. This study aims to compare five image-to-image translation approaches to assess the feasibility of reconstructing a mammography projection from its counterpart. The results indicate that ResViT shows the best overall performance in translating between both projections.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-62,2024,100.0,"Reconstruction of Mammography Projections using Image-to-Image Translation Techniques Mammography imaging is the gold standard for breast cancer detection and involves capturing two projections: mediolateral oblique and craniocaudal projections. The implementation of an approach that allows the acquisition of only one projection and reconstructs the other could mitigate patient burden, minimize radiation exposure, and reduce costs. Image-to-image translation has showcased the ability to generate realistic synthetic images in different medical imaging modalities which make these techniques a great candidate for the novel application in mammography. This study aims to compare five image-to-image translation approaches to assess the feasibility of reconstructing a mammography projection from its counterpart. The results indicate that ResViT shows the best overall performance in translating between both projections."
Unpaired Image-to-Image Translation to Improve Log End Identification,"Dag Björnberg, Morgan Ericsson, Welf Löwe, Jonas Nordqvist","1 - Linnaeus University Universitetsplatsen 1 -Växjö Sweden
2 - Softwerk AB Reveljgränd 5 -Växjö Sweden","Visual re-identification tasks are often subject to large domain variations due to camera types, brightness conditions, or environmental differences. For identification models to generalize in such varying domains, a large amount of training data is necessary for capturing these variations. We explore the potential of using unpaired image-to-image translation to enhance the generalization capacity of a log end identification model in the absence or combined with a smaller amount of labeled training data. * DBs work was funded by the Industry Graduate School on ""Data Intensive Applications (DIA)"" at Linnaeus University which is partially funded by the Knowledge Foundation (project id 20190336).",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-63,2024,100.0,"Unpaired Image-to-Image Translation to Improve Log End Identification Visual re-identification tasks are often subject to large domain variations due to camera types, brightness conditions, or environmental differences. For identification models to generalize in such varying domains, a large amount of training data is necessary for capturing these variations. We explore the potential of using unpaired image-to-image translation to enhance the generalization capacity of a log end identification model in the absence or combined with a smaller amount of labeled training data. * DBs work was funded by the Industry Graduate School on ""Data Intensive Applications (DIA)"" at Linnaeus University which is partially funded by the Knowledge Foundation (project id 20190336)."
Towards Contrail Mitigation through Robust and Frugal AI-Driven Data Exploitation,"Davide Giusto, Grégoire Boussu, Simon Alix, Céline Reverdy, Mathieu Riou, Teodora Petrisor","1 - Thales, Research and Technology France 1 avenue A. Fresnel 91767 Palaiseau France","Condensation trails significantly contribute to aviation's impact on climate change. Their effective mitigation involves formulating accurate predictions of occurrence, introducing the relevant constraints in trajectory optimization and employing reliable verification strategies based on observations. Atmospheric data, expert knowledge and contrails observations can be leveraged for these purposes. However, several factors determine a limited prediction accuracy and high uncertainty bounds, including the difficulties in predicting contrails persistence, the complexity of trajectory optimization problems and the lack of labelled data for contrail verification. This paper gives an overview of our robust Artificial Intelligence methods aiming to tackle these challenges throughout the entire contrail mitigation chain.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-64,2024,100.0,"Towards Contrail Mitigation through Robust and Frugal AI-Driven Data Exploitation Condensation trails significantly contribute to aviation's impact on climate change. Their effective mitigation involves formulating accurate predictions of occurrence, introducing the relevant constraints in trajectory optimization and employing reliable verification strategies based on observations. Atmospheric data, expert knowledge and contrails observations can be leveraged for these purposes. However, several factors determine a limited prediction accuracy and high uncertainty bounds, including the difficulties in predicting contrails persistence, the complexity of trajectory optimization problems and the lack of labelled data for contrail verification. This paper gives an overview of our robust Artificial Intelligence methods aiming to tackle these challenges throughout the entire contrail mitigation chain."
A Kalman Filter and Neural Network Hybrid Approach for Health Monitoring of Aircraft Engines,"Solene Thepaut, Sebastien Razakarivony, Dong Vu, Alfred Bauny","1 - Digital Sciences & Technologies Department Rue des Jeunes Bois Safran Tech 78114 Chateaufort, Magny-Les-Hameaux France
4 - Performance/ Operability Safran Aircraft Engine 77550 Moissy-Cramayel France","In aircraft engine monitoring, estimating performance indicators from observed measurement data has been an important and longstanding subject, as these indicators provide highly beneficial information to assist maintenance activities. The two main resolution approaches in tackling this problem are Bayesian inferences and machine learning methods, each having its own limitations: inferences are not robust against model-reality gap and non-linearity, while current implementations of machine learning algorithms do not take into account temporal information. In this work, we focus on a use case in estimating engine performance indicators from snapshot data. We explore several hybrid approaches, aiming to simultaneously leverage the advantages of Bayesian inferences and machine learning methods. We demonstrate that the estimation precision provided by one of our hybrid methods significantly improves upon that of state-of-the-art methods in the tested cases.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-69,2024,100.0,"A Kalman Filter and Neural Network Hybrid Approach for Health Monitoring of Aircraft Engines In aircraft engine monitoring, estimating performance indicators from observed measurement data has been an important and longstanding subject, as these indicators provide highly beneficial information to assist maintenance activities. The two main resolution approaches in tackling this problem are Bayesian inferences and machine learning methods, each having its own limitations: inferences are not robust against model-reality gap and non-linearity, while current implementations of machine learning algorithms do not take into account temporal information. In this work, we focus on a use case in estimating engine performance indicators from snapshot data. We explore several hybrid approaches, aiming to simultaneously leverage the advantages of Bayesian inferences and machine learning methods. We demonstrate that the estimation precision provided by one of our hybrid methods significantly improves upon that of state-of-the-art methods in the tested cases."
Aeronautic data analysis,"Jérôme Lacaille, Patrick Fabiani, Patricia Besson","1 - Safran Aircraft Engines -DataLab Moissy-Cramayel France
2 - Dassault Aviation -Études Scientifiques Saint-Cloud France
3 - Thales -Research & Technology Palaiseau France","The latest IPCC 1 report shows that the aviation industry is responsible for around 2% of greenhouse gas emissions; this is lower than emissions from many other sectors, but still equivalent to the total emissions of a European country like Germany. Following the recommendations of the International Civil Aviation Organization (ICAO 2 ) and its long-term global aspirational goal (LTAG), the aeronautics industry has come together under the Air Transport Aviation Group (ATAG 3 ) to converge towards zero greenhouse gas emissions by 2050, such as CO2 emissions and other radiative effects such as those generated by condensation trails. To achieve this goal, we have a number of levers at our disposal: technical improvements to our engines and aircrafts, the use of new sustainable fuels, and the use of data now accessible thanks to new engineering 4.0 technologies. This document first presents the data we now have at our disposal. The second section briefly recalls the opportunities offered by new renewable fuels. Finally, we present some digital approaches and conclude with details of three central themes illustrated by the contributions to this special session.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-7,2024,100.0,"Aeronautic data analysis The latest IPCC 1 report shows that the aviation industry is responsible for around 2% of greenhouse gas emissions; this is lower than emissions from many other sectors, but still equivalent to the total emissions of a European country like Germany. Following the recommendations of the International Civil Aviation Organization (ICAO 2 ) and its long-term global aspirational goal (LTAG), the aeronautics industry has come together under the Air Transport Aviation Group (ATAG 3 ) to converge towards zero greenhouse gas emissions by 2050, such as CO2 emissions and other radiative effects such as those generated by condensation trails. To achieve this goal, we have a number of levers at our disposal: technical improvements to our engines and aircrafts, the use of new sustainable fuels, and the use of data now accessible thanks to new engineering 4.0 technologies. This document first presents the data we now have at our disposal. The second section briefly recalls the opportunities offered by new renewable fuels. Finally, we present some digital approaches and conclude with details of three central themes illustrated by the contributions to this special session."
ProtoNCD: Prototypical Parts for Interpretable Novel Class Discovery,"Tomasz Michalski, Dawid Rymarczyk, Daniel Barczyk, Bartosz Zieliński","1 - Doctoral School of Exact and Natural Sciences Jagiellonian University Poland
2 - Faculty of Mathematics and Computer Science Jagiellonian University Poland
6 - -IDEAS NCBR Poland","In this work, we introduce ProtoNCD, a novel approach to novel class discovery (NCD) that leverages prototypical parts for enhanced interpretability. ProtoNCD extends the ProtoPool methodology to the NCD setting, employing techniques such as knowledge distillation and specialized prototypical parts initialization. Through comprehensive experiments on the CUB-200-2011 dataset, we demonstrate the efficacy of ProtoNCD and its pivotal role in explaining how the reasoning of known classes influences predictions for those newly discovered.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-70,2024,100.0,"ProtoNCD: Prototypical Parts for Interpretable Novel Class Discovery In this work, we introduce ProtoNCD, a novel approach to novel class discovery (NCD) that leverages prototypical parts for enhanced interpretability. ProtoNCD extends the ProtoPool methodology to the NCD setting, employing techniques such as knowledge distillation and specialized prototypical parts initialization. Through comprehensive experiments on the CUB-200-2011 dataset, we demonstrate the efficacy of ProtoNCD and its pivotal role in explaining how the reasoning of known classes influences predictions for those newly discovered."
Safety-Oriented Pruning and Interpretation of Reinforcement Learning Policies *,"Dennis Groß, Helge Spieker",1 - Simula Research Laboratory Oslo Norway,"Pruning neural networks (NNs) can streamline them but risks removing vital parameters from safe reinforcement learning (RL) policies. We introduce an interpretable RL method called VERINTER, which combines NN pruning with model checking to ensure interpretable RL safety. VERINTER exactly quantifies the effects of pruning and the impact of neural connections on complex safety properties by analyzing changes in safety measurements. This method maintains safety in pruned RL policies and enhances understanding of their safety dynamics, which has proven effective in multiple RL settings.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-71,2024,98.71794871794873,"Safety-Oriented Pruning and Interpretation of Reinforcement Learning Policies * Pruning neural networks (NNs) can streamline them but risks removing vital parameters from safe reinforcement learning (RL) policies. We introduce an interpretable RL method called VERINTER, which combines NN pruning with model checking to ensure interpretable RL safety. VERINTER exactly quantifies the effects of pruning and the impact of neural connections on complex safety properties by analyzing changes in safety measurements. This method maintains safety in pruned RL policies and enhances understanding of their safety dynamics, which has proven effective in multiple RL settings."
Positive and Scale Invariant Gaussian Process Latent Variable Model for Astronomical Spectra,"Nikolaos Gianniotis, Iliana Cortés Pérez, Kai Polsterer",1 - Astroinformatics -HITS gGmbH Schloss Wolfsbrunnenweg 35 D-69118 Heidelberg Germany,"We propose a probabilistic model that reduces the dimensionality of positive-valued data in a scale-invariant way, treating data items that differ only in scaling as identical. Extending the Gaussian Process Latent Variable Model, we ensure positive function values by applying a non-linear transformation to latent function values. To address the intractable marginal log-likelihood, we utilize a variational lower bound and amortized inference to reduce the number of variational parameters. We apply our model to reconstructing partially observed spectra and show how its scale-invariant property leads to better reconstructions.",Nonlinear dimensionality reduction and unsupervised learning,https://doi.org/10.14428/esann/2024.ES2024-72,2024,100.0,"Positive and Scale Invariant Gaussian Process Latent Variable Model for Astronomical Spectra We propose a probabilistic model that reduces the dimensionality of positive-valued data in a scale-invariant way, treating data items that differ only in scaling as identical. Extending the Gaussian Process Latent Variable Model, we ensure positive function values by applying a non-linear transformation to latent function values. To address the intractable marginal log-likelihood, we utilize a variational lower bound and amortized inference to reduce the number of variational parameters. We apply our model to reconstructing partially observed spectra and show how its scale-invariant property leads to better reconstructions."
From Three to Two Dimensions: 2D Quaternion Convolutions for 3D Images,"Valentin Delchevalerie, Benoît Frénay, Alexandre Mayer","1 - Faculty of Computer Science University of Namur -NaDI/naXys institutes Rue Grandgagnage 21 5000 Namur Belgium
3 - Department of Physics Rue de Bruxelles 61 University of Namur -naXys institute 5000 Namur Belgium","In fields like biomedical imaging, it is common to manage 3D images instead of 2D ones (CT-scans, MRI, 3D-ultrasound, etc.). Although 3D-Convolutional Neural Networks (CNNs) are generally more powerful compared to their 2D counterparts for such applications, it also comes at the cost of an increase in computational resources (both in time and memory). In this work, we present a new way to build 2D representations of 3D images while minimizing the information loss by leveraging quaternions. Those quaternion CNNs are able to offer competitive performance while significantly reducing computational complexity.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-73,2024,100.0,"From Three to Two Dimensions: 2D Quaternion Convolutions for 3D Images In fields like biomedical imaging, it is common to manage 3D images instead of 2D ones (CT-scans, MRI, 3D-ultrasound, etc.). Although 3D-Convolutional Neural Networks (CNNs) are generally more powerful compared to their 2D counterparts for such applications, it also comes at the cost of an increase in computational resources (both in time and memory). In this work, we present a new way to build 2D representations of 3D images while minimizing the information loss by leveraging quaternions. Those quaternion CNNs are able to offer competitive performance while significantly reducing computational complexity."
Human Activity Recognition from Thigh and Wrist Accelerometry,"Alejandro Castellanos, Antonio López, Diego García, Diego Álvarez, Juan Álvarez","1 - Electrical Engineering Department Departamental Oeste) Multisensor Systems and Robotics Lab (SiMuR) University of Oviedo. C/Pedro Puig Adam bloque 2, 2.1.09 33204, Campus de Gijón Ed. Torres Quevedo Spain","The IMPaCT Cohort (ISCIII, Spain) is expected to collect biomechanical parameters from a wide population (~200,000) over seven consecutive days, using a triaxial accelerometer and a gyroscope positioned on both the wrist and thigh of participants. This will be one of the distinctive features of the Cohort, based on the hypothesis that simultaneous placement of two devices on the wrist and thigh will enable accurate classification of subjects' activity. In this study, we aim to explore this crucial aspect using Deep CNNs and data from publicly available datasets. Our experimental findings demonstrate an 85% accuracy achieved when utilizing data from both the thigh and wrist. The results support the hypothesis that incorporating accelerometry data from both limbs enhances classification, yielding over a 15% increase in accuracy compared to using data from a single limb alone.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-75,2024,100.0,"Human Activity Recognition from Thigh and Wrist Accelerometry The IMPaCT Cohort (ISCIII, Spain) is expected to collect biomechanical parameters from a wide population (~200,000) over seven consecutive days, using a triaxial accelerometer and a gyroscope positioned on both the wrist and thigh of participants. This will be one of the distinctive features of the Cohort, based on the hypothesis that simultaneous placement of two devices on the wrist and thigh will enable accurate classification of subjects' activity. In this study, we aim to explore this crucial aspect using Deep CNNs and data from publicly available datasets. Our experimental findings demonstrate an 85% accuracy achieved when utilizing data from both the thigh and wrist. The results support the hypothesis that incorporating accelerometry data from both limbs enhances classification, yielding over a 15% increase in accuracy compared to using data from a single limb alone."
Constraints as Alternative Learning Objective in Deep Learning,"Quinten Van Baelen, Peter Karsmakers","1 - Flanders Make@KU Leuven Belgium
3 - Dept. of Computer Science Leuven.AI 1 -KU, B-2440 Leuven, Geel Campus, Geel Belgium","The success of deep learning has been based on smooth loss functions that can easily be optimized using gradient descent and an off-the-shelf optimizer. However, training a neural network for a new application is not trivial as it requires many hyperparameters to be tuned. Several issues exist such as overfitting and underfitting. Many applications allow for some errors to be made, although, traditional learning objectives will influence the training in all cases except the one perfect prediction is made. In this work, constraints are proposed to replace the cross-entropy or the mean squared error to allow the neural network to make some errors. These errors can be set in advance to reflect how accurate the predictions of the neural network need to be. For each loss function, it is shown on two different data sets that the proposed constraint based learning performs similarly or even outperforms the standard loss functions. Moreover, in the case of classification problems, the constraints can result in predictions with significantly higher probability on a test set.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-76,2024,100.0,"Constraints as Alternative Learning Objective in Deep Learning The success of deep learning has been based on smooth loss functions that can easily be optimized using gradient descent and an off-the-shelf optimizer. However, training a neural network for a new application is not trivial as it requires many hyperparameters to be tuned. Several issues exist such as overfitting and underfitting. Many applications allow for some errors to be made, although, traditional learning objectives will influence the training in all cases except the one perfect prediction is made. In this work, constraints are proposed to replace the cross-entropy or the mean squared error to allow the neural network to make some errors. These errors can be set in advance to reflect how accurate the predictions of the neural network need to be. For each loss function, it is shown on two different data sets that the proposed constraint based learning performs similarly or even outperforms the standard loss functions. Moreover, in the case of classification problems, the constraints can result in predictions with significantly higher probability on a test set."
CNNGen: A Generator and a Dataset for Energy-Aware Neural Architecture Search,"Antoine Gratia, Hong Liu, Shin Ichi Satoh, Paul Temple, Pierre-Yves Schobbens, Gilles Perrouin","1 - Digital Content and Media Sciences Research Division National Institute of Informatics Tokyo Japan
3 - University of Rennes IRISA Rennes Inria France
4 - Faculty of Computer Science University of Namur 1-NaDI Belgium","Neural Architecture Search (NAS) methods seek optimal networks by exploring thousands of variants of a reference architecture. Yet, optimality is typically related to prediction performance, overlooking the environmental impacts of training. Thus, NAS search spaces are unfit for performance and energy consumption trade-offs. We contribute to energy-aware NAS with (i) a grammar-based Convolutional Neural Network generator (CN-NGen) producing diverse architectures not based on a reference one; (ii) 1,300 available architectures obtained via CNNGen with their implementation, energy consumption and performance measurements; (iii) Three state-of-the-art predictors releasing the need for trained models for performance and energy estimation. 
 CNN Generator (CNNGen) CNNGen uses the Xtext context-free grammar framework  [3]  to generate CNN architectures. The sequence of grammar tokens describes the CNN's topology (i.e., the succession of layers). Our grammar captures the CNN domain knowledge to produce valid architectures. Thus, CNNGen differs from other NAS methods like NASBench [2] Indeed, CNNGen produces architectures from scratch and not as variants of existing ones. CNNGen also comes with an editor allowing to specify architectures. From a valid sequence of grammar tokens, 173",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-77,2024,100.0,"CNNGen: A Generator and a Dataset for Energy-Aware Neural Architecture Search Neural Architecture Search (NAS) methods seek optimal networks by exploring thousands of variants of a reference architecture. Yet, optimality is typically related to prediction performance, overlooking the environmental impacts of training. Thus, NAS search spaces are unfit for performance and energy consumption trade-offs. We contribute to energy-aware NAS with (i) a grammar-based Convolutional Neural Network generator (CN-NGen) producing diverse architectures not based on a reference one; (ii) 1,300 available architectures obtained via CNNGen with their implementation, energy consumption and performance measurements; (iii) Three state-of-the-art predictors releasing the need for trained models for performance and energy estimation. 
 CNN Generator (CNNGen) CNNGen uses the Xtext context-free grammar framework  [3]  to generate CNN architectures. The sequence of grammar tokens describes the CNN's topology (i.e., the succession of layers). Our grammar captures the CNN domain knowledge to produce valid architectures. Thus, CNNGen differs from other NAS methods like NASBench [2] Indeed, CNNGen produces architectures from scratch and not as variants of existing ones. CNNGen also comes with an editor allowing to specify architectures. From a valid sequence of grammar tokens, 173"
Enhancing Echo State Networks with Gradient-based Explainability Methods,"Francesco Spinnato, Andrea Cossu, Riccardo Guidotti, Andrea Ceni, Claudio Gallicchio, Davide Bacciu","1 - University of Pisa Italy
2 - ISTI-CNR Pisa Italy","Recurrent Neural Networks are effective for analyzing temporal data, such as time series, but they often require costly and time-intensive training. Echo State Networks simplify the training process by using a fixed recurrent layer, the reservoir, and a trainable output layer, the readout. In sequence classification problems, the readout typically receives only the final state of the reservoir. However, averaging all states can sometimes be beneficial. In this work, we assess whether a weighted average of hidden states can enhance the Echo State Network performance. To this end, we propose a gradient-based, explainable technique to guide the contribution of each hidden state towards the final prediction. We show that our approach outperforms the naive average, as well as other baselines, in time series classification, particularly on noisy data.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-78,2024,100.0,"Enhancing Echo State Networks with Gradient-based Explainability Methods Recurrent Neural Networks are effective for analyzing temporal data, such as time series, but they often require costly and time-intensive training. Echo State Networks simplify the training process by using a fixed recurrent layer, the reservoir, and a trainable output layer, the readout. In sequence classification problems, the readout typically receives only the final state of the reservoir. However, averaging all states can sometimes be beneficial. In this work, we assess whether a weighted average of hidden states can enhance the Echo State Network performance. To this end, we propose a gradient-based, explainable technique to guide the contribution of each hidden state towards the final prediction. We show that our approach outperforms the naive average, as well as other baselines, in time series classification, particularly on noisy data."
ChatDT: Simplifying Constraint Integration in Decision Trees,"Abiola Chokki, Benoît Frénay",1 - Faculty of Computer Science PReCISE Rue Grandgagnage 21 University of Namur -NaDI B-5000 Namur Belgium,"Decision trees help domain experts, such as doctors and bankers, rationalize system decisions. However, existing methods lack user-friendly ways to integrate multiple constraints and identify branches for pruning. This paper introduces ChatDT, a prototype developed with a new domain-specific language and an enhanced version of the CART algorithm to address these challenges. An evaluation involving 22 participants highlights ChatDT's effectiveness, confirming its role in facilitating decision tree creation tailored to domain-specific constraints and identifying branches for pruning.",Language models,https://doi.org/10.14428/esann/2024.ES2024-8,2024,100.0,"ChatDT: Simplifying Constraint Integration in Decision Trees Decision trees help domain experts, such as doctors and bankers, rationalize system decisions. However, existing methods lack user-friendly ways to integrate multiple constraints and identify branches for pruning. This paper introduces ChatDT, a prototype developed with a new domain-specific language and an enhanced version of the CART algorithm to address these challenges. An evaluation involving 22 participants highlights ChatDT's effectiveness, confirming its role in facilitating decision tree creation tailored to domain-specific constraints and identifying branches for pruning."
Why long model-based rollouts are no reason for bad Q-value estimates,"Philipp Wissmann, Daniel Hein, Steffen Udluft, Volker Tresp","1 - Ludwig-Maximilians-Universität München (LMU) Munich Germany
2 - Siemens AG, Technology Munich Germany","This paper explores the use of model-based offline reinforcement learning with long model rollouts. While some literature criticizes this approach due to compounding errors, many practitioners have found success in real-world applications. The paper aims to demonstrate that long rollouts do not necessarily result in exponentially growing errors and can actually produce better Q-value estimates than model-free methods. These findings can potentially enhance reinforcement learning techniques. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 16ME0735K. The sole responsibility for the report's contents lies with the authors.","Time series, recurrent and reinforcement learning",https://doi.org/10.14428/esann/2024.ES2024-80,2024,100.0,"Why long model-based rollouts are no reason for bad Q-value estimates This paper explores the use of model-based offline reinforcement learning with long model rollouts. While some literature criticizes this approach due to compounding errors, many practitioners have found success in real-world applications. The paper aims to demonstrate that long rollouts do not necessarily result in exponentially growing errors and can actually produce better Q-value estimates than model-free methods. These findings can potentially enhance reinforcement learning techniques. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 16ME0735K. The sole responsibility for the report's contents lies with the authors."
Adversarial Training without Hard Labels,"Ammar Al-Najjar, István Megyeri, Márk Jelasity","1 - University of Szeged Hungary
4 - -HUN-REN-SZTE Research Group on Artificial Intelligence Hungary","Adversarial training is widely used to enhance classifier robustness. Several improvements have been proposed including different forms of distillation and self-alignment. Here, we propose a novel loss function combining these two approaches, while not using the hard ground truth labels directly. Our new loss function is demonstrated to simultaneously improve both the robustness and the accuracy of some well-known competing solutions. This is a step towards combatting the robustnessaccuracy tradeoff, a crucial issue in adversarial training. Our method also reduces the variance of the accuracy over the classes in the experimental scenarios we examined, leading to a more balanced model.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-81,2024,100.0,"Adversarial Training without Hard Labels Adversarial training is widely used to enhance classifier robustness. Several improvements have been proposed including different forms of distillation and self-alignment. Here, we propose a novel loss function combining these two approaches, while not using the hard ground truth labels directly. Our new loss function is demonstrated to simultaneously improve both the robustness and the accuracy of some well-known competing solutions. This is a step towards combatting the robustnessaccuracy tradeoff, a crucial issue in adversarial training. Our method also reduces the variance of the accuracy over the classes in the experimental scenarios we examined, leading to a more balanced model."
XAI and Bias of Deep Graph Networks,"Michele Fontanesi, Alessio Micheli, Marco Podda",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy,"Generalization in machine learning involves introducing inductive biases that restrict the solution space of the learning problem, allowing for the inductive leap. In this paper, we show the existence of different inductive biases between convolutional and recursive Deep Graph Networks (DGN) by applying Explainable AI (XAI) methods as model inspection techniques. We show that different architectures can perfectly solve the given tasks by learning different labelling policies. Our results promote the usage of different architectures to address a task and raise warnings on the assessment of XAI techniques as their benchmarks may contain more ground truths than those provided.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-85,2024,100.0,"XAI and Bias of Deep Graph Networks Generalization in machine learning involves introducing inductive biases that restrict the solution space of the learning problem, allowing for the inductive leap. In this paper, we show the existence of different inductive biases between convolutional and recursive Deep Graph Networks (DGN) by applying Explainable AI (XAI) methods as model inspection techniques. We show that different architectures can perfectly solve the given tasks by learning different labelling policies. Our results promote the usage of different architectures to address a task and raise warnings on the assessment of XAI techniques as their benchmarks may contain more ground truths than those provided."
Evaluation methodology for disentangled uncertainty quantification on regression models,"Kevin Pasini, Clement Arlotti, Milad Leyli-Abadi, Marc Nabhan, Johanna Baro","1 - -IRT SystemX Paris France
4 - -Air Liquide Les-Loges-en-Josas France","A practical way to enhance the confidence of the predictions made by Machine Learning (ML) models is to enrich them with trustworthiness addons such as Uncertainty Quantification (UQ). Existing UQ paradigms capture two intertwined components (epistemic and aleatoric), but few of them evaluate their disentanglement, even less on real data. We thus propose and implement a methodology to assess the effectiveness of uncertainty disentanglement despite the absence of ground truth in real datasets. To do so, we use a data withdrawal-based strategy to simulate Out-of-Distribution (OOD) data and evaluate four state-of-the-art UQ approaches.",Trust in Artificial Intelligence: Beyond Interpretability,https://doi.org/10.14428/esann/2024.ES2024-87,2024,100.0,"Evaluation methodology for disentangled uncertainty quantification on regression models A practical way to enhance the confidence of the predictions made by Machine Learning (ML) models is to enrich them with trustworthiness addons such as Uncertainty Quantification (UQ). Existing UQ paradigms capture two intertwined components (epistemic and aleatoric), but few of them evaluate their disentanglement, even less on real data. We thus propose and implement a methodology to assess the effectiveness of uncertainty disentanglement despite the absence of ground truth in real datasets. To do so, we use a data withdrawal-based strategy to simulate Out-of-Distribution (OOD) data and evaluate four state-of-the-art UQ approaches."
On the Fine Structure of Drifting Features,"Fabian Hinder, Valerie Vaquet, Barbara Hammer",1 - Bielefeld University -Inspiration 1 33619 Bielefeld Germany,"Feature selection is one of the most relevant preprocessing and analysis techniques in machine learning, allowing for increases in model performance and knowledge discovery. In online setups, both can be affected by concept drift, i.e., changes of the underlying distribution. Recently, an adaption of classical feature relevance approaches to drift detection was introduced. While the method increases detection performance significantly, there is only little discussion on the explanatory aspects. In this work, we focus on understanding the structure of the ongoing drift by transferring the concept of strongly and weakly relevant features to it. We empirically evaluate our methodology using graphical models.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-89,2024,100.0,"On the Fine Structure of Drifting Features Feature selection is one of the most relevant preprocessing and analysis techniques in machine learning, allowing for increases in model performance and knowledge discovery. In online setups, both can be affected by concept drift, i.e., changes of the underlying distribution. Recently, an adaption of classical feature relevance approaches to drift detection was introduced. While the method increases detection performance significantly, there is only little discussion on the explanatory aspects. In this work, we focus on understanding the structure of the ongoing drift by transferring the concept of strongly and weakly relevant features to it. We empirically evaluate our methodology using graphical models."
Sparse Uncertainty-Informed Sampling from Federated Streaming Data,"Manuel Röder, Frank-Michael Schleif","1 - Fac. of Computer Science Technical UAS Würzburg-Schweinfurt Würzburg DE
2 - Faculty of Technology Bielefeld University Bielefeld DE
3 - Center for Artificial Intelligence and Robotics Würzburg DE","We present a numerically robust, computationally efficient approach for non-I.I.D. data stream sampling in federated client systems, where resources are limited and labeled data for local model adaptation is sparse and expensive. The proposed method identifies relevant stream observations to optimize the underlying client model, given a local labeling budget, and performs instantaneous labeling decisions without relying on any memory buffering strategies. Our experiments show enhanced training batch diversity and an improved numerical robustness of the proposal compared to existing strategies over large-scale data streams, making our approach an effective and convenient solution in FL environments. * MR is supported through the Bavarian HighTech Agenda, specifically by the Würzburg Center for Artificial Intelligence and Robotics (CAIRO) and the ProPere THWS scholarship.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-9,2024,100.0,"Sparse Uncertainty-Informed Sampling from Federated Streaming Data We present a numerically robust, computationally efficient approach for non-I.I.D. data stream sampling in federated client systems, where resources are limited and labeled data for local model adaptation is sparse and expensive. The proposed method identifies relevant stream observations to optimize the underlying client model, given a local labeling budget, and performs instantaneous labeling decisions without relying on any memory buffering strategies. Our experiments show enhanced training batch diversity and an improved numerical robustness of the proposal compared to existing strategies over large-scale data streams, making our approach an effective and convenient solution in FL environments. * MR is supported through the Bavarian HighTech Agenda, specifically by the Würzburg Center for Artificial Intelligence and Robotics (CAIRO) and the ProPere THWS scholarship."
Learning Kernel Parameters for Support Vector Classification Using Similarity Embeddings,"Murilo Menezes, Luiz Torres, Antonio Braga","1 - Department of Electronics Engineering Federal University of Minas Gerais Av. Antônio Carlos 6627, 30161-970 Pampulha, Belo Horizonte MG Brazil
2 - Department of Computing and Systems Federal University of Ouro 35931-008 Preto
3 - João Monlevade MG Brazil","In order to solve non-linear problems, kernel-based classifiers rely on implicit mappings to very high-dimensional spaces. These target spaces, although mathematically robust, often lack the property of visual interpretation, limiting the intuition of the problem at hand. In this work, the notion of a similarity space is presented, to which one can map input samples and visualize how they interact under a given kernel function. By exploring statistics in such space, a class separability measure is derived, which can be used to find optimal kernel parameters for binary classification. Experiments using support vector machines were conducted, showing the method's effectiveness when compared to grid-search approaches.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-90,2024,100.0,"Learning Kernel Parameters for Support Vector Classification Using Similarity Embeddings In order to solve non-linear problems, kernel-based classifiers rely on implicit mappings to very high-dimensional spaces. These target spaces, although mathematically robust, often lack the property of visual interpretation, limiting the intuition of the problem at hand. In this work, the notion of a similarity space is presented, to which one can map input samples and visualize how they interact under a given kernel function. By exploring statistics in such space, a class separability measure is derived, which can be used to find optimal kernel parameters for binary classification. Experiments using support vector machines were conducted, showing the method's effectiveness when compared to grid-search approaches."
Geometric Deep Learning to Enhance Imbalanced Domain Adaptation in EEG,"Shanglin Li, Motoaki Kawanabe, Reinmar Kobler","1 - -Advanced Telecommunications Research Institute International Kyoto Japan
2 - Nara Institute of Science and Technology Nara Japan
4 - RIKEN Artificial Intelligence Project Tokyo Japan","Electroencephalography (EEG) based brain-computer interfaces (BCIs) face great challenges in generalizing across different domains (i.e., sessions and subjects) without costly supervised calibration. To avoid supervised calibration, transfer learning, particularly unsupervised domain adaptation, has been a popular approach. In this work, we focus on a geometric deep learning framework previously proposed for EEG-based mental imagery BCIs. The framework aligns marginal feature distributions in latent space, assuming identical label distributions across domains. Here, we propose a novel approach integrating data augmentation and clustering techniques to align the latent distributions under label shifts.",Modern Machine Learning Methods for robust and real-time Brain-Computer Interfaces (BCI),https://doi.org/10.14428/esann/2024.ES2024-91,2024,100.0,"Geometric Deep Learning to Enhance Imbalanced Domain Adaptation in EEG Electroencephalography (EEG) based brain-computer interfaces (BCIs) face great challenges in generalizing across different domains (i.e., sessions and subjects) without costly supervised calibration. To avoid supervised calibration, transfer learning, particularly unsupervised domain adaptation, has been a popular approach. In this work, we focus on a geometric deep learning framework previously proposed for EEG-based mental imagery BCIs. The framework aligns marginal feature distributions in latent space, assuming identical label distributions across domains. Here, we propose a novel approach integrating data augmentation and clustering techniques to align the latent distributions under label shifts."
Leveraging performance-based metadata for designing multi-objective NAS strategies for efficient models in Earth Observation,"Emre Demir, Kalifou Traoré, Andrés Camero","1 - School of Computation, Information and Technology Technical University of Munich
2 - German Aerospace Center (DLR) Remote Sensing Technology Institute (IMF)
3 - Data Science in Earth Observation Technical University of Munich","Earth Observational (EO) datasets present challenges that differ from traditional Computer Vision benchmarks often examined by the AutoML community. To assist EO researchers in leveraging AutoML techniques, we offer a NAS benchmark with performance meta-data specifically for an EO context. This dataset not only focuses on resource-efficient models crucial to EO but also includes hardware-based metrics. Moreover, we investigate performance prediction to build a data-centric approach for initializing multi-objective NAS search algorithms.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-94,2024,100.0,"Leveraging performance-based metadata for designing multi-objective NAS strategies for efficient models in Earth Observation Earth Observational (EO) datasets present challenges that differ from traditional Computer Vision benchmarks often examined by the AutoML community. To assist EO researchers in leveraging AutoML techniques, we offer a NAS benchmark with performance meta-data specifically for an EO context. This dataset not only focuses on resource-efficient models crucial to EO but also includes hardware-based metrics. Moreover, we investigate performance prediction to build a data-centric approach for initializing multi-objective NAS search algorithms."
Lightweight Cross-Modal Representation Learning,"Bilal Faye, Hanane Azzag, Mustapha Lebbah, Djamel Bouchaffra","1 - LIPN UMR CNRS 7030 Sorbonne Paris Nord University Villetaneuse France
3 - -DAVID Lab University of Versailles University Paris-Saclay Versailles France
4 - Center for Development of Advanced Technologies Algiers Algeria","Low-cost cross-modal representation learning is crucial for deriving semantic representations across diverse modalities such as text, audio, images, and video. Traditional approaches typically depend on large specialized models trained from scratch, requiring extensive datasets and resulting in high resource and time costs. To overcome these challenges, we introduce a novel approach named Lightweight Cross-Modal Representation Learning (LightCRL). This method uses a single neural network titled Deep Fusion Encoder (DFE), which projects data from multiple modalities into a shared latent representation space. This reduces the overall parameter count while still delivering robust performance comparable to more complex systems. The code is available via https://github.com/bfaye/lightweightCRL/ 233",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-96,2024,100.0,"Lightweight Cross-Modal Representation Learning Low-cost cross-modal representation learning is crucial for deriving semantic representations across diverse modalities such as text, audio, images, and video. Traditional approaches typically depend on large specialized models trained from scratch, requiring extensive datasets and resulting in high resource and time costs. To overcome these challenges, we introduce a novel approach named Lightweight Cross-Modal Representation Learning (LightCRL). This method uses a single neural network titled Deep Fusion Encoder (DFE), which projects data from multiple modalities into a shared latent representation space. This reduces the overall parameter count while still delivering robust performance comparable to more complex systems. The code is available via https://github.com/bfaye/lightweightCRL/ 233"
The Reinforced Liquid State Machine: A New Training Architecture for Spiking Neural Networks,"Dominik Krenzer, Martin Bogdan",1 - Leipzig University -Neuromorphic Information Processing Augustusplatz 10 Leipzig Germany,"This work presents a novel Spiking Neural Network training architecture based on a deepened Liquid State Machine integrating Winner-Takes-All computation and Reward-Modulated Synaptic Plasticity. The networks performance is evaluated on the Heidelberg Dataset for spoken digit recognition. A two-layer liquid configuration improves classification accuracy by 5% over a single-layer baseline, while incorporating feedback between liquid layers. This architecture demonstrates that deep liquid models, combined with feedback and reward-driven learning, can effectively capture complex spatio-temporal patterns, offering significant advantages in terms of accuracy over traditional Liquid State Machines.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-161.pdf,2025,60.439560439560445,"The Reinforced Liquid State Machine: A New Training Architecture for Spiking Neural Networks This work presents a novel Spiking Neural Network training architecture based on a deepened Liquid State Machine integrating Winner-Takes-All computation and Reward-Modulated Synaptic Plasticity. The networks performance is evaluated on the Heidelberg Dataset for spoken digit recognition. A two-layer liquid configuration improves classification accuracy by 5% over a single-layer baseline, while incorporating feedback between liquid layers. This architecture demonstrates that deep liquid models, combined with feedback and reward-driven learning, can effectively capture complex spatio-temporal patterns, offering significant advantages in terms of accuracy over traditional Liquid State Machines."
Reconciling Grokking with Statistical Learning Theory,"Luca Oneto, Sandro Ridella, Andrea Coraddu, Davide Anguita","1 - University of Genoa Genova Italy
3 - Delft University of Technology Delft Netherlands","In recent years, Artificial Intelligence, particularly Machine Learning (ML), has demonstrated remarkable success in addressing complex problems. However, this progress has been accompanied by the emergence of unexpected, poorly understood, and elusive phenomena that characterize the behavior of machine intelligence and learning processes. Researchers are often challenged to interpret these phenomena within the existing theoretical frameworks of ML, fostering a search for more complex or technical explanations. One such phenomenon, known as ""grokking"", occurs when an ML model, after a long period of stagnant or even regressive learning, suddenly exhibits rapid and substantial improvement. In this paper, we argue that grokking can be explained with the theoretical foundations of ML by leveraging Statistical Learning Theory, i.e., Algorithmic Stability theory. We provide insights into how this theory can reconcile grokking with established principles of learning and generalization.",Kernel methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-111.pdf,2025,55.670103092783506,"Reconciling Grokking with Statistical Learning Theory In recent years, Artificial Intelligence, particularly Machine Learning (ML), has demonstrated remarkable success in addressing complex problems. However, this progress has been accompanied by the emergence of unexpected, poorly understood, and elusive phenomena that characterize the behavior of machine intelligence and learning processes. Researchers are often challenged to interpret these phenomena within the existing theoretical frameworks of ML, fostering a search for more complex or technical explanations. One such phenomenon, known as ""grokking"", occurs when an ML model, after a long period of stagnant or even regressive learning, suddenly exhibits rapid and substantial improvement. In this paper, we argue that grokking can be explained with the theoretical foundations of ML by leveraging Statistical Learning Theory, i.e., Algorithmic Stability theory. We provide insights into how this theory can reconcile grokking with established principles of learning and generalization."
Continual Unlearning through Memory Suppression,"Alexander Krawczyk, Alexander Gepperth",1 - University of Applied Sciences Fulda -Applied Computer Science Leipziger Str 123 Fulda Germany,"This study uncovers surprisingly effective synergies between the field of continual learning (CL) and machine unlearning (MUL). We extend the common class-incremental setting from CL to incorporate suppression requests in what we term class-incremental unlearning (CIUL). We present a light-weight approach to CIUL using replay/rehearsal-based CL approaches together with a selective replay strategy termed ""Replay-To-Suppress"" (RTS), where we actually make use of the catastrophic forgetting effect to achieve unlearning. In particular, we adapt a CL strategy termed adiabatic replay (AR) to achieve suppression at near-constant time complexity. We demonstrate excellent overall performance for all CL strategies extended by RTS on MNIST, F-MNIST and a latent encoded version of the challenging CIFAR and SVHN benchmarks.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-83,2025,53.333333333333336,"Continual Unlearning through Memory Suppression This study uncovers surprisingly effective synergies between the field of continual learning (CL) and machine unlearning (MUL). We extend the common class-incremental setting from CL to incorporate suppression requests in what we term class-incremental unlearning (CIUL). We present a light-weight approach to CIUL using replay/rehearsal-based CL approaches together with a selective replay strategy termed ""Replay-To-Suppress"" (RTS), where we actually make use of the catastrophic forgetting effect to achieve unlearning. In particular, we adapt a CL strategy termed adiabatic replay (AR) to achieve suppression at near-constant time complexity. We demonstrate excellent overall performance for all CL strategies extended by RTS on MNIST, F-MNIST and a latent encoded version of the challenging CIFAR and SVHN benchmarks."
Exoplanet detection in angular and spectral differential imaging with an accelerated proximal gradient algorithm,"Nicolas Mil-Homens, Cavaco, Laurent Jacques, P.-A Absil","1 - Research Fellow of the Fonds de la Recherche Scientifique -FNRS
2 - UCLouvain -ICTEAM institute B-1348 Louvain-la-Neuve Belgium","Differential imaging is a technique to post-process images captured by ground-based telescopes during an observation campaign, in order to make exoplanets in a distant planetary system directly visible and to remove the so-called quasi-static speckles that dramatically affect detection capabilities. In order to introduce geometric diversity between the exoplanets and the quasi-static speckles, the light is split into spectral channels during the data acquisition process, producing a 4-D data cube with images recorded at many wavelengths and at many times. In this work, we propose to follow an inverse problem approach to model the astronomical data as the contribution of a low-rank component containing the background of quasi-static speckles and a sparse component containing the exoplanets. We then formulate the resulting model as a convex non-smooth optimization model so that an accelerated proximal gradient descent can be used to solve the detection problem.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-80.pdf,2025,53.93258426966292,"Exoplanet detection in angular and spectral differential imaging with an accelerated proximal gradient algorithm Differential imaging is a technique to post-process images captured by ground-based telescopes during an observation campaign, in order to make exoplanets in a distant planetary system directly visible and to remove the so-called quasi-static speckles that dramatically affect detection capabilities. In order to introduce geometric diversity between the exoplanets and the quasi-static speckles, the light is split into spectral channels during the data acquisition process, producing a 4-D data cube with images recorded at many wavelengths and at many times. In this work, we propose to follow an inverse problem approach to model the astronomical data as the contribution of a low-rank component containing the background of quasi-static speckles and a sparse component containing the exoplanets. We then formulate the resulting model as a convex non-smooth optimization model so that an accelerated proximal gradient descent can be used to solve the detection problem."
A Model of Memristive Nanowire Neuron for Recurrent Neural Networks,"Veronica Pistolesi, Andrea Ceni, Gianluca Milano, Carlo Ricciardi, Claudio Gallicchio","1 - Department of Computer Science University of Pisa Italy
3 - Istituto nazionale di ricerca metrologica (INRiM) Italy
4 - Department of Applied Science and Technology Politecnico di Torino Italy","We propose a novel neural processing unit for artificial neural networks, inspired by the memristive properties of nanowires. Our analysis, framed within the Reservoir Computing paradigm, demonstrates the stability, short-term memory, and fading memory capabilities of the unit. Further experiments on assemblies of nanowire-inspired neurons show promising results in time-series classification tasks. Our introduced approach bridges analog neuromorphic hardware and AI applications, enabling efficient time series processing.",Feature extraction & Prototype learning,https://doi.org/10.14428/esann/2022.ES2022-94,2025,58.33333333333333,"A Model of Memristive Nanowire Neuron for Recurrent Neural Networks We propose a novel neural processing unit for artificial neural networks, inspired by the memristive properties of nanowires. Our analysis, framed within the Reservoir Computing paradigm, demonstrates the stability, short-term memory, and fading memory capabilities of the unit. Further experiments on assemblies of nanowire-inspired neurons show promising results in time-series classification tasks. Our introduced approach bridges analog neuromorphic hardware and AI applications, enabling efficient time series processing."
Leveraging Segmentation Maps to improve Skin Lesion Classification,"Simone Bonechi, Paolo Andreini, Fiamma Romagnoli","1 - Department of Information Engineering and Mathematics University of Siena Siena Italy
3 - Institute of Informatics and Telematics CNR Pisa Italy","We propose a novel approach for skin lesion classification that leverages a transformer architecture to integrate diverse clinical information (dermoscopic images, segmentation maps, and patient clinical information) for more accurate diagnosis. By incorporating binary semantic segmentation maps as input, we directly provide the model with border details critical for distinguishing between benign and malignant lesions. This integration improves classification performance compared to models that use only dermoscopic images or clinical data. To the best of our knowledge, this is the first application of segmentation maps to enhance skin lesion classification. Our experiments on the ISIC dataset yield promising results, highlighting the potential of combining advanced transformer models with multimodal data for improved dermatological diagnostics.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-90.pdf,2025,63.309352517985616,"Leveraging Segmentation Maps to improve Skin Lesion Classification We propose a novel approach for skin lesion classification that leverages a transformer architecture to integrate diverse clinical information (dermoscopic images, segmentation maps, and patient clinical information) for more accurate diagnosis. By incorporating binary semantic segmentation maps as input, we directly provide the model with border details critical for distinguishing between benign and malignant lesions. This integration improves classification performance compared to models that use only dermoscopic images or clinical data. To the best of our knowledge, this is the first application of segmentation maps to enhance skin lesion classification. Our experiments on the ISIC dataset yield promising results, highlighting the potential of combining advanced transformer models with multimodal data for improved dermatological diagnostics."
Screening Dyslexia for English: Impact of Heterogeneity in Demographic Variables,"Enrique Romero, Luz Rello","1 - Instituto de Salud Carlos III (ISCIII) Spain
2 - German Federal Ministry of Education and Research (BMBF) Germany
3 - National Centre for Research and Development (NCBR) Agence Nationale de la Recherche (ANR) France;, Poland
4 - Agencia Nacional de Investigación y Desar-rollo (ANID) Chile","Dyslexia is a complex learning disorder that can be challenging to diagnose. In this way, it is crucial to gather knowledge about the impact of key attributes. This work focuses on demographic variables used in a pioneering computer-based linguistic game designed for the screening of dyslexia using Machine Learning. The analysis reveals the heterogeneity in these variables, offering valuable insights for future Machine Learning approaches. It emphasizes key contributions, such as strategies to mitigate biases and effectively address heterogeneity, suggesting the formation of subgroups based on interaction data collected.",Environmental signal processing: new trends and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-136.pdf,2025,48.366013071895416,"Screening Dyslexia for English: Impact of Heterogeneity in Demographic Variables Dyslexia is a complex learning disorder that can be challenging to diagnose. In this way, it is crucial to gather knowledge about the impact of key attributes. This work focuses on demographic variables used in a pioneering computer-based linguistic game designed for the screening of dyslexia using Machine Learning. The analysis reveals the heterogeneity in these variables, offering valuable insights for future Machine Learning approaches. It emphasizes key contributions, such as strategies to mitigate biases and effectively address heterogeneity, suggesting the formation of subgroups based on interaction data collected."
Encoding Graph Topology with Randomized Ising Models,"Domenico Tortorella, Antonio Brau, Alessio Micheli","1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy
2 - Department of Physics 'E. Fermi' Largo B. Pontecorvo 3 University of Pisa 56127 Pisa Italy","The increasing popularity of deep learning on graphs has motivated the need for the co-design of hardware and graph representation models. We propose Randomized Ising Model (RIM), a reservoir computing model for encoding topological information of graph nodes, that is amenable to physical implementation via neuromorphic hardware. Our experiments demonstrate that RIM's node embeddings are able to provide sufficient topological information to be suitable to address node classification tasks, exhibiting an accuracy in line with Graph Echo State Networks.",Language models,https://doi.org/10.14428/esann/2024.ES2024-143,2025,49.46236559139785,"Encoding Graph Topology with Randomized Ising Models The increasing popularity of deep learning on graphs has motivated the need for the co-design of hardware and graph representation models. We propose Randomized Ising Model (RIM), a reservoir computing model for encoding topological information of graph nodes, that is amenable to physical implementation via neuromorphic hardware. Our experiments demonstrate that RIM's node embeddings are able to provide sufficient topological information to be suitable to address node classification tasks, exhibiting an accuracy in line with Graph Echo State Networks."
Performance monitoring and wear comprehension through Neural Network,"Thomas Binet, Hanane Azzag, Mustapha Lebbah, Jerome Lacaille","1 - UMR CNRS 7030 Sorbonne Paris Nord University -LIPN Villetaneuse France
2 - Safran Aircraft Engine Moissy-Cramayel France
4 - -DAVID Lab University of Versailles University Paris-Saclay Versailles France","In this paper, we present a novel approach to modeling the wear of complex dynamic systems, exemplified by aircraft engines, through the construction of a structured latent space. Unlike traditional methods, our model does not rely on explicit wear data but instead leverages supervised training to minimize the error on observable system parameters. Beyond wear forecasting, this work offers a foundation for unsupervised diagnosis, risk prevention, and the quantification of repair impacts.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-157.pdf,2025,53.79310344827586,"Performance monitoring and wear comprehension through Neural Network In this paper, we present a novel approach to modeling the wear of complex dynamic systems, exemplified by aircraft engines, through the construction of a structured latent space. Unlike traditional methods, our model does not rely on explicit wear data but instead leverages supervised training to minimize the error on observable system parameters. Beyond wear forecasting, this work offers a foundation for unsupervised diagnosis, risk prevention, and the quantification of repair impacts."
A Pipeline based on Differential Evolution for Tuning Parameters of Synaptic Dynamics Models,"Ferney Beltran-Velandia, Nico Scherf, Martin Bogdan","1 - Leipzig University -Neuromorphic Information Processing Augustusplatz 10 Leipzig Germany
2 - Center for Scalable Data Analytics and Artificial Intelligence ScaDS.AI Leipzig -Humboldtstrasse 25 Dresden, Leipzig Germany
3 - Max Planck Institute for Human Cognitive and Brain Sciences Stephanstrasse 1a Leipzig Germany","Integrating the modulatory properties of Synaptic Dynamics (SD) into Spiking Neural Networks (SNNs) can enhance their computational capabilities. For improving this integration process, this paper presents a pipeline based on Differential Evolution to tune parameters of SD models. Using reference signals from in vitro experiments, parameters of two models are tuned as study cases: the Tsodyks-Markram and the Modified Stochastic Synaptic Model. The pipeline has an average success rate of 75% and 80% respectively. The outcome is a distribution of parameters for each model, which can be considered as prior knowledge to facilitate the integration of SD models into SNNs.",Sequence learning and time series,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-118.pdf,2025,60.810810810810814,"A Pipeline based on Differential Evolution for Tuning Parameters of Synaptic Dynamics Models Integrating the modulatory properties of Synaptic Dynamics (SD) into Spiking Neural Networks (SNNs) can enhance their computational capabilities. For improving this integration process, this paper presents a pipeline based on Differential Evolution to tune parameters of SD models. Using reference signals from in vitro experiments, parameters of two models are tuned as study cases: the Tsodyks-Markram and the Modified Stochastic Synaptic Model. The pipeline has an average success rate of 75% and 80% respectively. The outcome is a distribution of parameters for each model, which can be considered as prior knowledge to facilitate the integration of SD models into SNNs."
Growth strategies for arbitrary DAG neural architectures,"Stella Douka, Manon Verbockhaven, Théo Rudkiewicz, Stéphane Rivaud, François Landes, Sylvain Chevallier, Guillaume Charpiat",1 - Inria TAU team LISN Université Paris-Saclay Orsay France,"Deep learning has shown impressive results, obtained at the cost of training huge neural networks. However, the larger the architecture, the higher the computational, financial, and environmental costs during training and inference. We aim at reducing both training and inference durations. We focus on Neural Architecture Growth, which can increase the size of a small model when needed, directly during training using information from the backpropagation. We expand existing work and freely grow neural networks in the form of any Directed Acyclic Graph. We design strategies that reduce excessive computations and steer network growth toward more parameter-efficient architectures.",Randomized Machine Learning approaches: analysis and developments,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-92.pdf,2025,51.515151515151516,"Growth strategies for arbitrary DAG neural architectures Deep learning has shown impressive results, obtained at the cost of training huge neural networks. However, the larger the architecture, the higher the computational, financial, and environmental costs during training and inference. We aim at reducing both training and inference durations. We focus on Neural Architecture Growth, which can increase the size of a small model when needed, directly during training using information from the backpropagation. We expand existing work and freely grow neural networks in the form of any Directed Acyclic Graph. We design strategies that reduce excessive computations and steer network growth toward more parameter-efficient architectures."
TEA: Trajectory Encoding Augmentation for Robust and Transferable Policies in Offline Reinforcement Learning,"Batıkan Bora Ormancı, Phillip Swazinna, Steffen Udluft, Thomas Runkler","1 - Siemens AG Munich Germany
2 - Technical University of Munich Germany","In this paper, we investigate offline reinforcement learning (RL) with the goal of training a single robust policy that generalizes effectively across environments with unseen dynamics. We propose a novel approach, Trajectory Encoding Augmentation (TEA), which extends the state space by integrating latent representations of environmental dynamics obtained from sequence encoders, such as autoencoders. Our findings show that incorporating these encodings with TEA improves the transferability of a single policy to novel environments with new dynamics, surpassing methods that rely solely on unmodified states. These results indicate that TEA captures critical, environment-specific characteristics, enabling RL agents to generalize effectively across dynamic conditions. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01IS24087A. The sole responsibility for the report's contents lies with the authors.",Learning I,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-101.pdf,2025,59.57446808510638,"TEA: Trajectory Encoding Augmentation for Robust and Transferable Policies in Offline Reinforcement Learning In this paper, we investigate offline reinforcement learning (RL) with the goal of training a single robust policy that generalizes effectively across environments with unseen dynamics. We propose a novel approach, Trajectory Encoding Augmentation (TEA), which extends the state space by integrating latent representations of environmental dynamics obtained from sequence encoders, such as autoencoders. Our findings show that incorporating these encodings with TEA improves the transferability of a single policy to novel environments with new dynamics, surpassing methods that rely solely on unmodified states. These results indicate that TEA captures critical, environment-specific characteristics, enabling RL agents to generalize effectively across dynamic conditions. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01IS24087A. The sole responsibility for the report's contents lies with the authors."
Introducing Intrinsic Motivation in Elastic Decision Transformers,"Leonardo Guiducci, Giovanna Dimitri, Giulia Palma, Antonio Rizzo","1 - DIISM Universitá di Siena Via Roma 56 53100 Siena, Siena Italy, Italy
2 - Universitá di Siena 1-DISPOC, Via Roma 56 53100 Siena, Siena Italy, Italy","Effective decision-making is a key challenge in artificial intelligence, with Reinforcement Learning (RL) emerging as one of the main approaches. However, RL often depends on complex reward functions, which are difficult to design. Intrinsic motivation, inspired by psychological concepts like curiosity, offers an alternative by generating agent-driven rewards to foster exploration. This paper introduces intrinsic motivation into the Elastic Decision Transformer (EDT) framework for Offline RL. By using an auxiliary intrinsic loss, we enhance representation learning without altering fixed reward signals. Experiments in locomotion tasks demonstrate improved performance, underscoring the potential of intrinsic motivation to advance RL in offline settings.","Image and signal processing, matrix computations and topological data",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-24.pdf,2025,54.6875,"Introducing Intrinsic Motivation in Elastic Decision Transformers Effective decision-making is a key challenge in artificial intelligence, with Reinforcement Learning (RL) emerging as one of the main approaches. However, RL often depends on complex reward functions, which are difficult to design. Intrinsic motivation, inspired by psychological concepts like curiosity, offers an alternative by generating agent-driven rewards to foster exploration. This paper introduces intrinsic motivation into the Elastic Decision Transformer (EDT) framework for Offline RL. By using an auxiliary intrinsic loss, we enhance representation learning without altering fixed reward signals. Experiments in locomotion tasks demonstrate improved performance, underscoring the potential of intrinsic motivation to advance RL in offline settings."
Unlocking Structured Thinking in Language Models with Cognitive Prompting,"Oliver Kramer, Jill Baumann",1 - Department of Computing Science Carl von Ossietzky Universität Oldenburg 26111 Oldenburg Germany,"We propose cognitive prompting as a novel approach to guide problem-solving in large language models (LLMs) through structured, human-like cognitive operations, such as goal clarification, decomposition, filtering, abstraction, and pattern recognition. By employing systematic, step-by-step reasoning, cognitive prompting enables LLMs to tackle complex, multi-step tasks more efficiently. We introduce three variants: a deterministic sequence of cognitive operations, a self-adaptive variant in which the LLM dynamically selects the sequence of cognitive operations, and a hybrid variant that uses generated correct solutions as few-shot chain-of-thought prompts. Experiments with LLaMA, Gemma 2, and Qwen models in each two sizes on the arithmetic reasoning benchmark GSM8K demonstrate that cognitive prompting significantly improves performance compared to standard question answering.","Language processing in the era of deep learning - organized by Ivano Lauriola (University of Padova, Italy), Alberto Lavelli (Fondazione Bruno Kessler, Italy), Fabio Aiolli (University of Padova, Italy)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-4.pdf,2025,50.0,"Unlocking Structured Thinking in Language Models with Cognitive Prompting We propose cognitive prompting as a novel approach to guide problem-solving in large language models (LLMs) through structured, human-like cognitive operations, such as goal clarification, decomposition, filtering, abstraction, and pattern recognition. By employing systematic, step-by-step reasoning, cognitive prompting enables LLMs to tackle complex, multi-step tasks more efficiently. We introduce three variants: a deterministic sequence of cognitive operations, a self-adaptive variant in which the LLM dynamically selects the sequence of cognitive operations, and a hybrid variant that uses generated correct solutions as few-shot chain-of-thought prompts. Experiments with LLaMA, Gemma 2, and Qwen models in each two sizes on the arithmetic reasoning benchmark GSM8K demonstrate that cognitive prompting significantly improves performance compared to standard question answering."
Conceptualizing Concept Drift,"Isaac Roberts, Fabian Hinder, Valerie Vaquet, Alexander Schulz, Barbara Hammer",1 - Faculty of Technology Inspiration 1 Bielefeld University 33619 Bielefeld Germany,"Concept drift refers to the phenomenon that the underlying data distribution changes over time. While detection methods or model adjustment methods exist, a proper explanation of drift in high-dimensional settings is still widely unsolved. This problem is crucial since it enables an understanding of the most prominent drift characteristics. In this work, we propose to explain concept drift of high-dimensional data objects by means of concept activation vectors which give rise to local, phase, and a novel, global explanation called the Concept 2 Drift Distribution.",Anomaly and change point detection,https://doi.org/10.14428/esann/2022.ES2022-71,2025,63.76811594202898,"Conceptualizing Concept Drift Concept drift refers to the phenomenon that the underlying data distribution changes over time. While detection methods or model adjustment methods exist, a proper explanation of drift in high-dimensional settings is still widely unsolved. This problem is crucial since it enables an understanding of the most prominent drift characteristics. In this work, we propose to explain concept drift of high-dimensional data objects by means of concept activation vectors which give rise to local, phase, and a novel, global explanation called the Concept 2 Drift Distribution."
Deciphering Barlow Twins: Redundancy Reduction is Insufficient and Normalization is Key,"Hans-Oliver Hansen, Marius Jahrens, Thomas Martinetz",1 - University of Lübeck -Institute for Neuro-and Bioinformatics Ratzeburger Allee 160 23562 Lübeck Germany,"Barlow Twins is a feature-contrastive self-supervised learning framework built on the principle of redundancy reduction. The idea is to train a network by maximizing the correlation between corresponding features and minimizing the correlation between non-corresponding features in distorted views of the same image, through this facilitating effective pretraining of a backbone network for a subsequent classification head. This is achieved by diagonalizing the cross-correlation matrix of the network's representations and scaling it towards the identity matrix. We show that the cross-correlation matrix of distorted images is inherently symmetric, independent of the backbone network's weights, which leads to two key insights: (i) the cross-correlation matrix can always be diagonalized using a linear transformation (layer), and (ii) the core idea of maximizing correlations between corresponding features while minimizing them for non-corresponding features alone is insufficient for effective backbone network pretraining. Nevertheless, Barlow Twins provide highly effective pretraining. We show that this is due to the normalization of the cross-correlation matrix in the Barlow Twins cost function. This normalization leads to minima of the cost function which are equivalent to the minima of sample contrastive approaches to enforce invariance.","Evaluation metrics, and concept drift",https://doi.org/10.14428/esann/2021.ES2021-24,2025,51.61290322580645,"Deciphering Barlow Twins: Redundancy Reduction is Insufficient and Normalization is Key Barlow Twins is a feature-contrastive self-supervised learning framework built on the principle of redundancy reduction. The idea is to train a network by maximizing the correlation between corresponding features and minimizing the correlation between non-corresponding features in distorted views of the same image, through this facilitating effective pretraining of a backbone network for a subsequent classification head. This is achieved by diagonalizing the cross-correlation matrix of the network's representations and scaling it towards the identity matrix. We show that the cross-correlation matrix of distorted images is inherently symmetric, independent of the backbone network's weights, which leads to two key insights: (i) the cross-correlation matrix can always be diagonalized using a linear transformation (layer), and (ii) the core idea of maximizing correlations between corresponding features while minimizing them for non-corresponding features alone is insufficient for effective backbone network pretraining. Nevertheless, Barlow Twins provide highly effective pretraining. We show that this is due to the normalization of the cross-correlation matrix in the Barlow Twins cost function. This normalization leads to minima of the cost function which are equivalent to the minima of sample contrastive approaches to enforce invariance."
Inferring Underwater Topography with Finite Volume Neural Networks,"Coşku Can Horuz, Matthias Karlbauer, Timothy Praditia, Sergey Oladyshkin, Wolfgang Nowak, Sebastian Otte","1 - Neuro-Cognitive Modeling Institute of Robotics and Cognitive Systems Lab University of Tübingen 2 -Adaptive AI
2 - Department of Stochastic Simulation and Safety Research for Hydrosystems University of Lübeck
3 - University of Stuttgart","Partial differential equations (PDEs) find applications across various scientific and engineering fields. There is a growing trend for integrating physics-aware machine learning models to solve PDEs. Among them, the Finite Volume Neural Network (FINN) has proven to be efficient in uncovering latent structures in data. This study explores the capabilities of FINN in the investigation of shallow-water equations, which simulate wave dynamics in coastal regions. Specifically, we investigate the efficacy of FINN in reconstructing underwater topography. We find that FINN excels at inferring topography solely from wave dynamics, stressing the importance of application-specific inductive bias in neural network architectures.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-154.pdf,2025,55.47445255474452,"Inferring Underwater Topography with Finite Volume Neural Networks Partial differential equations (PDEs) find applications across various scientific and engineering fields. There is a growing trend for integrating physics-aware machine learning models to solve PDEs. Among them, the Finite Volume Neural Network (FINN) has proven to be efficient in uncovering latent structures in data. This study explores the capabilities of FINN in the investigation of shallow-water equations, which simulate wave dynamics in coastal regions. Specifically, we investigate the efficacy of FINN in reconstructing underwater topography. We find that FINN excels at inferring topography solely from wave dynamics, stressing the importance of application-specific inductive bias in neural network architectures."
Towards Efficient Molecular Property Optimization with Graph Energy Based Models,"Luca Miglior, Lorenzo Simone, Marco Podda, Davide Bacciu",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 Pisa Italy,"Optimizing chemical properties is a challenging task due to the vastness and complexity of chemical space. Here, we present a generative energy-based architecture for implicit chemical property optimization, designed to efficiently generate molecules that satisfy target properties without explicit conditional generation. We use Graph Energy Based Models and a training approach that does not require property labels. We validated our approach on well-established chemical benchmarks, showing superior results to state-of-the-art methods and demonstrating robustness and efficiency towards de novo drug design.",Learning methods and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-115.pdf,2025,60.35502958579882,"Towards Efficient Molecular Property Optimization with Graph Energy Based Models Optimizing chemical properties is a challenging task due to the vastness and complexity of chemical space. Here, we present a generative energy-based architecture for implicit chemical property optimization, designed to efficiently generate molecules that satisfy target properties without explicit conditional generation. We use Graph Energy Based Models and a training approach that does not require property labels. We validated our approach on well-established chemical benchmarks, showing superior results to state-of-the-art methods and demonstrating robustness and efficiency towards de novo drug design."
Trajectory-Embedded Matryoshka Representation Learning for Enhanced Similarity Analysis,"Federico Pennino, Andrea Gurioli, Maurizio Gabbrielli",1 - University of Bologna -DISI Via Zamboni 33 40126 Bologna Italy,"This paper introduces Trajectory-Embedded Matryoshka Representation Learning (TE-MRL). This novel framework synergies the capabilities of trajectory representation learning with the adaptability and efficiency of Matryoshka Representation Learning (MRL). TE-MRL is engineered to generate adaptive, multi-granular embeddings that efficiently capture the spatial-temporal dynamics inherent in trajectory data. We evaluate TE-MRL on the Porto dataset, focusing on trajectory similarity and k-nearest trajectory similarity tasks. Our findings demonstrate that TE-MRL preserves critical features such as travel semantics and temporal regularities while it can significantly reduce computational time and memory footprint. The proposed approach matches existing methods' accuracy and efficiency but demonstrates robust adaptability under varying computational constraints. Furthermore, we proposed a two-stage retrieval pipeline to enhance computational time while maintaining the same precision. We reduced the computation time by 8× while maintaining state-of-the-art precision. The effectiveness of TE-MRL in handling the complexity of the Porto dataset underlines its potential for broader applications in urban computing and mobility analytics.",Embeddings and Representation Learning for Structured Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-4.pdf,2025,59.31034482758621,"Trajectory-Embedded Matryoshka Representation Learning for Enhanced Similarity Analysis This paper introduces Trajectory-Embedded Matryoshka Representation Learning (TE-MRL). This novel framework synergies the capabilities of trajectory representation learning with the adaptability and efficiency of Matryoshka Representation Learning (MRL). TE-MRL is engineered to generate adaptive, multi-granular embeddings that efficiently capture the spatial-temporal dynamics inherent in trajectory data. We evaluate TE-MRL on the Porto dataset, focusing on trajectory similarity and k-nearest trajectory similarity tasks. Our findings demonstrate that TE-MRL preserves critical features such as travel semantics and temporal regularities while it can significantly reduce computational time and memory footprint. The proposed approach matches existing methods' accuracy and efficiency but demonstrates robust adaptability under varying computational constraints. Furthermore, we proposed a two-stage retrieval pipeline to enhance computational time while maintaining the same precision. We reduced the computation time by 8× while maintaining state-of-the-art precision. The effectiveness of TE-MRL in handling the complexity of the Porto dataset underlines its potential for broader applications in urban computing and mobility analytics."
Robust Evolutionary Multi-Objective Neural Architecture Search for Reinforcement Learning (EMNAS-RL),"Nihal Adde, Alexandra Gianzina, Hanno Gottschalk, Andreas Ebert","1 - Volkswagen Group Innovation Volkswagen AG Wolfsburg Germany
2 - Institute of Mathematics TU Berlin Berlin Germany","This paper introduces Evolutionary Multi-Objective Neural Architecture Search (EMNAS) for the first time to optimize neural network architectures in large-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses genetic algorithms to automate network design, tailored to enhance rewards and reduce model size without compromising performance. Additionally, parallelization techniques are employed to accelerate the search, and teacher-student methodologies are implemented to ensure scalable optimization. Experimental results demonstrate that tailored EMNAS outperforms manually designed models, achieving higher rewards with fewer parameters.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-87,2025,54.32098765432099,"Robust Evolutionary Multi-Objective Neural Architecture Search for Reinforcement Learning (EMNAS-RL) This paper introduces Evolutionary Multi-Objective Neural Architecture Search (EMNAS) for the first time to optimize neural network architectures in large-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses genetic algorithms to automate network design, tailored to enhance rewards and reduce model size without compromising performance. Additionally, parallelization techniques are employed to accelerate the search, and teacher-student methodologies are implemented to ensure scalable optimization. Experimental results demonstrate that tailored EMNAS outperforms manually designed models, achieving higher rewards with fewer parameters."
A variational framework for local learning with probabilistic latent representations,"Cabrel Fokam, Khaleelulla Khan, Christian Mayr, Anand Subramoney, David Kappel","1 - Institut für Neuroinformatik Ruhr Universität Bochum Germany
2 - CITEC Bielefeld University Germany
3 - Faculty of Electrical and Computer Engineering
5 - Centre for Tactile Internet with Human-in-the-Loop (CeTI) Technische Universität Dresden Germany
6 - Department of Computer Science Royal Holloway University of London UK","We introduce a novel method for distributed learning by dividing deep neural networks into blocks and incorporating feedback networks to propagate target information backwards, enabling auxiliary local losses. Forward and backward propagation operate in parallel with independent weights, addressing locking and weight transport problems. Our approach is rooted in a statistical view of training, treating block output activations as parameters of probability distributions to measure alignment between forward and backward passes. Error backpropagation is then performed locally within blocks, hence block-local learning. Preliminary results across tasks and architectures showcase state-of-the-art performance, establishing a principled framework for asynchronous distributed learning. * CTF and KKN are funded by BMBF project EVENTS (16ME0733). DK is funded by the Ministry of Culture and Science of the State of North Rhine-Westphalia under project SAIL (grant no. NW21-059A) and BMWK project ESCADE (01MN23004D). The authors gratefully acknowledge the Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu) for providing computing time on GCS JUWELS at Jülich Supercomputing Centre (JSC).",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-40.pdf,2025,59.77011494252873,"A variational framework for local learning with probabilistic latent representations We introduce a novel method for distributed learning by dividing deep neural networks into blocks and incorporating feedback networks to propagate target information backwards, enabling auxiliary local losses. Forward and backward propagation operate in parallel with independent weights, addressing locking and weight transport problems. Our approach is rooted in a statistical view of training, treating block output activations as parameters of probability distributions to measure alignment between forward and backward passes. Error backpropagation is then performed locally within blocks, hence block-local learning. Preliminary results across tasks and architectures showcase state-of-the-art performance, establishing a principled framework for asynchronous distributed learning. * CTF and KKN are funded by BMBF project EVENTS (16ME0733). DK is funded by the Ministry of Culture and Science of the State of North Rhine-Westphalia under project SAIL (grant no. NW21-059A) and BMWK project ESCADE (01MN23004D). The authors gratefully acknowledge the Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu) for providing computing time on GCS JUWELS at Jülich Supercomputing Centre (JSC)."
Evolutionary Fault Localization Based on the Diversity of Suspiciousness Values,"Willian De, Jesus Ferreira, Plinio Leitao-Junior, Deuslirio Silva-Junior, Rachel Harrison","1 - Universidade Federal de Goias (UFG) -Instituto de Informatica (INF) Alameda Palmeiras Campus Samambaia Quadra D, Goiania, Goias Brazil
4 - Oxford Brookes -School of Engineering, Computing and Maths Headington Campus OX3 0BP Oxford United Kingdom","Context. Fault localization (FL) is a software lifecycle activity and its automation is a challenge for researchers and practitioners. Method. The study focuses on evolutionary fault localization and introduces a novel Genetic Programming (GP) approach that evolves FL heuristics based on the diversity of the suspiciousness score of program statements -a score to grade how faulty a statement is. Experimental analysis. The approach was evaluated against baselines, which include the canonical GP, in benchmarks with real programs and real faults. Conclusion. The results showed the competitiveness of the approach through evaluation metrics commonly used in the research field.",Optimization and metaheuristics,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-77.pdf,2025,53.06122448979591,"Evolutionary Fault Localization Based on the Diversity of Suspiciousness Values Context. Fault localization (FL) is a software lifecycle activity and its automation is a challenge for researchers and practitioners. Method. The study focuses on evolutionary fault localization and introduces a novel Genetic Programming (GP) approach that evolves FL heuristics based on the diversity of the suspiciousness score of program statements -a score to grade how faulty a statement is. Experimental analysis. The approach was evaluated against baselines, which include the canonical GP, in benchmarks with real programs and real faults. Conclusion. The results showed the competitiveness of the approach through evaluation metrics commonly used in the research field."
Investigating the Impact of Imbalanced Medical Data on the Performance of Self-Supervised Learning Approaches,"Manuel Laufer, Felicitas Brokmann, Dominik Mairhöfer, Erhardt Barth, Thomas Martinetz",1 - University of Lübeck -Institute for Neuro-and Bioinformatics Ratzeburger Allee 160 23562 Lübeck Germany,"In clinical practice, a substantial amount of data is generated on a daily basis for diagnostic purposes. Since expensive expert knowledge is required for data annotation in order to use this data for supervised learning, large amounts of data often remain unused. Self-supervised learning methods are well suited for using unlabeled data by pre-training networks to solve pretext tasks. As medical data follow an underlying uneven distribution of occurring diseases, they are inherently imbalanced. This could introduce an unwanted bias during pre-training, ultimately leading to negative consequences that may inhibit the benefits of finetuning. In this work we investigate the impact of the imbalance of 2D and 3D medical datasets used for pre-training, as well as the importance of the type and size of the dataset used for pre-training and the pretext task. Our findings indicate that the size of the dataset used for pre-training has greater impact on the final tasks than its balance.",Semi-supervised learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2011-57.pdf,2025,51.162790697674424,"Investigating the Impact of Imbalanced Medical Data on the Performance of Self-Supervised Learning Approaches In clinical practice, a substantial amount of data is generated on a daily basis for diagnostic purposes. Since expensive expert knowledge is required for data annotation in order to use this data for supervised learning, large amounts of data often remain unused. Self-supervised learning methods are well suited for using unlabeled data by pre-training networks to solve pretext tasks. As medical data follow an underlying uneven distribution of occurring diseases, they are inherently imbalanced. This could introduce an unwanted bias during pre-training, ultimately leading to negative consequences that may inhibit the benefits of finetuning. In this work we investigate the impact of the imbalance of 2D and 3D medical datasets used for pre-training, as well as the importance of the type and size of the dataset used for pre-training and the pretext task. Our findings indicate that the size of the dataset used for pre-training has greater impact on the final tasks than its balance."
Project-Specific Code Summarization with Meta-Learning and Explainability Techniques,"Quang-Huy Nguyen, Hoai-Phong Le, Bac Le","1 - Faculty of Information Technology University of Science Ho Chi Minh City Vietnam
2 - National University Ho Chi Minh City Vietnam, Vietnam","Code summarization generates natural language descriptions for code snippets, enhancing readability and maintainability. While current methods perform well with large-scale datasets, they struggle in low-resource scenarios typical of smaller and newer projects. Additionally, developers need summaries that capture project-specific characteristics rather than generic descriptions. To address these challenges, we propose a meta-learning-based training framework that adapts the model to individual projects as distinct tasks, even with minimal data. We introduce a strategy for selecting support projects to boost the framework's effectiveness. Experiments on eight real-world projects show that our method outperforms the baseline approach. Furthermore, we use explainability techniques to clarify the prediction process and identify potential issues.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-57,2025,53.06122448979591,"Project-Specific Code Summarization with Meta-Learning and Explainability Techniques Code summarization generates natural language descriptions for code snippets, enhancing readability and maintainability. While current methods perform well with large-scale datasets, they struggle in low-resource scenarios typical of smaller and newer projects. Additionally, developers need summaries that capture project-specific characteristics rather than generic descriptions. To address these challenges, we propose a meta-learning-based training framework that adapts the model to individual projects as distinct tasks, even with minimal data. We introduce a strategy for selecting support projects to boost the framework's effectiveness. Experiments on eight real-world projects show that our method outperforms the baseline approach. Furthermore, we use explainability techniques to clarify the prediction process and identify potential issues."
Is Q-learning an Ill-posed Problem?,"Philipp Wissmann, Daniel Hein, Steffen Udluft, Thomas Runkler","1 - Siemens AG Munich Germany
2 - TU Munich (TUM) Munich Germany","This paper investigates the instability of Q-learning in continuous environments, a challenge frequently encountered by practitioners. Traditionally, this instability is attributed to bootstrapping and regression model errors. Using a representative reinforcement learning benchmark, we systematically examine the effects of bootstrapping and model inaccuracies by incrementally eliminating these potential error sources. Our findings reveal that even in relatively simple benchmarks, the fundamental task of Q-learning -iteratively learning a Q-function from policy-specific target values -can be inherently ill-posed and prone to failure. These insights cast doubt on the reliability of Q-learning as a universal solution for reinforcement learning problems. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01IS24087A. The sole responsibility for the report's contents lies with the authors.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-23.pdf,2025,51.61290322580645,"Is Q-learning an Ill-posed Problem? This paper investigates the instability of Q-learning in continuous environments, a challenge frequently encountered by practitioners. Traditionally, this instability is attributed to bootstrapping and regression model errors. Using a representative reinforcement learning benchmark, we systematically examine the effects of bootstrapping and model inaccuracies by incrementally eliminating these potential error sources. Our findings reveal that even in relatively simple benchmarks, the fundamental task of Q-learning -iteratively learning a Q-function from policy-specific target values -can be inherently ill-posed and prone to failure. These insights cast doubt on the reliability of Q-learning as a universal solution for reinforcement learning problems. * The project this report is based on was supported with funds from the German Federal Ministry of Education and Research under project number 01IS24087A. The sole responsibility for the report's contents lies with the authors."
Coherence-based Sample Selection for Class-incremental Learning,"Andrea Daou, Jean-Baptiste Pothin, Paul Honeine, Abdelaziz Bensrhair","1 - Univ Rouen Normandie INSA Rouen Normandie Université Le Havre Normandie Normandie Univ LITIS UR 4108, 76000 Rouen France
3 - 1-DATAHERTZ 10000 Troyes France","Class-Incremental Learning (Class-IL)   is challenging as the model must adapt to new classes while retaining knowledge of old ones. To avoid catastrophic forgetting in knowledge distillation with a fixed-budget memory, exemplars from previously learned classes need to be stored. We propose a novel sample selection method based on the coherence measure to boost Class-IL performance. This is the first time the coherence is investigated in a deep model, specifically for Class-IL. We define the coherence between two samples as a normalized inner product between their deep feature extractor features. Theoretical results and extensive experiments demonstrate the relevance of our approach.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-80,2025,58.64661654135339,"Coherence-based Sample Selection for Class-incremental Learning Class-Incremental Learning (Class-IL)   is challenging as the model must adapt to new classes while retaining knowledge of old ones. To avoid catastrophic forgetting in knowledge distillation with a fixed-budget memory, exemplars from previously learned classes need to be stored. We propose a novel sample selection method based on the coherence measure to boost Class-IL performance. This is the first time the coherence is investigated in a deep model, specifically for Class-IL. We define the coherence between two samples as a normalized inner product between their deep feature extractor features. Theoretical results and extensive experiments demonstrate the relevance of our approach."
Solving Turbulent Rayleigh-Bénard Convection using Fourier Neural Operators,"Michiel Straat, Thorben Markmann, Barbara Hammer",1 - Bielefeld University -Center For Cognitive Interaction Technology Inspiration 1 33619 Bielefeld Germany,"We train Fourier Neural Operator (FNO) surrogate models for Rayleigh-Bénard Convection (RBC), a model for convection processes that occur in nature and industrial settings. We compare the prediction accuracy and model properties of FNO surrogates to two popular surrogates used in fluid dynamics: Dynamic Mode Decomposition (DMD) and the Linearly-Recurrent Autoencoder Network (LRAN). We regard Direct Numerical Simulations (DNS) of the RBC equations as the ground truth on which the models are trained and evaluated in different settings. The FNO performs favorably when compared to the DMD and LRAN and its predictions are fast and highly accurate for this task. Additionally, we show its zero-shot super-resolution ability for the convection dynamics. The FNO model has a high potential to be used in downstream tasks such as flow control in RBC.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-96.pdf,2025,53.41614906832298,"Solving Turbulent Rayleigh-Bénard Convection using Fourier Neural Operators We train Fourier Neural Operator (FNO) surrogate models for Rayleigh-Bénard Convection (RBC), a model for convection processes that occur in nature and industrial settings. We compare the prediction accuracy and model properties of FNO surrogates to two popular surrogates used in fluid dynamics: Dynamic Mode Decomposition (DMD) and the Linearly-Recurrent Autoencoder Network (LRAN). We regard Direct Numerical Simulations (DNS) of the RBC equations as the ground truth on which the models are trained and evaluated in different settings. The FNO performs favorably when compared to the DMD and LRAN and its predictions are fast and highly accurate for this task. Additionally, we show its zero-shot super-resolution ability for the convection dynamics. The FNO model has a high potential to be used in downstream tasks such as flow control in RBC."
Semantic Segmentation for Waterbody Extraction Using Superpixels and Convolutional Neural Networks Classifier,"Salim Iratni, Ferhat Attal, Yacine Amirat, Abdelghani Chibani, Moussa Diaf","1 - LVAAS Laboratory Mouloud Mammeri University of Tizi-Ouzou
2 - LISSI Laboratory Est Creteil University Paris","Waterbody extraction from satellite images is an important task for many applications, such as hydrological modeling, ecosystem monitoring and water reserve level tracking. To tackle this problem, several deep learning based approaches have been proposed in the literature. However, these approaches have difficulty delineating water bodies due to their variations in color, size and shape. To overcome this limitation, a novel deep learning-based approach that leverages the power of Convolutional Neural Networks (CNNs) and Superpixel technique using Simple Linear Iterative Clustering (SLIC) algorithm is proposed. The proposed method involves an initial over-segmentation of the input satellite image into homogeneous zones using the SLIC algorithm. These zones are then further processed to extract Regions Of Interest (ROI) that are classified as either water or non-water using a CNN model. Finally, each pixel within a homogeneous zone is assigned the predicted class of its associated ROI. The obtained results using Gaofen Image Dataset show the effectiveness of the proposed approach, while highlighting its superiority over state-of-the-art (SOTA) approaches.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-159.pdf,2025,63.594470046082954,"Semantic Segmentation for Waterbody Extraction Using Superpixels and Convolutional Neural Networks Classifier Waterbody extraction from satellite images is an important task for many applications, such as hydrological modeling, ecosystem monitoring and water reserve level tracking. To tackle this problem, several deep learning based approaches have been proposed in the literature. However, these approaches have difficulty delineating water bodies due to their variations in color, size and shape. To overcome this limitation, a novel deep learning-based approach that leverages the power of Convolutional Neural Networks (CNNs) and Superpixel technique using Simple Linear Iterative Clustering (SLIC) algorithm is proposed. The proposed method involves an initial over-segmentation of the input satellite image into homogeneous zones using the SLIC algorithm. These zones are then further processed to extract Regions Of Interest (ROI) that are classified as either water or non-water using a CNN model. Finally, each pixel within a homogeneous zone is assigned the predicted class of its associated ROI. The obtained results using Gaofen Image Dataset show the effectiveness of the proposed approach, while highlighting its superiority over state-of-the-art (SOTA) approaches."
On Domain Generalization for Human Activity Recognition with Mix-Based Methods,"Otávio Napoli, Edson Borin, Av Einstein","1 - Institute of Computing -State University of Campinas
2 - 1251 -Cidade Universitária, Campinas -SP 13083-889 Brazil","Domain generalization (DG) is a challenging problem that involves adapting a model trained on source domains to an unseen target domain. In human activity recognition (HAR), domain shifts often arise from differences in sensor placement, device specifications, or environmental factors, making generalization difficult. In this work, we investigate the effectiveness of mix-based methods like MixStyle and Exact Feature Distribution Mixing (EFDM) when integrated into state-of-the-art models like ResNet and TS2Vec for DG in HAR tasks, leveraging the DAGHAR benchmark. Our results demonstrate that MixStyle significantly outperforms both EFDM and Empirical Risk Minimization approaches, highlighting its effectiveness in addressing domain shifts. * This project was supported by the Ministry of Science, Technology, and Innovation of Brazil, with resources granted by the Federal Law 8.248 of October 23, 1991, under the PPI-Softex. The project was coordinated by Softex and published as Intelligent agents for mobile platforms based on Cognitive Architecture technology [01245.003479/2024-10]. The authors also thank CNPq (315399/2023-6 and 404087/2021-3) and Fapesp (2013/08293-7) for their financial support, and Discovery Laboratory for their computational resources. 1 t-SNE reduces high-dimensional data to a lower-dimensional space while preserving local similarities, helping to reveal patterns and distribution differences in HAR.",Human Activity and Motion Disorder Recognition: towards smarter Interactive Cognitive Environments,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-123.pdf,2025,56.470588235294116,"On Domain Generalization for Human Activity Recognition with Mix-Based Methods Domain generalization (DG) is a challenging problem that involves adapting a model trained on source domains to an unseen target domain. In human activity recognition (HAR), domain shifts often arise from differences in sensor placement, device specifications, or environmental factors, making generalization difficult. In this work, we investigate the effectiveness of mix-based methods like MixStyle and Exact Feature Distribution Mixing (EFDM) when integrated into state-of-the-art models like ResNet and TS2Vec for DG in HAR tasks, leveraging the DAGHAR benchmark. Our results demonstrate that MixStyle significantly outperforms both EFDM and Empirical Risk Minimization approaches, highlighting its effectiveness in addressing domain shifts. * This project was supported by the Ministry of Science, Technology, and Innovation of Brazil, with resources granted by the Federal Law 8.248 of October 23, 1991, under the PPI-Softex. The project was coordinated by Softex and published as Intelligent agents for mobile platforms based on Cognitive Architecture technology [01245.003479/2024-10]. The authors also thank CNPq (315399/2023-6 and 404087/2021-3) and Fapesp (2013/08293-7) for their financial support, and Discovery Laboratory for their computational resources. 1 t-SNE reduces high-dimensional data to a lower-dimensional space while preserving local similarities, helping to reveal patterns and distribution differences in HAR."
Influence of function nodes on automated generation of routing policies with genetic programming,"Marko Ðurasević, Francisco Gil Gala","1 - Faculty of Electrical Engineering and Computing University of Zagreb Unska 3 10000 Zagreb Croatia
2 - Department of Computer Science University of Oviedo Gijón Spain","Routing policies (RPs) are simple heuristics used to solve the electric vehicle routing problem, suitable for large or dynamic problems. Designing efficient RPs is difficult, because of which researchers started applying genetic programming (GP) for their automated development. For GP to be able to generate efficient RPs, it must be supplied with appropriate building blocks, i.e., functions and problem features, to construct the solution. This study investigates the selection of appropriate function nodes to construct RPs. The experiments demonstrate that the best results are obtained when using the most simple arithmetic operators enhanced with some additional operators.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-127,2025,53.260869565217384,"Influence of function nodes on automated generation of routing policies with genetic programming Routing policies (RPs) are simple heuristics used to solve the electric vehicle routing problem, suitable for large or dynamic problems. Designing efficient RPs is difficult, because of which researchers started applying genetic programming (GP) for their automated development. For GP to be able to generate efficient RPs, it must be supplied with appropriate building blocks, i.e., functions and problem features, to construct the solution. This study investigates the selection of appropriate function nodes to construct RPs. The experiments demonstrate that the best results are obtained when using the most simple arithmetic operators enhanced with some additional operators."
Reducing the stability gap for continual learning at the edge with class balancing,"Wei Wei, Matthias Hutsebaut-Buysse, Tom De Schepper, Kevin Mets","1 - Department of Computer Science
3 - IDLab University of Antwerp -imec
4 - Faculty of Applied Engineering
5 - Department of Electronics and Information and Communication Technology Sint-Pietersvliet 7 2000 Antwerp Belgium
6 - 1 -imec, 2","Continual learning (CL) at the edge requires the model to learn from sequentially arriving small batches of data. A naive online learning strategy fails due to the catastrophic forgetting phenomenon. Previous literature introduced the 'latent replay' for CL at the edge, where the input is transformed into latent representations using a pre-trained feature extractor. These latent representations are used, in combination with the real inputs, to train the adaptive classification layers. This approach is prone to the stability gap problem, where the accuracies of learned classes drop when learning a new class, and they only recover during subsequent training iterations. We hypothesize that this is caused by the class imbalance between new class data from the new task, and the old class data in the replay memory. We validate this by applying two class balancing strategies in a latent replay-based CL method. Our empirical results demonstrate that class balancing strategies provide a notable accuracy improvement, and a reduction of the stability gap when using a latent replay-based CL method with a small replay memory size.",Advances in Learning with Kernels: Theory and Practice in a World of growing Constraints,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-32.pdf,2025,58.0246913580247,"Reducing the stability gap for continual learning at the edge with class balancing Continual learning (CL) at the edge requires the model to learn from sequentially arriving small batches of data. A naive online learning strategy fails due to the catastrophic forgetting phenomenon. Previous literature introduced the 'latent replay' for CL at the edge, where the input is transformed into latent representations using a pre-trained feature extractor. These latent representations are used, in combination with the real inputs, to train the adaptive classification layers. This approach is prone to the stability gap problem, where the accuracies of learned classes drop when learning a new class, and they only recover during subsequent training iterations. We hypothesize that this is caused by the class imbalance between new class data from the new task, and the old class data in the replay memory. We validate this by applying two class balancing strategies in a latent replay-based CL method. Our empirical results demonstrate that class balancing strategies provide a notable accuracy improvement, and a reduction of the stability gap when using a latent replay-based CL method with a small replay memory size."
Making Convolutional Neural Networks Energy-Efficient: An Introduction,"Noémie Draguet, Benoît Frénay",1 - University of Namur -NaDI -PReCISE -HuMaLearn Rue Grangagnage 21 5000 Namur Belgium,"As convolutional neural networks (CNNs) have become mainstream for object recognition and image classification, the environmental impact caused by their high energy consumption (EC) is non negligible. This paper examines techniques that have the ability to reduce the EC of CNNs. It also highlights the inconsistency of metrics that are used for estimating or measuring EC, which reduces the comparability of these techniques. This review aims to shed light on the current situation and to provide a basis for future research in green machine learning.",Image processing and computer vision,https://doi.org/10.14428/esann/2024.ES2024-111,2025,55.84415584415585,"Making Convolutional Neural Networks Energy-Efficient: An Introduction As convolutional neural networks (CNNs) have become mainstream for object recognition and image classification, the environmental impact caused by their high energy consumption (EC) is non negligible. This paper examines techniques that have the ability to reduce the EC of CNNs. It also highlights the inconsistency of metrics that are used for estimating or measuring EC, which reduces the comparability of these techniques. This review aims to shed light on the current situation and to provide a basis for future research in green machine learning."
Continual Contrastive Learning on Tabular Data with Out of Distribution,"Achmad Ginanjar, Xue Li, Priyanka Singh, Wen Hua","1 - School of Electrical Engineering and Computer Science The University of Queensland Queensland Australia
2 - Indonesia Endowment Fund for Education Agency (LPDP)
5 - Department of Computing The Hong Kong Polytechnic University Hong Kong","Out-of-distribution (OOD) prediction remains a significant challenge in machine learning, particularly for tabular data where traditional methods often fail to generalize beyond their training distribution. This paper introduces Tabular Continual Contrastive Learning (TCCL), a novel framework designed to address OOD challenges in tabular data processing. TCCL integrates contrastive learning principles with continual learning mechanisms, featuring a three-component architecture: an Encoder for data transformation, a Decoder for representation learning, and a Learner Head. We evaluate TCCL against 14 baseline models, including state-of-the-art deep learning approaches and gradient-boosted decision trees (GBDT), across eight diverse tabular datasets. Our experimental results demonstrate that TCCL consistently outperforms existing methods in both classification and regression tasks on OOD data, with particular strength in handling distribution shifts. These findings suggest that TCCL represents a significant advancement in handling OOD scenarios for tabular data.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-167,2025,60.0,"Continual Contrastive Learning on Tabular Data with Out of Distribution Out-of-distribution (OOD) prediction remains a significant challenge in machine learning, particularly for tabular data where traditional methods often fail to generalize beyond their training distribution. This paper introduces Tabular Continual Contrastive Learning (TCCL), a novel framework designed to address OOD challenges in tabular data processing. TCCL integrates contrastive learning principles with continual learning mechanisms, featuring a three-component architecture: an Encoder for data transformation, a Decoder for representation learning, and a Learner Head. We evaluate TCCL against 14 baseline models, including state-of-the-art deep learning approaches and gradient-boosted decision trees (GBDT), across eight diverse tabular datasets. Our experimental results demonstrate that TCCL consistently outperforms existing methods in both classification and regression tasks on OOD data, with particular strength in handling distribution shifts. These findings suggest that TCCL represents a significant advancement in handling OOD scenarios for tabular data."
Benchmarking Data Augmentation for Contrastive Learning in Static Sign Language Recognition,"Ariel Basso Madjoukeng, Jérôme Fink, Pierre Poitier, Edith Kenmogne, Benoît Frénay","1 - University of Namur -NaDI -PReCISE -HuMaLearn Rue Grangagnage 21 5000 Namur Belgium
4 - Faculty of Sciences Foto University of Dschang 96 Dschang Cameroon","Sign language (SL) is a communication method used by deaf people. Static sign language recognition (SLR) is a challenging task aimed at identifying signs in images, for which acquisition of annotated data is time-consuming. To leverage unannotated data, practitioners have turned to unsupervised methods. Contrastive representation learning proved to be effective in capturing important features from unannotated data. It is known that the performance of the contrastive model depends on the data augmentation technique used during training. For various applications, a set of effective data augmentation has been identified, but it is not yet the case for SL. This paper identifies the most effective augmentation for static SLR. The results show a difference in accuracy of up to 30% between appearance-based augmentations combined with translations and augmentations based on rotations, erasing, or vertical flips.",Machine Learning Applied to Sign Language,https://doi.org/10.14428/esann/2023.ES2023-7,2025,58.53658536585367,"Benchmarking Data Augmentation for Contrastive Learning in Static Sign Language Recognition Sign language (SL) is a communication method used by deaf people. Static sign language recognition (SLR) is a challenging task aimed at identifying signs in images, for which acquisition of annotated data is time-consuming. To leverage unannotated data, practitioners have turned to unsupervised methods. Contrastive representation learning proved to be effective in capturing important features from unannotated data. It is known that the performance of the contrastive model depends on the data augmentation technique used during training. For various applications, a set of effective data augmentation has been identified, but it is not yet the case for SL. This paper identifies the most effective augmentation for static SLR. The results show a difference in accuracy of up to 30% between appearance-based augmentations combined with translations and augmentations based on rotations, erasing, or vertical flips."
Predictive Coding Dynamics Enhance Model-Brain Similarity,"Manshan Guo, Michael Samjatin, Bhavin Choksi, Sari Saba-Sadiya, Radoslaw Cichy, Gemma Roig","1 - Goethe Universität Frankfurt
2 - Freie Universität Berlin","Predictive coding-a popular theory in neuroscience-has garnered significant attention in the machine learning community aiming to incorporate brain-inspired components in neural networks. While various proposals have demonstrated the ability of predictive dynamics to render robustness and entail human-like perception of illusions, it remains unclear if they improve the alignment between brain and artificial representations. Here, we systematically investigate the conditions under which brain-inspired modifications in predictive processing improve alignment between model and neural representations in the brain. Our results reveal that the feedback component significantly increases similarity between model representations and those found in higher-level visual brain areas, especially when processing complex visual scenes.",Reinforcement learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-132.pdf,2025,54.54545454545454,"Predictive Coding Dynamics Enhance Model-Brain Similarity Predictive coding-a popular theory in neuroscience-has garnered significant attention in the machine learning community aiming to incorporate brain-inspired components in neural networks. While various proposals have demonstrated the ability of predictive dynamics to render robustness and entail human-like perception of illusions, it remains unclear if they improve the alignment between brain and artificial representations. Here, we systematically investigate the conditions under which brain-inspired modifications in predictive processing improve alignment between model and neural representations in the brain. Our results reveal that the feedback component significantly increases similarity between model representations and those found in higher-level visual brain areas, especially when processing complex visual scenes."
Resource-Aware Cooperation in Federated Learning,"Manuel Röder, Fabian Geiger, Frank-Michael Schleif","1 - Fac. of Computer Science Technical UAS Würzburg-Schweinfurt Würzburg DE
2 - Faculty of Technology Fac. of Business Management and Economics Bielefeld University 3 -JMU Bielefeld, Würzburg, Würzburg DE, DE","We present a novel Federated Learning framework, FedT4T, that systematically evaluates utility-driven client strategies under resource constraints. Recognizing the significant challenges in practical distributed learning environments, such as limited resources and non-cooperative behaviors, we model client interactions using the Iterated Prisoner's Dilemma. Our framework enables clients to adapt their decision rules based on prior interactions and available resources, optimizing both individual utility and collective contribution to solve a global learning task. We apply FedT4T to a Federated Learning benchmark classification task and explore the dynamics of cooperation between clients driven by common strategies from cooperation theory under the impact of varying resource availability. The code is publicly available at https://github.com/cairo-thws/FedT4T.","Federated Learning – Methods, Applications and Beyond",https://doi.org/10.14428/esann/2021.ES2021-4,2025,61.386138613861384,"Resource-Aware Cooperation in Federated Learning We present a novel Federated Learning framework, FedT4T, that systematically evaluates utility-driven client strategies under resource constraints. Recognizing the significant challenges in practical distributed learning environments, such as limited resources and non-cooperative behaviors, we model client interactions using the Iterated Prisoner's Dilemma. Our framework enables clients to adapt their decision rules based on prior interactions and available resources, optimizing both individual utility and collective contribution to solve a global learning task. We apply FedT4T to a Federated Learning benchmark classification task and explore the dynamics of cooperation between clients driven by common strategies from cooperation theory under the impact of varying resource availability. The code is publicly available at https://github.com/cairo-thws/FedT4T."
RAM: Retrieval Augmented Modelling for Tabular In-Context Few-Shot Domain Adaptation,"Oleh Kostromin, Felix Kossak, Michael Zwick",1 - Software Competence Center Hagenberg GmbH Softwarepark 32a 4232 Hagenberg Austria,"Transformer architectures have shown great success in natural language processing, sparking interest in their applications on tabular data. However, the potential of using transformer-like architectures for incontext domain adaptation in tabular settings remains underexplored. We introduce Retrieval-Augmented Modelling (RAM), a compact attentionbased architecture specifically designed for this task. RAM utilises a Domain-Aligned Memory training strategy, which ensures that it always processes the data from the same domain at each training step, allowing the model to focus on domain-specific patterns. Evaluated on synthetic data simulating domain shifts, RAM outperforms traditional machine learning models, effectively adapting to unseen domains.",Shallow and Deep models for transfer learning and domain adaptation,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-5.pdf,2025,50.72463768115942,"RAM: Retrieval Augmented Modelling for Tabular In-Context Few-Shot Domain Adaptation Transformer architectures have shown great success in natural language processing, sparking interest in their applications on tabular data. However, the potential of using transformer-like architectures for incontext domain adaptation in tabular settings remains underexplored. We introduce Retrieval-Augmented Modelling (RAM), a compact attentionbased architecture specifically designed for this task. RAM utilises a Domain-Aligned Memory training strategy, which ensures that it always processes the data from the same domain at each training step, allowing the model to focus on domain-specific patterns. Evaluated on synthetic data simulating domain shifts, RAM outperforms traditional machine learning models, effectively adapting to unseen domains."
Evaluating Concept Discovery Methods for Sensitive Attributes in Language Models,"Sarah Schröder, Alexander Schulz, Barbara Hammer",1 - Bielefeld University -AG Machine Learning Inspiration 1 33615 Bielefeld Germany,"This paper examines how to improve interpretability of language models in the context of fairness. While traditional concept learning focuses on identifying the most important concepts for a task, this study explores how to locate the representation of sensitive attributes in pretrained language models. We address challenges such as the potential low importance and sparsity of sensitive attributes in training data, and the limited amount of labeled data for this purpose. Our experiments evaluate potential methods to obtain such identity concepts, considering factors like label sparsity, generalizability, and the influence of different language models on the representation of sensitive attributes.",Language models,https://doi.org/10.14428/esann/2024.ES2024-206,2025,53.16455696202531,"Evaluating Concept Discovery Methods for Sensitive Attributes in Language Models This paper examines how to improve interpretability of language models in the context of fairness. While traditional concept learning focuses on identifying the most important concepts for a task, this study explores how to locate the representation of sensitive attributes in pretrained language models. We address challenges such as the potential low importance and sparsity of sensitive attributes in training data, and the limited amount of labeled data for this purpose. Our experiments evaluate potential methods to obtain such identity concepts, considering factors like label sparsity, generalizability, and the influence of different language models on the representation of sensitive attributes."
Expressivity vs. Generalization in Quantum Kernel Methods,"Markus Gross, Markus Lange, Bogusz Bujnowski, Hans-Martin Rieser",1 - DLR Institute for AI Safety and Security Sankt Augustin and Ulm Germany,"We analytically and numerically investigate the expressivity and generalization ability of quantum kernel models. We consider prototypical parallel encoding strategies and show that they give rise to simple universal forms of quantum kernels. By using qubit-dependent data rescaling schemes, we can exponentially vary the spectral content of the kernel and thereby control its simplicity bias. We obtain analytical results on the kernel eigenspectrum and connect it to theories of kernel generalization, which allow us to study the influence of expressivity on generalization error.",Informed Machine Learning for Complex Data,https://doi.org/10.14428/esann/2024.ES2024-20,2025,56.14035087719298,"Expressivity vs. Generalization in Quantum Kernel Methods We analytically and numerically investigate the expressivity and generalization ability of quantum kernel models. We consider prototypical parallel encoding strategies and show that they give rise to simple universal forms of quantum kernels. By using qubit-dependent data rescaling schemes, we can exponentially vary the spectral content of the kernel and thereby control its simplicity bias. We obtain analytical results on the kernel eigenspectrum and connect it to theories of kernel generalization, which allow us to study the influence of expressivity on generalization error."
Robustness in Protein-Protein Interaction Networks: A Link Prediction Approach,"Alessandro Dipalma, Domenico Tortorella, Alessio Micheli",1 - Department of Computer Science University of Pisa Largo B. Pontecorvo 3 56127 Pisa Italy,"Protein-protein interaction networks (PPINs) are indispensable in exploring complex biological systems, facilitating advancements in fields like drug discovery, protein function annotation, and disease mechanism elucidation. So far, predicting the dynamical properties of biochemical pathways has relied on costly numerical simulations. In this paper, we propose exploiting the topological information in PPINs to restate the problem of predicting pathway robustness as a link prediction task. Our experiments show that the PPIN topology can supply information on inter-pathway relationships, significantly improving predictions of the graph-agnostic baseline relying only on protein sequence embeddings.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-76.pdf,2025,68.91891891891892,"Robustness in Protein-Protein Interaction Networks: A Link Prediction Approach Protein-protein interaction networks (PPINs) are indispensable in exploring complex biological systems, facilitating advancements in fields like drug discovery, protein function annotation, and disease mechanism elucidation. So far, predicting the dynamical properties of biochemical pathways has relied on costly numerical simulations. In this paper, we propose exploiting the topological information in PPINs to restate the problem of predicting pathway robustness as a link prediction task. Our experiments show that the PPIN topology can supply information on inter-pathway relationships, significantly improving predictions of the graph-agnostic baseline relying only on protein sequence embeddings."
A feedback-loop approach for galaxy physical properties estimation,"Davide Zago, Giovanni Bonetta, Rossella Cancelliere, Mario Gai","1 - Department of Computer Science University of Turin 12 -10149 Turin Italy
2 - Fondazione Bruno Kessler via Sommarive, 18 -Povo 38123 Trento Italy
4 - Istituto Nazionale di Astrofisica Osservatorio Astrofisico di Torino V Osservatorio 20 10025 Pino Torinese (TO) Italy","Ongoing and forthcoming surveys promise great advances in our understanding of the Universe content and history, thanks to unprecedented improvements in the size and precision of observation datasets. On a cosmological scale, galaxies characteristics may be summarised by three main features, namely their redshift, stellar content mass and star formation rate, evolving throughout their lifetime. They are usually estimated from a set of photometric measurements, mapping their spectral emission. In this context, we propose a machine learning approach where we first evaluate redshift from the photometric data, and then merge it with them through a feedback loop, for subsequent estimation of the three desired parameters. In spite of its simplicity, our approach matches the performance of, and in some cases outperforms, significantly more complex previous tools exploiting also images. It achieves correct estimates on the near totality of instances for redshift and stellar mass, decreasing to about 70% on the more difficult case of SFR estimation.",Feature selection,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-41.pdf,2025,52.542372881355924,"A feedback-loop approach for galaxy physical properties estimation Ongoing and forthcoming surveys promise great advances in our understanding of the Universe content and history, thanks to unprecedented improvements in the size and precision of observation datasets. On a cosmological scale, galaxies characteristics may be summarised by three main features, namely their redshift, stellar content mass and star formation rate, evolving throughout their lifetime. They are usually estimated from a set of photometric measurements, mapping their spectral emission. In this context, we propose a machine learning approach where we first evaluate redshift from the photometric data, and then merge it with them through a feedback loop, for subsequent estimation of the three desired parameters. In spite of its simplicity, our approach matches the performance of, and in some cases outperforms, significantly more complex previous tools exploiting also images. It achieves correct estimates on the near totality of instances for redshift and stellar mass, decreasing to about 70% on the more difficult case of SFR estimation."
Generalized Stochastic Pooling,"Davide Bacciu, Francesco Landolfi","1 - Department of Computer Science Università di Pisa
2 - Largo Bruno Pontecorvo 56127 Pisa Italy","Pooling layers play a critical role in Convolutional Neural Networks by reducing spatial dimensions and enhancing translation invariance. While conventional methods like max pooling and average pooling are effective, they can respectively amplify noise or dilute important features. Stochastic pooling introduces probabilistic sampling to improve generalization but is susceptible to biases from outliers, often mimicking max pooling in such cases. To address these limitations, we propose a generalization of stochastic pooling that introduces a tunable parameter to control the balance between uniform sampling, stochastic pooling, and max pooling. Experiments on multiple datasets demonstrate that uniform sampling outperforms the biased one, achieving a favorable trade-off between regularization and performance.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-41.pdf,2025,56.25,"Generalized Stochastic Pooling Pooling layers play a critical role in Convolutional Neural Networks by reducing spatial dimensions and enhancing translation invariance. While conventional methods like max pooling and average pooling are effective, they can respectively amplify noise or dilute important features. Stochastic pooling introduces probabilistic sampling to improve generalization but is susceptible to biases from outliers, often mimicking max pooling in such cases. To address these limitations, we propose a generalization of stochastic pooling that introduces a tunable parameter to control the balance between uniform sampling, stochastic pooling, and max pooling. Experiments on multiple datasets demonstrate that uniform sampling outperforms the biased one, achieving a favorable trade-off between regularization and performance."
Quantum Tensor Network Learning with DMRG,"Gustav Jäger, Martin Plenio, Hans-Martin Rieser","1 - Deutsches Zentrum für Luft-und Raumfahrt e.V. -Institut für KI-Sicherheit Wilhelm-Runge-Straße 10 89081 Ulm Germany
2 - Universität Ulm -Institut für Theoretische Physik and IQST Albert-Einstein-Allee 11 89081 Ulm Germany","Tensor Networks are a relatively new machine learning approach. The architectures proposed initially are inspired by approaches from quantum many-body physics simulations. One common layout is the matrix product state (MPS) also known as a tensor train optimized with gradient descent techniques. We introduce a global normalization condition, so that the MPS represents a quantum state. We investigate two optimization methods that find the locally optimal tensors and compare them regarding their effectiveness. One is based on gradient descent and the other on an adaptation of DMRG.","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-80,2025,61.904761904761905,"Quantum Tensor Network Learning with DMRG Tensor Networks are a relatively new machine learning approach. The architectures proposed initially are inspired by approaches from quantum many-body physics simulations. One common layout is the matrix product state (MPS) also known as a tensor train optimized with gradient descent techniques. We introduce a global normalization condition, so that the MPS represents a quantum state. We investigate two optimization methods that find the locally optimal tensors and compare them regarding their effectiveness. One is based on gradient descent and the other on an adaptation of DMRG."
Investigating four deep learning approaches as candidates for unified models in time series forecasting and event prediction: application in anesthesia training,"Q Victor, I Clavier, H Boisaubert, F Picarougne, C Lejus-Bourdeau, C Sinoquet","1 - UMR 6004 Nantes University CNRS LS2N Nantes France
5 - LE SiMU / Nantes University Hospital Nantes University France","This paper explores deep learning architectures for the purposes of unsupervised representation learning of hybrid asynchronous data, and joint prediction tasks. We aim to forecast short-term multivariate time series contextualized by events and to predict events contextualized by time series. Our proof-of-concept examines a real-world case of digitally assisted training in anesthesia. We evaluate four different architectures, using two strategies to integrate both time series and event sequences in the models. We assess the prediction quality of the models, and demonstrate that only one of the four architectures achieves performance outcomes compatible with our application objective.","Towards Machine Learning Models that We Can Trust: Testing, Improving, and Explaining Robustness",https://doi.org/10.14428/esann/2023.ES2023-115,2025,50.16501650165017,"Investigating four deep learning approaches as candidates for unified models in time series forecasting and event prediction: application in anesthesia training This paper explores deep learning architectures for the purposes of unsupervised representation learning of hybrid asynchronous data, and joint prediction tasks. We aim to forecast short-term multivariate time series contextualized by events and to predict events contextualized by time series. Our proof-of-concept examines a real-world case of digitally assisted training in anesthesia. We evaluate four different architectures, using two strategies to integrate both time series and event sequences in the models. We assess the prediction quality of the models, and demonstrate that only one of the four architectures achieves performance outcomes compatible with our application objective."
Sleep Staging with Gradient Boosting and DWT-PSD Features from EEG/EOG Signals,"Luis Moctezuma, Yoko Suzuki, Junya Furuki, Marta Molinas, Takashi Abe","1 - International Institute for Integrative Sleep Medicine University of Tsukuba. Tsukuba Ibaraki Japan
4 - Department of Engineering Cybernetics Norwegian University of Science and Technology. Trondheim Norway","Advances in machine learning (ML) and deep learning (DL) have led to automated sleep staging approaches that achieve high accuracy but often require extensive computational resources and/or highdensity electroencephalograms (EEG). This paper presents a method for sleep staging using features extracted via the Discrete Wavelet Transform (DWT) and Power Spectral Density (PSD), followed by the Gradient Boosting (GB) classifier. The study employs a private dataset and the sleep-EDF dataset, comprising EEG and electrooculograms (EOG) channels. The analysis includes configurations with varying numbers of subjects (75, 20, and 12), and the results demonstrate that the proposed method achieves competitive performance with existing approaches that use complex DL architectures, even with fewer subjects. Feature importance analysis highlights the importance of detail coefficients from DWT and PSD-based features from EEG signals. The findings suggest that simplified methods using low-density EEG and EOG with wellselected features and GB classification can offer a viable alternative to DL approaches for sleep staging.",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-16,2025,52.76073619631902,"Sleep Staging with Gradient Boosting and DWT-PSD Features from EEG/EOG Signals Advances in machine learning (ML) and deep learning (DL) have led to automated sleep staging approaches that achieve high accuracy but often require extensive computational resources and/or highdensity electroencephalograms (EEG). This paper presents a method for sleep staging using features extracted via the Discrete Wavelet Transform (DWT) and Power Spectral Density (PSD), followed by the Gradient Boosting (GB) classifier. The study employs a private dataset and the sleep-EDF dataset, comprising EEG and electrooculograms (EOG) channels. The analysis includes configurations with varying numbers of subjects (75, 20, and 12), and the results demonstrate that the proposed method achieves competitive performance with existing approaches that use complex DL architectures, even with fewer subjects. Feature importance analysis highlights the importance of detail coefficients from DWT and PSD-based features from EEG signals. The findings suggest that simplified methods using low-density EEG and EOG with wellselected features and GB classification can offer a viable alternative to DL approaches for sleep staging."
SecureBFL: a Blockchain-enhanced federated learning architecture with MPC,"Tanguy Vansnick, Leandro Collier, Saïd Mahmoudi","1 - Faculty of Engineerging University of Mons -ILIA Rue de Houdain 9 7000 Mons Belgium
2 - Applied Research Center -CETIC Avenue Jean Mermoz 28 6041 Charleroi Belgium","The increasing demand for data in machine learning raises significant privacy concerns. Federated Learning (FL) enables multiple entities to train models collaboratively without sharing raw data. However, centralized FL (CFL) relies on a central server, making it vulnerable to poisoning attacks and single points of failure (SPOF). Decentralized FL (DFL) addresses these issues by removing the central server. This paper proposes a novel DFL architecture integrating blockchain for resisting attacks and Multi-Party Computation (MPC) for secure model parameter transfer. This architecture enhances security and confidentiality in collaborative learning without compromising result quality.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-34.pdf,2025,52.112676056338024,"SecureBFL: a Blockchain-enhanced federated learning architecture with MPC The increasing demand for data in machine learning raises significant privacy concerns. Federated Learning (FL) enables multiple entities to train models collaboratively without sharing raw data. However, centralized FL (CFL) relies on a central server, making it vulnerable to poisoning attacks and single points of failure (SPOF). Decentralized FL (DFL) addresses these issues by removing the central server. This paper proposes a novel DFL architecture integrating blockchain for resisting attacks and Multi-Party Computation (MPC) for secure model parameter transfer. This architecture enhances security and confidentiality in collaborative learning without compromising result quality."
Quantum Annealing based Feature Selection,"Daniel Pranjić, Bharadwaj Mummaneni, Christian Tutschku",1 - Fraunhofer Institute for Industrial Engineering -Nobelstr. 12 70569 Stuttgart Germany,"Feature selection is crucial for enhancing the accuracy and efficiency of machine learning models. Calculating the optimal feature set for maximum mutual information (MI) and conditional mutual information (CMI) remains computationally intractable for large datasets on classical computers, even with approximation methods. This study employs a Mutual Information Quadratic Unconstrained Binary Optimization (MIQUBO) formulation, enabling its solution on a quantum annealer. To showcase its real-world applicability, we apply MIQUBO to forecasting the price of used excavators. Our results indicate that using the MIQUBO approach there might be an improvement in the prediction of machine learning models for datasets, with a smaller MI concentration.",Quantum Artificial Intelligence,https://doi.org/10.14428/esann/2023.ES2023-99,2025,70.32967032967032,"Quantum Annealing based Feature Selection Feature selection is crucial for enhancing the accuracy and efficiency of machine learning models. Calculating the optimal feature set for maximum mutual information (MI) and conditional mutual information (CMI) remains computationally intractable for large datasets on classical computers, even with approximation methods. This study employs a Mutual Information Quadratic Unconstrained Binary Optimization (MIQUBO) formulation, enabling its solution on a quantum annealer. To showcase its real-world applicability, we apply MIQUBO to forecasting the price of used excavators. Our results indicate that using the MIQUBO approach there might be an improvement in the prediction of machine learning models for datasets, with a smaller MI concentration."
Explaining Outliers using Isolation Forest and Shapley Interactions,"Roel Visser, Fabian Fumagalli, Maximilian Muschalik, Eyke Hüllermeier, Barbara Hammer","1 - Bielefeld University D-33615 CITEC, Bielefeld Germany
3 - -LMU Munich MCML D-80539 Munich Germany","In unsupervised machine learning, Isolation Forest (IsoForest) is a widely used algorithm for the efficient detection of outliers. Identifying the features responsible for observed anomalies is crucial for practitioners, yet the ensemble nature of IsoForest complicates interpretation and comparison. As a remedy, SHAP is a prevalent method to interpret outlier scoring models by assigning contributions to individual features based on the Shapley Value (SV). However, complex anomalies typically involve interaction of features, and it is paramount for practitioners to distinguish such complex anomalies from simple cases. In this work, we propose Shapley Interactions (SIs) to enrich explanations of outliers with feature interactions. SIs, as an extension of the SV, decompose the outlier score into contributions of individual features and interactions of features up to a specified explanation order. We modify IsoForest to compute SI using TreeSHAP-IQ, an extension of TreeSHAP for tree-based models, using the shapiq package. Using a qualitative and quantitative analysis on synthetic and real-world datasets, we demonstrate the benefit of SI and feature interactions for outlier explanations over feature contributions alone.",Societal Issues in Machine Learning: When Learning from Data is Not Enough,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-124.pdf,2025,55.55555555555556,"Explaining Outliers using Isolation Forest and Shapley Interactions In unsupervised machine learning, Isolation Forest (IsoForest) is a widely used algorithm for the efficient detection of outliers. Identifying the features responsible for observed anomalies is crucial for practitioners, yet the ensemble nature of IsoForest complicates interpretation and comparison. As a remedy, SHAP is a prevalent method to interpret outlier scoring models by assigning contributions to individual features based on the Shapley Value (SV). However, complex anomalies typically involve interaction of features, and it is paramount for practitioners to distinguish such complex anomalies from simple cases. In this work, we propose Shapley Interactions (SIs) to enrich explanations of outliers with feature interactions. SIs, as an extension of the SV, decompose the outlier score into contributions of individual features and interactions of features up to a specified explanation order. We modify IsoForest to compute SI using TreeSHAP-IQ, an extension of TreeSHAP for tree-based models, using the shapiq package. Using a qualitative and quantitative analysis on synthetic and real-world datasets, we demonstrate the benefit of SI and feature interactions for outlier explanations over feature contributions alone."
Stability of State and Costate Dynamics in Continuous Time Recurrent Neural Networks,"Alessandro Betti, Marco Gori, Stefano Melacci","1 - IMT School for Advanced Studies Lucca Italy
2 - ""Human-Centered AI"" Università di Pisa, ""NextGenerationEU"" CUP I53C22001380006
3 - DIISM University of Siena Siena Italy","The notion of stability plays a crucial role in ensuring the safe development of a model in a lifelong learning context. This paper investigates the fundamental aspects of stability in a class of continuous-time recurrent neural networks which include both state and costate variables. The latter are directly inherited from optimal control theory, and they act as adjoint variables closely related to gradient terms. Stability is investigated both in terms of state and of costate dynamics, showing the key conditions that must be satisfied to produce bounded dynamics in the forward and learning stages.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-38.pdf,2025,62.65060240963856,"Stability of State and Costate Dynamics in Continuous Time Recurrent Neural Networks The notion of stability plays a crucial role in ensuring the safe development of a model in a lifelong learning context. This paper investigates the fundamental aspects of stability in a class of continuous-time recurrent neural networks which include both state and costate variables. The latter are directly inherited from optimal control theory, and they act as adjoint variables closely related to gradient terms. Stability is investigated both in terms of state and of costate dynamics, showing the key conditions that must be satisfied to produce bounded dynamics in the forward and learning stages."
Towards Streaming Land Use Classification of Images with Temporal Distribution Shifts,"Lorenzo Iovine, Giacomo Ziffer, Andrea Proia, Emanuele Valle","1 - Politecnico di Milano -DEIB Via Ponzio 34/5 Milan Italy
3 - Motus ml Viale Premuda 20 Milan Italy
4 - Thales Alenia Space Italia Via Saccomuro 24 Rome Italy","In this study, we introduce a new pipeline that integrates Streaming Machine Learning (SML) models and the Momentum Contrastive Learning (MoCo) technique for the streaming classification of satellite images subject to temporal variations in distribution. We present preliminary results of an experimental campaign conducted on the Functional Map of the World-Time dataset, one of the first benchmarks specifically designed to address temporal distribution shifts in satellite imagery. The results demonstrate that the proposed pipeline enhances robustness and generalization over time, surpassing traditional strategies.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-113.pdf,2025,55.172413793103445,"Towards Streaming Land Use Classification of Images with Temporal Distribution Shifts In this study, we introduce a new pipeline that integrates Streaming Machine Learning (SML) models and the Momentum Contrastive Learning (MoCo) technique for the streaming classification of satellite images subject to temporal variations in distribution. We present preliminary results of an experimental campaign conducted on the Functional Map of the World-Time dataset, one of the first benchmarks specifically designed to address temporal distribution shifts in satellite imagery. The results demonstrate that the proposed pipeline enhances robustness and generalization over time, surpassing traditional strategies."
O-Net: a Brain Tumor Segmentation Architecture Based on U-Net Using Alternated Pooling,"Omar El Barraj, Aya Hage Chehade, Jean Marion, Mohamad Oueidat, Pierre Chauvet, Nassib Abdallah","1 - LARIS University of Angers Angers France
2 - LabISEN Yncrea Ouest Brest France
4 - Faculty of Technology UMR 1101 Lebanese University Beirut -Lebanon 4-LaTIM INSERM University of Brest Brest France","Deep Learning (DL) offers promising tools for improving diagnostic processes in healthcare. Automated brain tumor segmentation using multi-parametric multimodal Magnetic Resonance Imaging (mpMRI) plays a vital role in the clinical management of brain tumor patients, enabling precise delineation of tumor regions. In this paper, we present O-Net, a deep learning model inspired by the U-Net architecture. O-Net employs an ensemble of two mirrored U-Nets with alternating pooling strategies -Max and Average Pooling-to enhance feature extraction. Our approach demonstrates the potential to improve segmentation accuracy using the BraTS 2021 training dataset and highlights the advantages of combining complementary pooling strategies for this task.",Recurrent networks and modeling,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-5.pdf,2025,52.94117647058824,"O-Net: a Brain Tumor Segmentation Architecture Based on U-Net Using Alternated Pooling Deep Learning (DL) offers promising tools for improving diagnostic processes in healthcare. Automated brain tumor segmentation using multi-parametric multimodal Magnetic Resonance Imaging (mpMRI) plays a vital role in the clinical management of brain tumor patients, enabling precise delineation of tumor regions. In this paper, we present O-Net, a deep learning model inspired by the U-Net architecture. O-Net employs an ensemble of two mirrored U-Nets with alternating pooling strategies -Max and Average Pooling-to enhance feature extraction. Our approach demonstrates the potential to improve segmentation accuracy using the BraTS 2021 training dataset and highlights the advantages of combining complementary pooling strategies for this task."
Proactive Privacy Risk Assessment for Android Applications: A Machine Learning Based-Approach,"Narjes Doggaz, Aissa Trad, Hella Kaffel, Ben Ayed",1 - Faculty of Sciences of Tunis LIPAH Research Lab. Campus Universitaire El-Manar University of Tunis El-Manar 2092 El-Manar Tunis Tunisia,"Mobile devices have become ubiquitous, collecting vast amounts of personal data through granted permissions. Privacy concerns arise when personal information is leaked to third parties without the user's awareness or consent. To address this issue, we propose a proactive approach based on a Machine Learning model to predict privacy risk scores for Android applications. These scores are based on the requested permissions and allow the users to be aware of the potential leakage of sensitive information before installing an application. Experimental evaluations demonstrate the competitive performance of our model against existing state-of-the-art methods.",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-34,2025,52.94117647058824,"Proactive Privacy Risk Assessment for Android Applications: A Machine Learning Based-Approach Mobile devices have become ubiquitous, collecting vast amounts of personal data through granted permissions. Privacy concerns arise when personal information is leaked to third parties without the user's awareness or consent. To address this issue, we propose a proactive approach based on a Machine Learning model to predict privacy risk scores for Android applications. These scores are based on the requested permissions and allow the users to be aware of the potential leakage of sensitive information before installing an application. Experimental evaluations demonstrate the competitive performance of our model against existing state-of-the-art methods."
Can MDS rival with t-SNE by using the symmetric Kullback-Leibler divergence across neighborhoods as a pseudo-distance?,"John Lee, Pierre Lambert, Edouard Couplet, Pierre Merveille, Ludovic Journaux, Dounia Mulders, Cyril De Bodt, Michel Verleysen","1 - Institut Agro Dijon -Laboratoire d'Informatique de Bourgogne Boulevard Docteur Petitjean 26 21079 Dijon France
2 - 1-UCLouvain -IREC/MIRO Avenue Hippocrate 55 1200 Brussels Belgium
3 - UCLouvain -ICTEAM/ELEN Place du Levant 3 1348 Louvain-la-Neuve Belgium","Local methods of dimensionality reduction like neighborhood embedding (NE) and t-SNE in particular outperform older global approaches such as stress-based multi-dimensional scaling (MDS). Stochastic neighborhoods are less sensitive than distances to statistical variations between spaces with strongly different dimensionalities, making a match across them very difficult. Here, we take inspiration from those stochastic neighborhoods in order to devise a pseudo-distance that is less prone to concentration than the Euclidean distance. For two points in the high-dimensional data space, it is defined as the symmetrized Kullback-Leibler divergence across the (stochastic) neighborhoods of the two points (SKLAN). Plugging the SKLAN in a method of stress-based MDS, we compare quantitatively t-SNE, MDS with all Euclidean distances, and MDS with SKLAN & Euclidean distances on several data sets. The results show that SKLAN allows MDS to perform competitively with t-SNE. 
 Dimensionality reduction and motivation Dimensionality reduction (DR) aims at representing high-dimensional (HD) data with low-dimensional (LD) embeddings, in which salient features of data are preserved or even highlighted. Such features can be for instance variance in principal component analysis (PCA)  [1] , distances in multidimensional scaling (MDS)  [2] , or similarities in neighbor embedding (NE)  [3] . Most of the current, state-of-the-art methods of DR stem from the family of neighbor embedding, with stochastic neighbor embedding (SNE)  [4]  as their common but forgotten ancestor. The celebrity in the family remains undoubtedly t-SNE [5], probably because of its capability to amplify cluster gaps in the embeddings, on top of overall good performance at DR. Neighbor embedding in general and t-SNE in particular have dusted previous paradigms of DR, and notably so for MDS. Stress-based MDS consists in finding embedding coordinates such that LD distances match those in HD  [2] . In contrast, NE determines the embedding by",Feature selection and dimension reduction,https://doi.org/10.14428/esann/2023.ES2023-147,2025,46.58634538152611,"Can MDS rival with t-SNE by using the symmetric Kullback-Leibler divergence across neighborhoods as a pseudo-distance? Local methods of dimensionality reduction like neighborhood embedding (NE) and t-SNE in particular outperform older global approaches such as stress-based multi-dimensional scaling (MDS). Stochastic neighborhoods are less sensitive than distances to statistical variations between spaces with strongly different dimensionalities, making a match across them very difficult. Here, we take inspiration from those stochastic neighborhoods in order to devise a pseudo-distance that is less prone to concentration than the Euclidean distance. For two points in the high-dimensional data space, it is defined as the symmetrized Kullback-Leibler divergence across the (stochastic) neighborhoods of the two points (SKLAN). Plugging the SKLAN in a method of stress-based MDS, we compare quantitatively t-SNE, MDS with all Euclidean distances, and MDS with SKLAN & Euclidean distances on several data sets. The results show that SKLAN allows MDS to perform competitively with t-SNE. 
 Dimensionality reduction and motivation Dimensionality reduction (DR) aims at representing high-dimensional (HD) data with low-dimensional (LD) embeddings, in which salient features of data are preserved or even highlighted. Such features can be for instance variance in principal component analysis (PCA)  [1] , distances in multidimensional scaling (MDS)  [2] , or similarities in neighbor embedding (NE)  [3] . Most of the current, state-of-the-art methods of DR stem from the family of neighbor embedding, with stochastic neighbor embedding (SNE)  [4]  as their common but forgotten ancestor. The celebrity in the family remains undoubtedly t-SNE [5], probably because of its capability to amplify cluster gaps in the embeddings, on top of overall good performance at DR. Neighbor embedding in general and t-SNE in particular have dusted previous paradigms of DR, and notably so for MDS. Stress-based MDS consists in finding embedding coordinates such that LD distances match those in HD  [2] . In contrast, NE determines the embedding by"
Towards metacognitive agents: integrating confidence in sequential decision-making,"B Pesquet, F Alexandre",1 - INRIA University of Bordeaux CNRS Bordeaux INP France,"In natural cognition, confidence is used to evaluate the quality of decisions and adapt one's behavior to the task at hand. For now, artificial agents lack this kind of metacognitive ability and interact with their environment in a purely reactive way. Inspired by recent findings about the cognitive modeling of confidence, we propose a novel architecture for sequential decision-making. It combines an evidence accumulation model with a metacognitive module that computes and exploits confidence to tune the decision process. The model has been assessed on a perceptual decision-making task, showing promises for more flexible artificial agents and a possible path towards artificial metacognition.",Incremental learning algorithms and applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-160.pdf,2025,54.358974358974365,"Towards metacognitive agents: integrating confidence in sequential decision-making In natural cognition, confidence is used to evaluate the quality of decisions and adapt one's behavior to the task at hand. For now, artificial agents lack this kind of metacognitive ability and interact with their environment in a purely reactive way. Inspired by recent findings about the cognitive modeling of confidence, we propose a novel architecture for sequential decision-making. It combines an evidence accumulation model with a metacognitive module that computes and exploits confidence to tune the decision process. The model has been assessed on a perceptual decision-making task, showing promises for more flexible artificial agents and a possible path towards artificial metacognition."
Do not get lost in projection: finding the right distance for meaningful UMAP embeddings,"Eva Blanco-Mallo, Verónica Bolón-Canedo, Beatriz Remeseiro","1 - CITIC Universidade da Coruña, A Coruña Spain
3 - Universidad de Oviedo Gijón Spain
4 - Grants PID2019-109238GB-C22, PID2023-147404OB-I00, TED2021-130599A-I00, PID2021-128045OA-I00","Dimensionality reduction techniques are essential for visualizing and analyzing high-dimensional data. This study explores the impact of distance measures on the performance of Uniform Manifold Approximation and Projection (UMAP), a widely used dimensionality reduction method. We evaluate their influence on cluster separation, structure preservation, and their effectiveness when used as a preprocessing step for classification tasks on real and synthetic datasets. The results highlight the importance of tailoring distance measures to specific data contexts and provide guidance for optimizing UMAP applications.","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-3,2025,49.43820224719101,"Do not get lost in projection: finding the right distance for meaningful UMAP embeddings Dimensionality reduction techniques are essential for visualizing and analyzing high-dimensional data. This study explores the impact of distance measures on the performance of Uniform Manifold Approximation and Projection (UMAP), a widely used dimensionality reduction method. We evaluate their influence on cluster separation, structure preservation, and their effectiveness when used as a preprocessing step for classification tasks on real and synthetic datasets. The results highlight the importance of tailoring distance measures to specific data contexts and provide guidance for optimizing UMAP applications."
Replay-free Online Continual Learning with Self-Supervised MultiPatches,"Giacomo Cignoni, Andrea Cossu, Alex Gómez Villa, Joost Van De Weijer, Antonio Carta","1 - University of Pisa
3 - Computer Vision Center (CVC)","Online Continual Learning (OCL) methods train a model on a non-stationary data stream where only a few examples are available at a time, often leveraging replay strategies. However, usage of replay is sometimes forbidden, especially in applications with strict privacy regulations. Therefore, we propose Continual MultiPatches (CMP), an effective plugin for existing OCL self-supervised learning strategies that avoids the use of replay samples. CMP generates multiple patches from a single example and projects them into a shared feature space, where patches coming from the same example are pushed together without collapsing into a single point. CMP surpasses replay and other SSL-based strategies on OCL streams, challenging the role of replay as a go-to solution for self-supervised OCL. Code available at https://github.com/giacomo-cgn/cmp .",Reinforcement learning and Evolutionary computation,https://doi.org/10.14428/esann/2023.ES2023-181,2025,60.0,"Replay-free Online Continual Learning with Self-Supervised MultiPatches Online Continual Learning (OCL) methods train a model on a non-stationary data stream where only a few examples are available at a time, often leveraging replay strategies. However, usage of replay is sometimes forbidden, especially in applications with strict privacy regulations. Therefore, we propose Continual MultiPatches (CMP), an effective plugin for existing OCL self-supervised learning strategies that avoids the use of replay samples. CMP generates multiple patches from a single example and projects them into a shared feature space, where patches coming from the same example are pushed together without collapsing into a single point. CMP surpasses replay and other SSL-based strategies on OCL streams, challenging the role of replay as a go-to solution for self-supervised OCL. Code available at https://github.com/giacomo-cgn/cmp ."
Explainable deep learning reveals a behavioral strategy underlying human decisions in a spatial navigation task,"Youri Marquise, Bilel Abderrahmane Benziane, Hachim Bani, David Romano-Lambert, Youssouf Cherifi, Denis Sheynikhovich","1 - Institut de la Vision Sorbonne University INSERM CNRS 2-L@bISEN F-75012 Paris France
2 - Usine du Futur ISEN Yncrea Ouest and DataLab Generix Group France
7 - Centre for Robotics -Mines Paris PSL Research University CAOR France","This paper uses a set of explainable AI (xAI) methods to study human behavior in a spatial navigation task. First, locomotion and gaze dynamics of human subjects recorded during the task were reproduced in a virtual environment and visual snapshots extracted from this simulation were used as a dataset. Second, the dataset was used to train a deep convolutional network to reproduce human navigation decisions. Third, network strategies used for image classification were analyzed using a combination of three xAI methods. Using this analysis, we discovered a specific oculomotor marker that indicated the behavioral strategy used by human participants in this task. We conclude that xAI is a promising approach to study human behavior in complex real-world tasks.",Dynamical systems and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-129.pdf,2025,50.21645021645021,"Explainable deep learning reveals a behavioral strategy underlying human decisions in a spatial navigation task This paper uses a set of explainable AI (xAI) methods to study human behavior in a spatial navigation task. First, locomotion and gaze dynamics of human subjects recorded during the task were reproduced in a virtual environment and visual snapshots extracted from this simulation were used as a dataset. Second, the dataset was used to train a deep convolutional network to reproduce human navigation decisions. Third, network strategies used for image classification were analyzed using a combination of three xAI methods. Using this analysis, we discovered a specific oculomotor marker that indicated the behavioral strategy used by human participants in this task. We conclude that xAI is a promising approach to study human behavior in complex real-world tasks."
Efficient Training of Neural SDEs Using Stochastic Optimal Control,"Rembert Daems, Manfred Opper, Guillaume Crevecoeur, Tolga Birdal","1 - Dept. of Theor. Comp. Science Technical University of Berlin Germany
2 - Inst. of Mathematics University of Potsdam Germany
3 - Centre for Sys. Modelling and Quant. Biomed University of Birmingham UK
4 - Dept. of Computing Imperial College London UK
5 - Ghent University 1-D2Lab Belgium
6 - Belgium","We present a hierarchical, control theory inspired method for variational inference (VI) for neural stochastic differential equations (SDEs). While VI for neural SDEs is a promising avenue for uncertaintyaware reasoning in time-series, it is computationally challenging due to the iterative nature of maximizing the ELBO. In this work, we propose to decompose the control term into linear and residual non-linear components and derive an optimal control term for linear SDEs, using stochastic optimal control. Modeling the non-linear component by a neural network, we show how to efficiently train neural SDEs without sacrificing their expressive power. Since the linear part of the control term is optimal and does not need to be learned, the training is initialized at a lower cost and we observe faster convergence.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-57,2025,54.13533834586466,"Efficient Training of Neural SDEs Using Stochastic Optimal Control We present a hierarchical, control theory inspired method for variational inference (VI) for neural stochastic differential equations (SDEs). While VI for neural SDEs is a promising avenue for uncertaintyaware reasoning in time-series, it is computationally challenging due to the iterative nature of maximizing the ELBO. In this work, we propose to decompose the control term into linear and residual non-linear components and derive an optimal control term for linear SDEs, using stochastic optimal control. Modeling the non-linear component by a neural network, we show how to efficiently train neural SDEs without sacrificing their expressive power. Since the linear part of the control term is optimal and does not need to be learned, the training is initialized at a lower cost and we observe faster convergence."
A new approach to multilayer SVMs,"Joan Acero-Pousa, Lluís Belanche-Muñoz",1 - School of Computer Science Jordi Girona 1-3 08034 Barcelona Catalonia Spain,"Despite the traditional high performance of Support Vector Machines (SVMs) in classification and regression tasks, modern data loads have introduced new efficiency challenges, rendering SVMs incapable of handling non-linear problems when the dataset size is large. On the other hand, neural architectures have shown excellent results when dealing with complex patterns in data. By leveraging kernel approximation techniques and linear optimizations, this work introduces a multilayer SVM architecture, presenting competitive performance against classical SVMs.",Image and video analysis,https://www.esann.org/sites/default/files/proceedings/legacy/es2010-85.pdf,2025,50.0,"A new approach to multilayer SVMs Despite the traditional high performance of Support Vector Machines (SVMs) in classification and regression tasks, modern data loads have introduced new efficiency challenges, rendering SVMs incapable of handling non-linear problems when the dataset size is large. On the other hand, neural architectures have shown excellent results when dealing with complex patterns in data. By leveraging kernel approximation techniques and linear optimizations, this work introduces a multilayer SVM architecture, presenting competitive performance against classical SVMs."
Membership Inference Attack in Random Forests,"Fatemeh Akbarian, Amir Aminifar",1 - Department of Electrical and Information Technology Lund University Sweden,"Machine Learning (ML) offers many opportunities, but its reliance on personal data raises privacy concerns. One such example is the Membership Inference Attack (MIA), which aims to determine whether a specific data point was part of a model's training dataset. In this paper, we investigate this attack on Random Forests (RFs) and propose a method to quantify their vulnerability to MIA. We also demonstrate that in collaborative setups like federated learning, a client with access to the model and partial training dataset can establish MIA against other clients' training data. The effectiveness of our method is validated through experiments.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-48.pdf,2025,53.333333333333336,"Membership Inference Attack in Random Forests Machine Learning (ML) offers many opportunities, but its reliance on personal data raises privacy concerns. One such example is the Membership Inference Attack (MIA), which aims to determine whether a specific data point was part of a model's training dataset. In this paper, we investigate this attack on Random Forests (RFs) and propose a method to quantify their vulnerability to MIA. We also demonstrate that in collaborative setups like federated learning, a client with access to the model and partial training dataset can establish MIA against other clients' training data. The effectiveness of our method is validated through experiments."
Adaptive Locally Aligned Ant Technique for Manifold Detection and Denoising,"Felipe Contreras, Kerstin Bunte, Reynier Peletier","1 - University of Groningen Netherlands
2 - Universidad de Valparaíso Chile","The detection and extraction of noisy manifolds from data have various applications. In Astronomy, the detection of faint streams and filaments is particularly difficult due to background contamination, which immerses and hides them in noise. The biologically inspired Locally Aligned Ant Technique (LAAT) has been demonstrated as an efficient and flexible algorithm to detect and denoise versatile structures within noisy backgrounds. Our contribution extends LAAT two-fold: (1) introduction of a dynamic local radius, and (2) locally variable pheromone deposition. The former avoids highlighting spurious patterns in noisy regions and allows smaller jumps in areas with strong alignment. The latter increases pheromone deposition in fainter zones. We demonstrate this in 2 datasets. * support by the National Agency for Research and Development scholarship 2020-21200114. 1 1-DREAM code publicly available at https://git.lwp.rug.nl/cs.projects/1DREAM",Supervised learning,https://doi.org/10.14428/esann/2021.ES2021-34,2025,52.63157894736843,"Adaptive Locally Aligned Ant Technique for Manifold Detection and Denoising The detection and extraction of noisy manifolds from data have various applications. In Astronomy, the detection of faint streams and filaments is particularly difficult due to background contamination, which immerses and hides them in noise. The biologically inspired Locally Aligned Ant Technique (LAAT) has been demonstrated as an efficient and flexible algorithm to detect and denoise versatile structures within noisy backgrounds. Our contribution extends LAAT two-fold: (1) introduction of a dynamic local radius, and (2) locally variable pheromone deposition. The former avoids highlighting spurious patterns in noisy regions and allows smaller jumps in areas with strong alignment. The latter increases pheromone deposition in fainter zones. We demonstrate this in 2 datasets. * support by the National Agency for Research and Development scholarship 2020-21200114. 1 1-DREAM code publicly available at https://git.lwp.rug.nl/cs.projects/1DREAM"
Reinforcement learning-based control system for biogas plants in laboratory scale,"Alberto Meola, Oliver Kiefner, Félix Delory, Sören Weinrich","1 - Faculty of Mathematics and Computer Science Leipzig University Augustusplatz 10 04109 Leipzig Germany
3 - Faculty of Energy • Building Servi-ces • Environmental Engineering Münster University of Applied Sciences Stegerwaldstraße 39 48565 Steinfurt Germany
4 - Bio-chemical Conversion Department Deutsches Biomasseforschungszentrum gemeinnützige GmbH 1 -DBFZ, Torgauer Straße 116 04347 Leipzig Germany","Reinforcement learning techniques can be used to learn effective policies for complex tasks, but they are rarely applied for control of biogas plants. While control of the anaerobic process is necessary for optimal plant operation, process complexity and instability prevent the usage of advanced control mechanisms in industrial settings. In this study, a proximal-policy optimization algorithm has been applied on the feeding schedule of a lab-scale biogas reactor for biomethane conversion to electrical energy depending on dynamic energy prices. The algorithm effectively optimizes feeding and selling strategies, outperforming traditional methods.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-203.pdf,2025,51.315789473684205,"Reinforcement learning-based control system for biogas plants in laboratory scale Reinforcement learning techniques can be used to learn effective policies for complex tasks, but they are rarely applied for control of biogas plants. While control of the anaerobic process is necessary for optimal plant operation, process complexity and instability prevent the usage of advanced control mechanisms in industrial settings. In this study, a proximal-policy optimization algorithm has been applied on the feeding schedule of a lab-scale biogas reactor for biomethane conversion to electrical energy depending on dynamic energy prices. The algorithm effectively optimizes feeding and selling strategies, outperforming traditional methods."
Generating Synthetic Spectral Data using Conditional DDPM,"Fabian Kubiczek, Stefan Patzke, Jörg Thiem",1 - Sciences and Arts Dortmund -Information Technology Sonnenstr. 96 University of Applied 44139 Dortmund Germany,"This study investigates the efficiency and effectiveness of Denoising Diffusion Probabilistic Models (DDPM) for generating synthetic spectral data. A modified DDPM was implemented and evaluated in comparison to a previously established model. Both models were trained with and without Classifier-Free Guidance (CFG). In addition, training duration and sample generation are compared. The results demonstrate that the synthetic spectral data exhibits a high degree of alignment with the training data, with only minor deviations. Furthermore, the influence of CFG on the generation process is evident. The findings indicate that the modified DDPM performs better on the given data.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-25.pdf,2025,55.319148936170215,"Generating Synthetic Spectral Data using Conditional DDPM This study investigates the efficiency and effectiveness of Denoising Diffusion Probabilistic Models (DDPM) for generating synthetic spectral data. A modified DDPM was implemented and evaluated in comparison to a previously established model. Both models were trained with and without Classifier-Free Guidance (CFG). In addition, training duration and sample generation are compared. The results demonstrate that the synthetic spectral data exhibits a high degree of alignment with the training data, with only minor deviations. Furthermore, the influence of CFG on the generation process is evident. The findings indicate that the modified DDPM performs better on the given data."
JEPA for RL: Investigating Joint-Embedding Predictive Architectures for Reinforcement Learning,"Tristan Kenneweg, Philip Kenneweg, Barbara Hammer",1 - University of Bielefeld -Technical Faculty Universitaetsstrasse 25 33615 Bielefeld Germany,"Joint-Embedding Predictive Architectures (JEPA) have recently become popular as promising architectures for self-supervised learning. Vision transformers have been trained using JEPA to produce embeddings from images and videos, which have been shown to be highly suitable for downstream tasks like classification and segmentation. In this paper, we show how to adapt the JEPA architecture to reinforcement learning from images. We discuss model collapse, show how to prevent it, and provide exemplary data on the classical Cart Pole task.","Reinforcement learning, control and optimization",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-93.pdf,2025,56.57894736842105,"JEPA for RL: Investigating Joint-Embedding Predictive Architectures for Reinforcement Learning Joint-Embedding Predictive Architectures (JEPA) have recently become popular as promising architectures for self-supervised learning. Vision transformers have been trained using JEPA to produce embeddings from images and videos, which have been shown to be highly suitable for downstream tasks like classification and segmentation. In this paper, we show how to adapt the JEPA architecture to reinforcement learning from images. We discuss model collapse, show how to prevent it, and provide exemplary data on the classical Cart Pole task."
Comparing Modern LLM Quantization Methods Across Natural Languages,"Maksym Iakovenko, Stéphane Dupont",1 - University of Mons -MAIA Unit Mons Belgium,"Weight quantization has become a key tool for democratizing access to large language models (LLMs). Despite the technique's growing popularity and potential to aid speakers of diverse languages worldwide, new LLM quantization methods are predominantly validated in monolingual English contexts. This study explores ways to consistently evaluate the multilingual performance of a variety of LLaMA-based models under different quantization configurations. We identify links between the multilingual performance of widely adopted LLM quantization methods and multiple factors such as language's prevalence in the training set and similarity to model's dominant language. 1 The evaluation code alongside extended evaluation results are available at https:// github.com/MaksymIakovenko/llm_quant_across_langs.",Language models,https://doi.org/10.14428/esann/2024.ES2024-143,2025,52.33644859813084,"Comparing Modern LLM Quantization Methods Across Natural Languages Weight quantization has become a key tool for democratizing access to large language models (LLMs). Despite the technique's growing popularity and potential to aid speakers of diverse languages worldwide, new LLM quantization methods are predominantly validated in monolingual English contexts. This study explores ways to consistently evaluate the multilingual performance of a variety of LLaMA-based models under different quantization configurations. We identify links between the multilingual performance of widely adopted LLM quantization methods and multiple factors such as language's prevalence in the training set and similarity to model's dominant language. 1 The evaluation code alongside extended evaluation results are available at https:// github.com/MaksymIakovenko/llm_quant_across_langs."
Encoding Matters: Impact of Categorical Variable Encoding on Performance and Bias,"Daniel Kopp, Benjamin Maudet, Lisheng Sun-Hosoya, Kristin Bennett",Unknown,"Encoding categorical variables impacts model performance and can introduce bias in supervised learning, particularly affecting fairness when some groups are under-represented. We analyze the effects of different encoding methods on synthetic and real datasets to mitigate unintended model reliance on specific variables. We propose CaVaR (Categorical Variable Reliance) to quantify model reliance on variables and an Availability Index to measure CaVaR's sensitivity to partial encoding changes. A high Availability Disparity, measured by the standard deviation of the Availability Index across encodings, highlights potential bias from mixed encodings. The results suggest encoding all categorical variables uniformly, regardless of their ordinal or nominal nature, may reduce bias, with the choice guided by computational and performance considerations.",Deep learning and image processing,https://doi.org/10.14428/esann/2021.ES2021-130,2025,52.4390243902439,"Encoding Matters: Impact of Categorical Variable Encoding on Performance and Bias Encoding categorical variables impacts model performance and can introduce bias in supervised learning, particularly affecting fairness when some groups are under-represented. We analyze the effects of different encoding methods on synthetic and real datasets to mitigate unintended model reliance on specific variables. We propose CaVaR (Categorical Variable Reliance) to quantify model reliance on variables and an Availability Index to measure CaVaR's sensitivity to partial encoding changes. A high Availability Disparity, measured by the standard deviation of the Availability Index across encodings, highlights potential bias from mixed encodings. The results suggest encoding all categorical variables uniformly, regardless of their ordinal or nominal nature, may reduce bias, with the choice guided by computational and performance considerations."
Data-Density guided Reinforcement Learning,"Leon Lantz, Maximilian Schieder, Michel Tokic","1 - Department of Computer Science -LMU Munich Geschwister-Scholl Platz 1 80539 Munich Germany
4 - Siemens AG -Foundational Technologies Otto-Hahn-Ring 6 81379 Munich Germany","This paper investigates reinforcement learning by avoiding low-density state regions using modified reward functions. The approach leverages data-density models within the state space, enabling a custom reward function that penalizes transitions into sparse regions. Applied in the Pendulum environment, this method encourages exploration in wellsampled areas while avoiding less-explored states. Empirical results show that this method effectively balances reward optimization with state confidence, enabling robust policy learning in challenging environments.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-84.pdf,2025,65.1685393258427,"Data-Density guided Reinforcement Learning This paper investigates reinforcement learning by avoiding low-density state regions using modified reward functions. The approach leverages data-density models within the state space, enabling a custom reward function that penalizes transitions into sparse regions. Applied in the Pendulum environment, this method encourages exploration in wellsampled areas while avoiding less-explored states. Empirical results show that this method effectively balances reward optimization with state confidence, enabling robust policy learning in challenging environments."
Enhancing Image Classification in Quantum Computing: A Study on Preprocessing Techniques and Qubit Limitations,"Henrique Barbosa, Gustavo Pires, Juliana Alves, Luiz Torres, Janier Garcia, Frederico Coelho","1 - Federal University of Minas Gerais -UFMG Belo Horizonte MG Brazil
4 - Federal University of Ouro Preto -UFOP Ouro Preto MG Brazil","Quantum algorithms present unique advantages over classical methods but remain constrained by the limited number of qubits in current quantum computers. This limitation hinders their effectiveness in machine learning tasks, such as image classification. Despite its relevance, the impact of these constraints on quantum machine learning remains underexplored. This study addresses this gap by analyzing preprocessing techniques for preparing images on quantum processors. We evaluated 10 dimensionality reduction methods across four standard datasets using three distinct quantum neural network architectures. The results provide valuable insights into optimizing classification efficiency under qubit constraints, paving the way for broader applications of quantum machine learning.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-155.pdf,2025,55.319148936170215,"Enhancing Image Classification in Quantum Computing: A Study on Preprocessing Techniques and Qubit Limitations Quantum algorithms present unique advantages over classical methods but remain constrained by the limited number of qubits in current quantum computers. This limitation hinders their effectiveness in machine learning tasks, such as image classification. Despite its relevance, the impact of these constraints on quantum machine learning remains underexplored. This study addresses this gap by analyzing preprocessing techniques for preparing images on quantum processors. We evaluated 10 dimensionality reduction methods across four standard datasets using three distinct quantum neural network architectures. The results provide valuable insights into optimizing classification efficiency under qubit constraints, paving the way for broader applications of quantum machine learning."
Hierarchical Residuals Exploit Brain-Inspired Compositionality,"Francisco López, Jochen Triesch","1 - Frankfurt Institute for Advanced Studies Ruth Moufang-Str. 1 60438 Frankfurt Germany
2 - Xidian-FIAS International Joint Research Center Ruth Moufang-Str. 1 60438 Frankfurt Germany
4 - 64 Average pooling Fully connected Input Output Conv 3x3 Conv 3x3, 16, /2 Conv 3x3, 16 Conv 3x3, 16 Conv 3x3, 16 Conv 3x3, 16 Conv 3x3, 32, /2 Conv 3x3, 32 Conv 3x3, 32 Conv 3x3, 32 Conv 3x3, 32 Conv 3x3, 32 Conv 3x3, 64, /2 Conv 3x3, 64 Conv 3x3, 64 Conv 3x3, 64 Conv 3x3, 64 Block 1 Block 2 Block 3 P3 P2 P1","We present Hierarchical Residual Networks (HiResNets), deep convolutional neural networks with long-range residual connections between layers at different hierarchical levels. HiResNets draw inspiration on the organization of the mammalian brain by replicating the direct connections from subcortical areas to the entire cortical hierarchy. We show that the inclusion of hierarchical residuals in several architectures, including ResNets, results in a boost in accuracy and faster learning. A detailed analysis of our models reveals that they perform hierarchical compositionality by learning feature maps relative to the compressed representations provided by the skip connections.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-88.pdf,2025,46.875,"Hierarchical Residuals Exploit Brain-Inspired Compositionality We present Hierarchical Residual Networks (HiResNets), deep convolutional neural networks with long-range residual connections between layers at different hierarchical levels. HiResNets draw inspiration on the organization of the mammalian brain by replicating the direct connections from subcortical areas to the entire cortical hierarchy. We show that the inclusion of hierarchical residuals in several architectures, including ResNets, results in a boost in accuracy and faster learning. A detailed analysis of our models reveals that they perform hierarchical compositionality by learning feature maps relative to the compressed representations provided by the skip connections."
Explainable ensemble learning for structural damage prediction under seismic events,"Michele Baldassini, Pierfrancesco Foglia, Beatrice Lazzerini, Francesco Pistolesi, Cosimo Prete","1 - Department of Information Engineering University of Pisa
2 - Largo Lucio Lazzarino 1 -56122 Pisa Italy","This paper presents an explainable ensemble learning framework using Bootstrap Aggregating to predict structural damage in masonry buildings during seismic events. It estimates the peak ground acceleration (PGA) leading to the damage control limit state (significant damage) based on structural parameters. The model achieves high accuracy (R 2 =0.9536, MAE=0.0057) and interpretability through SHAP, aligning with structural engineering principles. Compared to finite element analyses, it offers faster computations (milliseconds) and scalability, enabling rapid intervention planning after earthquakes. Developed under the MEDEA project (EU Grant n. 10101236), it supports disaster response and enhances seismic resilience.",Regression,https://www.esann.org/sites/default/files/proceedings/legacy/es2012-51.pdf,2025,60.11560693641618,"Explainable ensemble learning for structural damage prediction under seismic events This paper presents an explainable ensemble learning framework using Bootstrap Aggregating to predict structural damage in masonry buildings during seismic events. It estimates the peak ground acceleration (PGA) leading to the damage control limit state (significant damage) based on structural parameters. The model achieves high accuracy (R 2 =0.9536, MAE=0.0057) and interpretability through SHAP, aligning with structural engineering principles. Compared to finite element analyses, it offers faster computations (milliseconds) and scalability, enabling rapid intervention planning after earthquakes. Developed under the MEDEA project (EU Grant n. 10101236), it supports disaster response and enhances seismic resilience."
Exploring Model Architectures for Real-Time Lung Sound Event Detection,"Michiel Jacobs, Lode Vuegen, Tom Verresen, Marie Schouterden, David Ruttens, Peter Karsmakers","1 - Flanders Make Fac. of Medicine & Life Sciences AI -KU Leuven Institute for AI 4 -Hasselt University 3500 Leuven 3 -Leuven, Hasselt Belgium
3 - Dept. of Pulmonary Medicine -Ziekenhuis Oost-Limburg 3600 Genk Belgium
7 - Dept. of Computer Science Kleinhoefstraat 4 1 -KU, 2440 Leuven, Geel Belgium","Computerized detection of relevant lung sound events has the potential to assist physicians during auscultation and to monitor the severity of pulmonary diseases in ambulatory settings. In some cases, realtime detection of adventitious lung sounds is required to provide instant feedback to physicians, e.g. during autogenic drainage therapy. Stateof-the-art solutions for this task leverage deep learning models, which vary significantly in complexity. For real-time applications on resourceconstrained devices, such as stethoscope-integrated hardware, both detection accuracy and model complexity are important to consider. While most existing research focusses primarily on accuracy, this work evaluates both accuracy and computational complexity. The contributions of this work are threefold. First, the effect of using a full breathing cycle as input is studied to assess its impact on event detection performance. This approach introduces a computational cost due to the required segmentation process. Second, a transformer-based architecture is compared with two relatively simple convolutional models, each utilizing different input horizons. Evaluations are conducted on both public and in-house lung sound datasets. Third, recognizing that the event detection task aligns better with a multi-label setting than the commonly used multi-class setup, this study compares both approaches. We conclude that a multi-label output outperforms a multi-class approach, that inputs segmented per breathing cycle are preferred, and that the high complexity models have similar performance to the models with low complexity on unseen data. The source code is available through this GitHub repository.",Byte the bullet: learning on real-world computing architectures,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-12.pdf,2025,57.14285714285714,"Exploring Model Architectures for Real-Time Lung Sound Event Detection Computerized detection of relevant lung sound events has the potential to assist physicians during auscultation and to monitor the severity of pulmonary diseases in ambulatory settings. In some cases, realtime detection of adventitious lung sounds is required to provide instant feedback to physicians, e.g. during autogenic drainage therapy. Stateof-the-art solutions for this task leverage deep learning models, which vary significantly in complexity. For real-time applications on resourceconstrained devices, such as stethoscope-integrated hardware, both detection accuracy and model complexity are important to consider. While most existing research focusses primarily on accuracy, this work evaluates both accuracy and computational complexity. The contributions of this work are threefold. First, the effect of using a full breathing cycle as input is studied to assess its impact on event detection performance. This approach introduces a computational cost due to the required segmentation process. Second, a transformer-based architecture is compared with two relatively simple convolutional models, each utilizing different input horizons. Evaluations are conducted on both public and in-house lung sound datasets. Third, recognizing that the event detection task aligns better with a multi-label setting than the commonly used multi-class setup, this study compares both approaches. We conclude that a multi-label output outperforms a multi-class approach, that inputs segmented per breathing cycle are preferred, and that the high complexity models have similar performance to the models with low complexity on unseen data. The source code is available through this GitHub repository."
Comparison of Convolutional Neural Networks Approaches Applied to the Diagnosis of Alzheimer's Disease,"Luiza Scapinello, Aquino Da Silva, Leonardo Alexandre De Geus, Viviana Mariani, Leandro Dos, Santos Coelho","1 - Graduate Program in Electrical Engineering (PPGEE) Federal University of Parana (UFPR) Curitiba PR Brazil
2 - Undergraduate Program in Mechatronics Engineering Pontifical Catholic University of Parana Curitiba PR Brazil
3 - Graduate Program in Mechanical Engineering (PGMec) Federal University of Parana (UFPR) Curitiba PR Brazil","Alzheimer's disease (AD), a neurodegenerative disorder, progressively impairs memory and cognitive functions. Magnetic resonance imaging (MRI) is used as AD diagnosis and progress monitoring method. Convolutional Neural Network (CNN) is a data-driven deep learning model containing layers transforming data input using convolution filters. The goal of this paper is to present an analysis of the CNN architectures for classifying AD diagnoses using functional brain MRI scans acquired by the experimental dataset from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Results show CNNs variants such as InceptionV3 and In-ceptionResNetV2 as powerful computational tools for developing predictive neuroimaging biomarkers in AD diagnosis applications, with accuracy above 70%. * da Silva would like to thank Coordination of Higher Education Personnel Improvement (CAPES) for its financial support. The authors Mariani and Coelho thank the National","Recurrent learning, and reinforcement learning",https://doi.org/10.14428/esann/2021.ES2021-33,2025,55.95854922279793,"Comparison of Convolutional Neural Networks Approaches Applied to the Diagnosis of Alzheimer's Disease Alzheimer's disease (AD), a neurodegenerative disorder, progressively impairs memory and cognitive functions. Magnetic resonance imaging (MRI) is used as AD diagnosis and progress monitoring method. Convolutional Neural Network (CNN) is a data-driven deep learning model containing layers transforming data input using convolution filters. The goal of this paper is to present an analysis of the CNN architectures for classifying AD diagnoses using functional brain MRI scans acquired by the experimental dataset from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Results show CNNs variants such as InceptionV3 and In-ceptionResNetV2 as powerful computational tools for developing predictive neuroimaging biomarkers in AD diagnosis applications, with accuracy above 70%. * da Silva would like to thank Coordination of Higher Education Personnel Improvement (CAPES) for its financial support. The authors Mariani and Coelho thank the National"
Hyperbolic representation learning in multi-layer tissue networks,"Domonkos Pogány, Péter Antal",1 - Department of Artificial Intelligence and Systems Engineering Budapest University of Technology and Economics 1111 Budapest Hungary,"Predicting tissue-specific protein functions and proteinprotein interactions (PPI) is essential for understanding human biology, diseases, and potential therapeutics. Recently, as a promising direction, more and more complex unsupervised feature learning approaches have emerged in the field, but none of them consider the scale-free nature and the underlying geometry of multi-layer PPI networks. Therefore, this study proposes contextualized, tissue-specific representation learning in non-Euclidean geometries and demonstrates that hyperbolic embeddings capture the structure of multi-layer PPI networks with less distortion and achieve better performance in tissue-specific protein function prediction.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-169,2025,57.51633986928104,"Hyperbolic representation learning in multi-layer tissue networks Predicting tissue-specific protein functions and proteinprotein interactions (PPI) is essential for understanding human biology, diseases, and potential therapeutics. Recently, as a promising direction, more and more complex unsupervised feature learning approaches have emerged in the field, but none of them consider the scale-free nature and the underlying geometry of multi-layer PPI networks. Therefore, this study proposes contextualized, tissue-specific representation learning in non-Euclidean geometries and demonstrates that hyperbolic embeddings capture the structure of multi-layer PPI networks with less distortion and achieve better performance in tissue-specific protein function prediction."
Direct versus intermediate multi-task transfer learning for dementia detection from unstructured conversations,"Daniel Kumpik, Yoav Ben-Shlomo, Elizabeth Coulthard, Alex Hepburn, Raul Santos-Rodriguez","1 - Department of Engineering Mathematics University of Bristol Bristol UK
2 - Department of Population Health Sciences University of Bristol Bristol UK
3 - Department of Translational Health Sciences University of Bristol Bristol UK
6 - EP-SRC Centre for Doctoral Training in Digital Health and Care University of Bristol","Leveraging unstructured conversations for detecting early dementia may be possible through information transfer from more systematically constrained representations. To explore whether cross-domain (from semi-structured to unstructured) transfer learning improves dementia classification from conversational speech, we fine-tuned a BERT-family model using semi-structured narratives. We further fine-tuned on naturalistic conversations recorded in the home, but found that direct transfer from BERT to conversations was more effective for improving generalization. These findings show scope to directly leverage unstructured language samples for in-the-wild dementia detection.",Machine learning for medical applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-82.pdf,2025,53.271028037383175,"Direct versus intermediate multi-task transfer learning for dementia detection from unstructured conversations Leveraging unstructured conversations for detecting early dementia may be possible through information transfer from more systematically constrained representations. To explore whether cross-domain (from semi-structured to unstructured) transfer learning improves dementia classification from conversational speech, we fine-tuned a BERT-family model using semi-structured narratives. We further fine-tuned on naturalistic conversations recorded in the home, but found that direct transfer from BERT to conversations was more effective for improving generalization. These findings show scope to directly leverage unstructured language samples for in-the-wild dementia detection."
Topology-Aware Activation Functions in Neural Networks,"Pavel Snopov, Oleg Musin",1 - University of Texas Rio Grande Valley -School of Mathematical and Statistical Sciences Brownsville USA,"This study explores novel activation functions that enhance the ability of neural networks to manipulate data topology during training. Building on the limitations of traditional activation functions like ReLU, we propose SmoothSplit and ParametricSplit, which introduce topology «cutting» capabilities. These functions enable networks to transform complex data manifolds effectively, improving performance in scenarios with low-dimensional layers. Through experiments on synthetic and real-world datasets, we demonstrate that ParametricSplit outperforms traditional activations in low-dimensional settings while maintaining competitive performance in higher-dimensional ones. Our findings highlight the potential of topology-aware activation functions in advancing neural network architectures. The code is available via https: //github.com/Snopoff/Topology-Aware-Activations.","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-82.pdf,2025,59.64912280701755,"Topology-Aware Activation Functions in Neural Networks This study explores novel activation functions that enhance the ability of neural networks to manipulate data topology during training. Building on the limitations of traditional activation functions like ReLU, we propose SmoothSplit and ParametricSplit, which introduce topology «cutting» capabilities. These functions enable networks to transform complex data manifolds effectively, improving performance in scenarios with low-dimensional layers. Through experiments on synthetic and real-world datasets, we demonstrate that ParametricSplit outperforms traditional activations in low-dimensional settings while maintaining competitive performance in higher-dimensional ones. Our findings highlight the potential of topology-aware activation functions in advancing neural network architectures. The code is available via https: //github.com/Snopoff/Topology-Aware-Activations."
Don't Drift Away: Advances and Applications of Streaming and Continual Learning,"Andrea Cossu, Davide Bacciu, Alessio Bernardo, Emanuele Valle, Alexander Gepperth, Federico Giannini, Barbara Hammer, Giacomo Ziffer","1 - University of Pisa 2-DEIB
2 - Politecnico di Milano
5 - University of Applied Sciences Fulda 4-Bielefeld University","Non-stationary environments subject to concept drift require the design of adaptive models that can continuously learn and update. Two primary research communities have emerged to address this challenge: Continual Learning (CL) and Streaming Machine Learning (SML). CL manages virtual drifts by learning new concepts without forgetting past knowledge, while SML focuses on real drifts, rapidly adapting to evolving data distributions. However, a unified approach is needed to balance adaptation and knowledge retention. Streaming Continual Learning (SCL) bridges the gap between CL and SML, ensuring models retain useful past information while efficiently adapting to new data. We explore key challenges in SCL, including handling temporal dependencies in data streams and adapting latent representations for personalization and knowledge editing. Additionally, we identify promising SCL benchmarks which can foster and promote a unified research effort between CL and SML.",Machine learning and data mining for urban mobility intelligence,https://doi.org/10.14428/esann/2021.ES2021-119,2025,55.434782608695656,"Don't Drift Away: Advances and Applications of Streaming and Continual Learning Non-stationary environments subject to concept drift require the design of adaptive models that can continuously learn and update. Two primary research communities have emerged to address this challenge: Continual Learning (CL) and Streaming Machine Learning (SML). CL manages virtual drifts by learning new concepts without forgetting past knowledge, while SML focuses on real drifts, rapidly adapting to evolving data distributions. However, a unified approach is needed to balance adaptation and knowledge retention. Streaming Continual Learning (SCL) bridges the gap between CL and SML, ensuring models retain useful past information while efficiently adapting to new data. We explore key challenges in SCL, including handling temporal dependencies in data streams and adapting latent representations for personalization and knowledge editing. Additionally, we identify promising SCL benchmarks which can foster and promote a unified research effort between CL and SML."
Foundation and Generative Models for Graphs,"Davide Bacciu, Federico Errica, Stefano Moro, Luca Pasa, Davide Rigoni, Daniele Zambon","1 - University of Pisa -Largo Bruno Pontecorvo 3 56127 Pisa Italy
2 - NEC Laboratories Europe GmbH Germany
3 - -University of Padua -Via Trieste 63 35121 Padua -Italy
6 - The Swiss AI Lab IDSIA Università della Svizzera italiana Switzerland","The rapidly evolving field of machine learning for graphstructured data gathered significant attention due to its ability to preserve critical information inherent in complex data structures. As a result, significant efforts have been dedicated to designing advanced architectures and foundational models optimized for graph-based operations. Research in this area explores methodologies for graph representation learning and graph generation, incorporating probabilistic models such as variational autoencoders and normalizing flows. Despite increasing interest from researchers as well as their efforts in solving graph-related problems, several issues and areas remain to be addressed to improve model generalization and reliability. This tutorial reviews foundational concepts and challenges in graph representation, structure learning, and graph generation, while also summarizing the contributions accepted for publication in the special session on this topic at the 33th European Symposium on Artificial Neural Networks, Computational Intelligence, and Machine Learning (ESANN).",Deep learning for graphs,https://doi.org/10.14428/esann/2021.ES2021-112,2025,60.46511627906976,"Foundation and Generative Models for Graphs The rapidly evolving field of machine learning for graphstructured data gathered significant attention due to its ability to preserve critical information inherent in complex data structures. As a result, significant efforts have been dedicated to designing advanced architectures and foundational models optimized for graph-based operations. Research in this area explores methodologies for graph representation learning and graph generation, incorporating probabilistic models such as variational autoencoders and normalizing flows. Despite increasing interest from researchers as well as their efforts in solving graph-related problems, several issues and areas remain to be addressed to improve model generalization and reliability. This tutorial reviews foundational concepts and challenges in graph representation, structure learning, and graph generation, while also summarizing the contributions accepted for publication in the special session on this topic at the 33th European Symposium on Artificial Neural Networks, Computational Intelligence, and Machine Learning (ESANN)."
Machine Learning and applied Artificial Intelligence in cognitive science and psychology: a tutorial,"Caroline König, Alfredo Vellido",1 - Computer Science Department and Intelligent Data Science and Artificial Intelligence IDEAI-UPC) Research Center Universitat Politècnica de Catalunya Barcelona Spain,"Artificial Intelligence (AI) both in general and in its current predominant version, mostly based on connectionist tenets, lives in the paradox of aiming to reproduce and simulate the workings of an immensely complex system, the biological brain, which are still to a large extent unknown. This gives us latitude for some interesting domain interplay: concepts from the cognitive sciences can be used to improve AI models, while AI can be used in data science mode to analyze cognitive processes in neuroscience, as well as brain pathologies from a medical standpoint.",Classification,https://doi.org/10.14428/esann/2022.ES2022-59,2025,53.14009661835748,"Machine Learning and applied Artificial Intelligence in cognitive science and psychology: a tutorial Artificial Intelligence (AI) both in general and in its current predominant version, mostly based on connectionist tenets, lives in the paradox of aiming to reproduce and simulate the workings of an immensely complex system, the biological brain, which are still to a large extent unknown. This gives us latitude for some interesting domain interplay: concepts from the cognitive sciences can be used to improve AI models, while AI can be used in data science mode to analyze cognitive processes in neuroscience, as well as brain pathologies from a medical standpoint."
Network Science Meets AI: A Converging Frontier,"Matteo Zignani, Fragkiskos Malliaros, Ingo Scholtes, Roberto Interdonato, Manuel Dileo","1 - Department of Computer Science University of Milan Italy
2 - Université Paris-Saclay, CentraleSupélec Inria France
3 - CAIDAS Julius-Maximilians-Universität Würzburg Germany
4 - CIRAD UMR TETIS Montpellier France
5 - INRIA Montpellier France","The convergence of network science and artificial intelligence (AI) represents a rich area of research, where both fields can mutually enhance one another. Network science offers a comprehensive framework to analyze and model complex relationships, while machine learning (ML) and AI provide powerful tools for recognizing patterns and making predictions from large datasets. Combining these two disciplines can advance the study of complex systems and lead to new innovations in data-driven research. This tutorial paper reviews fundamental concepts of network science, describes the current and promising research direction for bridging network science and AI, and summarizes the contributions that have been accepted for publication in the ESANN 2025 special session on the topic.","Frontiers in Reservoir Computing - organized by Claudio Gallicchio (University of Pisa, Italy), Mantas Lukosevicius (Kaunas University of Technology, Lithuania), Simone Scardapane (Sapienza University of Rome, Italia)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-7.pdf,2025,58.22784810126582,"Network Science Meets AI: A Converging Frontier The convergence of network science and artificial intelligence (AI) represents a rich area of research, where both fields can mutually enhance one another. Network science offers a comprehensive framework to analyze and model complex relationships, while machine learning (ML) and AI provide powerful tools for recognizing patterns and making predictions from large datasets. Combining these two disciplines can advance the study of complex systems and lead to new innovations in data-driven research. This tutorial paper reviews fundamental concepts of network science, describes the current and promising research direction for bridging network science and AI, and summarizes the contributions that have been accepted for publication in the ESANN 2025 special session on the topic."
Enhancing Machine Learning with Quantum Methods,"Lautaro Hickmann, Markus Lange, Hans-Martin Rieser",1 - DLR Institute for AI Safety and Security Sankt Augustin and Ulm Germany,"Quantum physics offers a new paradigm that promises to make certain computations faster and more efficient. The recent progress of quantum computers allows for more complex applications which lead to a rising interest in transferring machine learning methods to quantum hardware for practical applications. However, the development of quantum computers is still in its beginnings and currently these approaches require synergy with classical computers. We present some methods where this quantum-classical interplay is used to enhance machine learning approaches.","Quantum Machine Learning - Organized by José D. Martín-Guerrero (Universitat de València, Spain), Lucas Lamata (Universidad de Sevilla, Spain)",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-6.pdf,2025,67.6056338028169,"Enhancing Machine Learning with Quantum Methods Quantum physics offers a new paradigm that promises to make certain computations faster and more efficient. The recent progress of quantum computers allows for more complex applications which lead to a rising interest in transferring machine learning methods to quantum hardware for practical applications. However, the development of quantum computers is still in its beginnings and currently these approaches require synergy with classical computers. We present some methods where this quantum-classical interplay is used to enhance machine learning approaches."
Mask-Aware Cropping: Mitigating Mask Imbalance in Segmentation Tasks,"Robin Ghyselinck, Valentin Delchevalerie, Benoît Frénay, Bruno Dumas",1 - Faculty of Computer Science Rue Grangagnage University of Namur -NaDI 21 5000 Namur Belgium,"Data imbalance can take various forms, such as uneven class distributions in the dataset. Solutions like data augmentation, sampling techniques and weighted loss functions are commonly used to address this issue. However, in segmentation tasks, an additional type of imbalance may occur at the pixel-level, with most of them belonging to the background class. This work introduces Mask-Aware Cropping (MAC), a technique to reduce pixel-level imbalance by cropping image regions containing key information about the minority class.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-144.pdf,2025,48.97959183673469,"Mask-Aware Cropping: Mitigating Mask Imbalance in Segmentation Tasks Data imbalance can take various forms, such as uneven class distributions in the dataset. Solutions like data augmentation, sampling techniques and weighted loss functions are commonly used to address this issue. However, in segmentation tasks, an additional type of imbalance may occur at the pixel-level, with most of them belonging to the background class. This work introduces Mask-Aware Cropping (MAC), a technique to reduce pixel-level imbalance by cropping image regions containing key information about the minority class."
Reward-Incremental Reinforcement Learning,"Yannick Denker, Alexander Gepperth",1 - Dept of Computer Science University of Applied Sciences Fulda Leipziger Strasse 123 Fulda Germany,"We address the challenge of reward-incremental learning (RIL) within the context of continual reinforcement learning. RIL presents a novel continual learning (CL) scenario where the same data samples (observations for RL) are mapped to different classes (Q-values) at different times. This is in contrast to class-incremental CL where new sample classes may be added, but without the contradictions inherent in RIL. To tackle this issue, we propose the use of an innovative replay-based approach called adiabatic replay (AR) which is inherently suited for RL since it removes the need for large replay buffers. Based on a simple benchmark scenario for continual RL, we empirically demonstrate that RIL scenarios can be handled by our approach, in contrast to conventional DQN methods.",Recurrent networks and reinforcement learning,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-84.pdf,2025,63.63636363636363,"Reward-Incremental Reinforcement Learning We address the challenge of reward-incremental learning (RIL) within the context of continual reinforcement learning. RIL presents a novel continual learning (CL) scenario where the same data samples (observations for RL) are mapped to different classes (Q-values) at different times. This is in contrast to class-incremental CL where new sample classes may be added, but without the contradictions inherent in RIL. To tackle this issue, we propose the use of an innovative replay-based approach called adiabatic replay (AR) which is inherently suited for RL since it removes the need for large replay buffers. Based on a simple benchmark scenario for continual RL, we empirically demonstrate that RIL scenarios can be handled by our approach, in contrast to conventional DQN methods."
Machine Learning on Smartphone-Captured Diffraction Data,"Ashish Jadhav, Andreas Backhaus, Udo Seiffert","1 - Otto von Guericke University Magdeburg -Institute for Information and Communication Technology Magdeburg Germany
2 - Compolytics GmbH Barleben Germany","This study presents a novel approach for classifying oily or cream-like substances using diffraction data captured on a smartphone camera, applied specifically to assessing engine oil quality. Utilising the COMPOLYTICS ® TapCorder approach, optical diffraction patterns were analysed with a tailored feature extraction method. The performance of three machine learning paradigms -Multilayer Perceptrons (MLP), Learning Vector Quantization (LVQ), and Radial Basis Function Networks (RBFN) -was analysed in classifying new and used oil samples. MLP achieved the highest accuracy, while LVQ required the least computation time, highlighting trade-offs relevant for consumer-focused applications. This work clearly demonstrates the feasibility of accessible, low-cost chemical substance analysis via smartphone-based systems.",Machine Learning Methods for Processing and Analysis of Hyperspectral Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-9.pdf,2025,59.04761904761905,"Machine Learning on Smartphone-Captured Diffraction Data This study presents a novel approach for classifying oily or cream-like substances using diffraction data captured on a smartphone camera, applied specifically to assessing engine oil quality. Utilising the COMPOLYTICS ® TapCorder approach, optical diffraction patterns were analysed with a tailored feature extraction method. The performance of three machine learning paradigms -Multilayer Perceptrons (MLP), Learning Vector Quantization (LVQ), and Radial Basis Function Networks (RBFN) -was analysed in classifying new and used oil samples. MLP achieved the highest accuracy, while LVQ required the least computation time, highlighting trade-offs relevant for consumer-focused applications. This work clearly demonstrates the feasibility of accessible, low-cost chemical substance analysis via smartphone-based systems."
Open-Vocabulary Robotic Object Manipulation using Foundation Models,"Stig Griebenow, Ozan Özdemir, Cornelius Weber, Stefan Wermter",1 - University of Hamburg -Knowledge Technology Group Vogt-Kölln-Straße 30 22527 Hamburg Germany,"Classical vision-language-action models are limited by unidirectional communication, hindering natural human-robot interaction. The recent CrossT5 embeds an efficient vision action pathway into an LLM, but lacks visual generalization, restricting actions to objects seen during training. We introduce OWL×T5, which integrates the OWLv2 object detection model into CrossT5 to enable robot actions on unseen objects. OWL×T5 is trained on a simulated dataset using the NICO humanoid robot and evaluated on the new CLAEO dataset featuring interactions with unseen objects. Results show that OWL×T5 achieves zero-shot object recognition for robotic manipulation, while efficiently integrating vision-language-action capabilities. * The research was supported by the DFG under the Crossmodal Learning (TRR-169) project and by the Horizon Europe project TERAIS under Grant agreement 101079338.",Signal and temporal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-115.pdf,2025,48.68421052631579,"Open-Vocabulary Robotic Object Manipulation using Foundation Models Classical vision-language-action models are limited by unidirectional communication, hindering natural human-robot interaction. The recent CrossT5 embeds an efficient vision action pathway into an LLM, but lacks visual generalization, restricting actions to objects seen during training. We introduce OWL×T5, which integrates the OWLv2 object detection model into CrossT5 to enable robot actions on unseen objects. OWL×T5 is trained on a simulated dataset using the NICO humanoid robot and evaluated on the new CLAEO dataset featuring interactions with unseen objects. Results show that OWL×T5 achieves zero-shot object recognition for robotic manipulation, while efficiently integrating vision-language-action capabilities. * The research was supported by the DFG under the Crossmodal Learning (TRR-169) project and by the Horizon Europe project TERAIS under Grant agreement 101079338."
Improving Privacy Benefits of Redaction,"Vaibhav Gusain, Douglas Leith",1 - School of Computer science and statistics Dublin Trinity College Dublin Ireland,We propose a novel redaction methodology that can be used to sanitize natural text data. Our new technique provides better privacy benefits than other state of the art techniques while maintaining lower redaction levels. * This work was supported by Science Foundation Ireland grant 16/IA/4610. 1 Sensitive dataset D 0 contains sentences which contains sensitive information such as a specific medical conditions etc and a safe dataset D 1 is a public dataset that is suitable diverse and non-sensitive.,Impact of Biases in Big Data,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-7.pdf,2025,50.74626865671642,Improving Privacy Benefits of Redaction We propose a novel redaction methodology that can be used to sanitize natural text data. Our new technique provides better privacy benefits than other state of the art techniques while maintaining lower redaction levels. * This work was supported by Science Foundation Ireland grant 16/IA/4610. 1 Sensitive dataset D 0 contains sentences which contains sensitive information such as a specific medical conditions etc and a safe dataset D 1 is a public dataset that is suitable diverse and non-sensitive.
Generative Kernel Spectral Clustering,"David Winant, Sonny Achten, Johan Suykens","1 - ESAT-Stadius KU Leuven Kasteelpark Arenberg 10 B-3001 Leuven Belgium
2 - KU Leuven institute for AI B-3000 Leuven Belgium","Modern clustering approaches often trade interpretability for performance, particularly in deep learning-based methods. We present Generative Kernel Spectral Clustering (GenKSC), a novel model combining kernel spectral clustering with generative modeling to produce both well-defined clusters and interpretable representations. By augmenting weighted variance maximization with reconstruction and clustering losses, our model creates an explorable latent space where cluster characteristics can be visualized through traversals along cluster directions. Results on MNIST and FashionMNIST datasets demonstrate the model's ability to learn meaningful cluster representations.",Clustering,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-163.pdf,2025,63.73626373626373,"Generative Kernel Spectral Clustering Modern clustering approaches often trade interpretability for performance, particularly in deep learning-based methods. We present Generative Kernel Spectral Clustering (GenKSC), a novel model combining kernel spectral clustering with generative modeling to produce both well-defined clusters and interpretable representations. By augmenting weighted variance maximization with reconstruction and clustering losses, our model creates an explorable latent space where cluster characteristics can be visualized through traversals along cluster directions. Results on MNIST and FashionMNIST datasets demonstrate the model's ability to learn meaningful cluster representations."
Ranking the scores of algorithms with confidence,"Adrien Foucart, Arthur Elskens, Christine Decaestecker","1 - Université Libre de Bruxelles -Laboratory of Image Synthesis and Analysis Av. FD Roosevelt 50 Brussels Belgium
3 - DIAPath Center for Microscopy and Molecular Imaging Rue Adrienne Bolland 8 Université Libre de Bruxelles Gosselies Belgium","Evaluating algorithms (particularly in the context of a competition) typically ends with a ranking from best to worst. While this ranking is sometimes accompanied by statistical significance tests on the assessment metrics, sometimes associated with confidence intervals, the ranks are usually presented as singular values. We argue that these ranks should themselves be accompanied by confidence intervals. We investigate different methods for computing such intervals, and measure their behaviour in simulated scenarios. Our results show that we can obtain robust confidence intervals for ranks using the Iman-Davenport test and the pairwise Wilcoxon signed-rank test with Holm's correction. * This research was supported by the Walloon Region (Belgium) in the framework of the Prother-wal program (grant No. 7289). CD is a senior research associate with the F.R.S.-FNRS and an active member of the TRAIL Institute (Trusted AI Labs, https://trail.ac/, Fédération Wallonie-Bruxelles, Belgium). CMMI is supported by the European Regional Development Fund and the Walloon Region (Walloniabiomed, #411132-957270, project ""CMMI-ULB"").",Image processing and vision systems,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-89.pdf,2025,55.55555555555556,"Ranking the scores of algorithms with confidence Evaluating algorithms (particularly in the context of a competition) typically ends with a ranking from best to worst. While this ranking is sometimes accompanied by statistical significance tests on the assessment metrics, sometimes associated with confidence intervals, the ranks are usually presented as singular values. We argue that these ranks should themselves be accompanied by confidence intervals. We investigate different methods for computing such intervals, and measure their behaviour in simulated scenarios. Our results show that we can obtain robust confidence intervals for ranks using the Iman-Davenport test and the pairwise Wilcoxon signed-rank test with Holm's correction. * This research was supported by the Walloon Region (Belgium) in the framework of the Prother-wal program (grant No. 7289). CD is a senior research associate with the F.R.S.-FNRS and an active member of the TRAIL Institute (Trusted AI Labs, https://trail.ac/, Fédération Wallonie-Bruxelles, Belgium). CMMI is supported by the European Regional Development Fund and the Walloon Region (Walloniabiomed, #411132-957270, project ""CMMI-ULB"")."
Multiclass Adaptive Subspace Learning,"Peter Preinesberger, Maximilian Münch, Frank-Michael Schleif","1 - Techn. Univ. of Appl. Sc. Würzburg-Schweinfurt Würzburg Germany
3 - Dept. of CS University of Groningen Groningen Netherlands
4 - Center for Artificial Intelligence and Robotics Würzburg Germany","In modern data analysis, there is an increasing trend towards the integration of information across diverse input formats and perspectives. If the available data is not given in large quantities deep learning is in general impractical. The recently introduced Adaptive Subspace Kernel Fusion (ASKF) technique provides an efficient solution for binary classification, facilitating the effective integration of diverse views throughout the learning process. In this paper, we extend ASKF by employing a vector-labeled multi-class model, eliminating the need for multiple individual models typically required in conventional one-vs-rest or one-vs-one approaches. We also evaluated the effect of using GPU-based numerical solvers, optimizing our problem formulation and the generated code for better efficiency. The approach is evaluated on various kernel functions, highlighting our methods ability of robustly dealing with multi-view data. 
 Background Consider a collection of N objects X = {x i } N i=1 in an input space X . Each object x i is described in M different modalities For each modality m, we assume a proximity *","Information Visualization, Nonlinear Dimensionality Reduction, Manifold and Topological Learning",https://www.esann.org/sites/default/files/proceedings/legacy/es2010-78.pdf,2025,55.44554455445545,"Multiclass Adaptive Subspace Learning In modern data analysis, there is an increasing trend towards the integration of information across diverse input formats and perspectives. If the available data is not given in large quantities deep learning is in general impractical. The recently introduced Adaptive Subspace Kernel Fusion (ASKF) technique provides an efficient solution for binary classification, facilitating the effective integration of diverse views throughout the learning process. In this paper, we extend ASKF by employing a vector-labeled multi-class model, eliminating the need for multiple individual models typically required in conventional one-vs-rest or one-vs-one approaches. We also evaluated the effect of using GPU-based numerical solvers, optimizing our problem formulation and the generated code for better efficiency. The approach is evaluated on various kernel functions, highlighting our methods ability of robustly dealing with multi-view data. 
 Background Consider a collection of N objects X = {x i } N i=1 in an input space X . Each object x i is described in M different modalities For each modality m, we assume a proximity *"
Towards Learning Vector Quantization in the Setting of Homomorphic Encryption,"Ronny Schubert, Thomas Davies, Mandy Lange-Geisler, Klaus Dohmen, Thomas Villmann","1 - Mittweida University of Applied Sciences Saxon Institute for Computational Intelligence and Machine Learning Technikumplatz 17 09648 Mittweida
2 - NEC Laboratories Europe GmbH Heidelberg Germany
7 - Technische Universität Freiberg","With federated learning scenarios gaining popularity to outsource computational heavy tasks or to increase generalizability of machine learning models, there is also a rise of research in terms of the security and privacy of the respective data used for these tasks. While differential privacy is studied well for Learning Vector Quantization, we want to present steps towards Homomorphic Encryption. In this regard, we will show theoretically how LVQ-1 can be adapted to be compatible with the TFHE encryption scheme and present experimental results. * T.D. is supported by an ESF PhD-grant. Underlined authors contributed equally.",Classification,https://doi.org/10.14428/esann/2023.ES2023-95,2025,63.08724832214765,"Towards Learning Vector Quantization in the Setting of Homomorphic Encryption With federated learning scenarios gaining popularity to outsource computational heavy tasks or to increase generalizability of machine learning models, there is also a rise of research in terms of the security and privacy of the respective data used for these tasks. While differential privacy is studied well for Learning Vector Quantization, we want to present steps towards Homomorphic Encryption. In this regard, we will show theoretically how LVQ-1 can be adapted to be compatible with the TFHE encryption scheme and present experimental results. * T.D. is supported by an ESF PhD-grant. Underlined authors contributed equally."
Towards Adaptive and Stable Compositional Assemblies of Recurrent Neural Network Modules,"Valerio De Caro, Andrea Ceni, Davide Bacciu, Claudio Gallicchio",1 - Department of Computer Science University of Pisa Largo Bruno Pontecorvo 3 Pisa Italy school,"Recurrent neural networks (RNNs) are computational models regarded as dynamical systems. Modularity is a key ingredient of complex systems. Thus, the composition of RNN modules provides a simple paradigm for building complex computational models, with the potential to approach the human brain capability. We devise strategies for training RNNs assembled into a larger RNN of RNNs, provided with theoretical guarantees of stability that hold during training for the composed global network. Experiments on pixel-by-pixel image classification benchmarks prove the effectiveness of this approach.",Time series and signal processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-159.pdf,2025,61.224489795918366,"Towards Adaptive and Stable Compositional Assemblies of Recurrent Neural Network Modules Recurrent neural networks (RNNs) are computational models regarded as dynamical systems. Modularity is a key ingredient of complex systems. Thus, the composition of RNN modules provides a simple paradigm for building complex computational models, with the potential to approach the human brain capability. We devise strategies for training RNNs assembled into a larger RNN of RNNs, provided with theoretical guarantees of stability that hold during training for the composed global network. Experiments on pixel-by-pixel image classification benchmarks prove the effectiveness of this approach."
3-WL GNNs for Metric Learning on Graphs,"Aldo Moscatelli, Maxime Bérar, Pierre Héroux, Florian Yger",1 - Univ Rouen Normandie INSA Rouen Normandie Normandie Univ LITIS UR4108 F-76000 Rouen France,"Since the advent of Graph Neural Networks (GNNs), many works have computed distances between graphs by embedding them in vector spaces using Message Passing GNNs (MPNNs). However, MPNNs are known for their lack of expressiveness as they are bounded by the firstorder Weisfeiler-Lehman test. In this paper, we use higher-order GNNs to tackle the metric learning problem and show on benchmark datasets how they can improve performance by using a node-level strategy and the Wasserstein distance. 
 Introduction A key challenge in modeling structured information with graphs lies in computing the distances between them. The Graph Edit Distance(GED)[4] is a state-ofthe-art method for this purpose; however, it suffers from NP-hard complexity. Recently, several architectures have been proposed to address this limitation  [9, 7, 8, 11, 12]  in a learning framework. These architectures generally consist of two main components. The first is an embedding block that uses siamese Graph Neural Networks(GNNs) to embed graphs either at the graph level or at the node level. The second component is a metric block that takes the embeddings generated by the first block as input and computes the distance between graphs, taking into account the embedding level. The rationale behind these architectures is that the embedding block learns an optimal representation to facilitate the computations in the metric block. To the best of our knowledge, existing embedding blocks in the literature rely on simple yet effective Message Passing Neural Networks(MPNNs), such as GCN [3]  or GIN  [2] . Consequently, they suffer from the well-known limitations of MPNNs, including over-smoothing, over-squashing, and limited expressive power. This last limitation is particularly significant for metric learning, as it affects the ability to generate distinct embeddings for different graphs. Yet, GCN and GIN models have been shown to be at most equivalent to the firstorder Weisfeiler-Lehman(WL) test in the WL hierarchy  [1] . Recently, more expressive GNNs such as PPGN [5]  and G 2 N 2 [6] have been introduced in the literature, achieving a 3-WL expressivity level. To attain this level of expressivity, these architectures naturally incorporate edge embeddings, adding valuable information to the traditional node-and graph-level representations. These recent developments raise two research questions: how can 3-WL GNNs be integrated into a metric learning framework, and do they enable improved performance? 283",Deep Learning for Graphs,https://doi.org/10.14428/esann/2022.ES2022-7,2025,63.49206349206349,"3-WL GNNs for Metric Learning on Graphs Since the advent of Graph Neural Networks (GNNs), many works have computed distances between graphs by embedding them in vector spaces using Message Passing GNNs (MPNNs). However, MPNNs are known for their lack of expressiveness as they are bounded by the firstorder Weisfeiler-Lehman test. In this paper, we use higher-order GNNs to tackle the metric learning problem and show on benchmark datasets how they can improve performance by using a node-level strategy and the Wasserstein distance. 
 Introduction A key challenge in modeling structured information with graphs lies in computing the distances between them. The Graph Edit Distance(GED)[4] is a state-ofthe-art method for this purpose; however, it suffers from NP-hard complexity. Recently, several architectures have been proposed to address this limitation  [9, 7, 8, 11, 12]  in a learning framework. These architectures generally consist of two main components. The first is an embedding block that uses siamese Graph Neural Networks(GNNs) to embed graphs either at the graph level or at the node level. The second component is a metric block that takes the embeddings generated by the first block as input and computes the distance between graphs, taking into account the embedding level. The rationale behind these architectures is that the embedding block learns an optimal representation to facilitate the computations in the metric block. To the best of our knowledge, existing embedding blocks in the literature rely on simple yet effective Message Passing Neural Networks(MPNNs), such as GCN [3]  or GIN  [2] . Consequently, they suffer from the well-known limitations of MPNNs, including over-smoothing, over-squashing, and limited expressive power. This last limitation is particularly significant for metric learning, as it affects the ability to generate distinct embeddings for different graphs. Yet, GCN and GIN models have been shown to be at most equivalent to the firstorder Weisfeiler-Lehman(WL) test in the WL hierarchy  [1] . Recently, more expressive GNNs such as PPGN [5]  and G 2 N 2 [6] have been introduced in the literature, achieving a 3-WL expressivity level. To attain this level of expressivity, these architectures naturally incorporate edge embeddings, adding valuable information to the traditional node-and graph-level representations. These recent developments raise two research questions: how can 3-WL GNNs be integrated into a metric learning framework, and do they enable improved performance? 283"
The Regulatory Character of Boredom in AI -Towards a Self-Regulating System based on Spiking Neural Networks,"Patrick Schöfer, James Danckert, Peter Stadler, Martin Bogdan","1 - Department of Neuromorphic Information Processing Augustusplatz 10 Leipzig University 04109 Leipzig Germany
2 - Department of Psychology University of Waterloo 2000 University Avenue West N2L3G1 Waterloo Canada
3 - Department of Bioinformatics Härtelstr Leipzig University 16-18 04107 Leipzig -Germany
4 - Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI","Boredom is increasingly recognized as a functional emotion playing an important role in regulating human behavior. Despite continuous advances in the field of artificial intelligence, research on whether these models can enter emotional states such as boredom remains limited. However, emotions can be pivotal towards more human-like intelligence in AI. This paper transfers the regulatory function of boredom into a control loop modeled with spiking neural networks. Simulations demonstrate the successful replication of the regulatory mechanism of boredom based on simulated input. This work provides a foundation for future research and development towards a self-regulating system based on spiking neural networks capable of entering a state of boredom.",Efficient Learning in Spiking Neural Networks,https://doi.org/10.14428/esann/2023.ES2023-174,2025,50.26178010471204,"The Regulatory Character of Boredom in AI -Towards a Self-Regulating System based on Spiking Neural Networks Boredom is increasingly recognized as a functional emotion playing an important role in regulating human behavior. Despite continuous advances in the field of artificial intelligence, research on whether these models can enter emotional states such as boredom remains limited. However, emotions can be pivotal towards more human-like intelligence in AI. This paper transfers the regulatory function of boredom into a control loop modeled with spiking neural networks. Simulations demonstrate the successful replication of the regulatory mechanism of boredom based on simulated input. This work provides a foundation for future research and development towards a self-regulating system based on spiking neural networks capable of entering a state of boredom."
INAM: Image-Scale Neural Additive Models,"Jana Hüls, Jan-Ole Perschewski, Sebastian Stober",1 - Department of Computer Science Otto von Guericke University Universitätsplatz 2 39106 Magdeburg Germany,"Neural Additive Models are inherently interpretable models that can be applied to tabular data. However, when applying these models to images the value of a given pixel is not a meaningful feature for understanding the model. For that reason, we propose INAM -Image scale Neural Additive Model -a combination of trainable feature extractors and NAMs. We show INAMs can be successfully applied to image data sets with low variability while allowing global explanations of the models and data point-specific explanations.",Learning of structured and non-standard data,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-82.pdf,2025,46.51162790697675,"INAM: Image-Scale Neural Additive Models Neural Additive Models are inherently interpretable models that can be applied to tabular data. However, when applying these models to images the value of a given pixel is not a meaningful feature for understanding the model. For that reason, we propose INAM -Image scale Neural Additive Model -a combination of trainable feature extractors and NAMs. We show INAMs can be successfully applied to image data sets with low variability while allowing global explanations of the models and data point-specific explanations."
Isotropy Matters: Soft-ZCA Whitening of Embeddings for Semantic Code Search,"Andor Diera, Lukas Galke, Ansgar Scherp","1 - Ulm University -Data Science and Big Data Analytics Helmholtzstrasse 16 89081 Ulm Germany
2 - Dept of Mathematics and Computer Science University of Southern Denmark Campusvej 55 5230 Odense Denmark","Low isotropy in an embedding space impairs performance on tasks involving semantic inference. Our study investigates the impact of isotropy on semantic code search performance and explores post-processing techniques to mitigate this issue. We analyze various code language models, examine isotropy in their embedding spaces, and its influence on search effectiveness. We propose a modified ZCA whitening technique to control isotropy levels in embeddings. Our results demonstrate that Soft-ZCA whitening improves the performance of pre-trained code language models and can complement contrastive fine-tuning.",Graph Representation Learning,https://doi.org/10.14428/esann/2023.ES2023-51,2025,51.908396946564885,"Isotropy Matters: Soft-ZCA Whitening of Embeddings for Semantic Code Search Low isotropy in an embedding space impairs performance on tasks involving semantic inference. Our study investigates the impact of isotropy on semantic code search performance and explores post-processing techniques to mitigate this issue. We analyze various code language models, examine isotropy in their embedding spaces, and its influence on search effectiveness. We propose a modified ZCA whitening technique to control isotropy levels in embeddings. Our results demonstrate that Soft-ZCA whitening improves the performance of pre-trained code language models and can complement contrastive fine-tuning."
Improving Robustness of Defect Detection models using Adversarial-based Data Augmentation,"Daniel García, Aleix García, Diego García, Ignacio Díaz","1 - Department of Electrical Engineering University of Oviedo 33204 Gijon, Asturias Spain
2 - CIN Advanced Systems -Machine Learning Department 33211 Gijon, Asturias Spain","We propose an adversarial-based data augmentation method to improve the robustness of object detection models, specifically for industrial defect detection. Unlike prior approaches focused on classification or synthetic datasets, our method generates adversarial examples that target both classification and localization outputs. We further introduce controlled white noise to these examples, enhancing robustness against environmental variations. Empirical evaluation on a real-world dataset of defective laser welding images shows that our approach outperforms standard data augmentation and existing adversarial training methods, improving both model accuracy and resilience to diverse perturbations encountered in real-world settings.","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-42,2025,53.987730061349694,"Improving Robustness of Defect Detection models using Adversarial-based Data Augmentation We propose an adversarial-based data augmentation method to improve the robustness of object detection models, specifically for industrial defect detection. Unlike prior approaches focused on classification or synthetic datasets, our method generates adversarial examples that target both classification and localization outputs. We further introduce controlled white noise to these examples, enhancing robustness against environmental variations. Empirical evaluation on a real-world dataset of defective laser welding images shows that our approach outperforms standard data augmentation and existing adversarial training methods, improving both model accuracy and resilience to diverse perturbations encountered in real-world settings."
Multi-View Graph Neural Network for Image Segmentation : Intermediate vs Late Fusion,"E Karam, N Jrad, P Coupeau, D Tobiano, J.-B Fasquel, F Abdallah","1 - Université d'Angers -LARIS SFR MATHSTIC F-49000 Angers France
2 - Université Catholique de l'Ouest -LARIS SFR MATHSTIC F-49000 Angers France
3 - -Lebanese University -Doctoral School of Science and Technology Beirut Liban
9 - Université de Lorraine -Laboratoire LCOMS Saint-Dié-des-Vosges France","Representing an image as a graph captures its spatial and contextual relationships effectively. Using Graph Neural Networks (GNNs) on graph-based images has considerably enhanced image segmentation. This paper investigates Multi-View GNNs for image segmentation, comparing Intermediate and Late Fusion methods. Experiments show that Intermediate Fusion achieves high accuracy on synthetic data by integrating relational features upfront. On a real dataset, Late Fusion methods, particularly RVCons, outperform Intermediate Fusion by dynamically aggregating multi-view predictions. Indeed, Late Fusion effectively mitigates issues arising from view-specific noise and variance. The results underscore the complementary strengths of both fusion strategies. * The authors would like to express their gratitude to Angers Loire Métropole and Université Catholique de l'Ouest for their financial support and contributions to this project.",Learning theory and principles,https://doi.org/10.14428/esann/2022.ES2022-95,2025,56.57894736842105,"Multi-View Graph Neural Network for Image Segmentation : Intermediate vs Late Fusion Representing an image as a graph captures its spatial and contextual relationships effectively. Using Graph Neural Networks (GNNs) on graph-based images has considerably enhanced image segmentation. This paper investigates Multi-View GNNs for image segmentation, comparing Intermediate and Late Fusion methods. Experiments show that Intermediate Fusion achieves high accuracy on synthetic data by integrating relational features upfront. On a real dataset, Late Fusion methods, particularly RVCons, outperform Intermediate Fusion by dynamically aggregating multi-view predictions. Indeed, Late Fusion effectively mitigates issues arising from view-specific noise and variance. The results underscore the complementary strengths of both fusion strategies. * The authors would like to express their gratitude to Angers Loire Métropole and Université Catholique de l'Ouest for their financial support and contributions to this project."
Integrating Class Relation Knowledge in Probabilistic Learning Vector Quantization,"M Kaden, R Schubert, T Geweniger, W Hermann, T Villmann","1 - Saxon Institute for Computational Intelligence and Machine Learning (SICIM) Mittweida University of Applied Sciences Saxony Germany
3 - West-Saxony University of Applied Sciences Zwickau Germany
4 - -SRO AG Spital Langenthal Switzerland
6 - -Technical University Freiberg Saxony Germany","An interpretable approach to classification learning using cross-entropy loss is the Probabilistic Learning Vector Quantizer (PLVQ) as a robust prototype-based classifier. We propose a variant of the PLVQ, that allows the integration of domain knowledge. This strategy is becoming increasingly popular as a means of developing intelligent models that can enhance performance and gain acceptance from domain experts. In this paper, we put forth the idea of incorporating externally known class relations as supplementary information. We present theoretical aspects of the model and demonstrate its capabilities through numerical experiments. * M.K. is supported by the IAI-XPRESS and the DAIMLER project which both are parts of the interdisciplinary project Artificial Intelligence Meets Space (AIMS, No. 50WK2270E) funded by the German Space Agency (DLR).","Machine learning in distributed, federated and non-stationery environments",https://doi.org/10.14428/esann/2024.ES2024-57,2025,60.689655172413794,"Integrating Class Relation Knowledge in Probabilistic Learning Vector Quantization An interpretable approach to classification learning using cross-entropy loss is the Probabilistic Learning Vector Quantizer (PLVQ) as a robust prototype-based classifier. We propose a variant of the PLVQ, that allows the integration of domain knowledge. This strategy is becoming increasingly popular as a means of developing intelligent models that can enhance performance and gain acceptance from domain experts. In this paper, we put forth the idea of incorporating externally known class relations as supplementary information. We present theoretical aspects of the model and demonstrate its capabilities through numerical experiments. * M.K. is supported by the IAI-XPRESS and the DAIMLER project which both are parts of the interdisciplinary project Artificial Intelligence Meets Space (AIMS, No. 50WK2270E) funded by the German Space Agency (DLR)."
Mitigating the Bias in Data for Fairness Using an Advanced Generalized Learning Vector Quantization Approach -FA(IR) 2 MA-GLVQ,"M Kaden, A Engelsberger, R Schubert, S Lövdal, E Van Den Brandhof, M Biehl, T Villmann","1 - Saxon Institute for Computational Intelligence and Machine Learning (SICIM) Mittweida University of Applied Sciences Saxony Germany
4 - University of Groningen The Netherlands
5 - -University Medical Center Groningen (UMCG) The Netherlands
10 - -Technical University Freiberg Saxony Germany","We propose a bias detection and mitigating scheme for data in the context of classification tasks based on learning vector quantizers (LVQ) as classifier. For this purpose generalized LVQ endowed with an advanced matrix adaptation scheme is used for bias detection. The bias removal from data is realized applying a nullspace data projection using the adjusted matrix. The usefulness of the approach is demonstrated and illustrated in terms of two real world datasets. * M.K. is supported by the IAI-XPRESS and the DAIMLER project which both are parts of the interdisciplinarry project Artificial Intelligence Meets Space (AIMS, No. 50WK2270E) funded by the German Space Agency (DLR). A.E. is supported by the PAL-project (Perspektive Arbeit Lausitz ) of UAS Mittweida, and S.L. by Stichting ParkinsonFonds.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-93.pdf,2025,58.47457627118644,"Mitigating the Bias in Data for Fairness Using an Advanced Generalized Learning Vector Quantization Approach -FA(IR) 2 MA-GLVQ We propose a bias detection and mitigating scheme for data in the context of classification tasks based on learning vector quantizers (LVQ) as classifier. For this purpose generalized LVQ endowed with an advanced matrix adaptation scheme is used for bias detection. The bias removal from data is realized applying a nullspace data projection using the adjusted matrix. The usefulness of the approach is demonstrated and illustrated in terms of two real world datasets. * M.K. is supported by the IAI-XPRESS and the DAIMLER project which both are parts of the interdisciplinarry project Artificial Intelligence Meets Space (AIMS, No. 50WK2270E) funded by the German Space Agency (DLR). A.E. is supported by the PAL-project (Perspektive Arbeit Lausitz ) of UAS Mittweida, and S.L. by Stichting ParkinsonFonds."
Learning of Probability Estimates for System and Network Reliability Analysis by means of Matrix Learning Vector Quantization,"Klaus Dohmen, Mandy Lange-Geisler, Thomas Villmann","1 - Mittweida University of Applied Sciences -Dept. of Mathematics Technikumplatz 17 09648 Mittweida Germany
4 - Akademiestraße 6 09599 Freiberg, Freiberg Germany","We present a new approach for the assessment of the reliability of coherent systems by using a prototype-based classification method. More specifically, reliability levels for consecutive k-out-of-n systems, which serve as a model for a particular type of networks, are classified using Generalized Matrix Learning Vector Quantization, which provides useful information about the impact of the input probabilities on the classified reliability levels. Our approach is not limited to reliability analysis, but is generally applicable for estimating the probability of the union of any finite family of events, based on their individual and pairwise probabilities.",Vector quantization- and nearest neighbour-based methods,https://www.esann.org/sites/default/files/proceedings/legacy/es2014-93.pdf,2025,54.46808510638298,"Learning of Probability Estimates for System and Network Reliability Analysis by means of Matrix Learning Vector Quantization We present a new approach for the assessment of the reliability of coherent systems by using a prototype-based classification method. More specifically, reliability levels for consecutive k-out-of-n systems, which serve as a model for a particular type of networks, are classified using Generalized Matrix Learning Vector Quantization, which provides useful information about the impact of the input probabilities on the classified reliability levels. Our approach is not limited to reliability analysis, but is generally applicable for estimating the probability of the union of any finite family of events, based on their individual and pairwise probabilities."
Shallow convolution and attention-based models for micro-expression recognition,"Prateek Upadhya, Tanmay Tulsidas Verlekar",1 - Department of CSIS BITS Pilani K.K. Birla Goa Campus 403726 Goa -India,"The use of deep learning models for micro-expression recognition is challenging because of the absence of large datasets. This paper proposes the construction of shallow models to address this problem. It explores block-wise 3D convolutions, 2D convolutions over frames and 2D convolutional long short-term memory (ConvLSTM) over the video and combines them with multi-headed self-attention to obtain three different models. The evaluation indicates that the proposed 2D ConvLSTM and attention-based model performs the best, beating the state-of-the-art by obtaining an accuracy of 74%. It also has a parameter size that is 10 times smaller than the state-of-the-art.",Deep learning and CNN,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-26.pdf,2025,54.90196078431373,"Shallow convolution and attention-based models for micro-expression recognition The use of deep learning models for micro-expression recognition is challenging because of the absence of large datasets. This paper proposes the construction of shallow models to address this problem. It explores block-wise 3D convolutions, 2D convolutions over frames and 2D convolutional long short-term memory (ConvLSTM) over the video and combines them with multi-headed self-attention to obtain three different models. The evaluation indicates that the proposed 2D ConvLSTM and attention-based model performs the best, beating the state-of-the-art by obtaining an accuracy of 74%. It also has a parameter size that is 10 times smaller than the state-of-the-art."
Artificial Surrogate Model for Computational Fluid Dynamics,"Abdallah Alfaham, Siegfried Mercelis",1 - Faculty of Applied Engineering Antwerp University of Antwerp -imec IDLab Belgium,"Simulating fluid dynamics is challenging due to the computational complexity of processing high-dimensional data, which often requires significant time. Fluid behavior is typically governed by partial differential equations (PDEs), and the complexity escalates when obstacles disrupt the flow, reinforcing vorticity formation. Vorticity describes the local rotational motion of a fluid. In this paper, we present a data-driven approach to automate PDE simulations and develop surrogate models to generate fluid dynamics based on the Kármán vortex street. Our approach aims to generate accurate fluid simulations with faster computation through architectural adjustments.",Aeronautic data analysis,https://doi.org/10.14428/esann/2024.ES2024-51,2025,52.3076923076923,"Artificial Surrogate Model for Computational Fluid Dynamics Simulating fluid dynamics is challenging due to the computational complexity of processing high-dimensional data, which often requires significant time. Fluid behavior is typically governed by partial differential equations (PDEs), and the complexity escalates when obstacles disrupt the flow, reinforcing vorticity formation. Vorticity describes the local rotational motion of a fluid. In this paper, we present a data-driven approach to automate PDE simulations and develop surrogate models to generate fluid dynamics based on the Kármán vortex street. Our approach aims to generate accurate fluid simulations with faster computation through architectural adjustments."
Motif-augmented classical music synthesis via recurrent neural networks,Alexandru-Ion Marinescu,"1 - Department of Mathematics and Computer Science Babeş-Bolyai University Str. Mihail Kogȃlniceanu, nr. 1 400084 Cluj-Napoca Romania","We propose a motif-augmented approach to classical music synthesis using LSTM-based recurrent neural networks trained on J. S. Bach violin compositions. By combining motif augmentation with temperature-based sampling, we improve the entropy alignment between generated sequences and ground-truth data. Our experiments show that motif augmentation significantly reduces entropy deviation and enhances sequence coherence, as confirmed by statistical analysis. This method advances generative music modeling, offering potential applications in music composition and sequence prediction tasks.",Deep learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-100.pdf,2025,61.8421052631579,"Motif-augmented classical music synthesis via recurrent neural networks We propose a motif-augmented approach to classical music synthesis using LSTM-based recurrent neural networks trained on J. S. Bach violin compositions. By combining motif augmentation with temperature-based sampling, we improve the entropy alignment between generated sequences and ground-truth data. Our experiments show that motif augmentation significantly reduces entropy deviation and enhances sequence coherence, as confirmed by statistical analysis. This method advances generative music modeling, offering potential applications in music composition and sequence prediction tasks."
Multimodal Explainable Automated Diagnosis of Autistic Spectrum Disorder,"Meryem Yahia, Moncef Garouani, Julien Aligon","1 - Université Jean Monnet Saint-Etienne France
2 - UMR 5505 IRIT CNRS Université Toulouse Capitole Toulouse France","Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by symptoms that affect social interaction, communication, and behavior, the diagnosis being complicated by significant individual variability and the absence of definitive biomarkers. Current artificial intelligence methods have improved diagnostic accuracy, but their reliance on subjective assessments or single-modal data, coupled with their ""blackbox"" nature, limits consistency and clinical applicability. Addressing current limitations, this paper introduces a multimodal ASD detection framework using deep neural networks (DNN) with explainable AI (xAI) to enhance model transparency. Our model achieves a mean 5-fold crossvalidation accuracy of 98.64% (± 0.86%), surpassing existing methods and demonstrating potential for clinical dependability of ASD diagnoses. The source code is available at : Multimodal-Explainable-Diagnosis-of-ASD.git","Image, signal and time series analysis",https://www.esann.org/sites/default/files/proceedings/legacy/es2013-48.pdf,2025,50.72463768115942,"Multimodal Explainable Automated Diagnosis of Autistic Spectrum Disorder Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by symptoms that affect social interaction, communication, and behavior, the diagnosis being complicated by significant individual variability and the absence of definitive biomarkers. Current artificial intelligence methods have improved diagnostic accuracy, but their reliance on subjective assessments or single-modal data, coupled with their ""blackbox"" nature, limits consistency and clinical applicability. Addressing current limitations, this paper introduces a multimodal ASD detection framework using deep neural networks (DNN) with explainable AI (xAI) to enhance model transparency. Our model achieves a mean 5-fold crossvalidation accuracy of 98.64% (± 0.86%), surpassing existing methods and demonstrating potential for clinical dependability of ASD diagnoses. The source code is available at : Multimodal-Explainable-Diagnosis-of-ASD.git"
Interpretable machine learning for the diagnosis of hyperkinetic movement disorders,"Elina Van Den Brandhof, Jan Elting, Inge Tuitert, Jelle Dalenberg, A Madelein Van Der Stouwe, Marina Tijssen, Michael Biehl","1 - Computer Science and Artificial Intelligence Univ. of Groningen -Bernoulli Institute for Mathematics Groningen NL
2 - Medical Center Groningen (UMCG) Dept. of Neurology, (b) Expertise Center Movement Disorders Groningen Univ Groningen NL
9 - Dept. of Metabolism and Systems Science College of Medicine and Health Univ. of Birmingham UK","We present a machine learning approach to the challenging differentiation of hyperkinetic movement disorders, based on accelerometric sensor data. We address the diagnosis of essential tremor and cortical myoclonus as a specific example. Generalized Matrix Relevance Learning Vector Quantization (GMLVQ) systems are applied directly to power spectra obtained from eight sensors recording upper body movements. We find excellent validation performance of the classifiers. Moreover, GMLVQ provides insight into the characteristic patterns of the phenotypes and the importance of particular frequency ranges in the spectra. We demonstrate that the explanatory power of the classifier is further enhanced when integrating information from several tasks per subject.",Regression and mathematical models,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-141.pdf,2025,58.89570552147239,"Interpretable machine learning for the diagnosis of hyperkinetic movement disorders We present a machine learning approach to the challenging differentiation of hyperkinetic movement disorders, based on accelerometric sensor data. We address the diagnosis of essential tremor and cortical myoclonus as a specific example. Generalized Matrix Relevance Learning Vector Quantization (GMLVQ) systems are applied directly to power spectra obtained from eight sensors recording upper body movements. We find excellent validation performance of the classifiers. Moreover, GMLVQ provides insight into the characteristic patterns of the phenotypes and the importance of particular frequency ranges in the spectra. We demonstrate that the explanatory power of the classifier is further enhanced when integrating information from several tasks per subject."
Compression-based kNN for Class Incremental Continual Learning,"Valerie Vaquet, Jonas Vaquet, Fabian Hinder, Barbara Hammer",1 - Machine Learning Group Bielefeld University Bielefeld Germany,"Catastrophic forgetting is a key challenge in continual learning. In the adjoining field of stream machine learning, few methods target the related problem of re-occurring drift by avoiding forgetting old data. In this work, we investigate whether we can transfer such strategies from the stream machine learning to the continual learning setup. Based on our consideration, we propose a simple yet efficient compression-based kNN scheme and evaluate it experimentally.",Statistical learning and optimization,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-176.pdf,2025,53.333333333333336,"Compression-based kNN for Class Incremental Continual Learning Catastrophic forgetting is a key challenge in continual learning. In the adjoining field of stream machine learning, few methods target the related problem of re-occurring drift by avoiding forgetting old data. In this work, we investigate whether we can transfer such strategies from the stream machine learning to the continual learning setup. Based on our consideration, we propose a simple yet efficient compression-based kNN scheme and evaluate it experimentally."
"Hierarchical decomposition through ""Mental Images"" evaluation","Gianluca Coda, Massimo De Gregorio, Antonio Sorgente, Paolo Vanacore",1 - Istituto di Scienze Applicate e Sistemi Intelligenti -CNR Italy,"Hierarchical Decomposition Methods (HDMs) are techniques that handle multi-class classification problems by breaking them down into smaller, more manageable binary classification tasks, typically achieving better accuracy than flat classification approaches. In this work, a new HDM based on the exploitation of DRASiW ""Mental Images"" to construct the optimal tree model is presented. Through experiments performed on 26 standard datasets, we show how this approach improves the system classification performance with respect to the classical flat classification.","Information Visualisation and Machine Learning: Techniques, Validation and Integration",https://www.esann.org/sites/default/files/proceedings/legacy/es2016-29.pdf,2025,53.23741007194245,"Hierarchical decomposition through ""Mental Images"" evaluation Hierarchical Decomposition Methods (HDMs) are techniques that handle multi-class classification problems by breaking them down into smaller, more manageable binary classification tasks, typically achieving better accuracy than flat classification approaches. In this work, a new HDM based on the exploitation of DRASiW ""Mental Images"" to construct the optimal tree model is presented. Through experiments performed on 26 standard datasets, we show how this approach improves the system classification performance with respect to the classical flat classification."
Encoding Higher-Order Logic in Spatio-Temporal Hypergraphs for Neuro-Symbolic Learning,"Bikram Pratim, Amylia Saadi, Amar Ramdane-Cherif","1 - LISV Laboratory Université Paris-Saclay 10-12 Avenue of Europe 78140 Vélizy France
3 - ESME Sudria 38 rue Molière 94200 Ivry sur seine France","This work integrates Monadic Second-Order (MSO) logic into Spatio-Temporal Heterogeneous Hypergraphs (STHH) to advance Neuro-Symbolic AI. By bridging higher-ordered symbolic logic with neural computations, STHH offers a novel framework for knowledge representation and learning. Evaluations on a custom agricultural dataset show that the proposed STHH outperforms state-of-the-art hypergraph models across F1-score, accuracy, and AUC metrics. Despite challenges such as limited standardized datasets, this study underscores the potential of integrating higher-ordered symbolic logic into neural systems to achieve robust and interpretable AI.",Continual Learning beyond classification,https://doi.org/10.14428/esann/2022.ES2022-83,2025,50.0,"Encoding Higher-Order Logic in Spatio-Temporal Hypergraphs for Neuro-Symbolic Learning This work integrates Monadic Second-Order (MSO) logic into Spatio-Temporal Heterogeneous Hypergraphs (STHH) to advance Neuro-Symbolic AI. By bridging higher-ordered symbolic logic with neural computations, STHH offers a novel framework for knowledge representation and learning. Evaluations on a custom agricultural dataset show that the proposed STHH outperforms state-of-the-art hypergraph models across F1-score, accuracy, and AUC metrics. Despite challenges such as limited standardized datasets, this study underscores the potential of integrating higher-ordered symbolic logic into neural systems to achieve robust and interpretable AI."
CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks,"Andrei Tomut, Saeed Jahromi, Abhijoy Sarkar, Uygar Kurt, Sukhbinder Singh, Faysal Ishtiaq, César Muñoz, Prabdeep Singh Bajaj, Ali Elborady, Gianni Del Bimbo, et al.","1 - Multiverse Computing Parque Cientifico y Tecnológico de Gipuzkoa 170 2 • Planta 20014 Paseo de Miramón, Donostia / San Sebastián Spain
2 - Catalan Institute of Nanoscience and Nanotechnology (ICN2) CSIC The Barcelona Institute of Science and Technology Campus UAB 08193 Bellaterra Catalonia Spain
4 - Donostia International Physics Center Paseo Manuel de Lardizabal 4 E-20018 San Sebastián Spain
7 - Centre for Social Innovation Multiverse Computing 192 Spadina Avenue Suite 509 M5T 2C2 Toronto ON Canada
23 - Ikerbasque Foundation for Science Maria Diaz de Haro 3 E-48013 Bilbao Spain","Large Language Models (LLMs) like ChatGPT and LlaMA offer immense opportunities but face challenges due to their vast size, leading to high training/inference costs and energy demands. Traditional compression methods focus on reducing neurons or precision. We introduce CompactifAI, a novel LLM compression using quantum-inspired Tensor Networks to compress the model's correlation space. Testing on LlaMA-2 7B showed a 93% memory and 70% parameter reduction, with minimal accuracy loss (2-3%) and significant training (50%) and inference (25%) speedups.",Language models,https://doi.org/10.14428/esann/2024.ES2024-129,2025,53.987730061349694,"CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks Large Language Models (LLMs) like ChatGPT and LlaMA offer immense opportunities but face challenges due to their vast size, leading to high training/inference costs and energy demands. Traditional compression methods focus on reducing neurons or precision. We introduce CompactifAI, a novel LLM compression using quantum-inspired Tensor Networks to compress the model's correlation space. Testing on LlaMA-2 7B showed a 93% memory and 70% parameter reduction, with minimal accuracy loss (2-3%) and significant training (50%) and inference (25%) speedups."
D4: Distance Diffusion for a Truly Equivariant Molecular Design,"Samuel Cognolato, Davide Rigoni, Marco Ballarini, Luciano Serafini, Stefano Moro, Alessandro Sperduti","1 - University of Padova -Dept of Mathematics ""Tullio Levi-Civita"" Via Trieste 63 35121 Padova Italy
2 - Fondazione Bruno Kessler Via Sommarive 18 38123 Trento -Italy
3 - Dept of Pharmaceutical and Pharmacological Sciences Via Marzolo University of Padova 35131 Padova -Italy
9 - Dept of Information Engineering and Computer Science University of Trento Via Sommarive, 9 38123 Trento Italy","Recent years have witnessed an increase in interest in leveraging generative models for de novo molecular design in drug discovery. Many State-of-the-Art (SotA) models incorporate the 3D structural information of the molecule, particularly atomic spatial coordinates. However, such approaches face challenges integrating SE(3) equivariance when trained on coordinates. This work explores the use of the distance matrix for molecular structures, natively SE(3) invariant, avoiding whatever the issue. Experimental evaluation shows that our proposed approach significantly improves upon MiDi, a SotA 3D molecule generator.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-100,2025,49.25373134328358,"D4: Distance Diffusion for a Truly Equivariant Molecular Design Recent years have witnessed an increase in interest in leveraging generative models for de novo molecular design in drug discovery. Many State-of-the-Art (SotA) models incorporate the 3D structural information of the molecule, particularly atomic spatial coordinates. However, such approaches face challenges integrating SE(3) equivariance when trained on coordinates. This work explores the use of the distance matrix for molecular structures, natively SE(3) invariant, avoiding whatever the issue. Experimental evaluation shows that our proposed approach significantly improves upon MiDi, a SotA 3D molecule generator."
Solar Panel Segmentation on Aerial Images using Color and Elevation Information,"Gerrit Luimstra, Kerstin Bunte",1 - Faculty of Science and Engineering University of Groningen,"The automatic detection of solar panels from aerial imagery is highly desirable for energy planning and urban development in the Netherlands, where such data has not been extensively explored. To address this gap, we publicise a new annotated dataset, tailored for the Dutch landscape, and compare several state-of-the-art semantic segmentation models. While traditional approaches primarily utilize RGB data, we incorporate elevation and angle information in the model to analyse its potential benefit. We achieved satisfactory performance for automated solar panel detection and segmentation, with surface estimates only diverging by 1m within a 900m 2 area. The additional elevation information does not improve the performance significantly, but is more robust in certain cases.",Deep learning and graph neural networks,https://www.esann.org/sites/default/files/proceedings/2020/ES2020-156.pdf,2025,56.05095541401274,"Solar Panel Segmentation on Aerial Images using Color and Elevation Information The automatic detection of solar panels from aerial imagery is highly desirable for energy planning and urban development in the Netherlands, where such data has not been extensively explored. To address this gap, we publicise a new annotated dataset, tailored for the Dutch landscape, and compare several state-of-the-art semantic segmentation models. While traditional approaches primarily utilize RGB data, we incorporate elevation and angle information in the model to analyse its potential benefit. We achieved satisfactory performance for automated solar panel detection and segmentation, with surface estimates only diverging by 1m within a 900m 2 area. The additional elevation information does not improve the performance significantly, but is more robust in certain cases."
Adversarial Attacks for Drift Detection,"Fabian Hinder, Valerie Vaquet, Barbara Hammer",1 - Bielefeld University -Inspiration 1 33619 Bielefeld Germany,"Concept drift refers to the change of data distributions over time. While drift poses a challenge for learning models, requiring their continual adaption, it is also relevant in system monitoring to detect malfunctions, system failures, and unexpected behavior. In the latter case, the robust and reliable detection of drifts is imperative. This work studies the shortcomings of commonly used drift detection schemes. We show that they are prone to adversarial attacks, i.e., streams with undetected drift. In particular, we give necessary and sufficient conditions for their existence, provide methods for their construction, and demonstrate this behavior in experiments.","Adversarial learning, robustness and fairness",https://www.esann.org/sites/default/files/proceedings/2020/ES2020-128.pdf,2025,64.58333333333333,"Adversarial Attacks for Drift Detection Concept drift refers to the change of data distributions over time. While drift poses a challenge for learning models, requiring their continual adaption, it is also relevant in system monitoring to detect malfunctions, system failures, and unexpected behavior. In the latter case, the robust and reliable detection of drifts is imperative. This work studies the shortcomings of commonly used drift detection schemes. We show that they are prone to adversarial attacks, i.e., streams with undetected drift. In particular, we give necessary and sufficient conditions for their existence, provide methods for their construction, and demonstrate this behavior in experiments."
Implicit Neural Decision Trees,"Francesco Spinnato, Antonio Matropietro, Riccardo Guidotti","1 - University of Pisa Italy
2 - ISTI-CNR Pisa Italy","Representation learning is a central topic in machine learning, with significant efforts dedicated to encoding structured data such as sequences, trees, and graphs for various downstream tasks. A branch of these studies focuses on functional data analysis, which views data not as discrete arrays but as continuous functions. When these functions are parameterized using neural networks, they are called Implicit Neural Representations (INR). INRs have been successfully applied to represent diverse data types but, to the best of our knowledge, have not been used for encoding decision models. This work addresses the novel challenge of using INRs to represent decision trees. We introduce a tailored coordinate system and train INRs to reconstruct decision trees with a loss function to minimize node reconstruction errors. We benchmark implicit neural decision trees on several datasets, showing that they can effectively represent individual trees, and show potential extensions to tree forests through meta-learning.",Classification,https://www.esann.org/sites/default/files/proceedings/legacy/es2016-102.pdf,2025,55.55555555555556,"Implicit Neural Decision Trees Representation learning is a central topic in machine learning, with significant efforts dedicated to encoding structured data such as sequences, trees, and graphs for various downstream tasks. A branch of these studies focuses on functional data analysis, which views data not as discrete arrays but as continuous functions. When these functions are parameterized using neural networks, they are called Implicit Neural Representations (INR). INRs have been successfully applied to represent diverse data types but, to the best of our knowledge, have not been used for encoding decision models. This work addresses the novel challenge of using INRs to represent decision trees. We introduce a tailored coordinate system and train INRs to reconstruct decision trees with a loss function to minimize node reconstruction errors. We benchmark implicit neural decision trees on several datasets, showing that they can effectively represent individual trees, and show potential extensions to tree forests through meta-learning."
Generate Polyphonic Music with Multivariate Masked Autoregressive Flow,"Massimiliano Sirgiovanni, Daniele Castellana","1 - Department of Statistics, Informatics and Applications Università degli Studi di Firenze Viale Morgagni, 59 Firenze Italy","This paper explores the use of the Masked Autoregressive Flow (MAF) model for music generation, specifically addressing its limitation to univariate time series. To extend MAF for polyphonic melodies, three approaches are proposed and tested on the Lakh Pianoroll Dataset. The results show promising accuracy and the model's ability to generate original, pleasing melodies, demonstrating the potential of this innovative interdisciplinary approach.",Deep learning and Computer vision,https://doi.org/10.14428/esann/2023.ES2023-171,2025,53.691275167785236,"Generate Polyphonic Music with Multivariate Masked Autoregressive Flow This paper explores the use of the Masked Autoregressive Flow (MAF) model for music generation, specifically addressing its limitation to univariate time series. To extend MAF for polyphonic melodies, three approaches are proposed and tested on the Lakh Pianoroll Dataset. The results show promising accuracy and the model's ability to generate original, pleasing melodies, demonstrating the potential of this innovative interdisciplinary approach."
Enhancing neural link predictors for temporal knowledge graphs with temporal regularisers,"Manuel Dileo, Pasquale Minervini, Matteo Zignani, Sabrina Gaito","1 - Department of Computer Science University of Milan Italy
2 - School of Informatics University of Edinburgh UK
3 - Miniml.AI UK","The problem of link prediction in temporal knowledge graphs (TKGs) consists of finding missing links in the knowledge base under temporal constraints. Recently, [4] and [8]  proposed a solution to the problem inspired by the canonical decomposition of 4-order tensors, where they regularise the representations of time steps by learning similar transformation for adjacent timestamps. However, the impact of the choice of temporal regularisation terms is still poorly understood. In this work, we systematically analyse several choices of temporal regularisers using linear functions and recurrent architectures. In our experiments, we show that by carefully selecting the temporal regulariser and regularisation weight, a simple method like TNTComplEx [4] can produce comparable results with state-of-the-art methods and enhance its original performance. Specifically, we observe that linear regularisers for temporal smoothing based on specific nuclear norms can significantly improve the predictive accuracy of the base temporal link prediction methods.",Machine Learning for multimedia applications,https://www.esann.org/sites/default/files/proceedings/legacy/es2013-109.pdf,2025,52.121212121212125,"Enhancing neural link predictors for temporal knowledge graphs with temporal regularisers The problem of link prediction in temporal knowledge graphs (TKGs) consists of finding missing links in the knowledge base under temporal constraints. Recently, [4] and [8]  proposed a solution to the problem inspired by the canonical decomposition of 4-order tensors, where they regularise the representations of time steps by learning similar transformation for adjacent timestamps. However, the impact of the choice of temporal regularisation terms is still poorly understood. In this work, we systematically analyse several choices of temporal regularisers using linear functions and recurrent architectures. In our experiments, we show that by carefully selecting the temporal regulariser and regularisation weight, a simple method like TNTComplEx [4] can produce comparable results with state-of-the-art methods and enhance its original performance. Specifically, we observe that linear regularisers for temporal smoothing based on specific nuclear norms can significantly improve the predictive accuracy of the base temporal link prediction methods."
Analysing the impact of brain-inspired predictive coding dynamics through gradient based explainability methods,"Bhavin Choksi, Gionata Zalaffi, Giovanna Dimitri, Gemma Roig","1 - Goëthe Universität 2-Università La Sapienza, 3-DIISM Frankfurt, Rome Germany), (Italy
2 - Università di Siena Siena Italy","Multiple theories exist for the role of feedback connections in the brain and in the artificial neural networks, but remain untested using modern tools. In this work, we undertake this task by exploring the utility of explainability methods like GradCAMs[1] in investigating bio-inspired recurrent networks-provided with the predify[2] package-that perform hierarchical updates inspired by the predictive coding theory in neuroscience. We report an extensive search with different levels of feedforward and feedback information. Our preliminary results show that the dynamics are able to recover the GradCAMs on noisy images, providing promising avenues for future work aiming to understand the role of recurrence.",Manifold learning and optimization,https://www.esann.org/sites/default/files/proceedings/legacy/es2015-131.pdf,2025,52.3076923076923,"Analysing the impact of brain-inspired predictive coding dynamics through gradient based explainability methods Multiple theories exist for the role of feedback connections in the brain and in the artificial neural networks, but remain untested using modern tools. In this work, we undertake this task by exploring the utility of explainability methods like GradCAMs[1] in investigating bio-inspired recurrent networks-provided with the predify[2] package-that perform hierarchical updates inspired by the predictive coding theory in neuroscience. We report an extensive search with different levels of feedforward and feedback information. Our preliminary results show that the dynamics are able to recover the GradCAMs on noisy images, providing promising avenues for future work aiming to understand the role of recurrence."
Evaluating Text Representations Techniques for Hypernymy Detection: The Case of Arabic Language,"Randah Alharbi, Husni Al-Muhtaseb","1 - IRC for Intelligent Secure Systems King Fahd University of Petroleum and Minerals (KFUPM) Dhahran Saudi Arabia
2 - Department of Information and Computer Science","Text representation is a key component in the performance of any hypernymy-related task. In this study, we investigate representation techniques to understand which features best represent the hypernymy relation, focusing on three factors of representation: word embedding, embedding combination techniques, and using features. The results indicate that different embeddings have different effects on performance; concatenation, 'addition and subtraction' have led to better performance, and using unsupervised measures has a negative effect on performance.",Deep learning and image processing,https://www.esann.org/sites/default/files/proceedings/legacy/es2018-155.pdf,2025,55.49132947976878,"Evaluating Text Representations Techniques for Hypernymy Detection: The Case of Arabic Language Text representation is a key component in the performance of any hypernymy-related task. In this study, we investigate representation techniques to understand which features best represent the hypernymy relation, focusing on three factors of representation: word embedding, embedding combination techniques, and using features. The results indicate that different embeddings have different effects on performance; concatenation, 'addition and subtraction' have led to better performance, and using unsupervised measures has a negative effect on performance."
Altered emotion recognition from psychiatric patient profiles using Machine Learning,"Pedro Copado, Martha Cárdenas, Alfredo Vellido, Caroline König","1 - Computer Science Department and Intelligent Data Science and Artificial Intelligence IDEAI-UPC) Research Center Universitat Politècnica de Catalunya Barcelona Spain
5 - Instituto de Salud Carlos III (ISCIII) Spain
6 - German Federal Ministry of Education and Research (BMBF) Germany
7 - National Centre for Research and Development (NCBR) Agence Nationale de la Recherche (ANR) France;, Poland
8 - Agencia Nacional de Investigación y Desarrollo (ANID) Chile","Mental illnesses influence the emotion recognition capabilities of those who suffer them. This article presents a study that involves the prediction, using multi-class classification models, of several human standard emotions from facial expressions. It is based on a publicly available dataset for emotion recognition that includes socio-demographic information and psychiatric profiles of individuals with mental illnesses. The study aims to explore how effectively these models can identify and classify emotions based on facial cues, considering the diverse psychiatric backgrounds of the subjects. It also aims to investigate to what extent the severity of the psychiatric condition affects the level of certainty of the predictions.",Domain adaptation and learning,https://www.esann.org/sites/default/files/proceedings/legacy/es2019-18.pdf,2025,59.602649006622514,"Altered emotion recognition from psychiatric patient profiles using Machine Learning Mental illnesses influence the emotion recognition capabilities of those who suffer them. This article presents a study that involves the prediction, using multi-class classification models, of several human standard emotions from facial expressions. It is based on a publicly available dataset for emotion recognition that includes socio-demographic information and psychiatric profiles of individuals with mental illnesses. The study aims to explore how effectively these models can identify and classify emotions based on facial cues, considering the diverse psychiatric backgrounds of the subjects. It also aims to investigate to what extent the severity of the psychiatric condition affects the level of certainty of the predictions."
Encoding hyperspectral data with low-bond dimension quantum tensor networks,"Fabian Fischbach, Hans-Martin Rieser, Oliver Sefrin","1 - DLR Institute for AI Safety and Security -Dept. for Execution Environments -Sankt Augustin & Ulm Germany
3 - DLR Institute of Quantum Technologies -Dept. for Quantum Information and Communication -Ulm Germany","Encoding data on a quantum computer poses a major challenge on data intensive quantum applications like machine learning. In particular, data with complex internal structure like emission spectra need to be adapted to reduce the encoding effort of quantum circuits. We empirically investigate the influence of compression on the encoding of hyperspectral data into quantum states, to make its encoding more efficient. To this end, we assess the effect of approximating states by low-bond dimension matrix product states fed into a variational quantum classifier on the public Pavia University benchmark dataset.",Deep and kernel methods: best of two worlds,https://www.esann.org/sites/default/files/proceedings/legacy/es2017-50.pdf,2025,53.06122448979591,"Encoding hyperspectral data with low-bond dimension quantum tensor networks Encoding data on a quantum computer poses a major challenge on data intensive quantum applications like machine learning. In particular, data with complex internal structure like emission spectra need to be adapted to reduce the encoding effort of quantum circuits. We empirically investigate the influence of compression on the encoding of hyperspectral data into quantum states, to make its encoding more efficient. To this end, we assess the effect of approximating states by low-bond dimension matrix product states fed into a variational quantum classifier on the public Pavia University benchmark dataset."
The Role of the Learning Rate in Layered Neural Networks with ReLU Activation Function,"Otavio Citton, Frederieke Richert, Michael Biehl","1 - Computer Science and Artificial Intelligence Bernoulli Institute for Mathematics University of Groningen The Netherlands
2 - Groningen Cognitive Systems and Materials Center (CogniGron) University of Groningen Groningen The Netherlands","Using the statistical physics framework, we study the online learning dynamics in a particular case of shallow feed-forward neural networks with ReLU activation. By expanding the activation function in terms of Hermite polynomials we derive analytical results for the evolution of order parameters for any learning rate. Moreover, we compare our results with online gradient descent simulations and show how our method describes the typical learning curves. We also present results on how the learning rate affects the overall behavior of the network and its equilibria, showing different learning regimes and critical values of the learning rate. * This work is funded by NWO M1 grant OCENW.M20.287 and the Groningen Cognitive Systems and Materials Center (CogniGron).",Online learning and concept drift,https://doi.org/10.14428/esann/2024.ES2024-116,2025,72.41379310344827,"The Role of the Learning Rate in Layered Neural Networks with ReLU Activation Function Using the statistical physics framework, we study the online learning dynamics in a particular case of shallow feed-forward neural networks with ReLU activation. By expanding the activation function in terms of Hermite polynomials we derive analytical results for the evolution of order parameters for any learning rate. Moreover, we compare our results with online gradient descent simulations and show how our method describes the typical learning curves. We also present results on how the learning rate affects the overall behavior of the network and its equilibria, showing different learning regimes and critical values of the learning rate. * This work is funded by NWO M1 grant OCENW.M20.287 and the Groningen Cognitive Systems and Materials Center (CogniGron)."
Early Prediction of Dynamic Sparsity in Large Language Models,"Reza Sedghi, Amit Pal, Anand Subramoney, David Kappel","1 - Institut für Neuroinformatik Ruhr Universität Bochum Germany
3 - Department of Computer Science Royal Holloway University of London UK
5 - CITEC Bielefeld University Germany","Large language models are powerful but computationally very expensive. We investigate dynamic sparsity in attention mechanisms, using the OPT model as a case study. We explore the dynamic nature of redundancy in attention heads and analyze which components of the model provide sufficient information to predict sparsity effectively. Our findings highlight the norm of attention outputs as a reliable criterion for ranking head importance. We systematically evaluate embeddings across layers and time steps, showing that dynamic sparsity predictions can be achieved early in the model pipeline with minimal loss in accuracy. By elucidating the mechanisms underlying dynamic sparsity, this work lays a foundation for more efficient and scalable transformer models. * RS is funded by BMBF project EVENTS (16ME0733). AP is funded by BMWK project ESCADE (01MN23004D). DK is funded by project SAIL (grant no. NW21-059A). The authors gratefully acknowledge the Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu) for providing computing time on GCS JUWELS at Jülich Supercomputing Centre (JSC).","Fairness and Interpretability, Clustering, and NLP",https://doi.org/10.14428/esann/2023.ES2023-78,2025,60.0,"Early Prediction of Dynamic Sparsity in Large Language Models Large language models are powerful but computationally very expensive. We investigate dynamic sparsity in attention mechanisms, using the OPT model as a case study. We explore the dynamic nature of redundancy in attention heads and analyze which components of the model provide sufficient information to predict sparsity effectively. Our findings highlight the norm of attention outputs as a reliable criterion for ranking head importance. We systematically evaluate embeddings across layers and time steps, showing that dynamic sparsity predictions can be achieved early in the model pipeline with minimal loss in accuracy. By elucidating the mechanisms underlying dynamic sparsity, this work lays a foundation for more efficient and scalable transformer models. * RS is funded by BMBF project EVENTS (16ME0733). AP is funded by BMWK project ESCADE (01MN23004D). DK is funded by project SAIL (grant no. NW21-059A). The authors gratefully acknowledge the Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu) for providing computing time on GCS JUWELS at Jülich Supercomputing Centre (JSC)."
Enhancing Computer Vision with Knowledge: a Rummikub Case Study,"Simon Vandevelde, Laurent Mertens, Sverre Lauwers, Joost Vennekens","1 - KU Leuven -Dept. Of Computer Science J.-P. De Nayerlaan 5 2860 Sint-Katelijne-Waver Belgium
2 - Leuven.AI -KU Leuven institute for AI B-3000 Leuven Belgium","Artificial Neural Networks excel at identifying individual components in an image. However, out-of-the-box, they do not manage to correctly integrate and interpret these components as a whole. One way to alleviate this weakness is to expand the network with explicit knowledge and a separate reasoning component. In this paper, we evaluate an approach to this end, applied to the solving of the popular board game Rummikub. We demonstrate that, for this particular example, the added background knowledge is equally valuable as two-thirds of the data set, and allows to bring down the training time to half the original time.","Kernels, graphs and clustering",https://www.esann.org/sites/default/files/proceedings/legacy/es2017-24.pdf,2025,49.152542372881356,"Enhancing Computer Vision with Knowledge: a Rummikub Case Study Artificial Neural Networks excel at identifying individual components in an image. However, out-of-the-box, they do not manage to correctly integrate and interpret these components as a whole. One way to alleviate this weakness is to expand the network with explicit knowledge and a separate reasoning component. In this paper, we evaluate an approach to this end, applied to the solving of the popular board game Rummikub. We demonstrate that, for this particular example, the added background knowledge is equally valuable as two-thirds of the data set, and allows to bring down the training time to half the original time."
Linear Domain Adaptation for Robustness to Electrode Shifts,"Rui Liu, Benjamin Paaßen","1 - Faculty of Technology Bielefeld University
3 - Inspiration 1 33619 Bielefeld Germany","Machine learning approaches have shown impressive achievements in bionic prostheses control. However, translating the machine learning models from labs to patient's everyday lives remains a challenge due to various disturbances, such as electrodes shifts. To mitigate the influence of electrode shifts, we investigate two linear domain adaptation methods and a robust training approach. In experiments, we compare all methods on both simulated electrode shifts on the Ninapro DB2 data set as well as real electrode shifts on Ninapro DB8. We find that linear domain adaptation could estimate the shift and reduce the impact of electrodes shift best, but robust training approaches similar performance without the need for new data.",Classification and regression,https://doi.org/10.14428/esann/2024.ES2024-123,2025,61.53846153846154,"Linear Domain Adaptation for Robustness to Electrode Shifts Machine learning approaches have shown impressive achievements in bionic prostheses control. However, translating the machine learning models from labs to patient's everyday lives remains a challenge due to various disturbances, such as electrodes shifts. To mitigate the influence of electrode shifts, we investigate two linear domain adaptation methods and a robust training approach. In experiments, we compare all methods on both simulated electrode shifts on the Ninapro DB2 data set as well as real electrode shifts on Ninapro DB8. We find that linear domain adaptation could estimate the shift and reduce the impact of electrodes shift best, but robust training approaches similar performance without the need for new data."
